{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25cbcd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2c1708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_jsonl(data, jsonl_file):\n",
    "    with open(jsonl_file, 'w', encoding='utf-8') as file:\n",
    "        for entry in data:\n",
    "            json.dump(entry, file, ensure_ascii=False)\n",
    "            file.write('\\n')\n",
    "\n",
    "def save_json(data, json_file):\n",
    "    with open(json_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False)\n",
    "        \n",
    "def count_chinese_chars(jsonl_file):\n",
    "    chinese_char_count = 0\n",
    "    with open(jsonl_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line)\n",
    "            for key, value in json_obj.items():\n",
    "                if isinstance(value, str):\n",
    "                    chinese_char_count += count_chinese_chars_in_string(value)\n",
    "    return chinese_char_count\n",
    "\n",
    "def count_chinese_chars_in_string(string):\n",
    "    count = 0\n",
    "    for char in string:\n",
    "        if '\\u4e00' <= char <= '\\u9fff':\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea853e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'me_train.json'\n",
    "new_json_file = 'KD_train.json'\n",
    "new_jsonl_file = 'KD_train.jsonl'\n",
    "\n",
    "data = load_json(json_file)\n",
    "json_no = list(data.keys())\n",
    "data_clean = []\n",
    "for q in json_no:\n",
    "    question = data[q]['question']\n",
    "    answer_dic = data[q]['evidences']\n",
    "    for i in range(len(answer_dic.keys())):\n",
    "        if i < 10:\n",
    "            no = '#0'\n",
    "        else:\n",
    "            no = '#'\n",
    "        answer = answer_dic[q+no+str(i)]['answer']\n",
    "        evidence = answer_dic[q+no+str(i)]['evidence']\n",
    "\n",
    "        if any(re.search(answer_single, evidence) for answer_single in answer):\n",
    "            tmp = {}\n",
    "            tmp[\"question\"] = question\n",
    "            tmp[\"answer\"] = answer\n",
    "            tmp[\"evidence\"] = evidence\n",
    "            data_clean.append(tmp)\n",
    "\n",
    "save_jsonl(data_clean, new_jsonl_file)\n",
    "save_json(data_clean, new_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b566bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json('KD_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2552fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140878"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e21c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汉字数： 3313226\n"
     ]
    }
   ],
   "source": [
    "jsonl_file = 'KD_test.jsonl'\n",
    "chinese_chars_count = count_chinese_chars(jsonl_file)\n",
    "print(\"汉字数：\", chinese_chars_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 知识岛目前的数据集\n",
    "1、餐饮行业：\n",
    "\n",
    "a、餐饮行业8000问，来源：2022年和2023年餐饮行业报告与行业白皮书，由chatGPT 3.5负责整理总结，共8204条问答对，1.3M的tokens总数（680k汉字总数）\n",
    "\n",
    "2、百度知道，来源：百度知道的帖子（2017年的数据整理），共211741条问答对，1.3M的tokens总数（680k汉字总数），42M的tokens总数（21M汉字总数），由于训练数据超过git的文件上限（25mb），因此可在hugging face上查看：https://huggingface.co/datasets/LIUshu123/knowledgeDAO/tree/main/WebQA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
