{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0b8c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub\n",
    "import ebooklib\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import KnowledgeDAO as kd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "51b9ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_epub(file_path):\n",
    "    book = epub.read_epub(file_path)\n",
    "    \n",
    "    result = []\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            content = item.get_content().decode('utf-8')\n",
    "            # 处理文档内容，例如打印到控制台\n",
    "            result.append(content)\n",
    "    \n",
    "    return result\n",
    "\n",
    "#解析知乎爬虫数据，找到超过10赞的回答，若所有回答的赞同数小于10，则找最高赞回答\n",
    "\n",
    "def get_zhihu_QA(data,agreement_num = 10):\n",
    "    soup = BeautifulSoup(data[0], 'html.parser')\n",
    "    h1_tag = soup.find('h1')\n",
    "    question = h1_tag.text.strip()\n",
    "    \n",
    "    answer_list = []\n",
    "    agreement_list = []\n",
    "    \n",
    "    for i in range(1,len(data)):\n",
    "        soup1 = BeautifulSoup(data[i], 'html.parser') #html.parser\n",
    "        \n",
    "        agreement = soup1.find('p', string=re.compile(\"赞同数：\"))        \n",
    "        if agreement:\n",
    "            agreement_text = agreement.text.split('：')[1].strip()\n",
    "            if \"万\" in agreement_text:\n",
    "                # 去除空格和万字符\n",
    "                agreement_text = agreement_text.replace(\" \", \"\").replace(\"万\", \"\")\n",
    "\n",
    "                # 将字符串转换为浮点数\n",
    "                number_float = float(agreement_text)\n",
    "\n",
    "                # 将浮点数乘以一万并转换为整数\n",
    "                agreement_text = int(number_float * 10000)\n",
    "        else:\n",
    "            agreement_text = 0\n",
    "        agreement_list.append(int(agreement_text))\n",
    "            \n",
    "        if int(agreement_text) > agreement_num:\n",
    "            p_tags = soup1.find_all(['p','li'])\n",
    "            content = \"\"\n",
    "            for p_tag in p_tags:\n",
    "                if 'data-pid'  in p_tag.attrs:\n",
    "                    text_p = p_tag.text.strip()\n",
    "                    content += text_p\n",
    "            \n",
    "            answer_list.append(content)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    if max(agreement_list) <= agreement_num:\n",
    "        num = agreement_list.index(max(agreement_list))\n",
    "        soup_max = BeautifulSoup(data[num], 'html.parser')\n",
    "        p_tags_max = soup_max.find_all(['p','li'])\n",
    "        content_max = \"\"\n",
    "        for p_tag in p_tags_max:\n",
    "            if 'data-pid'  in p_tag.attrs:\n",
    "                text_max = p_tag.text.strip()\n",
    "                content_max += text_max\n",
    "\n",
    "        answer_list.append(content_max)\n",
    "        \n",
    "    return question,answer_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6e5d6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例使用\n",
    "folder_path = 'D:/GPT/Data/Zhihu/Quant_QA/data'\n",
    "epub_file_list = kd.get_file_names(folder_path) # EPUB文件路径\n",
    "\n",
    "qa = []\n",
    "# 读取EPUB文件\n",
    "for i in range(len(epub_file_list)):\n",
    "    data = read_epub(folder_path+'/'+epub_file_list[i])\n",
    "    question,answer_list = get_zhihu_QA(data,agreement_num = 10)\n",
    "    \n",
    "    if answer_list == ['']:\n",
    "        continue\n",
    "    else:\n",
    "        qa_dic = {\n",
    "            \"Question\":question[5:],\n",
    "            **{f\"Answer_{num+1}\": answer for num, answer in enumerate(answer_list)}\n",
    "        }\n",
    "        qa.append(qa_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "13acf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd.save_json(qa,\"Zhihu_Quant_QA.json\")\n",
    "kd.save_jsonl(qa,\"Zhihu_Quant_QA.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7e6d0611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625325\n"
     ]
    }
   ],
   "source": [
    "size = kd.count_chinese_chars(\"Zhihu_Quant_QA.jsonl\")\n",
    "#sizes = kd.count_chinese_chars_in_string(qa)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b23b0f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023年个人做量化交易靠谱吗？'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "16d6db86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "print(len(qa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d37d9d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question': '2023年个人做量化交易靠谱吗？', 'Answer_1': 'chatgpt都出来了，你觉得量化还有前途？做辅助还行，单纯的量化早晚被ai淘汰。不会长久的。不要相信什么量化冠军，稳定盈利，一个系统吃一辈子的话了。'}\n"
     ]
    }
   ],
   "source": [
    "print(qa[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc3b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
