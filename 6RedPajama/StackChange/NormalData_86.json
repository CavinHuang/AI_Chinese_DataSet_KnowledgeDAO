["Q: Airplay XPC Helper consuming 2.5 GB of memory? Activity monitor showing Airplay XPC Helper process using 2.5GB of memory which seems like an obnoxious amount of memory for a Mac OS native audio network process. I do use Airplay regularly when home to stream Apple Music audio to Airplay speakers on the network. However currently, at the time of screenshot, I'm remote and NOT doing that, still this process is consuming this much memory.\nIs there any reason / explanation for this or is this a true memory leak issue?\n\n\nA: 2.5 GB seems a lot, it's 6.4 MB here. If memory is tight, you can kill the process from within Activity Monitor or with sudo kill -9 PID, it will restart automatically.\n", "Q: How do I limit the number of emails downloaded in Apple Mail for iOS 16? After several years with an Android phone, I have an iPhone again.\nI have a few Gmail accounts, as well as an iCloud account (from years ago).\nI connected one Gmail account, and the iCloud account is connected automatically.\nHowever, immediately the Apple Mail app started downloading thousands of emails. It seems to have downloaded the entire iCloud mail history, as well as all the Gmail emails. In addition, it loaded thousands of Gmail emails into \"spam\", even though they weren't marked as spam before. I tried to move all of the Gmail emails from spam to the Inbox, which means, of course, that I may have moved some actual spam emails to. But today when I go to my Gmail inbox, I have no emails for the last year -- they are there, in \"All Mail\", but not in \"Inbox\" nor in \"Spam\".\nUnderstandably I'm a bit frustrated. Not sure where things are going wrong, but any help would be appreciated.\nTo start, I'd really appreciate being able to limit the emails in my iPhone to a reasonable limit -- the last month, for example. Is there any way to do this? I was told to look for \"days to sync\", but I cannot find this for iCloud or Gmail email accounts -- I click on account settings, and don't see anything. The phone is running iOS 16, so I don't know if they've moved it/removed it.\nIf I find a way to limit the number of emails downloaded, what do I need to do to remove the thousands already downloaded? Do I need to remove the Gmail account and add it again? And for the iCloud account? (If I just delete the emails on my iPhone, unfortunately they'll be deleted everywhere, which isn't what I want).\n\nA: I think the 'Mail Days to Sync' setting is only available for Exchange accounts such as M365. IMAP accounts such as iCloud and Gmail don't have this option.\n", "Q: Strange Disk Image File (.dmg) problem - deleted files in xyz.dmg do not relinquish file space Hardware & OS used:\n\n*\n\n*Mac Studio M1 Max 32GB mem 1TB SSD Mac OS Ventura 13.2\n\n*Mac Mini M1 16GB mem, 1TB SSD Mac OS Ventura 13.2\n\n*Mac Mini Intel i7 32GB mem, 1TB SSD, Mac OS Ventura 13.2\n\nBackground:\nCurrently using Veracrypt software container to store sensitive files. Update files within this secured container (after mounting) with Free File Sync works perfectly.\nObjective:\nWould like to change this way of operating to Apple’s own software ecosystem by using an encrypted .DMG, created with disk utility.\nFollowed procedure:\nIn Disk Utility, select File > New Image > Blank Image, then save with name File.dmg and select location.\nSelect name, select Size: 1GB, Format: APFS, select Encryption (enter password), Partitions: GUID Partition map, Image Format: read/write disk image, then click Save\nFile.dmg was created with a password. Works perfectly, mount and dismount.\nThe problem/issue on all three Macs:\nIf I now manually add files to this mounted disk image, all works fine. However, when I want to delete some files, the obsolete files disappear in the Finder view (also when displaying hidden files) but they keep occupying space in file.dmg.\nYou can perfectly see this with the “Get Info” tab in Finder.\nSo my allocated 1GB gets very rapidly full as deleted files don’t hand back available file space to the system. I have tried all sorts of combinations (parameters) while creating a .dmg in Disk Utility, but the problem remains.\nThe only way in which I am able to reclaim the “lost” file space is to manually empty the Trash.  I think this is not right as deleting files on an HDD or SSD should relinquish the space the moment the files are deleted and are being placed in the Trash, this pending final deletion.\nIs anyone else experiencing this problem or am I doing something wrong?\n\nA: Deleted data goes to the Trash. Files in Trash are still considered as part of the total disk usage until the Trash is emptied.\nTrash does not recycle itself like Windows, though it has a 30-day timer [optional] to selectively fully delete files older than 30 days, similar to how many things on iOS work. If you start with an empty Trash bin, then you can see this in operation more easily. you can see items appear & disappear as you mount/unmount the dmg.\nIf you want to permanently delete items without emptying the entire Trash, delete them using\n Cmd ⌘   Opt ⌥  Delete ⌦\nYou can also selectively delete items from Trash permanently by the same method, or from the right click menu.\n", "Q: Numbers Mac Link Date Cells I would like to link cells formatted as dates together so that I can change the date in one cell and have all the  dates change to go in order from that date. So if I format the cells to go from Jan 1 2023 to Jan 31 2023, I'd like to be able to change Jan 1 2023 to Jan 1 2024 and the rest of the cells change to that year automatically.\n\nA: I put this into B1:\n=A1+365\n\nWhen cell A1 has 1 Jan 2023 in it.\nSo if you change A1 to 1 Jan 2024, then B1 will become 1 Jan 2025 and so on.\nThis works because the dates are actually stored as a serial number representing days, so adding x days like 30 or 31 will give the next month.\n\nDo check out the date functions like month etc that exist which can make other tasks easier.\n", "Q: How do I make an offline recovery USB for MacOS Monterey? I have a Macbook Pro from 2015 with a MacOS Monterey 12.6\nI want to make a recovery USB for it\nI tried following instructions here, https://mrmacintosh.com/how-to-create-a-bootable-macos-12-beta-usb-drive-in-5-min/\nbut after I clicked update now as mentioned in its step 1, and after waiting for about 30 seconds, I did not see any \"Install MacOS Monterey\" file in the Applications folder. Since this step did not work I have not tried the \"Install InstallAssistant.pkg\" method mentioned in its step 3.\nI also found this video https://www.youtube.com/watch?v=rgHyvj_nWCU which says to search for the MacOS Monterey installer in the App store, but when I search for monterey I don't see the installer in the result either. I can't find the official apple link for a recovery USB iso either.\nCould someone explain or point me to a tutorial on how to make an offline bootable MacOS Monterey USB recovery drive?\n\nA: You can use the command below to list which versions of macOS full installers are available to download on your Mac.\nsoftwareupdate --list-full-installers\n\n\nNote: This list only includes versions of macOS that Apple will allow you to download to your Mac. The actual list available downloads is probably longer.\n\nMonterey should appear in the list at least once. You can use softwareupdate to download a listed version of macOS. For example, if macOS Monterey 12.6.3 is shown, then command below would download this release.\nsoftwareupdate --fetch-full-installer --full-installer-version 12.6.3\n\nYou can get more information by entering the command below.\nsoftwareupdate --help\n\n\nThe steps below were taken from the Apple website Create a bootable installer for macOS.\n\n*\n\n*Format as Mac OS Extended a 16 GB or larger USB flash drive. Use the name MyVolume.\n\n\n*Enter the command below.\nsudo /Applications/Install\\ macOS\\ Monterey.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume\n\n \n\nA: The instructions are here.\nhttps://support.apple.com/en-us/HT201372\nThere are no ISO's, of course.  There never have been.\n", "Q: iOS/Notes app…Note lost after app crash…possible to recover? I was editing a note in the iOS Notes app (iPhone 13, iOS 16.1.1) when I had an app crash and lost the entire content of my note. Possible to restore in any way?\nI was editing a lengthy note, and while in the process of highlighting several blank rows to delete them from the text, my entire phone froze for several seconds. The entire screen greyed out and did not respond to any inputs. Then the app crashed altogether. When I restarted, my lengthy note that I had been editing was gone, and a new, blank note was open. The recently deleted folder was empty both on my phone and in iCloud.\nIm not entirely sure what happened, but as best as I can piece together, at some point during the freeze while I was trying to get the phone to respond, the “select all” option may have been activated and the entire text was deleted or cut. Which I guess aligns with the empty “new” note when I reopened the app.\nI tried to shake/undo inside the new note, but this didn’t do anything, as there was apparently nothing in the clipboard to restore.\nIs there any possibility of restoring the lost text?\nThe entire note, though quite long and compiled over several days, is still newer than my most recent total phone backup.\n\nA: This isn’t going to help you now, but for future reference, if you swipe left/right in Notes with three fingers it will undo/redo.\n", "Q: Admin account not in sudoers On my MacBook (OS 12.6.1) I have a primary account and a secondary one, which is an admin. In the terminal, I can su into the secondary one. However, if I try to use sudo then, I see that the admin account is somehow not listed as a sudoer.\nThe Mac is is a work one. There could be corporate intervention for all I know.\nIs there any way to restore the sudo rights using the admin powers alone (i. e. without using the terminal)?\n\nA: Probably corporate interference.\nCreated a brand new admin user, that one was in sudoers right away, used that new admin to edit the sudoers file and re-add the original designated admin account.\n", "Q: How do I turn off ONLY sounds for notifications? I want to set up my phone so that I have a ringtone and get notifications without sound (haptic only). I have tried 1000 different combinations and didn't manage to do it as I want but I noticed something strange:\nLet's take instagram for example - when I go to Settings>Sounds and Haptics and turn off Play Haptics in Ring mode it turns off vibrations as suggested and there is sound alerts when receiving notifications. But when I go to Settings>Notifications>Instragram and and turn off Sounds it turns off BOTH sounds and haptics. Now is that normal or is that a bug.\nI just want to have a ringtone for all incoming calls and put notifications on vibration.\nnew user using iphone12\n\nA: Get a “silent” notification tone\nThe easiest way to accomplish what you’re looking for is to use a silent notification tone/alert for your notifications.  You can record one with QuickTime or download one off the Internet.  A wuick search yielded these royalty free sound files of silence\nJust use Apple Music (iTunes if on Windows) to sync them to your phone and assign the new file for your notifications.\nThe downside to this is that if you want to re-enable tones for all the alert types, you’ll have to do each one manually.\n", "Q: Why does `/usr/bin/java` exist when java is not installed? It seems that /usr/bin/java exists on my mac even though java isn't installed.\n$ which java\n/usr/bin/java\n$ java --version\nThe operation couldn’t be completed. Unable to locate a Java Runtime.\nPlease visit http://www.java.com for information on installing Java.\n\n$ ls -lah /usr/bin/java\n-rwxr-xr-x  52 root  wheel   164K Oct 18 05:36 /usr/bin/java\n\nIf there is no Java Runtime on my machine, then what is inside the /usr/bin/java file? Wouldn't it be better for /usr/bin/java to not exist when java is not installed?\nI am pretty sure this is specific to mac, since I seem to remember when using other operating systems that when java isn't installed, the java command doesn't exist. (If that's not accurate, let me know and I can move this question to superuser.)\nA good answer to this question will explain the difference and the relationship between the java command and the Java Runtime on macOS.\n\nA: /usr/bin/java is a program supplied by Apple that chooses one of several Java JREs to be used if any are installed.\nIf you do not have any installed, then  the message shown will be displayed.\nIf you have any JREs installed then /usr/bin/java will run the one specified by the environment variable JAVA_HOME.\n", "Q: MacBook Pro: Android File Transfer, says \"Could not connect\" even though my Android phone gets the 'Allow' notification. Restarted needed MacBook Pro: Everytime I want to use the Android File Transfer, it says \"Could not connect to Device. Try reconnecting or restarting your device\" even though I am connected and my Android phone gets the 'Allow' notification and I allow it. I have to restart my computer each time with it connected.\nUnless I restart my computer with the cable already connected, my Macbook doesn't recognize my android. This issue started a few months ago, was working fine before then. It's time consuming to need to restart my computer anytime I want to take files off of it.\nThis the intel macbook pro, running 13.1\nThe phone is a samsung A52, completely up to date with android 13\n\nA: I'm sorry if I'm not solving your problem directly, but AFT has been super buggy for me too, I even tried OpenMTP and other alternatives to transfer files via a cable, but all of them face similar issues. So, I shifted to using Syncthing to directly sync my files from Android to Mac wirelessly. You can also try using Soduto on your MacOS device to send files wirelessly using KDE Connect. All of these applications are FOSS. Hope this helps.\n", "Q: Big Sur - Detecting when the screen has turned off Is there a way under MacOS Big Sur (11.7.3) to detect when power-saver mode has kicked in and the screen has turned off?\nI want to have a special utility run every time the screen turns off.\nIs this possible?\nThank you very much in advance.\n\nA: The NSWorkspace notification NSWorkspaceScreensDidSleepNotification is issued when the display sleeps.\nFor a CoreFoundation approach see the Stack Overflow question Check if display is at sleep or receive sleep notifications.\n", "Q: Trying to catalog my movie collection into Numbers app and \"48 hours\" becomes \"2d\" I can type into a cell \"40 year old virgin\" but I can't put in \"48 hours\" as it gets changed to \"2d\".\nWhat nonsensical setting is making this happen?\nAlso if I type in \"21\" (for the Movie 21) it right aligns, so I think it is also doing the same weird thing.\n\n\nA: By default, Numbers formats table cells automatically. If you enter only a numeric character, it assumes it is a number and displays it accordingly. Entries that look like durations are automatically displayed under the most appropriate duration format.\nIf you want automatic formatting not to apply to certain cells, you should set the formats for those cells using the Data Format option under the Format  -> Cell sidebar menu, preferably before starting to enter the data.\nIf you are entering movie titles, for example, format the cells to hold the titles as Text beforehand. If you do that, neither \"48 hours\" will be recognized and displayed as a duration nor \"21\" will be displayed as a right-aligned number.\nAnother way to make sure what you are entering in a cell is recognized as text even without formatting is to type a single quote ' first.\nSee the “Format dates, currency, and more in Numbers on Mac” Apple support webpage for more.\n", "Q: Make Audio Capture Engine (ACE) to act as an Input Device for Quicktime Screen Recording so currently I am running macOS Ventura 13.1 on MacBook Air M1 model. For Discord, I managed to download Rogue Amoeba's Audio Capture Engine (ACE) for screen share audio.\nI am interested in knowing is there a way for me to establish an aggregate device on Audio MIDI Setup so that I can utilise both the ACE and my microphone (if need be)? At the moment, my recognised audio devices do not showcase the ACE plugin.\nthank you in advance.\n\nA: As far as I'm aware, ACE needs to be called specifically by any app that uses it. It doesn't ordinarily appear as an audio device itself. Rogue Amoeba licence their technology to other companies so they can use it in their own structures.\nAudio Hijack uses the same technology to insert itself into any point on the audio path. Loopback provides a way to expose inputs & outputs to the system itself, so they can be used for inter-application routing, Aggregate & Multi-Output Devices.\nBoth the Rogue Amoeba apps have free trials, so you could test.\nThere's a freeware alternative to Loopback [which I've never tested personally] called Black Hole, that seems to be able to do a similar thing. I have no idea whether this can integrate both ACE & non-ACE audio paths.\n", "Q: \"do shell script\" fails with complaint about \"env\" and \"No such file or directory\" but the path for the command is correct Background: texdoc is a command installed by the LaTeX distribution MacTeX and which texdoc in the Terminal gives \"/Library/TeX/texbin/texdoc\".\nIn the Terminal, texdoc --version gives:\nTexdoc 3.4.1 (2022-03-19).\nBut in AppleScript, via do shell script, this didn't work.\ndo shell script \"/Library/TeX/texbin/texdoc --version\" gives the error:\nerror \"env: texlua: No such file or directory\" number 127.\nI don't understand why AppleScript speak about \"texlua\" not found and \"env\" (by the way which texlua gives \"/Library/TeX/texbin/texlua\").\nHow to call texdoc with do shell script?\nEdit\nIn fact, not only I can not call directly texdoc --version, but after this is resolved by append /Library/TeX/texbin: to the path, a real usage case is still not working, eg do shell script \"texdoc url\", even if I append /Library/TeX/texbin: to the path. Applescript complaints that it does not find the open command (open is called by texdoc to display the pdf documentation. Very strange, because when called directly, eg do shell script \"open /usr/local/texlive/2022/texmf-dist/doc/latex/url/url.pdf\", this works.\nSo, after adding export PATH='/Library/TeX/texbin:$PATH';, the AppleScript code :\ndo shell script \"export PATH='/Library/TeX/texbin:$PATH'; texdoc url\"\n\noutputs this error:\nerror \"sh: open: command not found\\rtexdoc error: Failed to execute: open \"/usr/local/texlive/2022/texmf-dist/doc/latex/url/url.pdf\"\" number 1\nSo what is the complete method to call a binary like texdoc with AppleScript?\n\nA: The very first line of /Library/TeX/texbin/texdoc\n$ head -1 /Library/TeX/texbin/texdoc\n#!/usr/bin/env texlua\n\ncalls texlua and relies on env finding the command within PATH. As AppleScripts run with the default path (which doesn't contain /Library/TeX/texbin) this will fail with the error you see.\nTo solve, use\ndo shell script \"PATH=/Library/TeX/texbin:$PATH texdoc --version\"\n\ninstead which makes sure PATH includes your texbin directory.\n", "Q: \"Security Settings prevented XYZ Software from Loading\" windows has not option to close I am trying to install a software for a graphical tablet called Wacom. On restarting my laptop after installing its device drivers, I see a warning on my desktop saying \"Security Settings prevented Wacom System Software from Loading\".\nThe only action possible is to click 'try again'. There is no option to close the window.\nWhy has it hijacked my screen and how can I close it?\nOS: Big Sur 11.0.1\n\n\nA: This is not a normal macOS prompt. This is from your Wacom software. Follow the instructions to be able to use the software (or uninstall the software if you do not wish to use it).\n", "Q: Encrypted and access-restricted iCloud Drive folders on iOS and iPadOS I use my iPad frequently in a teaching environment where it is unlocked and used by other people when presenting. Also, when I work with iPad in a shared office (I use iPad with Magic Keyboard as a laptop replacement), I sometimes forget to lock it when I get up for a few minutes (drinking, talking, etc.). It automatically locks after a few minutes, but — only after a few minutes.\nFolders with sensitive content should therefore be additionally protected (both encrypted on a cloud storage as well as protected against accessing them when the iPad is unlocked: passkey or biometry). This would be similar to the newly introduced protected notes in Apple‘s Notes app, which Apple introduced, I guess, for the above mentioned use-cases.\nSo, is there any way to encrypt and access-restrict a folder on iPad that is shared using iCloud Drive, without using third-party software?\n\nA: Possible (sub-optimal) solutions:\n\n*\n\n*Until a few days ago, I used the third-party app Cryptomator. It has worked most of the time but recently I have had problems, so I deleted it from my devices.\n\n\n*I‘m aware that there are other third-party tools like Cryptomator such as Boxcryptor or Tresorit. I am not writing an extensive list here since I‘m looking for a native solution with no third-party involvement for my most sensitive data.\n\n\n*To find an alternative not involving third-party software, I used the Disk Utility app on my Mac to create encrypted APFS images, both  a sparsebundle and a DMG. But I cannot open those on iPad. Interestingly, when I format an USB stick with an encrypted APFS using the Disk Utility of my Mac, I can access the files on my iPad when I connect the USB stick to it.\n\n\n*Using an encrypted ZIP file would be possible, but unzipping and zipping it every time I change its content is not what I want.\n\n\n*Dropbox offers its Vault with an additional layer of protection for folders. But I don‘t like to use another third-party cloud storage provider.\n\n\n*Apple recently introduced Advanced Data Protection for iCloud. It uses end-to-end encryption for various data including files and folders stored in iCloud Drive. However, the files are directly accessible when my iPad is unlocked. I also do not want to activate this for all my iCloud data but only for sensitive data. (I actually like it that Apple stores encryption keys for my non-sensitive data.)\n", "Q: Safari Export as PDF - crop / tile / posterize long PDF to multi pages When I save a webpage with Safari's > File > Export as PDF...\nSafari renders a long PDF in several (long) pages.\nHere a screenshot of Preview's Crop Inspector, 200 inch seems to be the height values for each page.\nSometimes have over 10 pages because the webpages get pretty long with +100 comments.\n\n\nSo now I want to crop, tile or posterize these long pages into normal height.\nI want to read them in portrait orientation on on old iPad 2 which has a screen resolution of 768px x 1024px.\nThe PDF I saved with Safari has already the 768px width because I used the Responsive Design Mode\nI tried following tools to crop / tile / posterize the long pages:\n\n*\n\n*ADOBE ACROBRAT PRO DC\nPrint > Page Sizing & Handling > Poster > Print\n! The app crashes\n\n\n*BRISS\nNever been able to get the crop arguments to work from the command line\nAuto cropping to a certain height does not work, even not in GUI mode\n\n\n*PDFTILECUT\nSeems to work but can't set the margins to zero, get rid of the trim marks and set the -tile-size value correctly\n\n\n*PDFPOSTER\nError in the Terminal\npdfposter: error: The input-file is either currupt or no PDF at all: Invalid Elementary Object starting with b'b' @7: b'3\\n%\\xc4\\xe5\\xf2\\xe5\\xeb\\xa7\\xf3\\xa0\\xd0\\xc4\\xc6\\n3 0 obj\\n<< /Filter /FlateDecode /Length 19229 >>\\nstream\\nx\\x01\\xd5\\xbdi\\x97\\x1c\\xc7\\x95'\nI don't get it, the webpage is saved to PDF by Safari and corrupt?\n\n*\n\n*UPDATE 1: I managed something in PDFPOSTER, after \"repairing\" the PDF\nI have set the height of the --poster-size BOX to something really long: 100000pt\npdfposter -v -m 768x1024pt -p 768x100000pt in.pdf out.pdf\nThat works for both pages, one after the other, but I can’t find a solution to set the Y coordinates of each page to 0\nThe pages always seem to start from the bottom of the poster size, leaving space at the top..\n\n*\n\n*UPDATE 2: attached a few pictures as why Safari > File > Print is NOT an option for me.\n\n\n*\n\n*It leaves me with borders unable to remove\n\n*Dark Mode is not applied\n\n*Responsive layouts are not applied\n\n\n\n\n\n*\n\n*UPDATE 3:\nThe last days I tried out libraries, toolkits, bindings, command line tools, modules, recipes ecc. like a mad man, but today I finally found my peace with PYPDF\nNow that I played around long enough with this Cropping and Transforming example I am confident I can do what I want.\n\nBasically with PYPDF you define:\nreader = PdfReader('mypdf.pdf')\nwriter = PdfWriter()\nI than loop over the pages page_x = reader.pages[i] from the input file, set mediaboxes for each \"new\" page and add it to the writer writer.add_page(page_x)\nFinally write out with writer.write()\nHyperlinks remain intact! \n\nA: \nWhen I save a webpage with Safari's → File → Export as PDF...\nSafari renders a long PDF in several (long) pages.\n\nThis is expected behavior.  A webpage is not a printed page.  As you've found, it can be 200 inches or more.  As stated in the comments, the correct action here would have been to utilize Print to PDF so the pagination would be the standard US Letter size (8.5\"x11\").  The print engine would have automatically handled page margins, header, footer, gutter, etc. without you having to manually do it.\nSo, how do we fix this?\n\nSo now I want to crop, tile or posterize these long pages into normal height.\n\nOption 1:  Print to PDF (again)\nUsing Adobe Acrobat or Preview, print the image to PDF using the standard settings.  This should paginate it correctly though it's impossible to guess where the page breaks would end up now.\nOption 2, Part I:  Split the image into multiple files\n\nI want to read them in portrait orientation on on old iPad 2 which has a screen resolution of 768px x 1024px...The PDF I saved with Safari has already the 768px width because I used the Responsive Design Mode\n\nFor this task, we're going to use a (free) tool called GraphicsMagick.  It's available via MacPorts, Homebrew, and direct download.\nWe are going to \"split\" the image using the convert command with the crop and adjoin operators:\nFirst, convert the PDF to an image. This is necessary because PDFs do not \"break\" easily.   For this I selected a PNG:\n% gm convert input.pdf output.png\n\nNext, crop the image by the desired (calculated) size:\ngm convert -crop 768x990 input.pdf +adjoin output%04d.pdf \n\nThe output file output%04d.pdf uses a C++ printf style %d output format. Simply put, it uses a signed four digit integer with leading zeros in the filename.  Example output0001.pdf.  This will create as many individual pages as necessary.\nPlease note:  Since it's not clear what the page margins were, I am using the raw values of US Letter or 8.5 inches wide and 11 inches long.  With the resolutions you used of 768px wide, this calculates to about 90-ish DPI; 72 DPI is the norm for a printed page whether on paper or viewing on an iPad.  The length value of 990px is calculated by multiplying 90DPI by 11 inches.\nYou might have to adjust to fit your margins.  If you do, remember to subtract the left and right margins from 8.5 then multiply by the DPI.  So, if your page has ½ inch margins all around, the formula to calculate crop size will be:  8.5 - (2*0.5) * 72.  It will be the same for the length except you'll substitute 11 for the 8.5.\nPart II:  Recombine the pages into a single PDF\nNow that we have all the individual pages created, we can recombine them into a single PDF file.  You can use either of two tools that you can use to accomplish this:  PDFtk or PDFBox.  Both are available on MacPorts, but Homebrew doesn't have PDFBox.  You'll need to download it directly from GitHub\n\n*\n\n*PDFtk:\n% pdftk *.pdf newDocument.pdf\n\n\n\n*PDFBox:\n% java -jar pdfbox-app-2.0.21.jar PDFMerger (output0001.pdf output0002.pdf...output000N.pdf) newDocument.pdf\n\n(PDFTk seems easier to use, but I've found the output \"better\" with PDFBox.  YMMV)\n\nA: On iPad you can create a screenshot with CMD-Shift-3. What many people do not know is that you can actually create a screenshot not only of the visible screen but of the whole webpage. For this, use the same keyboard combination and then tap on the little preview window that appears at the bottom left. Then, at the top, select „Full Page“.\n\n", "Q: This app won’t download on iPad and it won't let me delete So far I have tried:\n\n*\n\n*Press and holding on the app\n\n*System Prefs -> General -> Storage\n\n\n\nA: I think it is because you have the app offloaded. Go back into the storage settings, \"reinstall\" (or un-offload) the app, then try deleting.\n", "Q: How to restore data from a deleted app that uses iCloud? I deleted an app that stores data in iCloud. Then I wanted to restore the data by using Time Machine on my Mac with macOS 13.2. Unfortunately, when I started Time Machine in the iCloud folder, it does not show me the folder of the deleted app, not even for previous times.\nHow can I restore an iCloud folder of a deleted app with Time Machine to a different location?\n\nA: In navigated to ~/Library/Mobile\\ Documents/ in Finder. Then I started Time Machine from there. Within Time Machine, I could navigate into this folder and I saw a list of all folders that were previously hidden.\nHowever, restoring the desired directory was tricky as well because it was restored by default to the original folder, which was and is not visible.\nThe trick is to tap on the little button with the circle and the three dots and then select “Restore Cryptomator to…“ (see screenshot below).\n\n", "Q: Can‘t delete a folder from iCloud Drive I deleted the app Cryptomator from all my devices. I also tried to delete its iCloud data on iPhone, iPad and Mac.\nOn iPhone and iPad, I went to iCloud — Manage Account Storage, I tapped on the entry and selected „Delete Data“. Even after hours, the size was unchanged at 12.9 GB.\nThen I tried the same on my Mac. Here, I got an explicit error message stating that the data could not be deleted and I should try again later.\nFinally, I used the Mac Terminal app to delete the folder in Mobile Documents on my Mac, but the data is still in iCloud and taking space.\nWhat can I do?\n\n\nA: I noticed that my MacBook started to upload literally everything to iCloud. A few hours later, the Cryptomator 2 folder was gone and the space is now available.\n", "Q: Why is my iPhone crashing and reporting higher battery percentage? I have an iPhone 6S and the battery is starting to reach the end of its useful lifetime. What I am noticing is how I can get the battery down to about 10 or 20 percent, power the phone off (completely, as if to reboot) then come back a few minutes later (not plugging it in) and then the battery reads out higher then when I turned it off. I’ve tested this a few times and the phone seems to be able to do this on command. As far as I know, wireless charging wasn’t a thing until the iPhone X, and I’m using a 6S.\n\nA: It's well observed that when a battery gets towards the end of life, the % indicator can be unreliable.\nApple's battery replacement charges are quite reasonable, and well worth it, to extend the useful life of a phone.\n\nA: In broad strokes - the phone hasn't a clue how much charge the battery has. Because it's so old & worn out, its guesswork is getting worse. After a reboot it will have another think, but none of the figures will actually be accurate, merely new guesses.\nBy comparison, by the time I traded up my 6S it had gone through two batteries, lasting about 3 years each. After that point they just got really unreliable & started reporting odd figures & having random crashes, especially in the cold.\nI'd say it's time for a new battery, but it's really time for a new phone. [The 6S cannot be upgraded any further, iOS 15 was the last to support it.] A 2nd hand SE 2020 wouldn't be a bad trade up - it looks & feels like the 6s, still has TouchID not the infuriating FaceID;) The batteries are much better too, mine at 18 months old is showing 98% health. You can even use the same case, though you will need to chop a bit out of the camera hole as the SE's camera is larger.\n\nA: The phone's battery percentage is never accurate. Never ever. However, some are better than others. Doesn't matter if you phone is 1 year old or 10, that readout is only a rough guess. And your phone is a demonstration of how some guesses are better than others. As someone who is attempting to create my own tech company, I can tell you that the percent is usually based on how much voltage is being circulated through the device. That's how I build my own phone battery readout. The only problem is just like people, the older a phone gets the worse their memory and therefore guesswork can become, so your phone has to rethink itself every time it reboots because that's how rebooting works.\nI'd say that if you really are comfortable with this problem, and it doesn't make the phone unusable, you can probably squeeze a few more years out of it. I am also the owner of a 6S, and I still use it, but I wouldn't count on it to be used as (example) an emergency phone, since mine has the exact same thing going on, but mine shuts down early because it thinks it's lower than it is.\nAnd also, don't be afraid to get that battery replaced if you really are inconvenienced by this. I agree with you, I don't want to pay $400-$1000 dollars for a new phone, just to use for a year or two, then a few years later pull it out of the darn closet and squeeze the last bit of life out of it. I just wanted to say that the guy at the genius bar was lying to you, there is little to no risk in replacing your battery. The only risk would be the guy doing it is on his first day (VERY doubtful) or he screws something up big time (EVEN MORE DOUBTFUL).\nThe moral of the story is don't be afraid to change that old battery, and don't let your charge get low.\n", "Q: Apple Software Vendors I'm trying to round up a list of all of my previous software purchases through the years, but it goes back decades. I know Paddle has a front end for consumers, and I have reached out to Fastspring for support, but what other \"major\" third-party vendors have there been? I vaguely recall one going out of business within the last decade or so...\n\nA: System Information\nUse the macOS tool System Information.app to list your installed applications and where they were obtained from.\n/Applications/Utilities/System Information.app\n\nSelect Software > Applications and sort by the Obtained From column.\nWorking through this list you can discover the legal entity responsible for each piece of software on your Mac.\nLook for the Signed by entry:\nDeveloper ID Application: Entity Name (Apple Identifier), Developer ID Certification Authority, Apple Root CA\n\nThe legal name of the entity appears after the Developer ID Application: prefix. The sequence of letters and numbers in brackets after the legal name is issued by Apple and uniquely identifies the entity within Apple's internal systems.\nAn XML format of this report can be exported for bulk analysis using other tools.\nPayment Processors\nBoth Fastspring and Paddle are payment processors. These organisations handle the payment processing on behalf of the software vendor or developer. Your relationship is with the software vendor or developer.\nI suspect you are remembering the payment processor Kagi. Unfortunately Kagi shut down in July 2016 after 22 years in business.\nMac App Store\nIf you purchased the software from the Mac App Store, your contract is with Apple. Apple does not act solely as a payment processor.\nWhen you purchase software through the App Store or Mac App Store, your contractual relationship is with Apple and not the developer of the software.\n", "Q: macOS Ventura 13.0 does not show .Trash folder in my Home directory In Finder, .Trash does not appear.\n\nBut on Terminal, I can see the directory.\n\nI'd like to add Trash on the sidebar.\n\nA: I have just stumbled upon a simple way to add Trash to the Finder's sidebar in Ventura 13.2.1:\n\n*\n\n*Click on the Trash icon in the dock to open Finder showing the Trash\n\n*Either select \"Add to Sidebar\" from the File menu on the menu bar or use the shortcut Ctrl-Cmd-T\n\n\nA: The Finder based view of Trash is only available via the Bin on the Dock, so Finder will not show ~/.Trash. Essentially this is a design choice by Apple.\n~/.Trash may not be the only Trash folder in the system, and the job of the Bin is to present a consolidated view of all the files that you have permission for, in all the Trashes. This is because it's quite possible for other users to also Trash files on those other volumes, that you are not allowed to access.\nEach attached volume will have its own Trash. This can be tested by creating a new APFS volume in the existing container for your system, or connecting an external Volume, copying files to it, and then deleting them with Finder. They'll show up in the Bin, but not in ~/.Trash. They will however show up with sudo ls -lRa /Volumes/VOL/.Trashes. You'll see a subfolder under .Trashes, named for your UID (501, if you're the only user of the system), which contains the deleted files. So other users would trash files to subfolders for their UID. Again, this is why sudo would be needed because you are potentially not the only user.\nEdit March 23:\nFurther info, now possible in Ventura (maybe earlier but I can't check)  as mentioned in the better answer above, and also in https://apple.stackexchange.com/a/456614/221742\n", "Q: How can I configure Microsoft Teams on iPad so that it does not fit the incoming video(s) to the screen? By default, Microsoft Teams on iPad fits the incoming video(s) so that there is no black empty space, e.g. see the left half:\n\nInstead, I want the full video, e.g. see left half:\n\nHow can I configure Microsoft Teams on iPad so that  it does not fit the incoming video(s) to the screen?\n\nA: It seems it's not possible yet to configure Microsoft Teams on iPad so that it does not fit the incoming video(s) to the screen. As Reddit user jjgage mentioned:\n\njust pinch to zoom out on their video feed.\n\nIt works but as soon as I stop pinching, the video goes back to the default auto-fit that crops the video.\n", "Q: Will Factory Resetting my MacBook Pro (14\", 2021) slow it down? Will Factory Resetting my MacBook Pro (14\", 2021) slow it down? I want to completely reset it and delete everything on the disk, and so will the SSD become any slower when it is reset - in other words, will it have the same performance as when it is brand new? It is a very new laptop too...\n\nA: In a word no.\nThe SSD will not lose any \"data space\" whatever that might be.\nThe system might be a little slow at first as Spotlight re-indexes everything, but that passes in a day or so depending on how much personal data you have on the Mac. But really most people don't notice a thing...\nWiping your system has ZERO effect on performance.\n", "Q: How do I backup Google Authenticator on my iPhone? In 2022 I bought an iPhone 13 Pro Max. I had had an iPhone 12 Pro Max. I factory reset my iPhone 12 Pro Max and gave it to a friend who had lost his phone. My iPhone was doing a daily cloud backup. I had set up my new phone using my old phone. I thought everything was fine until I realized I had destroyed my Google Authenticator App and there seemed to be no getting it back.\nI was surprised. I had set up my new iPhone using my old iPhone. I do a daily phone backup. It did not occur to me that this would not also backup my Google Authenticator App.\nSo now having had this experience of having wiped out my Google Authenticator app on my iPhone, I want to backup my Google Authenticator app's data, the eight accounts I multifactor authenticate against using Google Authenticator app on my iPhone.\nI have Googled it, I have checked Google help and I can't seem to find the information I want which is, how do I backup Google Authenticator app on my iPhone?\n\nA: It is by design that Google Authenticator was not included in your backup - this is a decision made by Google.\nInitially there was no way of getting account information out of Google Authenticator, but back in December 2020 they added a feature to help you get account data out of the app - for example for when you get a new phone. It is still a manual process though.\nYou start with the old phone that has the account information in Google Authenticator. Open the app, tap \"Exports Accounts\" and select the accounts to export - and it will show a QR code (or more).\nThen on the new phone, install the Google Authenticator app and tap \"Import existing accounts\". Now you can scan the QR code(s) off the old phone to transfer the account information.\nFor backup purposes, you could copy the QR codes (i.e. screenshot or similar) and store them somewhere secure if you ever need to import them again on a new device.\n", "Q: Are there any issues with charging an pre-USB-C iPad with a high-wattage power adapter and a USB-C/Lightning cable? Specific configuration:\n\n*\n\n*iPad Pro 10.5\" (2017)\n\n*Anker Nano II 65W charger adapter\n\n*MTAKYI MFI-certified USB-C-to-Lightning Cable\n\nTIA!\n\nA: No, there's no issue there. The iPad will never draw more power from the charger than what it can handle.\n", "Q: looking for an SSH client that allows xwindows I've recently started using macOS. I am looking for an SSH client that allows xwindow tunneling through SSH. As suggested, I've installed Xquartz via brew but whenever I try opening an xwindow based app like gvim or Firefox, I get an error like this:\nE233: cannot open display\nI'm logging into the host like this:\nssh -X user@domain . I've also tried replacing the -X with -Y but it makes no difference at all. I've tried this with native terminal, iterm2 and termius. The latter two are great but they lack this very important feature that allows me to open things like Firefox and gvim directly from the terminal. Using putty is out of the question as it seems that it is no longer supported.\nPerhaps I am doing it wrong. Looking for tips/advice etc\n\nA: X11 isn't available in macOS by default but can be installed via XQuartz. Once installed, you can\n\n*\n\n*open Xterm and run ssh -X remotehost from there\n\n*open Xterm, run echo $DISPLAY, set the variable to the same value in Terminal and run ssh -X remotehost from Terminal\n\n", "Q: Can not claim free space after bootcamp partition, I do not want to remove my bootcamp I have removed a Container I used to have after bootcamp partition, so now I have 246.1 GB free space as can be seen in the diskutil list below:\nMacBook-Pro ~ % diskutil list                          \n/dev/disk0 (internal, physical):\n   #:                       TYPE NAME                    SIZE       IDENTIFIER\n   0:      GUID_partition_scheme                        *1.0 TB     disk0\n   1:                        EFI EFI                     314.6 MB   disk0s1\n   2:                 Apple_APFS Container disk1         625.3 GB   disk0s2\n   3:       Microsoft Basic Data BOOTCAMP                128.8 GB   disk0s4\n                    (free space)                         246.1 GB   -\n\n/dev/disk1 (synthesized):\n   #:                       TYPE NAME                    SIZE       IDENTIFIER\n   0:      APFS Container Scheme -                      +625.3 GB   disk1\n                                 Physical Store disk0s2\n   1:                APFS Volume Macintosh HD            11.7 GB    disk1s1\n   2:              APFS Snapshot com.apple.os.update-... 11.7 GB    disk1s1s1\n   3:                APFS Volume Macintosh HD - Data     248.3 GB   disk1s2\n   4:                APFS Volume Preboot                 3.7 GB     disk1s3\n   5:                APFS Volume Recovery                1.1 GB     disk1s4\n   6:                APFS Volume VM                      20.5 KB    disk1s5\n\nI have tried using diskutil apfs resizecontainer disk0s2 0, to add it to my Macintosh HD, but I have got the following, and of course I assume is because of Bootcamp partition.\ndiskutil apfs resizecontainer disk0s2 0\nStarted APFS operation\nError: -69519: The target disk is too small for this operation, or a gap is required in your partition map which is missing or too small, which is often caused by an attempt to grow a partition beyond the beginning of another partition or beyond the end of partition map usable space\n\nThe thing is, I do not want to remove my bootcamp as I have multiple configurations there.\nIs there a way to add that free space to my Macintosh disk0s2?\n\nA: You can't directly expand a volume or partition with another in the way, as you surmised. You need to move the other partition up to the end of the drive first.\nThis might be possible from the command line, but it's not something I have any experience with.\nIf you want to be able to do this from a GUI interface, the only app I know that can move & resize partitions, including Boot Camp, is Paragon Hard Disk Manager.\nThis is not something I'd attempt without a known-good backup.\n\nA: This question has be asked before. For example, see Missing around 20 GB of Space on MacBook.\nAnother similar question would be How to add to macOS (free space) from diskutil list?. Here the basic difference is you do not have a partition named OSXRESERVED. You just need to move the partition named BOOTCAMP to the end of the drive.\nIncluded with these questions are explanations of how the free software GParted or MiniTool Partition Wizard can be used to move Windows partitions on Intel Macs.\n", "Q: If I turn off iCloud Photos on my phone, will the photos I take show up on other devices? If I turn off iCloud Photos on my phone, will the photos I take show up on other devices linked to the same Apple ID?\n\nA: Assuming you will be keeping your iCloud account after turning off photos in iCloud and all your devices will remain signed in to iCloud with the same account, up to 1000 photos (not videos) you have taken in the last 30 days will be visible in those devices as part of Apple’s My Photo Stream service which is free. However, once a photo gets older than 30 days, it will be removed from My Photo Stream, remaining available only on the device it is taken.\nFor more information on this service, see the “My Photo Stream” Apple support webpage.\n", "Q: Did Apple drop/ reduce support for Chromecast? It appears to me that it is getting increasingly difficult to cast to Chromecast from my iPhone (iOS 16.1.2). Most apps still support it, but neither Safari nor Edge or Chrome allow me to cast a video to Chromecast, only to Airplay.\nI don’t cast so much, so this may have been so for a while, but I’m wondering: is Apple making it more difficult for developers to have their app support Chromecast or how can we understand that not even Chrome can cast to Chromecast?\n\nA: Apple has never supported Chromecast from its built-in apps like Safari.\nThere haven't been any substantial changes for developers to cast to Chromecast. One notable one – a number of years ago (not recent) – was the \"Local network\" prompt you might've seen. Chromecast requires communicating across the local network, and iOS requires user permission to do that.\nHowever, I wouldn't say this is a significant blocker. If the developer properly configures their app to wait to prompt until the user first tries to invoke Chromecast, it will be clear why they need the permission.\n", "Q: How to prevent Zoom from hijacking the \"Escape\" key during screen sharing with meeting controls hidden? In Zoom Screen Sharing, there is a \"meeting controls\" window by default, which can get in the way. It is possible to hide it with the ⌘ Command^ Control⌥ OptionH keyboard shortcut, which is nice.\nHowever, if you press the Esc key at any time during the screen share (for example, to stop editing in Vim, or un-focus an input field in a web form), Zoom will show the meeting controls again and steal window focus, which is quite disruptive.\nZoom does not seem to offer any settings to disable this behavior.\nRelevant Zoom community forum post here:  How can I disable Escape key binding in Zoom?\nIs there a way to prevent this, perhaps with a tool like Karabiner-Elements?\nI think what I want to do is prevent Zoom from listening to the Esc key when I am focused on other windows.\n\nA: I was able to solve this by using Hammerspoon to move the window offscreen.\nSteps:\n\n*\n\n*(Optional). If you want to use the same hotkey, go into Zoom Settings (⌘ Command,), press \"Keyboard Shortcuts\" on the left\", and scroll down to \"Show/Hide Floating Meeting Controls\" near the bottom, and clear the shortcut so it says \"Not set\".\n\n*Download & install Hammerspoon (I ran brew install hammerspoon in the Terminal). Open the application.\n\n*Add the following to ~/.hammerspoon/init.lua:\n\nlocal originalFrame = nil\n\nhs.hotkey.bind({\"cmd\", \"ctrl\", \"alt\"}, \"H\", function()\n  local zoomWindow = hs.window.find(\"zoom share statusbar window\")\n  if zoomWindow then\n    if originalFrame then\n      zoomWindow:setFrame(originalFrame)\n      originalFrame = nil\n    else\n      originalFrame = zoomWindow:frame()\n      local screen = zoomWindow:screen()\n      local frame = zoomWindow:frame()\n      frame.x = screen:frame().w + 3000\n      frame.y = screen:frame().h + 3000\n      zoomWindow:setFrame(frame)\n    end\n  end\nend)\n\nTo do this, you can open the Terminal application from Spotlight (cmd+space) and then run touch ~/.hammerspoon/init.lua and then open -A Textedit ~/.hammerspoon/init.lua and paste the above script in to the window, save it, and close it.\n\n\n*Restart Hammerspoon, and you're good to go – pressing ⌘ Command^ Control⌥ OptionH will now move the meeting controls offscreen, and pressing it again will move them back to where they were.\n\n\nCredits:\n\n*\n\n*User whatever1 in this post on the Zoom forum who suggested using BetterTouchTool for this and mentioned the name of\nthe window (thank you!).\n\n*ChatGPT, the author of ~all the above Lua code (I made a few tweaks).\n\n\n\nA: You can't prevent an app (Zoom in this case) from listening to a key press.  All applications are allowed to listen to and for key press events and act accordingly.\nIt's also important to note that the Zoom developers aren't really doing anything \"wrong\".  Per the macOS Human Interface Guidelines, universal keys and shortcuts (i.e. ⌘ CommandC/V for cut/paste) should be respected.  However, nothing is assigned to the Esc when pressed in isolation - that makes it fair game.\nThat said, it is probably a good idea to share feedback with Zoom as screen sharing is a valuable tool and it doesn't play well with other apps that use Esc for their own functions.\nThere are two potential workarounds:\n\n*\n\n*Use hidutil to remap the Esc to something else.  The downside to this is it is system wide meaning it will be remapped for every app.  This is probably something you don't want to do.\n\n\n*Use a 3rd party App like USB Overdrive ($20USD).  This is a key remapping utility similar to ControllerMate (described in detail below).  I've not tested this, but it should accomplish the same thing as CM.  YMMV.\n\n\n*ControllerMate.   It's free for a small number of building blocks, so for a single key like this you should be okay.  I personally use this to create a \"macro-board\" for apps like Photoshop Lightroom and Think-or-Swim.  You can create programming pages that only apply to specific applications - in your case, Zoom.\n\nThis second image is of the \"Page Programming sheet\" that allows you create \"building blocks\" of actions.  Here I have intercepted the Esc and set it to output a system beep.\n\nWhen I tested in Zoom, it seemed to work, but I didn't have a live Zoom call to to try it out on to see if that had any bearing on it's functionality.\n", "Q: HomePod 1st + 2nd gen I get you can’t pair them for stereo, fine. But can they simply be mixed in the same Mac / Siri network? I want to put my 1st gen upstairs, add a 2nd gen down - as the hub - and still have it all mostly work.\n\nA: Yes, you can mix any AirPlay devices in the same network and play simultaneously to them. You just can't make stereo pairs, as you note.\nFor example, you could stream to a HomePod mini, HomePod (1st gen), HomePod (2nd gen), and a Sonos device simultaneously using AirPlay.\nYour Home hub will also automatically self-select, you don't have to do anything for that to work.\n", "Q: Reduce Macbook data usage while it is connected to internet through iphone hotspot Is there a way to limit internet data usage while a Mac laptop is connected to internet through an iPhone hotspot? Some background tasks such as backing up, dropbox activity, automatic updates, can be using a large amount of data. Obviously it is possible to prevent some traffic by manually disabling some programs (e.g. Dropbox) but is there a more automated way of doing it?\n\nA: Try TripMode.\nYou can block applications on a per-network basis.\n", "Q: How to temporarily disable iPhone SIM card? It's easy to disable wi-fi connections or cellular data, but how does one disable connections to cellular networks?\nThree obvious solutions:\n\n*\n\n*use Airplane mode.\n\n*remove SIM card.\n\n*explicitly set the network to a different carrier.\n\nThe first also turns off wi-fi, the second is awkward and inconvenient, and the third burns CPU as it continually tries to connect to the wrong network.\nIs there an easy way to say that I want to use wi-fi without any cellular connection?\n(In case it makes a difference, this is specifically for an iPhone-8.)\n\nA: You can enable Airplane Mode without disabling Wi-Fi or Bluetooth.\nWhen you enable Airplane Mode, if it disables Wi-Fi just tap to re-enable Wi-Fi. It will remember your preferences for the next time you enable Airplane Mode.\n", "Q: How to get access to my iCloud backup if I neither have access to my other iDevices nor the phone number under which it was registered? About a year ago, I changed my phone number but never updated it in my iCloud account to the new one. Now, I lost access to all my iDevices and I want to restore my iCloud backup to an iPhone I got from a friend.\nThe problem is that when I enter my iCloud e-mail and password, it says that it sent an activation code to my other iDevices - but I don't have access to them. The only other option provided is a message to my phone-number, which is the old one however that doesn't exist anymore.\nI know the password of the account and I have access to the e-mail address of that iCloud account - how can I get access to it?\n\nA: Apple has a procedure called Account Recovery.  It’s considered a last resort method to access your account if you use 2FA (two factor authentication) and lost access to your devices.\n\nAccount recovery is a process designed to get you back into your Apple ID account when you don’t have enough information to reset your password. For security reasons, it might take several days or longer before you can use your account again. We know this delay is inconvenient, but it's important so that we can keep your account and information safe.\n\nBased on what you described, you are a prime candidate for this service.\n", "Q: Using multiple github accounts with ssh keys, works only first try on each account Following different pages I ended up with a ~/.ssh/config looking like this:\nHost github-personal\n  HostName github.com\n  IdentityFile ~/.ssh/one_key\n\nHost github.com\n  HostName github.com\n  IdentityFile ~/.ssh/two_key\n\nHost *\n  UseKeychain yes\n  AddKeysToAgent yes\n\nIt works fine but only on the first try on each repo after login. For example:\n\n*\n\n*Login\n\n\n*Execute git pull on a repo with ssh one_key. Successful.\n\n\n*Execute git pull on a repo with ssh two_key. Failed.\nERROR: Repository not found.\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights\nand the repository exists.\nNeed to logout\n\n\n*Login\n\n\n*Execute git pull on a repo with ssh two_key. Successful.\n\n\n*Execute git pull on a repo with ssh one_key. Failed.\nERROR: Repository not found.\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights\nand the repository exists.\nI can't get both of the keys working without logging out. Both are private repositories.\nI'm using macOS Ventura 13.2 with M2.\nAny ideas why this is happening?\n\nA: I found out I was missing IdentitiesOnly yes. My final config looks like this:\nHost github-personal\n  HostName github.com\n  IdentityFile ~/.ssh/id_ed25519\n  IdentitiesOnly yes\n\nHost github.com\n  HostName github.com\n  IdentityFile ~/.ssh/id_ed25519_imp\n  IdentitiesOnly yes\n\nHost *\n  UseKeychain yes\n  AddKeysToAgent yes\n\n", "Q: Opening drawer of empty optical drive Is there a command to tell an external optical drive to open that still works when there's no disk in it?\nIt has a button on the drawer, but it's vary tiny, and it requires a push in the opposite direction of opening.  It's so thin that I have to pick it up off the table to push it, and I have to push hard enough and not too hard.  And if I'm not fast enough, the slight pressure is enough to prevent opening.\n\nA: In the absence of an eject button on the keyboard, you may have to resort to Terminal…\n/usr/bin/drutil eject\n\n", "Q: Stop Gmail pop-up ad \"Google recommends using Chrome\" Often, when I open gmail.com in Safari for macOS, I get the following obtrusive pop-up ad in the corner of my email app:\n\n\nGoogle recommends using Chrome\nEasily search on Google with the fast, secure browser\nDon't switch | Yes\n\nI obviously want to keep using Safari, which is why I select Don't switch, but the annoying pop-up advertisement will be there next day or week when I open Gmail again.\nHow can I disable this pop-up advertisement for the Chrome browser in the gmail web interface?\n\nA: \nHow can I disable this pop-up advertisement for the Chrome browser in the gmail web interface?\n\nYou can't.\nThis is a Google (GMail) issue and has nothing to do with Safari.  Well, nothing that can be changed on Safari, actually.  Part of the issue is because you're using Safari.\nThere are two issues at play here:\n\n*\n\n*The browser's user agent string.  This is an identifier sent by your browswer to the server (Gmail) that tells it you are using a Safari browser, on a Mac running a particular version of macOS.  All browsers send this identifier.\n\n*That's not a pop-up in the traditional sense.  It's actually called a CSS Modal.  It's a CSS/Javascript element that part of the rendered page where as a traditional popup is a new window.\n\nWhat's happening here is that the Gmail server is detecting you're not using the Chrome browser and (through JavaScript) creating that modal that advertises their Chrome browser.  Unfortunately, it's the price you have to pay for utilizing a free email service - you're inundated with ads.\n\nA: Tl;Dr: In order to avoid being anoyed by this ad you have two main options:\n\n*\n\n*Find a way to prevent that the Google apps data (history) be deleted from your computer.\n\nI didn't have to do anything special on my Mac Mini with M1 and MacOs Ventura 13.1. Depending on your computer model and setup you might have to do something special.\n\n*Use an utility to block ads that keep track of the technologies used by Google to make this ad work.\n\n\nThe \"Google recommends using Chrome\" \"pop-up\" not only happens when visiting Gmail, it also happens when visiting other Google sites like Google (web search / https://www.google.com and all the country specific domains) but not all Google owned web apps, i.e. it hasn't appeared to me when using Youtube, maybe due to a business decision related to keeping brands separated.\nThis \"pop-up\" isn't managed by a setting managed on a Gmail or other Google services user settings. Based in my most recent experience, I think that the \"Don't switch\" option of this \"pop-up\" is managed by using something stored in the Safari history as clearing it makes that this \"pop-up\" appears again but Google might be using other way to store this user action.\nThe experience might vary for different users and for the same user from time to time as Google has a large history of creating variations of their web apps and target each variant to different users based on whatever they want to learn about the use of their web apps, so it might not make sense to go deeper on this as an end-user as finding way that Google apps work nowadays is not an easy task due to the way that Google develop them.\nRelated\nCookies\nCookies is a common way used in web apps to store data like user preferences in browser history\n\n*\n\n*Safari stopped remembering what is usually stored in cookies. What might have happened?\n\n*Allow cookies from certain websites?\n\n*Allowing cookies from a specific site in Safari\n\n*OS X Safari keeps forgetting cookies\n\n*Safari randomly and periodically loses cookies\nBlock ads\n\n*\n\n*How to block ads in Safari without installing anything?\n\n*What adblock extension works on macOS Safari?\n", "Q: In general, which files and directories can be deleted from MacOS without bricking it? I would like to make my MacOS as minimal as possible without it being unable to boot. The main reason is to reduce complexity and focus on understanding a smaller number of things before adding in more functionalities. In case someone were to say, \"That isn't a good way to learn,\" I would say, that's your opinion, but I would like to know out of curiosity's sake which files I can delete, and which I should not.\nI am pretty sure there are three permissions groups on Mac - staff, wheel, and admin, which is what you see when you do ls -l - drwxrwxrwx has three repetitions of \"rwx\", one for each group.\nI think \"sudo\" causes you to enter into the second-highest permissions level, but as I tried to delete some system files with sudo, I still got the message \"operation not permitted\" sometimes. Is there any command to delete those even more restricted files, or is it not a function in MacOS?\nWhat is a general explanation for which files/directories can be deleted, and which can't?\nI think there are some .plist files you can delete, but what I found so far is that when you reboot, the OS realizes something is wrong and goes into recovery mode, where I am pretty sure it regenerates a lot of the files it needs (I think I had this happen for a Bluetooth settings .plist file, for example).\nBut I am sure there are some files that comes with MacOS by default that are not needed, for example, I think I was able to get rid of the Movies and Music directories, and some system files I can't remember, I think it might have had to do with Xcode though.\nSo what can I delete without impeding or harming the system? I tried sudo rm -r * in the top level directory, because I was wondering if since sudo didn't have the absolute top-level permissions, it would not delete any truly system-critical files. So far that has appeared to be the case, as my Mac is functioning fine, but I have not rebooted yet to see what happens then. When I do sudo rm -r * in / or any directory, I get a message asking if I want to override that some file cannot be deleted. I do not see any message about what the expected responses are - \"yes\", \"y\"? Does pressing enter mean yes or no? If I hold the enter key down, there can be a huge number of such messages. Is there any way to force the override for the entire command so you do not have to manually answer \"yes\" to seemingly hundreds of such questions?\nI think some system administrators will say, \"You don't want to do that, that's a bad idea,\" but the point is I want to know what I can do that avoids the potentially destructive outcome such people may be forewarning one about.\nThank you.\n\nA: \nI would like to know out of curiosity's sake which files I can delete,\nand which I should not.\n\nFirstly, removing anything that the system expects to find is likely to cause errors.\nSecondly, macOS 'system' is now on a read-only volume that cannot normally be deleted. It is also cryptographically sealed, and attempts to modify it may result in a failure to boot.\nhttps://support.apple.com/en-gb/guide/security/secd698747c9/web\nThe benefits of 'minimality' are ... well, minimal.\nFinally, blindly deleting whatever you can and seeing what happens, is a terrible way to learn. That's not an opinion, but a didactic truth.\n\nA: You seem to have misunderstood a number of things about the system. Therefore I would highly recommend that you start by reading a macOS book or general introduction texts to operating systems in the Unix family. You'll learn much quicker that way.\nIf you want to understand an operating system as a beginner, you want to go with an educational operating system. They're made for the purpose of being easier to understand. Modern, consumer desktop operating systems are not created to be understood by a single person - they have other goals. Simply removing files until it breaks it not really going to leave you with something so small that it is understandable by a beginner.\nJust to get the misunderstandings out of the way:\n\n*\n\n*It is not so that there are three permission groups on macOS named \"staff\", \"wheel\" and \"admin\". Those are user groups - a standard system comes with a lot more than those three, and you can add more if you like. See the list in /etc/groups.\n\n\n*It is not so that the \"drwxrwxrwx\" letters means permissions for each of the three aforementioned groups. Instead the letters tells you something about read, write and execute permissions for the owner, the group and others. However this is not the whole story - some types of permissions are not expressible in this simple manner.\n\n\n*It is not so that sudo enters the \"second-highest permission level\". Instead sudo simply allows you to run a command as another user (which could include the superuser). There are operations that in some circumstances even the superuser cannot perform.\nYou ask for a command to delete \"restricted files\" - there's no such specific command. However, you can ofcourse delete files if you want - depending on the circumstances that could be by booting up in Recovery mode or by simply mounting the file system on a different computer and deleting the file.\nIn terms of \"restricted files\", it is so that modern macOS systems have a read-only volume that contains system files. Being read-only, you cannot really delete files from it in ordinary use (you can do it in other ways ofcourse, but it is generally a bad idea).\nIn general there's really nothing you can delete without \"impeding or harming the system\" - unless you take a very subjective point of view. I.e. if you never use \"Keynote\", you can delete \"Keynote\" without feeling that harms the system. If you use it every day, you cannot really delete it without feeling that harms the system. In general, if you delete something, you'll miss out on something - it might not be something you use (like a French dictionary might be of no use for you).\nNote that if you think that the system will perform \"better\" or \"faster\" after deleting these \"unnecessary\" data files - that's generally not the case.\n", "Q: Completely disconnect Apple computer from user ID I have been given an older Apple computer (the kind where everything is in the screen case), but I cannot use it, because it is linked to the Apple ID of the previous owner, who I have no means of reaching anymore.\nI have already tried to reinstall OS X (El Capitan) from USB stick (which I prepared on a Windows PC following instructions given in another thread here), but when that was done, I ended up at the login screen requiring me to enter the previous owner's credentials.\nHow do I get rid of that, so that I can link that computer to another Apple ID.\n\nA: Unfortunately, your iMac is a boat anchor.\nThe way Apple security works is that your computer is tied to your Apple ID. this is a double edged sword:  it supposedly disincentives thefts, but if you purchased a pre-owned unit that hasn’t been dissociated from the previous owner, it’s only good for parts.\nNow, this applies to Mac computers with the T2 security chip.  If you didn’t erase the drive before installing macOS, then you’ll see the previous users login.\n", "Q: Can someone help explain these iPhone network Interfaces? It seems as if there’s a lot of interfaces considering I’m not on a VPN.\niPhone $ ifconfig\nlo0: flags=8049<UP,LOOPBACK,RUNNING,MULTICAST> mtu 16384 index 1\n    options=1203<RXCSUM,TXCSUM,TXSTATUS,SW_TIMESTAMP>\n    inet 127.0.0.1 netmask 0xff000000 \nXHC0: flags=0<> mtu 0 index 2\npdp_ip2: flags=8010<POINTOPOINT,MULTICAST> mtu 1440 index 3\n    options=6463<RXCSUM,TXCSUM,TSO4,TSO6,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM>\npdp_ip0: flags=80d1<UP,POINTOPOINT,RUNNING,NOARP,MULTICAST> mtu 1440 index 4\n    options=6463<RXCSUM,TXCSUM,TSO4,TSO6,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM>\n    inet 192.0.0.2 --> 192.0.0.2 netmask 0xffffffff \npdp_ip3: flags=8010<POINTOPOINT,MULTICAST> mtu 1500 index 5\n    options=400<CHANNEL_IO>\npdp_ip1: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1440 index 6\n    options=6463<RXCSUM,TXCSUM,TSO4,TSO6,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM>\npdp_ip5: flags=8010<POINTOPOINT,MULTICAST> mtu 1500 index 7\n    options=400<CHANNEL_IO>\npdp_ip4: flags=8010<POINTOPOINT,MULTICAST> mtu 1500 index 8\n    options=400<CHANNEL_IO>\npdp_ip6: flags=8010<POINTOPOINT,MULTICAST> mtu 1500 index 9\n    options=400<CHANNEL_IO>\npdp_ip7: flags=8010<POINTOPOINT,MULTICAST> mtu 1500 index 10\n    options=400<CHANNEL_IO>\nutun0: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1500 index 11\nipsec0: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 50000 index 12\nipsec1: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1500 index 13\nipsec2: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1500 index 14\nap1: flags=8822<BROADCAST,SMART,SIMPLEX,MULTICAST> mtu 1500 index 15\n    options=400<CHANNEL_IO>\n    ether 02:00:00:00:00:00 \nen0: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 index 16\n    options=6463<RXCSUM,TXCSUM,TSO4,TSO6,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM>\n    ether 02:00:00:00:00:00 \n    inet 192.168.1.244 netmask 0xffffff00 broadcast 192.168.1.255\nanpi0: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 index 17\n    options=400<CHANNEL_IO>\n    ether 02:00:00:00:00:00 \nen1: flags=8822<BROADCAST,SMART,SIMPLEX,MULTICAST> mtu 1500 index 18\n    options=400<CHANNEL_IO>\n    ether 02:00:00:00:00:00 \nen2: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 index 19\n    options=400<CHANNEL_IO>\n    ether 02:00:00:00:00:00 \nawdl0: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 index 20\n    options=6463<RXCSUM,TXCSUM,TSO4,TSO6,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM>\n    ether 02:00:00:00:00:00 \nllw0: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 index 21\n    options=400<CHANNEL_IO>\n    ether 02:00:00:00:00:00 \nutun1: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1380 index 22\nutun2: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 2000 index 23\nutun3: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1000 index 24\nutun4: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1200 index 25\n    options=6463<RXCSUM,TXCSUM,TSO4,TSO6,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM>\nipsec3: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 2000 index 54\nipsec4: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 2000 index 55\n\n\n\nA: Since iOS and macOS are based on the same kernel, a number of these interfaces are addressed in the existing post Surprisingly many network interfaces on macOS: are these legitimate?\nAs this is a mobile device, there are some additional interfaces not present in macOS:\n\n*\n\n*ap1 is an Access Point interface.  This is if you turn it into a hotspot\n\n*llw0 is Low Latency WAN link. It is part of the (highly undocumented) SkyWalk subsystem\n\n*ipsecX are VPN links. While you aren’t using VPN currently, iOS is capable of VPN connectivity and these would be the interfaces used\n\n*pdp_ipX are cellular network interfaces like 5G, LTE, etc.\n\n*XHC0 is a USB interface likely for tethering\n\n", "Q: How to sign an application bundle with the same display name as the installer package? I can sign a bundle with \"Mac Developer\" identity which is connected to my Apple account user name (ie a \"person\").\nI can sign the package (.pkg) that contains the bundle with a \"3rd Party Mac Developer Installer\" identity (ie an \"organization\").\nThis results in the signature on the package (the organization) being different than the signature on the component (the developer that built the component).\nIt seems the \"Mac Developer\" name is hard linked to the Apple developer account and it is not possible to slide in the organization name instead.\nHow to sign components (applications, executables) with an organization name instead of a human person name?\n\nA: Apple needs to issue a new certificate with the desired organisation name. This typically requires the organisation to have an Apple Developer ID.\n\n*\n\n*Connect to the Developer Account for the organisation;\n\n*Select Certificates\n\n*Add a New Certificate, then either:\n\n*\n\n*Select Developer ID Installer for distribution outside of the Mac App Store;\n\n*Select Mac Installer Distribution for submission to the Mac App Store.\n\n\n\n*Select Continue and complete the remaining steps.\n\n", "Q: How to edit the end of the current page's URL in Safari on iOS? In Safari on iOS, imagine I am on the page at this url:\nhttps://www.example.com/long-long-url/very-long/very-long-path/page-1\n\nHow can I quickly navigate to\nhttps://www.example.com/long-long-url/very-long/very-long-path/page-2\n\nThe end of the url is different.\nClicking on the URL selects the whole URL, but does not scroll to the end. I can long-hold space to bring up a cursor, move it to the right of the screen, and slowly o-so-painfully slowly scroll horizontally to the end of the line. Or I can double-click the first word in the URL to select it, and drag the right-handle rightwards to get to the end before clicking again to start typing at the end, which is slightly faster.\nBut what's the fastest way to navigate to a page at a URL different to the current one only at the very end?\n\nA: Okay I think I found the fastest way to achieve this for now :\n\n*\n\n*Select the entire URL.\n\n*Cut the URL.\n\n*Paste it and the cursor should be at the end of the URL.\n\n*Edit as you wish.\n\nHere's a little example :\n\nHope it'll work for you !\n\nA: To quickly edit the URL, tap on the address bar as you normally would. The whole URL will be selected.\nNext, using the on-screen keyboard press and hold the spacebar.  After 1 second, you can then use the keyboard as a trackpad. Move the cursor to the end of the URL; the text will be automatically unselected.\nUse the whole onscreen keyboard as your trackpad, not just the spacebar. You can dramatically speed up the movement of the cursor by moving diagonally across the (blanked out keys) on-screen keyboard. It seems to work like a mouse pointer with acceleration.\nMake your edit and press return.\nThis and other useful tips for interacting with the on-screen keyboard can be found on Apple Support\n\nA: After tapping on the address bar, I double tap on a word (e.g. the word “example” in example.com). This selects the word “example” instead of the entire URL. Then I tap and hold to the right of the selected word. When a little magnifier appears after a second or so, sliding the finger to the right will quickly scroll all the way to the end of the URL.\nThen make the edit to get to the next page.\n", "Q: Can't use iTerm2 key bindings with Brave in foreground I'm having an issue using my keybinds for iTerm2 windows. I use Ctrl-Shift-space (C-S-space) as a primary bind. Earlier today, I used this keybind successfully, but at present, it doesn't work.\n\n*\n\n*Show/Hide toggling works when iTerm is in focus, and has at least 1 window currently open in addition to the window being toggled.\n\n*Show/Hide toggling when Brave or other desktop applications are in focus does not show an iTerm window. However the Show/Hide (0/1-parity) state of the iTerm window is evident if I application-switch back to the iTerm application. Window(s) that I have toggled while iTerm was not the application in focus, are visible and in foregrounded LRU order, as would be expected in normal operation.\n\nIn other words, the state of showing/not-showing parity is correctly tracked, but iTerm windows do not pop up over other applications.\nEnvironment\nSame login session as working earlier. iTerm not recently updated.\nAttempted\nI have restarted iTerm2--no change in behavior.\nNote:\nOn this or another StackExchange site, I've solved a different issue involving together iTerm and Brave. That issue related to AppleScript, Accessibility permissions, signed & entitled & recently opened applications. Issue observed was that Brave stopped responding to scripting commands, and osascript commands returned with an \"application closed\" or similar error message. I was able to check with a fresh, bare (no tmux) terminal in a newly reopened iTerm application. I was able to resolve by starting a new tmux server process, with a newly launched instance of iTerm as its parent.\nI remember an OS update, or application update, an expiring of a macOS entitlement -- a permission in the application's plist. Restarting applications was a necessary part of the solution, and the server process was, I believe, too old for macOS to track.\nOn reconsideration, I don't count it likely this issue or its resolution are related.\n\nA: This issue was resolved. I don't know how. Perhaps restarting both Brave and iTerm.\n", "Q: QuickLook won't show scaled-down SVG preview I have some SVG files, sketch drawings of a room. I've used real units in them as I want them to server as a reference. The SVG dimensions are something like 300 in by 200 in. QuickLook shows me a preview with tiny scroll bars, with the image at full scale. Is there a way to have Quicklook show a scaled-to-screen size version, by default?\nIn browser, I've been able to apply an overriding CSS style, width & height 100%. Can I apply CSS to Quicklook previews?\n\nA: It turns out qlmanage supports pre- or batch rendering thumbnails. You can specify output pixel dimension with -s [num].\nVerbosely named:\nqlmanage -t -o thumbnails -s 1000 drawing.svg\n\nPut thumbnail in current directory, as [src].png, here drawing.svg.png:\nqlmanage -t -o . -s 1000 drawing.svg\n\nTo view, use qlmanage -p [file].\n", "Q: How does \"caffeinate\" affect the remaining power adapter display turn-off delay? I'm running Big Sur 11.7.3.\nI know that the caffeinate utility can prevent the system from going into power-saver mode. But what I want to know is whether after caffeinate runs, will the power-saver display turn-off delay now be reset to its original value, or will the remaining time until display turn-off continue to decrement even when caffeinate is running?\nFor example ...\nSuppose that my power-saver \"Turn-off after\" delay is set to 120 minutes.\nAt 7:00 AM, I run the following command in order to prevent system idle for 80 minutes, and I do not interact with my machine at all ...\ncaffeinate -udist 4800 \n\nAt 8:20 AM, that caffeinate command will terminate. Now, assume that I continue not to interact with my machine. At 8:20, will my power-saver turn-off time be 120 minutes in the future from that point (at 10:20 AM), or will it now be 40 minutes in the future from that point (at 9:00 AM), because it originally started counting down from 120 minutes at 7:00 AM?\nThank you very much.\n\nA: Unspecified Behaviour\nThis behaviour is not formally specified by Apple and may change between versions of macOS.\nYou will need to run an experiment to determine the impact of a power assertion (such as those created by caffeinate) on the timing.\nLikely Approach\nI expect the power assertion will not affect the timing but this is an assumption.\nI assume this behaviour because maintaining constantly adapting timers is expensive. A less computationally demanding approach is to:\n\n*\n\n*Determine the next possible idle time;\n\n*Wait the full duration;\n\n*Then check if the conditions are met at that moment:\n\n*\n\n*If met, reduce power;\n\n*If not met, recalculate based on the current idle time.\n\n\n\nThis approach does not need to track the creation and removal of power assertions.\n\nA: Well, I was able to run some tests, and it turns out to be the opposite of the assumption. In other words, after the caffeinate -udist ... power assertion, the power timeout resets.\nI set my \"Turn display off\" timer to 60 seconds, and then I ran the following script without interacting with my Mac at all:\nwhile true\n  caffeinate -udist 2\n  sleep 43\ndone\n\nIn other words, when this script is running, the 2-second power assertion gets issued every 45 seconds. In this case, my Mac never goes to sleep.\nThis means that the display must indeed be getting reset to turn off one minute after each power assertion.\n", "Q: Mac can't receive call transfer from iphone When I transfer a call from my MacBook Pro 2021 (Ventura 13.1) to my iPhone everything works perfectly. However, when I do the other way around, from my iPhone to my MacBook facetime opens (on the computer) and immediately shuts down the call.\nI have tried the basic procedures, like switching on and off related options but this problem persists. I started experiencing this about a month ago and so far I could not find a solution to this problem.\nAnyone around here has successfully dealt with this issue?\n\nA: On iPhone, in Settings -> Cellular -> \"Voice & Data\" -> enable VoLTE.\nI think enabling, VoWi-Fi (if that's an option), should also do it.\n", "Q: Can I allow a remote user to log into my MacBook Pro laptop as an Admin? Hoping there is a simple way for a user to log into my Mac as an Admin remotely. I need them to be able to gain access to all the user's files whenever I am online.\nSo far, it seems they have to log in physically on my computer as an Admin.\n\nA: Where a user logs in from doesn’t change their permissions.  If the user has Admin rights locally, they will have Admin rights when logging in remotely.\n\nI need them to be able to gain access to all the user's files whenever I am online.\n\nThis is an ownership issue, not an Admin issue.\nIf you examine the permissions and ownership of any file - use Get Info CommandI in the GUI or ls -la in Terminal - you will see the permissions indicated as who can/cannot read, write or execute the file.\nFor example, in Terminal, I created a couple test files with different permissions for illustration:\n% ls -la\ntotal 8\ndrwxr-xr-x  2 allan  staff    64B Jan 30 21:45 testDir\n-rw-r--r--  1 allan  staff   860B Jan 22 16:30 testfile1.txt\n-rw-rw----  1 allan  staff     0B Jan 30 21:39 testfile2.txt\n\nAll file entries begin with a -rw….. The first position is whether or not it’s a directory; the first line shows this.  The next three positions are for the owner, in this case, the owner can read write and execute within the directory.  The next three are for members of the group; they can only read and execute in the directory.  The final three positions are for “everyone else;” they also have read and execute permissions.\nThe owner and group is denoted by the next two entries: allan staff.  Their permissions are set by the preceding bits.  Anywhere you see a dash - that means the permission is not set.\nGet access to the file with permissions\nSo that the user with Admin rights has access to “all the users files” you need to either take ownership or join the appropriate group (like staff) and modify the permissions of the file.  I recommend the latter because you don’t want to arbitrarily take ownership of a file created by someone else as it could lead to all sorts of confusion later on.\nTo change the permission of the file, use the chmod command.  For example, to change the permissions of testfile1.txt so that both the owner and staff have read/write permissions, issue the command:\n% chmod 664 testfile1.txt\n% ls -la testfile1.txt\ntotal 1\n-rw-rw-r--  1 allan  staff   860B Jan 22 16:30 testfile1.txt\n\nWhere did the 664 come from?  That another discussion, but for now, just use the online Chmod Calculator.\n", "Q: Is it possible to have multiple values in a cell I have a Column called \"Genre\" where it should be different TV show genres, but as you all might know these could be multiple. Like Drama, Comedy and so forth.\nWhen filtering for Comedy I need to select \"Comedy\" as well as \"Comedy, Drama\" and so on. Is it somehow possible to add multiple genres within a cell?\nThanks\n\nA: So you can use countif() like so:\n\nCOUNTIF(B$3:B$5,\"*\"&D2&\"*\")\n\nMade a very simple set of data as you did not provide much. The genres can be separated by commas as shown or spaces or semi-colons etc\nShown in Numbers as well:\n\n", "Q: Download BigSur for bootable flash drive Yesterday, I updated an old MacbookAir6,2 to macOS 11.7.3. Unfortunately, it did not start after this update and recovery (command + R) does not work, since I can't connect to any network. So I wanted to download BigSur and create a bootable device. AppStore does not work, since my Macbook runs macOS 13 and it won't let me download 11.7.3.\nsoftwareupdate --fetch-full-installer --full-installer-version 11.7.3 does also not work since softwareupdate --list-full-installers only shows available versions from 12.6.1 to 13.2. How can I download 11.7.3 (or any other compatible version for a MacbookAir6,2) to create a bootable flash drive?\n\nA: There is the canonical QA How can I download an older version of OS X/macOS?. In addition, I have included two methods which are suited to your situation.\n\nMethod 1\nDownload an available version from 12.6.1 to 13.2 to the host Mac. Install the chosen version in a virtual machine guest on the host. Oracle and VMware offer free software. Boot from the virtual machine guest and use the command below to list available downloads.\nsoftwareupdate --list-full-installers\n\n\nNote: Guests can list more versions of macOS installers than the host can. Hosts will only shown macOS versions compatible with the host. Guests do not have this restriction.\n\nFrom the guest, use the softwareupdate command to download an available installer application which is compatible with your MacbookAir6,2. Transfer the application to the host Mac. Follow the instructions given at Apple's website  Create a bootable installer for macOS to create the bootable USB flash drive installer.\n\nMethod 2\nUse of of the answer from the question How do I create El Capitan installer on a Catalina (or post-El Capitan) installed Mac for use on USB boot installer? to create a Sierra, El Capitan or Yosemite USB installer.\nBy using this method to get back to Big Sur, you would have to update your Mac. Recently, I have noticed that the Big Sur downloads from the App Store do not necessarily include all the software needed to install Big Sur. These types of downloads can not be used to create a USB flash drive Big Sur installer. So while this method may get you back to Big Sur, you may not be able to create a USB Big Sur installer by using this method until your MacbookAir6,2 is actually booted to Big Sur.\n", "Q: Global shortcut to open folder I very much like the Finder shortcut CmdShiftG to navigate my files. However, it is a hassle having to open the Finder every time I use it. I would therefore greatly benefit from being able to use this function from any app that is currently open, launching the nice dialog in which I can enter my folder path. Is there any way to accomplish this? The shortcut does not have to be CmdShiftG.\n\nA: \nI very much like the Finder shortcut CmdShiftG to navigate my files. However, it is a hassle having to open the Finder every time I use it.\n\nIt's important to understand that Finder is the desktop environment for your Mac.  It's unlike Windows File Explorer which is a completely separate application (utility) from the desktop environment.  You don't have to \"open\" Finder every time you want to use it - you just have to select your Desktop.\n\nGet to know the Finder on your Mac\nThe Finder is the first thing that you see when your Mac finishes starting up. It opens automatically and stays open as you use other apps. It includes the Finder menu bar at the top of the screen and the desktop below that. It uses windows and icons to show you the contents of your Mac, iCloud Drive, and other storage devices. It's called the Finder because it helps you to find and organize your files.\n\nWhat's also important to note is that applications are not required to adhere to system shortcuts.  Per the macOS Human Interface Guidelines it says that standard keyboard should be respected.\n\nRespect standard keyboard shortcuts. People expect the standard keyboard shortcuts to work, regardless of the app they’re using.\n\nHowever, this is not a hard-and-fast rule.  An application may or may not respond to said shortcut - it's entirely up to the developer.  For example, using Microsoft Word, the ⇧ Shift⌘ CommandG shortcut works, but in VirtualBox, it doesn't.\n\n\nI would therefore greatly benefit from being able to use this function from any app that is currently open\n\nI'm certain you would.  However, that's not the way the developer approaches it.  While it could be argued that would be nice to have that feature in VirtualBox for instance, the developers saw no need to implement it even within their \"import machine\" dialog box.  The bottom line is you can't force the app to do something it wasn't enabled to do.\n", "Q: How to point to a file in a different folder on iOS/iPadOS? On my iPad, I use iCloud Drive and the Files app. My files are organized in folders in iCloud Drive so that I can access them on all of my devices.\nI frequently want to point to a file that is stored in a different folder.\nFor example, I have four folders in iCloud Drive that I access via the Files app on iPad. I would like to have a reference/pointer to the same file (e.g., a PDF) in all of those four folders.\nHaving copies of the file in different folders causes redundancy and it needs space. When I update the file, I have to update it in all folders.\nOn macOS, I can create a symbolic link or an alias for such purposes. I believe that this is not possible on iOS and iPadOS.\nI‘m aware of tags and favorites. However, they are global and I don‘t want to clutter these with files I need only in certain projects. They also cannot be organized hierarchically like folders and subfolders.\nSo, what is the best way to point to a file in a different folder without having a copy of that file?\nAlthough symlinks and aliases are not supported by iPadOS, I am looking for creative ideas to deal with this shortcoming.\n\nA: \n... what is the best way to point to a file in a different folder without copying the file on iPadOS and iOS?\n\nTo paraphrase Steve Jobs, \"You're doing it wrong!\"  That's not meant as a dig, but more of a facetious way to approach this question.\nEverything should be done via iCloud (or another cloud service)\nYou shouldn't be trying to create symlinks and/or manage what file is where when iCloud Drive was designed to do exactly this.  If you enable iCloud Desktop and Documents always select the file using iCloud (found in the sidebar).  This way, any changes you make will be automatically synced with the cloud and you won't have to worry about symlinks and copies upon copies of the same file.\nWhile iCloud is great, I have opted for Microsoft OneDrive.  It provides a better mechanism for creating my folder hierarchy and configuring which folders I would like to sync and which ones I don't.\n\nIn your sidebar, you have all the locations from which to access files.  Instead of linking things from point A to B to C and copies made in two or three different places, always access the file via your cloud service.   Below are screen grabs from both my Mac sidebar and from my iPad Files App of where you should be storing your files for centralized access:\n \nIn my setup, I have my Documents folder completely sync'd with OneDrive.  Therefore, whether I choose to navigate through OneDrive (locations) or directly through Documents, the file is always the same one.  One feature of OneDrive that I particularly like is the ability to send a link to the file rather than the file itself.  If I send a Word or Excel file to be reviewed, for example, the recipient will get a link and open the file on my OneDrive account.  Any changes made will be saved there and they won't have to email me back a different version of the file.\nIt may take a little exploring around and experimenting with what you want and don't want synchronized, once you take the perspecitive of the cloud being the center from which you operate, you'll find that it works substantially better than all the symlinking you were looking to do.\n\nA: *\n\n*For a small number of projects (or something similar), tags are feasible, where the tag name may be equal to the project name (thanks „nohillside“)\n\n\n*For many folders, one could have one folder where all the original files for all projects are stored. Then, in a project folder, one would have a text document with the name of the file, which serves as a pointer. With this approach, one would not even have to store the full path but only the name of the file (since all original full-size files are in one and the same folder). This would work but it is cumbersome since one cannot just click on the text document to open the original file.\nI‘m looking for other creative ideas that are less limited or cumbersome.\n", "Q: iPad Security During Repair - how did it magically become unlocked? WiFi iPad has a secure PIN set, Fingerprint, and Auto-lock. Doesn't have face recognition enabled. The charging port broke, and the iPad was used until it was out of battery and wouldn't turn on.\nThe unit was taken to a local non-Apple repair person, who fixed/replaced the charging port.\nWhen the iPad was returned, it was powered up on the way home, and:\n\n*\n\n*It had a whole lot of notifications on it, as if it had been connected to the Internet (it had no Internet on the way home, the notifications had already downloaded).\n\n*It didn't ask for a PIN, multiple times (on initial power up, as well as press the lock button, then wake it up, and it woke up without a PIN.\n\nUpon returning home, the iPad connected to the home WiFi, and when it was next woken, it asked for a PIN.\n\n*\n\n*How did the repair person connect the iPad to Internet without the PIN? Using an Ethernet charger seems like a strange thing to do for a repair person?\n\n*Why was the PIN lock suddenly missing when it woke up, multiple times, before getting home?\n\n*How did the PIN lock suddenly resume once it had Internet access at home?\n\nThe iPad had secure information on it, did the repairer have unfettered access to the apps and data on this iPad while it was being repaired? And how?\n\nA: \nHow did the repair person connect the iPad to Internet without the PIN? Using an ethernet charger seems like a strange thing to do for a repair person?\n\nFirst, it is possible that the tech plugged in a USB Ethernet adapter; using either USB-C or USB-A via the Lightning to USB3 adapter. This would give your iPad network/Internet access.  Apps would update/refresh in the background and notifications would show on the lock screen as they normally would.  The iPad doesn’t need to be unlocked for background updates or for notifications to appear.\nWhy would a tech do this?  It would allow the tech to test USB functionality without needing to sync it to a computer. This is a quick and easy way to make sure all of the USB functions work and that the repair was successful.\n\nWhy was the PIN lock suddenly missing when it woke up, multiple times, before getting home?\n\nThe PIN cannot be disabled/enabled based on network connection or lack thereof.  It’s much more likely the tech at the repair shop had you test out the device prior to taking delivery. In that case you would have had to unlock it by either PIN or biometric (fingerprint).  Depending on your security settings, the device may not have locked for some time, even on your way home. What you were likely seeing was the iPad in an unlocked state.  If you interacted with the device on the way home while it was unlocked, you reset the lock timer.\n\nHow did the PIN lock suddenly resume once it had Internet access at home?\n\nThe lock timer probably coincidentally expired as you got home.  Again, security isn’t enabled/disabled based on the network an iPad connects to.\n", "Q: How do I point the mkdir to the Desktop using bin/zsh? I am on macOS $HOME How do I make this create the directory on my Mac desktop rather than the home folder alone.\nmkdir -p \"$HOME/${digits}_${date}\"\n\nRight now it goes to /Users/name/\nI need it to go one more folder to the Desktop.\n\nA: In your home directory, which is identified by the HOME shell variable (automatically set), you will find several sub-directories like Documents, Downloads, Desktop, etc.\nTo create a directory on your Desktop, you can change directory (cd) into the Desktop folder and use the make directory (mkdir) command (we are assuming the two variables digits and date have valid values already):\n% cd $HOME/Desktop\n% mkdir ${digits}_${date}\n\nYou could use tilde (~) expansion to avoid expanding the HOME variable:\n% cd ~/Desktop\n\nAnd you could create the directory using a one-liner:\n% mkdir $HOME/Desktop/${digits}_${date}\n\n--or--\n\n% mkdir ~/Desktop/${digits}_${date}\n\n\nA note on variables and variable/parameter expansion.  Shell variables are referenced by name (i.e. HOME) and not that there is a dollar sign ($) preceding it.  The $ expands (or substitutes) the value the variable contains.\nExample:\n% myVAR=\"Hello World!\"\n\n% echo $myVAR    ← This is equivalent to 'echo Hello World!'\nHello World!\n\n", "Q: Prevent iPhone being reset to factory settings and changing the Apple ID associated to bypass ScreenTime It's my personal parent control issue.\nI have an iPhone and MacBook which has screen time. My kid can bypass it\n\n*\n\n*By spamming unlock it seems that there is a way to prolong extra time endlessly!\n\n*By doing factory reset kid simply can resign to new appleid to device without problem!\n\nThe answer is, the Mobile Device Management for iPhone and proprietary company lock for apple laptops provided for companies.\nHow can I have this for family causes?\n\nA: It would help to list out the specific device and iOS version you're using. Generally though -\nIn ScreenTime you can disable account changes. You can only change accounts in iOS after a reset if you removed the account before resetting.\nOtherwise, there are MDM controls you could implement through something like JAMF (or another MDM), eg. Disable “Erase All Content and Settings”\nAnyone can buy and install an MDM, you don't need to be an enterprise. There are plenty of free options out there too.\nJamf make a guide specifically for families. They used to offer a free 3-device family plan, I don't see it any more.\n", "Q: Is it possible to distribute an app without going through the App Store? I have heard that it's possible to distribute an app on the iPhone without going through the Apple App Store. I'm dubious, but thought I'd check.\nIs this possible?\n\nA: Yes, this is possible. It is not as easy as the App Store, and it does come with some drawbacks. Contrary to the comments here, it does not mean that you have to have a jailbroken phone though.\nTake a look at for example the popular project \"AltStore\":\nhttps://altstore.io\n\nA: Developers can run their own code on their iPhones. The functionality behind this is essentially also used by the AltStore. (Here is an interesting explanation: http://rileytestut.com/blog/2019/09/25/introducing-altstore/)\nThere is TestFlight, which is offered by Apple. The idea is that developers can test their beta versions with a limited number of users. Although apps have to be submitted to Apple and they have to meet certain criteria, the review process is not as strict as for the App Store.\nCompanies and other institutions can use Apple Business Manager. However, the apps also have to go through review by Apple:\n\nDevelop custom apps for private distribution. Meet the unique needs of\nbusinesses by privately offering apps you’ve customized just for them.\nSpecific businesses who you identify in App Store Connect will see\nyour app and be able to purchase it in the Content section of Apple\nBusiness Manager. Custom app distribution works well if you’re\ndistributing apps to specific partners, clients, or franchisees. You\ncan also use custom app distribution for your internal employees.\nBusinesses can distribute and manage purchased apps through Mobile\nDevice Management. Alternatively, businesses can choose to provide\nredemption codes to authorized users. If you’ve been contracted to\ndeliver a custom version of your app to a business, distributing a\ncustom app allows you to maintain the code and retain your\nintellectual property rights. (Source: https://developer.apple.com/business/distribute/)\n\n", "Q: Switching from MacBook Pro Intel to MacBook Pro M2-Max I have a MacBook Pro Apple silicon M2-Max on order to replace my MacBook Pro Intel.\nI have a few questions:\n\n*\n\n*When I try to restore my system from the Time Machine backup, will my applications continue to work OK, or will I have to re-install everything?\n\n\n*Is it possible, when setting up the new machine, to tell it not to restore apps from the Time Machine, and limit the restore only to data?\n\nA: In general, applications will continue to work okay. You do not have to re-install everything.\nThere are some applications that do \"just work\" after being transferred from one computer to another. This is typically programs that requires a license code (serial number) or a cloud login that needs to be redone. This problem would also occur if you were switching from an Intel MacBook Pro to another Intel MacBook Pro.\nNote that even though the application continue to work just fine - it is sometimes possible that you could get even better performance by upgrading those apps to versions that include builds for Apple Silicon.\n", "Q: Mac loses the ability to set desktop image after a few days of automatic setting I have a script that pulls images from Reddit and sets them as my wallpaper. This works fine for the first few days, though after that it just stops changing the wallpaper. The images continue to download to the local folder but for some reason I just can't set my wallpaper anymore.  Even doing right click 'set desktop picture' on an image or manually using my automator app.\nThe only way to fix this is to reset it by going to wallpaper in settings and manually setting it. I've even tried using different methods of setting the wallpaper but the result is the same.\nDoes anyone know what might be causing this or how to debug?\n\n\nA: Eventually figured out that \"there is a problem where OS X would cache the wallpaper in RAM and not check to see if the picture file had changed given that it was using the same filename each time.\" So solved by just using the hash of the image as a filename.\n", "Q: iOS apps that lets you SSH into a server using Yubikey 5 NFC with Public Key authentication and gpg-agent I have a Yubikey 5 NFC, and iPhone 11. I am also running an Ubuntu Server. To log into my server on from mac using ssh. I use ssh with gpg-agent and public key authentication, and have the private (gpg) key credentials stored on my Yubikey 5 NFC in the gpg format. So I log into my server from Mac OS by sshing into my server with my yubikey (using gpg-agent). My yubikey authenticates into the server perfectly.\nTo make this work with Yubikey 5 (on MacOS), I have the following lines in my .zshrc file:\n# Make gpg check for yubikey on startup and insertion\ngpg-connect-agent \"scd serialno\" \"learn --force\" /bye\n\n# Launch gpg-agent for use by ssh\nexport GPG_TTY=\"$(tty)\"\nexport SSH_AUTH_SOCK=$(gpgconf --list-dirs agent-ssh-socket)\ngpgconf --launch gpg-agent\n\nI tried browsing the apple app store for iOS terminal emulators compatible with Yubikeys for ssh commands. I was hoping to find a Yubikey SSH compatible app but couldn't find anything. After browsing the app store for quite some time, I can't seem to find any terminal emulator app descriptions that show ssh compatibility with Yubikeys.\nMy question is, is there a terminal or ssh app for iOS that would allow me to ssh into my server in a similar fashion using the NFC protocol on my Yubikey 5 NFC? Any links or apps would be much appreciated.\n\nA: Termius supports Yubikeys on iOS. However, they're FIDO2 not GPG.\nThat said, you can use multiple methods to SSH to servers, and if you want it backed by a physical key the single Yubikey can work for both.\nIf you're looking for key-based auth from iOS Termius also support keys generated in the Secure Enclave and requiring biometrics. You could put both your Yubi GPG key on your server for desktop SSH access and the Termius key for iOS access.\nFWIW, I've found PKCS11 easier on Mac to SSH with than GPG. You can use the OpenSC libraries and have it load in your cert to your ssh agent on first try with a PIN, so keeping 2FA and it's physically backed by the Yubi.\n", "Q: Does DMG compress free space? I’m backing up an old Mac SSD and I wondered whether if creating a compressed DMG from that HFS+ disk with Disk Utility will actually consider the free space as zero and therefore compress it immensely or if it will simply compress a bit-by-bit image consisting also of the bits of long deleted files.\nDoes anyone know?\nThanks in advance.\n\nA: From Apple Support\nCreate a disk image from a disk or connected device\nYou can create a disk image that includes the data and free space on a physical disk or connected device, such as a USB device. For example, if a USB device or volume is 80 GB with 10 GB of data, the disk image will be 80 GB in size and include data and free space. You can then restore that disk image to another volume.\nIn Terminal, using the hdiutil command, you can convert existing disk images into a number of compressed file formats. If you are just storing the compressed files for archival purposes, this may work for you.\nconvert image -format format -o outfile\nThis page replicates the info from man hdiutil.\n", "Q: Is there a way to make certain applications hide as soon as they no longer become the active window? I have a few application which I would really like it if they were to hide automatically instead of moving behind the new active window. It would be great if I could make some sort of daemon which automatically hides these application windows when they stop being the active window.\nGoogling this isn't bringing up anything useful and I imagine it's because I don't know how to phrase it. I have no idea how I'm best to achieve this, but if there's a way, I'd like to have a go.\nI'm running MacOS Big Sur.\nDoes anyone know where I can start with this? If you could point me in the right direction that would be great.\n\nA: Probably not the full solution you are looking for, but maybe I can help get the ball rolling on this. There is a hidden mode in mac os, \"single app mode\" whereas switching between apps auto hides the previous. You can enable this by typing in this command in the terminal.\ndefaults write com.apple.dock single-app -bool true then do \nkillall Dock to restart the dock and commit the changes.\nif you wish to undo this command replace true with false. Another suggestion, if you hold the option key down while clicking (switching) on from app to app via the dock the previous app will automatically be hidden. This is also true if you have a window in the front and you option click the desktop in the background, will instantly hide the frontmost app window.\n", "Q: Why does \"ls\" show folders that the Finder doesn't? I'm using Terminal under ~/Apps.  When I do \"ls\", I can see a folder called \"tempr\"; there're files inside of it.  But when I open Apps in the Finder, I can't see the \"tempr\" folder? Apps look about 95% the same as from Terminal, but there're still some folder differences I can’t figure out.\nIf I open VSCode for example, File->Open shows the folder in the popup window.\nWhat's going on? I feel like I'm going crazy.\n\nA: Mac OS can hide files in a variety of ways and means.\nSimply appending . to the start of the filename will by default hide the file. Also macOS Finder will hide files that have a hidden flag attribute.\nWhen you run ls you are do not see files beginning with . but do see files with the hidden flag. You can try ls -a to view all files/folder including those beginning with .. To see if there are files with a hidden flag run ls -lO.\nFurthermore, you can do shiftcommand. on the keyboard to toggle visibility of files in the finder.\n", "Q: Is it at all possible for Big Sur to be booted from an HFS+ formatted volume? For various reasons, I wanted to install Big Sur 11.7.3 on HFS+, but I could not do it.  The install would always try to force-reformat my drive, so I eventually gave up and went with the APFS. Now I find out that an HFS+ volume can be installed as a separate volume on an APFS formatted drive. But could that HFS+ volume run Big Sur? Or are both these options a no-go? I haven't been able to find a specific answer to this. The target Mac is a 15\" MacBook Pro Mid 2015 with a half-terrabyte SSD and 16GB ram.  I know Carbon Copy Cloner won't do it, but is it even possible? At this point, my guess is \"no\", but I would sleep better, knowing.  Thanks!\n\nA: No. BigSur filesystem is setup to require/rely on features of APFS. Interestingly enough though, bootable Bigsur system installers work formatted as HFS Extended Journaled.\n", "Q: Numeric keyboard with Touch ID on Mac Studio I have a numeric keyboard with Touch ID for my Mac Studio.\nInstalled it and registered my fingerprint.\nI was under the impression that Touch ID would also work at a \"cold\" startup/boot as well as on a re-start, but it doesn't. Buttons Touch ID to unlock & autofilling passwords both on in settings. I don't get the choice on the start-up screen between a password or fingerprint.\nI've been searching on the net but cannot find any clues... other than use Touch ID to get mac out of sleep, which in my case works flawlessly.\nSo am I correct in understanding that the touch id option is only available for - unlock your Mac from sleep - purchases - auto filling - user switching?\n\nA: It's similar to how the iPhone deals with Touch ID [idk about Face ID, don't have anything using it] - periodically [seems to be about every two days] it will require your PIN on wake rather than Touch ID. This is I suppose a kind of 2FA.\nOn the Mac they seems to have decided to do this check at boot instead, perhaps on the assumption that people do actually periodically shut down or reboot their Mac far more frequently than their phone.\nThe end result is you need your password at boot. I've not known it ask at any other time.\n", "Q: Is there no way to show additional disk space/capacity columns in Finder? One of the things MacOS simply doesn't seem to do is easily show size and free space on disk drives. It shows size in Finder if you go to your computer:\n\nBut it does not show the disk size or free space, only the amount it's using - no way to easily see (unlike Windows) how full a disk is.\nI have enabled Status Bar but in my image above you can see it doesn't show me anything useful. Isn't it supposed to?\nI know I can select an item and preview by pressing Space which is... OK. And I can show Info in another window but that's quite clunky. What I really want is to see \"at a glance\" the size and 'fullness' of all my drives at once.\nIs this simply not possible?\n\nA: The problem is List View, where you are \"in\" the top hierarchy shown, regardless of what is selected and how far you drill down.\nIf you double-click on \"Macintosh HD\", then you will be 'in' the internal system volume, and you will see the free space shown in the status bar.\n\nThe same behaviour occurs in Icon View, where it makes more sense, as you only see one level at a time.\nIf you choose Column View then the problem does not appear. Simply selecting the volume there will show you the free space.\n\nIf you want to see info for all your drives at once, then in Ventura, go to System Settings > General > Storage > All Volumes.\n(In earlier versions, it was under \"About This Mac\".)\n", "Q: May I make a removable drive \"non ejectable?\" I have a large SSD drive connected to my iMac as my main working drive, and macOS is still on the internal drive. Can remove the ability to accidentally eject it from Finder somehow?\n\nI would just like to make ejecting the drive something a bit harder, so there's no change an errant mouse-click could do so!\n\nA: Open a Terminal application window and enter the following command.\ncd /Volumes/Data\n\nThis changes the current working directory to /Volumes/Data, which is the root folder of the external drive. If you try to eject the drive, you should get a message stating the drive is in use by the Terminal application.\nI suppose one could instead enter the commands below which would run processes in the background. Afterwards, you could quit the Terminal application while still protecting the drive from being ejected.\ncd /Volumes/Data\nbash -c 'while true; do sleep 3600; done &'\n\nUser Solomon Ucko posted the following question as a comment.\n\nTo make this permanent, would there be some way to set this as a startup script?\n\nThis subject is well covered elsewhere on Stack Exchange. Some examples are given below.\n\n*\n\n*Run command on startup / login (Mac OS X)\n\n\n*Running script upon login in mac OS X\n", "Q: Airpod Pro V2 case chirps / beeps when I pick it up My Airpods Pro V2 case sometimes \"chirps\" (beeps) for ~15 seconds when I pick it up in the morning. It happens about once a week, and it wakes up my wife. It is like someone is using the \"Find My\" app to make the Airpods case emit noise, but there's no notification on my iPhone, or on any device in my \"Family\" group (Settings > Apple ID > Family).\nUpdated to add: This sound is not the \"ding\" it makes when I plug in the charging cable (or put it on the wireless charging pad). The \"charging case sound\" is just a single chime, maybe 2 seconds long. In contrast, this weird sound is more like the dinging of an alarm clock -- maybe 10-15 seconds long.  And, weirdest of all, it even makes this 10-second sound when I lift it, fully charged, off the charging pad. So I don't think it's a \"low battery\" sound.\nHow can I debug this? Thanks!\n\nA: Does it sound like any of these? AirPods Pro 2 have 'Find My' built-in and perhaps this is the 'moving with you' chime that I hear every time I get in my car (inside which I have stashed an AirTag.)\nhttps://www.youtube.com/watch?v=c0TVHPHRjXg\n", "Q: Is there a way to make login items only work on specific days? Is there some kind of script or automation I can run that gives me the possibility for certain apps to open at login but only on certain days? For instance I want to be able to open Mail, Slack, Notion and Zoom automatically on weekdays but not on weekends. It's not a major issue but it would be nice. Thanks!\n\nA: There are a couple of ways to approach this, but they require removing the items from Login items and kicking them off a different way.  Here are your options:\n\n*\n\n*Use AppleScript.  You would replace your Login items with a single AppleScript that checks the day of the week and launches the applications  appropriately. It’s not too tricky to accomplish this.  Here are some excellent links that can get you started:\n\n*\n\n*How do I get an AppleScript application to automatically run at login?\n\n*How to control order of startup items for users at login?\n\n*How do I use AppleScript or Automator to turn Time Announce on or off at specified times?\n\n\n\n*Use a LaunchAgent managed by launchd (my preferred method).  You wouldn’t use Login Items for any of these apps. Though a bit more complex than an AppleScript (IMO), it gives you more granular control as every App becomes, in essence a service that you can individually control.\nThis is an excellent post, launchd plist format for running a command at a specific time on a weekday, that details how to create the .plist and in which directory you would place it in to achieve your desired results (~/Library/LaunchAgents would closely mimic the Login Items function).   Also see Is it possible to allow usage for an app or program for a specific times on a Mac?, it’s about allowing apps to only run on certain days (so, ignore the Gatekeeper portion), but provides an excellent example how to structure the .plist for day specific actions.\n\nA: Paste this following AppleScript code into a new Script Editor.app document and run the code to test that works then save it as an .app.\nThen just go to System Preferences and add your new .app to the Login Items.\nproperty theWeekdays : {\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"}\nproperty theApps : {\"Mail\", \"Slack\", \"Notion\", \"Zoom\"}\n\nset currentWeekday to weekday of (get current date) as text\n\nif currentWeekday is in theWeekdays then\n    repeat with thisApp in theApps\n        try\n            tell application thisApp to activate\n        end try\n        delay 10\n    end repeat\nend if\n\n", "Q: (AppleScript) How to adjust Apple Music's application volume? I'd like to write a Shortcut (\"Fade out Apple Music\") that slowly reduces the Apple Music volume over the course of ~5 seconds.\nI don't see a Shortcut option for getting/setting Apple Music's volume, so I figure that AppleScript would be the right choice - but I am not familiar enough with AppleScript to know what variables/syntax to use for it.\nHow can I get/set the volume of Apple Music? (As a bonus: how can I write a little loop to adjust the volume over the course of 5 seconds?)\nEssentially, that'd be the equivalent of slowly adjusting this slider down to zero:\n\n\nA: Alright, I figured out a simple script that does what I want! You can adjust the parameters in the first two lines to \"tune\" it to what you want - but I think this is a pretty-nicely-tuned setup. It slowly steps-down the volume to create a fadeout, which is nice when you're DJing the Zoom call and want a subtle fadeout effect.\nset fadeDuration to 3 -- in seconds\n\n\ntell application \"Music\"\n    set currentVolume to sound volume\n    \n    if currentVolume > 0 then\n        set fadeStepDuration to 0.02 -- in seconds, Apple says this should be > 0.01667\n        set fadeStepCount to fadeDuration / fadeStepDuration\n        set fadeStepSize to currentVolume / fadeStepCount\n        \n        repeat fadeStepCount times\n            set currentVolume to currentVolume - fadeStepSize\n            set sound volume to currentVolume\n            delay fadeStepDuration\n        end repeat\n    end if\n    \nend tell\n\nHere's how it looks in action:\n\n", "Q: Do Mac or iOS IMAP passwords expire from the client side? I tried to log in to my 3rd party hosted (i.e. not Apple) IMAP email account this morning and got an authentication error. I then tried connecting on my phone and same thing occurred.\nSo, I contacted that host company’s support chat and was told to delete and re-create the account. I did it on the phone using the same password and all, and it worked.\nThe Mac Mail client still won't connect. The support person told me that the pw expired on the client side and that's why it won't connect.\nI’ve never heard of that before and I've been using this same Mac, with Mac Mail connecting to multiple email accounts/servers and never had this happen before.\nIs this just BS? And why/how would deleting and re-creating do anything different even if it was a server problem? I should probably let it go and get on with my life, but it's bugging me.\n\nA: Your IMAP password cannot expire on the client side. An IMAP sever was literally the forerunner to cloud based email like Gmail or Outlook.com; everything is handled by and through the server.\nYou authenticate to the IMAP server, not to a local IMAP client.  Only the IMAP server can expire your password.\n\nSo I contacted that host co's support chat and was told to delete and re-create the account.\n\nThis is an old, old tech support trick.  When an error occurs, whether on your end or theirs (this was most likely on their end), they will have you delete your account and recreate it as it’s the easiest and most efficient way to resolve (not actually fix) the problem.  If they make a change that breaks your authentication, deleting the local profile and creating what amounts to a new one “fixes” things.\nWhat was the problem?  We can’t know because it was “deleted” when you deleted your account.\n", "Q: Troubleshooting WiFi downloading MacOS in Recovery Mode I erased my disk and rebooted to download and install macOS over the internet in Recovery Mode.\nI do not believe there is any damage to my hardware since it worked completely fine before this.\nIt may have been something about Internet, but I do not think so since my Internet is fast and I use it regularly.\nThe installer log showed it was basically stuck and not making any progress. Meanwhile the loading bar was estimating longer and longer time, from 3 hours to 4, and beyond.\nWhat are the factors that can influence this, and why?\nSomeone said the download works much better plugged into Ethernet. But, can it really be that finicky to download macOS over WiFi in the modern era? I do not think Internet connection should have been a problem.\nSince I erased the disk completely I feel like there should not be any particular settings there that is interfering with the installation, but maybe there is. I tried to use fsck, but it gave an error saying disk5 was mounted; so I tried to unmount disk5, which gave an error that it couldn’t be done for some reason.\nI do not know the general reason why this would not work. Is it more likely to be my Internet, or something deep in my disk? If so, why? Why wasn’t my disk back to normal after I completely erased it?\n\nA: \nthe loading bar was estimating longer and longer time, from 3 hours to 4, and beyond.\n\n\nWhat are the factors that can influence this, and why?\n\nThere are several factors that could be at work here:\n\n*\n\n*Latency.  This could be your WiFi, the connection to the modem/gateway, your ISP, their network, the content delivery network, the content servers (that serve up the file(s) to download, and Apple’s network and server’s.\n\n*Network congestion.  Your WiFi could be saturated with traffic causing a slowdown.  This is one of the reasons for trying Ethernet\n\n*Hardware.  This again ranges from your WiFi to Apple’s servers. But, being pragmatic here, you might have a defective router\\switch or a bad gateway (supplied by ISP)\n\n\nSomeone said the download works much better plugged into Ethernet. But, can it really be that finicky to download macOS over WiFi in the modern era?\n\nEthernet will always be more reliable to WiFi.  WiFi continues to improve, but so does Ethernet.  A wired connection gives you a clean connection to the network without worrying about rogue signals your neighbors are broadcasting. As far as “WiFi in the modern era goes,” if the gear is faulty it won’t matter what year it is.  Always eliminate suspect factors based on function, not the calendar.\n\nI tried to use fsck,\n\nYour disk is irrelevant here.  macOS is loaded into RAM disks so that you can mount/dismount your main drive to facilitate erasure and formatting. Even if you formatted it, the downloaded OS won’t be aware of this and needs to be able to manipulate the drive.\n\nIs it more likely to be my Internet, or something deep in my disk? If so, why? Why wasn’t my disk back to normal after I completely erased it?\n\nMy guess, based on extensive experience, is this is a network issue. Try the Ethernet cable.  Take the unit to an Apple store and download there or try a different network (like work).  As far as your disk goes, “normal” is relative.  Without putting hands on, it’s impossible to see what’s abnormal.  Either way, you need to get the OS reinstalled to get back to normalcy.\n", "Q: MacBook Air M1 2020 touchpad and keyboard unresponsive after sleep For the last week, I've been experiencing the following issue: After my MacBook Air (M1, 2020, Monterey 12.6.3 (21G419)) goes to sleep, it becomes unresponsive to touch and keyboard; only the power button works (and signing in successfully, hence I could physically screenshot the console error logs below.)\nAny help and pointers would be much appreciated since I am travelling currently and need the machine.\nI have already tried:\n\n*\n\n*Booting in safe mode (issue persists)\n\n*Full reinstall after wiping SSD clean (issue persists)\n\nThe following kernel error messages show up in console:\nSandbox: swed (464) deny (1) system-fsctl _IO('h',\n47)\n[HID] (0x100000787][41c][AppleHIDTransportProtocolHIDSPI::powerHasChanged]:ERROR!/ioRet == 0\nfile: /AppleInternal/Library/BuildRoots/f1d94df-906-11ed-8745-66a073a27ee/Library/Cac[...]\n[HID] (0x1000004ea][41c][AppleHIDTransportDeviceSPI::interruptAction]: ERROR!I boolResult,\nfile: /AppleInternal/Library/BuildRoots/f1d9e4df-906-11ed-8745-66a073a27ee/Library/Caches/cc\n[HID] [®x1000004ea][41c][AppleHIDTransportDeviceSPI::handleFatalError]: ERRORI! Couldn't talk to firmware\n[HID] (8x1000004ea][41c][AppleHIDTransportDeviceSPI::handleFatalError]: ERRORI/ Powering off due to reaching maximum number of consecutive boot failures (10\n\n\nA: This appears to be a hardware issue.\nThe one error message that stands out is:\nERRORI! Couldn't talk to firmware\n\nWhen a process cannot speak to the firmware (on your logic board) especially after a clean reinstall of the OS, this is not something that a tweak of a setting in the OS will fix.\nThis is hardware related and your Mac needs to go in for service.\n", "Q: Ongoing kernel panics on Mid 2014 MacBook Pro with Big Sur I've been having an ongoing issue with Kernel panics on my mid-2014 MacBook Pro running Big Sur, 11.7.3. Log from the latest is below. Things I have tried:\n\n*\n\n*Full system reformat and reinstall\n\n*memtest86 (4 passes, no memory errors)\n\n*Boot into Apple Diagnostics (No issues found)\n\n*Switching to regular use of Firefox instead of Chrome\n\nIssues seem to happen most often in the web browser, and after waking/login.\nMachine-check capabilities: 0x0000000000000c0a\n family: 6 model: 70 stepping: 1 microcode: 28\n signature: 0x40661\n Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz\n 10 error-reporting banks\nProcessor 0: IA32_MCG_STATUS: 0x0000000000000005\n IA32_MC4_STATUS(0x411): 0xbe00000000800400\n IA32_MC4_ADDR(0x412):   0x00007fff204fdd86\n IA32_MC4_MISC(0x413):   0x00007fff204fdd86\nProcessor 1: IA32_MCG_STATUS: 0x0000000000000005\n IA32_MC4_STATUS(0x411): 0xbe00000000800400\n IA32_MC4_ADDR(0x412):   0x00007fff204fdd86\n IA32_MC4_MISC(0x413):   0x00007fff204fdd86\nProcessor 2: IA32_MCG_STATUS: 0x0000000000000005\n IA32_MC4_STATUS(0x411): 0xbe00000000800400\n IA32_MC4_ADDR(0x412):   0x00007fff204fdd86\n IA32_MC4_MISC(0x413):   0x00007fff204fdd86\nProcessor 3: IA32_MCG_STATUS: 0x0000000000000005\n IA32_MC4_STATUS(0x411): 0xbe00000000800400\n IA32_MC4_ADDR(0x412):   0x00007fff204fdd86\n IA32_MC4_MISC(0x413):   0x00007fff204fdd86\nProcessor 6: IA32_MCG_STATUS: 0x0000000000000005\n IA32_MC4_STATUS(0x411): 0xbe00000000800400\n IA32_MC4_ADDR(0x412):   0x00007fff204fdd86\n IA32_MC4_MISC(0x413):   0x00007fff204fdd86\nProcessor 7: IA32_MCG_STATUS: 0x0000000000000005\n IA32_MC4_STATUS(0x411): 0xbe00000000800400\n IA32_MC4_ADDR(0x412):   0x00007fff204fdd86\n IA32_MC4_MISC(0x413):   0x00007fff204fdd86\nmp_kdp_enter() timed-out on cpu 6, NMI-ing\nmp_kdp_enter() NMI pending on cpus: 0 1 2 3 4 5 7\nmp_kdp_enter() timed-out during locked wait after NMI;expected 8 acks but received 1 after 29584139 loops in 1396766742 ticks\npanic(cpu 6 caller 0xffffff800f9c21d9): \"Machine Check at 0xffffff800f9b559a, registers:\\n\" \"CR0: 0x0000000080010033, CR2: 0x000000010a7ed000, CR3: 0x000000022b5fc1a0, CR4: 0x00000000001626e0\\n\" \"RAX: 0x0000000000000000, RBX: 0x0000000000000000, RCX: 0x0000000000000018, RDX: 0x0000000000000001\\n\" \"RSP: 0xffffffa0b0be3938, RBP: 0xffffffa0b0be3960, RSI: 0x0000000000000018, RDI: 0x00007fff302b5490\\n\" \"R8:  0xffffffa0b0be3da0, R9:  0x00007fff302b5490, R10: 0x0000000000000100, R11: 0x0000000000000000\\n\" \"R12: 0xffffff869d0892a0, R13: 0xffffffa0b0be3da0, R14: 0x0000000000000000, R15: 0xffffffa0b0be39e8\\n\" \"RFL: 0x0000000000000282, RIP: 0xffffff800f9b559a, CS:  0x0000000000000008, SS:  0x0000000000000010\\n\" \"Error code: 0x0000000000000000\\n\"@/System/Volumes/Data/SWE/macOS/BuildRoots/90c5b03f75/Library/Caches/com.apple.xbs/Sources/xnu/xnu-7195.141.49/osfmk/i386/trap_native.c:168\nBacktrace (CPU 6), Frame : Return Address\n0xffffff800f7592d0 : 0xffffff800f88822d \n0xffffff800f759320 : 0xffffff800f9d0be3 \n0xffffff800f759360 : 0xffffff800f9c11da \n0xffffff800f7593b0 : 0xffffff800f82ca2f \n0xffffff800f7593d0 : 0xffffff800f887a4d \n0xffffff800f7594f0 : 0xffffff800f887d43 \n0xffffff800f759560 : 0xffffff801009bcea \n0xffffff800f7595d0 : 0xffffff800f9c21d9 \n0xffffff800f7596c0 : 0xffffff801009fa8e \n0xffffff800f7596d0 : 0xffffff800f82d28f \n0xffffffa0b0be3960 : 0xffffff800fb0c10b \n0xffffffa0b0be3b80 : 0xffffff800fb28bf9 \n0xffffffa0b0be3be0 : 0xffffff800fb2ed3e \n0xffffffa0b0be3f20 : 0xffffff800fb2f644 \n0xffffffa0b0be3f40 : 0xffffff800ff3d01e \n0xffffffa0b0be3fa0 : 0xffffff800f82d1f6 \n\nProcess name corresponding to current thread: plugin-container\n\nMac OS version:\n20G1116\n\nKernel version:\nDarwin Kernel Version 20.6.0: Fri Dec 16 00:35:00 PST 2022; root:xnu-7195.141.49~1/RELEASE_X86_64\nKernel UUID: 5C6437D0-3E72-3CE6-A06A-A14A999AF7ED\nKernelCache slide: 0x000000000f600000\nKernelCache base:  0xffffff800f800000\nKernel slide:      0x000000000f610000\nKernel text base:  0xffffff800f810000\n__HIB  text base: 0xffffff800f700000\nSystem model name: MacBookPro11,2 (Mac-3CBD00234E554E41)\nSystem shutdown begun: NO\nPanic diags file available: YES (0x0)\nHibernation exit count: 0\n\nSystem uptime in nanoseconds: 35770315737096\nLast Sleep:           absolute           base_tsc          base_nano\n  Uptime  : 0x000020886cf6eefb\n  Sleep   : 0x0000000000000000 0x0000000000000000 0x0000000000000000\n  Wake    : 0x0000000000000000 0x0000001b1bc7236e 0x0000000000000000\nlast started kext at 35687094696867: >!AHIDKeyboard 224 (addr 0xffffff8010d3f000, size 16384)\nlast stopped kext at 228356001284: >IOPlatformPluginLegacy  1.0.0 (addr 0xffffff7faa7a8000, size 36864)\nloaded kexts:\n@filesystems.smbfs  3.6.2\n>AudioAUUC  1.70\n>AGPM   122.1\n>!APlatformEnabler  2.7.0d0\n>X86PlatformShim    1.0.0\n@fileutil   20.036.15\n@filesystems.autofs 3.0\n@filesystems.ntfs   3.14.3\n>!AUpstreamUserClient   3.6.8\n>!AHDA  283.15\n>!A!IHD5000Graphics 16.0.5\n>!AGraphicsDevicePolicy 6.3.6\n@AGDCPluginDisplayMetrics   6.3.6\n>eficheck   1\n>pmtelemetry    1\n|IOUserEthernet 1.0.1\n>usb.!UUserHCI  1\n|IO!BSerialManager  8.0.5d7\n>!ASMCLMU   212\n@Dont_Steal_Mac_OS_X    7.0.0\n>!AHV   1\n>!ABacklight    180.3\n>!ADiskImages2  1\n>!A!IFramebufferAzul    16.0.5\n>!ALPC  3.1\n>!ACameraInterface  7.6.0\n>!AMCCSControl  1.14\n>!AThunderboltIP    4.0.3\n>!A!ISlowAdaptiveClocking   4.0.0\n|IO!BUSBDFU 8.0.5d7\n|SCSITaskUserClient 436.140.1\n>!UTCKeyEventDriver 256\n>!UTCButtons    256\n>!UTCKeyboard   256\n>!UCardReader   511.141.1\n>!AFileSystemDriver 3.0.1\n@filesystems.tmpfs  1\n@filesystems.hfs.kext   556.100.12\n@BootCache  40\n@!AFSCompression.!AFSCompressionTypeZlib    1.0.0\n@!AFSCompression.!AFSCompressionTypeDataless    1.0.0d1\n@filesystems.apfs   1677.141.3\n>!AAHCIPort 346.100.2\n@private.KextAudit  1.0\n>AirPort.BrcmNIC    1400.1.1\n>!ASmartBatteryManager  161.0.0\n>!ARTC  2.0\n>!AACPIButtons  6.1\n>!AHPET 1.8\n>!ASMBIOS   2.1\n>!AACPIEC   6.1\n>!AAPIC 1.7\n@!ASystemPolicy 2.0.0\n@nke.applicationfirewall    311\n|IOKitRegistryCompatibility 1\n|EndpointSecurity   1\n>!AHIDKeyboard  224\n>IO!BHIDDriver  8.0.5d7\n@kext.triggers  1.0\n>DspFuncLib 283.15\n@kext.OSvKernDSPLib 529\n>!AGraphicsControl  6.3.6\n|IOSerial!F 11\n>!AHDA!C    283.15\n|IOHDA!F    283.15\n|IOAVB!F    940.4\n|IOEthernetAVB!C    1.1.0\n>!ABacklightExpert  1.1.0\n|IONDRVSupport  585.2\n|IOAccelerator!F2   442.9\n>!ASMBus!C  1.0.18d1\n@!AGPUWrangler  6.3.6\n@!AGraphicsDeviceControl    6.3.6\n|IOGraphics!F   585.2\n>!UAudio    405.39\n|IOAudio!F  300.6.1\n@vecLib.kext    1.2.0\n>!AThunderboltDPOutAdapter  8.1.4\n>X86PlatformPlugin  1.0.0\n>IOPlatformPlugin!F 6.0.0d8\n|IOSlowAdaptiveClocking!F   1.0.0\n@plugin.IOgPTPPlugin    985.2\n|Broadcom!BHost!CUSBTransport   8.0.5d7\n|IO!BHost!CUSBTransport 8.0.5d7\n|IO!BHost!CTransport    8.0.5d7\n>!UMultitouch   264\n>usb.IOUSBHostHIDDevice 1.2\n>usb.cdc    5.0.0\n>usb.networking 5.0.0\n>usb.!UHostCompositeDevice  1.2\n>usb.!UHub  1.2\n>!AThunderboltDPInAdapter   8.1.4\n>!AThunderboltDPAdapter!F   8.1.4\n>!AThunderboltPCIDownAdapter    4.1.1\n>!ABSDKextStarter   3\n|IOSurface  290.8.1\n@filesystems.hfs.encodings.kext 1\n>!AXsanScheme   3\n|IOAHCIBlock!S  332\n|IOAHCI!F   294.100.1\n>usb.!UHostPacketFilter 1.0\n|IOUSB!F    900.4.2\n>!AThunderboltNHI   7.2.8\n|IOThunderbolt!F    9.3.2\n|IO80211!F  1200.12.2b1\n|IOSkywalk!F    1\n>mDNSOffloadUserClient  1.0.1b8\n>corecapture    1.0.4\n>!A!ILpssGspi   3.0.60\n>usb.!UXHCIPCI  1.2\n>usb.!UXHCI 1.2\n>!AEFINVRAM 2.1\n>!AEFIRuntime   2.1\n|IOSMBus!F  1.1\n|IOHID!F    2.0.0\n$!AImage4   3.0.0\n|IOTimeSync!F   985.2\n|IONetworking!F 3.4\n>DiskImages 493.0.0\n|IO!B!F 8.0.5d7\n|IOReport!F 47\n|IO!BPacketLogger   8.0.5d7\n$quarantine 4\n$sandbox    300.0\n@kext.!AMatch   1.0.0d1\n|CoreAnalytics!F    1\n>!ASSE  1.0\n>!AKeyStore 2\n>!UTDM  511.141.1\n|IOUSBMass!SDriver  184.140.2\n|IOSCSIBlockCommandsDevice  436.140.1\n|IO!S!F 2.1\n|IOSCSIArchitectureModel!F  436.140.1\n>!AMobileFileIntegrity  1.0.5\n@kext.CoreTrust 1\n>!AFDEKeyStore  28.30\n>!AEffaceable!S 1.0\n>!ACredentialManager    1.0\n>KernelRelayHost    1\n|IOUSBHost!F    1.2\n>!UHostMergeProperties  1.2\n>usb.!UCommon   1.0\n>!ABusPower!C   1.0\n>!ASEPManager   1.0.1\n>IOSlaveProcessor   1\n>!AACPIPlatform 6.1\n>!ASMC  3.1.9\n|IOPCI!F    2.9\n|IOACPI!F   1.4\n>watchdog   1\n@kec.pthread    1\n@kec.corecrypto 11.1\n@kec.Libm   1\n\n\nA: This particular kernel panic is a machine check exception, which indicates that some type of error condition was detected by the CPU itself.\nThe comment I saw about the panic occurring on cpu 6 as being indicative of a problem with the CPU is not really the correct way of interpreting the panic. All kernel panics (by the nature of things) happen on a CPU. It doesn't mean that the kernel panic is caused by or related to the CPU at all.\nHowever, in your specific case the kernel panic is, as mentioned, a machine check exception. The kernel panic contains the values of various registers from which it is possible to decode the cause of the MCE (machine check exception). In this case it is an \"Invalid timer error\".\nThe status registers also indicate that it could be possible to continue executing after this MCE. I.e. some error conditions are temporary in nature, and the system could keep running just fine after such an MCE.\nThe operating system has tried to progress, but it has timed out waiting for CPU core number 6 to finish flushing its translation lookaside buffer (table for mapping from virtual memory addresses to physical memory addresses).\nFrom the kernel panic it looks like you're running software that could be  using virtualization (i.e. it is containerized software). You are also on relatively old hardware. The timeout value is set to some value that is deemed \"reasonable\" on a modern Mac - but for an old computer, and especially one that is doing virtualization work loads, it might be set a bit too low.\nYou can try disabling the timeout and essentially make the system wait as long as it takes for the CPU core to finish its work. You can do that by adding:\ntlbto_us=0\n\nto the boot-args of your system. Another possibility is to also add:\nvti=9\n\nto the boot-args. This changes various timeouts within the operating system to better suit a virtualization work load.\nThis small configuration change might solve your problem entirely - or it might just make your computer hang/freeze instead of kernel panic.\nAs it is very likely that this problem is hardware related, I would suggest to make sure the CPU is properly cooled. An older machine could have a malfunctioning CPU fan(s) - i.e. either worn out/damaged, or filled with dust. Make sure the computer internals are as dust free as possible and that the fans are working properly.\nIf that is still not helpful, there is a slight chance that you could fix the problem by replacing RAM modules. If not, then it is either the CPU that needs replacement or the main board itself. For a 2014 MacBook Pro that essentially means that getting a different computer - it is usually not worth it considering that a used 2014 MBP can be purchased at very low cost.\n", "Q: New 2023 MacBook Pro Internet connection issues Bought a brand-new 2023 MacBook Pro 14 inch running Ventura 13.2 (updated from 13). It intermittently disconnects from the internet. The issue manifests in one of two ways: either there's an exclamation point on top of the WiFi 'pie' in the menu bar, or there's no indication at all but sites don't load. Either way it usually reconnects within around 10-20 seconds.\nI have my iPhone X (iOS 16.3) and my previous laptop (2015 MacBook Pro 15 inch running Monterey 12.6.2) working fine on the same network. The router being used is an Adtran C424G.\nWhile I'm no networking expert, there's a lot of crowding of SSIDs nearby and I've read that that can be a problem. But then I don't understand why more of my devices don't have a problem with it.\nWhen I first set up the computer I installed a VPN and Little Snitch before connecting to WiFi for the first time. Thinking that might have messed with things, I then factory-reset the machine, but the issue persists. I have followed some of the steps here and here, including deleting the network preference files and disabling airdrop, forgetting and re-adding the wifi network, restarting my computer, restarting the router, using 2.4 ghz instead of 5, safe mode, etc.\nI've called both Apple and my ISP. No dice.\nI cannot reproduce the issue when I use my phone as a hotspot. Also, when I tried the laptop on a different wifi network, I was unable to reproduce the issue, too. I'd be tempted to conclude that something is wrong with my wifi network but again it works fine for my other devices so I'm left where I started.\nUpdate: PS when I click on the WiFi 'pie' with the exclamation point I can expand the error message and it says \"No Internet Connection – Your Mac successfully joined the Wi-Fi network, but cannot reach the internet. If this is your Wi-Fi network, try restarting the modem and router, or contact your ISP.\"\nUpdate: ran pings over wifi hotspot (iphone) for ~9 hours over night, could not reproduce the issue there.\n\nA: I believe the issue is related to similar issues being reported about Mac mini M2 Wi-Fi issues in the Apple Community discussion forums.\nIt seems there might be an issue related to 5Ghz connections related to AWDL (Apple Wireless Direct Link) stuff on the system.\nIt seems like the “solution” is to either connect to the router only via 2.4Ghz or disabled AWDL (Apple Wireless Direct Link) on the problematic device. AWDL is what is used for AirDrop, AirPlay, Handoff and other “magic” connectivity services and such.\nDetails below.\n\nHere are the devices you are using and their Wi-Fi specs.\n\n*\n\n*Apple MacBook Pro 15-Inch (2015): 802.11ac Wi-Fi\n\n*Apple MacBook Pro 14-Inch \"M2 Pro\" (2023): Wi-Fi 6E (802.11ax)\n\n*iPhone X (2017): 802.11ac Wi‑Fi with MIMO\n\n*Adtran C424G: 2.4 GHz 802.11 b/g/n / 5 GHz 802.11 ac (WiFi 5)\n\nNote how the 2015 MacBook Pro and the iPhone X is 802.11ac and so is the Adtran router. And how the 2023 MacBook Pro is 802.11ax. I believe that is the issue; that the 2023 MacBook is having issues connecting at 802.11ac on 5Ghz.\nThe “solution” (ideas?) presented by the user named “hanlanx” there are as follows:\n\n*\n\n*Create two separate networks for 2.4Ghz and 5Ghz: “Just separate my wifi network from shared SSID into 2 standalone SSID, 2.4GHz only and 5GHz only. Now manually connected to \"2.4 only\", it works perfectly without any problem, the \"5 only\" somehow works, but not stable, many packages are getting lost, get some big swing on the chart when doing a speedtest.net.”\n\n*Disable AWDL: You would do this by running this command in the terminal sudo ifconfig awdl0 down (you can re-enable it with sudo ifconfig awdl0 up) and see if that clears it up. FWIW, AWDL is not Bluetooth but rather a peer-to-peer Wi-Fi protocol developed by Apple for things like AirDrop, AirPlay and the Universal Clipboard. More information on this great site Owlink (Open Wireless Link) dedicated to deconstructing and documenting Apple’s AWDL protocol.\n\nI think both of these are viable items to test since they are both easy to handle and reversible. I would personally test disabling AWDL and see how that works. I mean, you won’t be able to AirDrop or use Handoff with that 2023 MacBook Pro but at least you can see if that clears things up. And if it makes no difference? Easy to undo with a basic sudo ifconfig awdl0 up command.\nAnd for that Adtran router, here are instructions on how to control and tweak them 802.11 settings. I would see about disabling the 5Ghz network completely or tweaking the accepted protocol to be 802.11n only or even 802.11g only.\n\n\nAll that said, maybe the best long-term solution is to get a real router that works better with 5Ghz 802.11ax  Wi-Fi 6 connections.\nBut I believe that the ultimate solution here would be to set that Adtran router/modem into bridge mode so it is just a modem and then purchase a real/dedicated router to the setup that is more friendly with 802.11ax connections. The reality is ISP provided combo router/modem devices stink. Just forget about it and get a real router.\n\nA: Apple has exhibited this problem for donkey’s years now.  A device driver engineer I worked with (I was on the hardware manufacturing side prior to going into management) explained that Apple drivers aren’t as tolerant as other drivers.  In this case, the Signal to Noise threshold may be too “conservative” and will drop a connection due to signal quality.  This is why you will often see a MacBook with Bootcamp have WiFi issues with macOS and seem to work fine on Windows.  More commonly, you’ll have WiFi that seems to just “break” after an update or upgrade.\n\n*\n\n*Painfully slow WiFi after Sierra update on Mac Mini\n\n*Trying to Analyse a WIFI Hardware Problem\n\n*Macbook Pro WiFi hardware sporadically malfunctioning\nThat’s just a small sampling of issues.\nThe question is… how do you solve it?\nGet a better Access Point\nYes, this is counterintuitive.  However, I’ve done extensive testing and found that Apple products work best with Enterprise Grade networking gear.\nDoes this mean you have to get rid of your router?\nNot necessarily.  As described in the previous link, you can simply get a dedicated Access Point (AP).  You can disable the WiFi on the router (based on bargain bin chips) and just allow it to serve as your DHCP/DNS, firewall and gateway between your network and the Internet.  The higher grade APs will handle your WiFi needs.\nWhy does an Enterprise grade AP work?\n\nWhile I'm no networking expert, there's a lot of crowding of SSIDs nearby\n\nIt’s not just your MacBook’s AirPort adapter (WiFi) that has to find a suitable channel with sufficient signal strength, the\nWiFi chip in the router must also content with channel crowding and trying to overcome all these rogue signals.  That retail “router” is only capable of so much.\nGetting a dedicated AP centrally placed with high quality chips and antennae that allows for higher signal power (more power equals better signal), you will be able to overcome the problem of the tight thresholds the macOS driver (kexts) preventing you from having a stable connection.\n", "Q: Apple Pages weird table numbering In Apple Pages for Mac, if I create a table, then enable its title, and then make a copy of this table, the second table will be titled Table 1-1 (and not Table 2). Is it a bug or what?\n\nA: No, it is not a bug. It is expected behavior and works the same way with tables in Numbers and Keynote.\nIf you keep creating fresh new tables, they will be named consecutively as \"Table 2\", \"Table 3\", etc. However, when you copy and paste an existing table, Pages tries to duplicate it as fully as it can. But because tables are identified by their names, those in the same document need to have different names, compelling Pages to add \"-1\" while naming the duplicate.\n", "Q: MacBook Pro - Flip front camera for documents online Sometimes Apple just drive me up the wall. I need to show an identity document to a bank, so, of course (Apple!! OF COURSE) I need to flip the camera.\nIs it easy? No. Are there lots of click bait solutions on the net. Yes.\nCommand Option System Preferences didn't do it for me. I'm on Monterey so there's no Camera in System Preferences.\nHow can I flip the camera?\n\nA: It’s not going to be possible directly but, on the principle that you can always fool a computer, I will take a photo with a phone, flip it and then present that to the live feed. Or use a device with two cameras.\nI am simply annoyed and frustrated that I’ve spent £3000 on a computer that won’t perform a simple operation that I require.\n", "Q: What’s the meaning of this square with a down arrow icon on my HomePod in Control Center? This is first time I see this icon.\n\nWhat’s it’s meaning?\nIt’s in Control Center. The HomePods are in “Salon”.\n\nI’m wondering about the icon on the right:\n\n\nA: A software update is available for HomePod\n\n\n\n*Open the Home app.\n\n*Tap or click the More button , then Home Settings  > Software Update.\n\n\nUpdate HomePod - Apple Support\n", "Q: How to install package without administrator password? For example i am installing ms teams. It is definitly known that it does not require admin permissions. But package requests it. Of course they could install some backdoor even for user, but for admin that is dangerous twice.\nThe same with pkg and with brew (because it installs cask which is that pkg).\nSo, is there a way to install for user but avoid entering password?\nmay be there is a sandboxing way?\n\nA: pkgutil\nExtract the files from the .pkg file with the built in macOS command pkgutil:\npkgutil --expand <pkg-path> <dir-path>\n\nThen manually place the extracted files as needed.\nSee also Install as non-admin user when the installer requires admin permissions\n", "Q: How you bring back a network interface, after choosing NO to \"Would you like USB 10/100/1000 to return next time it is connected to your Mac?\" In Mac OS 13 Ventura (and earlier versions), there is an option to Delete network interfaces, like the one used by USB-C ethernet adapters, \"USB 10/100/1000\".  This produces the question,\n\nWould you like  to return next time it is connected to your Mac?\n\ne.g.,\n\nWould you like USB 10/100/1000 LAN to return next time it is connected to your Mac?\n\n\nIf you choose 'No', the device will not appear on screen when you plug the device in, the next time.\nIf you choose 'No', how do your undo your choice later?\n\nA: Use networksetup -detectnewhardware.  From the man page:\nDetects new network hardware and creates a default network service on the hardware.\n\nNote that this change will not be immediately reflected in System Preferences/Settings, so quit them first.\n\nA: Blogger Rich Tong provided the answer in a 2017 posting:\nFrom the terminal, enter this command:\n\nsudo rm /Library/Preferences/SystemConfiguration/NetworkInterfaces.plist\n\n\n", "Q: Which key mechanism do Apple Magic Keyboards use? Apple currently has 2 different Magic Keyboards:\n\n*\n\n*A2449 Magic Keyboard with Touch ID\n\n*A2450 Magic Keyboard with Lock Key\nI'm trying to decide between the two. I don't necessarily need Touch ID, but I absolutely want to avoid getting butterfly keys.\nDo both keyboards use the scissor mechanism? Are there any advantages to the A2449 model besides Touch ID?\n\nA: The Magic Keyboard was introduced in 2021, which is after Apple reverted to the Scissor key design in 2019. The keys feel exactly like the laptop keys in the current M1/M2 models.\nIt's always worth trying one out in an Apple Store before purchase.\nThere's no other difference between them than TouchID. TouchID only works with Apple Silicon Macs. (Having used TouchID on iPhones and iPads for years, I had thought that it was unnecessary and a bit of a gimmick on macOS, but I do find it a really useful time-saver, instead of typing a lengthy password all the time, while maintaining security.)\nYou might want to consider getting the 'full-size' keyboard with numpad keys, better arrow keys, PageUp, etc.\n", "Q: Watch unlock support now gone? (12.6.3 Monterey) I've been using Watch unlock quite happily, including for sudo. However, it stopped working recently.\n\n*\n\n*Today, I noticed the Security & Privacy pane setting \"Allow this mac to be unlocked with Apple Watch\" unexpectedly unchecked.\n\n\n*I tried to check it again, and was met with an error, [Apple ID not signed in]. All the other Apple ID linked services were still available and active, including for example active syncing of Notes.\n\n\n*In the iCloud pane of System Preferences, I logged out and logged back in, but now the unlock with Watch checkbox no longer appears at all.\nCan I re-enable watch unlock, or has Apple regressed this feature on Monterey?\n(In re-authorizing & re-syncing iCloud, I'm a little disappointed to be asked for my phone lock pin on my Mac, instead of authorizing it from my phone. Bad training for users. Oh well.)\n\nA: Sign in with Watch has reappeared. It seems to have been an issue with iCloud partial sign-out or partial sign-in. Component services of iCloud seem to authorize separately, take time to sync, and finish syncing at different times. I got unlucky, (impatiently) observing the intermediate state.\n", "Q: How can I make my phone prefer my mobile network (LTE) over WiFi? I have an iPhone 7. Is there a way that I can make it prefer my mobile network over WiFi? This is because I'll be traveling on a ferry and want it to use the much cheaper mobile network over the exorbitant prices charged by the ferry's operator. This is mainly for when I get back in range of cellular - I'll manually switch at the beginning of the journey.\n\nA: If the WiFi on the ferry is not free, it would most probably ask you to login before using it. Then, if you do not login to it, your iPhone should continue using the cellular network instead of the ferry’s WiFi. To ensure this works as planned, make sure “Ask To Join Networks” in Settings->WiFi on your iPhone is turned on.\nIf for some reason your iPhone has been connected to the WiFi on the ferry before, it might remember that and reconnect to the WiFi automatically on the ferry. To prevent this, go to Settings->WiFi before starting your journey, find the name of the Wifi on the ferry, tap on the info button next to it and tap on “Forget This Network”.\nThe two above should be enough to make your iPhone use the cellular network instead of the ferry's WiFi. In case you wish to take extra action or do it differently, here is what you can also do:\nYou can prevent your iPhone connecting to any WiFi network through its control center for the next 24 hours: shortly before boarding the ferry, swipe up from the bottom of your iPhone (swipe down from the top right for iPhone X or later)  to open its control center and tap on the WiFi icon so that its color changes from blue to white. Assuming you will be on the ferry for less than 24 hours, you can change this back after you leave the ferry through the same procedure.\nAnother solution is to turn off the WiFi on your iPhone completely through Settings->WiFi, either shortly before boarding the ferry or at the beginning of your journey, and turn it on through the same procedure after leaving the ferry.\n", "Q: How to browse photos from iPhone on an iPad? Is it possible to stream/cast my photos app running on my iPhone to an iPad to have a larger screen to browse my photos? I don't want to move or copy them to the iPad, I just want to access the iPad's larger screen to review photos and delete the poor photos from a group. Is there any capability to do that much like AirPlay can handoff to a TV, can I likewise handoff to an iPad? Alternatively can I mirror my iPhone screen to an iPad?\n\nA: I don't think there is a native option here.\nYou cannot use the iPad as an AirPlay target.\nMaybe there is a third-party app?\nI have two options for you that may or may not help, as they are not exactly what you asked for.\nOption 1 (iCloud - Photos app)\nYour easiest and most \"Apple way\" would be to use the Photos app in combination with iCloud to sync the photos between the two devices. You can edit them on the iPad and these changes get made on the iPhone as well. You can also delete them, sort them and do whatever you want with them, the changes will be synced to your Phone and vice versa.\nThe Photos app is smart enough not to fill up your storage and only keep some photos locally if you don't need all of them. (You will see them all, but they may take some time to download once you click on them depending on your internet speed)\nOption 2 (AirDrop - copy paste & copy paste back)\nAnother option would be to AirDrop the photos to the iPhone, edit them there, and AirDrop them back. This would not match your request that you \"don't want to move or copy them to the iPad\". But it is an option that is fast and does not require iCloud.\n", "Q: Enabling 120 fps on mobile Safari I just recently discovered that you can enable 120 fps animation on macOS Safari by following these steps:\n\n*\n\n*In Safari, go to Preferences > Advanced and check Show Develop in menu bar\n\n*Develop > Experimental Features and uncheck Prefer Page Rendering Updates near 60fps\n\n*Quit Safari\n\nNow when using Safari you can experience any webpage that supports up to 120fps.\nHowever, I was wondering if there was any way to do this on iPad/iPhone? I use some animation-based webpages on a daily basis that support 120 fps.\n\nA: The same option as in your question is available on iOS: Settings → Safari → Advanced → Experimental Features → Prefer Page Rendering Updates near 60fps. This option is enabled by default.\n\nA: There is no specific Safari setting for your question. However, in the Settings app, you can turn the ProMotion (120hz) feature on, on your iPhone/iPad.\n(Settings > Accessibility > Motion > Limit Frame Rate)\nMake sure you are using the supported devices for ProMotion:\n\n*\n\n*iPhone 13 Pro and Pro Max\n\n*iPhone 14 Pro and Pro Max\n\n*iPad Pro (2017 or later)\n\n", "Q: How can I close a window without bringing other windows for that app to the front? If have multiple windows open for an app and I close one of those windows the top-most window from that app immediately jumps to the front even if it was behind a window from another app. I'm a long time Mac user and somehow I'm only just now noticing this behavior. Is there some shortcut or tool that can override this either?\n\nA: This is one of a small family of actions you can perform by adding the  Cmd ⌘  key.\nIf you  Cmd ⌘  click the red dot, it won't bring the rest of the app to the front.\nYou can also use this for various types of window move or resize. This works either inside the same app, or for any other app window you can see at the time.\n", "Q: Set environment variable for the whole GUI session (Aka without using `~/.zshenv`) (EDIT OF 06/02/2023 : Previous title was\nVariables set using launchctl setenv aren't part of environment in Mac OS 12 )\nI'm a daily Linux user and decided to try Mac recently.\nI have a Macbook pro 13\" early 2015 that currently run macOS Monterey (12.6.3).\nI'm struggling since a few day to setup SSH_AUTH_SOCK environment variable for my whole session\nI relied on the following plist file in $HOME/Library/LaunchAgents/:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n    <key>Label</key>\n    <string>com.mooltipass.mc-agent</string>\n\n    <key>RunAtLoad</key>\n    <true/>\n\n    <key>StandardOutPath</key>\n    <string>/tmp/mc-agent.log</string>\n    <key>StandardErrorPath</key>\n    <string>/tmp/mc-agent.err</string>\n    <key>Debug</key>\n    <true/>\n\n    <key>ProgramArguments</key>\n    <array>\n        <string>/opt/local/bin/mc-agent</string>\n        <string>-n</string>\n        <string>--address=/tmp/moolticute-ssh-agent.sock</string>\n    </array>\n    <key>EnvironmentVariables</key>\n    <dict>\n        <key>AUTH_SSH_SOCK</key>\n        <string>/tmp/moolticute-ssh-agent.sock</string>\n        <key>TOTO</key>\n        <string>test</string>\n    </dict>\n</dict>\n</plist>\n\nI then activate the agent using launchctl bootstrap gui/501/com.moolticute.mc-agent (or something similar, i don't remember well) and restart my session.\nThe binary mc-agent is running as expected but:\n\n*\n\n*when i check SSH_AUTH_SOCK variable, it still contains the default value, not the one superseeded by my script.\n\n*when i run virt-manager (which make use of this variable) from the Launchpad, it obviously doesn't have the correct value.\n\n*when i run launchctl getenv SSH_AUTH_SOCK the variable value is the one expected.\n\ndid i missed something ?\n06/02/2023 : EDIT FOR CLARIFICATIONS\nAfter the first answer, which is correct but doesn't fullfill my needs, i noticed that my question wasn't clear enought.\nAt the end, i want to mimic the behaviour of regular ssh-agent.\nOn raw MacOS installation, ssh-agent is launched using a plist file at GUI session launch, out of any shell.\nI want my agent to be launched at GUI session startup and the environment variable set for the whole session, in or out the shell.\nThe goal is, when i launch virt-manager (which is a graphical app) directly from the finder or launchpad, no shell is spawned to launch it, virt-manager won't inherit the variable set in my .zshenv or .bashrc, right ?\nThis is the same i guess for any IDE with git connectivity.\nFor example, in Linux, this would be achieved by tweaking Xsession for your favourite DM or by using legacy startup mode for xsession and setting a .xinitrd or .Xsession.\nThen, every variable set this way will be inherit by any applications launched from the window manager as it's part of its environment.\nI have read this week end several methods to do this with launchctl/ launchd but it seems that all of them stopped working on later MacOS versions...\n\nA: The variables that you set using launchd are only valid for the sub-shell in which it executes.\nWhen you check SSH_AUTH_SOCK, or run virt-manager you are opening an interactive shell (via Terminal or iTerm) and that shell process has no clue what environment variables were set in the non-interactive shell opened by launchd.  Therefore, the environment variables are unchanged/unset as you've discovered.\nIf you want that variable to propagate both in your interactive and non-interactive shell(s) then you should set the PATH variable in .zshenv.  See the post ZSH: .zprofile, .zshrc, .zlogin - What goes where? for further details.\nPassing variables to other shells\nYou can use export to pass variables to sub-shells.\nexport PATH=“/foo/bar:/hello/world:/acme;road_runner/coyote” \n\nThe variable is “exported” from the parent shell to the child sub-shell.  However, since Finder is not a sub-shell of the launchd shell executing your script, the variables wont be passed through.\nFrom Apple Support\n\nUse environment variables in Terminal on Mac\nAlthough child processes of a shell inherit the environment of that shell, shells are separate execution contexts that don’t share environment information with each other. Variables you set in one Terminal window aren’t set in other Terminal windows.\n\nTo solve your issue, you need to use .zshenv or .zprofile or .zshrc.  Since it’s a GUI app, you can place it in Login Items and have it launch within Finder, but Finder gets it’s variables set by one of these files anyway.\n", "Q: Private relay working together with Mullvad Most of the time I have iCloud Private Relay enabled. Occasionally I use Mullvad VPN. Recently, I do not know exactly when, this combination stopped working.\nAfter installation of Mullvad VPN, iCloud Private Relay is not working anymore. I get this pop-up stating\n\nPrivate Relay Unavailable Your system settings are incompatible with Private Relay.\n\n\nUninstalling Mullvad VPN and rebooting brings Private Relay back to life. But I still want to use Mullvad VPN now and then. So that's not a permanent solution.\nI tried to manually disable all Mullvad components. To do this, I ranthe first part of the Mullvad uninstall script, see below. After running this script and turning private relay off and on I still get the same error.\necho \"Stopping GUI process ...\"\nsudo pkill -x \"Mullvad VPN\" || echo \"No GUI process found\"\n\necho \"Stopping and unloading mullvad-daemon system daemon ...\"\nDAEMON_PLIST_PATH=\"/Library/LaunchDaemons/net.mullvad.daemon.plist\"\nsudo launchctl unload -w \"$DAEMON_PLIST_PATH\"\nsudo rm -f \"$DAEMON_PLIST_PATH\"\n\nsudo dscl . -delete /groups/mullvad-exclusion || echo \"Failed to remove 'mullvad-exclusion' group\"\n\n\necho \"Resetting firewall\"\nsudo /Applications/Mullvad\\ VPN.app/Contents/Resources/mullvad-setup reset-firewall || echo \"Failed to reset firewall\"\nsudo /Applications/Mullvad\\ VPN.app/Contents/Resources/mullvad-setup remove-device || echo \"Failed to remove device from account\"\n\nOn further investigation I found the following issue Mullvad-daemon (without VPN active) on macOS Ventura disrupts iCloud Private Relay #4215. On the Mullvad GitHub. So it's a common problem.\nWhat I am know looking for is a workaround. Is it possible to temporarily disable Mullvad and enable Private Relay again, without uninstall and reboot?\nThis issue exists with Mullvad VPN 2022.05 on both macOS 13.1 and 13.2.1\n\nA: Mullvad released version 2023.1 a few days ago (2/20/2023). While I haven't tried it yet, it may be worth testing the new version to see if the issue has been resolved. If the problem persists, consider using Wireguard instead.\nHere is a link to the instructions for installing Wireguard on a Mac. - Link.\n", "Q: Unable to install MacOS Sierra on a 2015 Macbook Air I have an early 2015 MacBook Air - which had macOS Monterey installed that I want to exchange with my new Macbook Pro. So I erased the Air using the steps provided in the official Apple Support website.\nNow, when the system restarted it showed a folder with a flashing question mark (??) since it was not able to find anything to boot.\nI restarted the MBA in recovery mode and tried to re-install macOS, after which it did some pre-checks and prompted me to install Sierra\nIt failed at last step of the installation stating “Error Occurred while Preparing the Installation” error. I have now tried it thrice but I keep getting the same error.\nI've also tried Disk Utility - ran First Aid on the disk and then re-installing Sierra.  It is not working and fails at the same last step.\n\n[Update 1] I was on call with Apple Support for almost 1.5 hrs today and they were not able to solve the issue. This issue persists even after erasing the disc using “HFS+ [Mac Extended, Journaled]” as suggested in the comments.\nApple Support has finally asked me to go ahead and create a bootable installer to try and boot from an external device.\n\nA: I have an early 2015 macbook air and I had the exact same issue. A possible fix could be, go to utilites when you are in macOS Utilities (top left of the screen) then click startup security utility, enter password (create a password if you don't have one and restart if it tells you and go back to the utilities), under Secure Boot, click Medium Security and under Allowed Boot Media, click Allow booting from external or removable media. Then try to install macOS (restart if it doesn't work the first time).\nIf that method does not work, install a bootable USB that the GB needed can vary depending on the size of the macOS. (You need another mac for this, you can do it on windows, but I couldn't get it to work)\nhttps://www.youtube.com/watch?v=AUOx0b3YjlI\nFollow this from 0 to 5:37\nand 5:37 to 7:27 is an example of the fix I explained above.\nI didn't search up the macOS on apple store because it didn't pop up, so I typed it on google and clicked on the link from apple and it took me to the apple store and I installed macOS Big Sur and made sure it was compatible to my mac. (Depending on the version the mac you are using to install, the macOS can vary, a good rule is to install the macOS that is compatible with your mac you are using to install or the current macOS of the mac you are using to install). After your done creating the bootable USB (Follow 7:38 to 8:29 and 9:26 to the end is the installing the macOS for this part and 8:30 to 9:25, if you need it, is about the internal hard drive), plug the USB in the mac and turn it on and immediately hold option. You'll see the USB name and click on it (the arrow). For the internal hard drive I erased used Mac extended (Journal), but this may vary depending on the macOS you used. Then I downloaded the macOS and it took a while. If it freezes, turn  it off and turn it back on again or go and install the macOS again through cmd + r.\n", "Q: macOS HDD not listed anymore EDIT: I had the SDD analyzed by a data restore company. They wrote that the SSD has a fatal error in its firmware / microcode (controller damage). Since it is an Apple SSD they cannot do anything about it. Do you know, if Apple itself has some measures to restore this?\nORIGINAL POST: I updated an old mid-2013/early 2014 MacBook Air (with the model identifier MacBookAir6,2) to macOS 11.7.3. After the update the MacBook Air did not start anymore. Recovery and internet recovery did not work. I now have a bootable stick and tried to install macOS Big Sur from that. Unfortunately, I can't since neither Install, nor Disk Utility or diskutil list show the SSD anymore. It did work before the update. Has this ever happened to anyone or does anyone have an idea how to get the MacBook Air to recognize the SSD again? Still have some important data on that drive.\n\n\n\nA: It is likely, considering the age of the Mac, that the drive is no more, off to meet it's maker and joined the choir invisible... (ummmm sorry)\nThe fact that the installer, nor disk utility, don't see the MBA's drive lead me to believe this.\nIt is unlikely that the upgrade damaged something, rather the drive was already on its last legs and you're using it to effect an upgrade was just the straw that broke the camel's back.\nWhile it is possible that you could take the drive out of that Mac, attach it to another and use some data recovery software to get the files you need off of it. You may have to send it off to a data recovery company. This can be expensive so I'd try the data recovery software first.\n", "Q: How do I pay for my kid's app after I've approved it via Family Sharing? My 10-year-old son is set up as a family member with his own Apple account. His iPad, it's set to \"Ask To Buy.\" So, when he wants to download an app from the App Store, I get a notification on my iPhone.\nThis works great for free apps... but for a paid app (or in-app purchase), after I approve it via the iPhone notification, it asks him to put in a credit card on his iPad.\nFor obvious reasons, I'm wary of putting my credit card info onto his iPad. But I do want to buy this app for him. I would have expected the \"Ask To Buy\" notification to go the next step and give me the option to purchase it on his behalf.\nHow do I do this? I feel like I'm missing something obvious here.\n\nI Googled around for an answer, but to no avail. Lots of info on sharing purchases. But not purchasing initiated on the child's device. If I'm just a bad Googler, point me in the right direction!\n\nA: Enable Purchase Sharing\nIn addition to Family Sharing, Purchase Sharing needs to be enabled to share purchases (redundant, I know) and to have the family organizer billed for all purchases.\n\nWhen you turn on purchase sharing, everyone in your family gets access to apps, music, movies, TV shows, and books that family members buy. The family organizer is billed for family members' purchases.\n\nYou as the organizer must have a payment method saved to your account for purchases to made seamlessly.\n", "Q: 2 Computers, multiple email accounts; removing Mail app storage on old laptop I have 2 MacBooks: One that is I use, and one that my kids share, but that used to be my old personal one. I have kept my Admin account on that laptop. It's running out of Storage space, and I noticed that I have 11GB of Mail storage on it. How do I safely remove everything related to Mail on that laptop, including all used storage, without affecting my main laptop? I have:\n\n*\n\n*1 iCloud IMAP account using my iCloud email address that I never use\n\n*1 IMAP Google account which is my main personal email address\n\n*1 work Google account\n\nI have unchecked the \"Enabled\" box for each of these in Mail -> Preferences -> Accounts.\nIf I try to remove the iCloud account by hitting the minus symbol below the list of accounts, it says \"The iCloud account personalemail@email.com is shared by other applications on this Mac. You can remove this account in Internet Accounts.\"\nOk, fine. So I hit Internet Accounts and there I see iCloud at the top, and the Mail box is not checked for syncing. Same for my Personal and Work accounts; I see both of them in Internet Accounts and neither have the Mail box checked for Syncing. So far so good?\nBack to Mail app -> Accounts, if I try to hit the - symbol on my work account (which, remember, is not enabled), I see \"The google account workemail@work.com is shared using iCloud Keychain; you can remove it in Internet accounts\". Ok, so back to Internet Accounts, then. If I hit the - symbol on it there, it said \"Do you want to remove the Gmail account workemail@work.com from all your computers using iCloud Keychain?\". Well, no, I don't want to remove it from my current laptop, just from this old one. So I guess if nothing is checked for Syncing for this account in Internet Accounts, then it doesn't matter, and nothing is downloaded to this laptop, right?\nBack to Mail app again. Same thing, if I hit the - symbol on it, I am directed back to Internet Accounts. This time, I get a different message if I hit the - symbol in Internet Accounts. \"Do you want to remove the Gmail account personalemail@email.com from all your computers using iCloud Keychain or turn it off on only this Mac?\"...  I suppose I can hit \"Turn Off Account\" here?\nThanks for your assistance!\n\nA: You can safely remove email accounts\nYou can safely remove email accounts from one Mac without affecting another Mac using the same email account. Per Apple Support:\n\nYou can remove an email account from the Mail app on your Mac at any time. When you do, the account’s email messages are removed from your Mac. Copies of messages remain on the account’s mail server and are still available (from webmail, for example).\n\nWith very rare exception, email is cloud based - Gmail, Outlook.com, etc. This means all of your messages are stored at the server, not on the client (your Mac).  You no longer have to “download email from a POP server.\nWhile cloud services like Gmail and Outlook.com (IMAP and Exchange, respectively) allow you to sync mail accounts to your client devices, it doesn’t delete messages when you remove an account.  In other words, it will sync deletions to individual messages, but a removal of the account is not a deletion event.  This is how you can wipe a lost device, get a new one and not lose a single message, calendar event or piece of contact info.\nKeychain is not an “account.”\n\n\"Do you want to remove the Gmail account workemail@work.com from all your computers using iCloud Keychain?\"\n\nThis is not removing an account from your Mac, but removing a Keychain entry from the Keychain database.  It’s analogous to syncing messages described above.  Here, you’re deleting a record which will sync across all devices - not deleting (removing) the whole keychain.\nBe sure you have a backup!\nWhile everything described here is quite safe, it’s always a good idea to have a Time Machine backup especially before making changes.  We’re all human and we will make mistakes even when attempting completely innocuous tasks like removing an email account.  It’s much better to have and not need it than to need and not have it.\n", "Q: How do I remove a device that I no longer own from Find My? I sold my MacBook Pro a while ago and even if I did signed out from my Apple account, I realize now that it still appears in Find My and I see the location of the new owner.\nWhen I select that device in my Find My, I have the option to erase it or mark as lost. I do not see any option to remove it from my account though.\nIf I right click on the device in the list as some suggest, I also do not see the Remove option\n\nThe Apple support page was not helpful.\nHow can I remove it?\nUPDATE\nI noticed that when the device is offline, I do have the option to remove it. If I do so, I confirm with my Apple password and the device is removed but appears again after some seconds in the device lists.\n\n\nA: Right-click on the device in the sidebar and choose ‘Remove This Device’.\n\nAs explained in the linked Apple Support article, there should also be an option to remove the device underneath the Erase button when viewing the device on the map. You may need to scroll down to see it.\n\n", "Q: Does dialing 911 in the iOS Phone app trigger the same Emergency SOS features? When using Emergency SOS on the iPhone, a notification is sent to emergency contacts as defined in the Health application Medical ID feature.\nWhen manually dialing 911 in the Phone application, does this same behavior apply? Or does it only work when using the specific Emergency SOS feature?\n\nA: When you manually dial 911 (North American Emergency number), the iPhone does not implement the features in the Emergency SOS feature.\n\nWhen you make a call with SOS, your iPhone automatically calls the local emergency number… You can also add emergency contacts. After an emergency call ends, your iPhone alerts your emergency contacts with a text message, unless you choose to cancel.\n\nEmphasis Mine\nYou either have to intentionally activate SOS or have your iPhone/Apple Watch detect a crash or a fall for these features/functions to work.\nWhen your iPhone contacts the emergency number configured in your device, it will send an automated voice message that includes your location.  After that call and if configured, it will send text messages to your emergency contacts.\nDialing the local emergency number doesn’t initiate SOS.\n", "Q: How to install macOS with no mouse or trackpad I'm preparing a Mac mini for sale.  I have no mouse or trackpad.  Using just the wireless keyboard, I managed to reboot in Recovery Mode and erase the drive in Disk Utility.  However, the Install macOS utility is poorly designed - there's only one hard drive (shown as an image), it has to be selected before you can continue, and you can't get to it with any kind of normal Full Keyboard Access key combos, arrows, tabs, or whatever.\nI once was able to use Mouse Keys in a similar situation, but I can't figure out how to get them on in Recovery Mode.  I've tried Cmd+Opt+F5 (including fn on my mini keyboard), tapping Opt 5 times, and some other key combo I found online.  I can get Voiceover to come on with Cmd+F5, but that doesn't help select the drive.  These accessibility keys are a nightmare.\nJust to keep the dream alive, I also tried creating a bootable installer flash drive.  The very first screen it comes up with requires a mouse or trackpad to navigate.  Still, I could not get mouse keys working.\n\nA: Problem solved.  I didn't give Voiceover enough of a chance, and didn't realize it has enough capability that Mouse Keys is not needed.\nAfter booting into Recovery Mode, ordinary keyboard access can be used to navigate until you get to the installer screen where you have to choose the drive to install to.  Then:\n\n*\n\n*Turn on Voiceover: Cmd+F5 (this also requires\nholding the Fn key on my keyboard).\n\n*Navigate down until the grid of drive choices is surrounded by a rectangle: Ctl+Opt+Down (or right arrow).\n\n*To enter and interact with the grid: Ctl+Opt+Shift+Down.\n\n*The first grid cell will be selected.  If necessary, select desired one:\nCtl+Opt+Right (or down arrow).\n\n*Exit the grid: Ctl+Opt+Shift+Up.\n\n*Navigate to Continue button: Ctl+Opt+Down (or right arrow).\n\n*Press spacebar to 'click' on it.\n\n*Turn off Voiceover: Cmd+F5.\n\n", "Q: Force iCloud to sync from phone reminders I went from iPhone to Android and now back to iPhone.\niCloud seems to have my old iPhones reminders even though I have iCloud turned on for reminders on new phone. I only know this because I opened iCloud reminders from my PC for the first time in several years and found the problem.\nIf I turn iCloud off and back on though my phone settings it says it will delete all local reminders and refresh from iCloud which is useless to me.\nIs there a way to sync from my iPhone up to the cloud so the cloud reflects the current reminders app contents?\n\nA: You need to clear out iCloud Reminders first before you connect your iPhone and synchronize it.\n\niCloud seems to have my old iPhones reminders … I opened iCloud reminders from my PC for the first time in several years and found the problem.\n\nFollow these steps to get the reminders on your iPhone to iCloud (assumes you’ve already disabled iCloud sync on your iPhone):\n\n*\n\n*Turn or remove iCloud sync on your PC\n\n*Log into iCloud.com\n\n*Open Reminders and ensure everything is deleted\n\n*Enable iCloud sync on your phone.\n\nIf you have other devices synchronizing Reminders (like a MacBook or iPad, for example), you need to disable these as well.\n", "Q: Control Podcasts in MacOS using Apple Watch Is it possible to control the Podcasts app, running in MacOS, using Apple Watch?\nI tried using the watch's Now Playing app, also to use the watch's Podcasts app, and the built-in Remote app, without any success.\nIt seems to me this feature of controlling audio with Apple Watch, is working only for the Music library, but this Apple Discussions' issue points out that also Spotify tracks are working, so it's not limited to Apple Music.\n\nA: According to the  Now Playing App description, there’s no mention of Mac computers running macOS:\n\nThe Now Playing app on Apple Watch will surface controls for content playing on your Apple Watch, iPhone or any of your connected devices like HomePod or paired Bluetooth speakers.\n\nIt’s important to remember that the Watch is an extension of the iPhone so the Now Playing App acts as a separate UI for the media playing on your iPhone.\nAddaitionally, if you look under “Information” it will show the compatibility requirements:\n\nCompatibility\n\n*\n\n*iPhone - Requires iOS 13.0 or later.\n\n\n*iPod touch - Requires iOS 13.0 or later.\n\nThere’s no mention of Mac computers or macOS.  So, this infers that it is controlling the app on device only and not the desktop.\nAs for Spotify, keep in mind that it is a cloud music service.  Now playing can control the app on the iPhone and if you’re signed into Spotify on a Mac as well, those activities will be mirrored.  There’s no evidence that Now Playing is controlling a desktop application from any of the discussions.\n", "Q: How do security keys interact with other methods for 2FA and account recovery? If security keys are enabled for an Apple ID, are all other forms of two factor authentication and account recovery disabled? The question is prompted this statement:\n\n\"If you lose all of your trusted devices and security keys, you could\nbe locked out of your account permanently.\"\n\n(Quoted from \"About Security Keys for Apple ID - Apple Support\".)\nI'm puzzled because after I enabled security keys for my account, the \"Passwords & Security\" tab in the Settings app still shows:\n\n*\n\n*A trusted phone number.\n\n*An account recovery contact\n\n*Recovery Key: on\n\nWill any of these still work if needed? The warning quoted above suggests that they will not, but if this is true, why does the Settings app still show them being active, and why won't it allow me to remove my trusted phone number?\n\nA: First, it's important to recognize that the following statement by Apple is basically a disclaimer should you get locked out of your account.\n\n\"If you lose all of your trusted devices and security keys, you could be locked out of your account permanently.\"\n\nCan it happen?  Yes, the possibility is real.  Is it likely to happen?  Not likely.\nNot all services utilize security keys so you'll still need the alternate methods of 2FA (two factor authentication).\nAs for getting your account locked, there are several steps here to help mitigate that:\n\n*\n\n*Multiple keys.  When you have a hardware token like the Yubikey or RSASecureID, you want to have a second one that is ideally in a secure, off-site location.  Should you lose one, there's always the second to get you back into your account\n\n*Trusted devices.  Like having a second (backup) hardware token, having multiple trusted devices allows you flexibility should you have a device lost or stolen.  Similarly, it advisable to have a trusted device you don't always take (a second iPad for home use) with you like your iPhone and primary iPad.\n\n*Finally, there is Account Recovery.  This is a manual process by Apple to validate your identity and get your access into your account restored.\n\nThe hardware tokens (security keys) provide a much higher level of security than the already strong 2FA.  However, higher security means an increased chance of locking yourself out of the account.  That said, taking some simple precautions detailed above should mitigate that risk.\n\nA: After some experiments with how Apple handles security keys, I was able to answer the question to my own satisfaction. For details, see:\nHow do security keys interact with other methods for 2FA and account recovery?\n", "Q: Using an iMac as an additional monitor for Mac Mini M1 I am aware that the Mac Mini M1 has an infuriating limit of two monitors. However, it appears that you can attach an AirPlay device as an additional monitor.\nI have a retired iMac running AirServer or Reflector (I’ve tried both), and I can use it as an extended monitor on my Mac Mini. AirServer does it a little more transparently, though there seems to be less lag with Reflector.\nThe limitation with both is that AirPlay itself appears to have a limited resolution of 1080p, and so I don’t get the full benefit of the size and resolution of the iMac.\nUnfortunately, the iMac is a little too old for built-in AirPlay support and too new for Target Display mode.\nIs there some other software solution to this?\n\nA: There are several questions already dealing with this topic of using a Mac of some type (MacBook, iMac, iPad, etc.) as an additional display to a computer whether it be another Mac or even a Windows machine.\n\n*\n\n*Using iMac late 2013 as external monitor to HP EliteBook 820 G3 on Windows 10\n\n*Connect another mac as secondary display\n\n*How can I use an iPad with a Retina display as an external monitor?\n\n*How to use my iMac 2017 as a second monitor for my MacBook Pro mid 2012?\nTarget Display Mode\n(Just putting this here to address the question)\niMac computers prior to 2014 supported Target Display Mode,  Potentially your iMac might support it (you mentioned it was \"too old\" for AirPlay) but Mac computers running  High Sierra or later couldn't connect to it.  This makes an Apple-centric hardware solution untenable.\nSoftware Solutions\nIn the links of similar question linked above, it comes down to about two different solutions:\n\n*\n\n*Luna Display.  This uses a hardware based dongle to connect a computer to a Mac or iPad as a secondary monitor\n\n*AirParrot 3. This allows you to turn any device including AppleTV and Chromecast into another monitor you can stream/mirror to.\n\nThe problem with these solutions is the limited amount of bandwidth available to send high definition video with a high refresh rate reliably.  This is why you're not getting the resolutions you're looking for.\nFinal thoughts\nThere are good to excellent apps out there to stream and extend a desktop, but they are not designed for \"production use.\"  They are for setting things up in an ad-hoc manner. I've personally used SpaceDesk on a Windows machine to extend the display of a laptop to my iPad.  It was great when I was in the local Panera working on financials, but when I got back to my desk, I didn't give it a second thought since I had my multi-monitor setup.\nDon't try and bodge this.  Restore that iMac back to it's glory and sell it or get into retro computing.  For the secondary display, get a quality monitor.\n", "Q: Does the iPad Pro M2 (4th generation) support 6 GHz Wi-Fi? I’m confused! Does the iPad Pro M2 (4th generation) support 6 GHz?\nIt’s mentioned on this kbase:\n\n“Wi-Fi 6E uses the 6 GHz wireless band to enable faster and more reliable wireless connections on supported devices. Here's how to get the best wireless performance when using Wi-Fi 6E with an Apple device.”\n\nBut on the iPad’s specs page it’s mentioned:\n\n“Wi‑Fi 6E (802.11ax) with 2x2 MIMO, simultaneous dual band (2.4GHz and 5GHz)”\n\nI only have two WiFi 6 « E » clients for now but I want to use the 6 GHz band with an Unifi Entreprise AP.\n\nA: \nDoes the iPad Pro M2 (4th generation) support 6Ghz Wi-Fi?\n\nThe short answer is yes, it supports 6GHz Wi-Fi.\nBasically, Wi-Fi 6E is compatible with Wi-Fi 6 and legacy standards that already operate in the 2.4 and 5GHz ranges.  What the spec page is referencing that the iPad can do two simultaneous streams using both the 2.4GHz radio and the 5GHz radios.\nFrom Network World:\n\n2x2 MIMO, for example, indicates two antennas at the transmit end and 2 antennas at the receive end, the minimum required by the draft 802.11n standard.\n\n", "Q: Macbook Pro x86_64 Triple-Boot: How can I fix EFI boot and Startup Manager Summary\nI successfully created a triple-boot on my 2015 MBP with macOS (Big Sur), Ubuntu 22.0.1, and Windows 10. I can boot into any of the 3 successfully, however, the Startup Manager does not show all the boot options. I have to use the Grub menu to boot into Windows, which is not what I want. What must I do to update the Startup Manager so that it presents me with boot options for Windows, Ubuntu and macOS installations?\nInstallation History\nThe drive has two macOS installations on different partitions - Yosemite and Big Sur - which I can choose with the startup manager. This is a fairly common practice.\nI installed Windows 10 using Boot Camp from Big Sur, which seems to create a Windows bootloader partition at /dev/sda1. At this point, the startup manager (holding the option key at startup) correctly showed the macOS and Windows options.\nI then created a separate partition at /dev/sda3 for Ubuntu's Grub bootloader in addition to a partition /dev/sda7 for Ubuntu's main file system, and I installed Ubuntu using these partitions. I specifically chose /dev/sda3 for the EFI bootloader so that it wouldn't overwrite the Windows bootloader in /dev/sda1. Everything installed fine, however, I lost the ability to boot directly into Windows from the startup manager.\nAfter the Ubuntu installation was complete I was expecting the startup manager to show Windows and Ubuntu options in addition to macOS, but only the Windows and macOS icons appear. But when I select the Windows icon in the startup manager, it boots into Ubuntu's grub bootloader. The Grub menu has options for booting into Ubuntu or Windows (which the grub menu shows is /dev/sda1). So I can boot into Windows or Ubuntu successfully using the Grub menu.\nHowever I want the startup manager to display separate icons for Windows and Ubuntu at startup and allow me to select them from there. I have tried a few things to fix this unsuccessfully and am a bit baffled how to accomplish this.\nSome things I tried\nThere are 2 EFI partitions on the disk, one created by Boot Camp at /dev/sda1 for the Windows bootloader, and one I created at /dev/sda3 for Ubuntu's Grub bootloader. When I mounted the /dev/sda3 partition, I noticed the EFI directory was empty. Following instructions from some past posts here, I copied the contents of the EFI directory in /dev/sda1 partition to the EFI directory in the /dev/sda3 partition, which allowed me to \"bless\" the partition in macOS as a bootable volume in the startup manager. After this, the startup manager did show an additional icon at startup, but as expected both icons look identical (Windows icon) and selecting either of them puts me into Grub.\nI was hoping to adjust the contents of the two EFI partitions so that they each point to the respective bootloader, one for Windows and one for Grub/Ubuntu. This is where I am having difficulty. I know the boot configuration for Windows is displayed along with others when I run \"efibootmgr -v\" in Linux, but I don't know how to apply this information to accomplish what I am asking.\nDisk partitions and information\nResult of fdisk -l /dev/sda:\n$ sudo fdisk -l /dev/sda\nDisk /dev/sda: 465.92 GiB, 500277790720 bytes, 977105060 sectors\nDisk model: APPLE SSD SM0512\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: A79A70A1-D180-47E6-BBAC-80365256A8F0\n\nDevice         Start       End   Sectors   Size Type\n/dev/sda1         40    409639    409600   200M EFI System\n/dev/sda2     409640 616597135 616187496 293.8G Apple APFS\n/dev/sda3  616597504 617129983    532480   260M EFI System\n/dev/sda4  617129984 702054399  84924416  40.5G Microsoft basic data\n/dev/sda5  702055552 780652767  78597216  37.5G Apple HFS/HFS+\n/dev/sda6  780652768 781922303   1269536 619.9M Apple boot\n/dev/sda7  781955072 977104895 195149824  93.1G Linux filesystem\n\nResult of gdisk -l /dev/sda:\n$ sudo gdisk -l /dev/sda\nGPT fdisk (gdisk) version 1.0.8\n\nPartition table scan:\n  MBR: protective\n  BSD: not present\n  APM: not present\n  GPT: present\n\nFound valid GPT with protective MBR; using GPT.\nDisk /dev/sda: 977105060 sectors, 465.9 GiB\nModel: APPLE SSD SM0512\nSector size (logical/physical): 512/4096 bytes\nDisk identifier (GUID): A79A70A1-D180-47E6-BBAC-80365256A8F0\nPartition table holds up to 128 entries\nMain partition table begins at sector 2 and ends at sector 33\nFirst usable sector is 34, last usable sector is 977105026\nPartitions will be aligned on 8-sector boundaries\nTotal free space is 34425 sectors (16.8 MiB)\n\nNumber  Start (sector)    End (sector)  Size       Code  Name\n   1              40          409639   200.0 MiB   EF00  EFI System Partition\n   2          409640       616597135   293.8 GiB   AF0A  \n   3       616597504       617129983   260.0 MiB   EF00  EFI for GRUB\n   4       617129984       702054399   40.5 GiB    0700  Basic data partition\n   5       702055552       780652767   37.5 GiB    AF00  Yosemite\n   6       780652768       781922303   619.9 MiB   AB00  Recovery HD\n   7       781955072       977104895   93.1 GiB    8300  \n\nResult of efibootmgr -v:\n$ sudo efibootmgr -v\nBootCurrent: 0000\nTimeout: 5 seconds\nBootOrder: 0000,0002,0001,0080\nBoot0000* ubuntu    HD(1,GPT,a61ea436-09b2-4355-a10e-e89f519653d6,0x28,0x64000)/File(\\EFI\\ubuntu\\shimx64.efi)\nBoot0001* Windows Boot Manager  HD(1,GPT,a61ea436-09b2-4355-a10e-e89f519653d6,0x28,0x64000)/File(\\EFI\\Microsoft\\Boot\\bootmgfw.efi)WINDOWS.........x...B.C.D.O.B.J.E.C.T.=.{.9.d.e.a.8.6.2.c.-.5.c.d.d.-.4.e.7.0.-.a.c.c.1.-.f.3.2.b.3.4.4.d.4.7.9.5.}....................\nBoot0002* ubuntu    HD(3,GPT,e2387071-5951-4a9f-8d7d-2b113d3ce3b7,0x24c08800,0x82000)/File(\\EFI\\ubuntu\\shimx64.efi)\nBoot0080* Mac OS X  PciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/Sata(0,0,0)/HD(2,GPT,11eb72ed-4a8f-4f7d-a8f7-4fca3438adf6,0x64028,0x24c1e788)/VenMedia(be74fcf7-0b7c-49f3-9147-01f4042e6842,cbcfd61e0b162b4aafa0d79e9050dcbb)/File(\\A62C572A-E899-4CAC-A2C9-F54103EAD91E\\System\\Library\\CoreServices\\boot.efi)\nBoot0081* Mac OS X  HD(1,MBR,0x901c8f2d,0x800,0xe51f800)\nBoot0082*   PciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/Sata(0,0,0)/HD(2,GPT,11eb72ed-4a8f-4f7d-a8f7-4fca3438adf6,0x64028,0x29d24458)/VenMedia(be74fcf7-0b7c-49f3-9147-01f4042e6842,cbcfd61e0b162b4aafa0d79e9050dcbb)/File(\\C04D8B5C-49A1-4AD5-9182-459286FF5241\\System\\Library\\CoreServices\\boot.efi)\n\n\nA: Well, after sifting through many posts on the subject and trying different things, I found an answer to my own question. Posting it here in case others are having the same issue. The two posts I found to be the most helpful are here and here.\nThe short answer is that after installing Windows, you have to back up the Windows bootloader before installing Ubuntu, because there is a bug in the Ubuntu installer that doesn't honor your EFI partition selection, and it overwrites the Windows bootloader. If you don't back up the Windows bootloader first, fixing it is difficult to impossible. If this happens and you try to re-install Windows, the presence or a second EFI bootloader partition causes Windows installation to fail, and leaves additional new problems with your partitions.\nThe easiest way to accomplish installing Ubuntu and preserving an existing dual-boot into Mac or Windows, is to add some steps after installing Windows and before installing Ubuntu, as follows.\nMake sure you have a separate 100 to 200MB partition for the Ubuntu bootloader in addition to the partition for the filesystem.\nBoot into the \"Try Ubuntu First\" option from the Ubuntu install disk before doing the install. Open a terminal with command-option-T, mount the Windows bootloader partition /dev/sda1, and rename the EFI directory to some other name like EFI.win.\nThen install Ubuntu, specifying your new EFI partition (in my case /dev/sda3). What should happen is the EFI bootloader gets installed into the partition you select. But, due to a bug in the installer, what actually happens is that it formats the new EFI partition, but installs the bootloader into /dev/sda1. You end up with a correctly formatted but empty new EFI partition. The first EFI partition on the drive, /dev/sda1, contains directories EFI and EFI.win. This needs to be fixed.\nAfter the Ubuntu install is complete, restart the computer with the option key down, and boot into \"EFI\" which is the new Ubuntu installation. Open a terminal. Mount the two bootloader partitions. Copy the EFI directory in the Windows bootloader partition (which is actually the Ubuntu bootloader) to the 2nd EFI partition. Then delete the EFI directory there and rename your backed-up Windows bootloader, by renaming EFI.win back to EFI.\nNext, check the UUIDs of the two EFI partitions with the command 'blkid /dev/sda1 /dev/sda3'. (your partition numbers many be different, use the partition numbers on your drive.) Edit the /etc/fstab file. Locate the UUID in this file for the Windows bootloader partition, /dev/sda1, and replace it with the UUID of the correct Ubuntu EFI partition (UUID of /dev/sda3 in my case).\nLastly, the Ubuntu install leaves the disks's master boot record in a state that can't be read by the Windows bootloader. Rebuild the master boot record for the drive by using gdisk, as follows. Open a terminal and type 'sudo gdisk /dev/sda'. This puts you into an interactive shell for gdisk. Type the following keys in the following order, which will rebuild the master boot record correctly: x n w y. This fixes the master boot record and saves it to a format that Windows bootloader can use again.\nAt this point you can restart the computer, hold down the option key, and you should see separate icons labeled \"EFI\" (Ubuntu) and \"Windows\", along with all your bootable macOS and recovery partitions. There are ways to rename these labels or make other cosmetic changes, these are described in the included links.\nI know this explanation is compressed and could have been written in a more expanded way. I wanted to at least capture the important points for experienced people. I hope this information is useful. If you need more detailed instructions, the linked pages provide expanded instructions.\n", "Q: Does Mojave 10.14 support core audio FireWire? I would like to upgrade from high sierra but afraid my mackie 1640i mixer will not be recognized by core audio. Thank you.\n\nA: I can verify that the Mackie 1640i was recognized by mid-2010 Mac Pro with Metal capable GPU running Mojave macOS 10.14 (thanks to information provided by Tetsujin).\n", "Q: What is \"Remind Me\" supposed to do? When I use the Remind Me feature in iOS Mail (iOS 16, iPhone 8) I imagine that when the fire date has passed I'll receive a local notification reminding me about the message. That never happens. I'm also never alerted in the app. I can set the remind date to one minute in the future and watch the minutes pass without any results.\nWhile the feature is already useless to me as it is, before concluding it's defective I thought I'd ask what's supposed to happen. In what way is it meant to \"remind me\"?\nAll relevant notification permissions are enabled for the app and feature in question.\n\nA: In my experience, Remind Me will send a notification and move the message to the top of the mailbox it resides in.\nEx: If you mark \"Remind Me\" on an email in your Archive folder, it will go to the top of the Archive folder when the time comes.\nYou can check your notification settings. Go to Settings > Notifications > Mail. Check that notifications are enabled, then tap Customize Notifications > Remind Me to check those are also enabled.\n", "Q: Why does my iPhone not show all the backup to restore? I forgot to backup a chat history of my messaging app before reinstalling it, so tried to restore my iPhone with a yesterday's backup, but after erasing all the data and going into restore option, I found that the most recent backup was from just a few minutes before (the one with all the messages are gone), and the next backup is the one on January 31rd. I want to restore it with the yesterday's backup, but for some reasons I cannot see it on the list of my backups, nor I cannot see any backup between now and January 31rd.\nThis makes all of my messages between today and January 31rd gone, so I would rather want to restore it with yesterday's (or even better, today's, though I think iPhone didn't backup today yet).\nHow can I get the yesterday's backup?\n\nA: You cannot restore a backup that does not appear on the list.\nApple does not publish the strategy they use to pick which backups are available, but the only guarantee is that the most recent one is available.\nAny previous backups that do appear should be considered complimentary, as they don't count towards your storage quota.\n", "Q: My iMessage usually goes through as SMS with one individual Using an iPhone 14 with iOS 16.3. iMessage with other iPhone owners usually has no issue. However, when I send a message to my wife, a large majority of the time it goes through as a green text bubble. This is regardless of if I’m on Wi-Fi or cellular. I don’t have issues with anyone else. Usually when I text her she is at home, where we have a fairly stable WiFi (T-Mobile home internet). I have tried turning off iMessage and turning it back on, and the same with her phone, iPhone 12.\nAre there any other troubleshooting steps I can take to resolve this issue?\n\nA: Your iPhone sends blue bubble messages to all iPhones except for your wife's iPhone. So the problem must be with her iPhone.\nOn her iPhone, have a look at Settings > Messages.\nIs iMessage enabled?  If not, enable it.\nFurther down you will see \"Send as SMS\" which is enabled (keep it so) and is used when iMessage is turned off or not contactable.\nIf iMessage is already enabled, then it may be that your wife's iPhone is frequently not connected to the Internet - such a connection would either be via a WiFi connection or your mobile provider.  In Settings > Mobile is Mobile Data enabled?\nIn your part of the world, \"mobile\" may well be \"cellular\".\n", "Q: How to parse values from macOS extended file attributes? If you download a file from the internet using Safari, some extended attributes are added to the downloaded file, among which com.apple.metadata:kMDItemWhereFroms which contains the original URL of the download. In Finder > Get Info the value of this key will be displayed under Where from:.\n/bin/ls -alh shows the presence of extended attributes with a @ in the mode column and xattr -l filename.zip will list all the attributes.\nAccording to the xattr's man page to print the value of an attribute one can use:\nxattr -p com.apple.metadata:kMDItemWhereFroms filename.zip\n\n# OUTPUT\n# com.apple.metadata:kMDItemWhereFroms: bplist00�_=https://example.com/filename.zip\n\nSo even if the content is visible, the value is in a binary format with a header of bplist00�_.\nI tried to parse it in the following way:\nxattr -p com.apple.metadata:kMDItemWhereFroms filename.zip > url.plist\n\n# checking the file format:\nfile url.plist\n\n# OUTPUT:\n# url.plist: Apple binary property list\n\n# assuming this should work:\nplutil -convert xml1 url.plist\n\n# OUTPUT:\n# url.plist: Property List error: Unexpected character b at line 1 / JSON error: \n# JSON text did not start with array or object and option to allow \n# fragments not set. around line 1, column 0.\n\nTrying to parse the file with python's ootb plistlib throws an error too:\nimport plistlib\n\nwith open('url.plist', 'rb') as fi:\n    plist = plistlib.load(fi)\n\n# OUTPUT:\n# plistlib.InvalidFileException: Invalid file\n\nFrom the output it looks like it is not a regular binary plist format even though file url.plist claims it is an 'Apple binary property list'. Any hints as to what the format is and how to parse it to a plain text value?\n\nA: You can print it in hex and then run it through xxd like so:\nxattr -x -p com.apple.metadata:kMDItemWhereFroms filename.zip | xxd -r -p | plutil -p - \n\nIf you want to have other output format you can change plutil to something like:\nplutil -convert json -o - -\n\nExample output:\n[\"https:\\/\\/another.example.com\",\"https:\\/\\/example.com\\/path\\/\"]\n\n\nA: Ended up using python as described at https://stackoverflow.com/a/33182025/191246\n# dependencies:\n# pip install xattr biplist\n\nimport biplist\nimport xattr\n\nattrs = xattr.xattr('filename.zip')\n\nprint(biplist.readPlistFromString(attrs.get('com.apple.metadata:kMDItemWhereFroms')))\n\n# OUTPUT:\n# ['https://example.com/..', 'https://another.example/..']\n\nWith python the result is a list that can be manipulated and iterated programmatically.\n\nA: Howard Oakley has created an editor for extended attributes, that may be useful for parsing the contents.\nhttps://eclecticlight.co/xattred-sandstrip-xattr-tools/\n", "Q: Facebook no longer posts a panoramic photo as a 360 photo In the past, I have posted panoramic photos on Facebook, and Facebook posted them as 360 photos.\nRecently I have been unable to get Facebook to post any panoramic photo as a 360 photo; instead Facebook will just post it as a really wide photo. I'm using the same camera (iPhone SE) as I did before when Facebook posted them as 360 photos.\nThis problem occurs with both the Facebook website and the Facebook app.\nHow can I get Facebook to post panoramic photos as 360 photos?\n\nA: So apparently some EXIF data in the photos is either missing or corrupted, which is odd, because the photos that I'm uploading to Facebook are direct from my phone - I never modified them.\nI found a utility called Exif Fixer that adds any missing EXIF data that Facebook requires. I ran it on one of my panoramic photos using the default settings, then uploaded the photo to Facebook, and Facebook finally recognized it was a panorama and posted it as a 360 photo.\n", "Q: Activity Monitor's Process Name connection to each software I have Activity Monitor open to check how much memory is being used, and the main part I usually check is the bottom where it mentions how many GBs have been used. However, with the ability to stop it, I would now like to know what each Process Name belongs to and how it would affect it if I stopped it.\n\nSome of them are easy to tell, such as one's with the Process Name being called \"Google Chrome\" which would have me come to the conclusion that if I stop it while I have it running, it will exit out of it. In other cases, however, it is very difficult to see what it is linked to and whether it would affect anything I have open at the moment. I have previously done one after some research: It was toward Core Sync for Adobe Creative Cloud, but without the research or Creative Cloud icon I would not have known what it would have affected.\nThis is what I mean when I say \"stop\": \nIs there a solution for how to find what each one of these Process Names is sourced with without having to do research for every one of them? Or, the overall question is how can I get enough information on each Process Name to find out things such as what software it is part of or what may happen if I hit \"stop\"?\n\nA: I am not entirely sure what you mean by \"I would now like to know what each Process Name is connected to\", but you can find out more about each process using Terminal and the ps command.\nFor example, the command ps -A will list ALL processes with 1) their PID (process ID) as in Activity Monitor, and b) the command which started the process (in most cases, each apps file location and name).\nSo now you know the location of the command which started each process. Seems like a good first interpretation of what it is \"connected to\".\nYou can reduce the output of ps -A by combining with grep. For example: ps -A | grep -i safari will list all the processes related to Safari.\nActivity Monitor is designed to keep things fairly simple; anything else will be more complex.\n\nA: \nI would now like to know what each Process Name belongs to and how it\nwould affect it if I stopped it.\n\nI have over 600 processes running currently. The vast majority are part of the OS, and should not be stopped.\nI would not recommend stopping any processes without good reason, e.g. stopped responding, or using a frightening amount of RAM or CPU. It's difficult to know what effects there will be from quitting processes that need to be running, but there can only be disadvantages.\nYour memory usage is still 'in the green', and nothing to worry about. macOS will try to use as MUCH memory as it can. I'd just let the OS get on with the memory management, and you can get on with your work.\nIf you're concerned about memory usage, you could always stop using Chrome entirely, for a more efficient browser. ;-)\n", "Q: Is there a way to detect licensed/unlicensed installations of Docker? Now that Docker is licensed in corporate environments, does anyone have a way of finding the licensed/unlicensed status of a Docker installation?\nWe have many Macs and some of our users have licenses to run Docker Desktop. Some do not, and we would like to detect these so we can either remove unlicensed machines, or get them licensed.\nI have not found any way of detecting whether a machine is running a licensed copy of Docker or not. Is this something that can be done?\n\nA: This FAQ suggests creating an Organization in Docker Hub. The impression I get from reading it is Docker lacks any licensing indicators, e.g. sudo find / -iname license 2>/dev/null | grep -i docker reveals nothing noteworthy.\nThe last two questions just before the Pricing and Billing section also hint at using Docker Hub to reveal the number of licenses used - sort of like a head count - or contacting sales to opt for IP-based access for larger teams.\nThe overarching theme is that Docker trusts its clients to purchase the correct number of licenses per user, which seems to be the official and only stance the company has put forth on its website.\n", "Q: How to switch keyboard to normal view in Chrome? Something happened and onscreen keyboard (in Google Chrome) on my iPad Pro 11\" was switched to small mode.\n\n\n\nIs's not clear what is happened and how to switch it back to normal view. In Safari it has normal view:\n\n\n\nI'm on iPadOS 16.3\nMy issue seems slightly different than in  iPad keyboard is now small, where floating keyboard can be moved to the bottom and expanded to normal view. In my case this doesn't work, and as you can see in my case there is small addition floating window with \"undo, top/up, mic, enter\" buttons, that not exist while regular floating keyboard is displayed.\n\nA: Disabling the  Scribble feature of the Apple pencil resolves the issue.  It's not ideal if you use that feature. Settings → Apple Pencil → Scribble\nRestarting Chrome resolves the issue; the full size keyboard appears again. But, using the Pencil, with Scribble enabled will cause the small keyboard and small tool bar to appear. Two finger gesture to expand the keyboard does not work. When the small keyboard appears the small toolbar appears as well.\n", "Q: Forced re-login to any Stack Exchange site on Safari after running Apple News I'm on an old Mac Pro with Safari. Both are now out of date [macOS 10.14 & Safari 14], but this has been happening for years, since both were still current - I've just patiently put up with it.\nI am not a frequent rebooter, so uptime can often be a month or more. The Mac never sleeps. If I do reboot, Safari auto-reopens in the same state as at quit. Logins & cookies are preserved. I just need to refresh to see each page's current state.\nI keep about 7 SE tabs open permanently - plus many others on questions I'm actively but temporarily involved with. I refresh periodically to see new questions etc.\nI can do this as many times as I like with no adverse effect… unless I've just quit Apple News. Then I get asked to log in again.\nIt doesn't happen if I refresh whilst News is still open, only after I quit it. It also doesn't seem to happen a second time if I launch News again soon after the last forced login. There seems to be a retention period before the time-out. I've been unable to hone this down to an actual time, it may be hours rather than minutes.\nAs I tend to browse News morning and evening, I generally get logged out twice a day.\nAdditional tests\nIf I quit News then refresh immediately, I get the forced login.\nIf I quit News and wait several minutes, it isn't triggered.\nBrowser plugins have been eliminated as a potential issue.\nCookies are established & hold at all other times.\nNews seems to add a lot of com.Apple.WebKit processes. Safari also uses WebKit. This is about the only connection I can see, I'm not a coder or web dev, so my knowledge is extremely limited in this area.\nThis issue does not happen with non-WebKit browsers & I cannot reproduce it on any other Mac. Tested back to El Capitan on one Mac & up to Monterey on another. I don't have a sock-puppet or other means of testing another account on this same Mac.\nI first asked this on Meta, wondering if it was some site-specific context server-side. This received little love, so having now found a solution, I'm moving it here just in case this ever affects anyone else.\n\nA: I finally managed to fix this by rather brutally deleting everything I could find in Prefs related to News. I made no alterations to Safari data.\nI cleared cache, history, advertising ID & all saved data from within the app [News menu > Clear History, followed by all options one at a time], then everything in ~/Library starting with com.apple.news* from an EasyFind search.\nI'm uncertain as to exactly which of those actually fixed it, but I haven't had to relog in the two days since I cleared it all.\n", "Q: Force Quit Applications appears when memory is not full I have a Macbook 14\" ( M1 Pro ) with 16GB of RAM.\nHowever, the Force Quit Applications window pops up when I surpass the ~10GB of RAM utilization.\nEven if I close some applications, this window keeps popping up after a short while. The system becomes unusable until I restart it. This mostly happens after 16-20h of uptime.\nAttached is the picture of htop output and the popup. I did not close any applications; I just waited for the popup to appear.\n\n\nA: I figured out that what was full was the virtual memory address space. The Grammarly application was occupying 13GB on average in the span of 16h of uptime.\nI followed the advice from this post and found the responsible for it. Both methods worked and confirmed Grammarly app was the culprit:\n\n*\n\n*Method A. Look at Applications -> Utilties -> Activity Monitor -> View (menu) -> All Processes -> Memory (tab), you can see what processes are using lots of memory.\n\n\n*Method B. Applications -> Utilities -> Terminal: ps ax -o vsz,pid,comm | sort -n, which will display the virtual memory used sorted, so the largest virtual memory-consuming users are at the end.  The virtual memory sizes are in 1024-byte units.\nBoth methods come from BobHarris answer to the apple discussions.\n", "Q: Firefox fails to launch on 2014 computer running Big Sur I reinstalled my Mac computer from 2014 with Big Sur. I installed Firefox with\nbrew install --cask Firefox\n\nand it worked for a few days, then it stopped working. I reinstall with:\nbrew remove --cask Firefox\nbrew install --cask Firefox\n\nWhen I launch it, the OS does not even ask for a verification such as \"This program was downloaded from the internet, are you sure you want to open it?\". Instead, I get this message in the Terminal:\n$ open -a Firefox\nThe application /Applications/Firefox.app cannot be opened for an unexpected reason, error=Error Domain=NSOSStatusErrorDomain Code=-10673 \"(null)\" UserInfo={_LSLine=3878, _LSFunction=_LSOpenStuffCallLocal}\n\nIs Firefox still compatible with my environment?\nupdate\nToday I restarted the computer and Firefox works. Now it's Opera that is not working:\n$ open -a Opera\nThe application /Applications/Opera.app cannot be opened for an unexpected reason, error=Error Domain=NSOSStatusErrorDomain Code=-10673 \"(null)\" UserInfo={_LSLine=3878, _LSFunction=_LSOpenStuffCallLocal}\n\nSo the problem is not from the browser, but from my system. And yet, the reason I am reinstalling the browsers is because I did a fresh new install of Big Sur, during which I wiped out the hard drive with Disk Utility.\n\nA: I would recommend doing it the old fashioned way  ;-)\nGo to firefox.com and download the latest version. Once downloaded open the dmg file and drag it to /Applications.\nIf you need to launch it via a shell you can point your command to the firefox executable inside the firefox app package.\n", "Q: Need Terminal command to ping every second, pause and then repeat I want to find a Terminal command that will provide a timestamped ping every second for a period of time (say 5 minutes) and then pause for another period of time (say 30 minutes) and then repeat that process until I stop it. I will need to let it run for days.\nIn other words, what I want is sort of a combination of the following 2:\n1) ping 8.8.8.8 | while read line; do echo `date` - $line; done\n2) ping 8.8.8.8 | while read line; do echo `date` - $line; sleep 1800; done\n\n(1) provides a ping listing every second with a timestamp, while (2) does the same thing but every 30 minutes instead of every second. I can use (1) but it generates way more data than I need. (2) provides the pauses I need but cannot catch the events I'm looking for (which last about 4 seconds, see below).\nAlthough not needed to answer my question, the reason I want this is to deal with an intermittent internet connectivity problem. By using (1) above I have found that most of the time my internet connection is fine, but every couple of days or so there will be periods (lasting hours) during which I get unusually high pings for about 4 seconds, and this repeats every 15 seconds or so. But using (1) to figure that out meant a lot of unnecessary data collection. Also, I have a separate script which will plot the data and there are just way too many data points to plot conveniently since I need to collect for days.\nI'm running OS 13.2 on a MacAir M1\n\nA: while :; do\n    ping --apple-time -c $((5*60)) 8.8.8.8\n    sleep $((30*60))\n    echo # if required to separate the blocks\ndone\n\n--apple-time obviously is an Apple addition which is quite useful for what you need here, the output would look like\n15:50:24.467213 64 bytes from 8.8.8.8: icmp_seq=0 ttl=114 time=2.991 ms\n15:50:25.471150 64 bytes from 8.8.8.8: icmp_seq=1 ttl=114 time=1.805 ms\n15:50:26.476259 64 bytes from 8.8.8.8: icmp_seq=2 ttl=114 time=1.822 ms\n15:50:27.480521 64 bytes from 8.8.8.8: icmp_seq=3 ttl=114 time=1.832 ms\n15:50:28.485576 64 bytes from 8.8.8.8: icmp_seq=4 ttl=114 time=1.785 ms\n\nIf you just want the timestamp and the ping time, you can use sed to filter out the noise:\n$ ping --apple-time -c $((5*60)) 8.8.8.8 | sed -n -E 's/(.*) 64 bytes.*time=(.*) ms/\\1 \\2/p'\n19:11:49.447810 2.928\n19:11:50.450692 1.836\n19:11:51.455125 1.829\n\n\nTo accomplish the same without relying on Apple-specific options, you can also just take your second command and put the sleep outside of the while read line loop:\nwhile :; do\n    ping -c $((5*60)) 8.8.8.8 | while read line; do echo $(date): \"$line\"; done\n    sleep $((30*60))\n    echo # if required to separate the blocks\ndone\n\nor, again without the noise\nwhile :; do\n    ping -c $((5*60)) 8.8.8.8 | while read line; do \n        echo $(date): $(sed -n -E 's/.*time=(.*) ms/\\1/p' <<<$line)\n    done\n    sleep $((30*60))\n    echo # if required to separate the blocks\ndone\n\n", "Q: Prevent iOS from adding a space/newline to pasted text On my iPhone running iOS 16.1.2, pasting text with the cursor set at the end of a word or on an empty line adds a space and newline, respectively. This is annoying. How do I turn it off?\n\nA: \niOS 16.1.2, pasting text with the cursor set at the end of a word or on an empty line adds a space and newline, respectively.\n\nThe default behavior is that a space is provisionally appended to the end of the text.  If you type another space, it will change it to a period.\nIf you are getting a newline, this means that a newline character was copied.\n", "Q: How can I set Python symlink in MacOS Ventura? I am trying to set a symlink so that I can point the python command in Terminal to a new install of python3.\nI last did this in Mojave, where one could disable csrutil and then run the following command before re-enabling:\nsudo ln -s /usr/bin/python3 /usr/bin/python\nNow I am trying to do the same in MacOS Ventura 13.1, and I am met with the error feedback:\nln: /usr/bin/python: Read-only file system\nWhat is this new roadblock that \"MacOSimandius, destroyer of worlds\" throws in my path?\nAnd more importantly (please): How do I set my symlink? It must still be possible. This is still unix, is it not?\n\nA: You can't modify /usr/bin any longer (at least not without disabling SSV). What you can do instead is\nsudo mkdir -p /usr/local/bin\nsudo ln -s /usr/bin/python3 /usr/local/bin/python\n\nand then make sure that /usr/local/bin is in PATH.\n", "Q: Video connection for Mac Mini M2 to DisplayPort/DVI monitor I'm planning to order an M2 Mini and I want to connect it to a Dell U2412M monitor that I already have.\nThe Mini has HDMI video output, but I believe it can also serve video via Thunderbolt 4.\nThe monitor has DisplayPort and DVI inputs.\nWhat would be a good way to connect these two devices?\nThe monitor does not have speakers, so I don't care about running audio.\nMy only other Mac experience is with a 2013 MacBook Pro, so my hardware/port knowledge is not exactly up to date.\n\nA: I would connect the DisplayPort output on your Mac to the DisplayPort input on your monitor. I see no reason to convert to or from HDMI, DVI, Thunderbolt 3 or Thunderbolt 4. The USB-C ports on your Mac can supply DisplayPort output directly from the Mac's graphics hardware.\nFor example, you could use this cable.\nIn your case, you should be looking for cable specifications which equal or exceed the the following.\n\n*\n\n*Connector A: USB Type C Male\n\n*Connector B: DisplayPort Male\n\n*Apple ALT-MODE Compliant\n\n*DisplayPort v1.1a resolution up to 1920x1200@60HZ\n\n\nNote: Apple refers to \"USB-C Alt-mode\" as \"native DisplayPort output over USB‑C\",\n\nReferences\n\n*\n\n*Connect a display to Mac mini\n\n*DellTM UltraSharp U2412M/U2412MWh Monitor\n\n*Apple Mac mini Specs\n", "Q: How do I troubleshoot why my MacBook Pro lost internet access even when connected to WiFi? I've noticed over the last few months that every few days, my M1 Pro MacBook Pro loses internet access even when successfully connected to a WiFi network. For example, earlier today I couldn't access the internet on my browser. I went to my WiFI settings and saw the following:\n\nIn iStat Menus, however, it seems like there is some minimal WiFi network usage (however, I can't confirm if this is internet usage):\n\nWhen I try the ping command in the Terminal, it seems to error out:\n\nThe only way to get connected to the internet again is by rebooting my MacBook, which is often a hassle.\nNote that although I've connected to a network used by many people, this also happens with my personal router.\nIs there any good way to troubleshoot exactly why my MacBook Pro regularly and seemingly randomly loses connection to the internet so that I can find the root cause of the issue? I don't think macOS has an \"internet troubleshooter\" like Windows does.\n\nA: The router, the network service provider, and the Mac are typically the main culprits in most cases. Take a look at this guide. It listed some possible causes and fixes for Mac connected to WiFi but no internet.\n", "Q: How to create a bootable Windows 11 installation USB drive (for a PC) on macOS and avoid the error \"media driver on your computer is missing\"? I bought a PC without OS and I want to install Windows 11 on it. But I only have a Mac and a flash drive at hand. Neither my Mac nor the PC have a DVD drive.\nI cannot use Microsoft's official Media Creation Tool\n(mediacreationtool.exe) for copying the Windows 11 image to the USB drive -- there's no Mac version available.\nI tried to Restore the ISO to the USB drive in Disk Utility, but it resulted in the error message \"Restore process has failed\".\nI tried to Create a Windows 10 or later install disk in Boot Camp Assistant, but after booting on USB, the Windows installer could not open the partition and reported \"A media driver on your computer is missing\". Disconnecting and reconnecting the USB drive did not help.\nI tried with balenaEtcher but I got the same result.\nHow can I copy the Win11 ISO file to the USB drive so that the installation works flawlessly on the PC?\nNote: I'm using macOS Big Sur on an Intel Mac.\n\nA: Jensd's guide did the trick for me (Thanks!)\nTLDR:\n\n*\n\n*In Disk Utility, Erase the USB drive with Format: MS-DOS (FAT) and Scheme: Master Boot Record.\n\n*Mount the Win11 ISO and copy all files except source/install.wim (too big for FAT32)\n\n*Install Wimlib: brew install wimlib\n\n*Copy the remaining file while splitting it in FAT32-compatible chunks: wimlib-imagex split /Volumes/CCCOMA_X64FRE_EN-US_DV9/sources/install.wim /Volumes/WINUSB/sources/install.swm 4000\n", "Q: How to Reset the PMU on a PowerBook G4 15\" A1095 5, 4 laptop? I have been refurbishing 3 PowerBook G4 15\" A1095s and 1 PowerBook G4 15\" A1106 and need help with battery issues.  All of them have been able to charge a battery.  I have attempted to and rebuilt 1 A1078 battery with excellent results and have failed on another.   I have learned how to reset the Pram but do not know how to reset the PMU or if that will even make a difference.   Also I am wondering if removing the Pram battery has an effect on the charging system as I have one time experienced the single flashing green light on an A1078 battery and managed to get it to charge by  putting it in a G4 A1095 that I had just reassembled and had previously removed the pram battery.  I need to know this because the A1078 battery rebuild I failed on will not charge on 2 machines that will charge other batteries.  I have an A1148 battery that I rebuilt that has never charged beyond 88% and now has dropped to 66%.  I assume that I either used some bad cells or damaged the controller within the battery.  Any useful information will help.\n\nA: The PMU reset key sequence for this model differed to earlier ones.\nThere are two ways to reset the Power Management Unit on this model (1) using a key sequence and (2) using the PMU Reset pads.\nKey Sequence\nUse the following procedure:\n\n*\n\n*If the PowerBook is on, turn it off.\n\n\n*Disconnect the power adapter\n\n\n*Remove the main battery.\n\n\n*Hold the power button down for ﬁve seconds, then release.\n\n\n*Install the main battery and connect the power adapter.\n\n\n*Press the power button to restart the PowerBook.\nPMU RESET pads on logic board\nThis model has pads for PMU RESET, which work when their pads are shorted together (with a tool like a ﬂat blade screwdriver). The pads are separated with a white horizontal line between the pads.\nThe pads are located near the edge of the logic board, just above center of the hard drive.\nSee photo below:\n\nSource: PowerBook G4 (15-inch 1.67/1.5GHz)  Service Source © 2005 Apple Computer, Inc. All rights reserved.\n", "Q: How to set up Varnish locally on a Mac OS with MAMP Pro? I'm trying to make Varnish work on my local Mac with MAMP Pro (running a Drupal website). I have installed Varnish with Homebrew\nbrew install varnish\n\nSo far so good. Then I start Varnish with the following command :\nsudo varnishd -a 127.0.0.1:8080 -T 127.0.0.1:6082 -f /usr/local/etc/varnish/drupal.vcl -s file,/tmp,500M\n\nThe varnish child start and I start to monitor with :\nvarnishstat\n\nMAMP Pro is set to port 80 which is the conf I have in my .vcl file. The problem is Varnish does not cache the page when I go to my http://drupal.local website (All the caching conf from Drupal is properly set up as it works on a centOS server).\nAny idea about what I'm missing ?\n\nA: Here is the solution and what I was missing. My vhost was in HTTPS and working with Varnish it's easier to work with HTTP.\nHere is all the step that might help someone :\nMake sure that Apache in MAMP Pro is running on port 80.\nIn the VCL file make sure that Varnish targets port 80. Mine was looking like that :\nbackend default {\n  .host = \"127.0.0.1\";\n  .port = \"80\";\n}\n\nThen I start varnish with the following command (varnish running on port 8080) :\nsudo varnishd -a :8080 -T localhost:6082 -f /usr/local/etc/varnish/drupal.vcl -s file,/tmp,500M\n\nWhen I visit http://my-vhost.local:8080/node/1 varnish is properly caching the page. If I go to http://my-vhost.local/node/1, I see the page without varnish.\nTo clear the varnish cache of the page I just do this command :\ncurl 'http://my-vhost.local:8080/node/1' -X PURGE\n\n", "Q: How to add up multiple values per row in Numbers using SUMIF? \nI would like to use a formula to add the values from columns B,C and D for all rows where checkbox A is set.\nIn this example, this would be 1+5+9+3+7+11 = 36.\nUnfortunately, my attempts like\nSUMIF(A;TRUE();SUM(Value 1;Value 2;Value 3))\n\nhave failed. What would the formula have to be?\n\nA: Assuming it also has an extra closing parenthesis at the end, your formula fails because SUMIF() requires its test values to have the same number of sequential cells with the values to be summed.\nI can think of more than one way of implementing what you are trying to accomplish with one being the addition of a column calculating the subtotal of a row  when the checkbox for that row is TRUE. Below is the screenshot of an example with this solution.\n\nThe other could be to add a column again but for the unconditional subtotal of each row and then sum those subtotals using a SUMIF() whose test values would be coming from the column with the checkboxes.\n\nUPDATE\nAs the poster suggested in a comment to this answer and assuming there are not too many columns in the actual spreadsheet to utilize it, another solution would involve the following formula:\nSUM(SUMIF(A;TRUE();Value 1);SUMIF(A;TRUE();Value 2);SUMIF(A;TRUE();Value 3))\n\nThis formula would find the sum of the cells per column with TRUE in the checkbox cells in the same rows with them and then take the sum of all the column-based sums.\n", "Q: AWS Environment Variables - IDE I use the IntelliJ IDE for my daily tasks. I set up my AWS environment variables, by executing a script. If I wish to use a plugin built into the IDE to query AWS K8S it will fail as it expects the AWS environment variables to be set OS-wide.\nThe AWS environment-specific variables are only set in the context of the terminal running in the IDE. If I do env in a separate terminal, the environment variables for AWS differ and match the default values I set via apple-script example do shell script \"launchctl setenv AWS_ACCESS_KEY_ID 12345\".\nWhat is the best approach here to set the AWS environment variables at the OS level, which then can be read by the built-in plugin as well as the IDE CLI session?\n\nA: Including the following statements provided a solution I could use with MacOS Ventura and IntelliJ.\nUnset global AWS environment variables\nlaunchctl unsetenv AWS_DEFAULT_REGION\nlaunchctl unsetenv AWS_ACCESS_KEY_ID\nlaunchctl unsetenv AWS_SECRET_ACCESS_KEY\nlaunchctl unsetenv AWS_SESSION_TOKEN\n\nSet global AWS environment variables\nlaunchctl setenv AWS_DEFAULT_REGION $REGION\nlaunchctl setenv AWS_ACCESS_KEY_ID $AWS_ACCESS_KEY_ID\nlaunchctl setenv AWS_SECRET_ACCESS_KEY $AWS_SECRET_ACCESS_KEY\nlaunchctl setenv AWS_SESSION_TOKEN $AWS_SESSION_TOKEN\n\n", "Q: Unable to recover contacts from Mojave to Big Sur I upgraded from Mojave to Big Sur and forgot to export contacts. I have a backup of the files in ~/Library/Application Support/AddressBook, which I tried to recover with the three methods mentioned in How to restore the AddressBook database from backup\nFirst, I quit all applications (except Terminal and Firefox), deleted the .abcddb file and copied it from the backup\n$ rm ~/Library/Application\\ Support/AddressBook/*.abcddb \n$ cp /path/to/backup/AddressBook/AddressBook-v22.abcddb ~/Library/Application\\ Support/AddressBook \n\nContacts showed no cards, so the first line worked (otherwise, it would show the Apple card and my own card):\n\nThen, I copied the Metadata directory, which supposedly contains all the information in case the .abbcddb file goes corrupt:\n$ rm ~/Library/Application\\ Support/AddressBook/*.abcddb                                                  \n$ rm -r -f ~/Library/Application\\ Support/AddressBook/Metadata/\n$ cp -r /path/to/backup/AddressBook/Metadata ~/Library/Application\\ Support/AddressBook \n\nAgain, Contacts shows no contact information, just like above.\nThird, I change the extension of the AddressBook directory in the backup to .abbu and double-click on it, which has an effect:\n\nI click \"Replace all\". This does something because the ~/Library/Application Support/AddressBook/Metadata shows all 1,122 items and they are indexed by Spotlight. But, like before, the application itself shows no contacts.\nI also have a Time Machine backup of Mojave, but because it was not set up with this computer, I cannot use it to recover contacts as in this blog post.\nHow can I recover contacts from my backup?\n\nA: Although neither method seemed not to work, after a few days and several restarts, Contacts is now showing all the cards and the groups. Since the third method with the .abbu package was the only one that I didn't reset, I believe it will work.\nFor the future, I will avoid this issue by exporting the contacts as an archive before reinstallation.\n", "Q: iPhone calls keep dropping when switching on Mac Answering phone calls on iPhone 13 (iOS 16) and then switching on Mac, causes call to drop.\nWhat happens is that Mac's (Ventura 13.2) FaceTime opens the entire window, not just the small call window, and go fully dark.\nAnswering on Mac and then switching to iPhone works fine, but not the other way.\n\nA: On iPhone, in Settings -> Cellular -> \"Voice & Data\" -> enable VoLTE.\nI think enabling, VoWi-Fi (if that's an option), should also do it.\n", "Q: Odd ding sound when I'm typing sometimes? In the past couple of weeks, I've noticed that while typing I will get a \"ding\" sound as if I am being notified of something. It will be a single ding. I'm not sure what's doing it, but it only happens when I type; I'm unable to reproduce it at will.\nIt is not any of the sounds in the Sounds effect tab of System Preferences.\nI'm on iMac M1 running Monterey 12.5.1 and use an external keyboard.\nIs there a way that I can find or track down what is causing this \"ding?\"\nHere is the audio of the ding.\nAnd here's a screenshot of Activity Monitor, ordered by CPU, at approximately the time of the ding:\n\n\nA: I figured it out. It was coming from a piece of software called Typinator that I use. It turns out that it has sound options not just globally but for each set of typing corrections that it offers. I had to turn all the sounds off and I think it's problem solved.\n", "Q: Make a keyboard shortcut for adding specific text? I am using a Late 2014 iMac running Big Sur.  I would like to be able to make a keyboard shortcut to automatically enter a specific text screen into the current window.  I did a Google search on how to do that (I had been thinking it would be an Automator workflow or something like that) and found this guide: https://medium.com/macoclock/using-automator-to-insert-text-with-a-shortcut-key-on-mac-a-step-by-step-guide-b0c30fa2c7c2\nI followed the instructions in the guide, but instead of entering the text, it entered a blank line.  What am I doing wrong?\n\nA: Turns out I was able to get it to work.  Here's the working code:\non run {input, parameters}\n\ntell application \"System Events\" to keystroke \"Test test test\"\n\nreturn input\nend run\n\n", "Q: Is the Blood Oxygen app required on the Apple Watch to get VO2 max cardio fitness levels in the Health App? Deciding whether to remove the Blood Oxygen app on the Apple Watch.\nWould it be okay to remove it without losing the VO2 max estimate?\n\nA: VO2 Max, or \"Cardio Fitness,\" does not require the Blood Oxygen sensor or app.\nEvidence for this can be found in the support document that notes all watches Series 3 and later support VO2 max. The Blood Oxygen sensor & app require Series 6 and later.\n\nApple Watch Series 3 or later can record an estimate of your VO2 max using the heart and motion sensors during an outdoor walk, run, or hike. It can also estimate your VO2 max if you start an outdoor walk, run, or hike in the Workout app. Apple Watch supports a VO2 max range of 14-65 mL/kg/min that is validated for users 20 years or older.\n\nSource: Track your cardio fitness levels\n\nUpdate your Apple Watch Series 6, or Series 7, Series 8, or Ultra to the latest version of watchOS.*\n\nSource: How to use the Blood Oxygen app on Apple Watch\n", "Q: Are all the default applications duplicated? I noticed that all of the default applications (Finder, Preview, etc.) each appear in /Applications, but also again in /System/Applications. Given that these applications are combined just under one GB, duplicating them all seems a massive waste of space. Neither version has an alias symbol indicating a symbolic link, but in each version (the /Applications and /System/Applications) have Last Opened dates in sync. Are the applications really duplicated in memory, or are they somehow referencing the same locations on disk from different filenames without any evidence of a symbolic link? I have heard that directories (which the applications themselves are) cannot be hardlinked so what could be going on here?\n\nA: Those applications are not duplicated - nor are they symbolic links, hard links or firm links.\nInstead what happens is that you're using Finder to view the folder - and Finder chooses to show you a mix of apps found in /Applications and /System/Applications.\nFor example, open Finder and navigate to /Applications, then try right-clicking Photos.app and select Get Info. You'll see under Where that Photos.app is really located in /System/Applications.\nIt is thus entirely a feature of Finder that these apps are shown together. It is not how the files are organized in the file system - so if you use other programs to list the folders (that do not implement the same special case logic as Finder), then you wouldn't find them to be duplicated.\n", "Q: MacBook Air M1, I have a login screen but no account is showing although I have one I can’t login to my Mac. It gives me the login screen but doesn’t accept my email and password. Also, it’s not using my account nor logging in automatically with my Apple Watch. What can I do? It looks like my account was deleted. Command S Command V don’t work at all for some reason.\nHow can I log in to my Mac?\n\nA: If you forget your username, you can try your full name, first and last.  Also try with the middle initial or  middle name fully spelled out, if applicable.\nThis is what worked for me.\n", "Q: What would cause a bootable USB for Yosemite created in Windows to shut the laptop off less than 30 seconds into booting? I've followed this guide and everything looks to be correct. I'm using this to restore an old Macbook Pro Unibody (2008) that was using Yosemite previously. When I go to restore the laptop, I get the option to install off the flashdrive and it starts up but after maybe 20-30 seconds the laptop shuts off. All diagnostics for the drive appear to be good. Any thoughts? What am I missing?\nNOTE: I can get into Recovery Mode with no issues.  I've run diagnostics on the drive and there are no errors.  I've also tried to restore from the internet (it connects, appears to download everything then goes right back into Recovery Mode). I also erased the hard drive using the Disk Utility.\nThis is the guide I followed:\nHow can I use Windows to create an OS X Yosemite USB flash drive installer from the disk image (.dmg) file downloaded from Apple?\n\nA: First, there was no PowerBook in 2008, the last one was produced in 2005 and being that it used the PowerPC processor [PPC) it can’t possibly run Yosemite.  For the 2008 model year, you could have either the MacBook [White or Black Unibody) or the MacBook Pro (not unibody). The highest version of OS X for that vintage was 10.7.5 (Lion) and 10.11 (El Capitan) respectively.\nIf was a PowerBook or the White/Black unibody, it couldn’t run Yosemite; but the MacBook Pro could.\nNow, if you are booting an OS and it shuts off mid-boot in the manner you describe, you have a hardware issue.  If the OS installation failed, you’d get an error or it would hang.  Since it’s powering off, it’s definitely pointing to hardware.\nWhat could it be?\nFrom past experience with these models, it could likely be the CPU or GPU.  You can try booting into Diagnostics.  However, this vintage of MacBook could actually boot the Ultimate Boot CD.  Since it boots up in a text environment, it doesn’t tax the GPU from the outset and you can run the diagnostics on the CD to help narrow down the problem.\nHowever, since it’s 15+ years old now, it’s likely to be a lost cause and you will probably get more value for it as parts on eBay.\n", "Q: How can I prevent Safari (and other apps) from quitting? Often times I will try to quit (for example) Slack, but accidentally quit Safari, and thus lose the arrangement of my millions  of Safari windows.  (This can happen if Safari is the top-most app, but without any visible windows.  If I don't look in the upper left-hand corner and actually read the app name, it may appear that Slack is selected because its window is visible on top.)\nSince Apple only sees fit to restore windows to the proper desktop when you start up your Mac with windows being automatically opened, and otherwise opens them all in the same desktop (which is a horrible UX oversight!), I really really really want to avoid accidentally quitting Safari (or any other browser).  How can I easily prevent this from happening?\nManually customizing the keystrokes is a last resort, being kind of kludgey.\n\nA: You should be able to Change Safari's (or other applications') keyboard shortcut for quitting, as suggested here:\nWarn before quitting in Safari\n", "Q: where is Apple's reference documentation In general, where would one find comprehensive documentation for Apple's software that comes with MacOS? The help menu option is almost always useless.  This stuff has to be documented somewhere.  Where is it?\nBelow a couple of examples.  Please, while I would love to know the answers to the questions posed in the examples, let's not get distracted with them. My question is IN GENERAL where would I find this kind of info.\n\nHow can I find out exactly what Spin Reports in the Console.app are?  Does anyone find this explanation to provide insight into what functionality Spin Reports UI feature offers?  To me, absolutely not.\n\nIn airport utility, how do I find out what exactly Router Mode pulldown menu controls?  The unhelpful help is organized as tutorials to achieve specific tasks using the software. Where can I find what the acronyms stand for?  How do their meanings relate to the function of the router controlled by the UI feature?\n\nA: There's no such place that gathers comprehensive documentation for all of Apple's software for each searching.\nIn general, when Apple's help menu is lacking, it can be a good idea to simply use Google or DuckDuckGo and limit the search to apple.com, in order to find documentation from Apple.\nIn terms of your specific questions, you can find more information about spin reports by opening up Terminal.app on your Mac and run the command: man spindump. It is a developer-oriented feature, and they're generally documented on Apple's developer site.\nRegarding AirPort Utility and the \"Router Mode\" setting - those are generic networking terms that applies to all sorts of computers and networks - not just Apple. You can read up on those in basic network literature, by searching for information on Google or on Youtube for example.\n", "Q: Moving photos to another iCloud account and device, with full resolution, edit history, everything I need to move photos from one iCloud account (my work account, on my work iPhone) to another one (my private account on my private iPhone). I used the work phone for a while to take photos, but now I finally upgraded my private phone and I want to separate affairs again.\nNaturally, I tried a shared album and copied the photos from there into the camera roll of the target phone. But I realized that they arrived in reduced resolution (3 MP instead of 12 MP) and that all edit history was gone (i.e. I'm not able to go to the unedited state on my other phone).\nThen I found the option to share the photo with all meta-data and edits. I activated that, did the shared album thing again, but the photos were still reduced in size, and there was no edit history. (Maybe the geo location was there, don't remember.)\nThen I tried sending a single photo via Airdrop, with that option activated. This time, I got geo-location and the full resolution, but still no edit history. [That's actually wrong! See answer below.]\nI also tried exporting the raw unedited photos from the Photo app on the Macbook connected with my iCloud, but obviously this loses the edit history again, so I didn't even bother to import them to my private account.\nSo, the question is: How can I move photos (and videos) from one iCloud account to another, or simply from one device to another, and retain...\n\n*\n\n*the full resolution,\n\n*geo location,\n\n*the little \"heart\"\n\n*and the full edit history?\n\nIs that even possible? Any help appreciated!\nI do have a Macbook connected to the source account, if that helps, and that Macbook as well as the two phones are on the latest OS versions. I also have a Macbook connected to the target account, but on an older MacOS.\nSide note: That half-working sharing with full details option is not even available on the Macbook.\n\nA: I meanwhile found out that I was wrong regarding missing edits when sending the photos via Airdrop.\nDecided to keep the post, in case somebody else needs this.\nSo, at the time of writing, what actually works is to send photos via Airdrop, with that somewhat hidden \"keep everything\" option enabled. To me it looks like this option is only available on iOS, but not on the Mac Photo app.\n\nA: The best option would be:\n\n*\n\n*With the origin account, set up your Photo Library on macOS to download originals\n\n*Transfer the Photo Library to another macOS user/device running the destination iCloud account and open it in Photos. Set it as the System Photo Library and enable iCloud.\n\n*iCloud will merge the photos with any existing ones in the destination account.\n\n", "Q: Apple M2 to use performance cores when plugged in I have noticed that whenever plugged in my M2 Air macbook will still use efficiency cores predominantly, which are clocked lower.\nI'd like it to actually use performance cores first if i'm plugged in which is usually when im doing work.\nIt is plugged in with 100W (older 2019 16\" macs power adapter), so it definitely has more than enough power to draw from.\nIt also definittely has no issues with heat. Temperatures are nearly always at 60C (i have done some minor modifications with thermal pads to this mac air and i never saw it overheat in my daily use).\nAlso in battery section i have Low Power Mode = Never.\nIn short i'm sure its not lack of power and its not the temperature, it seems to be programmed to do this.\nIs there any way to influence this?\n\nA: I don't think users have a great deal of influence over what cores are used when. Priorities can be set by app writers, but Apple have done an awful lot of work to streamline the dispatching process around the key goals of energy efficiency, and ensuring that threads get just the right amount of power they need.\nA lot of workload is still classed as low priority, which means it gets relegated to efficiency cores, and of course high priority workload may still be affected by other factors, such as being IO-bound.\nHoward Oakley has done an extremely thorough job of analysing how this all works, and shows how efficiency cores probably do more work that you realise.\nhttps://eclecticlight.co/2022/10/03/making-the-most-of-apple-silicon-power-1-m-series-chips-are-different/\nThere is some information on policies and how the user can have some control over QoS, which may be what you are looking for. But you cannot promote workloads from efficiency to performance QoS (of which there are multiple tiers), only demote them (and re-promote if applicable). Their QoS is set by the application code when a task is created, whether it be pThread, Dispatch queue, async / await.\nhttps://eclecticlight.co/2022/10/20/making-the-most-of-apple-silicon-power-5-user-control/\nSee also this earlier discussion How does macOS decide when to use M1's performance vs. efficiency cores?\n\nA: I understand from your comments that it is in particular Intellij IDEA that you want to use the performance cores, and not only the efficiency cores.\nYou can suggest to the system that you want a running programming to use performance cores by running a command in the Terminal like this:\ntaskpolicy -B -p <PID>\n\nwhere  is the process ID of that program. You can look that up in Activity Monitor or using the ps command.\nNote that this is not a guarantee that performance cores will be used, as there are cases where that is not possible. I.e. if you have more threads runnable that are eligible for performance cores than you have physical cores, the overall throughput of the system would be higher by running some of them on efficiency cores rather than not running them at all.\nYou can inspect what the current requested and effective QoS policies are for a running program, by running this command in the terminal:\nsudo taskinfo <PID>\n\nagain substitute  with the process ID of the process, you want to examine.\nYou'll see there in particular whether or not the process is currently scheduled with \"background priority\" (which typically means it will run on efficiency cores) - and you can see the QoS clamp (think of this as the maximum quality of service, you have requested to be provided to this running program).\nIn addition to the \"background priority\" that we can manipulate with the taskpolicy command above, we can also set other QoS policies. Such as for example setting a new requested throughput tier:\ntaskpolicy -t 5 -p <PID>\n\nthis will request a process to be set up for throughput tier 5 (tiers 0-5 are available, 3 is the default).\nSimilarly you can use:\ntaskpolicy -l 5 -p <PID>\n\nto set the latency tier (tiers 0-5 are available, 3 is the default).\nFor an easier \"systemwide\" overview, you might consider running the powermetrics program. Use the --show-process-qos-tiers parameter to show QoS tiers - for example a command line like this:\nsudo powermetrics --show-process-qos --show-process-qos-tiers --show-cpu-qos --samplers tasks -n 10 | less\n\n", "Q: Ensure data of an iMac is gone and unrecoverable I have a Late-2015 Apple iMac with 1 TB HDD.\nSince it's not being used, was thinking of selling it.\nDid some reading online and seems that there are many ways the data can be recovered.\nHow can we ensure the data is completely gone and unrecoverable? So that the new owner cannot access.\n\nA: Disk Utility has a secure erase function.\n\n*\n\n*Open Disk Utility\n\n*Select the disk that you wish to erase\n\n*Select the Erase tab\n\n*Click on the Security Options... button\n\n*Move the slider to Most Secure\n\n*Click the OK button\n\nThis screen shot is for Disk Utility, version 13 (517), that comes with Mavericks (OS X 10.9.5), later versions may vary in appearance:\n\nThis will securely erase the disk. As you have selected the most secure option, this may take a while.\nThis option states:\n\nThis option meets the US Department of Defense (DOD) 5220-22M standard for securely erasing magnetic media. It erases the information used to access your files and writes over the data 7 times.\n\n", "Q: How can I see what IP address my iPhone, iPod touch, or iPad has? I would like to know what IP-address my iPhone, iPod touch, or iPad has. E.g. if I use my iPhone, iPod touch or iPad over WiFi, how can I get the local IP-address that is assigned to my iPhone, iPod touch, or iPad?\n\nA: The IP address is shown in Settings -> WiFi -> Info icon at end of (Name of network):\n\n\nA: There are two potential solutions to getting your IP: a Shortcut and An App.\nShortcut\nI created a simple shortcut called Get IP Addresses.  It was tested on iPad running iPadOS 16 and iPhone 12 running 16.1.2. It will output both your Local and External IP addresses.\n\nSystem Status App\nThere is a simple App (free) called System Status.\nIt gives a full view of your hardware from battery to CPU and of course, network.  What I like is that all the info is right there on the main screen including private (internal) IP, external IP, gateway, DNS and SSID.  Here’s a sample screen grab (redacted my external IP).\n\nSince I am always diagnosing someone’s network, this app give me a single tap access to the info I’m looking for.\n\nA: Or from your Mac you could try to list all devices in your local network with a little tool, for example https://angryip.org which is free & OpenSource.\nNext to each IP Adresses there is the associated host name device (for example \"iPhone of Elon Musk\")\n", "Q: Can I connect Thunderbolt 2 devices which require power through the cable to Mac Mini M1 I have a late 2013 27\" iMac to which are connected two external drives, a MyPassport Pro 1GB and a LaCie 500MB SSD. These connect to the iMac via the iMac's Thunderbolt ports (I believe Thunderbolt 2). The drives also have no external power supplies, they receive power through the ThunderBolt cables.\nI don't know how long my iMac will last and I'd like to connect these drives to my Mac Mini M1's USB-C/Thunderbolt ports. I tried the T2/T3 adapter cable Apple sells but had to return it because it does not transmit power.\nIs there any way I can connect the drives to the Mini?\nThank you in advance for any info.\n\nA: \nThis answers assumes the OP's drives can not be daisy chained.\n\nApple's Thunderbolt 3 (USB-C) to Thunderbolt 2 Adapter overview states the following.\n\nThe Thunderbolt 3 (USB-C) to Thunderbolt 2 Adapter lets you connect Thunderbolt and Thunderbolt 2 devices — such as external hard drives and Thunderbolt docks — to any of the Thunderbolt 3 (USB-C) / USB 4 ports on your Mac.\n\nI suppose this means you would also need a powered dock such as the Belkin Thunderbolt 2 Express HD Dock with 1-Meter Thunderbolt Data Transfer Cable, Mac and PC Compatible (F4U085tt)\n\n\nThis dock is has two Thunderbolt 2 ports. You would plug one drive into one of the ports and connect Apple's Thunderbolt 3 to Thunderbolt 2 Adapter through a Thunderbolt 2 cable to the remaining port. This would mean you would need to purchase a dock for each drive.\nThe alternative would be to find a dock with more than 2 Thunderbolt 2 ports.\nReferences\n\n*\n\n*My Passport Pro\n", "Q: DocView mode doesn't show pdf I read in the manual \"Document Viewing\" page that DocView mode shows pdf files (since version 23, I found on the Internet), but my version 26 does not. It opens pdf documents always in Fundamental mode. I try to enable DocView mode with \"M-x doc-view-mode\", getting \"Type C-c C-c to toggle between editing or viewing the document\" in minibuffer and that is all. C-c C-c does nothing.\nWhat's the matter?\nEmacs v.26 on El Capitan OSX not in a shell window, in GUI.\n\nA: From the doc-view documentation:\n\ndoc-view.el requires GNU Emacs 22.1 or newer. You also need Ghostscript, dvipdf (comes with Ghostscript) or dvipdfm (comes with teTeX or TeXLive) and pdftotext, which comes with xpdf (http://www.foolabs.com/xpdf/) or poppler (http://poppler.freedesktop.org/).\n\nSo make sure to install them (e.g. via Homebrew) first.\nThen, add /usr/local/bin value to `exec-path variable, as suggested by user phils in response at Thain's message.\nFantastic Emacs!\n", "Q: Reasonable-seeming entries in /etc/export don't work—why? I'm trying to learn more about NFS, and I'm experimenting by exporting arbitrary volumes on my M1 Air (running Ventura 13.1) and then mounting them. Often, I write a row to my /etc/exports file and then find that nfsd doesn't do what I expect; I believe it's erroring, though I haven't been able to find any error logs. I've carefully read through man 5 exports but even so, what works and what doesn't seems totally arbitrary to me.\nIn all of my experiments, I add a single row to /etc/exports and then run sudo nfsd restart; sleep 3; showmount -e. I've pasted a table of my results so far below. Does anyone know why nfsd is failing to come up, or showmount -e doesn't show any mounts in the indicated cases below?\n\n\n\n\n/etc/exports entry\nResult\n\n\n\n\n/Users -network=127.0.0.1 -mask=255.0.0.0\nWorks\n\n\n/Users -network=127.0.0.0 -mask=255.0.0.0\nnfsd won’t start\n\n\n/Users -network=127.0.0.1/8\nshowmount -e returns nothing\n\n\n/Users -mapall=root -network=127.0.0.1 -mask=255.0.0.0\nWorks\n\n\n/Users -mapall=root:root -network=127.0.0.1 -mask=255.0.0.0\nshowmount -e returns nothing\n\n\n/Users/m -network=127.0.0.1 -mask=255.0.0.0\nWorks\n\n\n/Users/m/test -network=127.0.0.1 -mask=255.0.0.0\nWorks\n\n\n/Users/m/Documents -network=127.0.0.1 -mask=255.0.0.0\nshowmount -e returns nothing\n\n\n\n\nN.B. In the cases where I've written \"showmount -e returns nothing\", the specific output is this:\n$ showmount -e\nExports list on localhost:\n\n$\n\nWhere I've written \"nfsd won't start\", the output is:\n$ showmount -e\nshowmount: Cannot retrieve info from host: localhost: RPC: Program not registered\n\n\nRemoving the line and then running sudo nfsd restart seems to fix it in these cases.\n\nA: nfsd checkexports has given me a lot of information about what's going wrong. There are still a few mysteries, but here's what it outputs:\n\n\n\n\n/etc/exports entry\ncheckexports output\n\n\n\n\n/Users -network=127.0.0.1 -mask=255.0.0.0\n-\n\n\n/Users -network=127.0.0.0 -mask=255.0.0.0\n[1] 13001 segmentation fault nfsd checkexports \n\n\n/Users -network=127.0.0.1/8\nBad net: 127.0.0.1/8 exports:1: error processing options: -network=127.0.0.1/8 (this format is not claimed to work in man 5 exports, so it's my mistake to have tried it)\n\n\n/Users -mapall=root -network=127.0.0.1 -mask=255.0.0.0\n-\n\n\n/Users -mapall=root:root -network=127.0.0.1 -mask=255.0.0.0\nUnknown group: root. no groups found: (null). map credential error. (N.B. And using root:staff seems to work)\n\n\n/Users/m -network=127.0.0.1 -mask=255.0.0.0\n-\n\n\n/Users/m/test -network=127.0.0.1 -mask=255.0.0.0\n-\n\n\n/Users/m/Documents -network=127.0.0.1 -mask=255.0.0.0\nexports:1: sandbox_check failed. nfsd has no read access to \"/Users/m/Documents” (N.B. Going to \"System Settings\" > \"Privacy & Security\" > \"Full Disk Access\" and giving full disk access to /sbin/nfsd fixes this)\n\n\n\n\nThe segmentation fault on 127.0.0.0 seems like it must be a bug in nfsd that would be nice to understand, but other than that, I think I largely understand these issues now.\n", "Q: Using curl to download image, and copy to the PNG to the clipboard I'm using curl and grep to get the URL of an image, after that I'd like to download the image itself, and copy it to the clipboard directly, rather than saving it to the disk temporarily before. I'm puzzled that the output doesn't seem to work. It only gives me \"text\" rather than the image itself. Here's the command I have so far:\ncurl -s https://www.tradingview.com/x/4WuY06rl/ | grep -oE \"src='[^']+'\" | sed -E \"s/src='([^']+)'/\\1/\" | xargs curl -s | pbcopy\n\nIf there's an easier solution to this, please let me know. The command is built around the idea that the website here has only ONE img tag.\n\nA: To answer my own question. In the end I settled for, grudgingly, write the image to a fixed file in /tmp, and then read that image into the clipboard using AppleScript. That was just easier than messing around with uuencode. Thank you for all the suggestions.\ncurl -s https://www.tradingview.com/x/4WuY06rl/ | grep -oE \"src='[^']+'\" | sed -E \"s/src='([^']+)'/\\1/\" | xargs curl -s -o /tmp/tvimg.png & osascript -e 'set the clipboard to (read (POSIX file \"/tmp/tvimg.png\") as «class PNGf»)'\n\n", "Q: How can I change Display Refresh Rate with Apple Script on Ventura? I want to change the Refresh Rate between 60Hz and ProMotion(120Hz) with Apple Script on Ventura.\nSystem Settings have changed on Ventura and I couldn't find anything about how to write proper Apple Script for this change.\n\nA: DisplayPlacer is probably what you want. You can install it with Homebrew.\nI use it to store defaults for where my laptop it relevant to my desktop monitor (either in a stand horizontally, or vertically below it on my desk.\nThen you can store the config and switch between them.\nI use an AppleScript script stored in my Scripts folder so it's easily accessible in the menubar.\nAs you can see, it includes the options for refresh rate, so you can just pick the various options and then store them in the script, switching between them. I have it with a dialog to choose, but you could also just create two scripts and store both in the folder to pick from.\nset theOptions to {\"Desk\", \"Stand\"}\nset theChoices to choose from list theOptions with prompt \"Select the layout you'd like.\"\n\nif theChoices contains \"Stand\" then do shell script \"/opt/homebrew/bin/displayplacer 'id:37D8832A-2D66-02CA-B9F7-8F30A301B230 res:1800x1169 hz:120 color_depth:8 scaling:on origin:(0,0) degree:0' 'id:6A89831D-5BCB-4C81-A867-B0E1A52F54F6 res:3840x2160 hz:144 color_depth:7 scaling:off origin:(1800,0) degree:0'\"\n\nif theChoices contains \"Desk\" then do shell script \"/opt/homebrew/bin/displayplacer 'id:37D8832A-2D66-02CA-B9F7-8F30A301B230 res:1800x1169 hz:120 color_depth:8 scaling:on origin:(0,0) degree:0' 'id:6A89831D-5BCB-4C81-A867-B0E1A52F54F6 res:3840x2160 hz:144 color_depth:7 scaling:off origin:(-865,-2160) degree:0'\"\n\n", "Q: MacOS zip folder error code -36/ couldn't communicate with a helper application I want to zip a folder (any folder). When I try to do so I get:\n\ncouldn't communicate with a helper application\n\nAlso, when I try to copy any folder I get exactly the following:\n\nFinder can’t complete the operation because some data in “” can’t be read or written. (Error code -36)\n\nI've tried\n\n*\n\n*restarting finder\n\n*restarting the computer\n\n*shutting down and then re-opening the computer\n\n*checking file and folder permissions (both read and write)\n\n*showing hidden files, none show up\n\n*running dot_clean command\n\nBoth errors persist and only apply to folders (copying/zipping files is fine). I have no idea/direction on how to solve them. I can only think it could be related to having recently changed my Apple ID password. The Terminal zip command works fine on both folders and files.\n\nA: The problem seems to have solved itself after I loaded a time machine backup i had from two weeks ago. I have not found the cause but it seems to work fine for now.\n", "Q: How to detect HTML redirection I have a script that opens a random pick from a local list of over a thousand URIs on a particular website.  I haven't changed the script, but today, every time, I get a page that is not on the list but is on the same website.  The URI requested is not in my browser history.  (Safari)\nIs there a way I can detect a redirection?\ntcpdump comes to mind, but the output is difficult to search.\n\nA: If you use curl and don't tell it to follow redirects you'll get the 3xx response code back and can use that to see where you're being redirected.\neg.\n➜  curl -v apple.com\n*   Trying 17.253.144.10:80...\n*   Trying [2620:149:af0::10]:80...\n* Connected to apple.com (17.253.144.10) port 80 (#0)\n> GET / HTTP/1.1\n> Host: apple.com\n> User-Agent: curl/7.86.0\n> Accept: */*\n>\n* Mark bundle as not supporting multiuse\n< HTTP/1.1 301 Redirect\n< Date: Sun, 12 Feb 2023 00:54:52 GMT\n< Connection: close\n< Via: http/1.1 usnyc3-edge-bx-011.ts.apple.com (acdn/59.14204)\n< Cache-Control: no-store\n< Location: https://www.apple.com/\n< Content-Type: text/html\n< Content-Language: en\n< X-Cache: none\n< CDNUUID: d503e213-6686-4d83-822f-c424b6638655-321701193\n< Content-Length: 304\n<\n<HTML>\n<HEAD>\n<TITLE>Document Has Moved</TITLE>\n</HEAD>\n\n<BODY BGCOLOR=\"white\" FGCOLOR=\"black\">\n<H1>Document Has Moved</H1>\n<HR>\n\n<FONT FACE=\"Helvetica,Arial\"><B>\nDescription: The document you requested has moved to a new location.  The new location is \"https://www.apple.com/\".\n</B></FONT>\n<HR>\n</BODY>\n* Closing connection 0\n\nTo limit output to just the response code do something like:\n➜  curl -o /dev/null -s -w \"%{http_code}\\n\" apple.com\n301\n➜  curl -o /dev/null -s -w \"%{http_code}\\n\" https://www.apple.com\n200\n\nIf you're using Python and the requests library you can call status on your request object and get the response code too.\neg. response.status_code\n", "Q: Reset name and password to access macOS My father passed about four months ago. He had a macOS computer we need to access for photos and a lot of information and files has stored. I do not have the Name or Password he used. Is the there a way to access this info?\n\nA: You can ask Apple to request access to the Apple ID account: this would cover photos stored in iCloud, Calendar, Contacts, email and any documents in iCloud Drive.\nhttps://support.apple.com/en-gb/HT208510\nIt is possible to reset the disk password, by booting into Recovery mode, selecting the Terminal app, and typing resetpassword.\nhttps://support.apple.com/en-gb/HT212190\nIt may also be possible to reset the password using the AppleID.\nhttps://support.apple.com/en-gb/HT202860\nAlternatively, if the data is not encrypted on the disk, then you might be able to access the files using Target Disk Mode. This treats the Mac like an external disk for another Mac. Connect the two computers with a cable, and boot the target Mac while holding T.\nhttps://support.apple.com/en-gb/guide/mac-help/mchlp1443/mac\nYou should be able to access all the files and folders.\nYou could also check if there is a backup disk that isn't password protected.\n", "Q: samba.org install on Monterey serving files with Active Directory binding My basic requirement is to use a macOS Monterey machine as a server (without running macOS Server, which is deprecated) to host SMB shares while using Active Directory as my network accounts source (an Ubuntu server running Samba4 AD DC), and have other macOS machine's user's loging in using the Kerberos SSO Extension (in other words, without having to enter credentials for the shares). Seemed simple enough :)\nFor the server, I initially explored the built-in smb setup in Monterey (ie: enabling \"File Sharing\") with the machine bound (authenticated bind) to the AD DC, but when trying to login via SMB from the client machines (click on the server on the left of a finder window), \"Network Users\" cannot see shares created by a local admin user (though the Kerberos SSO Extension handled passing the SSO credentials flawlessly).  If I logged into the macOS Monterey server machine with an Active Directory account, it created a local home folder and then I could auto-log-in with the Kerberos-SSO extension for that same user as expected from a client machine (but could only see the home folder for that network user as a share - still couldn't see the ones that the local admin account created).  Searched for a long time, tried lots of suggestions, but gave up on that option.\nFigured I'd try installing samba from samba.org so I did a brew install samba on the Monterey server machine.  I set it up similar to another SMB file server I have running on Ubuntu (eg: security = ads, configured realm = AD.DOMAIN.COM, etc.) but I seem to be unable to get it to talk to the AD DC server to validate user accounts.  I get a lot of \"NT_STATUS_NO_LOGON_SERVERS\" in the debug log along with \"winbindd not running\" (which of course, doesn't appear to be available for macOS these days unless I've missed it).  So - samba.org's implementation doesn't seem to pick up the methods Apple has used to get the kerberos authentication and domain binding working despite having done that AD authenticated bind on the server machine and seeing proper output from sudo ktutil list (even when configuring the smb.conf to include password server - dc.ad.domain.com), and I don't seem to be able to figure out what those underlying components are without spending significantly more time here.  (did notice that homebrew's formula code for samba compiled it by default using --without-ads, which was problem #7 or #8 I stumbled upon - which told me that the formula trimmed samba down to the basics to get it to compile on a mac).\nI've spent quite a bit of time searching for others who may have documented this same setup (host SMB shares on a mac using AD as the source for network accounts and Kerberos SSO Extension as the macOS client's authentication method (though I'd settle for simply entering a username/password and saving that to the keychain)) to no avail.  Searching for macos and samba bring up a lot of stuff all the way back to 2004 (making it harder to sift through, as some of the older items are no longer relevant)\nQuestion:\nRather than troubleshooting my setup, config files, etc. (which might take a while), I'm wondering if anyone can point me to a documented setup like this that they've seen that someone has managed to get working?  I've just about exhausted the ways in which I can search for this setup.  (I realize this looks like an ask to do my searching for me, but I'm really just looking to see if someone already has this running and can share a few tricks they used to get it going that I may not have run across yet - if my pain sounds familiar).\nFailing that, perhaps I'll start a new post with lots of detail on my two approaches here (including what I've already tried over the last few weeks) to see if I've missed something.  I know - trying to get a mac to host a robust samba file server is probably not the best idea (but I'll cling to that requirement for a while longer before I elect to go with another option).\nThank you in advance!\n\nA: So, a bit of inspiration from @Todd's post here (Mounting SMB share on Monterey is rejected) using Apple's built-in SMB service about adding users to a specific share (com.apple.sharepoint.group.#) using dscl which I had read before and tried (didn't work) got me thinking about permissions.   I realize that the folder I set up to test a share from the local admin account was within the local admin account's home directory structure (and hence not accessible to network users).  Setting up a folder in the /Users/Shared folder instead resulted in AD Network users successfully seeing and accessing the share.\nDoh!  (I say sheepishly)\nSo I've solved my problem for using Apple's built-in SMB services (which was Plan A).  The issues with the samba.org install (Plan B) still persist, but I will move on from here.  I am happy that Ask Different's \"Related Posts\" on the right brought that one back to my attention again to carry on the thinking.  Great site!  Thank you.\n", "Q: Installing old printer drivers (Canon Pixma MX850) I would like to install drivers for MX850 on macOS Ventura.\nAs expected, upon running the installation package I get prompted with an “incompatibility with current OS” error, which is obvious since the driver is for 10.0.3 or something like that.\nI disabled auth. root and SIP, then tried mounting.\nReturns:\nmount_apfs: volume could not be mounted: Permission denied\n\nmount: / failed with 66\n\nI’m still unable to run installation package successfully.\n\nA: Assuming this is for the Canon Pixma MX850, Canon's website shows drivers compatible with Mojave at latest.\nhttps://www.canon.co.uk/support/consumer_products/products/fax__multifunctionals/inkjet/pixma_mx_series/pixma_mx850.html\nIt's likely that these are 32-bit drivers, which won't work on strictly 64-bit OSes, e.g. Catalina and later.\nIn short, even if you can install them, they won't work. This printer is likely over 15 years old.\nIf the printer doesn't support standard communication protocols like Airprint, or languages like PostScript, then you're at the mercy of the manufacturer to keep the drivers up-to-date.\n(Even the drivers for Windows haven't been updated for Windows 10 or 11.)\n\nA: If you are trying to use the scanning capabilities of your printer, I can recommend 'Vuescan' software. This is not an ad, just a happy customer. Vuescan is in the business of working to make old scanners work in MacOS.\nYour printer's scanner is supported:\nhttps://www.hamrick.com/vuescan/canon_mx850.html#technical-information\nNote, this will not enable you to print, only scan.\n\nA: This is an attempt to write a canonical answer for this issue, as per the Meta post: Where is the list of canonical questions stored for Ask Different? I expect it to be periodically edited with the goal of becoming a comprehensive information resource.\n\nUnfortunately, that printer is no longer supported by the manufacturer.  However, there may be some recourse; it will take a little investigation and some creativity.\nBackground\nApple has been licensing and using CUPS (Common Unix Printing System) since 2002 and then acquired it in 2007.  CUPS.org is the main repository for the all the built in drivers for macOS.  When you add a printer and your system connects to the Internet to download a driver, it's pulling it through CUPS.\nIs my printer compatible?\nBefore you begin what could be an exhaustive search for the elusive printer driver, first determine when your printer was released.  If it was prior to 2018 when Mojave was released then you may face some compatibility issues because this was the last release of macOS to support 32bit applications.\nThe manufacturer may have updated their drivers to 64bit or they may have retired the product with no more official support.  There may be alternatives like compatible drivers (i.e HP LaserJet, Xerox, etc.), emulation modes (EPSON, IBM, Oki, etc.) or printer control/description languages (PCL, Postscript, PDF, etc.) These details can be found in the printer's technical specification sheet or in the user manual.  If it's not listed, it's a safe bet that emulation modes or printer control languages are not supported.\nPrinter buying tip: Stay away from the \"home office\" or \"consumer\" printers.  These will undoubtedly have limited driver support once they are retired.  Look for printers with Postscript and/or PCL language support.  Even if the manufacturer stops making printers altogether, there will be a PostScript or PCL PPD that keeps your printer working.\n\n*\n\n*Check the manufacturer's website.\nThis should be your first stop.  The printer may be supported under an older version of macOS.  If you are trying to install a printer, especially a consumer grade in a post-Mojave world, you'll need updated drivers.\n\n\n*Check the OpenPrinting.org Database.\nThe OpenPrinting database contains a wealth of information about specific printers, along with extensive driver information, the drivers themselves, basic specifications, and an associated set of configuration tools.\n\n*\n\n*Seach the Driver Listing. This is a listing of all printer drivers supported under CUPS; both generic and manufacturer supplied drivers are included\n\n\n*Search the Printer Listing.  Here you'll be able to find specific models that are supported (fully, partially, or as \"paperweight\").  You can search by specific model  or for all of the models supported by a manufacturer (Example:  Canon).  This is a great tool if you're looking to buy a used printer and want to know if it will be supported or to create a list of printers to search for.\nWhat to do if there are no new drivers\nThere are a couple of solutions to make that printer work again:\n\n*\n\n*Buy an older, inexpensive Mac mini to act as Print Server.  By using Print Sharing in this manner, you can extend the life of your printer because the older (pre-Mojave) version of macOS will support the 32bit print drivers that are still available.  You'll also have the added benefit of creating networked printer that you can print to from any device.\n\n\n*Install Windows.  Yes, Windows, but not on Bootcamp.  Similar to using an older Mac mini, any inexpensive computer (Dell, HP, etc.) are more than sufficient.  In many cases there have been Windows drivers that were available long after Mac support ended.\nIf a physical PC is out of the question, fire up a VirtualBox (free) VM running Windows with the printer drivers installed.  It doesn't need a lot of resources since it will be for printing only and you can configure it to used a shared folder or as a network based printer.\n", "Q: How to fix \"Update Apple ID Settings\" bug, when I don't have an Apple ID? My macbook has been upgraded to macOS 13.2 today.\nThis has not cleared my problem.  I still have a notification from System Settings, that wants me to \"Update Apple ID Settings\".\nI have never created an Apple ID.  Nobody has logged into an Apple ID on this macbook.  I don't particularly want to create one.\nI read How to fix the “Update Apple ID Settings” bug in MacOS Catalina [digitaltrends.com].  I can't follow the \"simple\" logout & login steps because I don't have an Apple ID.  I tried the \"complex\" method of removing the random UUID folder in ~/Library/Keychains, but it did not work.\nIn desperation, I tried the \"wrong\" method from Mac keeps saying update Apple ID settings [discussions.apple.com].\nThat is, I saw someone gave confusing instructions, and one or two people cleared /Library/Keychains/apsd.keychain, and thought that worked.  I tried this, but it did not work.  (I don't know why it would work, and it could be dangerous.  Please don't try this method unless you really know what you're doing).\nMotivation\nI do not want this permanent red dot on System Settings, showing an unresolved issue.  I want a red dot on System settings when there is a security update, so that I do not miss it.  When there is not a security update, or another important issue, I do not want a red dot on System Settings.\n\nA: I opened Keychain Access. (I searched for it).\nIn Local Items, I deleted all the entries for com.apple.cloudd.deviceidentifier.Production, plus iCloud Keychain Account Meta-data.\nAfter logging out and back in, I think the red dot remained.  But, when I went to System Settings, the entry for \"Update Apple ID Settings\", on the left below \"sign in with your apple ID\", had gone.  Then I noticed the red dot was gone.\nIt's possible this was a coincidence, and macOS had just fixed the problem itself, a few minutes after the upgrade to 13.2.  There was a notification about \"optimizing\" my computer, and that it would be slower until it had finished.  See also: \"I've been told confidently it has been addressed in 13.2\".\n", "Q: iOS 16 - remove Home from Control Centre Ever since updating to iOS 16, I now have this Home section added to my Control Centre.\nI neither need nor want this. Home is not enabled as one of my Control Centre items, yet this sits here prompting me to set up some 'accessories and scenes' for equipment I don't own… [I've tried clicking the helpful 'Open Home' in the hope it would be satisfied, but I can't do anything with it, as I have nothing to configure.]\nThis, combined with the fact the entire screen now sits much lower than it used to, wasting an entire row at the top, pushes all the icons I do want off the bottom of the screen.\nIs there any way to get rid of it?\n\nInside the Home app I found prefs to switch off 'suggestions' and also removed the default 'home' it had decided I needed to get started. No joy.\nLate edit\nMentioned in comments & in an answer is to switch off 'Show Home Controls', just below 'Access within apps'. I do not have this option…\n\n\nA: Settings → Control Centre → Show Home Controls.\n\nI tried this on a device without a Home, which still showed the section in Control Center as you have in your screenshot, and with a Home where that section had controls. Turning off this option in Settings removed the section in both cases.\nThis is different to the Home option in the list of Control Center items in Settings. That controls a separate button for showing the Home app or holding for controls.\n", "Q: I want to not auto-mount a partition, but I messed up: /etc/fstab asking for encryption password and does nothing (macOS Ventura) I want to have two partitions, one for home and one for work, but do not want the partitions to “see” each other, hence not-automounting the partition came in mind.\nSo I made two partitions, and then I went into Terminal, looked up the UUID for \"work\", opened up sudo vifs and entered the following:\nUUID=<..> none APFS rw, noauto. \n\nI pressed escape and then entered :X to close the file. It did not do anything, then I thought it must be because it is encrypted. So I entered:\nUUID=<..> none APFS encrypted rw, noauto \n\nThen I pressed escape followed by :X, but here sudo vifs asks me the encryption password. Here I messed up, I know. I do not know what to do, so I entered the normal admin password but it will not save and exit. So I stopped the file and know I get a notice that I need to choose between quit, delete etc. I did a bunch of options and I am stuck. It now says swap files found.\n\nAt this moment I repeated steps and nothing helped. I got it to go back to a file that says the first line :UUID=<..> none APFS rw, noauto. But when I try to alter it and press escape followed by :X, it will still ask for the encryption password. I tried using the admin password of that partition, but I need to enter it again and then nothing. When I try to close /etc/fstab, it will ask if I want to terminate the process.\nThe thing that I want is that sudo vifs is normal again. Can you help get the sudo vifs file normal again?\nThen I want to add the line like Alexander Presber said (Prevent encrypted APFS volume on partition to automount / ask for password on login - Catalina):\nUUID=C58A1BDC-593C-4854-B954-702A73ABD67C none auto noauto\n\nHopefully this line with \"auto\" knows what format it is and hopefully it will not ask for the encryption key.\n\nA: Your problem is coming from using the wrong keyboard commands to exit vi. Applied correctly, the answer to Prevent encrypted APFS volume on partition to automount / ask for password on login - Catalina should work in your case as well.\n\n*\n\n*Get the UUIDs for the drives/partitions you want to NOT automount on start\n\n*Run sudo vifs\n\n*Add the lines\n\nUUID=<UID of work partition> none auto noauto\nUUID=<UID of home partition> none auto noauto\n\n\n*\n\n*Press ESC\n\n*Type :wq to write the file to disk and quit vi.\n\nYou can check whether your update was successful by running cat /etc/fstab and looking for the lines you've inserted.\n", "Q: How can I automatically get the Apple (Mac) mail app to display the sender's email rather than their account name? I was wondering if there was any way for me to get the standard Mac email client to display the sender's full email rather than the account name? Some of my email adresses are susceptible to phishing and it is slightly annoying to constantly have to click on the dropdown bar for every email to check.\nHow the email sender is currently displayed\nNote:\nAccording to this (https://discussions.apple.com/thread/251434424) apple discussion, you can't change the \"at a glance\" settings to show it, but is there any workaround for it?\n\nA: While I don't know of a way to add this to the list of messages, you can have it displayed automatically when you open the message by using custom header display in the display pane of preferences.\nSee the section on \"Show message headers\" at:\nhttps://support.apple.com/guide/mail/change-viewing-settings-cpmlprefview/mac\nAdding \"Return-Path\" in a custom header leaves the sender/subject/to as usually displayed, then shows the email address.  Thanks to your question, I've changed my setup.\n", "Q: How does Safari (desktop and mobile) know I have a Google account, even in private mode? While browsing in Safari (Private Mode as well as non-private), I recently saw multiple times some new overlay/modal that offers me to quickly create an account with that respective page using the \"login via Google\" feature.\nI have never seen that before I actually had added my Google account to the account list in iCloud recently, and the modal is always localized (French websites ask in French, German ones in German etc.) and differently styled – so obviously Safari somehow shares with any website that I have a Google account.\nI didn't find any information on how this sharing works and how I could turn it off. It's quite unsettling that information is shared even in private mode…\nCan anyone shed some light on this issue?\n\nA: Fortunately, Safari is not sharing your data or the fact you’ve got a Google account.\nThis is a Google API that webmasters/designers use so they can offer a secure and convenient authorization method to visitors to their site.    Facebook (Meta), and Twitter also offer this service. Google is just bold and very blatant about presenting the sign in when you load the page.\nEven Stack Exchange utilizes both the Google and Facebook login APIs:\n\nIt’s safe to ignore and not utilize it (I don’t, personally) because it just gives Google another analytic point for analysis into creating a user profile on you.  As far as stopping it, you could try blocking Google Analytics with an ad blocker or firewall rule, but you risk breaking a lot of web page functionality.\n", "Q: I was trying to delete Ubuntu from my MacBook Air and now I can't access macOS I had installed Ubuntu on my MacBook, but I don't need it anymore so I was trying to delete the parts of Ubuntu.\nWhen I entered Disk Utility the minus button was greyed out, so I checked some videos and they explained that sometimes you just need to change the format of the partitions and the minus button becomes active, but I didn't see any change. Then here on Stack Exchange, I saw that someone reboot his Mac and entered Disk Utility from the Recovery, but when I rebooted my Mac a message appeared: GNU GRUB version 2.06 and now can't see any of my partitions even when I enter to Disk Utility and if I used ⌥ Option I only see EFI Boot.\nI hope someone could help me, please. Because I'm very concerned and I don't want to lose my information.\nsw_vers and diskutil list output\n\nUpdate\nI created a bootable USB with Linux Mint. I used the command lsblkand I could see my disks. Now I want to know if I can access my files from here. Or I don't know if I can solve the problem by deleting nvme0nlp3 which is the partition that had Ubuntu.\n\nUpdate\ngdisk -l /dev/nvme0n1\n\n\nA: This answer assumes the version of macOS installed on the OP's Mac is Mojave or newer.\nThe Code FFFF shown in the output from gdisk -l /dev/nvme0n1 should be AF0A. You can change this by running the interactive version of the gdisk command. Start by entering the command given below while booted to Linux Mint.\ngdisk /dev/nvme0n1\n\nNext, enter the values given in the Entry column of the table below.\n\n\n\n\nEntry\nType\nComment\n\n\n\n\nt\ncommand\nChange a partition's type code\n\n\n2\nparameter\nPartition number\n\n\naf0a\nparameter\nHex code or GUID\n\n\nw\ncommand\nWrite table to disk and exit\n\n\ny\nparameter\nDo you want to proceed? (Y/N)\n\n\n\n", "Q: Using iPhone as mic for Mac, clicked \"Disconnect\", and can't find iPhone in \"Sound Input\" anymore. What should I do to fix? I have been using my iPhone as a Mic for my mac for a while. It works perfectly.\nHowever, today I clicked the \"disconnect\" button and I can't see my iPhone in the Sound Input any more. What can I do to get it back?\n\n\nA: I tried rebooting my MacBook Pro. It doesn't work.\nThen I tried rebooting my iPhone. It works.\n", "Q: Screen mirroring of selected area in iPhone Is there any way in iPhone through which only a selected area of iPhone screen is mirrored onto TV unlike Airplay's complete screen mirroring? I know it is not exactly a code related or technical question. But, I have tried googling a lot and could not find anything useful.\n\nA: Unfortunately, there is no \"partial\" mirroring of your iPhone screen. You can use AirPlay to stream video or mirror the screen of your iPhone, iPad, or iPod touch.\nEven on macOS, there's no partial mirroring of your display.  If you want to do something like this for the purposes of obfuscating content, you'll need to record the video then redact it manually like blurring or boxing out the portion of the image you want hidden.\nIf it must be live, consider using OBS Studio that allows you to capture a video stream, modify it then broadcast out as a single video.\n", "Q: Installation issue \"ext4fuse:Linux is required for this software.\" on Mac OS Mojave When I ran\n'brew install ext4fuse' in Terminal (10.14.6),\nit returned\n'ext4fuse: Linux is required for this software.\nlibfuse@2: Linux is required for this software.\nError: ext4fuse: Unsatisfied requirements failed this build.'\nHow to resolve it?\nThanks in advance.\n\nA: You might need to build it manually on your Mac.\nTaken from https://github.com/gerard/ext4fuse/issues/74#issuecomment-1374069541:\n\n*\n\n*install mac4fuse from https://osxfuse.github.io/, restart\n\n*Run the following in Terminal\n\ngit clone https://github.com/gerard/ext4fuse.git && cd \"$(basename \"$_\" .git)\"\nmake\nmkdir ~/ext4_mount\ndiskutil list # shows you a list of all disks connected to your system, choose your ext4 disk/partition, let's assume it's /dev/disk4\nsudo ./ext4fuse /dev/disk4 ~/ext4_mount -o allow_other # sudo is required\n# approve all the security prompts, reboot\nsudo ./ext4fuse /dev/disk4 ~/ext4_mount -o allow_other # run again after reboot\n\n", "Q: Entirely prevent specific apps from starting I have a certain issue with my Mac, which is that in certain situations, \"standard\" system apps are started. For example, clicking on any link in MS Office will fire up Safari, which I never use while my \"normal\" Browser is configured as \"default Browser\" in the system's settings. Connecting a BT headset will start Music, which I never use.\nAs it appears, there is no way of simply \"deactivating\" this behavior. As there is apparently no way of \"patching\" the system by completely uninstalling system apps, I want to at least prevent them from being started.\nWhat I want/need is a way to force-stop specific apps (quietly) as soon as they are started. Like watching if a specific process is started and immediately killing it.\n\nA: Firstly, changing the default browser in Ventura's System Settings to MS Edge works for me when clicking on a link in Word version 16.69.\nApps that are bundled with the OS cannot be deleted: the OS cannot be altered in any way, as a security defence. Safari is a bit different, as it can be a separate install; however, it is also fairly core to the OS.\nGiven that I can't replicate the problem, and the difficulty of deleting apps, it may be that there's another solution to the problem.\nI would try testing the problem in a new user account. If the correct behaviour occurs there, then you know that the cause is something in your old user account, rather than at the system level. You can then go back and investigate.\n\nA: Here goes the solution. It is a small tool someone programmed apparently having the same issue I have. It is only focussed on iTunes and Music, but its a start. More importantly, it shows that more people have this problem.\nWhat it does is simply quitting iTunes and/or Music as soon as they are started, so they can never be open/used.\nhttps://github.com/tombonez/noTunes\n", "Q: Why did my SSH agent disappear after updating to macOS Ventura? I recently updated my Macbook to macOS Ventura 13.1, and ever since that I've had trouble using SSH. This has always kind of \"just worked\", I've always been able to just ssh to a host and a popup would prompt me to unlock the relevant key. I've never given it much thought.\nHowever, since I upgraded, there doesn't seem to be anything standing in for a SSH agent anymore:\n$ ssh-add -L\nError connecting to agent: No such file or directory\n\n$ env | grep -i ssh\nSSH_AUTH_SOCK=/gcr/ssh\n\n$ file /gcr/ssh\n/gcr/ssh: cannot open `/gcr/ssh' (No such file or directory)\n\nI'm currently working around this by launching ssh-agent in the current shell:\n$ eval \"$(ssh-agent)\"\n$ ssh-add ~/.ssh/...\n$ ssh my-target-host\n\nI have Googled this to death, but it really seems like I'm the only person in the world with this issue.\nAs I don't really know how the SSH agent was working in the first place, I have no idea where to start looking. I suspect it was the macOS keychain?\nHow was this working in the first place, and why did it stop working?\n\nA: Alright, it turns out there's a good reason I couldn't Google this issue. It was entirely self-inflicted. I sync my .zprofile and .zshrc files across all my computers, all of which run Linux except this Macbook.\nSomewhat recently (around the same time as I updated the Macbook to Ventura) started using Gnome's Keyring SSH agent on my Linux machines. That involved adding this line to .zprofile:\nexport SSH_AUTH_SOCK=\"$XDG_RUNTIME_DIR/gcr/ssh\"\n\nThis resolved to /gcr/ssh on the Macbook and overwrote the OS-provided SSH_AUTH_SOCK variable, which should look something like:\nSSH_AUTH_SOCK=/private/tmp/com.apple.launchd.XJ4sRgc4gr/Listeners\n\nI moved this line to a Linux-specific block like this, which fixed the issue:\n# Very Linux specific stuff here\nif [[ \"$(uname)\" == \"Linux\" ]]; then\n    # ...\n\n    # Gnome Keyring SSH agent\n    export SSH_AUTH_SOCK=$XDG_RUNTIME_DIR/gcr/ssh\nfi\n\n", "Q: External display will not achieve full brightness? My external display (HP 27f 4k) will not achieve full brightness when connected to my M1 MacBook Pro (2020, 13\", Ventura 13.2) via the official Apple USB-C HDMI adapter.\n\n*\n\n*The display's brightness is cranked all the way up\n\n*\"True Tone\" is off\n\n*\"Automatically adjust brightness\" is off\n\n*\"Slightly dim display on battery\" is off\n\n*I've recalibrated the display color, gamma, and white point (in macOS) and then restored it back to the factory default (because it made no difference to the brightness)\n\nI noticed this because I sometimes need to use a Windows laptop with this display. The monitor on Windows was noticeably brighter. So, I measured the brightness with a screen calibration tool and compared the results of the same monitor in the same location (all the same external variables) with the monitor plugged into my MacBook and then into a Windows laptop. I measured against a fullscreen browser window displaying a page with nothing but #FFFFFF (white) as the background color. Results:\n\n*\n\n*290 nits from the MacBook\n\n*335 nits from the Windows laptop\n\nWhat's going on here?\nI suspect this is a software thing because I think I've seen the display snap from full brightness to this dimmed state after login. I say \"think\" because now that I've decided to write this post, I can't reproduce it. But my memory is that I'll log in, and seconds after the desktop is displayed, the brightness snaps to this dimmed state.\n\nA: The short answer is you cannot change this because it's a limitation of the GPU kext (driver) in macOS.\nApple set the brightness level to be a range of two values - minimum and maximum brightness* - whereas the Windows driver uses min/max values sightly more/less than Apple's.\nFor a full explanation of this, see the answer in MacBook Air 2020 change screen brightness limit in macOS.\nI attempted to get datasheets for the most recent AMD GPUs (RX 5600M), but unfortunately they are protected behind an “OEM Partner site” which I don’t have access to.  However, in my research, I found this information about Adjusting Display Brightness for all AMD GPUs.\nWhile this info is  Windows centric, it illustrates that brightness control is via GPU through the driver (in Windows) or kext (in macOS).  Even though you can adjust the brightness value, it’s limit is constrained by the driver/kext, not the OS itself.\nAs for what you experienced with Windows being brighter than macOS, this just illustrates the point that the driver in Windows is configured with a higher maximum value than macOS.\nWhy?\nOnly Apple can say for sure, but I would bet they limited the brightness to extract every minute they could from the battery.\n\n* It's actually a value of dimness.  By default, the panel is 100% bright and by controlling signaling to the panel, it dims it by lowering voltage within a pre-programmed range defined in the driver.\n\nA: In general, a Mac does not control the brightness of an external monitor as such.\nThe explanations regarding min/max values in GPU kernel extensions and PWM signaling to LCD drivers chips are incorrect. That sort of thing applies only to the internal display on the laptop.\nIn your case, you have an external monitor connected over HDMI. There's no PWM brightness signal in a HDMI connector - it simply doesn't work that way.\nOnly some monitors actually support controlling their brightness from the computer - and again in some cases it's a proprietary interface. In general, external monitors that do support brightness control over HDMI, do so via DDC.\nDDC is an I2C bus with a somewhat standardised, digital protocol on top that allows for information to flow to/from the monitor and the computer. The brightness \"signal\" is thus not analog voltages or a PWM signal, it's digital commands.\nOn top of DDC, there's a standard set of commands known as MCCS (Monitor Control Command Set). A few monitors also make MCCS available over USB (for example the old Apple Cinema HD display).\nMacOS does not send out these MCCS commands over DDC to external monitors. Apple has their own system for managing brightness on their own external monitors, but it is not used with third-party external monitors.\nTo sum that part up - macOS is not asking the monitor to lower its brightness.\nThis means that there are two possibilities:\nEither:\n\n*\n\n*The settings in the on-screen-display menu on the monitor has the brightness somehow set lower than maximum (unlikely given the information you have included in your answer)\n\nor\n\n\n*The Mac is not sending the same image data to the monitor to display as the Windows PC.\n\nThe latter can happen because of color profiles:\nOn the Mac, check System Settings > Displays and \"Colour Profile\". Try changing that to see if it changes the brightness output, you're measuring. Browsers can and will use colour profiles - so even if you display the same PNG file (for example) in two different browsers they can show different colours - even when the colour code is listed as #FFFFFF for example. The browser might apply a color profile as can the operating system in general.\nIf you want to try setting the monitor brightness from macOS, you can do that by installing a third party DDC utility. I think the best/easiest is to install BetterDisplay or MonitorControl.\nIt could also be for example the ddcctl tool available from HomeBrew, however I'm not sure how well it supports your M1-based Mac yet.\nFor the M1 specifically there's another tool named m1ddc. Unfortunately it is not clear whether that works when controlling a monitor connected over HDMI. So you might need to use a different cable to connect the monitor over DisplayPort instead.\n", "Q: How to store terabytes of photos in iCloud from an external drive? I have a friend who is an Apple-only user; just iPhones and MacBooks, both new from 2022 or 2023.\nThey have about 1.5TB of photos stored on an external drive; I told them they should have them backed up somewhere else other than that one place.\nCan they upload them to iCloud without it trying to sync all these files to their iPhones and MacBooks, and taking up tons of room?\n\nA: iCloud/iCloud Photos is more a syncing than a backup solution. It mainly protects against big failures like damaged drives or lost devices, but if you delete a photo by accident, the deletion will sync across all devices resulting in a photo lost. Syncing of course also requires adequate storage on all devices. Also, the maximal storage you get with iCloud is currently limited at 2 TB (extensible to 4 TB if you also purchase Apple One), so depending on the number of additional photos per day you may run into problems rather soon.\nSo\n\n*\n\n*get one or several additional drives (>= 2 TB) and use software like SuperDuper or Carbon Copy Cloner to regularly backup the master drive to the clones. Store at least one clone off site (e.g. at the office) and rotate with each backup cycle.\n\n*install Backblaze or Arq and schedule regular backups to a cloud storage provider like AWS, Google or Microsoft.\n\nThe first option obviously needs more manual work, so if you are looking for a \"install once and let it run\" solution go with a cloud backup.\n\nA: iCloud is not the right tool for this.  Instead, I suggest you use a NAS like Synology or TrueNAS*.  Both products have Photos (and full media organization) feature sets:\n\n*\n\n*Synology.  They have a  built in tool for media organization that allows for uploads from iDevices, centralized archiving and backing up to external USB drives and to the cloud.  If you're looking for something that's easy to configure and with no monthly cost - this is your best bet.  I have used this to create slideshows from locally stored photos that could be displayed on any TV in the house.  Synology also supports 3rd party apps like Plex Media server that can host photo galleries.\n\n\n*TrueNAS mainly uses third party apps.  Two of them are PhotoPrism and Piwigo.  I've seen PhotoPrism implemented and liked the interface.  I haven't personally implemented either of these apps on a TrueNAS (yet).\niCloud is good, but you're limited to what you can do.  It's main function is giving you a place to put photos and share them.  While Apple backs up their servers, you can't really consider it a backup for you.  By that, I mean if Apple goofs up and loses data, they can restore it.  If you goof up and delete a bunch of photos, you might be able to get Apple to restore it - nothing is certain.\nThe benefit of going this route is you bypass monthly fees, load only the photos you want on your iPhone and have a central repository for all your photos and multimedia with offline backup capabilities.\n\n* I am a longtime user of Synology and only recently started with TrueNAS because of their ZFS support and better ability to host VMs.  I still wholehartedly recommend Synology.\n", "Q: Nothing has or can be given Full Disk Access after 13.2.1 Update Following an update from macOS 13.2 to 13.2.1, all the items that had Full Disk Access have lost it (and nothing is listed as having FDA). Now new items can be added.\nIs this some kind of intentional lockdown? A bug?\n\nA: I also experienced this upgrading to 13.2.1\nRestart your machine (2 restarts were needed in my case).\nI could not add any new items to the permissions sets for screen recording or full disk access and all previous items were no longer there (completely blank list).\nAfter 2nd restart all previous permissions were restored and all functionality seems to be as it was.\n", "Q: Safari Develop menu not responding I've enabled Develop menu but when I click it, it takes around 1.5 minutes to open.\nThis behavior was not happening at the beginning but started after a while, presumably around the time I inspected my iPhone simulator through Safari.\nI disabled cache, reset settings and restarted, but none of these have solved the problem. I have no extensions installed in Safari.\nThis is the screenshot of the Console app's logs:\n\n\nA: After a lot of hair pulling, I finally figured it out.\nChecking Console apps logs, I saw a lot of SafariBookmarksSyncAgent timeout errors.\nSo I unchecked the Safari option from iCloud sync options, and it worked. It appears that there's an issue with syncing bookmarks.\n", "Q: Jump to the end of animations when going to previous slide I use Keynote for my presentations, and I often have fairly complicated slides with many animations.\nThis generally works well, and it makes for a nice presentation. However, at the end of the talk, I am often asked to go back to a specific slide. This is made complicated because I need to find the right slide and the go forward however many animations I have to get the final state of the slide. Moreover, if I don't remember the exact number of animations and click one time too many, I have to go back and repeat the whole process.\nIs there a way to see the final state of a slide, after all animations have been applied, when going backward? Alternatively, is there a shortcut that displays the final state of the current slide?\n\nA: You can hold ⇧ SHIFT when changing the slides with arrows. This disables the animations.\n\n*\n\n*← and → arrows skip animations\n\n*↑ and ↓ arrows skip to the next slide\n\nIn order to \"load\" all animations you can press ⇧SHIFT↓ (next slide) and then ⇧SHIFT← (previous slide with all animations completed).\n", "Q: Looking for an exit from the iTunes <> iPhone Music sync hell by enabling \"Sync Music\" Using iTunes (latest) on a Windows 11 laptop and iPhone (iOS 16.2).\nI have 4000 songs on the iPhone, and a bit more in the iTunes library (from CDs... ; the lib was manually copied from the Music folder after a PC upgrade, and is correctly shown in iTunes Library).\n\n*\n\n*Transfer Purchases (to iTunes) has been done (from my 2 Apple accounts)\n\n*Not an Apple Music subscriber\n\n---- Target ----\nOn iTunes, I want to be able to\n\n*\n\n*add other CDs\n\n*listen and remove about 30% of the old songs in the iTunes lib\n\n*then sync that to iPhone\n\nFor that, \"Sync Music\" (device / settings / Music) is necessary. But a click on the Sync Music gives this message, triggering a few questions\n\nQuestions\n\n*\n\n*How can I see what would be deleted if Sync Music is to be performed?\n\n*my numerous iPhone playlists are not listed in iTunes, will they be cleared on the iPhone? What can I do to prevent that?\n\n*no Books is shown in iTunes (have plenty on the iPhone), the message says they will be deleted, why would Sync Music clear the iPhone books? Will that really happen? Can I avoid this?\n\nA simple setup that should not take so much time :(\n\nA: Do all of the items on the phone originate from that specific instance of iTunes on that computer?\niTunes is the 'master' in this arrangement, the phone the 'slave'. Anything not already in iTunes on that specific computer will be discarded as it syncs. It does not copy songs/books etc back from the phone, only such as playlists.\n", "Q: Can I use pf to route incoming incoming traffic on a specific port differently? I have a mac that's connected to a VPN, where the VPN's gateway is the system's default gateway for all outgoing traffic. This means that I cannot connect to any services running on my mac from some arbitrary IP outside of my local network, even when port forwarding is set up correctly on my router, because the source IP address of the connection will be a non-local IP and therefore the system will try to route it through the VPN, not through my local gateway.\nHowever, I think it might be possible to use pf to route this traffic differently based purely on its port number. What I'd want is to have the default gateway for a connection on a specific port to be my local gateway, rather than the VPN, regardless of what the source IP address is. (If I knew the IP in advance, I could just set up a static route.)\nIs it possible to do this? If so, how would I configure pf to do so? (Perhaps it's possible to use pf to select a different routing table for the connection based on its port?)\n\nA: If you need to route specific traffic over a different gateway then you can enable split tunneling - the vpn client controls pf and the local route table.\nhttps://openvpn.net/solutions/use-cases/split-tunneling-with-access-server/\nNot sure I 100% understand the question, but hopefully this helps.\n", "Q: What is the \"open\" UNIX script for and why is it unidentified? I just updated to macOS 13.2.1 today. After doing so, I logged back in and a notification popped up, mentioning something called \"open\". Clicking on this notification took me to the settings. Specifically, it took me to the \"Allow in the background\" settings.\nThere, I can see the Unix script named \"open\". This file exists in the \\usr\\bin directory. Opening it in a text editor shows a jumbled mess of characters. It has permission to work in the background enabled. It also says that it is an \"item from an unidentified developer\".\n\nWhat is this \"open\" script? And is there a way for me to identify where it came from?\n\nA: It's not a \"UNIX script\". It's a regular program, it comes with the standard macOS installation \"from factory\". Its purpose is simply to \"open\" up files and folders for you - i.e. from the command line (or a script or ordinary program), you can go open myfile.xyz and it will open up using a GUI application like had you double-clicked the file.\nThe fact that you get this permission prompt indicates that you have installed something that tries to run it in the background or at login time. Seeing that you have pgAdmin 4 installed, it sounds likely you might have other, developer-related stuff installed. So check those newly installed programs and you'll probably find the culprit.\nTo sum up, this program comes from Apple and it is completely non-problematic to have it on your system. If you want to verify that it is signed by Apple, run this command in Terminal.app:\ncodesign -dv --verbose=4 /usr/bin/open\n\nAt the end it should list the \"Signed Time\" as well as the \"Authority\", which would be \"Apple Root CA\" and \"Apple Code Signing Certification Authority\".\n", "Q: Is it possible to add Merriam-Webster to Mac's Dictionary app? I searched for \"misclassify\" in Dictionary.app and it couldn't find anything. I Googled it, and Google gave the a nice definition in the first result, from Merriam-Webster.\nIs it possible to add Merriam-Webster to Mac's Dictionary app?\n\nA: Apple's Dictionary app uses data in its own special format. It is possible to create dictionary files using Xcode; and there are scripts to convert other dictionary formats into Apple's own data type.\nSo, possible: yes. However, I don't think anyone has done it. MW have their own app on the App Store. It's possible that they have restrict access to their data.\n", "Q: Can I use an APFS snapshot to generate a list of all files changed since an earlier point? I just clean installed macOS on a new VM and now need to set it up with various preferences and stuff to customize it. What I am curious about is where all those customizations actually get stored.\nI think most are probably in Preferences plists but others might be in other system databases or third party app configuration files. Regardless, really I'm just wanting to see a list of files changed between \"Point A\" and some later \"Point B\" and this is probably interesting in a lot of other cases too.\nIs there a way I can use the command line to:\n\n*\n\n*Trigger an APFS snapshot of my \"Macintosh HD\" boot disk — starting point \"A\"\n\n*…then do whatever using the computer…\n\n*Then trigger a new snapshot and/or at least compare now at time \"B\" what files have been modified since the snapshot at \"A\"?\n\nDon't need a GUI or anything, just commands that would mark the snapshot and echo out a list of files that changed later. And I don't really need any sort of diff showing the changes within each files, just the overall paths/names of ones that did. (Also not really interested here in solutions based on file modification timestamps; I want to really know at the lower level even if some file's metadata didn't get touched for some reason.)\n\nA: Unfortunately, using the command line to do APFS snapshots manually is quite a bit involved:\nThe program that issues the request to make the snapshot is required to have the com.apple.developer.vfs.snapshot entitlement, which is basically a sort of \"permission slip\" from Apple for that feature. Apple only gives that entitlement out to specific types of programs (i.e. backup software, disk cloning software, etc) - but as far as I know, no generic, command line tool has been given the entitlement.\nA number of generic, command line tools do however exist - for example this:\nhttps://github.com/ahl/apfs\n\nHowever, you have to manually give it the above mentioned entitlement. It's easy enough, but macOS won't validate that entitlement per default. You have to disable some of the security feature in macOS in order to get such \"homemade entitlements\" to work. Specifically you need to disable SIP and boot up with  amfi_get_out_of_my_way set. There's guides available to follow if you want to go down that route.\nHowever, I propose a simpler solution:\nUse one of the existing, already entitled, programs to create snapshots - and compare them using standard tools.\nOne idea would be to setup Time Machine backups (if you haven't done so already). Disconnect the backup disk so that snapshots are created locally. They're created once per hour - so it can be a bit of a waiting game. Note that snapshots are only kept around for 24 hours by default.\nYou can use Disk Utility to mount the snapshots afterwards, and then run the diff -r dirA dirB command in the Terminal to compare the two folders.\nYou could also just run full Time Machine backups to a connected disk - then you do not have to wait an hour in between snapshots. You can then use software such as BackupLoupe to see exactly what was changed between two backups.\nAnother option is using the software CarbonCopyCloner to create the snapshots. You'll need to enable APFS snapshots for the startup volume in the settings.\n", "Q: Broken DNS resolvers automatically included on scutil --dns What are the ways to persist DNS and SearchDomain settings? How to remove?\nIf I run scutil --dns it shows these two resolvers (and a few others for *.in-addr.arpa addresses)\nresolver #1\n  search domain[0] : 0.mydomain.com\n  nameserver[0] : 10.10.50.53\n  if_index : 15 (en0)\n  flags    : Request A records\n  reach    : 0x00000002 (Reachable)\n\nresolver #2\n  domain   : 0.mydomain.com\n  nameserver[0] : 10.10.10.53\n  flags    : Supplemental, Request A records\n  reach    : 0x00020002 (Reachable,Directly Reachable Address)\n  order    : 101600\n...\n\nBoth resolvers include one of my domains, and #2 has the wrong nameserver IP.\nI don't have a search domain configured on *Settings -> Network -> Detail -> DNS, and my local DHCP server does not provide a searchdomain.\nIf I remove the invalid resolver with:\n# sudo scutil\n# get State:/Network/Service/[redacted, random numbers and letters]/DNS\n# d.show\n<dictionary> {\n  ServerAddresses : <array> {\n    0 : 10.10.10.53\n  }\n  SupplementalMatchDomains : <array> {\n    0 : 0.mydomain.com\n  }\n}\nremove State:/Network/Service/a09acf02331d4926/DNS\nquit\n\nThen, scutil --dns shows the correct resolvers, without search domains.\nresolver #1\n  nameserver[0] : 10.10.50.53\n  if_index : 15 (en0)\n  flags    : Request A records\n  reach    : 0x00000002 (Reachable)\n\nresolver #2\n  domain   : local\n  options  : mdns\n  timeout  : 5\n  flags    : Request A records\n  reach    : 0x00000000 (Not Reachable)\n  order    : 300000\n...\n\nAfter removing that key, everything works as expected. But that entry returns on every reboot.\nWhat could be including this config? Where should I look at?\nEdit: As suggested by @Allan, this ensures I`m not receiving the search domain setting from DHCP.\n# ipconfig getpacket en0 | grep -i domain\ndomain_name_server (ip_mult): {10.10.50.53}\n\n\nA: Searching on my computer with sudo mdfind \"0.[my-domain]\" for the domain name guided me to /Library/Application Support/ZeroTier/One/networks.d, which has two files, [redacted-letters_and_numbers].local.conf and [redacted-letters_and_numbers].conf\nThe first file had Zeroties`s configuration to customize the DNS and searchdomain. I figured the \"redacted\" part were my zerotier network id.\nI thought I had already uninstalled this VPN software, but ps aux | grep zerotier shows it is running. Removing it with sudo \"/Library/Application Support/ZeroTier/One/uninstall.sh\" solved my problem.\n", "Q: Enabling HDR on macOS ventura using an apple script I have a macbook M1 Max 2021, 1tb, 64gb ram, with mac os 13.1 ventura and my HDR always randomly turns off when my computer wakes up from sleep. My monitors are dell s3422dwg and dell s2721dgf.\nMy externals are 1 and 3 while my internal is monitor 2.\nI have to go into the menu and find the monitors and enable the hdr slider.\nI am trying to write an apple script that can enable HDR on the external monitors without affecting my internal retina monitor. The internal screen can only enable or disable tru tones not hdr.\nHere is what I have so far but I keep running into an end of line error.\ntell application \"System Preferences\"\n    activate\n    reveal anchor \"displaysDisplayTab\" of pane id \"com.apple.preference.displays\"\n    tell anchor \"displaysDisplayTab\" of pane id \"com.apple.preference.displays\"\n        tell table 1 of scroll area 1\n            select (row whose value of static text 1 contains \"DELL S3422DWG\")\n        end tell\n        tell table 1 of scroll area 1\n            select (row whose value of static text 1 contains \"DELL S2721DGF\")\n        end tell\n        click checkbox \"High Dynamic Range\" of group 1\n    end tell\n    quit\nend tell\n\n\nThen I also tried to do it another way like this,\ntell application \"System Settings\"\n    activate\n    set current pane to pane id \"com.apple.preference.displays\"\nend tell\n\n\ntell application \"System Events\"\n    tell process \"System Preferences\"\n        set frontmost to true\n        repeat until exists window \"Displays\"\n        end repeat\n        tell scroll area 1 of group 1 of window \"Displays\"\n            click checkbox \"High Dynamic Range\"\n        end tell\n    end tell\nend tell\n\ntell application \"System Settings\"\n    quit\nend tell\n\n\nBut the system preferences app opens up on the appearance tab and I get thrown an error error \"System Settings got an error: AppleEvent handler failed.\" number -10000.\nI just started using apple script and I am not really sure what I am doing. Any help would be greatly appreciated. Thanks!\n\nA: Stolen from here: https://gist.github.com/skempken/46c184c1a5eac2e88c9c31ce09a38300\nuse AppleScript version \"2.4\" -- Yosemite (10.10) or later\nuse framework \"Foundation\"\nuse framework \"AppKit\"\nuse scripting additions\n\ntell application \"System Settings\"\n    activate\n    current application's NSWorkspace's sharedWorkspace()'s openURL:(current application's NSURL's URLWithString:\"x-apple.systempreferences:com.apple.Displays-Settings.extension\")\n    delay 0.5\n    \n    tell application \"System Events\"\n        tell process \"System Settings\"\n            key code 48 -- One tab to hit left monitor\n            delay 0.5\n\n            -- activate hdr on left monitor                         \n            set hdr to checkbox 1 of group 3 of scroll area 2 of group 1 of group 2 of splitter group 1 of group 1 of window \"Displays\" of application process \"System Settings\" of application \"System Events\"\n            tell hdr\n                if value is 0 then click it\n             end tell\n            \n            key code 48 -- Switch to the MBP screen         \n            key code 48 -- Another tab to hit the right monitor\n            delay 0.5\n            -- do it again\n            set hdr to checkbox 1 of group 3 of scroll area 2 of group 1 of group 2 of splitter group 1 of group 1 of window \"Displays\" of application process \"System Settings\" of application \"System Events\"\n            tell hdr\n                if value is 0 then click it\n            end tell\n            \n        end tell\n    end tell\n    quit\nend tell\n\n", "Q: Why did Telegram app suddenly appear on my iPhone? I didn't install it! Telegram was never something I have ever installed manually. So how the heck did it suddenly randomly appear on my phone when I switched it on today. It started up with a notification. I thought heck that's odd. Then I find I had an app I never downloaded. So I immediately trashed the app.\n\nA: Perhaps your work phone has an Apple ID same as a private phone, which has Telegram installed on it ?\n\nA: The only way apps get installed are via the App Store or a management profile.\nCheck for profiles in the settings app.\nUnless you’re jailbroken, one of the above avenues placed the app on the phone. From a practical standpoint delete it and then wait and watch would be my advice.\n", "Q: I can’t log in, how to reset password macbook m1 the password is wrong it shows but I have taken the pic of the password last night  \n\nA: To reset password for macbook m1 (icloud password needed) press power button until shut down then before the keyboard on and in case in turn on again before logo appeared or opening sound we press power button for long time until the logo appear and said continue holding for start up option\nhttps://youtube.com/watch?v=pXiqUwB0piE&si=EnSIkaIECMiOmarE\n", "Q: Is it possible? Right-Click in Finder folder should launch a vi editor in that folder I often find myself wanting to use the vi editor (vim) to add a text file in an open finder window (directory).\nI strongly dislike using TextEdit since it often mangles my text file.\nCurrently I need to launch vi from the Dock, write my file, but then ask for a save with a filename that needs all of the path from my home directory.\nThanks\n\nA: One way to do so is the following:\n\n*\n\n*in the Finder menubar go to View and select \"Show Path Bar\" and at the bottom of the Finder window you will have a chain of directory icons for the current directory.\n\n*Right click on the last directory icon (you could do it also on any\nof the previous) and choose \"Open in Terminal\".\n\n*You will now have a shell open at the desired location and you can\nlaunch vi from it (or any other shell command you might need).\n\n", "Q: Number between brackets next to interface name What is the number between brackets next to the interface name in ifconfig output?\nIn the following output i.e. (17)\nen0 (17):\n  inet address  192.168.4.5\n\nEDIT\nAs requested I add more info.\nI was using ifconfig on Ventura but this called the Homebrew command instead the native one.\nUsing /sbin/ifconfig i got the output without the brackets.\nen0: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500\n...\n..\n\n\nA: You're using the GNU ifconfig tool that comes when installing inetutils from HomeBrew (for example).\nThe number in the brackets is just an ID/index number - it is not listed when using the standard, macOS ifconfig command.\n", "Q: Set macOS wallpaper without re-encoding image I have a PNG gradient with the same resolution as my screen, 3072 × 1920, and 16-bit color, which renders without banding when viewed full-screen using Preview, but becomes banded when set as the desktop wallpaper. How can I prevent whatever re-encoding is doing this?\nI’ve tried exporting the wallpaper as an 8-bit PNG, but that introduces banding even when viewed in Preview. I’ve also tried the sRBG, Display P3, and Color LCD color profiles, and using a TIFF, as well as setting the wallpaper via System Settings, the Finder context menu, and an AppleScript that tells Finder set desktop picture to POSIX file \"/example/filename.png\".\n\nA: This is a workaround I’m currently using.\n\n*\n\n*Export the wallpaper as a 16-bit PNG.\n\n*View the PNG in Quick Look, not Preview.\n\n*Make the Quick Look window fullscreen, then tap an arrow key, hiding the cursor and making the image fully fill the screen.\n\n*Take a screenshot.\n\n*Use the screenshot as the wallpaper.\n\nThis results in a wallpaper without banding.\nThe screenshot comes out as 4096 × 2560 and 8-bit, despite that the display is 3072 × 1920 and 10-bit. The color profile on both is Color LCD.\nI’m not sure what’s going on here. Maybe the wallpaper is always 8-bit, the image actually can work as 8-bit, and the screenshot downsampling code is just better than the downsampling code for wallpapers, Pixelmator Pro, and Affinity Photo. Of note, though, if you open the screenshot then export it using those editors, changing nothing and matching settings, banding appears.\n", "Q: In Terminal, 'Meta+L' is somehow shortcut for 'ls'. How to disable it? In macOS' Terminal, the Meta L (or OptionL if you enabled \"Use Option as Meta key\" in settings) is somehow a shortcut for ls.\nHow do I disable it? I want to use shell default Alt+L for converting to lowercase. The opposite shortcut Alt+U (convert to uppercase) works as expected.\n\nA: It's part of zsh keybindings. You can see them with typing bindkey in Terminal. By default it says:\n\"^[l\" \"ls^J\"\n\nYou can change this to \"downcase\" with\nbindkey \"^[l\" down-case-word\n\nIf you are using oh-my-zsh it's set in\n~/.oh-my-zsh/lib/key-bindings.zsh\n\nwith bindkey -s '\\el' 'ls\\n' # [Esc-l] - run command: ls\n", "Q: Can't move Dropbox to ~/Library/CloudStorage I'm unable to complete the latest Dropbox update that changes the location of Dropbox on macOS to ~/Library/CloudStorage.\n\nFollowing the walkthrough that appears in the Dropbox app I get in an infinite loop where the files can't be moved (\"right now\").\n\nFWIW, I can't move them there using the app's settings either, though I have no problem adding or changing files in the folder otherwise, and can even drag the Dropbox folder there in Finder (though that disconnects Dropbox).\nHow do I complete the update? Is anyone else having these issues.\n(macOS 13.2.1 / MBA M2)\n\nA: Quit Dropbox and then delete the Dropbox cache folder (which is hidden by default), then launch Dropbox again. That should do it.\n", "Q: Is it possible to screen share (VNC?) into another instance of a user account? I'm trying to remotely log into my home MBP that has 4 monitors, and that's proving to be a pain when connecting from a screen with one monitor. I just view one screen at a time, but often when I make new windows or something, it opens on a different monitor out of sight. What would be ideal is if I could just log in as another instance of my user account that doesn't actually show up with what the computer is showing, but all windows would show up on one screen as if no external monitors were plugged into the MBP. Does what I'm looking for make sense and is something like that possible?\n\nA: No something like that isn't possible, only one gui login session for each user id. If you had multiple accounts set up then yes it might be possible but I have a feeling that isn't going to help much, if that won't be an issue then just log in using the alternate account and it'll open a new gui login.\nSome things you might want to try (I'm assuming you're using a Mac on both ends and either ARD or Screen Sharing to remotely connect.)\nYou could view all four screens at the same time by turning scaling on (this wouldn't be very useful unless you were remoting in from a machine with a huuuuge display, or you could only turn scaling on when you want to view all screens to find that window you just opened)\nYou could also control-click on the app icon in the dock, go to options, then assign the app to a desktop on a particular display so it opens new windows and you know which display it's gonna be on.\nBut yeah, no what you're looking for isn't possible in macOS, I'm not confident but I don't know any other window systems that let you log in into separate gui sessions with one user id, so it might not make too much sense either.\nEdit: alternative workaround\nOkay another workaround which I feel is pretty messy is to create another user account and physically log in using that one.\nNo need to log out of the original account (that you said had things running and didn't want to log out of). You just need the account that is logged in locally to be the alternate account.\nYou can either do this by directly switching accounts on the local machine, or you can log into the main account using screen sharing, and then use the user switching menu to log into the alternate account. (This doesn't log you out of the first account)\nThen disconnect (close screen sharing) if you switched accounts remotely.\nNow, since the local machine is logged into the alternate account, if you try to remote into the machine and log in using your original account, it'll tell you that there's a session already and if you'd like to share the screen or log in as yourself. Logging in as yourself give you another gui login, under a separate user of course.\nBut at this point the screen share will probably replicate the local machine's display setup. If you want everything to show up in one virtual remote display, open system preferences, display settings, and mirror all displays except the main one (maybe built in one?).\nThis doesn't mess with the display configuration when you're logged in locally, only when you're using vnc to remote in. (Not completely sure how, it creates virtual display projector devices that sort of replicate the hardware computer is connected to, but it's not the actual display so the settings are separate. On the flip side, the settings are preserved if you use the same method to remote in again)\nThis is a super messy workaround but I hope it sort of answers the additional question you asked in comment.\n", "Q: Install macOS Sierra on \"Macintosh HD\" or on \"Update\" First time I see these two options - which should I use?\n\nThis is a 2017 MacbookPro 13\" with Intel i5, model A1708, right after I erased \"Macintosh HD\" using Disk Utility and reset its NVRAM.\nHow come there are two options and what is this Update option?!\n\nA: Learning from this question, it seems I didn't fully erase the the hard drive. The proper steps are:\n\n*\n\n*Enter recovery modeShut down, long press power to boot, immediately hold cmd+R until you see the apple again\n\n*Fully erase the drive and create partitionUsing Disk Utility, erase the root of the tree. Be sure to name the new partition Macintosh HD, choose Journaled and GUID Partition Map(Note: Change Untitled to Macintosh HD)\n\n*Install macOSIf you go back and choose reinstall macOS you should now have a single drive named Macintosh HD to choose from\n\n", "Q: Encrypt PDF on Linux, decrypt on Mac? (in 2023) There are many tools available for the Linux user to encrypt a file:  Encrypting/Decrypting a single file in Ubuntu 12.04 LTS.\nI want to…\n\n*\n\n*encrypt a single PDF on my Linux OS,\n\n*email it to a non-technical user on a Mac and\n\n*expect they can easily decrypt the PDF(using a password I provide through \"another channel\".\n\nIdeally, the non-technical recipient is not required to install additional software.  Preferred (fool-proof) solutions involve native-to-macOS (built-in) capabilities or, perhaps, double-clicking a password-protected \"self-extracting\" file ... minimal experience or thinking needed.\nMy knowledge of macOS is thin.  Suggestions?\n( Side question - first post from a no-longer-virgin Stack Exchange user.\nShould this have instead gone to https://unix.stackexchange.com/ ?)\n\nA: Recommendations for software (and Linux software at that) are off-topic, but: password-protected encryption is part of the PDF standard, so any Linux PDF-compliant app should be able to create a PDF that requires a password to open it.\nOn MacOS, Apple's built-in Preview app can open encrypted PDFs, if the password is entered.\nFor other file formats, zip encryption with a password may be a good option.\n\nA: The PDF standard (2.0) uses AES 256-bit encryption.*\nThis is platform agnostic meaning if it is a PDF file, then it can be encrypted/decrypted on any OS on any processor including Apple Silicon and ARM.  In your example, you can encrypt using Ubuntu (or Mint or Kali or whatever), then decrypt it on Mac and even Windows. Vice versa, a PDF encrypted on a Mac (or Windows) can be decrypted on Linux. The native PDF tools on each OS will work fine.\n\n* Wikipedia link provided.  Official ISO 32000-2-2020 Standard Definition is behind a paywall. Click the link and search for “encryption”.\n", "Q: What happened to the .zshrc I am trying to setup my new MacBookPro M2-Max.\nI can't find the .zshrc, the only hidden files in my home folder are:\n.zprofile\n.zsh_history\n.zsh_sessions\n\nBut no .zshrc\nMy OS is Ventura. Any ideas?\n\nA: As pointed out in the comment, ~/.zshrc is not created by default in macOS. However, you can create it easily enough:\n% touch ~/.zshrc  \n\nThere's a nice Q&A here that summarizes one opinion of the raison d'être for the ~/.zshrc file. And there's another opinion here, which also suggests what types of configuration parameters should go into a ~/.zshrc file. You didn't ask what to put in ~/.zshrc, and I assumed the two references covered that in enough detail... but one of the comments suggested I should say something explicit.\nClearly, Apple has deemed .zshrc unnecessary, but many people use it. I keep (among other things) my HISTORY configuration there.\n", "Q: Passing Text to Shortcut via Command Line Arguments Problem\nI want to run a Shortcut from the command line and include Unicode text as a part of the command. I want to do something like: shortcuts run \"My Notification Shortcut\" \"My Text Input\"\n\nAccording to the Shortcuts Docs:\n\nRunning shortcuts from the command line is no different from running shortcuts in the Shortcuts app—you can pass documents, images, text, and more.\n\nshortcuts -h:\nshortcuts run <shortcut-name-or-identifier> [--input-path <input-path> ...] [--output-path <output-path>] [--output-type <output-type>]\n\nThis seems to imply that the text must be included as a file. This works:\nshortcuts run \"Test\" -i \"/Users/Dave/My Text.txt\"\nand I want to do this:\nshortcuts run \"Test\" \"My Text Input\"\nHaving to save the text to a file seems like an unnecessary step.\nQuestion:\nIs it possible to pass a text object as a command line arg directly to a Shortcut?\n\nA: Looks like it's possible after all using the bash operator <<<. This shell command works as intended:\nshortcuts run \"Test Alert\" <<< \"My Text Input\"\n\n\"man bash\"\n   Here Strings\n       A variant of here documents, the format is:\n\n              <<<word\n\n       The word is expanded and supplied to the command on its standard input.\n\nUpdate 1: per @Martin R.'s comment above, the following construction also works.\necho \"My Text Input\" | shortcuts run \"Test Alert\"\n\nA: According the the shortcuts man page (man shortcuts) input to be passed must be a file or set of files:\n\nAn input file (or set of files) to be processed by the shortcut. Wildcards accepted.\n\nUnfortunately, you cannot pass a text object (a variable, for example) as an argument to the shortcuts command.  It has to be a file.\n", "Q: What's different between Command N or T on Safari? On Safari, when I type Command + N or Command + T, both shortcuts do same thing: Create a new tab and move to it.\nWhat's the difference?\nWhen should I use Command + N and Command + T?\n\nA: This is the behavior in full screen Safari and they are both the same. When in windowed mode ⌘CMDN opens new window.\nIf you want to open new window in full screen you have to press ⌘CMD⌥ALTN. This creates new full screen Safari window in a new Space.\n", "Q: How can I fit more things on my Mac Menu Bar? I have a MacBook Pro 16 inch, and because of the camera notch, I have very limited space on my Menu Bar (the top right part of the screen). Because of this, I can only see a handful of applications that use the menu bar. Just to name a few I have Dropbox, Caffeine, a bunch of iStat Menu icons, Scroll reverser, Alfred.\nThis has become really frustrating for me, for when say I want to turn on/off Caffeine but it is not present on my Menu Bar because it's hidden and I have to close other applications on my menu bar to see it.\nHow can I increase the space on my Menu Bar? On Windows I have a system tray where I can access my background running applications, does Mac have anything similar?\n\nA: For this I strongly recommend Bartender, which lets you hide most menu-bar items behind a little disclosure toggle, and selectively/temporarily show them based on various rules (e.g. show wifi only when disconnected, show dropbox only when syncing, show Carbon Copy Cloner only when there's an error).\n\n", "Q: Video player in browser turns black when using sidecar When I'm using my MacBook Pro 13\"(M1 chip, Big Sur) and my iPad Pro as sidecar screen, some players (for instance the Udemy website player) in any browser I have installed turn black while playing, although the audio works fine and all the controls are working fine. As soon as I disconnect from sidecar I can play the video with no issues. I've tried to google this issue, but no luck. Any idea?\n\nA: It's because of some video security measures that some streaming sites have. I've had this happen with almost all of them, including Udemy, Netflix and Disney Plus.\nFrom Udemy's customer support:\n\nDue to enhanced security measures on our platform, Udemy does not officially support video playback on externally connected monitors. That being said, we have found that video playback should function when plugging in a connector cord such as an HDMI cable directly from the monitor to your device (IE without the use of ports or docking stations).\n\n", "Q: When uploading a screenshot to Slack, it gets uploaded as a \"binary file\" I take a screenshot using Command Shift 4, then upload it to Slack, but it gets uploaded as a \"binary file\". I can download the file, but to open it, I need to add a \".png\" extension first.\n\nA: Solution was to enable \"Show all filename extensions\" in Finder preferences under Advanced, then relaunch Finder using the Force Quit window.\n", "Q: Is there a way to detect power state change from the command line? I would like to disable some power hungry services once I disconnect the power cord.  Was thinking of creating a launchd agent that can monitor a file and run a script.\nIf there are other ways of doing this without purchasing a separate app, that would be OK as well.  Although, preferred way would be to do it with existing macOS commands.\n\nA: You can use system_profiler to get this info.\n% system_profiler SPPowerDataType | grep -i “current power source” -B10\n\nYou will get the current power source and the relevant details.  For example, on my iMac, I get the following:\nAC Power:\n      System Sleep Timer (Minutes): 45\n      Disk Sleep Timer (Minutes): 10\n      Display Sleep Timer (Minutes): 10\n      Sleep on Power Button: Yes\n      Automatic Restart on Power Loss: No\n      Wake on LAN: Yes\n      AutoPowerOff Delay: 259200\n      AutoPowerOff Enabled: 1\n      Current Power Source: Yes.      <- This tells you this is the current power source\n      DarkWakeBackgroundTasks: 0\n      Display Sleep Uses Dim: Yes\n      Hibernate Mode: 0\n      High Standby Delay: 86400\n      PrioritizeNetworkReachabilityOverSleep: 0\n      Standby Battery Threshold: 50\n      Standby Delay: 86400\n      Standby Enabled: 1\n\n", "Q: Cannot log into my Mac because the password contains the symbols ¨^ I am using a MacBook Pro 16 2019 (MacOS 13.2) and a very funny problem.\nI created a new admin password that contains the symbols ¨^, but in the login screen I can’t introduce those symbols, because when I press the corresponding key no symbols appears. Because of this, I am unable to log into the device.\nThe symbols on my keyboard from Spain are done with the keys right to ñ and p (see the attached image) while holding down Shift, but I suppose that in different countries the combination may differ.\nI can't restore the admin password with my Apple ID because I have a firmware password to turn on the Mac, and I don’t remember that password. Without that password I cannot restore the admin password.\nWhat would be the best way to solve this?\nMore information about the symbols\nSymbol  ¨ [diaeresis]\nASCII code  249\nHTML entity &uml\nUnicode U+00A8\nSymbol  ^ [circumflex]\nASCII code  94\nHTML entity ^\nUnicode U+005E\n\n\nA: If you enabled SSH in the past (by default disabled), you could SSH into this Macbook and use the passwd command to reset your password from there.\n\nA: On a British English keyboard set to British or a US keyboard set to US English:\nDiaeresis is generated by  Opt ⌥   u  then  [space] \nCircumflex is generated by  Opt ⌥   i  then  [space] \nThis will not type a space afterwards, it's like adding an accent to a letter using a dead-key combo, but without adding a letter, so it adds only the accent with no letter under it.\nOn an English keyboard set to Spanish ISO (not Spanish, which can't do both symbols directly, as a far as I can see.) [From comments, this may have changed in Ventura, but I can't test.]\nDiaeresis is generated by  Shift ⇧   ' \n[marked single quote on UK English keyboard, 2 keys right of L]\nCircumflex is generated by  Shift ⇧   [ \n[marked left square bracket on UK English keyboard, 1 key right of P]\nSame physical locations as on a Spanish keyboard.\nBy the way, Macs don't use Windows-style ASCII codes at all.\n\nA: You may reset your password with: three times wrong password, then \"Reset Password using your Apple ID\". There is also a possibility in Recovery Mode (restart with Command+R or with M1-Chip hold the power button until you see \"options\")\n", "Q: Iphone Data Transfer: Same Number of Photos but Different Total Storage Context\nI am transferring all my data from an iphone X to iphone 14 pro.\nI was about to wipe the iphone X , when I did a last second comparison to make sure that the data was correct on both phones and noticed this anomaly:Same Number of Photos but Different Total Storage ( Please see photos attached)\n\n*\n\n*They both have optimize storage on\n\n*I looked at identical image and video sizes and they are the same for the 5 I looked at\n\n*There are a ton of images that are duplicates, specifically screenshots\n\nQuestion\nCould newer IOS 16 have the ability to downsample or detect the duplicates? If so, how would the image and video counts stay the same? What would cause the phone to truncate the photos by a third?\n\n\n\nA: As you have optimize storage enabled, the storage difference could be the result of the old phone having more photos downloaded in full resolution than the new one.\nOTOH, your iCloud storage is full so not all photos may have been uploaded. One way out of this is to increase storage, disable Airplane mode on the old phone and let it sync with iCloud again.\n\nA: It's not that IOS 16. can compress its locally stored photos and videos more efficiently than previous versions, not to the degree you're experiencing, it's that your new iPhone doesn't have as much storage that your previous model had.\nSince the transfer isn't complete yet you don't have all of your past photos and videos on your new phone, yet. Since your iCloud storage is full you would either have to backup the files you already have saved there elsewhere and then resume the backup via your iPhone. Or you could delete some apps or perhaps some other file on your new iPhone to free up some storage locally. If not, there's also the option of upgrading your subscription plan at Apple, so that you'll receive more cloud storage.\nUnless you're certain that your new iPhone should at least have the same, or a larger amount of storage room on your new iPhone? Then you should be able to just transfer the old data directly to your new iPhone and just skip the iCloud backup storage, for now at least. It's either a lack of storage on your new iPhone and on your iCloud, or that during set up a setting may have made switched so that it would prefer cloud over local storage.\n", "Q: Unable to fully uninstall Vim from Monterey I installed Vim using Homebrew, but I need to uninstall it.\nI ran brew uninstall vim, but for some reason I'm still able to launch vim from the Terminal. Even after trying to uninstall, vim --version shows that I have v8.2 installed and provides a list of included features in my install.\nwhereisvim gives me usr/bin/vim and usr/share/man/man1/vim.1 but I'm unable to delete the files from these directories. I've also checked in the Applications folder and the ~/Library directories but there aren't any files related to Vim.\nI'm new to this so any input would be greatly appreciated.\n\nA: /usr/bin/vim is the Apple supplied version.\nFor instance on my Ventura system:\n% /usr/bin/vim --version\nVIM - Vi IMproved 9.0 (2022 Jun 28, compiled Dec 16 2022 23:29:16)\nmacOS version - arm64\nIncluded patches: 1-981\nCompiled by root@apple.com\n.\netc, etc...\n\nreports Compiled by root@apple.com. It would be worthwhile verifying who built your remaining version. Note this cannot be uninstalled as it's part of the secure system volume.\n\nA: That’s the default VIM included with macOS\n/usr/bin/vim is the version of VIM that ships  with macOS.  In fact, you can browse https://opensource.apple.com/releases/ and scroll down to find Apple’s VIM project on GitHub\nIf you used brew uninstall vim then you’ve removed the VIM installed via said method.\nAnything in /usr/bin is on the read only portion of your system and thusly, you cannot delete anything from there.\n", "Q: 2019 15” MacBook Pro - USB-C port not loading One of my four USB-C ports is not loading.  I have done a soft reset, SMC reset, and zapped the NVRAM with no success.\nAny suggestions to get this fixed? \n\nA: To clarify; on the right side, the rear port is not working, while the forward port on the same side works  If this is the case, it sounds like the physical port itself failed.\nThere are two USB controller chips on these models MacBook Pro; one on each side controlling the two USB-C ports in it’s proximity.  If one of the ports fails while the other functions then the USB controller is functional.  This sounds like a failure of the physical port itself or some of the circuitry connecting the port to the controller.\nIf you wish or need to use this port and the other three are insufficient for your needs, then it will need to go in for service.  There’s no software fix for this.\n", "Q: RAID failure notifications I recently bought a Mac Mini to use as a NAS, among other things. I'm thinking about setting up a couple external drives as a RAID 1 (mirrored) set to help safeguard my data in case one of them goes bad. When a disk goes bad, how does the system notify you? Is there any way to be emailed or notified on my iPhone?\nI doubt I will be using a monitor with the computer very often and I'm afraid that a dialog box or notification will sit there for months, unnoticed, while I continue to use the drive over the network.\n\nA: From what I was able to find on Apple's discussion site (examples 1, 2, 3, 4), it appears that macOS Server (discontinued) has notification options for RAID failures but the normal consumer version of macOS does not. Instead, you can check the status yourself in Disk Utility or rely on a 3rd party tool.\nFor that reason, I've decided to return the Mac Mini (it hasn't even arrived yet) and get a Synology NAS instead.\n", "Q: SMB folder won't connect after Monterey upgrade PROBLEM...\n\n*\n\n*After upgrading to Monterey from Big Sur, my 2019 Intel Macbook Pro won't connect to an SMB share on my FujiXerox RIP (FXServer).\n\n*Nothing else has changed since running Big Sur on the same Macbook\nPro. This Macbook is connected via ethernet over a thunderbolt dock which has worked fine for years.\n\n*A 2013 Macbook Pro running Mojave on the same network has no issues. It's connected via an Apple TB 2 Ethernet adapter.\n\n*I usually connect by hitting CMD + K, double-clicking the share (smb://fxserver/SCAN) and /SCAN would mount with no login etc\n\n\nHAVE TRIED...\nSteps from this post: https://forums.macrumors.com/threads/smb-broken-with-monterey.2324371/post-30668058\n1\nAs noted above I added a nsmb.conf file to /etc containing the following...\n[default]\nprotocol_vers_map=6\n\nThen restarted but it keeps asking me for login credentials and failing (guest doesn't work either). This is just a scan folder from our FujiXerox RIP that requires no login. This is how the other Macbook Pro connects as well.\n2\nAs noted in the post above, I also tried adding signing_required=no to the conf file like this...\n[default]\nprotocol_vers_map=6\nsigning_required=no\n\nAnd restarted but still no joy.\n3\nI then tried adding port445=no_netbios as noted here: https://support.apple.com/en-us/HT211927\n[default]\nprotocol_vers_map=6\nsigning_required=no\nport445=no_netbios\n\nBut that wouldn't even attempt to connect so I removed it.\n4\nThis articles suggests checking the SMB version: https://lemp.io/how-to-check-smb-version-mac-os/\nBut when I run the command from the article, it doesn't seem to exist...\ndefaults read /Library/Preferences/com.apple.smb.server SupportedProtocols\n2023-02-17 16:05:16.412 defaults[2258:18483] \nThe domain/default pair of (/Library/Preferences/com.apple.smb.server, SupportedProtocols) does not exist\n\n5\nThis post suggested adding .local to the address: https://forums.macrumors.com/threads/update-resolved-brand-new-m1-macbook-pro-does-not-see-any-other-macs-or-network-drives-can-anyone-assist.2334034/post-30840040\nBut this didn't work: smb://fxserver.local/SCAN\n6\nThis post suggests a ktext is the culprit: Mac mini can't connect to my corporate SMB server. Was working some days ago\nBut I don't seem to have it installed unless I'm reading this wrong.\nkextstat | grep -iv apple\nExecuting: /usr/bin/kmutil showloaded\nNo variant specified, falling back to release\nIndex Refs Address            Size       Wired      Name (Version) UUID <Linked Against>\n\n7\nHave tried flushing the DNS cache using...\nsudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder\n\n8\nTried smb://fxserver.home/SCAN & smb://fxserver.local/SCAN as well as the IP address instead. No joy.\n9\nAlso tried shutting down, waiting a minute then restarting.\n\nQUESTIONS...\n1\nBecause no SMB supported protocols exist, does that mean that SMB is somehow not installed?\n2\nThis is a clean erase and upgrade to Monterey that's about a week old, do I need to enable SMB somehow?\n\nOTHER...\n\n*\n\n*Sorry, I'm not knowledgeable about SMB at all. This has worked\nautomatically for years without problems.\n\n*Nothing else with the network, printer, share, router has changed.\n\n*The other Macbook Pro running Mojave has no issues and before the\nupgrade from Big Sur, this Macbook had no issues either.\n\n*I'd previously hit CMD + K, double-click the share at\nsmb://fxserver/SCAN and the SCAN share would mount - no login\netc.\n\nSorry if I'm missing something basic, any help or suggestions much appreciated.\n\nA: Thanks to a pointer in the right direction by @user3071284 here are the exact steps to fix...\n\n*\n\n*Open Terminal\n\n*Run the following sudo nano /etc/nsmb.conf\n\n*Enter account password\n\n*Add the following text to the file as shown...\n\n[default]\nprotocol_vers_map=1\nsigning_required=no\n\n\n\n*Hit CTR + X\n\n*Hit 'Y' to save\n\n*In the Finder, hit CMD + K\n\n*Enter the server address e.g. smb://fxserver/SCAN\n\n*Connect as a guest (still can't get the registered user to work)\n\n", "Q: Script to run Apple Inbox Rules Note: I am not asking how to create a rule which runs an Applescript. I want to go the other way around: run a script that will apply existing rules to all the messages in the inbox. That is, simulate\n\n*\n\n*Select Inbox\n\n*Select All messages\n\n*Menu Message/Apply Inbox Rules\n\nI have ActOn rules that purge certain old messages, and I'd like a script I can set to run, say, nightly.\nEDIT: My Google search turns up only people doing this by hand or with Keyboard Maestro. Rather discourgingly, I don't see any verb exposed in the Apple Mail script dictionary to run the rules, only to make or edit them. (See screenshots.)\nIs this really so difficult?\n\nA: You don't really need the dictionary for this, as all the things you need to do are key-commandable. The only manual step is to deselect all afterwards [I can't, or am not willing to, test this script in action. I have some fairly complex rules plus some manual mail-shifting which a global Rules run will upset.]\nYou don't really need much more than\ntell application \"Mail\" to activate\ntell application \"System Events\"\n    keystroke \"1\" using command down --select inbox\n    keystroke \"a\" using command down --select all\n    keystroke \"l\" using {command down, option down} --run Rules\nend tell\n\nperhaps with some delays added to give it time to catch up.\nI haven't run this to test it, but it's simple enough syntactically & does compile correctly.\nAfter that all you need is a way to trigger it on time. You can do that by either keeping it constantly running & doing its own time check, or launching it from Calendar.\nSee Applescript run code at specific time and Softron - HOW TO: Trigger an AppleScript at specific date and time\nLittle trick to deselect everything in a mailbox when All are selected.\nCmd/click one mail, which will deselect it.\nClick the same mail again, will select it.\nCmd/click the same mail again, will deselect.\n", "Q: Using wallpaper shuffle with a set order (iOS) I want to use wallpaper shuffle to show a carousel of images, but they are being shown in a random order. This isn't very functional, is there any way to turn this off or make a shortcut?\nI'm using change on tap.\n\nA: \nI want to use wallpaper shuffle to show a carousel of images but mine is in a random order..\n\nIt’s working as expected.  Per Apple Support one of the Wallpaper options is a Photo Shuffle and provides instructions on how to create a gallery of photos to use.\nFrom Merriam-Webster, the definition of Shuffle:  to mix in a mass confusedly; jumble\nWhen you select Shuffle it will give you the items, in this case wallpaper images/backgrounds in random order.\n\nis there any way to turn this off\n\nNot presently.\n\nor make a shortcut\n\nIt definitely possible for a shortcut to rotate iOS wallpaper and there are many, many existing tutorials and articles on how to do so.\n", "Q: iPhone not detecting NFC tag I want to be able to open a link on my phone using an NFC tag.\nI brought some Timeskey NFC tags to do some tests.\nOn Android, I have no issue using NFC tools app I can read and write, on iPhone 12 nothing works.\nFirst I tried with an empty tag using NFC tools and my iPhone never detects the tag to read or write. Then I updated the tag to open a link but nothing happens, I tried with the phone locked and unlocked.\nThen I tried with an iPhone 13 and I have the exact same issue, I read some posts but on those phones seems that the NFC can not be disabled, the service is always listening.\nI contacted the NFC tag vendor, and they ensure me the tag is working with iPhone, but you know this is this typical product coming from a Chinese factory and no one know how it works in details. The tag type is ISO 14443-3A.\nI can not find any information on the Internet to know if there are only some tags compatible with iPhone or if there is some kind of special encoding for iPhone.\n\nA: The NFC tag must be NDEF formatted in order to work with the iPhone.\nAlso make sure that you do not have a cover on the iPhone preventing the tag from working. I would suggest testing without a cover at first - and make sure to place the tag directly against the antenna on the iPhone.\nAnd yes, only some tags are compatible with iPhone. The tag must be of NFC Forum Tag Type 1-5. This does cover some ISO 14443-3A tags.\n", "Q: With oh-my-zsh, ls hides the group field instead of showing colors I'm using Zsh on macOS Big Sur (11.7.4), and in my Terminal I am trying to look at ownership (user & group) of files in the current folder. I want to know the user as well as the group of my files using the ls -la command.\nIn the Bash shell on macOS, the command:\nls -la\nin the /Users/ folder returns:\ndrwxr-xr-x   5 root  admin   160 Jan  1  2020 .\ndrwxr-xr-x  20 root  wheel   640 Jan  1  2020 ..\n-rw-r--r--   1 root  wheel     0 Jan  1  2020 .localized\ndrwxrwxrwt  14 root  wheel   448 Feb 16 00:25 Shared\ndrwxr-xr-x@ 71 Danran   staff  2272 Feb 17 09:41 Danran\n\nThis clearly shows that the user of the /User/Danran folder is \"Danran\" and the group that it belongs to is \"staff\".\nHowever, when switching back to Zsh and entering the command ls -la on the /Users/ folder it returns:\ntotal 0\ndrwxr-xr-x   5 root  160 Jan  1  2020 .\ndrwxr-xr-x  20 root  640 Jan  1  2020 ..\n-rw-r--r--   1 root    0 Jan  1  2020 .localized\ndrwxrwxrwt  14 root  448 Feb 16 00:25 Shared\ndrwxr-xr-x+ 71 Danran  2272 Feb 17 09:47 Danran\n\nAs you can see, in the Zsh command, it only shows the user name, but does not show  the group name.\nMy question is, how can I get Zsh in macOS to show the username and  group name using the ls -la command, and if I can't, what command should I use in Zsh to list both users and groups of files and folders?\nUPDATE: The output of the alias command is:\n-='cd -'\n...=../..\n....=../../..\n.....=../../../..\n......=../../../../..\n1='cd -1'\n2='cd -2'\n3='cd -3'\n32x='ykr && rl && ssh 32x'\n32xroot='ykr && rl && ssh 32xroot'\n4='cd -4'\n5='cd -5'\n6='cd -6'\n7='cd -7'\n8='cd -8'\n9='cd -9'\nCA='2>&1 | cat -A'\nG='| grep'\nH='| head'\nHOMEBREW_NO_AUTO_UPDATE=1\nL='| less'\nLL='2>&1 | less'\nM='| most'\nNE='2> /dev/null'\nNUL='> /dev/null 2>&1'\nP='2>&1| pygmentize -l pytb'\nT='| tail'\n_='sudo '\nali='nano -c ~/.aliases'\nautobrewoff=export\nautobrewon=export\nbcubc='brew upgrade --cask && brew cleanup'\nbcubo='brew update && brew outdated --cask'\nbfu='brew upgrade --formula'\nbp='nano ~/.bash_profile'\nbrewp='brew pin'\nbrewsp='brew list --pinned'\nbrewup='brew update; brew upgrade; brew update --cask; brew upgrade --cask; brew cleanup; brew doctor'\nbrewup2='brew upgrade --cask --greedy; brew outdated --cask --greedy --verbose | grep -v '\\''(latest)'\\'' | awk '\\''{print }'\\'' | xargs brew cask reinstall'\nbubc='brew upgrade && brew cleanup'\nbubo='brew update && brew outdated'\nbubu='bubo && bubc'\nbubug='bubo && bugbc'\nbugbc='brew upgrade --greedy && brew cleanup'\nbuz='brew uninstall --zap'\ncaskup='brew cu --all'\nccat=colorize_cat\ncless=colorize_less\ncmds='cat ~/.aliases'\ncp='cp -i'\ndec2='ykr && rl && ssh dec2'\ndec2def='ykr && rl && ssh dec2def'\ndisks='diskutil list'\ndpr10='sudo gdd if=/dev/urandom of=/dev/rdisk10 bs=1M count=50 status=progress'\ndpr2='sudo gdd if=/dev/urandom of=/dev/rdisk2 bs=1M count=50 status=progress'\ndpr3='sudo gdd if=/dev/urandom of=/dev/rdisk3 bs=1M count=50 status=progress'\ndpr4='sudo gdd if=/dev/urandom of=/dev/rdisk4 bs=1M count=50 status=progress'\ndpr5='sudo gdd if=/dev/urandom of=/dev/rdisk5 bs=1M count=50 status=progress'\ndpr6='sudo gdd if=/dev/urandom of=/dev/rdisk6 bs=1M count=50 status=progress'\ndpr7='sudo gdd if=/dev/urandom of=/dev/rdisk7 bs=1M count=50 status=progress'\ndpr8='sudo gdd if=/dev/urandom of=/dev/rdisk8 bs=1M count=50 status=progress'\ndpr9='sudo gdd if=/dev/urandom of=/dev/rdisk9 bs=1M count=50 status=progress'\ndpz10='sudo gdd if=/dev/zero of=/dev/rdisk10 bs=1M count=50 status=progress'\ndpz2='sudo gdd if=/dev/zero of=/dev/rdisk2 bs=1M count=50 status=progress'\ndpz3='sudo gdd if=/dev/zero of=/dev/rdisk3 bs=1M count=50 status=progress'\ndpz4='sudo gdd if=/dev/zero of=/dev/rdisk4 bs=1M count=50 status=progress'\ndpz5='sudo gdd if=/dev/zero of=/dev/rdisk5 bs=1M count=50 status=progress'\ndpz6='sudo gdd if=/dev/zero of=/dev/rdisk6 bs=1M count=50 status=progress'\ndpz7='sudo gdd if=/dev/zero of=/dev/rdisk7 bs=1M count=50 status=progress'\ndpz8='sudo gdd if=/dev/zero of=/dev/rdisk8 bs=1M count=50 status=progress'\ndpz9='sudo gdd if=/dev/zero of=/dev/rdisk9 bs=1M count=50 status=progress'\ndr10='sudo gdd if=/dev/urandom of=/dev/rdisk10 bs=1M status=progress'\ndr2='sudo gdd if=/dev/urandom of=/dev/rdisk2 bs=1M status=progress'\ndr3='sudo gdd if=/dev/urandom of=/dev/rdisk3 bs=1M status=progress'\ndr4='sudo gdd if=/dev/urandom of=/dev/rdisk4 bs=1M status=progress'\ndr5='sudo gdd if=/dev/urandom of=/dev/rdisk5 bs=1M status=progress'\ndr6='sudo gdd if=/dev/urandom of=/dev/rdisk6 bs=1M status=progress'\ndr7='sudo gdd if=/dev/urandom of=/dev/rdisk7 bs=1M status=progress'\ndr8='sudo gdd if=/dev/urandom of=/dev/rdisk8 bs=1M status=progress'\ndr9='sudo gdd if=/dev/urandom of=/dev/rdisk9 bs=1M status=progress'\ndud='du -d 1 -h'\nduf='du -sh *'\ndz10='sudo gdd if=/dev/zero of=/dev/rdisk10 bs=1M status=progress'\ndz2='sudo gdd if=/dev/zero of=/dev/rdisk2 bs=1M status=progress'\ndz3='sudo gdd if=/dev/zero of=/dev/rdisk3 bs=1M status=progress'\ndz4='sudo gdd if=/dev/zero of=/dev/rdisk4 bs=1M status=progress'\ndz5='sudo gdd if=/dev/zero of=/dev/rdisk5 bs=1M status=progress'\ndz6='sudo gdd if=/dev/zero of=/dev/rdisk6 bs=1M status=progress'\ndz7='sudo gdd if=/dev/zero of=/dev/rdisk7 bs=1M status=progress'\ndz8='sudo gdd if=/dev/zero of=/dev/rdisk8 bs=1M status=progress'\ndz9='sudo gdd if=/dev/zero of=/dev/rdisk9 bs=1M status=progress'\nefi='sudo mkdir /Volumes/ESP && sudo mount -t msdos /dev/disk0s1 /Volumes/ESP/'\negrep='egrep --color=auto --exclude-dir={.bzr,CVS,.git,.hg,.svn,.idea,.tox}'\nej10='diskutil eject /dev/disk9 && echo \"Disk 10 Ejected.\" || \"Disk 10 NOT Ejected.\"'\nej2='diskutil eject /dev/disk2 && echo \"Disk 2 Ejected.\" || \"Disk 2 NOT Ejected.\"'\nej3='diskutil eject /dev/disk3 && echo \"Disk 3 Ejected.\" || \"Disk 3 NOT Ejected.\"'\nej4='diskutil eject /dev/disk4 && echo \"Disk 4 Ejected.\" || \"Disk 4 NOT Ejected.\"'\nej5='diskutil eject /dev/disk5 && echo \"Disk 5 Ejected.\" || \"Disk 5 NOT Ejected.\"'\nej6='diskutil eject /dev/disk6 && echo \"Disk 6 Ejected.\" || \"Disk 6 NOT Ejected.\"'\nej7='diskutil eject /dev/disk7 && echo \"Disk 7 Ejected.\" || \"Disk 7 NOT Ejected.\"'\nej8='diskutil eject /dev/disk8 && echo \"Disk 8 Ejected.\" || \"Disk 8 NOT Ejected.\"'\nej9='diskutil eject /dev/disk9 && echo \"Disk 9 Ejected.\" || \"Disk 9 NOT Ejected.\"'\nejefi='diskutil unmount /dev/disk0s1'\nfbox='ykr && rl && ssh fbox'\nfd='find . -type d -name'\nff='find . -type f -name'\nfgrep='fgrep --color=auto --exclude-dir={.bzr,CVS,.git,.hg,.svn,.idea,.tox}'\nflushdns='sudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder'\ng=git\nga='git add'\ngaa='git add --all'\ngam='git am'\ngama='git am --abort'\ngamc='git am --continue'\ngams='git am --skip'\ngamscp='git am --show-current-patch'\ngap='git apply'\ngapa='git add --patch'\ngapt='git apply --3way'\ngau='git add --update'\ngav='git add --verbose'\ngb='git branch'\ngbD='git branch --delete --force'\ngba='git branch --all'\ngbd='git branch --delete'\ngbda='git branch --no-color --merged | command grep -vE \"^([+*]|\\s*($(git_main_branch)|$(git_develop_branch))\\s*$)\" | command xargs git branch --delete 2>/dev/null'\ngbl='git blame -b -w'\ngbnm='git branch --no-merged'\ngbr='git branch --remote'\ngbs='git bisect'\ngbsb='git bisect bad'\ngbsg='git bisect good'\ngbsr='git bisect reset'\ngbss='git bisect start'\ngc='git commit --verbose'\n'gc!'='git commit --verbose --amend'\ngca='git commit --verbose --all'\n'gca!'='git commit --verbose --all --amend'\ngcam='git commit --all --message'\n'gcan!'='git commit --verbose --all --no-edit --amend'\n'gcans!'='git commit --verbose --all --signoff --no-edit --amend'\ngcas='git commit --all --signoff'\ngcasm='git commit --all --signoff --message'\ngcb='git checkout -b'\ngcd='git checkout $(git_develop_branch)'\ngcf='git config --list'\ngcl='git clone --recurse-submodules'\ngclean='git clean --interactive -d'\ngcm='git checkout $(git_main_branch)'\ngcmsg='git commit --message'\n'gcn!'='git commit --verbose --no-edit --amend'\ngco='git checkout'\ngcor='git checkout --recurse-submodules'\ngcount='git shortlog --summary --numbered'\ngcp='git cherry-pick'\ngcpa='git cherry-pick --abort'\ngcpc='git cherry-pick --continue'\ngcs='git commit --gpg-sign'\ngcsm='git commit --signoff --message'\ngcss='git commit --gpg-sign --signoff'\ngcssm='git commit --gpg-sign --signoff --message'\ngd='git diff'\ngd10='sudo gdisk /dev/disk10'\ngd2='sudo gdisk /dev/disk2'\ngd3='sudo gdisk /dev/disk3'\ngd4='sudo gdisk /dev/disk4'\ngd5='sudo gdisk /dev/disk5'\ngd6='sudo gdisk /dev/disk6'\ngd7='sudo gdisk /dev/disk7'\ngd8='sudo gdisk /dev/disk8'\ngd9='sudo gdisk /dev/disk9'\ngdca='git diff --cached'\ngdct='git describe --tags $(git rev-list --tags --max-count=1)'\ngdcw='git diff --cached --word-diff'\ngds='git diff --staged'\ngdt='git diff-tree --no-commit-id --name-only -r'\ngdup='git diff @{upstream}'\ngdw='git diff --word-diff'\ngf='git fetch'\ngfa='git fetch --all --prune --jobs=10'\ngfg='git ls-files | grep'\ngfo='git fetch origin'\ngg='git gui citool'\ngga='git gui citool --amend'\nggpull='git pull origin \"$(git_current_branch)\"'\nggpur=ggu\nggpush='git push origin \"$(git_current_branch)\"'\nggsup='git branch --set-upstream-to=origin/$(git_current_branch)'\nghh='git help'\ngignore='git update-index --assume-unchanged'\ngignored='git ls-files -v | grep \"^[[:lower:]]\"'\ngit-svn-dcommit-push='git svn dcommit && git push github $(git_main_branch):svntrunk'\ngithub='ykr && rl && ssh github'\ngk='\\gitk --all --branches &!'\ngke='\\gitk --all $(git log --walk-reflogs --pretty=%h) &!'\ngl='git pull'\nglg='git log --stat'\nglgg='git log --graph'\nglgga='git log --graph --decorate --all'\nglgm='git log --graph --max-count=10'\nglgp='git log --stat --patch'\nglo='git log --oneline --decorate'\ngloburl='noglob urlglobber '\nglod='git log --graph --pretty='\\''%Cred%h%Creset -%C(auto)%d%Creset %s %Cgreen(%ad) %C(bold blue)<%an>%Creset'\\'\nglods='git log --graph --pretty='\\''%Cred%h%Creset -%C(auto)%d%Creset %s %Cgreen(%ad) %C(bold blue)<%an>%Creset'\\'' --date=short'\nglog='git log --oneline --decorate --graph'\ngloga='git log --oneline --decorate --graph --all'\nglol='git log --graph --pretty='\\''%Cred%h%Creset -%C(auto)%d%Creset %s %Cgreen(%ar) %C(bold blue)<%an>%Creset'\\'\nglola='git log --graph --pretty='\\''%Cred%h%Creset -%C(auto)%d%Creset %s %Cgreen(%ar) %C(bold blue)<%an>%Creset'\\'' --all'\nglols='git log --graph --pretty='\\''%Cred%h%Creset -%C(auto)%d%Creset %s %Cgreen(%ar) %C(bold blue)<%an>%Creset'\\'' --stat'\nglp=_git_log_prettily\ngluc='git pull upstream $(git_current_branch)'\nglum='git pull upstream $(git_main_branch)'\ngm='git merge'\ngma='git merge --abort'\ngmom='git merge origin/$(git_main_branch)'\ngmtl='git mergetool --no-prompt'\ngmtlvim='git mergetool --no-prompt --tool=vimdiff'\ngmum='git merge upstream/$(git_main_branch)'\ngp='git push'\ngpd='git push --dry-run'\ngpf='git push --force-with-lease --force-if-includes'\n'gpf!'='git push --force'\ngpoat='git push origin --all && git push origin --tags'\ngpod='git push origin --delete'\ngpr='git pull --rebase'\ngpristine='git reset --hard && git clean --force -dfx'\ngpsup='git push --set-upstream origin $(git_current_branch)'\ngpsupf='git push --set-upstream origin $(git_current_branch) --force-with-lease --force-if-includes'\ngpu='git push upstream'\ngpv='git push --verbose'\ngr='git remote'\ngra='git remote add'\ngrb='git rebase'\ngrba='git rebase --abort'\ngrbc='git rebase --continue'\ngrbd='git rebase $(git_develop_branch)'\ngrbi='git rebase --interactive'\ngrbm='git rebase $(git_main_branch)'\ngrbo='git rebase --onto'\ngrbom='git rebase origin/$(git_main_branch)'\ngrbs='git rebase --skip'\ngrep='grep --color'\ngrev='git revert'\ngrh='git reset'\ngrhh='git reset --hard'\ngrm='git rm'\ngrmc='git rm --cached'\ngrmv='git remote rename'\ngroh='git reset origin/$(git_current_branch) --hard'\ngrrm='git remote remove'\ngrs='git restore'\ngrset='git remote set-url'\ngrss='git restore --source'\ngrst='git restore --staged'\ngrt='cd \"$(git rev-parse --show-toplevel || echo .)\"'\ngru='git reset --'\ngrup='git remote update'\ngrv='git remote --verbose'\ngsb='git status --short --branch'\ngsd='git svn dcommit'\ngsh='git show'\ngsi='git submodule init'\ngsps='git show --pretty=short --show-signature'\ngsr='git svn rebase'\ngss='git status --short'\ngst='git status'\ngsta='git stash push'\ngstaa='git stash apply'\ngstall='git stash --all'\ngstc='git stash clear'\ngstd='git stash drop'\ngstl='git stash list'\ngstp='git stash pop'\ngsts='git stash show --text'\ngstu='gsta --include-untracked'\ngsu='git submodule update'\ngsw='git switch'\ngswc='git switch --create'\ngswd='git switch $(git_develop_branch)'\ngswm='git switch $(git_main_branch)'\ngtl='gtl(){ git tag --sort=-v:refname -n --list \"${1}*\" }; noglob gtl'\ngts='git tag --sign'\ngtv='git tag | sort -V'\ngunignore='git update-index --no-assume-unchanged'\ngunwip='git log --max-count=1 | grep -q -c \"\\--wip--\" && git reset HEAD~1'\ngup='git pull --rebase'\ngupa='git pull --rebase --autostash'\ngupav='git pull --rebase --autostash --verbose'\ngupom='git pull --rebase origin $(git_main_branch)'\ngupomi='git pull --rebase=interactive origin $(git_main_branch)'\ngupv='git pull --rebase --verbose'\ngwch='git whatchanged -p --abbrev-commit --pretty=medium'\ngwip='git add -A; git rm $(git ls-files --deleted) 2> /dev/null; git commit --no-verify --no-gpg-sign --message \"--wip-- [skip ci]\"'\ngwt='git worktree'\ngwta='git worktree add'\ngwtls='git worktree list'\ngwtmv='git worktree move'\ngwtrm='git worktree remove'\nh=history\nhelp=man\nhgrep='fc -El 0 | grep'\nhidefiles='defaults write com.apple.finder AppleShowAllFiles -bool false && killall Finder'\nhistory='omz_history -f'\nhosts='sudo nano /etc/hosts'\nipinfo=$'echo \"Your current public ip address is... \\t\" && curl https://ipinfo.io/ip'\nkh='nano ~/.ssh/known_hosts'\nl='ls -lFh'\nl.='ls -d .* --color=auto'\nlS='ls -1FSsh'\nla='ls -lAFh'\nlanscan='arp-scan -l'\nlanscan2='arp -a'\nlart='ls -1Fcart'\nldot='ls -ld .*'\nlistcasks='brew search --casks --desc '\\'\\'\nll='ls -la'\nlr='ls -tRFh'\nlrt='ls -1Fcrt'\nls='ls -G'\nlsa='ls -lah'\nlsn='ls -1'\nlsr='ls -lARFh'\nlt='ls -ltFh'\nmaildel='echo '\\''d *'\\'' | mail -N'\nmailsaved='mail -f ~/mbox'\nmd='mkdir -p'\nmv='mv -i'\nnano='nano -c'\nnmap_check_for_firewall='sudo nmap -sA -p1-65535 -v -T4'\nnmap_check_for_vulns='nmap --script=vuln'\nnmap_detect_versions='sudo nmap -sV -p1-65535 -O --osscan-guess -T4 -Pn'\nnmap_fast='nmap -F -T5 --version-light --top-ports 300'\nnmap_fin='sudo nmap -sF -v'\nnmap_full='sudo nmap -sS -T4 -PE -PP -PS80,443 -PY -g 53 -A -p1-65535 -v'\nnmap_full_udp='sudo nmap -sS -sU -T4 -A -v -PE -PS22,25,80 -PA21,23,80,443,3389 '\nnmap_full_with_scripts='sudo nmap -sS -sU -T4 -A -v -PE -PP -PS21,22,23,25,80,113,31339 -PA80,113,443,10042 -PO --script all '\nnmap_list_interfaces='nmap --iflist'\nnmap_open_ports='nmap --open'\nnmap_ping_scan='nmap -n -sP'\nnmap_ping_through_firewall='nmap -PS -PA'\nnmap_slow='sudo nmap -sS -v -T1'\nnmap_traceroute='sudo nmap -sP -PE -PS22,25,80 -PA21,23,80,3389 -PU -PO --traceroute '\nnmap_web_safe_osscan='sudo nmap -p 80,443 -O -v --osscan-guess --fuzzy '\nodmt='telnet 149.28.125.6 25'\nodmtd='telnet mail.facl.xyz 25'\nofd='open_command $PWD'\np='ps -f'\npath='echo \"Your current path is\" && echo $PATH'\nprivdns=$'echo \"Your current private DNS Server is ...\\t\" && grep \"nameserver\" /etc/resolv.conf'\nprivip=$'echo \"Your current private IP Address is ...\\t\" && ipconfig getifaddr en0'\npsmo='curl -I -p https://www.mcmo.is'\npubip=$'echo \"Your current public IP Address is...\\t\\t\" && curl https://ipinfo.io/ip'\nrd=rmdir\nrl='source ~/.zshrc && echo \"File .zshrc reloaded correctly\" || echo \"Syntax error, could not import the .zshrc\"'\nrm='rm -i'\nrun-help=man\nsali='source ~/.aliases && echo \"File ~/.aliases reloaded (sourced) correctly\" || echo \"File ~/.aliases didn not reload (was NOT sourced) correctly. please check your syntax and try again.\"'\nsconf=' nano -c ~/.ssh/config'\nsgrep='grep -R -n -H -C 5 --exclude-dir={.git,.svn,CVS} '\nshowfiles='defaults write com.apple.finder AppleShowAllFiles -bool true && killall Finder'\nsortnr='sort -n -r'\nssl=ssllabs-scan\nst=speedtest\nstubbyconf='nano /usr/local/etc/stubby/stubby.yml'\nsurf='ssh surf'\nt='tail -f'\num10='diskutil unmountDisk /dev/disk10 && echo \"Disk 10 unmounted.\" || \"Disk 10 NOT unmounted.\"'\num2='diskutil unmountDisk /dev/disk2 && echo \"Disk 2 unmounted.\" || \"Disk 2 NOT unmounted.\"'\num3='diskutil unmountDisk /dev/disk3 && echo \"Disk 3 unmounted.\" || \"Disk 3 NOT unmounted.\"'\num4='diskutil unmountDisk /dev/disk4 && echo \"Disk 4 unmounted.\" || \"Disk 4 NOT unmounted.\"'\num5='diskutil unmountDisk /dev/disk5 && echo \"Disk 5 unmounted.\" || \"Disk 5 NOT unmounted.\"'\num6='diskutil unmountDisk /dev/disk6 && echo \"Disk 6 unmounted.\" || \"Disk 6 NOT unmounted.\"'\num7='diskutil unmountDisk /dev/disk7 && echo \"Disk 7 unmounted.\" || \"Disk 7 NOT unmounted.\"'\num8='diskutil unmountDisk /dev/disk8 && echo \"Disk 8 unmounted.\" || \"Disk 8 NOT unmounted.\"'\num9='diskutil unmountDisk /dev/disk9 && echo \"Disk 9 unmounted.\" || \"Disk 9 NOT unmounted.\"'\numefi='diskutil unmount /dev/disk0s1'\nunexport=unset\nuuid='python -c '\\''import sys,uuid; sys.stdout.write(uuid.uuid4().hex)'\\'' | pbcopy && pbpaste && echo'\nwhich-command=whence\nykr='gpg-connect-agent \"scd serialno\" \"learn --force\" /bye'\nyks='gpg --card-status'\nzrc='nano ~/.zshrc'\nzshrc='${=EDITOR} ${ZDOTDIR:-$HOME}/.zshrc'\n\nNEW DISCOVERY:\nI am using oh-my-zsh and have plugins enabled. By disabling oh-my-zsh plugins one by one, I have discovered that the command ls -la works properly in zsh when disabling the gnu-utils plugin for oh-my-zsh. Therein, the answer lies inside of the gnu-utils plugin, but I'm not sure which alias from oh-my-zsh is causing this.\n\nA: The ls command displays the group field by default. It doesn't matter what shell you invoke it from. If ls doesn't display the group field, it's because your shell configuration has an alias (or, in theory, a function, but in practice it's an alias) that adds an option to disable the group field.\nOn macOS, there are two plausible implementations of the ls command: the one provided by the system, and the one from GNU coreutils which many people install via one of Homebrew, Macports, etc. With the system ls, the option to turn off the group field is -o. With GNU ls, it's -o or -G or --no-group.\nWith macOS/FreeBSD ls, the option -G enables colored output. So the most likely explanation for not seeing the group field in ls output, and not seeing colors either, is that you have an alias ls='ls -G' with the intent to enable colored output, but ls is actually the GNU version.\nThe fix is to check the version of ls (and not just the operating system) when setting up the alias. For example:\nif ls --colors -d / >/dev/null 2>/dev/null; then\n  # ls is GNU ls\n  alias ls='ls --colors'\nelif ls --colors -d / >/dev/null 2>/dev/null; then\n  # GNU ls is often installed under the name gls\n  alias ls='gls --colors'\nelif ls -G -d / >/dev/null 2>/dev/null; then\n  # ls has a -G option, assume it means to display colors like on FreeBSD\n  alias ls='ls -G'\nfi\n\n\nOh-my-zsh has logic like what I showed above, but covering more cases, in lib/theme-and-appearance.zsh. But the logic isn't quite right for Darwin or FreeBSD: it assumes that ls is the system ls. If you've installed GNU coreutils in such a way that ls invokes the GNU version and not the system version, oh-my-zsh sets up the alias incorrectly.\nThis is a bug in oh-my-zsh, which can be triggered in two cases on macOS or FreeBSD:\n\n*\n\n*GNU coreutils (specifically ls) are installed under their default name (not with a g prefix) and come before /usr/bin in $PATH.\n\n*GNU ls is available as gls, but you have not set up a color theme for it (by setting the environment variable LS_COLORS or by having a ~/.dircolors file), and you're using the gnu-utils plugin.\n\nHere are some possible workarounds:\n\n*\n\n*Set up zsh on your own instead of using oh-my-zsh, which is complex and opinionated.\n\n*Use an oh-my-zsh theme that defines LS_COLORS, or define it yourself with dircolors. You can write a file `~/.dircolors`` and oh-my-zsh will read it for you.\n\n*At the end of ~/.zshrc, manually override the ls alias: if you're running into this problem, alias ls='ls --color' should work for you (as long as you don't share your .zshrc with systems where ls isn't GNU ls).\n\n", "Q: Displaying file name of desktop wallpaper on desktop I'm running Ventura (macOS 13.2) on an M1 MacBook Pro.  I typically use five desktops (spaces).  I have the desktop wallpaper on each to randomly change from a specified folder every hour.  Everything works.\nWhat I'd like to do is superimpose the file name of the wallpaper image on the desktop it's being displayed on.  I know this can be done, because the Particulars applet (freeware by Fraser Hess) does this, as does an older wallpaper manager, Change Desktop.\nI think I could use an AppleScript or Shortcut to get the file name, but I don't know how to display it (overlay) on the image.  Any ideas?\n\nA: You can use GraphicsMagick to add the filename to the image.\nBelow is a “one liner” that will get the job done.\nfor f in *.jpg; do bname=$(basename $f .jpg); \\\nfname=${bname}-wp.jpg; \\ \ngm convert $f xc:”white” \\\n-draw “text 10,10 ‘${fname}’ $fname; done\n\nI’ve separated the commands on different lines for readability.  You can put it all on one line by removing the backslashes.  You can also cut/paste as is and it will execute in your shell.\nThis command does the following:\n\n*\n\n*parses through all of the JPEG files (.jpg) in a directory.  If you use a different format (PNG, for example), just change the extensions as necessary\n\n\n*it obtains the basename of the file without the extension (bname)\n\n\n*it then creates a new filename (fname) with the “-wp” for “wallpaper” appended to it (Eg. image-wp.jpg)\n\n\n*the gm convert command draws the text, sourced from the variable fname in white at XY coordinates 10,10 on the image\n\n\n*it saves the new image leaving the original untouched.\n", "Q: How to suppress the connection sound when using the iPhone as webcam on my MacBook I would like to use my iPhone as webcam on my MacBook, but I haven't found a way to mute the sound on the iPhone when the camera is activated. Even when the iPhone is in silent mode, all sounds are switched off, the volume is set to zero and \"do not disturb\" is activated on my iPhone, it plays the same unnerving connection sound.\n\n*\n\n*Is there a reason for this behaviour?\n\n*Is it documented somewhere?\n\n*Are there MacBook settings that control the iPhone behaviour in this case?\n\n(I have iOS 16.3.1 on my iPhone SE and macOs Ventura 13.2.1 (22D68) on my MacBook Pro 16 inch, 2019.)\n\nA: This is a privacy indicator\nPer Apple Support document Choose your iPhone as your camera or microphone\n\nPrivacy. While the camera or mic is in use, a privacy indicator appears in the iPhone status bar and next to Control Center  in the Mac menu bar. When used wirelessly, iPhone plays a brief sound when an app begins using its camera or mic.\n\nEmphasis Mine\nSince there’s no visible LED like on the iSight camera, there needs to be a way to let you know that the camera has been activated. Since the iPhone can be used as a wireless microphone, it’s quite possible to activate it while in your pocket.  This is how you know it’s live.\nThere is no setting to disable this behavior.\n", "Q: Dock Hiding gets stuck - how to fix? Update 2: This problem is due to 3rd party software -- details at the bottom of this post\nI use dock \"hiding\" which is supposed to show the Mac OS dock only when the mouse is brought to that edge of the screen, and I've been having trouble with the dock sometimes getting \"stuck\" open rather than automatically hiding.\nBut until now, I've never been able to figure out why it gets stuck. I've tried solutions on some sites (such as this) which recommend using the Terminal killall Dock command or other solutions, but none of it has worked for me.\nAs the following screen capture shows, the problem I'm experiencing happens when the mouse is dragged to the edge of the screen and then slid along that edge. In my video the Dock is along the left edge, but similar things happen when it's placed at the bottom or on the right side of the screen.\n\nWhile recording this video I used software which shows mouse left clicks as red circles and keystrokes in a gray box at the upper left corner.\nAlthough I move the mouse pretty quickly, before each \"stuck\" event I have inserted a red arrow to show how the mouse is about to move to cause the problem.\nIt was hard for me to figure out how to reproduce this, so don't be surprised if you find it difficult to reproduce. As seen in the .gif, I have several failed attempts even with all my practice.\nTo get it unstuck requires moving the mouse back to the edge where the dock is, but I've also found that clicking twice on the control center menu bar item will get it unstuck. Using cmd-opt-D to hide/unhide does not help it get unstuck, and as you can see in the .gif no amount of clicking away from the dock helps.\nIs there a solution to this problem?\nUpdate: After @Tetsujin commented on an inability to get the Dock to pop up \"while the cursor is still moving\" I did some more tests. In the .gif below you can see that I am able to reproduce the problem even with a very slow moving cursor.\nI'm using MacOS 13.2.1 on a MacBook Air M1, 2020\n\nUpdate 2:  This problem is due to 3rd party software. Specifically, a feature called \"Hide Menu Icons\" within the \"Parallels Toolbox\" of the Parallels emulation software for Mac OS. I've posted a bug report on their site, but here is a screen capture demonstrating that the Dock gets stuck (1) when the \"Hide Menu Icons\" is turned on and (2) the Dock does not get stuck when the \"Hide Menu Icons\" is turned off and (3) the Dock gets stuck again when the \"Hide Menu Icons\" is turned back on. Thanks to @benwiggy\n\n\nA: It's possible that this is caused by some third-party software that is interfering with the UI, either by accident or by design.\nStarting in Safe Mode will disable any Launch Agents and Login Items: if this fixes the issue, you will have to narrow it down by testing combinations of your software.\nTesting a brand new user account is another way of pinpointing the source of the problem. If the problem persists, the cause is at the system level; otherwise it's something in the user domain.\n", "Q: How to configure shortcut too toggle keyboard light How to configure shortcut to toggle keyboard light on and off on MacBook Air M2?\nLike I am have set it to 20% and when I press shortcut it sets to 0%, then if I press the shortcut again it sets to 20% again(toggling).\nI am tired to enter setting, or open menubar thing to add 1% of keyboard backlight to type 10 words and then turn it back off. Any app for this situation?\n\nA: The keyboard backlight has a timer. No need for 'tiresome' shortcuts.\nSystem Settings | Keyboard | Turn Keyboard Backlight Off After Inactivity\nYour setting might be on 'never' by default.\n", "Q: Navigate in man intro I was checking the man intro command in the terminal, and the section \"SEE ALSO\". How do I access man(1) or intro(4) for example?\n\n\nA: You can't navigate within man, you need to access all man pages directly from the shell.\n\n*\n\n*man man for the manual page of the man command\n\n*man 4 intro for the intro page of section 4 (which is not installed, so ìntro(1)` is incorrect)\n\n*man 8 intro for the intro page of section 8\n\nPS: See https://en.wikipedia.org/wiki/Man_page#Manual_sections for an explanation of the various sections.\n", "Q: Does “Optimized Battery Charging” require “Location Services” to be enabled? My Mac is almost always connected to a powered Thunderbolt 3 dock and noticed battery cycle count is 48 and maximum capacity is 89% (lower than I expected after less than 2 years of use).\nDoes “Optimized Battery Charging” require “Location Services” to be enabled?\nFor privacy reasons, I typically disable “Location Services”.\n\nA: Yes, Location Services must be enabled.\nAccording to the Apple Support document, About Optimized Battery Charging on your iPhone, it specifically states that Location Services must be enabled\n\nMake sure that these settings are enabled:\n\n*\n\n*Settings > Privacy & Security > Location Services > Location Services.\n\n*Settings > Privacy & Security > Location Services > System Services > System Customization.\n\n*Settings > Privacy & Security > Location Services > System Services > Significant Locations > Significant Locations.\n\n\nOptimized battery charging “learns” your charging habits, for instance, you plug it in at overnight when at home.\n", "Q: What to do about iCloud messages to a phone I no longer have? Can I direct them to a new number? Some years ago, I had an iPhone. It was couple to my iCloud account along with my computers so that any text messages also showed up in the messaging app.\nI no longer have that phone or that number. All the people who used to send me text messages to that number are still sending them, and the messages appear on my Messages app but not my new Android phone. I've told them all that I have a new number, but they're using the Messages app on their iPhones and apparently can't change (I don't think they even see the phone number they're texting to.)\nThis is causing all sorts of problems, since someone sends me a text message and I don't see it until I get home and turn my computer on.\nIs there some way to forward these messages to my Android, or at least bounce the messages back? Is deleting my iCloud messaging completely my only recourse? Will even that work?\n\nA: You need to Deregister iMessage on your iPhone or online.\n\nIf you switched to a non-Apple phone and aren't getting SMS/MMS messages, you might need to deregister iMessage.\n\nThis is because iMessage can use multiple methods to message you including your phone number and email address. By deregistering, you’re telling the iMessage server you’re no longer reachable and thus should “bounce” the message sent to you.\n", "Q: Cannot disable F14 and F15 keyboard shortcuts controlling the brightness I read this question/answer: Disable F14/F15 for Brightness Control\nI have a different problem, I can see these options, I can check and uncheck them:\n\nBut even when the options are unchecked, F14 and F15 still control the brightness. What's wrong?\nI have the BetterDisplay tool, but I can't see additional keyboard shortcuts.\nI already have the standard F1 and F2 keys controlling the brightness, so F14 and F15 are really useless.\n\nA: I have found the solution. There was really an option to deactivate in the BetterDisplay tool settings:\n\n", "Q: How do I install Big Sur on a machine running Mavericks? I just erased an MBP 2014 that had been running the latest Big Sur to factory settings in preparation for migrating from another MPB running Big Sur, following the instructions provided by Apple. But the process has installed Mavericks and provides no way to install Big Sur.\nHow do I install Big Sur on a Mavericks machine? Can I just run Migration Assistant on the Big Sur (source) - Mavericks (destination) combo and end up with Big Sur on the destination? Is there some way to download a disk image to the Mavericks Mac that will work as an installer there?\n\nA: If using the various macOS Recovery options doesn't get you there, you should be able to upgrade to a more recent version of macOS from Mavericks.\nOnce you're up to El Capitan (or later) you then have the option of creating a bootable installer for macOS.\n", "Q: Is APFS more reliable than HFS+ for a network (sparse bundle) drive? I do Time Machine backups from my laptop to an SMB network drive. No doubt this is inherently unreliable because mounting a disk image over a network connection can result in the disk needing repair if either of the 2 machines turn off, fall asleep, or otherwise disconnect. I currently address this by using 'just-in-time' mount and unmount; and by relying on Alsoft DiskWarrior about once a year when something goes wrong and fsck can't fix it.\nMy question: I have kept the Time Machine image on HFS+ because DiskWarrior doesn't support APFS. But maybe APFS is a more robust design than HFS+ and would survive network disconnects? Does anyone know, or else how could I find out, other than by a 2-year experiment with my backups?\n\nA: Why not both? Even with HFS+ when a Time Machine destination has corruptions, it goes read only. I always have two destinations that I cycle in and out once a quarter or if I have a big change (major upgrade / major project / other big change about to happen) - I'll connect both and get dual backups.\nIn your case, make one of each. I'm all in on APFS for my destinations - ever forward. Thankfully, I haven't needed Disk Warrior / Drive Genius or other third party tool since before the transition started.\nSpare bulk drives are cheap, my time or a wrong guess aren't so I spend on resources to insulate me from a single failure on the backup side. Also I would consider a direct backup instead of network - they are more reliable in my testing and experience - but I'll assume you have a very good reason why network backup is your thing.\n", "Q: Erase Data from Uninitialised External HDD My HDD has most likely been damaged after one day of usage (WD MyPassport 2TB).\nIs there any way if I can erase it? I am pretty sure I have something on it.\nDisk Utility cannot do it, 69825 error, plus disk cannot be initialised.\n$ diskutil list\n...\n   /dev/disk2 (external, physical):\n   #:                       TYPE NAME                    SIZE       IDENTIFIER\n   0:                                                   *2.0 TB     disk2\n\nRunning diskutil erase does not help either:\n$ diskutil eraseDisk JHFS+ empty /dev/disk2\nStarted erase on disk2\nUnmounting disk\nCreating the partition map\nError: -69825: Wiping volume data to prevent future accidental probing failed\n\n\nA: System has read external hard drive, it seems that after running unmountDisk and waiting for few hours, drive was read, but interacting with it was far for perfect.\n", "Q: How can I access the higher function keys (F16 in particular) on a MacBook Pro? I'm toying around with DOSBox in debugger mode and it seems that in order to break into the debug mode while running I need to run Alt-Pause which on the Mac is Alt+F16 (see DOSBoxWiki: Special Keys). However, there is no F16 key on a MacBook Pro; if you hold Fn, you only get F1-F12.\nIs there some way to either remap a function key or to have access to the higher function keys? Even using the Accessibility keyboard, it doesn't seem to have obvious access to these keys.\n\nA: To remap a key, you can use the hidutil command.  In this example, I am remapping F16 to the ⌥ Option on the right side (probably not used much, if at all).\n\nhidutil property --set '{\"UserKeyMapping\": \\\n[{\\\"HIDKeyboardModifierMappingSrc\":0x7000000E6, \\\n\"HIDKeyboardModifierMappingDst\":0x70000006A}]}}\n\nThe backslashes (\\) allow for a multi-line command to facilitate better readability.  The command can be copied/pasted as-is or the backslashes and new-lines removed to make it a true one-liner.\nWhen you're writing the command, keep this in mind:\n\n*\n\n*Src = the key you want to press\n\n*Dst = what you want it to do\n\nI have supplied a portion of the Hex values for the extended function keys as defined in Apple Technical Note TN240 that describes how to use hidutil.\n\n\n\n\nKey\nHex Code\nKey\nHex Code\n\n\n\n\nKeyboard F13\n0x68\nKeyboard F19\n0x6E\n\n\nKeyboard F14\n0x69\nKeyboard F20\n0x6F\n\n\nKeyboard F15\n0x6A\nKeyboard F21\n0x70\n\n\nKeyboard F16\n0x6B\nKeyboard F22\n0x71\n\n\nKeyboard F17\n0x6C\nKeyboard F23\n0x72\n\n\nKeyboard F18\n0x6D\nKeyboard F24\n0x73\n\n\n\nImproving with a script...\nTo make this complex command easier to work with, I have created a simple Bash script (below) that will allow you to specify the source and destination keys as variables.\nI used a function, mdCMDStr, to \"make the command string\" so you can easily replicate additional commands with minimal effort.  Simply, reassign the SOURCE and DEST variables and call the mkCMDStr and hidutil commands as many times as necessary.\n#! /bin/bash\n\n\n\nfunction mkCMDStr () {\n# Creates the command string\n\n    SETKEY_CMD={\\\"UserKeyMapping\\\":[{\\\"HIDKeyboardModifierMappingSrc\\\":${1},\\\"HIDKeyboardModifierMappingDst\\\":${2}}]}\n\n}\n\nSOURCE=0x7000000E6      #Keyboard Right Option/Alt              \nDEST=0x70000006A        #Keyboard F16\n\nmkCMDStr $SOURCE $DEST\nhidutil property --set \"${SETKEY_CMD}\"\n\nexit\n\nDownload the Script\nThis will not persist through reboots.  You can make this \"permanent\" by putting this script in Login Items or creating a LaunchAgent.\n", "Q: How to switch between fullscreen apps with Control + Number shortcut? I have Macbook Pro Ventura 13.1 and I would like to know how to switch between fullscreen apps with keyboard shortcut e.g. Control + Number (As with Desktops, as how i3wm). What do I need to configure or to install to realise it?)\n\nA: You can't.\nFullscreen desktops have no number. They start from 'one to the right' of your current highest number, no matter what that is.\nIf you drag to re-arrange, they still don't fill a numbered Space, the numbers shift around them…\n\nYou can, of course, use  Ctrl ⌃   →  or  ←  but you'll need to start from a 'real' number nearby; or  Ctrl ⌃   ↑  to reveal all Desktops across the top of your screen [as in the partial image above], then click.\nOne of many reasons I never use fullscreen;)\n", "Q: Can't get original iPad Air to update from 10.2 to 12.5.7 I am trying to update an original iPad Air (FD786LL/A) from iOS 10.1.1 to 12.5.7, but the process keeps failing and I can't tell what the problem is. (It is a 32GB iPad with 5.73 GB free after downloading the update.)\nWhen it gets to \"Verifying update...\", it stalls for almost 10 minutes, then an error pops up \"Unable to Install Update  An error occurred installing iOS 12.5.7\"\nI have tried deleting and re-downloading the update; but, the same thing happens.\nIs there a way to get a more specific error message?\nIs there a way to update to iOS 11 instead of all the way to 12.5.7?  (Perhaps updating in steps will to better?)\n\nA: There is two possibilities for this to happen:\n\n*\n\n*Ipad Air 1st gen isn't supported by the update (Available for:      iPhone 5s, iPhone 6, iPhone 6 Plus, iPad Air, iPad mini 2, iPad mini 3, and iPod touch (6th generation)\n\n*You don't have enough storage space available.\n\nHope you'll find this helpful\n", "Q: Run a shell script having individual icon in dock Target\nRun a command line tool or script displayed with a specific icon in dock. A terminal window should not be displayed. I would like to use this to start octave with its gui.\nWhat I tried\n\n*\n\n*Automator\n\n*\n\n*Create an automator application and running a shell script.\n\n*Change its icon using finders file information window\n\n*I now have an individual application icon\n\n\n*\n\n*Result: After start, automator calls terminal and terminal icon appears in dock hosting my command line tool. My indiviual icon is not showing up in dock while running.\n\n\n\n*Shell script\n\n*\n\n*Create a shell script myapp.sh starting my command line tool.\n\n*Make executable with chmod u+x myapp.sh\n\n*Can not change icon at all using finders information window.\n\n\n*\n\n*Result: When clicking a terminal window is opened.\n\n\n\nPossible solutions\n\n*\n\n*Use a command line tool to change the icon of the currently running process?\n\n*Start terminal with a specific icon?\n\n*...?\n\n\nA: First locate your octave-gui Unix Executable file.  This is the path my version is located.\n/usr/local/Cellar/octave/7.3.0_3/libexec/octave/7.3.0/exec/x86_64-apple-darwin22.1.0/octave-gui\nThen in Finder, go ahead and change its icon in the Get Info window.\nNext, create a new Script Editor.app document and paste this following AppleScript code.\ndo shell script \"/usr/local/bin/octave --gui\"\n\n(I installed Octave using Homebrew in Terminal.app. After it was installed, to retrieve it's full path to use in the above AppleScript code, in Terminal, the command which octave... Returned its full path.)\nNext, save your new Script Editor document as an application.  (I saved my version as Launch_Octave.app)\nNow, anytime you run the Launch_Octave.app, both the Launch_Octave.app and octave-gui with its custom icon will appear in the Dock.\nHowever, you can hide the Launch_Octave.app from appearing in the Dock, so you can only see octave-gui with its custom icon appearing in the Dock by adding these two following lines to the Info.plist file within the Contents folder inside the Launch_Octave.app package. (Right click Launch_Octave.app in Finder and choose \"Show Package Contents\")\n<key>LSUIElement</key>\n<true/>\n\nAs you can see in this following animation, I am double clicking on the Launch_Octave.app located on my Desktop (which launches the octave-gui with its custom icon, which appears in the Dock while Launch_Octave.app does not appear in the Dock.\n\n", "Q: FreeForm app on mac and incosistent connection line arrow behavior I cannot figure out how connection line arrows work, when to use Start and End.\nHere you can see 3 connections to Help | Feature Request | Bug\n\nWith Help I had to use Start to put arrow in a correct place\n\nFor the other two had to use End\n\nI cannot figure out how these work and its driving me crazy.\nInitially I thought it was doing this based on the order in which I selected items, but no. Then I though order in which they were created, but still no.\n\nA: When a line is placed on the diagram it appears to regard the direction as left to right. So, without reshaping the line, start is left, end is right.\nTry setting end to an arrow, and then drag the endpoint to the 'to' object, and drag the un-arrowed start to your 'from' object. For your connections which are right to left you would need to drag the arrows around such that the direction of the line is reversed. Note you'd only need to do this if you were really concerned enough about your arrow heads matching the internal settings of the line.\n\nA: It depends on the relative positions of linked objects.\n\n", "Q: Can I have dual monitors on my MacBook Pro (Early 2011)? I have a MacBook Pro (13\") from Early 2011 and want to use 1 external monitor as extended monitor. When I connect my Xiaomi Redmi 1A 23.8\" Monitor in Mini Display Port Using HDMI to DP adapter. The new connected monitors appears under displays but not showing anything in it.\nIs there any way for me to have that displays work, I'm using macOS High Sierra 10.13.6 (17G14042)?\n\nA: The most likely cause of any problem is the adaptor. It's also the easiest/cheapest part to replace and test with alternatives.\nHowever, it's always possible that a 12-year-old computer won't be compatible with a much newer device, for whatever reason.\n", "Q: Typing 'ls' in iterm causing to tab to close I have been trying to customise my iTerm terminal using the steps in the following video:\nhttps://www.youtube.com/watch?v=0MiGnwPdNGE\nWhen opening a new quick window using the Control-’ on my Mac, if I type the ls command, it causes the Terminal to disappear. I've attached a screenshot of a popup that occurs before the widow disappears\n.\nI would appreciate any advice in working around this issue.\n\nA: \nWhen opening a new quick window ... if I type the ls command, it causes the Terminal to disappear.\n\nStart by Uninstalling OMZ (Oh-My-Zsh)\nWhy?  This open source framework causes more problems than it solves.  It doesn't really add anything but a flashy UI to a terminal screen.  From the OMZ main page:\n\nOh My Zsh will not make you a 10x developer...but you may feel like one!\n\nEmphasis Mine\nThere are tons of plugins and themes to supposedly make life easier and make looking at your Terminal screen more enjoyable.  Unfortunately, all these plugins, modifications to your Zsh startup files (i.e. .zshrc) can wreak havoc when trying to do things.  A simple command like ls shouldn't close a window.\nHere are some more recent examples:\n\n*\n\n*With oh-my-zsh, ls hides the group field instead of showing colors\n\n*Environment Variable $HOST Changes to My LAN IP Automatically\n\n*How to fix Mac terminal being incredibly slow after brew install tmux\nWhat's wrong with OMZ?\nThere's nothing wrong with it, if you know what you're doing.  If you're new -- and we all were at one time -- and you install OMZ, you take away the learning curve that comes with the experience of doing things manually at first.\nWe all want a fancy, colorized prompt; I fault nobody for that.  However, until you painstakingly learn how to create it, you won't understand what is happening when OMZ decides to flake out on you.  The same holds true for the Git, Python, and the myriad of other plugins available.  If you become dependent on OMZ, you'll find yourself in a difficult spot when things don't work or you find yourself on a system without this little helper.\nThis is not a \"knock\" on OMZ. But, keep in mind that OMZ is a community project where people contribute what works for them; it's massive ball of disparate pieces of yarn.  What works for you may be a tiny fraction of the OMZ framework.  It's best to start defining what you need specifically and making those customizations yourself.  As you gain experience, you'll be able to install and troubleshoot OMZ on your own, but then you won't need OMZ.\n", "Q: How to default file saving to phone (not cloud)? I recently downloaded a lot of files to the \"Files\" folder app on my iPhone that came with it (not an app installed). Unfortunately, this caused all the files to be put on the \"cloud\", not on my phone as I expected, resulting in (among other problems) with me being unable to access those files when my phone is not connected.\nHow do I make Files store files on my phone, not the cloud by default? (Also, now that they are on the cloud, how do I move them onto the phone and off the \"cloud\"?)\nI am using an iPhone 8 with iOS 16.\nPlease include step by step instructions. Pretend I'm stupid. Please don't just link generic instruction sites like the one from pcmag.com. They are old, useless and don't cover my use case. I need to get the files off the iCloud Drive and onto my local phone storage.\n\nA: If you are downloading via Safari, it is possible to change the default destination as follows:\n\n*\n\n*Open the Settings app\n\n*Scroll down and tap Safari\n\n*In the General section tap Downloads\n\n*Select On My iPhone to store downloads locally, or select Other to choose another more specific location\n\nNote: I assume you are downloading files through your browser, as other apps on iOS often bring up a prompt that lets you pick the location manually.\n\nAs for moving existing files from the cloud to local storage:\n\n*\n\n*Open the Files app:\n\n\n*Select the Browse tab on the bottom right\n\n\n*Starting under Locations, navigate to the files you wish to move\n\n\n*Tap the three dots in a circle on the top right\n\n\n*Choose Select\n\n\n*Select the files you wish to move\n\n\n*Tap and hold any of your selected files and do not let go until step 13\n\n\n*Once an options menu appears, drag your finger away until it is gone\n\n\n*Tap Done on the top right\n\n\n*If you have more files in other locations you wish to move:\na. Navigate to them with another finger\nb. Repeat steps 2 to 6 and 9 while continuing to hold your selected files\n\n\n*Select the Browse tab on the bottom right\n\n\n*Navigate to where you wish the files to be\n\n\n*Release the finger with the files you have been holding since step 7, doing so anywhere except onto a folder icon (as that would copy the files to that folder instead)\nNote: As of iOS 16.3.1 there is no way to move files between cloud and local storage - only copy. So you would need to delete files manually from the cloud to free up space.\n\nA: You could disable the iCloud folder:\n\n*\n\n*Click on the 3 dots : \n\n*Click on \"Edit Sidebar\" : \n\n*Disable the iCloud folder : \nThis is for disabling the default file adding to iCloud.\nHow to move files from iCloud to your local iPhone storage (also works for iPad):\n\n*\n\n*Click on the \"Select\" button : \n\n*Click on \"Move\" : \n\n*Click on \"On My iPhone\" : \nAnd now, it's normally moved to your local storage.\n\nHope this helps! :D\n", "Q: Looking for a way to read out Battery and PowerAdapter Information via ioreg I'm trying to collect information on power usage of our Apple (for now macOS only) devices. I came across some good posts and was already able to read out the AppleSmartBattery object via ioreg. That already would help me to determine if it is a laptop or a desktop model. But is is actually pretty hard to get more detailed information around the actual power drain. I'm less interested if a device runs on battery but actually more on the consumption if it is connected to a charger. I found the child object of PowerTelemetryData which contains a lot of interesting information but have no real clue how to interpret the data (reformatted for better readability).\n$ /usr/sbin/ioreg -rc AppleSmartBattery | grep PowerTelemetryData\n      \"PowerTelemetryData\" = {\n         \"WallEnergyEstimate\"=2305,\n         \"AccumulatedSystemPowerIn\"=28547763,\n         \"AdapterEfficiencyLossAccum ulatorCount\"=3586,\n         \"AccumulatedWallEnergyEstimate\"=9196925,\n         \"SystemInputVoltage\"=12145,\n         \"SystemPowerInAccumulatorCount\"=3586,\n         \"SystemEnergyConsumed\"=1987,\n         \"SystemPowerIn\"=7156,\n         \"SystemLoad\"=7576,\n         \"PowerTelemetryErrorCount\"=0,\n         \"AccumulatedSystemLoad\"=28544320,\n         \"SystemLoadAccumulatorCount\"=3587,\n         \"AccumulatedSystemEnergyConsumed\"=7928273,\n         \"AdapterEfficiencyLoss\"=318,\n         \"SystemInputCurrent\"=588,\n         \"AccumulatedAdapterEfficiencyLoss\"=1268652\n   }\n\nFrom what I can see there is already some items which are pretty interesting, e.g. WallEnergyEstimate, AccumulatedWallEnergyEstimate or SystemEnergyConsumed. But have no clue in what unit of measure these read outs actually are and couldn't find any (even non-official) documentation. Is there anyone that can help?\n\nA: And playing around with all the data it seems that it is pretty self-explanatory. For almost all values you might assume the prefix of milli – so  millivolt, milliampere, milliwatt.\n\n*\n\n*SystemInputCurrent is the currently measured current in milliampere\n\n*SystemInputVoltage is the currently measured voltage in millivolt\n\n*If you multiply those and divide by 1000 (to eliminate one milli) you get  roughly the value of SystemPowerIn measured in milliwatt\nAnd actually one of the most interesting fields is AccumulatedSystemEnergyConsumed which gives you the total amount of energy consumed measured in Joules. So actually dividing this by 3,600,000 will give you the amount of kWh your machine consumed since ??? (I guess it is ever).\nFound the answer – so closing this question. But will need to look for a different approach that also works on older macOS versions.\n", "Q: Making launchd agent uninstall itself I have a launchd agent which is a companion to another tool. When it runs, it checks if the tool is ready before proceeding. I want to add an extra case in which the launchd will also remove itself if the tool no longer exists.\nThis methodology is in use across a range of separate tools. As such, I make them as cookie-cutter as possible.\nI can tell the launchd agent plist to delete itself by adding its full path and editing it every time for every tool, but is there a better way? Is there (for example) a variable I could grab where the launchd returns its own name or path?\nAlso open to other methods which would allow a launchd agent to uninstall itself. It is important that it does not need to call a tool which does not ship with a standard installation of macOS, as that would defeat the point.\n\nA: \nI can tell the launchd agent plist to delete itself by adding its full path and editing it every time for every tool, but is there a better way?\n\nI am unaware of any launchd .plist setting/command that will allow it to \"delete itself.\"\nWhen your Mac boots and when you load a .plist, launchd scans (as applicable):  /Library/LaunchAgents, ~/Library/LaunchAgents, /Library/LaunchDaemons, /System/Library/LaunchAgents and /System/Library/LaunchDaemons.  If the .plist isn't there, it doesn't load.\nSo, if you \"check to see if the tool exists and remove itself\" you'll need to incorporate that logic as part of the script that's kicked off by launchd.\n\nIs there (for example) a variable I could grab where the launchd returns its own name or path?\n\nlaunchd doesn't return \"its own name or path;\" it loads/unloads/launches/stops a job defined by a .plist at a path.  Therefore, if you want that variable to be available, you'll need to set it as part of the environment defined in the .plist.\nThat said, I don't believe it possible that you can both have a job running and simultaneously unload it especially by itself; more so if it requires elevated privileges to do so.  This is probably why install/uninstall requires user intervention.\nAdditionally, per the man page for launchd.plist it addresses agents/daemons accessing \"protected\" files/folders:\n\nCAVEATS\nDaemons and agents managed by launchd are subject to macOS user privacy protections. Specifying privacy sensitive files and folders in a launchd plist may not have the desired effect, and may prevent the job from running.\n\nBy having an agent call a script that in effect deletes itself (from one of the directories listed above) may have unintended consequences and may not even run.\n", "Q: Does the MacBook Pro M2 2023 charge >100W (140W, FastCharge) via the USB-C ports? On the M1 MacBook Pros charging via the USB-C ports if only up to 100W (USB PowerDevlivery 20V 5A)\nHwr, did they improve it on the MBP M2 2023, so you could also FastCharge (140W - USB PD 28V 5A) via one of the USB-C Ports? Or still just via MagSafe3?\n\nA: You can only FastCharge using MagSafe 3 at 140 W\nApple doesn't mention nor offer FastCharge only using USB-C port.\nHere is a screenshot from Apple's Fast Charge informations :\n\nSee also this from Macworld https://www.macworld.com/article/819438/best-macbook-usb-c-charger.html\n\nOn the 16-inch MacBook Pro, you can only fast-charge with Apple’s 140W USB-C Power Adapter paired with the USB-C to MagSafe 3 Cable. Apple, Anker and UGreen are the only companies to make a power adapter that supports the latest PD 3.1 standard that supports power output to up to 240W; other USB chargers have a practical maximum of 100W.\n\n\nA: The MacBook Pro M2 has two Thunderbolt/USB4.  USB4 mandates PD (Power Delivery Specification) which version 3.1 allows for charging up to 240W (48V x 5A).  However, to achieve this, you must have a specific USB4 PD cable which is specially marked as such.  The charger must also conform to the 3.1 PD spec for this to work.\nSo, in short, you can get both charging speeds from the USB4 port and from the MagSafe3 adapter.\n", "Q: How to undo iPhone slo-mo on a video? When recording a video in slo-mo in iPhone, it is saved so that the first x seconds are regular speed, then it smoothly transitions to the slow-motion speed, then near x seconds from the end of the video it smoothly transitions back to regular speed.\nWhat method can I use to turn a slow-motion iPhone video sent to me from someone else back into a regular-speed video all the way through?\nSimply multiplying the video speed by 4 using regular methods won't cut it because of the regular speed parts at the start and end, and smooth transitions in-between them.\n\nA: That depends on how the video was sent to you. If the slow motion is \"baked-in\" to the video you currently have, it will be hard and you will need video editing software to do it.\n\"Baked in\" means instead of the e.g. 120FPS you film a slow motion video at the video is played at 60FPS.\nThe iPhone automatically plays the first and last part of the video at double the speed and all the rest at normal 60fps.\nThis is where the slow motion effect comes from.\nIf you received the Video via WhatsApp or some App that transcodes the video to compress it (so that it does not take up as much data when being sent to you) this app will have baked in the slow motion parts.\nYour best option is to ask the person who took the video if they could AirDrop the original file or sent it to you via iCloud Link or some App that does not tamper with the video in any way.\nThis way you will have the video in full quality and you can choose where you want slow motion and where not.\n", "Q: How to install a fresh macOS on an iMac with a new hard disk? I have an old iMac with a brand new disk (completely empty). I do not have the old disk, I just have the new one. Of course, now it can't boot, and the flashing folder with the question mark appears. I need to install a new MacOS (e.g., Mountain Lion?). I have tried the internet recovery, but it's running for more than 30minutes now, and I'm afraid it'll end with an error.\nThe second option is creating a bootable USB on another Mac running Ventura. However, when I download the file InstallMacOSX.pkg, it looks like I can't create a bootable of Mountain Lion from such a file on Ventura.\nWhat can I do?\nUPDATE: the Internet Recovery gave the following error:\napple.com/support -21 06U\n\nA: I`d say try the Internet recovery. It should download everything and install it. And it might take MUCH longer than 30 minutes. Just give it a try.\nApart from that, your best option might be to create a bootable USB on a different Mac. Here are the steps you can follow to create a bootable USB for Mac OS X:\n\n*\n\n*Make sure you have a USB drive with at least 8GB of storage\navailable.\n\n\n*On the other Mac, open the App Store and download the OS X you need.\nYou may need to purchase it if it's not already associated with your\nApple ID.\n\n\n*Once the download is complete, the installer will automatically\nlaunch. Quit the installer and make sure it's located in the\n/Applications folder.\n\n\n*Open the Terminal application (located in /Applications/Utilities/)\non the other Mac.\n\n\n*Type the following command into Terminal: sudo /Applications/Install\\ OS\\ X\\ YOUR_OS_X_NAME.app/Contents/Resources/createinstallmedia --volume /Volumes/Untitled --applicationpath /Applications/Install\\ OS\\ X\\ YOUR_OS_X_NAME.app --nointeraction\n\n\n*The process will take several minutes to complete. Once it's\nfinished, you'll have a bootable USB drive.\n\n\n*Insert the USB drive into your Mac and hold down the Option key\nwhile powering on your Mac. This will bring up the startup manager.\n\n\n*Select the USB drive from the list of available startup disks, and\nthen follow the on-screen instructions to install OS X.\n", "Q: Automator run shell script does not know my PATH? When I use the \"run shell script\" in automator, and do, for example\nsay $PATH\n\nit then tells me the PATH. But the path is incomplete. Some items I have in $PATH when using the terminal (zsh) are missing.\nHow can I fix this, so I have the same $PATH variable everywhere?\n\nA: There are two different shells - interactive and non-interactive.  They behave just like they are described - interactively and non-interactively.\nIf you set your path in .zprofile, for example, anything you do in Terminal will have the path you set.  However, a non-interactive shell (like when run from Automator) won’t read .zprofile so any variables like PATH won’t be set.  I suggest using .zshenv or setting the path manually in your shell script.\nSee ZSH: .zprofile, .zshrc, .zlogin - What goes where? for a full description of what should go where when setting paths.\n\nA: As Allan said, the shell environment variables, such as $PATH, are typically set in the shell configuration files (e.g., ~/.bashrc or ~/.zshrc). However, when you use Automator's \"run shell script\" action, it does not necessarily load your shell configuration files, which may result in a different $PATH variable than what you have in your terminal.\nTo ensure that you have the same $PATH variable in Automator's \"run shell script\" action as in your terminal, you can explicitly set the $PATH variable in your script. You can do this by adding the following line at the beginning of your shell script:\nexport PATH=\"$PATH:/your/additional/path/here\"\n\nThis command sets the $PATH variable to the existing value of $PATH (represented by \"$PATH\") plus any additional directories you want to add (separated by colons).\nAlternatively, you can source your shell configuration file at the beginning of the script by adding the following line:\nsource ~/.zshrc\n\nThis command sources your ~/.zshrc file, which will set the $PATH variable to its proper value.\nBy doing either of these, you can ensure that your \"run shell script\" action in Automator has the same $PATH variable as your terminal.\n", "Q: Macbook Air M1 - how is this display spare part called? I broke my display by closing it while something was left in the gap between body and display. There seems to be some sort of sticker covering the lower part of the display and I wonder if this is available as a spare part?\n\n\nA: That part is called a bezel.\nYou could try authorized repair shops or the secondary market (eBay) for a part like this but since these MacBooks are so new, it’s unlikely to be a very common part.\nIt also appears to be adhered to the glass assembly so you may have to replace the entire display to effect that repair.\n", "Q: PDF icon after unzipping changes I was recently sent a PDF file obtained by scanning some paper sheets with the software CamScanner (File.pdf). I noticed that the top right corner of the Desktop icon was not fully bent and it looks like only the first page of the document had been angled (see photo below). Instead, if I compress the file and open it the corner is now fully bent.\nAt the same time, the left-hand black strip on the icon disappears.\nI'm assuming there's something changing in the format or encoding but I have no idea what it is happening to the file. Does anyone know what this means?\nI'm working on a macOS Ventura 13.2.1 if that helps in any way. Thanks!\nEDIT: The original file is not accepted for submission in the TurnitIn online platform while the other one is, so something in the metadata must have changed as pointed by @Xenonite. Still, the change in the black strip perhaps is the most obvious difference and I don't know what that represents.\n\n\nA: It is possible that the differences you are seeing in the PDF file icon are due to changes in the file's metadata or thumbnail preview. When a file is compressed, its metadata and thumbnail preview are typically updated to reflect the new file size and format.\nIn the case of your PDF file, it's possible that the compression process caused the metadata or thumbnail preview to be updated, resulting in the changes you observed in the file icon. However, the actual content of the PDF file should not be affected by the compression process.\nIt's also possible that the differences you observed in the file icon are simply due to visual artifacts or inconsistencies in how the icon is displayed by your operating system. This can sometimes occur when working with files that were created or edited on different platforms or software applications.\nIf you want to verify that the content of the PDF file has not been affected by the compression process, you can try opening both the original and compressed versions of the file and comparing them side-by-side. If the content appears identical, then it's likely that the differences you observed in the file icon are simply due to metadata or display issues.\n\nA: Some time ago, Apple changed the preview icon for PDFs, so that multi-page PDFs show a 'binder' on the left edge, and pages shown behind the corner fold of the first page.\n\nNote that content from page 2 will actually show where the corner fold is.\nA single page PDF has no binder and no pages behind the fold.\nWhy you get the single-page icon for the second file (if it's identical), I cannot explain. It may simply be that after un-zipping, the file is still being processed by Spotlight/QuickLook.\n", "Q: /dev/disk/by-id on macOS? Suppose that we are doing some operations on drives using for example diskutil. Usually we use /dev/diskX to indicate which drive we are working on, but the number X could change next time we connect the drive to computer, so we have to look at and check the number X again and again. On Linux we have /dev/disk/by-uuid. How could we get this on macOS?\n\nA: Use the following command to obtain the UUID of a disk:\ndiskutil info diskX | awk '/Volume UUID:/ {print $5}'\n\nThis will give you the Disk / Volume UUID (I omitted the “Disk” portion in the awk statement for simplicity).\nOne you have that, you can utilize it with diskutil:\ndiskutil info XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n\nI tested this with a WD USB external drive and it worked as expected.\nCaveats\n\n*\n\n*APFS drives: The synthesized drive must be referenced.  Example:  /dev/disk5 is the physical drive and /dev/disk6 would be the synthesized drive.\n\n\n*HFS/HFS+ on GPT: A partition/slice must be referenced. Example:  /dev/disk5s1 will give you the first partition of the drive.  Alternatively, you can obtain the partition UUIDs with the command:\nsudo gpt show diskX | awk '/GPT\\ part\\ -/ {print $3 \"--\" $7}'\n\nAnd you will get the UUIDs of the partitions by index:\n1--XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n2--YYYYYYYY-YYYY-YYYY-YYYY-YYYYYYYYYYYY\n\n\n\n*MS-DOS on GPT: The drive or partition can be referenced. Examples:  /dev/diskX or /dev/diskXsN\n\n\n*MS-DOS on MBR: There is no Disk UUID available.  However, you can obtain the Volume UUID with the command:\ndiskutil info diskXsN | awk '/Volume\\ UUID:/ {print $3}'\n\n\n\n*HFS/HFS+ on MBR: Same as MS-DOS on MBR.\n\nA: There's no /dev/disk/by-uuid folder structure in macOS.\nmacOS uses UUIDs for internal structures within a physical disk, such as a partition (equatable to an APFS container or HFS+ partition), or an APFS volume. The best you can do is to identify a physical device after connection by the structures it contains, rather than anything associated with the physical device itself.\nThe device specification in diskutil sub-commands will accept a UUID as an argument. Check man diskutil and search for DEVICES for all the accepted device identifiers.\nYou can retrieve the UUID for a particular container or volume by using eg. diskutil info disk5 and grepping for the Disk / Partition UUID, or Volume UUID.\nUnfortunately I don't think there's any switch to make diskutil list output the UUID. However, you can use diskutil apfs list which will also output UUIDs for APFS containers and volumes.\n\nA: df | grep \"/dev/\" | awk '{print $NF \" = \" $1}'\n\nis one way to map the names of the volumes to their device IDs.  The name of the volume ($NF) will not change until a user or script changes it.  A sed or perl (etc.) regex can remove the slice ID if needed: s:(/dev/disk\\d+)s\\d+:\\1:\n", "Q: How to save input of `less` to file as explained in the man doc? I'm trying to save the piped input to less to a file as explained in the man doc:\ns filename\n      Save the input to a file.  This only works if the input is a pipe, not an ordinary file.\n\nHowever, when I hit s, instead of a prompt opening, the line just scrolls down as if I had hit j.\nI'm using the version of less that comes with macOS:\n$ less --version\nless 581.2 (POSIX regular expressions)\nCopyright (C) 1984-2021  Mark Nudelman\n\nless comes with NO WARRANTY, to the extent permitted by law.\nFor information about the terms of redistribution,\nsee the file named README in the less distribution.\nHome page: https://greenwoodsoftware.com/less\n\n\nA: This feature seems to have been introduced in a more recent version than the one installed out of the box, at the moment.\nInstalling a current release using\nbrew install less\n\nand restarting my shell fixed it.\nNow I'm on version 608 as opposed to 581.2\n$ less --version\nless 608 (PCRE2 regular expressions)\nCopyright (C) 1984-2022  Mark Nudelman\n\nless comes with NO WARRANTY, to the extent permitted by law.\nFor information about the terms of redistribution,\nsee the file named README in the less distribution.\nHome page: https://greenwoodsoftware.com/less\n\nNow, when I hit s I get a prompt of log file: to type the file I want to save to.\n", "Q: How can I take a screenshot and then send it in an email with Automator? I run some tests on my Mac that take several hours.  When the tests are done, I want to send myself an email with a screenshot of the test results.\nHere is how I configured my Automator App:\n\n*\n\n*New mail message (to me, subject: tests done, message: here are the results)\n\n*Take screenshot (type: full screen, main monitor only, save to Desktop: latest-test-results)\n\n*Add attachments to front message\n\n*Send outgoing message\n\nThis doesn't work because when the screenshot is taken, the Mail app is already open and covering Terminal, which is showing the test results.\nSo I next tried this:\n\n*\n\n*Take screenshot (type: full screen, main monitor only, save to Clipboard)\n\n*New mail message (to me, subject: tests done, message: here are the results)\n\n*Get contents of clipboard\n\n*Add attachments to front message\n\n*Send outgoing message\n\nFor some reason, this action sends me an attachment that is a zip file containing the files on my desktop, but not the screenshot, which is apparently not saved to the desktop.  I don't want a zip file; I want the actual screenshot, and obviously I don't want all the files on my desktop.\nThis seems like a simple task... what am I doing wrong?  I want to take a screenshot and then email it to myself.  The Automator app is triggered through a bash script that runs the tests.\nmacOS Ventura.\n\nA: So, I configured it as such, and it worked. It's saving to a file called \"test\". You could trash it after sending if you wanted too. This is all in automator, but if you're wrapping it in bash you could use the screencapture command to capture the image first, then trigger the automation to send it. Something like:\nscreencapture ~/desktop/out.png\n\nHere's the working config:\n\nThis produced this email (I had this question up in Safari), and you can see that it's not covered with the email window:\n\n", "Q: How to restore default user permissions (MacOS 13 Ventura) Background\nI have 3 Macs at home, all running MacOS 13 Ventura. All of these Macs are running on relatively new computers but the systems have been passed on via Migration Assistant/Time Machine backups since the beginning of the ~2010s (OSX Snow Leopard & Lion).\nI recently discovered the user permissions on these Macs probably are wrong (i.e they are not the default permissions). I'm not sure why that is, but it may be that I changed things due to ignorance far back in the past, or migrations, etc, may have altered things.\nRationale: I'm concerned for security reasons, and additionally while I haven't had much issues with these Macs, one issue is when attempting to use File Sharing over the local network, I can see folders loading on the remote Mac but no files therein will load (I just see a spinning wait cursor and the text \"Loading…\") – unless if I specify particular folders and users to share to, which shouldn't be necessary given that I'm authenticating myself with an administrator user on the target Mac – which is why I started to suspect that permissions might be erroneous.\nQuestion\nShould I, and if so, how can I restore or apply Apple default user permissions, without having to erase my systems and recreate them from scratch? (Assuming that this is a good idea?)\nSIP is activated, and as mentioned I am running the latest MacOS version as of February, 2023 – therefore many old Ask Different answers may not apply.\n\nAdditional info\nOn one of my Macs, I created a new administrator user (named test) to see what the default permissions are for common Home folders. WARNING: I can't guarantee that these are correct for an entirely fresh system, this is just what I happen to see on a new user on a non-factory restored Mac – please do not attempt to replicate:\n\n*\n\n*Mac #1\n\n*\n\n*test (New test user):\n\n*\n\n*~ (Home folder test)\n\n*\n\n*test (me): Read & Write\n\n*staff: Read only\n\n*everyone: No Access\n\n\n\n*~/Desktop, ~/Documents, ~/Downloads, ~/Library:\n\n*\n\n*test (me): Read & Write\n\n*everyone: No Access\n\n\n\n*~/Library:\n\n*\n\n*test (me): Read & Write\n\n*everyone: No Access\n\n\n\n*~/Public:\n\n*\n\n*test (me): Read & Write\n\n*staff: Read only\n\n*everyone: Read only\n\n\n\n*Macintosh HD/Applications\n\n*\n\n*system: Read & Write\n\n*admin: Read & Write\n\n*everyone: Read only\n\n*NOTE: These Applications groups look strange to me. Since they are shared by all users on the computer it's possible that they aren't the default Apple permissions. My other Mac does instead of system: Read & Write and admin: Read & Write, have user (me): Read & Write and staff: Read only.\n\n\n\n\n\n\n\nFollowing are settings on my actively in-use accounts on my Macs.\nNoteworthy: in some folders I see peculiar users called: com.apple.sharepoint.group.1 com.apple.sharepoint.group.2, com.apple.sharepoint.group.3, and Fetching… (a spinning wait cursor and contents that don't load) – these have \"Custom\" permissions!\n\n*\n\n*Mac #1\n\n*\n\n*user (Old user):\n\n*\n\n*~ (Home folder user)\n\n*\n\n*user (me): Read & Write\n\n*staff: Read only\n\n*everyone: Read only (No Access on test)\n\n\n\n*~/Desktop, ~/Documents, ~/Downloads\n\n*\n\n*user (me): Read & Write\n\n*everyone: Read only (No Access on test)\n\n\n\n*~/Library:\n\n*\n\n*user (me): Read & Write\n\n*everyone: No Access\n\n\n\n*~/Public:\n\n*\n\n*user (me): Read & Write\n\n*staff: Does not exist at all (staff: Read only on test)\n\n*everyone: Read only\n\n\n\n*Macintosh HD/Applications\n\n*\n\n*system: Read & Write\n\n*admin: Read & Write\n\n*everyone: Read only\n\n\n\n\n\n\n\n*Mac #2\n\n*\n\n*user (Old user):\n\n*\n\n*~ (Home folder user)\n\n*\n\n*user (me): Read & Write\n\n*staff: Read only\n\n*everyone: Read only (No Access on test)\n\n\n\n*~/Desktop, ~/Documents, ~/Downloads\n\n*\n\n*user (me): Read & Write\n\n*staff: Read only (staff does not exist here on test)\n\n*everyone: Read only (No Access on test)\n\n\n\n*~/Library:\n\n*\n\n*user (me): Read & Write\n\n*everyone: No Access\n\n\n\n*~/Public:\n\n*\n\n*com.apple.sharepoint.group.1: Custom (I don't know what this is!)\n\n*user (me): Read & Write\n\n*staff: Does not exist at all (staff: Read only on test)\n\n*everyone: No Access (Read only on test)\n\n\n\n*Macintosh HD/Applications\n\n*\n\n*system: Read & Write\n\n*admin: Read & Write\n\n*everyone: Read only\n\n\n\n\n\n\n\n*Mac #3\n\n*\n\n*user (Old user):\n\n*\n\n*~ (Home folder user)\n\n*\n\n*com.apple.sharepoint.group.2: Custom (I don't know what this is!)\n\n*Fetching…: Custom (I don't know what this is. Doesn't load properly – shows a spinning wait cursor!)\n\n*user (me): Read & Write\n\n*staff: Does not exist at all (staff: Read only on test)\n\n*everyone: No Access\n\n\n\n*~/Desktop, ~/Documents, ~/Downloads\n\n*\n\n*user (me): Read & Write\n\n*everyone: Read only (No Access on test)\n\n\n\n*~/Library:\n\n*\n\n*user (me): Read & Write\n\n*everyone: No Access\n\n\n\n*~/Public:\n\n*\n\n*user (me): Read & Write\n\n*staff: Does not exist at all (staff: Read only on test)\n\n*everyone: Read only\n\n\n\n*Macintosh HD/Applications\n\n*\n\n*user (me): Read & Write (Does not exist on test. system: Read only exists instead)\n\n*staff: Read only (Does not exist on test. admin: Read only exists instead)\n\n*everyone: Read only\n\n\n\n\n\n\n\n\nEdit: More Additional info\nSome additional information after the original post.\nOn \"Mac #3\" above, when attempting to share my Home (~) folder specifically (System Settings > Sharing > File Sharing > ℹ️ > Shared Folders), I see the following:\n\n*\n\n*Unknown User: Custom\n\n*Unknown User: Custom\n\n*Unknown User: Custom\n\n*Unknown User: Custom\n\n*My user (me): Read & Write\n\n*Everyone: No Access\n\nRelated to the \"Unknown Users\" is probably the endlessly spinning wait cursor for the \"Get Info\" permissions on the Home (~) folder [my user is truncated from the screenshot, but it has Read & Write, and Everyone has No Access]:\n\nIf I try to share the ~/Downloads folder specifically, I instead see this in File Sharing:\n\n*\n\n*Downloads: Custom\n\n*Discord Data: Custom (\"Discord Data\" is a folder in Downloads)\n\n*Downloads: Custom\n\n*Downloads: Custom\n\n*My user (me): Read & Write\n\n*Everyone: No Access\n\nAnd the Get Info permissions below [my user is truncated from the screenshot, but it has Read & Write, and Everyone has No Access]:\n\n\nA: This answer is pointers, not a detailed solution, to resetting permissions.\nHoward Oakley (Electic Light Company) has, at least twice, discussed the mysteries of resetting home folder permissions:\nSome years old, but essential reading: Something odd you can’t fix? Sierra re-introduces repairing permissions\nMore recent: Repairing Home folder permissions: a mystery\nWhy 'mystery'? Because this is not properly documented by Apple and uses commands not mentioned in any man page.\nTry using diskutil resetUserPermissions which will give your brief usage instructions.  Also the Recovery mode command repairHomePermissions. Both are undocumented and there is some uncertainly regarding exactly what they change!\nI have not used either of these and, if you do, make sure you have a backup and recovery plan in case of disaster.\n", "Q: Cannot deactivate Firewall Stealth Mode Probably after last macOS upgrade I cannot deactivate Stealth Mode in Firewall options. Even if I deactivate it, after system restart it is active.\nIt is some bug in macOS last upgrade, is there any possibility to disable stealth mode from command line?\n\nA: The only thing that helped was to reset Firewall from terminal with:\nsudo /usr/libexec/ApplicationFirewall/socketfilterfw \\\n  --setblockall off \\\n  --setallowsigned on \\\n  --setallowsignedapp on \\\n  --setloggingmode on \\\n  --setstealthmode on \\\n  --setglobalstate on\n\n", "Q: Stop “Sharing Suggestion” spam This morning my iPhone interrupted me with a random solicitation to use its Photos app:\n\n\n\nI am sick of applications abusing notifications to increase “user engagement”, and am saddened to see Apple finally succumbing to the trend.\nHow can I opt out of receiving these notifications?\n\nA: On iOS, this can be disabled in Settings -> Notifications -> Photos -> „option at bottom“ -> Sharing Suggestions.\n\nA: The setting to opt out is located under headings called Style and Appearance:\nSettings → Notifications → Notification Style: Photos → Lock Screen Appearance: Customize Notifications → Sharing Suggestions\n", "Q: MacBook Air M1 and 100W USB-C Output Solar Battery I have a MacBook Air M1 and two different solar batteries* that have 100W USB-C outputs. Can plug the USB-C cable that came with my computer from the USB-C output port on the battery directly into the USB port on the MacBook Air?\n*Bluetti EB70 and PowerWorks PSE701\n\nA: \nCan plug the USB-C cable that came with my computer from the USB-C output port on the battery directly into the USB port on the MacBook Air?\n\nCheck with the manufacturer first\nThe technical specifications are lacking in detail to say the least.  Here’s a summary of what was found after some research:\n\n*\n\n*For the EB70 it specifies 2 USB-C ports at 100W maximum.\n\n*\n\n*It DOES NOT specify if that is 100W per port or 100W for both ports\n\n*It DOES NOT specify USB-C PD (Power Delivery) compliance.  This  would indicate that the port(s) is capable of delivering up to 100W of power and could negotiate the power delivery with the device. Unfortunately, it makes no mention of this capability.\n\n*The USB-A ports specify 2 ports at 5V at 3A or 15W.  Similar to the USB-C ports, tt doesn’t specify whether that’s 15W per port or in total.  Either way, the best that these ports can manage is simultaneous charging of two iPads.\n\n\n\n*The PSE701 is not available on the manufacturer’s website.  The closest model is the PS70.  However, on the Amazon listing for the PSE701 (see image below), it specifies one USB-C port with PD and QC 3.0 (quick charge).  I am assuming that this is USB-C Power Delivery Specification 3.0 (their wording seems jumbled).  However, on the image, it specifies QC 3.0 on the USB-A ports.\n\nShould you plug it in?\nUntil you get a definitive answer from the manufacturer, it’s highly advisable to use the power adapter that came with your Mac.\nWhy?\nThe marketing verbiage is suspect. The specification in the image says it’s compliant, but the verbiage from Amazon is not quite correct; it doesn’t give a sense of confidence that this is a well put together product and it’s actually USB-IF compliant.\nAdditionally, as there is no product page for the PSE701 and the EB70’s technical specifications are also vague as to what the USB-C power capabilities are, it gives reason to pause before plugging in an expensive MacBook into this power source.\nTL;DR\nUse your MacBook USB-C charger in one of the (NEMA 1-15R) receptacles.  The technical specifications where available are vague and not worded correctly.  Don’t risk an expensive Mac on a power source that isn’t clear with what it can deliver.\n", "Q: How to log medication for past days in the Health app? The title pretty much says it all: In the Health app, how do I to add medication for past days?\nWhen you press “Log”, you can only select the time, not the date.\nI have tried navigating to the day in question and pressing “Log”, but even then, the record will be added to the current date.\n\nA: Instead of first selecting the medication and then navigating to the day you want to log the medication, you need to first select the date in question and then, under \"Log\", either select the scheduled medication or another one via \"As-needed Medication\". You can still only select the time, but it will be added to the day you previously selected.\ntl;dr select the date first, then the medication (not vice versa).\n", "Q: The battery life of the case of my AirPods Pro 2 is four days - is that expected? I have owned AirPods, AirPods 2 and recently AirPods Pro 2.  The battery life on the cases on the original AirPods and AirPods 2 usually lasts far longer than a week, in fact I haven't used my AirPods 2 much since I bought the Pro 2's and they have been sitting on my desk for weeks.  I just checked the case battery level and it's about 28%.\nThe Pro 2's however seems to be a different situation altogether.  I find that I have to constantly charge the case.\nSo, I measured the drain and (by chance) I didn't use the AirPods during the duration of the test (except for 15 mins once.)\nThe case went from 100% to 0% in four days.\nIs this normal?  Am I just spoiled by the insane battery life of the older models' cases?\nThanks\n\n\nA: I got a suggestion from somewhere else and it worked.\nApparently this is a firmware issue and can be resolved by resetting the AirPods\nhttps://support.apple.com/en-gb/HT209463\nI can confirm that this worked for me.\n", "Q: Detect substituted glyphs Here is how U+261E (manicule) and U+00B6 (pilcrow) are displayed in Pages:\n\nAs you can see, all the U+261E and U+00B6 glyphs looks pretty the same across Menlo, Monaco and Courier New (with the exception of pilcrow in Courier New) and across Helvetica Neue and Gill Sans, and for this reason it is not clear to me whether these glyphs are really from their respective fonts or macOS has \"borrowed\" them from some another font or from multiple fonts (a technique which is known as font substitution).\nHow I can verify it?\n\nA: Selecting a character in Pages or TextEdit should show the font being used in the font window.\nYou can also open Character Viewer and find each of these and then look at the Font Variation panel at bottom right and you can see exactly how each font displays it.\n\n\n\nA: Font Book will show you what glyphs are contained in any given font. Double-click on an individual typeface (e.g. Regular), and it will show you all the glyphs under the \"Repertoire\" section.\nClicking on a glyph will show you its Unicode value.\nThird-party software, such as PopChar, can provide a better interface and more features for viewing and selecting glyphs within a font.\nYou are right, however, that macOS does have a 'fall-back' substitution for missing glyphs.\nFrom what I can see, Menlo is the only font in your list that includes U+261E. So macOS is providing different replacements, perhaps based on serif, sans, fixed width. All the fonts contain U+00B6.\n", "Q: Unable to reclaim free space after bootcamp uninstall I'm unable to reclaim free space after uninstalling Boot Camp (done through the Boot Camp Assistant).\nHere are some screenshots from Disk Utility and results from diskutil:\n\n$ diskutil list\n/dev/disk0 (internal, physical):\n   #:                       TYPE NAME                    SIZE       IDENTIFIER\n   0:      GUID_partition_scheme                        *1.0 TB     disk0\n   1:                        EFI EFI                     209.7 MB   disk0s1\n   2:                 Apple_APFS Container disk2         771.3 GB   disk0s2\n                    (free space)                         228.7 GB   -\n\n/dev/disk1 (internal, physical):\n   #:                       TYPE NAME                    SIZE       IDENTIFIER\n   0:      GUID_partition_scheme                        *28.0 GB    disk1\n   1:                        EFI EFI                     314.6 MB   disk1s1\n   2:                 Apple_APFS Container disk2         27.7 GB    disk1s2\n\n/dev/disk2 (synthesized):\n   #:                       TYPE NAME                    SIZE       IDENTIFIER\n   0:      APFS Container Scheme -                      +799.0 GB   disk2\n                                 Physical Stores disk1s2, disk0s2\n   1:                APFS Volume Macintosh HD - Data     365.7 GB   disk2s1\n   2:                APFS Volume Preboot                 1.8 GB     disk2s2\n   3:                APFS Volume Recovery                1.1 GB     disk2s3\n   4:                APFS Volume VM                      4.3 GB     disk2s4\n   5:                APFS Volume Macintosh HD            8.9 GB     disk2s5\n   6:              APFS Snapshot com.apple.os.update-... 8.9 GB     disk2s5s1\n   \n$ diskutil info disk0\n   Device Identifier:         disk0\n   Device Node:               /dev/disk0\n   Whole:                     Yes\n   Part of Whole:             disk0\n   Device / Media Name:       APPLE HDD ST1000DM003\n\n   Volume Name:               Not applicable (no file system)\n   Mounted:                   Not applicable (no file system)\n   File System:               None\n\n   Content (IOContent):       GUID_partition_scheme\n   OS Can Be Installed:       No\n   Media Type:                Generic\n   Protocol:                  SATA\n   SMART Status:              Verified\n\n   Disk Size:                 1.0 TB (1000204886016 Bytes) (exactly 1953525168 512-Byte-Units)\n   Device Block Size:         512 Bytes\n\n   Media OS Use Only:         No\n   Media Read-Only:           No\n   Volume Read-Only:          Not applicable (no file system)\n\n   Device Location:           Internal\n   Removable Media:           Fixed\n\n   Solid State:               No\n   Virtual:                   No\n   Hardware AES Support:      No\n\n$ diskutil info disk1\n   Device Identifier:         disk1\n   Device Node:               /dev/disk1\n   Whole:                     Yes\n   Part of Whole:             disk1\n   Device / Media Name:       APPLE SSD SM0032L\n\n   Volume Name:               Not applicable (no file system)\n   Mounted:                   Not applicable (no file system)\n   File System:               None\n\n   Content (IOContent):       GUID_partition_scheme\n   OS Can Be Installed:       No\n   Media Type:                Generic\n   Protocol:                  PCI-Express\n   SMART Status:              Verified\n\n   Disk Size:                 28.0 GB (28000002048 Bytes) (exactly 54687504 512-Byte-Units)\n   Device Block Size:         4096 Bytes\n\n   Media OS Use Only:         No\n   Media Read-Only:           No\n   Volume Read-Only:          Not applicable (no file system)\n\n   Device Location:           Internal\n   Removable Media:           Fixed\n\n   Solid State:               Yes\n   Virtual:                   No\n   Hardware AES Support:      No\n\n$ diskutil info disk2\n   Device Identifier:         disk2\n   Device Node:               /dev/disk2\n   Whole:                     Yes\n   Part of Whole:             disk2\n   Device / Media Name:       APPLE SSD SM0032L\n\n   Volume Name:               Not applicable (no file system)\n   Mounted:                   Not applicable (no file system)\n   File System:               None\n\n   Content (IOContent):       EF57347C-0000-11AA-AA11-00306543ECAC\n   OS Can Be Installed:       No\n   Media Type:                Generic\n   Protocol:                  PCI-Express\n   SMART Status:              Verified\n   Disk / Partition UUID:     A267C17A-5F6E-42B8-8B18-0F212E883B18\n\n   Disk Size:                 4.6 EB (4611686789742047232 Bytes) (exactly 9007200761214936 512-Byte-Units)\n   Device Block Size:         4096 Bytes\n\n   Media OS Use Only:         No\n   Media Read-Only:           No\n   Volume Read-Only:          Not applicable (no file system)\n\n   Device Location:           Internal\n   Removable Media:           Fixed\n\n   Solid State:               Yes\n   Virtual:                   Yes\n   Hardware AES Support:      No\n\n   This disk is an APFS Container.  APFS Information:\n   APFS Physical Store:       disk1s2\n   APFS Physical Store:       disk0s2\n   Fusion Drive:              Yes\n\nWhat can I do to fix this?\nThanks in advance for any help!\n\nA: The Terminal application command to enter is given below.\ndiskutil apfs resizecontainer disk0s2 0\n\nIf this command does not work, post the output to your answer.\n", "Q: Virtualbox more than twice as slow on Ventura I have a virtualbox setup I was using on catalina. I finally got around to reinstalling the machine and updating to Ventura.\nThe test suite (running in an Ubuntu vm) has gone from 26 minutes to over an hour, with no other changes.  The VMs' are running without display. I have looked at other issues and many people have commented on the graphics, but, that shouldn't be an issue here.\nI guessed (incorrectly!) that it might be to do with the new permissions model, so, I gave virtualbox full disk access and still no luck.\nIs there some secret setting somewhere I can set to get it all working again? ;)\nAnswers:\n\n*\n\n*This is a newly installed OS and newly created VM (vagrant destroy, vagrant up..)\n\n*GuestAdditions 7.0.6 installed and running\n\n*VirtualBox 7.0.6\n\n*Mac -> 2.9Ghz Core i7. 16Gig ram\n\n*Two VMs running Ubuntu 18.04, one with 3GB ram other with 4 (this is more than they used to have and ample for the boxes) Running free on the boxes shows they are not using swap.\n\nTried so far:\n\n*\n\n*Giving virtual box full disk access.\n\n*setting display to none.\n\n*setting config.vm.synced_folder \"./foo\", \"/srv/www/local\", type: \"nfs\", mount_options: [\"actimeo=2\"]\n\nOption 3 may have sped things up (from about 68 minute to 48 minutes). Still hoping to get it back down to under 30 minutes (which is what it should be)\n\nA: For me I ended up using the rsync option for the shared folder:\nconfig.vm.synced_folder \"./localfolder\", \"/srv/www/remote\", id: 'code', type: \"rsync\", rsync__exclude: \"./git\", rsync__args: [\"--verbose\", \"--archive\", \"--delete\", \"-z\"], rsync__auto: true\n\n\nThat brought the test suite back down to ~35 minutes (still 7 minutes slower, but, not more than double the time at least)\n", "Q: Can QR codes be used to invite someone to send me an iMessage? I have tried messages//emailaddress but I am told that it just opens the Messages app on iPhones, not a new message to the user (on my Mac it opens that specific users thread).\n\nA: In Theory, yes.\nYou just need to create an SMS QR Code to send a message to a number that is associated with an iMessage account.\nMessages will do the rest to confirm that it is a valid iMessage account.\nSearch online for \"SMS QR Code\" for examples.\n", "Q: Xcode sign MacOS binary AdHoc with entitlement (for coredump) I want to enable coredumps for a locally used MacOS binary. I'd like Xcode to sign the binary appropriately.\nCurrently I need to run the following two commands after the binary is generated to enable core dumps:\n% /usr/libexec/PlistBuddy -c \"Add :com.apple.security.get-task-allow bool true\" tmp.entitlements\n% codesign -s - -f --entitlements tmp.entitlements MyBinary\n\nHow can I make Xcode do this for me?\nFWIW my org doesn't distribute mac binaries, so we don't have \"developer credentials\". Just want coredump on machine where binary was compiled.\n\nA: Custom Build Scripts\nYou can add a custom build script step to your Xcode workflow, see Running custom scripts during a build:\n\nTo execute a custom script at build time, add a Run Script build phase to your target. This build phase runs separately from the target’s other build phases, such as the compilation and link build phases. You may add multiple script-related build phases to your target to execute scripts at different stages of the build.\nTo add a Run Script build phase to a target:\n\n*\n\n*In the project navigator, select your project.\n\n*Select the target you want to modify.\n\n*Click the Build Phases tab.\n\n*Click the Add button (+), then choose “New Run Script Phase” from the pop-up menu.\n\n*Click the disclosure triangle for the newly added Run Script phase.\n\n*In the Shell text field, enter your script code.\n\n\n", "Q: Check VPN status with command I would like to get the VPN connection status in a script.\nOn macOS 13.2.1 I have two VPNs configured (i believe both are of type IKEv2) but i can see neither of them using\n\n*\n\n*scutil --nc list nor\n\n*networksetup -listpppoeservices.\n\nIs there another way to query the status of these VPNs?\n\nA: If you are speaking of a VPN used to access a private network, perhaps the easiest approach would be to check if an IP address specific to that network is reachable.\nFor example, if your VPN connects you to a network 192.168.100.0/24, using ping to check if 192.168.100.1 (probably the gateway) is reachable:\nif ping -c 4 192.168.100.1 &> /dev/null\nthen\n  echo \"connected\"\nelse\n  echo \"not connected\"\nfi\n\nSolution copied from this answer (in my example, -c 4 tries 4 times).\nIf you are using a VPN to avoid blocking, you might instead test against any IP address that is otherwise blocked.\nThis approach is not very sophisticated, but its advantage is its simplicity, and that it should work independent from the type of VPN and also on most operating systems.\n", "Q: iCloud Drive, please don't download this folder on iOS so far I have used iCloud for one text app sync between my MacOS and iOS. Yesterday I added a 4GB folder to iCloud drive so I can access these files on Windows. But of course my iPhone started downloading the folder as well. Now it has only 200MB of free space and constantly reboots/springs (or whatever that is) and is pretty much unusable.\nI know that with time iOS will delete its local copy of said folder to free up space. But I can't wait, and those large files change all the time so it will endlessly download them again.\nIs there any way on iOS to say: Download this folder only on demand? People with 200GB plans must have a way not to run into this with their phones, right?\nThanks for helping.\n\nA: *\n\n*Open Files\n\n*Long-press on the file/folder in question\n\n*Select \"Remove Download\" (first entry in menu)\n\n", "Q: zip: cannot use the -FF flag and -q flag at the same time I am having trouble quietly zipping a large zip file which needs fixing.\nI have a large zip file that needs fixing so I can use -FF flag:\nzip -FF TEST.zip --out TEST_fixed.zip\n\nIf I want to suppress the print statements I can add the -q flag\nzip -q -FF TEST.zip --out TEST_fixed_quiet.zip\n\nBut the resulting file is empty:\n$ unzip -q TEST_fixed_quiet.zip\nwarning [TEST_fixed_quiet.zip]:  zipfile is empty\n\nThis is not the expected behavior for the -FF flag. Zipping TEST.zip with -FF and without -q yields the correct non-empty archive. Zipping TEST.zip with -F and -q yields the correct non-empty archive.\nSo how can I zip a file quietly with the -FF flag and without destroying it in the process?\n\nA: Using -FF together with -q seems to destroy the zip file.\n$ ll\ntotal 8\n-rw-r--r--  1 pse  staff  1151 Feb 12 16:26 foo.txt\n$ zip foo foo.txt\n  adding: foo.txt (deflated 44%)\n$ zip -q -FF foo.zip --out foo-fixed.zip\n$ ll\ntotal 24\n-rw-------  1 pse  staff    22 Feb 23 20:19 foo-fixed.zip\n-rw-r--r--  1 pse  staff  1151 Feb 12 16:26 foo.txt\n-rw-r--r--  1 pse  staff   806 Feb 23 20:18 foo.zip\n$ unzip -l foo-fixed.zip \nArchive:  foo-fixed.zip\nwarning [foo-fixed.zip]:  zipfile is empty\n\nBut you can suppress the default output by redirecting it:\n$ zip  -FF foo.zip --out foo-fixed.zip > /dev/null\n$ ll\ntotal 24\n-rw-------  1 pse  staff   806 Feb 23 20:40 foo-fixed.zip\n-rw-r--r--  1 pse  staff  1151 Feb 12 16:26 foo.txt\n-rw-r--r--  1 pse  staff   806 Feb 23 20:18 foo.zip\n\n", "Q: Get purgeable space with diskutil CLI With something like diskutil info /dev/disk1s1 among other things I can get my free space as follows:\nContainer Free Space:      28.3 GB (28347076608 Bytes) (exactly 55365384 512-Byte-Units)\n\nThe question is, how can I get purgeable space as shown in Disk Utility's GUI 30.41 GB (2.05 GB purgeable) from diskutil CLI ?\n\nA: \nhow can I get purgeable space as shown in Disk Utility's GUI 30.41 GB (2.05 GB purgeable) from diskutil CLI ?\n\nUnfortunately, this is not possible.\nThe purgeable space reported by the (GUI) Disk Utility is a summation of the temp files, caches, backup files, Trash, and even some iCloud data (from Optimize my Mac).  A simple reboot will clear out a lot of these as will emptying the Trash.\nYou could potentially get an approximation of this info with the command\n% du -ch -d0 ~/.Trash ~/Library/Caches $TMPDIR \n\nThat will get you a nice summation of the bulk of the purgeable space excluding iCloud optimizations and any other temp/cache files not stored in the directory referenced by TMPDIR.\n\nA: The diskutil command can not output the amount of “purgeable space”. The accuracy of the amount of “purgeable space” reported by the Disk Utility application (IMO) is questionable since the value differs from what the Finder application reports.\nThe Get detailed information about a disk in Disk Utility on Mac section of “The Disk Utility User Guide” for Ventura defines “purgeable space” as the following.\n\nspace that macOS can free up when needed by removing files from your computer (you can’t manually remove the files that are designated purgeable, but macOS removes them as space is required)\n\nSo “purgeable space” can not include files in the Trash. Nor, can purgeable space include allocated space documented to be removable by restarting your Mac.\n", "Q: How to view details of computers connected via network? In finder, I can connect computers over the network. However, it just displays the computer's name, without any information such as ip address. Using \"get info\" does not give any details either.\nHow can I view those details?\nEDIT: to be more specific, I am interested to know the IP address and port. At the moment I could not think of anything other than this, but I do want to know about whether the connection is secure and if other people can connect.\n\nA: \nI am interested to know the IP address and port…I do want to know about whether the connection is secure and if other people can connect.\n\nFinder is not the tool for this.\nFinder has no ability to scan open ports on remote nodes.  To get the IP, you can use tools like ping, host, or dig. This assumes you or your organization is running a DHCP server that updates records with DHCP leases.  However, you can try pining the host:\nping computername\n\nUse host to query the DNS server:\nhost computername dns-server\n\nThere are a number of tools that will do port scans.  nmap is one of them.  It’s not built into macOS, but it is available vis Homebrew or MacPorts.  To scan all 65,535 TCP ports on a host, you can issue the command:\nnmap -sT host -p- host\n\nAre there GUI tools?  Yes.  Wireshark is a popular tool.  However, whether using command line tools or GUI tools with point-and-click functionality, these tools are complex and require a significant learning curve.\n", "Q: How to Add ˜/.Trash to Time Machine Exclusions in Ventura? This topic has been covered in other questions (e.g. this one here: On OS X, what files are excluded by rule from a Time Machine backup? ). However, due to the significant changes in the latest versions of the Mac OS, most of it is no longer valid. As an example, a built-in list of exclusions is no longer stored in    /System/Library/CoreServices/backupd.bundle/Contents/Resources/StdExclusions.plist\nAllow me therefore to pose the question again.\nUsing the System Settings way I am not able to add the Trash folder to the exclusion list because it does not show in the home folders list:\n\nIs there another way to add it? Or is it already excluded by default?\nI have tried to run tmutil isexcluded ~/.trash and I get [Excluded]    /System/Volumes/Data/Users/username/.trash, but I don't know if I can trust it because if I run it for the Desktop in two different manners, I get two contradicting results:\ntmutil isexcluded ~/desktop returns [Included]    /System/Volumes/Data/Users/username/desktop\nwhile tmutil isexcluded /Users/username/Desktop returns\n[Excluded]    /System/Volumes/Data/Users/username/Desktop\nI did sudo tmutil addexclusion -p /system/volumes/data/Users/username/.trash but this did not add Trash in GUI:\n\n[EDITED Feb 26]: I am not sure how much to trust the system. As you can see from the screenshot above, I have excluded the Desktop. However, it seems that it is still being backed up. To test it, yesterday I have placed a file directly on the desktop and another one inside a folder. Today, when browsing the Time Machine backups, I can see that they have all been backed up, regardless of the exclusion:\n\n\nA: Trash folders are not backed up by Time Machine. So there is no need to add any trash folders to the exclusions.\nAs you have already discovered with tmutil isexcluded ~/.trash the trash folder in your home directory is excluded.\nBut you can also look in the backup.\nIf your Finder shows ~/.trash (with view hidden files enabled), you can navigate to your home folder in a TM backup.  There is no .trash folder in the backup.\nIf Finder doesn't show ~/.trash:\n\n*\n\n*Navigate to your backup in Finder and find your home folder;\n\n*Control-click and Option select Copy ... as Pathname;\n\n*In Terminal use ls -lah  and paste the path.\n\nThat will show that the trash is not present in the backup.\n", "Q: Disabling SIP doesn't allow me to edit \"protected\" files I wanted to make a small change to a file in a protected directory, so I went into recovery mode and entered csrutil disable. Now rebooted into normal macOS csrutil status returns System Integrity Protection status: disabled.. Now when I go to make the small change, even after I changed the permissions in the info interface, the warnings are the same as before. My OS is Ventura 13.3 Beta on an M1 Mac. Is it because Apple Silicon, the beta OS or am I doing something wrong?\n\nA: /bin is part of the Signed System Volume and can‘t be changed by users any longer, see https://support.apple.com/guide/security/secd698747c9/web for details.\nInstead, put your modified binary into any other directory (e.g. /usr/local/bin) and make sure this directory is at the beginning of PATH.\n", "Q: USB-C to HDMI to DP I have a MacBook Pro 2017 (two USB-C ports only), running Ventura. I have a USB-C to HDMI female adapter and a HDMI (male) to DP (male) cable to connect everything to a Dell P2415Q. But there arrives no picture on the monitor; it only says 'there is no signal coming from your computer'. The problem persists with different such cables and adapters. Only connecting the adapter to the monitor with a HDMI-HDMI-cable that I borrowed worked. Is there any chance to connect the computer to the monitor with the USB-HDMI adapter and the HDMI-DP cable only?\n\nA: \nI have a USB-C to HDMI female adapter and a HDMI (male) to DP (male) cable\n\nThis will not work.\nWhat you’re doing is is taking a DisplayPort signal and converting to HDMI which removes the clock signal, then converting it back to DisplayPort which needs one.\nWhat you need is a quality USB-C to DisplayPort cable.  The linked answer is in relation to a similar question of converting TB3 to TB2 to DisplayPort.  Even though each signal was technically compatible, the multiple conversions proved unreliable.  Your setup is much more complex; converting actual signaling configurations from DP to to HDMI back to DP will likely never work.\nFurther Reading….\n\n*\n\n*What's wrong with HDMI?\n\n*Can a USB-C to mini DisplayPort cable be used with USB-C to Thunderbolt ports?\n\n*HDMI to DisplayPort Not Working\n", "Q: How do I enable Proxy Configuration File for VPN on Mac Terminal? I'm using a Mac, I have the corporate VPN turned on (Cisco AnyConnect Secure Mobility Client)\nIn the Proxies tab of System Preferences I have \"Proxy Configuration File\" enabled with the URL (http://proxyaddress:portnumber)\nI can connect to the internet via chrome browser fine, but my terminal has no internet access.\nIs there a way for me to declare the Proxy Configuration File URL in Terminal, so I can connect terminal to the internet while the VPN is turned on?\n\nA: Unfortunately, you can’t.\nTerminal is not a “network connected” application.  It is nothing more than a portal into the OS that allows you to enter and execute  commands. It’s the command(s) themselves that need to be able to utilize a proxy.\nFor example, you can’t ping or traceroute through a proxy; those commands will fail.  However, curl has the ability to specify a proxy with the flag —-proxy <[protocol://][user:password@]proxyhost[:port]>\n", "Q: Is it possible for a trojan app to keep plaguing an iOS device after the app had been uninstalled? An app that comes with AceDeceiver got installed invisibly against my will on my iPhone, iOS ver. 15.6.\nFull background analysis by PaloAltoNetworks:https://unit42.paloaltonetworks.com/acedeceiver-first-ios-trojan-exploiting-apple-drm-design-flaws-to-infect-any-ios-device/\nI have now removed it from my phone, by the looks of it this trojan ware was from 2016 but my device has a system version much older than that, yet it succumbed to this malware.\nWhat I'm trying to find out is how dangerous is this malware after the app has been removed? Should I reset my phone? Will a reset even work to remove the malware?\nWould it breach some underlying safety mechanisms and obtain information from other apps, or even passwords? Of course I didn't enter anything into that app. I believe iOS does a decent job in maintaining access control, true?\nAll in all, how worried should I be?\nPlease help!\n\nA: When in doubt, format!\nYour safest course of action will always be to wipe the device and reset to factory. A third party app cannot write to the protected system volume. That said, iOS security is quite robust and uninstalling the app should be sufficient.\niOS Security\n\nWhat I'm trying to find out is, how dangerous is it after the app has been removed?\n\nInstalled third party apps are “sandboxed” meaning they are isolated from other apps and from modifying the OS. While there are “hooks” that allow applications to access info like contacts, location, etc., it must do so through iOS; it cannot do it on its own.\n\nSandboxing\nAll third-party apps are “sandboxed,” so they are restricted from accessing files stored by other apps or from making changes to the device. Sandboxing is designed to prevent apps from gathering or modifying information stored by other apps. Each app has a unique home directory for its files, which is randomly assigned when the app is installed. If a third-party app needs to access information other than its own, it does so only by using services explicitly provided by iOS and iPadOS.\n\nEven if the app somehow was able to write code to memory and attempt to execute it whether the app was still installed, iOS employs a security feature on the ARM chip called Execute Never.\n\nFurther protection is provided by iOS and iPadOS using ARM’s Execute Never (XN) feature, which marks memory pages as nonexecutable. Memory pages marked as both writable and executable can be used only by apps under tightly controlled conditions: The kernel checks for the presence of the Apple-only dynamic code-signing entitlement. Even then, only a single mmap call can be made to request an executable and writable page, which is given a randomized address. Safari uses this functionality for its JavaScript Just-in-Time (JIT) compiler.\n\n", "Q: Terminal calculator like concalc from Ubuntu Is there a terminal calculator for the Mac that's similar to concalc from Ubuntu?\nconcalc allows you to calculate an expression by prefixing it with the tool name (more on the concalc man page)\nExpected usage:\nconcalc 2*(3+4/9)^3\n\n\nA: In addition to Glorfindel’s answer (should be accepted), there is Calc (free) which is a C style arbitrary precision calculator. I’m just posting this as an excellent alternative to consider.\nIt’s available via MacPorts and Homebrew.  I’ve not used this on a Mac, but in FreeBSD.  What I  liked about it was that you could either use it as a single CLI command or in interactive mode; just type calc and begin entering calculations\nCalc allows you to use variables and functions in your calculations:\n% calc \"v=2; 5^v\"\n  25\n\n% calc \"v=3; x=v^2; sqrt(x)\"\n  3\n\n% calc \"define myfunc(a,b) = a^b; myfunc(8,2)\"\nmyfunc(a,b) defined\n    64\n\nAdditionally, you can create a file of calculations and have them read into calc with a calc -f filename operator.  This is helpful when defining your own complex functions.\n\nA: This answer discusses a few possibilities that are bundled with macOS.\nShell built-in features\nIn this section, $ represents a bash prompt and % represents a zsh prompt.\nFor simple operations, if you don't mind typing a little more punctuation, you can use the shell's built-in arithmetic. The shell evaluates arithmetic expressions inside $((…)) or $[…] (they're exactly equivalent).\n# bash or zsh\n$ echo $[3*4] $((1/2))\n12 0\n\nBash can only do integer operations. Zsh can also do floating point operations.\n# zsh only\n% echo $[1./2]\n0.5\n\nTo set up easier access to arithmetic in zsh without having to type punctuation, see https://unix.stackexchange.com/questions/700892/evaluate-terms-in-zsh-without-a-command/700946#700946. (I don't recommend it though: it's a lot of work for little benefit compared to typing a couple of punctuation characters or running zcalc.)\nIn zsh, you can get additional mathematical functions by loading the zsh/mathfunc module.\n% zmodload zsh/mathfunc\n% echo $[sin(1)]\n0.8414709848078965\n\nAnd by running zmathfunc, you get access to a few other functions.\n% autoload -zU zmathfunc\n% zmathfunc\n% echo $((sum(1,2,3)))\n6\n\nZsh also comes with a calculator mode, which gives access to the same operators and functions, plus a few more features like the constant PI, output format customization, and a stack. See the manual for details. In particular, run zcalc -f to perform floating-point operations all the time (by default, / calculates the integer quotient if both operands are integers).\n% autoload -zU zcalc\n% zcalc\n> 3/2\n1\n> 3/2.\n1.5\n> sin(PI/2)\n1.\n> q\n% zcalc -f\n> 3/2\n1.5\n\nTo make all of this available by default in all interactive shells, make sure you're using zsh and put this in your ~/.zshrc:\nzmodload zsh/mathfunc\nautoload -zU zmathfunc\nzmathfunc\nautoload -zU zcalc\n\nbc and dc\nbc and dc are two classic Unix calculator programs. bc uses classical infix notation whereas dc uses reverse Polish notation (RPN).\nNote that both tools work with a defined number of digits (called the scale) after the decimal point, rather than floating point. The default scale is 0.\n\n% bc\nbc 1.06\nCopyright 1991-1994, 1997, 1998, 2000 Free Software Foundation, Inc.\nThis is free software with ABSOLUTELY NO WARRANTY.\nFor details type `warranty'.\n5/3\n1\nscale=4\n5/3\n1.6666\nquit\n\n(In the session above, the bold text is what I typed, and the rest is displayed by the bc, or by the shell on the first line.)\nThe command to exit bc is quit. The command to exit dc is q (quit also works). You can also type Ctrl+D at the beginning of a line.\nPython\nPython comes bundled with the system and can offer a very powerful calculator-like experience. Basic arithmetic operators are available out of the box. Common mathematical functions are in the math module, and some basic statistical functions in the statistics module. There's also cmath for complex numbers, fractions for rational numbers, and decimal for decimal arithmetic (rather than binary floating-point).\n% python3\nPython 3.8.9 (default, Oct 26 2021, 07:25:53)\n[Clang 13.0.0 (clang-1300.0.29.30)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> from math import *\n>>> 3//2\n1\n>>> 3/2\n1.5\n>>> sin(pi)\n1.2246467991473532e-16\n>>> exit()\n\nThe command to exit Python is exit(). You can also type Ctrl+D at the beginning of a line.\n\nA: You can compile concalc for macOS yourself.\n\n*\n\n*Get Homebrew and use it to install cmake\n\n*Get the latest concalc source from Sourceforge (version 0.9.3 dated 2010-04-05)\n\n*tar xzf concalc-0.9.3.tar.gz to unpack it\n\n*cd concalc-0.9.3\n\n*cmake . to build the Makefile (ignore the warnings)\n\n*make, again ignore the warnings.\n\nThis will build concalc into the current directory.\n$ ./concalc -v\n\nVersion: 0.9.3 2010-04-04\nCalculator algorithms: extcalc v0.9.3 2010-03-28\n\nAuthor:\nRainer Strobel\nhttp://extcalc-linux.sourceforge.net\n2010\n$ ./concalc 2*(3+4/9)^3\n81.7311385459534\n\n\nA: Your Mac comes preinstalled with bc;\nbc -le \"2*(3+4/9)^3\"\nbc <<< \"2*(3+4/9)^3\" -l\n\nboth produce\n\n81.73113854595336076784\n\n(thanks @Gilby for the more natural syntax)\nThe -l option is needed to change the precision; without it, it rounds 4/9 down to 0 and the result will be 54 instead.\nIt also has an interactive mode (bc -l) where you can enter expressions in the prompt.\n", "Q: Equivalent to systemd timers on OS X? On Linux, many distros ship with systemd. Systemd supports \"timers\", which are a kind of systemd service for running programs on a schedule. There are of course many ways of scheduling tasks, such as the venerable cron which was replaced by systemd. However, the benefits of systemd specifically are:\n\n*\n\n*CLI with convenient commands to enable, disable and check the status of timers\n\n*Each scheduled task is entirely defined in a single text file\n\n*The timer syntax is very extensive with ways to cover different types of exceptional situations and corner cases\n\nIs there a similar way of scheduling tasks in OS X? I am interested primarily in running command line programs and scripts, so GUI support is not important to me.\n\nA: \nOn Linux, many distros ship with systemd. Systemd supports \"timers\", which are a kind of systemd service for running programs on a schedule... Is there a similar way of scheduling tasks in OS X?\n\nIt’s called launchd.\nFrom Wikipedia:\n\nlaunchd is an init and operating system service management daemon created by Apple Inc. as part of macOS to replace its BSD-style init and SystemStarter. There have been efforts to port launchd to FreeBSD and derived systems\n\nAdditional Resources\n\n*\n\n*launchd plist format for running a command at a specific time on a weekday\n\n*Is there a way to make login items only work on specific days?\n\n*Scheduling Timed Jobs (Apple Developer)\n\n*A Launchd Tutorial\n", "Q: How can I disable S/MIME signing/encryption for Mail on iOS? I would like to deactivate S/MIME signing and encryption in Mail on iOS (latest version 16.3.1) as I no longer use it. In Settings > Mail > Accounts > [my account] > Account > Advanced, I see at the bottom two options for S/MIME signing and encryption that can, however, not be deactivated (see screenshots). If I recall correctly, there seemed to have been a third option in the advanced settings, and that was whether to use S/MIME at all. That option is not visible in my settings however. Any help with this is much appreciated\n\n\n\n\nA: If you cannot deactivate signing and encrypting, then it has probably been configured by a profile.\nSearch for „profile“ under in your Settings app to find the configuration. You can delete the profile unless it has been protected from removal by a password.\n", "Q: Time Machine data exists in Terminal but no longer in Finder or the TM app I have tried searching for it but maybe I am not using the right words. tmutil does also not seem to have anything?\nTime Machine started claiming that there was not enough space for the backup (I have been using the same HDD for about 1.5 years now). And true enough, only 50 GB are remaining, but incremental backups were much less than that. Turns out, when opening the Time Machine mount, there is no backup there, but when browsing the folder in the Terminal I can see\nls -lh /Volumes/TimeMachine/\ntotal 8\ndrwxr-xr-x@ 3 root  wheel    96B Jan 22 01:46 2022-12-16-223342.previous\ndrwxr-xr-x@ 3 root  wheel    96B Jan 16 07:06 2023-01-08-153244.interrupted\ndrwxr-xr-x@ 3 root  wheel    96B Jan 22 00:46 2023-01-08-233410.interrupted\ndrwxr-xr-x@ 3 root  wheel    96B Jan 22 13:26 2023-01-11-102405.previous\ndrwxr-xr-x@ 3 root  wheel    96B Jan 22 13:37 2023-01-22-015014.interrupted\ndrwxr-xr-x@ 3 root  wheel    96B Jan 31 06:07 2023-01-22-144359.previous\ndrwxr-xr-x@ 3 root  wheel    96B Jan 31 06:01 2023-01-28-120137.interrupted\ndrwxr-xr-x@ 3 root  wheel    96B Feb 11 18:29 2023-02-11-125628.previous\ndrwxr-xr-x@ 3 root  wheel    96B Feb 12 23:24 2023-02-12-142959.previous\ndrwxr-xr-x@ 3 root  wheel    96B Feb 19 07:00 2023-02-13-101611.previous\ndrwxr-xr-x@ 5 root  wheel   160B Feb 19 09:17 2023-02-19-093419.previous\ndrwxr-xr-x@ 3 root  wheel    96B Feb 25 09:41 2023-02-25-023743.interrupted\ndrwxr-xr-x@ 5 root  wheel   160B Feb 25 07:39 2023-02-25-073801.interrupted\ndrwxr-xr-x@ 5 root  wheel   160B Feb 25 08:39 2023-02-25-083814.interrupted\ndrwxr-xr-x@ 5 root  wheel   160B Feb 25 09:40 2023-02-25-093843.interrupted\ndrwxr-xr-x@ 5 root  wheel   160B Feb 25 10:41 2023-02-25-103941.interrupted\ndrwxr-xr-x@ 5 root  wheel   160B Feb 25 12:41 2023-02-25-123952.interrupted\ndrwxr-xr-x@ 5 root  wheel   160B Feb 25 13:41 2023-02-25-133958.inprogress\n-rw-r--r--@ 1 root  wheel   1.4K Feb 22 15:19 backup_manifest.plist\n\nbut none of these are available in the Time Machine app or system settings or in the Finder. I tried removing the HDD as a TM location ('-' symbol in the settings) and re-adding it, but to no avail. Ideally, there should be some way to reconnect / reindex or something like that the backups that are clearly present in some form on the drive and then continue incrementally from there. The alternative would be to erase and begin again but surely this is not exactly what you have a backup like TM for.\nThanks for your help!\nSome hardware details:\n\n*\n\n*MacBook Air M1 2020 with a 512 GB SSD\n\n*Currently on the latest Ventura 13.2.1\n\n*External HDD (not SSD) with an AFPS Time Machine partition of 1 TB\n\nThe error appears to have begun over night two weeks ago, when suddenly the last backup failed because it tried to do a backup of everything, ignoring the previous ones.\n\nA: Generally if TM is complaining about space, then it's probably not space on your TM disk, but space on your system disk for snapshots. I myself have been caught out by this before now.\nTo mitigate this one would check free space and manage that, check and empty trash. There's likely a load of snapshots around for all those failed backup attempts. If necessary you can remove old ones with Disk Utility. Finder does interesting things to make TM backups not appear until complete so you will see different results in Finder vs Terminal.\nThe local TM snapshots get tidied up after 24h, but can grow quite large if there is a lot of churn on a disk. The snapshot view gives the 'private size', the size of each snapshot, and the cumulative size based on the amount of change there has been since each snap. Even if files & folders are excluded from a TM backup they still make their way into snapshots, which are volume based. So large files excluded can still cause problems later on if they persist in snaps, even if deleted.\nSince you've tidied up your internal disk (ref. comments) but still running into a problem with space, it now more likely to be there probably isn't enough space on the external drive. As you can't manually get rid of broken backups (normally the system manages them itself as part of a cleanup process) the safest thing to do would be to erase the disk and start a new TM backup.\nBecause of all the .interrupted and .inprogress folders it seems that the backup state is undetermined. In a healthy backup (on my machine at least), I only see a single folder corresponding to the last successful backup. The other backups are 'hidden away' by the OS, and only properly visible in Finder, or the TM restore utility. eg.\n% ls -l /Volumes/Time\\ Machine\\ 2TB\\ Grey \ntotal 48\ndrwxr-xr-x@ 7 root  wheel    224 26 Feb 21:06 2023-02-26-210632.previous\n-rw-r--r--@ 1 root  wheel  20829 26 Feb 21:06 backup_manifest.plist\n\nThere are other ways to get to the earlier backups via the command line, but they, and macOS's behaviour when presenting them, are poorly understood by me and so I don't want to draw attention to them for the risk of getting it totally wrong. The UI is always the safest approach IMHO.\n", "Q: Restore default Finder keyboard shortcut for Sort by Name The default keyboard shortcut to sort by Name is ⌃ Control⌥ Option⌘ Command  1 as described here. However in  my Finder menu, Name does not have a keyboard shortcut.\nI have gone through all my App Shortcuts and nothing else is mapped to ⌃ Control⌥ Option⌘ Command  1. I have tried adding the shortcut manually with the exact string \"Name\", but it does not get added to Sort By -> Name; it gets added to Group By -> Name.\nHow do I restore the default shortcut for Sort By -> Name?\n\n\nA: You'll probably find that key command has been assigned to another menu item in Finder. That will definitely 'steal' it from the default.\nHere I've intentionally used that command for 'Use Stacks', which you can see has removed the one for 'Name'.\n\nIf you go to System Preferences > Keyboard > Shortcuts >App Shortcuts you will likely find the culprit.  You can either delete this with the  -  button underneath, or change the shortcut to something that doesn't conflict.\n\nI'm aware the locations of prefs have changed with Ventura, but I don't yet have a Mac with Ventura to test this new location. I'm sure you should be able to find it - or someone might kindly add this information.\nAfter comments\nAs it appears to not have been 'stolen' in this manner, then one way to force it back is to add it again in Prefs. Because this particular menu item appears twice in different sub-menus, you can force a specific instance by quoting its 'full path' in the prefs, e.g. View->Sort By->Name\n\nA: Turns out there is a \"quirk\" with this particular menu item. Sort by -> Name has the same exact item text as Group By -> Name, and Group By -> Name takes precedence. What this means it that when you set an App Shortcut for \"Name\", it will apply to Group By -> Name, and it will remove the default shortcut for Sort By -> Name.\nRemove \"Name\" from Finder App Shortcuts and the default will be restored.\n", "Q: Is it possible to OPERATE an iPad app from an iMac? Sidecar, maybe? My wife is a nurse, and she - along with the other nurses on her ward - has been given an iPad Air with a keyboard case by her hospital for the purposes of charting. The issue here being that the keyboard in said case is A. notably smaller than a full-sized laptop keyboard, and B. heavier than my MBP, and C. sucks. But, since it's corporate hardware and does provide a disproportionate amount of armor for the device (as well as being SCREWED closed around the device), I'm reticent to just swap out the case and risk reprisals for her.\nThe device's UUID is what is dictating her login, best as I can tell, so I cannot swap out the device itself.\nWe're an all-Apple household/ecosystem, and she has an Silicon iMac at her desk now. I know it's possible to INSTALL an iOS app onto an M Mac, but is it possible to OPERATE one ON the iPad using her iMac? Can I mirror the screen or SideCar/AirBridge/Cast/Airplay/etc. to her iMac, allowing her to provide inputs using the iMac, and view the screen on the iMacs much-larger display?\nIn short, can she use the iMac as a proxy to OPERATE an iPad app ON the iPad?\nEDIT\nAdditional information:\n\n*\n\n*It is an iPad Air gen3\n\n*The iPad is secured with a corporate provisioning profile, which both precludes the installation of additional apps (apparently), and prevents her logging in with her own iCloud account\n\n(Ugh, as I type this, I think I'm answering my own question here).\nIs there a \"docking station\" hardware solution, perhaps? Like a port-replicator/KVM-style extension?\n\nA: The (/An) Answer\nSo, the general consensus is, \"No, given the constraints [I'm] operating within.\" The options one has to carry out what I was trying to do are all contingent on the AppleID's matching, installation of an app, or both.\nAn alternative solution\nI figured I'll post what I wound up jury-rigging up from materials I had on hand to resolve the stated complaints (admittedly, though, not in as seamless a form factor as I'd have liked), in the off chance someone with a similar issue might take inspiration.\nI dug out an old 27-inch Samsung monitor and, using the VESA mount holes on its backside, bolted on an old sleeve-style wall-mount formerly belonging to a now-retired laptop. This allows the iPad - still in its stupidly-overbuilt case - to be slid in from the side of the display, securely holding it out of view.\nNext, I used a Lightning Digital AV Adapter to connect it to the display via a 6\" HDMI cable. This addressed the screen size constraints (although resolution is dictated by the iPad).\nSlap down a spare magic keyboard and magic mouse, and we wind up with a not-too-distant analog to an iMac, albeit one far-less svelte/sexy or as feature-rich (and which occupies a second desk, hooray).\nI took measurements offa the cased iPad and the VESA position, and I'll 3D print a better mount this week that will both hold the AV Adapter's lightning plug and snugly-guide the still-cased iPad onto it, so she can just slide it in from the top & it'll \"dock\" with the cable like those Henge docks that were all the rage back in the late 2010's.\n", "Q: Can I start AirPlay automatically? My Macbook is without a screen as the connector broke. There's a way to start AirPlay automatically on startup so I can watch on my AppleTV or any script I can use to start the AirPlay?\n\nA: Yes, it is possible to start AirPlay automatically on startup or use a script to start AirPlay.\nTo start AirPlay automatically on startup, you can follow these steps:\n\n*\n\n*Connect your MacBook to your Apple TV using an HDMI cable.\n\n*Turn on your Apple TV and your MacBook.\n\n*Go to Apple menu > System Preferences > Displays > Arrangement, check the box that says Mirror Displays.\n\n*Close the Displays preferences window.\n\nYou can also add the AppleScript application to your startup items to automatically start AirPlay whenever you log in to your MacBook. To do this:\n\n*\n\n*Go to Apple menu > System Preferences > Users & Groups\n\n*Click on your username in the left sidebar.\n\n*Click on the Login Items tab.\n\n*Click on the \"+\" button to add the AppleScript application to the list of startup items.\n\nNow, whenever you log in to your MacBook, the AppleScript application will automatically run and start AirPlay.\n", "Q: How to close all quicktime windows from zsh? I wish to close all the open windows of Quicktime from zsh, i.e. I want to automate from zsh the following two operations that I am currently doing manually:\n\n*\n\n*Bring Quicktime in forefront (i.e. I don't know if that is the appropriate word)\n\n*Hit CMD + W\n\n\nA: SOLUTION\nIt is not possible to directly control the GUI from a shell, as suggested.\nHence, I prepared the following AppleScript\ntell application \"QuickTime Player\"\n    if it is running then\n        delay 0.5\n        close every window of it\n    end if\nend tell\nreturn\n\nthat can be conveniently called from a zsh shell with\nosascript ~/QuickTimeClose.scpt\n\nassuming that the script is called QuickTimeClose.scpt and it is located in your HOME folder.\n", "Q: How to run AppleScript from Keynote? Within Keynote and using AppleScript, I’m trying to emulate a macro used in a Windows PowerPoint file by a colleague. The macro is executed by clicking on a customized button. So, I wonder if the same feature can be replicated in Keynote. Is it possible to run some AppleScript code within Keynote, and how?\n\nA: In Keynote or other iWork software such as Numbers or Pages, it is not possible to create a \"clickable customized button\", which is officially called a form control button in Microsoft Office applications. However, it is possible to run automation code from Keynote or other iWork software via the (Keynote->)Services menu or a keyboard shortcut.\nSuch automation code, which is usually called a macro in Microsoft Office, can be created, among other things, as a Quick Action in macOS. A Quick Action is created from within the Automator app and you may or may not need to include some AppleScript code in it to achieve your objective.\nIf you really want to do this, my suggestion would be for you to review the Automator user guide and see if you can achieve your objective using the ready actions in the Automator library. If the ready actions turn out be insufficient, you can add some AppleScript or JavaScript code to your Quick Action as also described in the Automator user guide to achieve your objective. There are many excellent sources in the Internet on either Automator or AppleScript but here is the official AppleScript Language Guide for a start if you need it.\nAfter researching, learning and trying these tools for at least a while, if you get stuck, come back to this site and ask a new question which should include a sufficiently detailed description of your objective and what you have done so far in terms of implementation.\n", "Q: fastboot hangs (but adb works) On a MacBook Air M1 running Big Sur, I have an Android device (Fairphone 4) connected with a USB-C cable (both ends are USB-C, there is no adapter or hub). I've enabled developer options, adb and OEM unlocking. I have android-platform-tools 34.0.0 installed through Homebrew. The adb command works fine. But fastboot doesn't. Even fastboot devices just hangs. The state of the device (running normally, or with fastboot running after doing adb reboot bootloader) doesn't matter. sudo fastboot devices doesn't help.\nHow can I make fastboot work on my Mac?\n\nA: What made it work for me was to plug the USB cable in a different port! Either port works for adb, but fastboot seems to only work with the USB port that's furthest back.\n\n*\n\n*If no USB device is plugged in, fastboot devices hangs.\n\n*If a non-Android USB device is plugged in on any port, fastboot devices returns immediately.\n\n*If the phone is connected to the USB-C port that's furthest from the back, fastboot doesn't detect it.\n\n*If the phone is connected to the USB-C port that's closest to the back, fastboot detects it normally: fastboot devices returns immediately with no output if the device isn't in fastboot mode, and fastboot devices lists the device if the device is in fastboot mode. Fastboot commands work if the device is connected to the back USB port and in fastboot mode.\n\n", "Q: How to prevent being locked out of AppleID with stolen iPhone The WSJ Video indicates that all that is necessary to gain access to the password keychain and lock me out is for the bad actor to:\n\n*\n\n*\"shoulder surf\" to acquire password\n\n*acquire physical access to the iPhone (steal it)\n\n*immediately change the AppleID password with password in step 1\n\nBad actors are following the above script to gain control of the AppleID including the password keychain for financial theft.  The video indicates that the 6-digit code is all that is necessary to allow the AppleID password to be changed.\nI would think that a more secure method is to require the AppleID password to be changed using 2FA that requires a second Apple device, like an Apple Watch and not password recovery via email.\nIf the goal is to prevent the bad actor from locking out the rightful AppleIDowner:\n\n*\n\n*Is there a mechanism to require the user (i.e. bad actor) to input something other than the 6-digit password (perhaps the current AppleID password) to change the AppleID password?\n\n\n*How to require AppleID password to change AppleID password on iPhone?\nBonus:  How to invoke 2FA (like when adding your AppleID to a new Macintosh account) to change AppleID password?.\n\nA: \nIs there a mechanism to require the user (i.e. bad actor) to input something other than the 6-digit password (perhaps the current AppleID password) to change the AppleID password?\n\nThis is what bio-metric authentication - TouchID and FaceID - is for.  There are only three times when you must enter a passcode:\n\n*\n\n*When you wake in the morning\n\n*When the phone boots or reboots\n\n*When you manually lock it to disable FaceID (Press Power and Volume button)\n\nBio-metric authentication has been available on the iPhone since the 5S. Whether you use bio-metric authentication by choice or by necessity, you must take responsibility for the security of your passcode much like you would with your ATM pin code.\nYour iPhone is treated as your primary \"trusted device\" like an RSA Secure Token would be.  So, in the event you lose this device and the unlikely event that someone shoulder-surfed you at one of the three instances described above, it's incumbent upon you to take steps to \"lock it out.\"\nApple's FindMy Feature\n\n*\n\n*Can be done from another iDevice\n\n*Apple Watch can locate it, make it play a sound, and even lock it remotely\n\n*Can be accessed via any computer through iCloud.com/find\nIt's important to remember that no device can be 100% secure - even the RSA SecureID tokens (which are used in DoD) or Yubikeys; those devices can be stolen as well.  A well-placed shoulder surfer or keystroke logger can grab your password just like they can grab your phone.  The last mile of security is the user, and this is where you can stop any potential security breach.\n", "Q: Help with osascript Command to Hide Login Item on MacOS Ventura I'm attempting to use the following command in Terminal on MacOS 13.2.1 to add WebDrive.app to my login items hidden (or even just minimized) on MacOS, since there appears to be no way to do it with the new Login items UI under the Settings \"General\" tab:\n/usr/bin/osascript -e ‘tell application “System Events” to make login item at end with properties {path:”/Applications/WebDrive.app”, hidden:true, name:”WebDrive”}’\nWhile I'm not sure this approach would even work if it were syntactically valid, this gives me a 0:1: syntax error: A unknown token can’t go here. (-2740) error. I'm just not seeing what token osascript is complaining about, so any help with this would be very appreciated.\n\nA: This works for me.\n/usr/bin/osascript -e 'tell application \"System Events\" to make new login item at end with properties {name:\"WebDrive.app\", path:\"/Applications/WebDrive.app\", kind:\"Application\", hidden:true}'\n", "Q: Caffeinated Mac I've just moved to a new M1 Mac Mini. I'm used to keep my Mac on for months, just leaving it in sleep mode when not in use.\nI've just realised that this new Mac never really sleeps! It keep waking up every around 15 mins:\n\n\nI've checked all the settings and, I believe, I disabled all the relative settings (Energy Saver -> Wake for network access, Powernap in past.)\nWhat else can I do to make my Mac sleep when set in sleep mode?\nADD: USB plugs are empty and bluetooth is connected to mouse and keyboard. Of course, no direct interaction with devices while sleeping.\nTerminal pmset -g log output.\nIt's a new Mac set from scratch so basic setup + Dropbox and iStat running background.\nMail, Safari and an RSS reeder running while sleeping. Even closing those 3 apps, same result.\n\nA: This is probably linked to when you receive notifications, it turns on to make the notification appear just like an iPhone and then turn off. I suppose you might just turn it off completely if you don't want this to happen. :)\n", "Q: Connecting legacy Mac OS (10.3.9) to modern HTTPS via TLS I'm using an old iMac G3, running Mac OS 10.3.9 Panther, for research purposes. My concern is not security - I don't put sensitive information on this machine, nor do I mind if the integrity of the Operating System is compromised. I just want to be able to connect to the internet for benchmarking purposes. I am aware that the specs of this machine are too low to run most websites.\nAs you're probably aware, the SSL security protocols on this version of Mac OS X are out of date enough to prevent me from visiting anything aside from Google.\nOne step I've taken care of is following the directions from How do I update my root certificates on an older version of Mac OS (e.g. El Capitan)? :\n\nSome operating systems hold onto the expired R3 > DST Root CA X3 chain even if your server is no longer using it. Try a restart of the affected client device.\nFor older macOS not updated by Apple:\nDownload the ISRG Root X1 certificate file from http://x1.i.lencr.org/\nOpen the Keychain Access app and drag that file into the System folder\nof that app. Find the ISRG Root X1 certificate in System and double\nclick on it, open the Trust menu and change \"Use System Defaults\" to\n\"Always Trust\", then close that and enter your password to confirm the\nchange (if prompted).\n\nI seem to be able to connect to Google via HTTPS, which is a step up, but sites like Wikipedia still prevent me from accessing them for security reasons. What else could I try doing in order to get this computer on the internet (for better or worse)?\n\nA: As you noted, the problem is that your OS X does not support modern versions of the SSL protocol, such as TLS 1.2. Wikipedia, like many modern websites, does not support older versions of SSL. This creates an impasse where neither can talk to each other. Updating root certificates won't help, because your Mac and the server do not speak the same language.\nInstead, you need a translator—a piece of software which sits between you and the server, intercepts your traffic, and modifies it to be compatible. This is called a \"man-in-the-middle\" or \"MiTM\" proxy server. The proxy will decrypt and re-encrypt your traffic before sending it on its way.\nFor Macs running at least OS X 10.6, I created a turn-key solution to set up a local MiTM proxy server: https://jonathanalland.com/old-osx-projects.html. However, this won't work on OS X 10.3. Unfortunately, I don't know of any MiTM proxy software that will run on your OS.\nSo, what you have to do instead is set up an MiTM proxy server on a second device, such as a Raspberry Pi or a modern PC, and then connect to that proxy from your old Mac.\nBecause this involves networking multiple machines, exact instructions will depend on your setup, but it can work! Although the proxy server on the page linked above requires OS X 10.6, you may still want to reference the Squid configuration file included in the package as a starting point.\n\nP.S. And even if your OS supported modern protocols, there would be the issue of cipher suites! My OS, OS X 10.9 Mavericks, supports TLS 1.2. However, I cannot connect to Wikipedia without my proxy server, because Mavericks lacks support for modern cipher suites, and Wikipedia does not support older cipher suites.\n", "Q: Time Machine - cannot access all TM backups I have a senior pal who came to me for help and I am stumped.\nHe just ran the latest incremental update to Ventura on a fairly new iMac (not Silicon) and he lost all the many mailboxes he had set up in the Mail.app because he choose to set up those mailboxes On My Mac and not in iCloud.\nWhen he went to [Browse Time Machine Backups] he cannot go back any farther than one day, 24 Feb, even though he had backups over a year old. Looking at those little tick marks on the right side of his screen when browsing time machine, all are the same color save the one for 24 Feb, which bears a red tick mark.\nIs there any app/terminal command/whatever one could use to repair his Time Machine so that he can access the backups made before this latest incremental update within Ventura?\nIs there any other way to get at the contents of a TM Backup prior to 24 Feb?\nGreatly appreciate any suggestions.\n\nA: Just to close the loop on this problem:\nWhat he finally did was to purchase BackupLoupe, got into his 15 Feb TM backup, found the V10 folder, replaced his current \"corrupted\" V10 folder with it, got back the many mailboxes he had created On My Mac, but all of them were empty.  The hundreds of emails that once populated those mailboxes were gone.\n", "Q: Can I delete the CombinedVocalizerVoices file from Mac? Can I delete the following directory on my MacBook Air?\ncom_apple_MobileAsset_VoiceServices_CombinedVocalizerVoices\n\nwhich is located at:\n/System/Library/AssetsV2/com_apple_MobileAsset_VoiceServices_CombinedVocalizerVoices\n\nIt's over half a GB as shown in the Finder screenshot below and I can't find much info about its use online.\n\n\nA: I would recommend against removing anything in /System—and you can’t do it without disabling SIP.  I especially recommend against removing this if you do any IOS programming.\n", "Q: Numbers: Get max value and the value's date I have a document where one column is a date and another is a value for the date. I'd like to be able to get the maximum value and the date when that value appeared. For example if I had\n\n\n\n\n\nA (Date)\nB (Value)\n\n\n\n\n1\n2023-02-18\n2\n\n\n2\n2023-02-19\n7\n\n\n3\n2023-02-20\n3\n\n\n4\n2023-02-21\n9\n\n\n5\n2023-02-22\n5\n\n\n\n\nI know I could use MAX to get the max value of 9 but I also want to know the date when that value appears. How can I do that?\n\nA: One way is achieving desired result is using LOOKUP function.\n\"Algorithm\" can be described as: \"find maximum value in Values column and return corresponding row in Date column\".\nAssuming that data provided is in table starting from A1: maximum value (MAX(C2:C6)), range where to look for this value (C2:C6) and range where corresponding row should be returned (B2:B6):\nLOOKUP(MAX(C2:C6),C2:C6,B2:B6)\n", "Q: M1 Mac unable to switch bash Greeting!\nI followed the answers in here and got the latest version (5.2.15) of bash installed on my Mac. But when I ran bash --version it still shows:\nGNU bash, version 3.2.57(1)-release (arm64-apple-darwin22)\n\nI check the /etc/shells and the newly installed bash path is in the list:\n...\n/bin/zsh\n/opt/homebrew/Cellar/bash/5.2.15/bin/bash\n\nWhen I tried running dscl . -read ~/ UserShell it shows the newly installed bash.\nUserShell: /opt/homebrew/Cellar/bash/5.2.15/bin/bash\n\nI already restarted the Terminal and my mac but to no avail.\nI also tried changing the Shells open with: in Terminal settings to Default login shell and Command (complete path) but both still show the 3.2.57 version\nAlso I already found this but I don't the tmux installed on my Mac.\nAny idea about this? I need to run a .sh file and it require bash 4 or above\nUPDATE:\nRunning which bash shows /bin/bash\n\nA: Most likely you switched shells successfully, but use the wrong command to check the version. bash --version will start a new bash from PATH, in your case this is /bin/bash. Use echo $BASH_VERSION instead to check the version.\nNevertheless, it's a bad idea to use a path pointing to the Homebrew Cellar, it will break as soon as Bash gets updated to 5.2.16. Most binaries installed via Homebrew are linked to from $(brew --prefix)/bin (/opt/homebrew/bin for M1/M2), so to fix this\n\n*\n\n*edit /etc/shells (sudo nano /etc/shells), replace /opt/homebrew/Cellar/bash/5.2.15/bin/bash with /opt/homebrew/bin/bash\n\n*run chsh -s /opt/homebrew/bin/bash\n\n*open Terminal settings and set \"Shells open with\" to \"Default login shell\"\n\nThen restart Terminal.\n", "Q: How do I completely block the app store from an iPhone? I talked to customer service about this issue. The iMessage app contains access to the app store and it isn't something you can remove from the dock in there.\nI need some ideas on how to block access to the app store as it has inappropriate content for my child, but they need to be able to use iMessage as well.\nRestricting the app store app in screen time doesn't remove the widget from iMessage. It isn't able to be removed by conventional means, so looking for some suggestions.\n\nA: You have to set \"Screen Time Restrictions\".\n\n*\n\n*Go to settings\n\n*Select the \"Screen Time\" option\n\n*Select \"Turn On Screen Time\"\n\n*Select \"This is my Child's Ipad\"\n\n*Personalize\n\n*Select \"Content and Privacy Restrictions\" and turn it on\n\n*Select \"Allowed Apps\"\n\n*Disable App Store\n\nHope this helps! :)\n", "Q: MacOS Microsoft Remote Desktop - external monitors cut in half horizontally Upgraded my MacBook Pro to Ventura 13.2.1. Dual monitors connected via a thunderbolt hub. This has worked bun multiple monitor mode for the past 9 months until now (the OS upgrade). Rebooted the remote Win10 desktop and my local Mac.\nSingle monitor mode works fine. Both external monitors look like this and the MacBook monitor if fine. At a loss what to try next.\n\nA: So I figured it out by accident.  Prior to my Venture 13.2.1 update the RD app would glitch out unless the Man menu bar was on the laptop - the external monitors would get cut off on the top.\nOn a hunch I switched that back and now it works and the old glitch is gone.  Very weird but a win-win.\n", "Q: Is this a legit macOS modal, or a malware attempt? The following modal dialog prompting for a software update password has been popping up a few times and I really do not know what to make of it:\n\n*\n\n*it seems to be controlled by the Finder (not a browser or any particular app)\n\n*it does not seem to be part of the standard macOS update workflow, but coincidentally, there is an update available (as seen in my System Preferences)\n\n*I cannot find a single hit on Google for the exact wording in that modal\n\n*It seems plausible that it could come from one of the (very few) system extensions I have installed, but no indication of which.\n\nAny idea how I could confirm whether this is legit (although horrible UX) or Malware. And if the latter: how could I go about finding the source (the fact that this pops-up would indicate that the system is already partly compromised).\n\n\nA: This appears the same as when you run an update. However, to confirm I would recommend doing the following:\nCancel out of the alert and go to System Settings. Press to install the update. You will receive an alert shortly after that looks like this and can enter your password to install the update.\nYou can also download & run Malwarebytes to be safe - it doesn't hurt.\n\nA: I don't think your Mac is compromised. But it depends if you have already downloaded the update (In your System Preferences) (or if it has downloaded automatically) (anyways you should see the label \"downloaded\" or something similar (sorry if unclear)). If the update has been downloaded, it is normal to have this alert showing up, you have to confirm your password to install an update to your Mac, it is just a standard confirmation.\nHope this helps! :)\n", "Q: Taking a screenshot of the same area of the screen multiple times I often want to take before/after screenshots of things. I often use the inbuilt screenshot tool to screenshot a portion of the screen (cmd + shift + 4). However, having to redrag to get the same portion of the screen (and often get it slightly wrong) is an inconvenience.\nIdeally I would like to screenshot a portion of the screen as normal, then trigger a screenshot of the exact same selection as before.\nIs this possible?\n\nA: Since Mojave, the Screenshot application has allowed the user to define a rectangular of the part of the screen the user wishes to capture. This rectangle can be left unchanged in subsequent screen captures.\n\nWhich is basically what Tetsujin posted as an answer similar previous question.\n\nA: It is possible with the default Mac screenshot tool but you might want to check this (it might answer your question) : https://superuser.com/questions/875342/how-can-i-repeatedly-take-a-screenshot-of-a-specific-area-in-os-x\nAlso, the same type of question was already asked : How to take a screenshot of the same precise region with a key combo?\nHope this helps! :)\n", "Q: RSS Feed interrogation: What is it? What is an RSS Feed? I saw this multiple times on this website and it is in the shortcuts app.\nIs there someone to explain? Thank you\n\nA: An RSS Feed is a way to stay up to date on your chosen websites (or something else). It sends you information (title, description, and link back to the original content) about the website (or something else) you have chosen regularly\n", "Q: What sets the SHELL environment variable? I've set my default shell to be the Brew-installed Bash, and that's what I get when I run Terminal.app.\n\nHowever, something is still setting SHELL to /bin/zsh, which causes problems since some programs check this variable when spawning subshells.\n$ which bash\n/usr/local/bin/bash\n\n$ echo $BASH_VERSION\n5.2.15(1)-release\n\n$ echo $SHELL\n/bin/zsh\n\nWhat is setting this value for SHELL, and how do I permanently change or unset it?\n\nA: The screenshot you posted doesn’t set your default shell, it runs a command when you open the default shell (which is Zsh).  In this case, you’re opening Bash from Zsh.\nHow to fix:\n\n*\n\n*Reset the setting back to \"Default Login Shell\"\n\n\n*Issue the following command to change your login shell:\nchsh -s /usr/local/bin/bash\n\n\n\n*Close your Terminal windows and reopen.\n", "Q: iphone gets dimmer occasionally I have auto brightness turned off, and I still notice sometimes my iphone will get dimmer randomly. When it gets dimmer, I check the brightness and it's on max brightness, so I'm not sure what's going on. Could someone advise?\nI am using iphone 12 pro on iOS 13.1 though this problem occured in the past on older iOS versions. The use is indoor and there's seemingly no lighting change in my environment\n\nA: Maybe this abrupt luminosity changes are linked to your battery level and therefore the automated activation of low power mode. Low power mode slightly reduces your luminosity while in use. It normally activates automatically when your battery reaches 20% and deactivates when your battery is at 80%. If you are using your iPhone while charging it, it might be a reason.\nThere are 2 solutions to me:\n\n*\n\n*Disable low power mode when it pops up.\n\n*Or, create an automation the \"Shortcuts\" saying that when low power mode is turned on, disable low power mode.\n\nHope this helps!\n", "Q: AirDrop - *Only* show Contacts' Devices as *Recipients*? Question:\nDoes anyone know of a settings hack to prevent me from being able to see people not in my contacts as AirDrop recipients (regardless of their own privacy settings)?\nMore details:\nThis is the opposite of the traditional problem* with AirDrop ; in this case, my neighbor(s) annoyingly leave their AirDrop discoverability settings as \"Everyone,\" meaning their devices pop up every time I try to AirDrop something from one of my devices to the other. Combined with the fact that recipient bubbles pop in and out at random in the UI, I'm worried that I may mistakenly AirDrop them a sensitive document.\n* \"why isn't such and such device showing up\"\n\nA: Currently there’s no way to limit the possible recipients for you to send a file to.\nThough not explicitly stated by Apple, it’s conceivable that blocking recipients was not implemented because this would defeat the purpose of AirDrop:  to quickly and easily share files (like a contact) between iPhone/iPad.\nAirDrop security, from a recipient’s perspective, was implemented to protect against AirDrop SPAM\n\nCombined with the fact that recipient bubbles pop in and out at random in the UI, I'm worried that I may mistakenly AirDrop them a sensitive document.\n\nWhile this would be a great feature, it’s currently unavailable and there’s no AirDrop workaround.  However, if you do have a sensitive document to send, there are a couple  prudent measure you can take:\n\n*\n\n*Password protect the document and use a different method to communicate (i.e. Messages/SMS) the passkey.  The AirDropped document will be useless without the password.\n\n\n*Share it on iCloud, OneDrive (my preferred), DropBox, or similar and share a link via email.  The document or the link can be password protected similar as above\n\n\n*Email the document.\n", "Q: How can I update just one built-in app at a time, if possible? I have a MacBook Air computer that is running Catalina version 10.15.4. I know it is possible to just do an all-encompassing software update but I've had this computer for some five or six years by now, and I'm worried if my computer may not be able to handle a software update. It works very well currently for its age as a MacBook and I've read and heard about how sometimes Apple products' software updates intentionally bring down the quality of the device to convince the user to just buy a new one at the store.\nI don't know if this is really true or not for Apple computers, but I'm pretty sure that's how it is for phones, isn't it? Anyways, I don't want this to happen - but at the same time I really do like the new Apple maps interface I've seen on my friend's updated Mac. I wish I could just update just that app, like how one can do in the app store with other Apple apps like Pages, Garageband, etc. But since it's a built in app, it seems like the only way I can update Maps is to update the whole system, which I don't want. Is it possible to update just one built-in app without updating my entire computer?\n\nA: Apps are instructions to the OS. New apps may use new features of a new OS, which aren't available (or work differently) in the older OS. So it's unlikely that a newer version of Maps would work on an older OS.\nEven if the OS-bundled apps were available separate on the App Store, the Store won't let you download a version that requires a newer OS.\n\nThe notion that Apple deliberately makes older computers (or phones) run slower on new OSes to encourage hardware sales is a lovely conspiracy theory, but not borne out by evidence.\nFirstly, it's in Apple's interest to have as many people as possible running the latest OS. A fragmented user base is not attractive to application developers, and having lots of third-party apps available is a major selling point for the platform to users.\nSecond, Apple makes more money from selling services than Macs. So, if you're paying for Apple Music, TV, iCloud Drive, App Store apps, then Apple is doing very nicely from you.\nMaking devices appear to be slow is not in Apple's interest, because it reflects badly on the experience of using an Apple device. If your Mac is running slow, you might decide to move to Windows or Linux instead.\nAdmittedly, to some extent, new OSes (and the apps that run on it) will want to use the increased computing power of newer hardware, so older devices may eventually struggle somewhat.\nBut at the same time, Apple is primarily focused on giving mobile devices a long battery life, and this is achieved in part by efficiency of operation.\nSome older devices are deliberately excluded from installing new OSes because the 'user experience' isn't good enough. Apple spends a lot of time and effort to try to make new OSes run on older devices; and only when they can't cope are they removed from support.\nThe support lifespan for Apple's phones is way ahead of Android devices. If Apple wanted to get people buying new phones, then they could just reduce the support lifespan.\nThe only time they have throttled devices is on phones with failing batteries, in order to avoid the phone switching off because the battery can't give maximum power anymore. Again, from the user experience perspective, having a phone that randomly switches off is worse than one that can't use full power.\n\nA: It's probably not possible. To be a bit more specific with benwiggy's answer, a lot of Apple's own apps will outsource their code to \"frameworks\" that are bundled in the system. For example, the Maps app code doesn't all exist in the Maps app itself; a bunch of code is moved to the GeoServices, MapKit, MapsSuggestions, MapsSupport, MapsSync, MapsUI, and Navigation frameworks, plus dozens more that are shared with other apps (as of Ventura 13.2.1). All of those are built in to the system, so you'd have to move over updated versions of every one of them. Those frameworks are also available to other apps, so you might get compatibility problems with other apps having mismatched versions. At that point, you'd probably be better off updating the entire OS.\n(If you're curious, you can run the otool -L \"/System/Applications/Maps.app/Contents/MacOS/Maps\" command in the Terminal app to get a list of all the frameworks that the Maps app uses. The command works with other apps as well.)\n", "Q: No images appear when visiting netflix.com using Safari under macOS Somewhat recently I have been having issues with Netflix.com while using my MacBook Pro (15\" 2018). I currently have macOS Monterey 12.6.3 with Safari 16.3. The problem has been happening for over a month I think.\nI've also just noticed that despite visiting https://netflix.com, there is no lock icon next to the URL in the address bar unlike all of my other tabs for other https sites I'm currently on.\nThe only Safari Extension I have installed is AdGuard and the problem exists whether the extension is enabled or not. Netflix.com is the only site I've seen this problem with.\nIf I visit Netflix.com using my iPhone 13 Pro with iOS 16.3 while on the same Wi-Fi network as my MacBook Pro, all images appear just fine and the lock icon appears next to the URL.\nIf I select \"Show Page Source\" and look in the console I see a whole bunch of errors like the following:\n\n[Error] [Report Only] Refused to load http://occ-0-114-3419.1.nflxso.net/dnm/api/v6/<long string of letters and numbers>.avif?r=229 because it does not appear in the img-src directive of the Content Security Policy.\n\nI also see a bunch of warnings similar to the following:\n\n[Warning] The page at https://www.netflix.com/browse was allowed to display insecure content from http://occ-0-114-3419.1.nflxso.net/dnm/api/v6/<long string of letters and numbers>.avif?r=229. (browse, line 6)\n\nI've restarted my Mac, restarted Safari, used the Developer menu to clear caches. Nothing I've tried is working.\nDoes anyone know how to resolve these two issues (get images to appear, get lock icon to appear)?\nIf any additional information is needed, please ask.\n\nA: While not the ideal solution, I was able to get this working by updating macOS from 12.6.3 to 13.2.1 (the latest as of this writing).\nOddly, Safari is still at version 16.3 after the update so I don't know why this fixed the issue. I didn't get a good look at the build number under macOS 12.6.3 so maybe this version of Safari 16.3 is a slightly different build than the Safari 16.3 from macOS 12.6.3.\n", "Q: iPhone to monitor connectors with no noticeable latency I have a VP2768A monitor (provided by my employer), and I bought a lightning to HDMI cable yesterday because I wanted to project my iPhone 12 Pro to a larger monitor for certain activities (e.g. gaming). However, I noticed that there's a delay. It's not too bad (maybe around 100ms or so), but it's definitely not ideal for certain activities.\nThis is the cable that I purchased: RAVIAD Apple MFi Certified Lightning to HDMI Digital Cable\nI don’t know if it's possible to reduce or eliminate the delay. Should I try switching the cable  or is the latency more associated with the iPhone/monitor (which I can't replace)?\n\nA: \nShould I try switching the cable or is the latency more associated with the iPhone/monitor (which I can't replace)?\n\nYou could try switching out the cable, but you’re not likely to see much improvement. Your device itself isn’t the problem here, it’s the conversion from USB to a digital video signal that’s the culprit.\nIt’s technically a USB to HDMI adapter\nThe Lightning port does not supply a native video signal; just four data lines.  As such, it only supports a small number of signals:  USB, charging, and audio (via a DAC). This means that the video must be “created” to connect to your display/TV.\nBasically, there is a typical USB to HDMI (or VGA for analog) adapter embedded in the cable; it’s actually just the  chip.  That chip is just enclosed in an “all-in-one” cable that goes from the Lightning connector to the HDMI connector.\nCreating video takes time\nThis video signal creation means there is an inherent latency no matter what you do.  It takes time to create that signal and it will be nowhere as fast as the embedded GPU in your iPhone.\nGet a better cable…\nYou could potentially reduce the latency with a higher quality cable from a reputable cable manufacturer(I am partial to Anker, CableMatters, Belkin) or get the Apple Lightning to Digital AV adapter.  (IMO) The cable that you linked is from an unknown brand (likely Chineseium); it’s a red flag when they pepper their Amazon title with every potential keyword like they did.\nTL;DR\nBottom line, try a better quality cable to reduce the latency, but in this case, you cannot eliminate it.  It’s also important to remember, this feature was meant for mirroring your iPhone display for convenience, not to be an external display in which performance is a factor.\n", "Q: Does deleting iCloud backup deletes iCloud Photo library? The purple color denotes the backup and yellow color for iCloud photos. So does deleting this purple thing which is a backup (which I assume also has all the photos data), deletes the iCloud photo library too?\n\n\nA: The iCloud Backup, a.k.a. “that purple thing”, does not include any copies of the videos and photos kept through the Photos app on your iPhone when iCloud Photos is activated.\nTherefore, deleting an iCloud Backup would have no impact on your photo and video library kept through the Photos app on your iPhone. The deletion would affect neither such photos and videos locally stored on your iPhone nor their copies in iCloud Photos.\nDeleting an iCloud backup only deletes the iCloud backups of whatever is being backed up to iCloud from your iPhone as part of the iCloud Backup service, not anything on your iPhone and also not any of their copies in iCloud if they have gotten there through an iCloud service other than iCloud Backup such as iCloud Photos.\nSee the “What does iCloud back up?” Apple support webpage for more.\n", "Q: Shell script to reboot from different volume I have two installations of OSX (both Ventura) on my machine on two separate APFS volumes. I need to often switch between the two machines. I am only aware of the option to press and hold the power button during boot-up to be able to choose the machine I would like to boot from.\nQuestion: Is there a shell script I can run to make my machine restart and boot from the \"other\" volume? Ideally, this could be transformed into an Alfred workflow.\n\nA: I used the command suggested in comments and it worked.\nsudo bless -mount /Volumes/Boot_Volume -setBoot\n\nFrom there I can create a Bash/Zsh script, function or alias that I can call that will set my boot volume quickly.\n", "Q: Right Single Quotation Mark (U+2018) being replaced by Apostrophe (U+0027) in iTerm2 I use iTerm2 (version 3.50beta10) on my Mac (macOS 13.2.1). Whenever I paste a right single quotation mark (U+2018) aka (’) into a terminal window, it is replaced by an  apostrophe (‘) (U+0027).\nCan I disable that somehow?\nI am pasting using  ⌘ Command V.\n(I am aware I could use ⌥ Option ⌘ CommandV  for \"Advanced Paste\" to open a dialog and then ⌘ Command  ⏎ Return to paste my test, but I don't want more keys and more steps. I want it to paste what I copied.)\n\nA: You could try using an app called Keyboard Maestro.\nThis can allow you to set macros that can do what you're wanting.\nE.g. - you could set up a macro like (only in application iTerm2) when I paste \" RIGHT SINGLE QUOTATION MARK (U+2018) aka ’ \", backspace one character and type \"RIGHT SINGLE QUOTATION MARK (U+2018) aka ’\".\nNot the perfect solution but an easy workaround.\n", "Q: Issue with an installed public Github package: how and where can I raise my point? Recently, I habe some issues with a (public) software package available on Github which I would like to communicate to the developer such that others can follow the discussion.\nHow and where is the right procedure / place to do this?\n\nA: Issues\nCreate an issue:\n\nIssues can be used to keep track of bugs, enhancements, or other requests. For more information, see \"About issues.\"\n\n", "Q: PDF reader for iPad that refreshes automatically after changes to the PDF? I am looking for a pdf reader for my iPad Pro, which automatically refreshes the pdf when another app makes changes to the pdf.\nI using Vim in a-Shell to edit my LaTeX document and display the pdf next to it. When I use pdflatex to compile the LaTeX-file, I want the pdf reader to automatically show the then new generated pdf.\nThe only apps I found so far for this are the Readdle-Apps “Documents” and “PDF Expert”, but both require monthly payments after a short trail period and I cannot afford to pay monthly for something I am using regularly but not daily. I am more than happy to make a one-time-payment for it.\nDoes anybody know such a pdf reader?\n\nA: Nevermind, I finally found one myself: “PDF Viewer” from “PSPDFKit GmbH”. It has some subscription model, but only for advanced features that are not necessary for my case.\n", "Q: How to insert a link in Pages which allow me to redirect user to specific sections in the document? This is the part of my document:\n\nI would like to add links for line:\nMore info under points 3, 4 and 5.\n\nI mean the same points as it is linked in Table of contents:\n\nWhen I try to add link, there is no option for header or section...\n\n\nA: There are no default jumping points, i.e. bookmarks, for any type of header or section in Pages. You need to first create a bookmark for that point in your document so that you can create a link to it.\nTo create a bookmark for a header or a section:\n\n*\n\n*Go to its beginning.\n\n*Click on the Document icon on the top right.\n\n*Click the Bookmarks tab.\n\n*Click Add Bookmark.\n\nYou can now add a link to that point in your document by using the newly created bookmark. See the \"Add bookmarks and link to them in Pages on Mac\" Apple support webpage for more.\nYou can also create a bookmark through the Insert->Bookmark menu option or simply by pressing Alt ⌥+Command ⌘ +B after moving to that point in the document.\nP.S. Beware of adding a lot of links to bookmarks in a large Pages document, i.e. one with for example 50-60 pages or more. For some reason, Pages slows down noticeably whenever I try to add a link to a bookmark in such a document. The only workaround I could find is to restart Pages after adding a link to a bookmark in such a document. I have encountered this problem in pretty much all versions of Pages since 2018 and with numerous documents. Pages and the document returns to normal once a link to a bookmark is added in such a document and then restarted but adding a link to a bookmark becomes a hassle.\n", "Q: Why did my USB-C monitor stop working even though I didn't change anything? I have a MacBook Pro with 4 USB-C ports (it's the generation that has the Touch Bar nobody likes). I have a Dell USB-C monitor. I have used the two for months together and had no problems. Then a few days ago, the monitor just stopped getting a signal from the USB-C port. Same cable. I tried all 4 ports. I tried to force Detect Displays on the Mac. I tried cycling through inputs on the monitor. The monitor works. The Mac makes a sound and flashes when I plug it in so it's like it knows it's there, but I can't get it to drive the display. Unsure if this was the newest Ventura Update that created the problem. What else is there to try?\n\nA: I had to physically unplug the monitor. The problem survived a Mac restart. There's probably some USB-hub or other display-handling firmware in the monitor that gets confused and needs resetting.\n", "Q: Running GL applications through UTM: GLX: Failed to create context: GLXBadFBConfig I have a Mac with OSX installed, and I'm trying to run a virtual machine with Debian. I am using utm to virtualize Debian with the arm64 arch. When I run kitty, a graphical Linux terminal with 3D-acceleration, I'm getting\n[glfw error 65543]: GLX: Failed to create context: GLXBadFBConfig\nFailed to create GLFW temp window! This usually happens because of old/broken OpenGL drivers. kitty requires working OpenGL 3.3 drivers.\n\nHow can I resolve this error? I can get around this error with\nLIBGL_ALWAYS_SOFTWARE=true kitty\n\nBut, I want hardware acceleration which utm claims to support. If I look at my video device with lspci, I see it's\n00:02.0 Display controller: Red Hat, Inc. Virtio GPU (rev 01)\n\n\nA: OpenGL is not supported\n\nWhen I run kitty, a graphical Linux terminal with 3D-acceleration…\n\n3D acceleration requires a GPU.  The error message “This usually happens because of old/broken OpenGL drivers” also points to this; the drivers are “broken” because there’s no GPU to talk to because…\nUTM lacks the support for GPU emulation.\nPer the front page of the UTM website, it specifically states that it doesn’t support this feature (see below).  Granted, the information is under the heading concerning games, but OpenGL is something used extensively for gaming.\n\nCan I run games?\nNo, probably not. UTM does not currently support GPU emulation/virtualization on Windows and therefore lacks support for 3D acceleration (e.g. OpenGL and DirectX). There is experimental support for hardware OpenGL acceleration on Linux through Virgl.\n\nEmphasis Mine\nAs for Linux, the support is only experimental and looks to be a port of some kind from/supported on QEMU.  Take that to mean that in UTM’s current state,  it’s not currently supported.\n\nA: This seems to be a bug related to OpenGL 3.3 specifically.\nhttps://github.com/utmapp/UTM/issues/4285\n", "Q: Repair of internal SSD? I can no longer boot from up my Samsung EVO SSD 1TB. I messed it up while trying to install OpenCore on my MBP 2012.\nI can reach the drive from a docking station on a second Mac.\nFirstAid of either the disk or the Volumes failed.\ndiskutil recoverVolume/-Disk failed, also diskutil repairVolume/-Disk.\nAny thing else I can do before erasing it completely + TM Restore??\nWould appreciate any suggestions?\n\nA: Since you can see the drive from another Mac, you could try a data-recovery program.  But I haven't tried any commercial ones myself, and was very UNimpressed by all the free ones I tried.  Still, I've heard that some of them can fix things Disk Utility can't fix.\nI've also been \"impressed\" by Disk Utility's ability to precisely identify an error without being able to fix it.  The most recent was \"bad (something) number of (large number)\" and refusing to mount the volume.  Seems they could overwrite it with something legitimate and mark as free space any orphaned sectors.  It would take a long time to do so, but \"First Aid\" always takes a long time anyway even if no errors.\n", "Q: Cannot download updates: Failed Software Update - Refusing invalid certificate from host: swcdn.apple.com I have a MacBook 2019 and when I am trying to install macOS Ventura I get the following error immediately before the download starts:\n\nInstallation failed\nAn error occurred while installing the selected updates.\n\nAfter checking install.log (available at About this Mac / System report / Software / Logs) I can see that the download fails with the following error:\nFailed Software Update - Refusing invalid certificate from host: swcdn.apple.com\n\nI have also tried running the softwareupdate tool with no luck:\n➜ softwareupdate -l\nSoftware Update Tool\n\nFinding available software\nThe operation couldn't be completed. (NSURLErrorDomain error -1012.)\n\nThis generates a similar certificate error for a different URL:\nFailed Software Update - Refusing invalid certificate from host: swscan.apple.com\n\nOpening the specific URLs in the browser shows me they have a valid certificate. As a last effort, I did update the root certificate to be always trusted but this did not help either.\nThe time is correctly set on my machine.\nHave anyone experienced a similar issue? What can be the solution?\n\n\nA: If there is more than one digicert listed under \"system\" in keychain access then look at removing the one not in the \"system roots\" category.\n", "Q: Private Mac Address in iPhone When I connect to Wi-Fi in public spaces I use \"private MAC address\" for each connection. Does Apple have a database (and save) each of the private mac addresses used by my phone device or it's absolutely private?\n\nA: It will be temporary stored on device in certain logs like the WiFi connection log but that isn't transmitted to Apple or anything so it's pretty private to your device.\n", "Q: Can't figure out how to get fzf to ignore ~/Library ~/Applications and ~/Music on OSX I've gotten fzf to work on MacOS X Ventura with the Kitty terminal, and it's great!\nAlt+T and Alt+C work as expected, but there's one fly in the ointment.\nI can't get either of them to ignore all the spurious files in ~/Library ~/Applications or ~/Music\nMy environment variables look like this:\nexport FZF_DEFAULT_COMMAND=\"fd . $HOME\"\nexport FZF_CTRL_T_COMMAND=\"$FZF_DEFAULT_COMMAND\"\nexport FZF_ALT_C_COMMAND=\"fd -t d . $HOME\"\n\nThe fd docs say it should ignore anything in my ~/.config/git/ignore, and I've tried adding:\nLibrary\nApplications\nMusic\n\n**/Library\n**/Applications\n**/Music\n\nAs well as a bunch of other combinations with no success.\nThanks in advance for any clues!\n\nA: In the end analysis, the answer turned out to be adding the absolute paths to $HOME/.config/fd/ignore.\nI think Marc Wilson was on the right track, but in the end analysis I decided that putting the restrictions into fd's config was the better choice.\nThanks for the commnts!\n", "Q: Reinstalled High Sierra: System now extremely slow and unresponsive In attempting to solve another problem, I've tried to reinstall macOS High Sierra onto my Mac mini (2011). Everything seemed to go fine with the install, however after booting up it is now extremely slow. Every action I take requires a beachball, every button I press in any application, including clicking the red X button to close a window will cause the machine to lock up for a few seconds. Any application I try to launch bounces on the dock for 15-30 seconds. They system is basically unusable, and won't respond to any of my attempts to connect to its file shares, which means I cannot access any of my documents, which has me very stressed out. (This Mac's primary job is to host files from its internal drive, which I connect to with my MacBook).\nSome additional notes:\n\n*\n\n*There are no processes consuming the CPU\n\n*There are no processes using up all the memory\n\n*The OS is on an internal SSD which is performing fine.\n\n*This behavior is not limited to GUI apps, entering terminal commands, even ssh'd in from a different machine frequently locks the machine up\n\n*I am using Remote Desktop to control this machine and every minute or so it completely locks up and enters the \"Reconnecting...\" phase for some time. Seems like this is only getting worse.\n\n\nA: This is a known issue with that version of macOS.\nIt's internally doing a bunch of stuff, the solution is to simply wait.\nSo for example if you have errands to run or something make sure sleep is set to off and leave the Mac running.  It'll come back to normal soon.  On my old iMac it probably took half a day but that didn't have an SSD so yours should be faster.\n", "Q: Where are file extended attributes saved? It seems to be an obvious question, but for some reason I cannot find an answer. Apparently, I just discovered a well-known MacOS feature: extended file attributes.\nContext: When I download a file, I see that Finder shows \"Where from\" for a downloaded JPG file when looking up the file properties. However, once I've used exiftool to add an XMP/IPTC attribute (so something different), the \"Where from\" disappears. I undertsand that exiftools edits EXIF/XMP/IPTC tags, while \"where from\" is the extended attribute. However I don't understand why exiftool has an effect on it.\nI wonder where this attribute is stored. I do not mind it being present of absent, but I want to avoid file modification as much as possible (for archival preservation reasons)---especially the uncontrolled modification. So, is it stored in the file, and exiftool deletes it though I didn't ask it to, or is it stored somewhere else in the file system, and in that sense its disappearance doesn't indicate the file modification?\n\nA: Extended attributes are stored separately in the file system (such as APFS or HFS+).\nThis means that the extended attributes are not stored inside the main file data, so no file modification takes place when adding, removing or editing extended attributes. In fact you can add extended attributes to other file system objects than files - for example directories and symbolic links.\nOn macOS you can manipulate extended attributes from the Terminal by using the xattr command. In the following I'll demonstrate in a simple way that extended attributes are not stored inside the file data:\nFirst we'll fire up Terminal.app and run the following commands to create a sample data file named testcontaining just the word \"TEST\" and calculating an MD5 checksum of its contents:\necho \"TEST\" > test\nmd5 test\n\nYou'll get the following result:\nMD5 (test) = 2debfdcf79f03e4a65a667d21ef9de14\n\nNow if you change the contents of the file in (almost) any way, you'll get a different MD5 checksum value.\nNow we'll add an extended attribute named \"test.attribute\" with the value \"value\" to the file:\nxattr -w test.attribute value test\n\nWe can confirm that the extended attribute is stored in the file system like this:\nxattr -l test\n\nThis will read out that the \"test\" file has an attributed named test.attribute with the value \"value\".\nNow rerun md5 to get the checksum of the file's contents:\nmd5 test\n\nYou'll see that you get the exact same MD5 checksum as before.\nHistorically, extended attributes were originally added to macOS as a file system feature in HFS+ with the release of Mac OS X 10.4 Tiger back in 2005. Even much earlier than that, Mac OS X had similar features that allowed storing extra data alongside files - for example in so called \"Named Forks\" and \"Resource Forks\". Those features dates back to eighties.\nIn modern day macOS, extended attributes are natively supported by APFS. If you look at Apple's reference documentation for APFS, you'll find that it specifies an object type APFS_TYPE_XATTR with a j_xattr_key structure, which basically contains the name of the attribute (for example \"com.apple.quarantine\"), and a j_xattr_val structure, which basically contains the value of the attribute.\nIn addition to the value of the attribute, the j_xattr_val structure also specifies exactly where the attribute data is actually stored in the file system. It can be either stored in a data stream (in extents for large attributes), embedded directly in the file system record (for small attributes), or handled directly by the file system (i.e. a specific attribute that has a dedicated structure for it in the file system - most prominently used for symbolic and firm links).\n\nA: EXIF data is stored within the JPG, if you'd like to modify other EXIF attributes, you can keep the original date and time with this:\n\"-filemodifydate<datetimeoriginal\"\n\nHTH!\nSources:\nhttps://www.phototraces.com/b/what-is-exif-data/\nhttps://exiftool.org/forum/index.php?topic=1666.0\n\nA: These attributes are stored totally separate from the file itself, in a special section of the disk volume.  So adding, removing or modifying extended attributes does not alter the file in any way.\n", "Q: Repair MBR or GPT Table from recovery as both OSs fail to boot On my Mac Mini 2014 I tried to repair GPT table (MBR.. ?) with an answer given on Trying to rebuild my partition map (using GPT fdisk, SIP disabled) for my issue of Windows 10 not booting itself but by going through the Option menu on each boot. And, it's messed up now.\nI can't boot to any of the OS now. I even can't reinstall the MacOS. I have tried to take screenshots of the output with the reference of the thread. Please help me to recover my OSs.\n\n\n\n\n\nHUM\n\nNew screenshots:\n\n*\n\n*DiskUtil\n\nAdditional information:\nHums-Mac-mini:~ humgurung$ ls /Volumes/BOOTCAMP/boot/bcd\nls: /Volumes/BOOTCAMP/boot/bcd: No such file or directory\nHums-Mac-mini:~ humgurung$ sudo diskutil mount disk0s1\nVolume EFI on disk0s1 mounted\nHums-Mac-mini:~ humgurung$ ls /Volumes/EFI/EFI/Microsoft/Boot/bcd\nls: /Volumes/EFI/EFI/Microsoft/Boot/bcd: No such file or directory\nHums-Mac-mini:~ humgurung$ diskutil unmount disk0s1\nVolume EFI on disk0s1 unmounted\n\nHums-Mac-mini:~ humgurung$ sudo fdisk /dev/disk0\nPassword:\nDisk: /dev/disk0    geometry: 60801/255/63 [976773168 sectors]\nSignature: 0xAA55\n         Starting       Ending\n #: id  cyl  hd sec -  cyl  hd sec [     start -       size]\n------------------------------------------------------------------------\n 1: EE    0   0   2 -   25 127  14 [         1 -     409639] <Unknown ID>\n 2: AF   25 127  15 - 1023 254  63 [    409640 -  195312496] HFS+        \n*3: F7 1023 254  63 - 1023 254  63 [ 195723264 -  781049856] <Unknown ID>\n 4: 00    0   0   0 -    0   0   0 [         0 -          0] unused      \nHums-Mac-mini:~ humgurung$\n\nUPDATE 2 RESULT:\n\n\nA: \nThis answer is only intended make macOS bootable. There may be further repairs which need to be made.\n\nYou should be able to use the following command to make macOS bootable.\nfdisk -e /dev/disk0\n\nThis command is interactive. Enter the values in the order given in the first column of the table below.\n\n\n\n\nEntry\nType\nComment\n\n\n\n\ne 4\ncommand\nEdit given table entry 4\n\n\n0\nparameter\nPartition id ('0' to disable)\n\n\nq\ncommand\nQuit edit of current MBR, saving current changes\n\n\n\n\nUpdate 1:\nIf the Boot Camp Assistant is used to install Windows 10 on your 2014 Mac, Windows 10 is installed to UEFI boot. From what you have posted so far, it would appear Windows 10 is installed to BIOS boot. This could happen if you upgraded from a previous Windows install (such as Windows 7). The existence of a BCD file in the /Volumes/BOOTCAMP/boot folder would indicate BIOS booting. In other words, the output from the command below can be used to help determined is Windows BIOS boots.\nls /Volumes/BOOTCAMP/boot/bcd\n\nThe existence of a BCD file in the /Volumes/EFI/EFI/Microsoft/Boot folder would indicate UEFI booting. In other words, the output from the commands below can be used to help determined is Windows UEFI boots.\nsudo diskutil mount disk0s1\nls /Volumes/EFI/EFI/Microsoft/Boot/bcd\ndiskutil unmount disk0s1\n\nCould you enter the above commands while booted to macOS and post the output?\n\nUpdate 2:\nThe id the MBR table for the third partition should be 07. This can be changed by entering the following command while booted to recovery mode.\nfdisk -e /dev/disk0\n\nThe interactive entries can be taken from the first column of the table below.\n\n\n\n\nEntry\nType\nComment\n\n\n\n\ns 3\ncommand\nSet the identifier of table entry 3\n\n\n7\nparameter\nPartition id\n\n\nq\ncommand\nQuit edit of current MBR, saving current changes\n\n\ny\nparameter\n(Optional) Enter if asked for OK\n\n\n\n\n\nNote: In the MBR table, the id of the second partition currently is AF, which represents a HFS+ type partition. Actually, your second partition is APFS, but since there is no official id assigned to APFS, you might as well leave the id as AF.\n\n", "Q: Query whether MacBook is plugged or on battery from shell script I am writing a shell script that I will leave running in background for some syncing tasks. I would like this script to behave differently depending on whether my MacBook is plugged to a power source, or on battery.\nIs there a way to determine from within a shell script, wether my MacBook (which is running the script) is on battery, or plugged?\n\nA: You can leverage the pmset (power management settings) tool from a shell script to ascertain if you are running on battery or AC power. See the manual pages (man pmset) for more details.\nFor example, when connected to AC power:\npmset -g ps\n\nNow drawing from 'AC Power'\n -InternalBattery-0 (id=5898339)        79%; charging; (no estimate)     present: true\n\nAnd when running on battery power:\npmset -g ps\n\nNow drawing from 'Battery Power'\n -InternalBattery-0 (id=5898339)        79%; discharging; (no estimate) present: true\n\nTo capture the current power condition in a bash script, use something like:\n[[ $(pmset -g ps|grep \"AC Power\") ]] && state=\"AC\" || state=\"BATT\"\n\nAn alternative way to capture the current power source was suggested by @nohillside. This directly snips the token \"AC\" or \"Battery\" from pmset output:\nstate=$(pmset -g ps|sed -nE \"s|.*'(.*) Power.*|\\1|p\")\n\n", "Q: Installing R 4.2.2 (ARM) fails I am trying to update from R 4.2.1 to R 4.2.2 via the .pkg installer. However, I can't install since I get the message The installation failed. The installer encountered an error and let me contact the software manufacturer. You can see a similar case here. Seems like the only available solution so far is to reinstall macOS and I really want to avoid that. Anyone else having this problem? I also tried to trash the R.app, but it was of no use. I could also delete the R.framework folder, but I doubt it will be of any use. Any ideas here?\nEDIT: I could succesfully install via commandline $ sudo installer -pkg R-4.2.2-arm64.pkg -target /. The same problem occurred trying to install XQuartz-2.8.5, which I could also succesfully install via CLI. Not all .pkg fail via GUI though. I could install Adobe Reader successfully via GUI.\n/var/log/install.log show the same error for RStudio and XQuartz:\n2023-03-02 14:12:13+01 [device] installd[802]: PackageKit: Install Failed: Error Domain=PKInstallErrorDomain Code=110 \"Beim Extrahieren von Dateien aus dem Paket „R-4.2.2-arm64.pkg“ ist ein Fehler aufgetreten.\" UserInfo={NSLocalizedDescription=Beim Extrahieren von Dateien aus dem Paket „R-4.2.2-arm64.pkg“ ist ein Fehler aufgetreten., NSURL=file:///Users/gernophil/Downloads/R-4.2.2-arm64.pkg#R-fw.pkg, PKInstallPackageIdentifier=org.R-project.arm64.R.fw.pkg, NSUnderlyingError=0x13c289e50 {Error Domain=PKXARArchiveErrorDomain Code=101 \"archive open failed\" UserInfo={NSURL=file:///Users/gernophil/Downloads/R-4.2.2-arm64.pkg, NSFileOwnerAccountID=501, NSFileHFSTypeCode=0, NSFileSystemFileNumber=33338670, NSFileExtensionHidden=false, NSFileSystemNumber=16777234, NSFileSize=90203062, NSFileGroupOwnerAccountID=20, NSFileHFSCreatorCode=0, NSFileOwnerAccountName=gernophil, NSFilePosixPermissions=420, NSFileCreationDate=2023-03-02 13:01:34 +0000, NSFileType=NSFileTypeRegular, NSFileProtectionKey=NSFileProtectionCompleteUntilFirstUserAuthentication, NSFileGroupOwnerAccountName=staff, NSFileReferenceCount=1, NSFileModificationDate=2023-03-02 13:01:40 +0000, NSLocalizedDescription=archive open failed}}} {\n        NSLocalizedDescription = \"Beim Extrahieren von Dateien aus dem Paket \\U201eR-4.2.2-arm64.pkg\\U201c ist ein Fehler aufgetreten.\";\n        NSURL = \"file:///Users/gernophil/Downloads/R-4.2.2-arm64.pkg#R-fw.pkg\";\n        NSUnderlyingError = \"Error Domain=PKXARArchiveErrorDomain Code=101 \\\"archive open failed\\\" UserInfo={NSURL=file:///Users/gernophil/Downloads/R-4.2.2-arm64.pkg, NSFileOwnerAccountID=501, NSFileHFSTypeCode=0, NSFileSystemFileNumber=33338670, NSFileExtensionHidden=false, NSFileSystemNumber=16777234, NSFileSize=90203062, NSFileGroupOwnerAccountID=20, NSFileHFSCreatorCode=0, NSFileOwnerAccountName=gernophil, NSFilePosixPermissions=420, NSFileCreationDate=2023-03-02 13:01:34 +0000, NSFileType=NSFileTypeRegular, NSFileProtectionKey=NSFileProtectionCompleteUntilFirstUserAuthentication, NSFileGroupOwnerAccountName=staff, NSFileReferenceCount=1, NSFileModificationDate=2023-03-02 13:01:40 +0000, NSLocalizedDescription=archive open failed}\";\n        PKInstallPackageIdentifier = \"org.R-project.arm64.R.fw.pkg\";\n    }\n2023-03-02 14:12:13+01 [device] installd[802]: PackageKit: Cleared responsibility for install from 9550.\n2023-03-02 14:12:13+01 [device] installd[802]: PackageKit: Cleared permissions on Installer.app\n2023-03-02 14:12:13+01 [device] installd[802]: PackageKit: Hosted team responsible for install has been cleared.\n2023-03-02 14:12:13+01 [device] installd[802]: PackageKit: Running idle tasks\n2023-03-02 14:12:13+01 [device] installd[802]: PackageKit: Done with sandbox removals\n2023-03-02 14:12:13+01 [device] installd[802]: PackageKit: Removing client PKInstallDaemonClient pid=9550, uid=501 (/System/Library/CoreServices/Installer.app/Contents/MacOS/Installer)\n2023-03-02 14:12:13+01 [device] Installer[9550]: install:didFailWithError:Error Domain=PKInstallErrorDomain Code=110 \"Beim Extrahieren von Dateien aus dem Paket „R-4.2.2-arm64.pkg“ ist ein Fehler aufgetreten.\" UserInfo={NSUnderlyingError=0x6000018040f0 {Error Domain=PKXARArchiveErrorDomain Code=101 \"archive open failed\" UserInfo={NSURL=file:///Users/gernophil/Downloads/R-4.2.2-arm64.pkg, NSFileOwnerAccountID=501, NSFileHFSTypeCode=0, NSFileSystemFileNumber=33338670, NSFileExtensionHidden=false, NSFileSystemNumber=16777234, NSFileSize=90203062, NSFileGroupOwnerAccountID=20, NSFileHFSCreatorCode=0, NSFileOwnerAccountName=gernophil, NSFilePosixPermissions=420, NSFileCreationDate=2023-03-02 13:01:34 +0000, NSFileType=NSFileTypeRegular, NSFileProtectionKey=NSFileProtectionCompleteUntilFirstUserAuthentication, NSFileGroupOwnerAccountName=staff, NSFileReferenceCount=1, NSFileModificationDate=2023-03-02 13:01:40 +0000, NSLocalizedDescription=archive open failed}}, NSURL=file:///Users/gernophil/Downloads/R-4.2.2-arm64.pkg#R-fw.pkg, PKInstallPackageIdentifier=org.R-project.arm64.R.fw.pkg, NSLocalizedDescription=Beim Extrahieren von Dateien aus dem Paket „R-4.2.2-arm64.pkg“ ist ein Fehler aufgetreten.}\n2023-03-02 14:12:14+01 [device] Installer[9550]: Install failed: Die Installation ist aufgrund eines Fehlers fehlgeschlagen. Wende dich an den Hersteller der Software.\n2023-03-02 14:12:14+01 [device] Installer[9550]: IFDInstallController 16DBF00 state = 8\n2023-03-02 14:12:14+01 [device] Installer[9550]: Displaying 'Install Failed' UI.\n2023-03-02 14:12:14+01 [device] Installer[9550]: 'Install Failed' UI displayed message:'Die Installation ist aufgrund eines Fehlers fehlgeschlagen. Wende dich an den Hersteller der Software.'.\n(sorry for German)\n\n\nA: The solution was to give the installer full disk access.\n", "Q: How can I clone my internal BOOTCAMP to a bootable USB? I have problems with a windows game on Bootcamp that used to work fine, and now doesn't. So I tried making a bootable bootcamp on a USB. Bootcamp runs on the USB but I would say it doesn't run as well as on my mac's internal HDD. Windows tend to not respond a lot. Also, the 32bit windows game on the USB crashes from memory errors even though I use LargeAddressAware. The game does not crash on my original bootcamp and I can get the game to use over 2GB RAM and it doesn't crash. I think maybe getting my original bootcamp setup on the flash drive might fix my issue. I also want to use this USB to be able to test doing things without it messing up my original bootcamp.\nI have read that bootcamp can have problems from USB and it's better to clone your existing bootcamp to the USB. Using WintoUSB seems like a great option, but I have Windows 10 Pro, and you can't use WintoUSB with Windows 10 Pro.\nI have also read that you can create a .CDR image using Disk Utility and then convert it to an .iso; then I guess I can use Rufus maybe to burn it to the usb. But the problem is, the BOOTCAMP uses 100GB but is a 230GB partition. I have more than 100GB available on my mac, but not 230GB and it told me there's not enough space. Also, everything I try takes so long, so I want to know what will work because I'm getting nowhere when trying things myself.\nCan anyone suggest an easy way to clone BOOTCAMP (with Windows 10 Pro) to a USB? I have access to both Mac and Windows to do this from. Ideally I want it to clone directly so I don't have to store the 100GB or 230GB somewhere other than the USB drive.\n\nA: Since you feel your internal HDD is failing, you would be better off doing a clean install of Windows 10 to a bootable external SSD. I would not recommend trying to install Windows to flash drive. The Boot Camp Assistant can not be used to install Windows 10 on to a external SSD. There are references given at the end of this answer, which outline various methods that can  be used to install Windows 10 to an external USB SSD.\nCurrently, you have Windows 10 install on your internal SATA HDD. The SATA interface has a maximum transfer limit of 6 Gb/s. This is more than adequate of HDDs, which generally have a transfer limit that does not exceed 3 Gb/s. Modern SSD chips can read/write data a speeds which well exceed 10 Gb/s. This means the performance of a Windows 10 installation on a modern external SSD should exceed that of your existing internal SATA HDD installation. The table below shows which ports on your Mac you can connect an external SSD.\n\n\n\n\nName\nPort Type\nTransfer Limit\nDoes Transfer Limit Havea Major Effect on theExternal SSD Speed?\n\n\n\n\nUSB 3.2 Gen 1x1USB 3.2 Gen 1USB 3.1 Gen 1USB 3.0\nUSB Type A\n5 Gb/s\nYes\n\n\nUSB 3.2 Gen 2x1USB 3.2 Gen 2USB 3.1 Gen 2\nUSB Type C\n10 Gb/s\nYes\n\n\nThunderbolt 3\nUSB Type C\n40 Gb/s\nNo\n\n\n\n\nYou should expect an external SSD which has a higher transfer limit to cost more and perform better than external SSDs with a lower transfer limit.\n\nWindows 10 is scheduled for retirement on Oct 14, 2025. You might consider installing Windows 11 on an external SSD. I did this late last year and was able to upgrade from Windows 10 for free. I do not know is upgrading is still free.\nReferences\n\n*\n\n*Is it possible to use Boot Camp with Windows 10 from an external HDD?\n\n*Drivers not working on Windows 10 installed (CLI process) on external SSD running on MacBook Air 2018\n", "Q: macOS 11+ on Intel based mac I am wondering if installing a new macOS (Big Sur and newer) that is meant for Apple Silicon macs, on an old Intel-based mac will carry any performance penalty. I'm thinking along the lines that all CPU instructions need to be translated to Intel instructions and that would result in worse performance than if using a fully updated macOS 10 (Catalina) which was meant for Intel.\n\nA: Big Sur, Monterey and Ventura contain code for both Intel and Apple Silicon CPUs. (As do most new applications -- they are 'Universal Binaries' that contain both sets of instructions.)\nThere is therefore no 'translation to Intel' required. All copies of macOS have Intel code (going back to Tiger 10.4 in 2006!). The latest OS, Ventura, supports Intel Macs from 2017 and later. Big Sur supports Intel Macs going back to 2013. These OS versions are not only for Apple Silicon; but for Intel Macs as well.\nM-series Macs can translate application code from Intel to Apple Silicon, and there is a slightly performance penalty; but this is at the application level, not at the OS level. No such capability exists for Intel code to run AS code.\nIt is generally advisable to be on the latest OS that your Mac can support -- though staying on Monterey until Ventura is a bit more mature is also a wise policy.\nYour Early 2015 MBP is supported by Monterey (the last OS it will run); and you should find it will run perfectly happily.\nIt's likely that some future OS will only contain Apple Silicon code, dropping support for Intel Macs altogether. (And halving the size of the OS!) Only then will the OS be 'meant for Apple Silicon'.\n", "Q: UTM crashes falling back to console with a black screen? For some reason when I'm in the virtualization application, UTM, and running a virtual machine when I run startx and Xorg starts, everything is smooth and it adjusts. But falling back down the the console -- exiting Xorg -- just leaves a black screen.\nIs there anyway to fix this problem?\n\nA: Not really a crash. Though the display is black, the system is not responseless. I can't figure out what's happening I'm still working on that but if you type,\n\n*\n\n*startx\nAs you did to start the X Windows system, it will again start Xorg and the display WILL work.\n", "Q: Deleting a binary from the bin folder that attempts to open at startup in Mac Ventura 13.2.1 There is a binary named 'Open' that resides in my /usr/bin folder that I cannot delete. I have tried sudo rm open and even tried sudo su and then rm open and it fails because I cannot override the permissions.\nI have tried to use chmod and that does not work either. Perhaps I need to enable root and then try?\nAny advice would be appreciated.\n\nA: \nThere is a binary named 'Open' that resides in my usr/bin folder that I cannot delete.\n\nYou cannot and should not delete this file!\nIt’s a macOS utility that allows you to open files and folders with the registered application (or alternatively specify a different one) from the command line. For full details, see the open man page.\nYou cannot delete the file nor modify its permissions because its protected by the read only volume of the APFS container.  Even with root privileges, you won’t be able to delete it; disabling SIP will not have any effect either.\nEven if you could, you’d be deleting a valid macOS binary.  This would likely be copied back to the /usr/bin directory on the next update.\n", "Q: How to check how long AC adapter has been connected Is there any way to check how long a 2020 M1 MacBook Pro has been connected to an AC adapter? (I have a charger that I think is periodically disconnecting and reconnecting.)\nI'd like something like Terminal \"uptime\" but for this purpose it'd print something, for example, \"On AC Adapter for H hours M minutes).\n\nA: pmset\nUse the built-in macOS command line tool pmset to see a log of power events. The log should include switches to and from AC power:\npmset -g log\n\n", "Q: \"Users & Groups\" does not display groups on Ventura 13.2 On Ventura 13.2, when I go to the \"Users & Groups\" settings page, no groups are displayed and there does not seem to be any way to make them appear.\nThe \"macOS User Guide\" indicates that there should be a section called \"Groups\" where I can \"View the list of groups. Click the Info button  next to a group name to view details and make changes. See Change Group settings.\", but there is no such section.\nI am an admin account.\n\nA: Default groups like admin or staff don't show up in Users & Groups. You can add your own groups by clicking Add Account... and selecting \"Group\" from the \"New Account\" dropdown. Groups created this way can afterwards be managed in Settings.\n", "Q: Problem with iCloud setting, pop-up warnings won't go away Since last week, I have been having this pop-up. I entered my password numerous times but it won't go away.\n\nI have also been getting the following warning. I open the AppleID panel and again enter my password. It seems to get accepted but then the pop-up comes up again.\n\n\nA: We used to get this a lot because of one of our security products. Best bet: sign out of your iCloud completely, reboot your machine, and then sign back in.\n", "Q: External display doesn't work, keeps disappearing and reappearing in settings I am trying to connect my MacBook Pro to an external display (HP E24i G4) via HDMI. The display doesn't work. When I go to Display Settings to check on it, I see the following:\n\nThen, in a split second, this\n\nAnd so it keeps \"blinking\", appearing and disappearing in display settings. The display itself stays dark the whole time\nThe display works fine with other computers. What can I do to resolve this?\n\nA: Press the \"Settings\" button on the display itself to open the settings menu. Navigate to \"input\". Most likely it is set to DisplayPort or something else. \"Auto-Switch input\" is set to True which should lead to the display auto-detecting that it needs to use HDMI, but with a Mac it leads to this weird blinking behavior. Switch to HDMI.\n", "Q: Can airtags be tracked from an iMac desktop, with no iPhone? I don't have an iPhone, but I want to use Apple airtags to track my bicycle, and other high value goods.   Can I get all the airtag tracking capability from an iMac desktop?\n\nA: Yes you can track an AirTag with your Mac, but you can't set it up unless you have an iOS device.\nVerbatim tracking instructions transcribed and formatted below, taken from the Apple Support link above:\nTrack\nSee the location of an item\n\n*\n\n*In the Find My app  on your Mac, click Items.\n\n\n*\n\n*Tip: If an item’s battery level is low, a low battery icon appears next to its name in the Items list. See the Apple Support article How to replace the battery in your AirTag.\n\n\n*In the Items list, select the item you want to locate.\n\n\n*\n\n*If the item can be located: It appears on the map so you can see where it is. The updated location and timestamp appear under the item’s name. If there’s a blue circle around the item, the location is approximate.\n\n*If the item can’t be located: Below the item’s name, “No location found” appears. If you want to be notified when the location is available, click the Info button  on the map, then select Notify When Found. You receive a notification once it’s located.\n\nImportant: Make sure you allow notifications for the Find My app. See Change Notifications settings on Mac.\n", "Q: Blue-ish band on a MacBook Pro screen I'm on a MacBook Pro 15-inch, 2018. I have just realized that there's a dark blue band on the bottom right of the screen. You can see it in this photo:\n\nI'm quite sure that it is a display problem, but I'd like to ask if there's something that I can do to mitigate that problem.\n\nA: Unfortunately, there’s nothing you can do to address this other than take it in for service.\nIt could be a loose or damaged flex cable or it could be a faulty panel that needs to be replaced.  Either way, it’s a physical issue that can’t be addressed other than a physical repair.\n", "Q: How to get rid of ghost device on FaceTime? On my iPhone in Settings > Phone > Calls on Other Devices, my MacBook appears twice.\nHow do I get rid of the second entry?\nI've tried logging out and back into iCloud, but it doesn't do the trick. I suspect it has to do with some \"lost\" key in iCloud Keychain.\nIt only appears twice there, so I'm assuming FaceTime, and not in the iCloud list of devices as well.\nAny idea how can I remove that extra entry?\n\nA: Change your Apple account password, and when asked, log out of all devices, this will force a log out of whatever \"ghost devices\" show up in \"Calls on Other Devices\" list.\n", "Q: Connect a Magic Keyboard to a Windows 10 PC with a Logitech Unifying Receiver? I hope someone can help me with this. I have a user at work that wants to connect her Apple Magic Keyboard to her Windows 10 work PC (she just likes the way the keys are).\nThe PCs don’t actually have a Bluetooth radio, they require a USB receiver to use anything with Bluetooth. Is it possible to connect her keyboard with a Logitech Unifying Receiver to her PC?\n\nA: \nIs it possible to connect her keyboard with a Logitech Unifying Receiver to her PC?\n\nNo.  The Unifying Receiver is a proprietary Logitech wireless protocol; it is not Bluetooth which is what the Magic Keyboard requires.\nPer the Technical Specifications:\n\nSystem Requirements\n\n*\n\n*Bluetooth-enabled Mac computer with OS X v10.11 or later\n\n*iOS devices running iOS 9.1 or later\n\n\nWhile it will likely connect (if you utilize a Bluetooth USB adapter), there’s no guarantee it will work as expected.\n", "Q: How to get the \"Your battery is broken\" message to go away? Every time I turn on my computer, I see a message saying something like:\nYour battery may be old or broken.\n\nI am already aware that my battery is bad. How do I suppress this message?\n\nA: This worked for me:\nIf you have a machine with Windows as a dual-boot option, you can boot to Windows and let the battery recharge here. When the battery has recharged for a while, you can boot to Ubuntu and let it do the rest.\n\nA: I run this:\ngconftool --set /org/mate/power-manager/notify-low-power --type boolean false\ngconftool --set /org/mate/power-manager/notify-low-capacity --type boolean false\n\n\nA: In Ubuntu mate, gconf editor is not installed by default and installing it will not help.\nInstead, you should use dconf editor.\nYou will need to navigate to /org/mate/power-manager and then untick notify-low-capacity.\n\nA: Maybe these instructions will help you to get rid of that message.\nAdded instructions from the link, Alt+F2, then type in gconf-editor. \nNavigate to /apps/gnome-power-manager/notify/low_capacity and untick the value.\nOr a single command:\ngconftool --set /apps/gnome-power-manager/notify/low_capacity --type boolean false\n\n", "Q: How can I set the Software Center to install software for non-root users? How can I set the Software Center to allow non-root users to install stuff from the Ubuntu repos without having to type in their password?\nI'm fully aware of the security implications, and I am willing to take the risk. Fedora 12 shipped with something like this. (By modifying the PolicyKit configuration, I believe)\n\nA: RAOF's answer applies to Ubuntu only. Kubuntu uses QAptWorker as backend (observed for Natty and Oneiric). To allow for non-root installations, create /etc/polkit-1/localauthority/50-local.d/10-allow-non-root-install-packages.pkla containing:\n[Update Software Sources]\nAction=org.kubuntu.qaptworker.updateCache\nResultAny=no\nResultInactive=no\nResultActive=yes\n\n[Install Software]\nAction=org.kubuntu.qaptworker.commitChanges\nResultAny=no\nResultInactive=no\nResultActive=auth_self\n\nI wanted to allow some non-admin users to install software while not granting sudo access directly. That was accomplished by inserting the next lines in both configuration groups:\nIdentity=unix-user:some-non-admin-user\n\nIf there is a group that must be granted permission, use unix-group instead of unix-user.\n\nA: If you only need a generic permission to allow/disallow package installation, go for PolicyKit.\nUnfortunately PolicyKit doesn't have fine control over the package to install. If you want to give your users permission to install only a restricted set of applications, you should use sudo and install something like softwarechannels...\nI also looked for something like that, but since I didn't find anything, I coded this easy solution \"softwarechannels\", available here on GitHub\nIt is a very simple system to allow common (non-admin) users to install packages from restricted catalogs.\nJust define 'channels' (groups of packages) in a simple text file and give your users permissions to launch softwarechannels.\nThey will only see packages in channels matching their unix groups.\n\nA: You can modify the PolicyKit permissions to allow the users to access the aptdaemon backend that Software Centre uses.\ndpkg --listfiles aptdaemon shows that /usr/share/polkit-1/actions/org.debian.apt.policy is the file specifying the actions possible on the aptdaemon backend.  \nLooking in that file, the < action id=\"\"> tags specify the possible actions.  You'd probably want org.debian.apt.install-packages to allow users to install new packages from the archive, and org.debian.apt.update-cache to allow users to update the package lists.\nSee man pklocalauthority which documents how to set local permissions on PolicyKit actions.  Putting the following into /etc/polkit-1/localauthority/50-local.d/10-allow-users-to-install.pkla will allow any user logged in to the local machine to install packages after typing their own password (even when they're not in the admin group) and to update the package cache without typing any password.\n[Untrusted Install]\nAction=org.debian.apt.install-or-remove-packages\nResultyAny=no\nResultInactive=no\nResultActive=auth_self\n\n[Untrusted Update]\nAction=org.debian.apt.update-cache\nResultAny=no\nResultInactive=no\nResultActive=yes\n\n\nA: I don't think it's currently possible to do so via the GUI, but the following should work, albeit be a little kludgy. YMMV. \nAdd the following line to /etc/sudoers (use sudo visudo to edit the file):\n%packageinstallers ALL = NOPASSWD: /usr/bin/software-center /usr/bin/apt-get\n\nThen you just need to create and add the specific users to the packageinstallers group:\n$ sudo addgroup packageinstallers\n$ sudo adduser jdoe packageinstallers\n\nNow jdoe can do the following:\n$ sudo apt-get install <some-package>\n\nand you can edit the desktop menu item for the Software Center so that it call on software-center prepending the command with gksudo. \nPolicyKit may allow you to do so without sudo, but it's beyond my understanding at this point. \n\nA: To make this working in my Ubuntu 18.04, I had to change the /etc/polkit-1/localauthority/50-local.d/10-allow-users-to-install.pkla file to:\n[Untrusted Install]\n#Action=org.debian.apt.install-or-remove-packages\nAction=org.freedesktop.packagekit.package-*\nResultyAny=no\nResultInactive=no\nResultActive=auth_self\nIdentity=*\n\n[Untrusted Update]\nAction=org.debian.apt.update-cache\nResultAny=no\nResultInactive=no\nResultActive=yes\nIdentity=*\n\n[Admin Install]\n#Action=org.debian.apt.install-or-remove-packages\nAction=org.freedesktop.packagekit.package-*\nResultyAny=no\nResultInactive=no\nResultActive=yes\nIdentity=unix-group:adm\n\nMoreover with the last rule I enable everybody in the adm group to install/remove without any password.\n", "Q: What are some alternatives to upgrading without using the standard upgrade system? What are some alternatives to upgrading without using the standard upgrade system? Suppose for example that I wanted to upgrade an Ubuntu installation on a machine with a poor Internet connection. What would my options be? Could I just use a standard Ubuntu disk to upgrade this machine? If I already have a standard Ubuntu disk and want to use that, could I do a clean install without wiping data?\n\nA: You can use the alternative CD (instead of Ubuntu Desktop, Kubuntu Desktop, Server CD) which allows you to upgrade from CD.\n\nA: You can do an installation of a newer version of Ubuntu over top of an existing installation.  You'll lose all of your (non-local [1]) system files and applications, but it will preserve everything in /home.\nSelect the advanced partitioning option from the menu of either the desktop CD installer or the alternate CD installer.  Set the mountpoint of your existing root partition to / and make sure the format box is not checked.  Repeat these steps for your home partition, if you have one.\n1: Where local system directories would be /usr/src, /usr/local, and /var/local\n", "Q: How to graphically interface with a headless server? I have a ubuntu development server at work. It is an old rack server that is located somewhere in the company's dungeon, where nobody ever goes. The only way it can work is as a so-called headless server (i.e. with no monitor/keyboard connected and only accepting network connections).\nObviously, if you just need terminal access ssh is more than enough. I, however, would also like to connect to the graphical interface from time to time. At the moment I am using the built in VNC functionality but I am pretty sure this is neither the most efficient nor the most secure way of approaching this issue.\nI have done a bit of research on the issue but failed to come to any definite conclusions. I read about trying to forward the X environment over ssh, which would at least solve my security concerns. Can anyone share their experiences in setting this up? Is there any other way that might be worth looking at?\nI almost exclusively connect to this server from a Windows machine. I don't know if that might be a problem for some of the methods suggested.\n\nA: I don't know about the \"best\" way, I guess YMMV, but here's a fairly comprehensive overview of tools at your disposal: http://www.mynitor.com/2010/02/07/15-remote-desktop-solutions-for-linux/\nI particular here's my experience:\n\n\n*\n\n*nomachine nx - Impressive speed. In its native mode it feels like you're in front of the console. It supports starting new sessions as well as shadowing the console (but shadowing is slower). It supports detaching and attaching to sessions. Clipboard sharing only worked one way for me and I wasn't able to fix it. nomachine offers free server and client packages with some licensing restrictions.\nFreeNX is built on the nomachine nx libraries\n\n*x2go - Impressed with this also especially sound redirection but I didn't use it for as long as nomachine nx because I found out about it later.\n\n*x11vnc - Great vnc server that is able to attach to the console session. Used it in conjunction with nomachine nx. I'm not sure if it can be run in headless mode but I'm listing it in case it can, because for me it was the fastest vnc server around.\n\n*xrdp - Looked promising but it looks to be unmaintained. The OpenSuse nomad solution is based on xrdp and I hear nomad is the best remote desktop experience you can get on linux.\n\n*teamviewer - The linux version is still beta, runs under wine and consumes some CPU but I used it a lot quite recently and I was pleased with it. Not sure if it works on a headless server.\n\nA: Also consider xpra, which allows you to detach to an running session from somewhere else, like \"screen for X\".\nThere's also Window Shifter, a front end for xpra, which should work also for Windows, see the demo.\n\nA: Yes, X forwarding over ssh is a beautiful thing indeed. It allows you to use graphical applications on an app by app basis and have windows handled by your own desktop environment. You do not even need a desktop environment installed on the server.\nYou do need to set up some authentication things for it to work though. I believe you need xauth for that.\nIt's SO much faster than VNC as well. VNC was always rather laggy in my experience.\nEdit:\nI have no experience using this method via Windows, but I found this tutorial for you if you're interested.\n\nA: You could use freenx instead of vnc. Freenx transmits x-commands (with caching) instead of bitmaps.\n\nA: Xming and XDMCP is a brillant option.\nEdit:\nXming is a x-server for windows, which is based on Cygwin and has the ability to share the clipboard and implements different desktop layouts as well.\nXDMCP is a simple and - important - unencrypted protocol (don't use it over the internet) to connect a X-displaymanager and a x-server.\n\nA: While inherently insecure, you could use XDMCP over a local network. I use it frequently to access virtual machines. Its just like logging on to your desktop, except you chose the remote server.\n\nA: I use x11vnc, which works very well for me. It lets you keep a persistent graphical session between connections, so you can disconnect and reconnect and everything will be just the way you left it. It also supports tunneling over SSH. See these Ubuntu community docs for a short description and some instructions on setting it up.\n\nA: I have successfully used freenx on Ubuntu using the Windows client from http://nomachine.com.\nFor me this was to allow me to use an old tablet PC (that struggled even with a clean install of Windows XP) as a front end into a more powerful Ubuntu desktop machine.\nThe only issue I had was that you needed to turn the \"Visual Effects\" to none to get decent performance.\nI was going to comment on txwikinger's answer suggesting nxserver, but I don't have enough reputation.\n\nA: Setting up for remote X access can be daunting, and involves multiple steps.\nI use x2go, which is load-and-go, and exceptionally easy to use. It gives you a full desktop, just as if you had connected a new screen and keyboard to your server. It has full X functionality.\nx2go is NOT a \"remote desktop\" solution. You get a completely new session. However, you can disconnect and reconnect from the same or different machine with the x2go client; your desktop is persistent. Best of all, the desktop on your client machine is completely scale-able in real-time simply by resizing the window.\nx2go uses ssh for transport, so your data is encrypted. This simplifies traversing firewalls. Speed doesn't feel impacted by the use of ssh for transport.\nx2go client software is available for Linux and Windows, and Mac.\nVery nice free and open source software. I use it every day.\n", "Q: How do I run a successful Ubuntu Hour? I'm taking my be-stickered laptop to a coffee shop tonight for an Ubuntu Hour.  I've let a bunch of local LUG people know about it.  How can I ensure people come away from it feeling like the experience was valuable?  Is there something you've done that was particularly successful?\nThere is a wiki page about Ubuntu Hours which is very helpful.  I'm interested in collecting best practices from the community.\n\nA: I've always helped identified people's needs and showed them how Ubuntu's implemented those needs. My audience is usually Mac and Windows people - but it's the same idea. Spend a few minutes touching on the new features in 10.04 then let the questions begin. I've also found that spending a little time highlighting what you like and use it for is also helpful to show why you like/use Ubuntu.\nTry not to (as I've made the mistake in the past) to be THIS IS > ALL OF YOUR ALTERNATIVES as it's usually frowned upon.\n\nA: The way we run our Ubuntu Hour is basically one of a very relaxed social interaction. No one needs to talk about Ubuntu if they don't want to and we generally let the flow of the hour or two take us to random places.\nBasically we just enjoy each others company.\nIt's important to not put too much of a burden or expectation, those kinds of more targeted events should be saved for specific things, like the Ubuntu Workshops etc.\nOh and make sure you pick a location that members can get to.\n\nA: I've always thought that the Ubuntu Hour isn't supposed to preach Ubuntu to the Linux converted (although if that happens, it's not necessarily a bad thing), it's more supposed to be try and encourage people who don't have any experience of Linux, let alone Ubuntu to give it a try.\nConsider making a small sign (just an A4 sheet folded into three - making a triangle should be fine) and write in VERY clear text \"Give Ubuntu Linux a try\". Make sure you've got Ubuntu images to hand, and if you've got a second machine that you can bring along as well, perhaps play some kind of demo video on there - perhaps something like this one: http://www.youtube.com/watch?v=ll3yDLeioXQ (there are many other copies of this!)\nSomeone I've seen doing a great job of demoing Ubuntu at BarCamps over the past few months is http://twitter.com/biglesp http://identi.ca/biglesp and he's encouraged people into doing a few installs at events recently.\n\nA: In my humble opinion an Ubuntu hour can serve two different purposes. It is possible for the event to serve one or the other, or both.\n\n\n*\n\n*Advocacy\nFor successful advocacy having informational handouts, CDs and a computer that people can sample improve the quality of the event. Handouts can contain Ubuntu only information or contain both information about Ubuntu and local LUGs or Free Software Groups. If people are interested in giving Ubuntu a try you can tell them about local groups that can help them or even arrange to help them at the next Ubuntu Hour. Advocacy at its simplest form is just having the logo visible so people think about Ubuntu like they do Apple or Windows.\n\n*Team Building\nAn event that helps support people currently using Ubuntu are a fantastic way of building friendships and camaraderie. These types of events usually require no more than giving advance notice and a choosing a comfortable gathering place with Internet access. If you are making use of a business space (coffee shop or similar) it is a good idea to plan on having to make purchases. With that in mind choosing a place that is not too expensive is ideal.\n\nFor both types of events remember that this is supposed to be a simple relaxed hour focused on making the Ubuntu experience a personal one. Remember to post the event at loco.ubuntu.com, your teams wiki and/or website. Working with local LUGs or Free Software groups can also be useful. Most importantly have fun.\n\nA: Step 0: Define your target audience.\nIf you've talked to your LUG, you've probably not tapped anyone that hasn't heard of Ubuntu. Try to reach outward, far beyond the traditional LUG crowd. Try to define and reach an audience that has no idea what Ubuntu is. That's where the real progress is made.\nStep 1: Advertise your event at least 1 week in advance. \nCreate small posters and place them in busy public places. Say something like: \"We're getting together to talk about Ubuntu. Please join us!\" (Have an email address or an RSVP link on the poster where people can indicate they are coming. RSVP'ing is better because it potentially lets you poll them for \"What do you expect from this meeting?\" )\nStep 2: Look at the Responses\nHow many people are coming? What are they looking for? Can you meet their expectations?\nStep 3: Prepare some small tent signs for the coffee shop tables. Make them professional, and make sure they conform to the Ubuntu Branding Guidelines. (You are representing Ubuntu so it's important to get this right.) Recognize that there will be many people that see the signs that have never heard of Ubuntu. First impressions count.\nStep 4: Don't get hung up on convention/tradition/governance or any other construct that doesn't necessarily apply to your situation. The people you'd meet at an Ubuntu themed event might be totally different that what has traditionally been the Ubuntu LoCo crowd in other areas. Do what seems right for your community, culture and situation.\nStep 5: Have fun. Always!\nPeople won't stick around if the events are boring, dull, or if it's all about creating work. That's what day jobs are for! (Unless they are Ubuntu day jobs of course!)\n\nA: Try and make it as regular as possible, that way you'll get to meet people more often but others will be able to pop in if they know it's going to happen so that it doesn't have to be pre arranged.  In Ireland we have 3 of them running, Dublin is on the last Wednesday of the month and people chose that date and it's worked out well.  \nWhat we've found is by picking somewhere central to meet up, people can have a bite to eat, or drink and chat.  Making it relaxed and not a formal event is key to making it fun and for it to happen again and again. \nIt's a fun way to explain/show people new features you've found in a casual way, so I've showed the Loco Directory and let people use my laptop if I was running the latest release.\nMake sure everyone is welcome, if there are new less technical people present and the topics are getting too technical, talk to them separately or perhaps suggest techy talk for another time.\nAbove all just have fun and chat about your community.  Ubuntu hours are about your local area and the people in your community. \n", "Q: How do I go back to KDE splash / login after installing XFCE? I started with Ubuntu Karmic, and wanted to try KDE. So I installed kubuntu-desktop. Then I wanted to see how XFCE progressed, so I installed xfce4. I now have Kubuntu with an XFCE splash and login.\nHow do I (safely) purge XFCE and just have the Kubuntu splash / login screen, or am I stuck with frank-en-buntu?\n\nA: You can just switch back the display manager to use kdm using \nsudo dpkg-reconfigure gdm\n\nand then selecting kdm.\n\nA: From a terminal:\nsudo apt-get remove xfce4\n\n\nA: splash screen is configured by the alternatives system... you can get a list of available plymouth themes by doing: update-alternatives --list default.plymouth\nYou can then change the current plymouth theme by doing\nsudo update-alternatives --set default.plymouth /lib/plymouth/themes/kubuntu-logo/kubuntu-logo.plymouth\nThe alternative way of getting Kubuntu splash it to remove package xubuntu-plymouth-theme.\nTo change the login screen you can either run sudo dpkg-reconfigure gdm and choose kdm as mentioned in another comment or remove gdm which should set kdm as default display manager.\n\nA: Also after you remove xfce and all other apps, reinstall ubuntu-desktop to make sure you get everything back\n", "Q: How do I enable automatic updates? Update Manager is constantly offering me updates (e.g. security fixes, updates from PPAs).\nHow can I tell my Ubuntu installation to automatically download and install updates whenever they become available?\n\nA: In the Update Manager click the Settings button. This dialog will show up:\n\nSelect the \"Download and install automatically\". This will automatically install security updates. If you want to set this up for them remotely via, you can do this:\nsudo apt-get install unattended-upgrades\nIf the package is installed already you can do:\nsudo dpkg-reconfigure unattended-upgrades\nto change it's behavior. Follow the prompts to enable the feature once you run the command. There's currently no graphical method to just set the entire system to update unattended for everything (you want to play it safe when it comes to automatic upgrades), but setting security updates automatically is a good idea.\nCheck out the pages for more information if you want to automate getting -updates and -backports: \n\n\n*\n\n*https://help.ubuntu.com/community/AutomaticSecurityUpdates#Using_the_.22unattended-upgrades.22_package\n\n*How to enable silent automatic updates for any repository?\n\n*How do I enable automatic updates of all packages?\n\nA: You can do this easily for security updates.\nFrom System Settings open Update Manager. Click the 'Settings...' button, then on the 'Updates' tab, select the radio button 'Install security updates without confirmation.'\nTo automatically install all updates, see the answer below.\n\nA: Go to terminal, and enter:\nsudo dpkg-reconfigure unattended-upgrades\n\nSay \"yes\" to the prompt. You'll still be notified about \"normal\" updates, such as those that contain bugfixes, but security updates will be installed automatically.\n\nA: Although it is not wrong or dangerous (see comments to this answer), using apt-get upgrade -y is not the best way to achieve this.\nunattended-upgrades is one of the best practices of having automatic updates, especially for headless machines or servers!\nYou can set up unattended-upgrades pretty easily by typing this in a terminal:\nsudo apt-get install unattended-upgrades\nsudo dpkg-reconfigure unattended-upgrades\n\nFrom the description:\n This package can download and install security upgrades automatically\n and unattended, taking care to only install packages from the\n configured APT source, and checking for dpkg prompts about\n configuration file changes.\n\n\nA: I use apticron to get informed by mail if an update needs to be done.\nIn your case, I would use cron-apt or unattended-upgrades to do the job of automagically updating your machines.\n", "Q: How do I install Adobe Flash player? I have had significant problems with watching flash video in 64-bit Ubuntu.  Does anyone know of a good way to get flash running on the platform?\n\nA: For 11.04 and earlier:\nAre you installing it from the Ubuntu Software Center?\n\n*\n\n*Go to Applications->Ubuntu Software Center.\n\n*Click on Canonical Partners\n\n*Click the Adobe Flash Plugin 11 and click install.\n\nNote: this is the method I use on my 64-bit Ubuntu install and it has yet to fail me.\n\n\nA: For 11.10 and later\nStart Software Center from the Launcher and search for flash \nTwo entries will be found.  The first is the wrapper around the 32bit flash version from Adobe.  The second is the 64bit flash version.\nSelect the second flash entry - if the following picture is seen then you have not already enabled the Canonical Partner Repository previously.\n\nClick More Info\n\n... and click Use this source to enable the Canonical Partner Repository\n\nsee the end of this answer for the bug-report\nClick Install \n\nClick the Install button and enter your password when prompted.  Note - you must have permission to install software.\n\nThe installation will proceed:\n\nOnce complete - launch Firefox and browse to your Flash Video.  Right click and confirm that the latest version of Flash has been installed correctly.\n\nNote - pictures subject to change - the 64bit version has only been recently packaged in the last week before Oneiric release - One issue currently exists:\n\n\n*\n\n*https://bugs.launchpad.net/ubuntu/+source/flashplugin-nonfree/+bug/870835\nIn the interim - either use the first \"Multiverse\" 32bit plugin in the pictures above or use adobe-flashplugin\nsudo apt-get install adobe-flashplugin\n\n\nA: Get my Flash-Aid extension for Firefox. It will take care of downloading and installing the appropriate version for your system architecture and will also remove conflicting plugins. If you are on 64bit, it also allows to install the 64bit preview version, which renders better results than the 32bit with nspluginwrapper.\nBTW, if you can't copy anything to ~/.mozilla/plugins folder, then you should check the ownership of the ~/.mozilla folder. It should allow to copy anything there. Unless of course you are referring to a system folder outside your home directory, which requires root privilege.\n\nA: It depends on what browser you are using.  Google Chrome (not Chromium) has Flash player by default.\nGo to www.google.com/chrome and click download Chrome  Choose 64-bit .deb (anybody reading this using 32-bit machines should select the 32-bit .deb)\nWhen you click on the .deb file when it has downloaded it will open in the Software Centre.  Now click install and when it has finished you can find the browser in Applications -> Internet.\n\nA: This is how to install Adobe Flash Plugin for Firefox:  \n\n\n*\n\n*Go to this page and select the option .tar.gz for other Linux. Download the file.  \n\n*Unpack the plugin tar.gz and copy the files to the appropriate location.  \n\n*Save the plugin tar.gz locally and note the location the file was saved to.  \n\n*Launch terminal and change directories to the location the file was saved to.  \n\n*Unpack the tar.gz file.  Once unpacked you will see the following:  \n\n\n*\n\n*libflashplayer.so  \n\n*/usr  \n\n\n*Identify the location of the browser plugins directory, based on your Linux distribution and Firefox version.(Usually it is /usr/lib/mozilla/plugins/)\nFor ubuntu 14.04 path is :  /usr/lib/firefox/browser/plugins \n\n*Copy libflashplayer.so to the appropriate browser plugins directory.  At the prompt type:  \nsudo cp libflashplayer.so <BrowserPluginsLocation>\n\n\n*Copy the Flash Player Local Settings configurations files to the /usr directory.  At the prompt type:        \nsudo cp -r usr/* /usr\n\n\n*Now restart your browser.\n\nA: Since you have stated that this is the first time you have ever used ubuntu. i would suggest that you install the package ubuntu-restricted-extras, this includes lots of useful stuff like adobe flash and codecs and MS fonts etc.\nyou can do this in many ways. \nsoftware centre: Click on this link:\n\nor in a terminal: type sudo apt-get install ubuntu-restricted-extras\nsynaptic: search for the package ubuntu-restricted-extras right click the package and select install, and then select mark. after click the apply button and it will all install. \n\nA: Use the Ubuntu Software Center (in the Applications menu).  In the text entry field (of the search box), you can search for \"flash\", and the results will populate one Adobe Flash plugin (note the Adobe logo).  Choose that, and follow the directions to use the source.\n\nA: Double check which \"plugin\" directory is being used. Had to spend a good hour one time just plowing through all the plugin directories till I found which ones my firefox was actually reading, and then ln -sed them all to point to a common one.\nEnd of the day you might be dropping it in the wrong place. \nAlso start firefox from the command line, you might see errors. Example is running a x86 flash player in an x64 browser(not os) and vice versa. From the command line (%> firefox) you should see the plugin initialization log lines. (maybe try this one first :P)\nAlso anything in /usr/lib/... is owned by root so you would have to sudo cp libflashplayer.so /usr/lib/firefox/plugin where .../firefox/plugin points to the location of the firefox plugin directory.\n\nA: Definite fix for 64 bit Flash on 11.10\nI fixed 64 bit Flash on my 11.10 systems without any wrappers. If you follow the solutions mentioned above you will still end up with the 32 bit version and wrappers.\nNote: most of this can be done in a terminal as well, in that case you don't need to install Synaptic. Furthermore, it could be that just executing steps 5, 6 and 8 is enough, but I have not tested this yet.\n\n\n*\n\n*Install Synaptic (Software Center doesn't show the package you need, not in the main items and not within the technical items and not even after it's been installed)\n\n*Start Synaptic and search for 'flash'\n\n*Sort by installed state\n\n*Remove all flash-related packages (such as flashplugin-downloader:i386, flashplugin-installer, ndiswrapper-common etc.). If there's nothing listed you probably don't have Flash installed at all. In that case, just move on to the next step.\n\n*Enable the Canonical partner repository (see above posts on how to do that)\n\n*Update the package list (don't count on Software Center doing this for you, it sometimes doesn't) by clicking 'Reload' in\n\n*Search for 'flash' again\n\n*Install the package 'adobe-flashplugin'. If it's not in the list, something went wrong with updating the package lists. Try quiting and restarting Synapic, then click on 'Reload'.\n\n\nOne extra package, 'adobe-flash-properties-gtk' will be installed automatically.\nNothing more.\nNow you will have full 64 bit Flash without any wrappers and other garbage in both Firefox and Chromium. A restart of your browser(s) is required though. If it's still not working, try a reboot (there might be some bogus reference to the old plugins somewhere).\n\nA: sudo apt-get remove --purge adobe-flashplugin flashplugin* nspluginwrapper\nsudo apt-get install --reinstall adobe-flashplugin\n\nRef: http://ubuntuguide.net/install-adobe-flash-pluginfix-not-working-problem-in-ubuntu-11-10-oneiric\n\nA: Here's what you need to do: by default, Ubuntu comes with only open source software enabled (I think that's the case, anyway). \nThe way you enable other stuff (like Flash, Java, and support for recording or playing MP3s, which is NOT open source) is to go in your Software Center, go in the menus (unfortunately I'm not currently on Ubuntu and can't tell you which menu) and search for Software Sources. \nClick it, and you'll be brought to a window which tells Ubuntu what it's allowed to install for you. In front of you should be a list of five different \"universes\". What you need to do is enable the two that aren't currently enabled. \nAfter that, it should ask you whether you want to reload your repositories, but if it doesn't, get in a command line and type \nsudo apt-get update\n\nand let it finish. Then you should be able to find flash in either the Software Center or in the command line. You could alternatively install the ubuntu-restricted-extras package, which will give you all of the three things I mentioned above.\nGood luck!\n\nA: I went through as many possible suggestions as I could find in an effort to get flash to work in Chrome on my 13.10 64bit installation. Nothing worked. I finally stumbled on the Pepper Flash answer. \nThere are complete and well-written instructions at (link is direct)\nubuntuhandbook.org\nThey detail adding the repository, updating apt, installing Pepper, and modifying the chrome config. The thing that I did differently from their instructions was to change to the /etc/chromium-browser directory and issue the command \nsudo gedit default \nwhich allowed me to add a comment to the file in addition to the necessary .sh info so the last couple lines of my modded default file were:\n# enable Pepper Flash Player Plugin\n. /usr/lib/pepflashplugin-installer/pepflashplayer.sh\n\nHopefully this solution will work for some time. \n\nA: Flash videos wouldn't play on a fresh Ubuntu 14.04 install, even with adobe-flashplugin from the \"partner\" repository — got black screen on youtube (except after having setting it to use HTML5), dailymotion, etc.. Installing freshplayerplugin (apparently a wrapper for Chrome's flash player) solved the issue :\nsudo add-apt-repository ppa:nilarimogard/webupd8\nsudo apt-get update\nsudo apt-get install freshplayerplugin\n\n\nA: There is a simple solution for this problem.\nOpen your Firefox and go to Youtube. Click on any video. Definitely it won't play because you don't have any flash player installed. But Firefox will promote you to install missing plug-in at the top. Simply click on it and follow the procedure. After that your video will start to play. Make sure you have latest Firefox browser installed.\nOr  try this in your terminal\nsudo apt-get install flashplugin-installer\n\n\nA: In case the\nsudo apt-get install flashplugin-nonfree\n\ndoes not work (like in my case and I do not know why...), you may want to give Opera as your browser a try. It is the only one that works for me.\nPS: I do not want to advertise Opera a browser, it's just that this was the only solution that somehow worked for me.\n\nA: I've just found a solution for those who has flash working on Firefox but not on Chromium. It's based on the fact that every browser has it's own plugins directory:\n\n\n*\n\n*/usr/lib/firefox-addons/plugins (for Firefox)\n\n*/usr/lib/chromium-browser/plugins (for Chromium)\n\n\nSo, the only thing you've to do is to unificate them, aka, making one the link to the other. Probably, all plugins are on Firefox plugins directory, but it isn't worth to ensure that:\nls -l /usr/lib/{mozilla,chromium-browser}/plugins\n\nIf Firefox is the one where all plugins are, do the next. If not, do the opposite:\nsudo rmdir /usr/lib/chromium-browser/plugins\nsudo ln -s /usr/lib/mozilla/plugins /usr/lib/chromium-browser/\n\nFinally, restart Chromium so changes take effect.\nProbably, it wouldn't be a bad idea to create a bug report on Chromium/Firefox package maintainers to alert about the bug and the simple solution.\n\nA: Well I post this here, in hopes of helping someone. I'll state what was happening and how I solved it. \nSETUP:\n    Running 12.04 from a WUBI installation.\nPROBLEM:\n    When I searched in the Ubuntu Software Center the keyword flash, none of the options posted here appeared except ONE for a flash plugin for Mozilla. When attempting to install it, I got a dependency error. \nTried installing it through the Ubuntu Restricted Extras from Ubuntu Software Center, however the flash plugin portion of this installation did not work because of the dependency error.\nKept searching and found this command to install the plugin\nsudo apt-get install flashplugin-nonfree\n\nand ran it from the terminal. \nSame dependency error with this output:\nReading package lists... Done Building dependency tree        \nReading state information... Done Note, selecting 'flashplugin-installer' instead of 'flashplugin-nonfree' \nSome packages could not be installed. This may mean that you have requested an impossible situation or if you are using the unstable distribution that some required packages have not yet been created or been moved out of Incoming. \nThe following information may help to resolve the situation:\nThe following packages have unmet dependencies:  \n flashplugin-installer : \n Depends: libnspr4-0d but it is not going to be installed E: Unable to correct problems, you have held broken packages.\n\nSOLUTION: \nI ran \nsudo apt-get install -f \n\nand then \nsudo apt-get update \n\nwhich I found from some other post that was trying to solve dependencies.\nThen I ran \nsudo apt-get install flashplugin-nonfree\n\nand flash plugin now works on Chromium and Firefox.\n\nA: It depends on how you are installing. is it via a tar.gz file or rpm or some other method. There are a bunch of ways to get flash.\nDownload link: https://get.adobe.com/flashplayer/\n\nInstallation instructions\n-------------------------\n\nInstalling using the plugin tar.gz:\n    o Unpack the plugin tar.gz and copy the files to the appropriate location.  \n    o Save the plugin tar.gz locally and note the location the file was saved to.\n    o Launch terminal and change directories to the location the file was saved to.\n    o Unpack the tar.gz file.  Once unpacked you will see the following:\n        + libflashplayer.so\n        + /usr\n    o Identify the location of the browser plugins directory, based on your Linux distribution and Firefox version\n    o Copy libflashplayer.so to the appropriate browser plugins directory.  At the prompt type:\n        + cp libflashlayer.so <BrowserPluginsLocation>\n    o Copy the Flash Player Local Settings configurations files to the /usr directory.  At the prompt type:\n        + sudo cp -r usr/* /usr\n\nInstalling the plugin using RPM:\n   o As root, enter in terminal:\n          + # rpm -Uvh <rpm_package_file>\n          + Click Enter key and follow prompts\n\nInstalling the standalone player:\n   o Unpack the tar.gz file\n   o To execute the standalone player,\n          + Double-click, or \n          + Enter in terminal: ./flashplayer\n\nBonus:\nUninstallation instructions\n---------------------------\n\nManual uninstallation (for users who installed the plugin via Install script):\n   o Delete libflashplayer.so binary and flashplayer.xpt file in \n   directory /home/<user>/.mozilla/plugins/\n\nRPM uninstallation:\n   o As root, enter in terminal:\n          + # rpm -e flash-plugin\n          + Click Enter key and follow prompts\n\n\nA: \nLinux is not supporting Adobe Flash Player in its store anymore.Therefore you have to do it manually.\n\n\n\nThis is only verified on Firefox also if you have Chrome/Chromium you don't have to install it.\n\n There is a procedure of Manual Installation of Adobe Flash Player on Ubuntu, follow these steps :- \n\n\n*\n\n*Open this link. It will automatically suggest you a version according to your desktop environment.\n\n*Select .tar.gz for Linux option as shown in below screen-shot.\n\n\n*Now click on Download Button (Select the downloading path as Downloads in your system for easy access).\n\n*Now extract file by Right clicking on folder and selecting Extract Here option.\n\n\n*Open Terminal CTRL+ALT+T and copy below command one by one\n5.1. cd ../\n5.2. cd your-pc-name (eg; paper96)\n5.3.  cd Downloads (this is the folder where you have downloaded the file in Option 3).\n5.4. cd flash_player_npapi_linux.x86_64 (Your file name may be different just copy name of file and paste it in terminal)\n5.5. sudo mv libflashplayer.so \\/usr/lib/firefox-addons/plugins hit enter and thats it.\n \n\n*Now close your browser(Firefox) and Terminal.\n\n*Restart Firefox and now you have Flash Player in your browser. Visit this link to verify.\n\n\nA: I checked many answers on this topic in the past week. Finally I found a link with a solution that DOES work:\nhttps://ubuntu-mate.community/t/tutorial-flash-player-for-chromium-and-firefox/3598 \nBasically, the answer is that it seems to be removed from all software sources and you need to download an old version and install it manually \n", "Q: How can I make Ubuntu check for updates less often? I'd like to have Ubuntu not check for updates as often. How do I accomplish this?\n\nA: System -> Administration -> Software Sources -> Updates (tab) -> Check for updates: [Daily | Every two days | Weekly | Every two weeks]\n\nA: For 11.04 and higher\n\n\n*\n\n*Start System settings.\nEither search for it in dash or click on the gear in the top right corner. \n\n\n*click on Software sources\n\n\n*Choose updates\n\n\n*now choose how often you want to check for updates.\n\nFor people in a hurry!\nPress Alt+F2 and search as shown and click software-properties-gtk, then jump to step 3.\nOR open a terminal Ctrl+Alt+T, and type software-properties-gtk, then jump to step 3.\n\nVia the Ubuntu software center\nIf you are more comfortable with using the USC then you could open it, and click on edit and then at the bottom software sources. Now just go to step 3. \n\nA: And if I want to check monthly?\nWhere are stored this settings?\nI don't see this on /etc/update-manager\n\nOk, now I've found this meaning file in Ubuntu 10.10:\n/etc/apt/apt.conf.d/10periodic\n\nA: For 10.10 and earlier versions (and 11.04, in an Ubuntu Classic session)\nOpen Update Manager (System > Administration > Update Manager).\nOn the Updates tab, there's a drop down box for \"Check for updates:\", with options for Daily, every two days, weekly or every two weeks.\nOr you can turn it off and just check manually whenever you want.\n", "Q: What might prevent mouse movements between xrandr screens? I've followed the steps outlined in this HowTo.\nRight after I log in to Gnome I can move the mouse back and forth but as soon as the task bar loads, the mouse becomes jailed in the screen its in (can't move between screens).\nThis is my xorg.conf:\n Section \"ServerLayout\"\n            Identifier     \"Layout0\"\n            Screen      0  \"DisplayLinkScreen\" 0 0\n            Screen   1  \"Screen0\" LeftOf \"DisplayLinkScreen\"\n            InputDevice    \"Keyboard0\" \"CoreKeyboard\"\n            InputDevice    \"Mouse0\" \"CorePointer\"\n            Option     \"Xinerama\" \"0\" #Could not get this to work it has to be disable\nEndSection\n\nSection \"Files\"\n ModulePath   \"/usr/local/lib/xorg/modules/drivers\"\n ModulePath      \"/usr/lib/xorg/modules/drivers\"\n ModulePath      \"/usr/local/lib\"\n\n ModulePath   \"/usr/lib/xorg/modules\"\n FontPath     \"/usr/share/fonts/X11/misc\"\n FontPath     \"/usr/share/fonts/X11/cyrillic\"\n FontPath     \"/usr/share/fonts/X11/100dpi/:unscaled\"\n FontPath     \"/usr/share/fonts/X11/75dpi/:unscaled\"\n FontPath     \"/usr/share/fonts/X11/Type1\"\n FontPath     \"/usr/share/fonts/X11/100dpi\"\n FontPath     \"/usr/share/fonts/X11/75dpi\"\n FontPath     \"/var/lib/defoma/x-ttcidfont-conf.d/dirs/TrueType\"\n FontPath     \"built-ins\"\nEndSection\n\nSection \"Module\"\n Load  \"dbe\"\n Load  \"dri\"\n Load  \"dri2\"\n Load  \"extmod\"\n Load  \"glx\"\n Load  \"record\"\nEndSection\n\nSection \"InputDevice\"\n Identifier  \"Keyboard0\"\n Driver      \"kbd\"\nEndSection\n\nSection \"InputDevice\"\n Identifier  \"Mouse0\"\n Driver      \"mouse\"\n Option     \"Protocol\" \"auto\"\n Option      \"Device\" \"/dev/psaux\" \n # Option     \"Device\" \"/dev/input/mice\"\n Option     \"ZAxisMapping\" \"4 5 6 7\"\nEndSection\n\nSection \"Monitor\"\n Identifier   \"Monitor0\"\n VendorName   \"Monitor Vendor\"\n ModelName    \"Monitor Model\"\nEndSection\n\nSection \"Device\"\n        ### Available Driver options are:-\n        ### Values: <i>: integer, <f>: float, <bool>: \"True\"/\"False\",\n        ### <string>: \"String\", <freq>: \"<f> Hz/kHz/MHz\"\n        ### [arg]: arg optional\n        #Option     \"NoAccel\"             # [<bool>]\n        #Option     \"SWcursor\"            # [<bool>]\n        #Option     \"ColorKey\"            # <i>\n        #Option     \"CacheLines\"          # <i>\n        #Option     \"Dac6Bit\"             # [<bool>]\n        #Option     \"DRI\"                 # [<bool>]\n        #Option     \"NoDDC\"               # [<bool>]\n        #Option     \"ShowCache\"           # [<bool>]\n        #Option     \"XvMCSurfaces\"        # <i>\n        #Option     \"PageFlip\"            # [<bool>]\n Identifier  \"Card0\"\n Driver      \"intel\"\n VendorName  \"Intel Corporation\"\n BoardName   \"Core Processor Integrated Graphics Controller\"\n BusID       \"PCI:0:2:0\"\n Option     \"DPMS\"\nEndSection\n\nSection \"Screen\"\n Identifier \"Screen0\"\n Device     \"Card0\"\n Monitor    \"Monitor0\"\n SubSection \"Display\"\n  Viewport   0 0\n  Depth     1\n EndSubSection\n SubSection \"Display\"\n  Viewport   0 0\n  Depth     4\n EndSubSection\n SubSection \"Display\"\n  Viewport   0 0\n  Depth     8\n EndSubSection\n SubSection \"Display\"\n  Viewport   0 0\n  Depth     15\n EndSubSection\n SubSection \"Display\"\n  Viewport   0 0\n  Depth     16\n EndSubSection\n SubSection \"Display\"\n  Viewport   0 0\n  Depth     24\n EndSubSection\nEndSection\n\nSection \"Monitor\"\n    Identifier     \"DisplayLinkMonitor\"\nEndSection\nSection \"Device\"\n    Identifier  \"DisplayLinkDevice\"\n    Driver  \"displaylink\"\n    Option   \"fbdev\" \"/dev/fb0\"\nEndSection\nSection \"Screen\"\n    Identifier      \"DisplayLinkScreen\"\n    Device          \"DisplayLinkDevice\"\n    Monitor         \"DisplayLinkMonitor\"\n    SubSection \"Display\"\n        Depth       24\n        Modes       \"1920x1200\" \"1920x1080\" \"1680x1050\" \"1600x1200\" \"1440x900\" \"1366x768\" \"1280x1024\" \"1280x960\" \"1280x800\"  \"1280x768\"  \"1152x864\" \"1024x768\" \"800x600\" \"640x480\" \n    EndSubSection\nEndSection\n\nAny help would be appreciated. I'm so close to getting this to work!\n\nA: My best guess here is that the position of the right screen is causing the problems. You could try modifying the ServerLayout section like this:\nSection \"ServerLayout\"\n        Identifier     \"Layout0\"\n        Screen         0 \"Screen0\" 0 0\n        Screen         1 \"DisplayLinkScreen\" RightOf \"Screen0\"\n        InputDevice    \"Keyboard0\" \"CoreKeyboard\"\n        InputDevice    \"Mouse0\" \"CorePointer\"\n        Option         \"Xinerama\" \"0\"\nEndSection\n\nOr if you really want the DisplayLinkScreen to be the primary screen, modify it so that the coordinates match the resolution of Screen0. For example Screen0 has resolution 1900x1200:\nSection \"ServerLayout\"\n        Identifier     \"Layout0\"\n        Screen         0  \"DisplayLinkScreen\" 1900 0\n        Screen         1  \"Screen0\" LeftOf \"DisplayLinkScreen\"\n        InputDevice    \"Keyboard0\" \"CoreKeyboard\"\n        InputDevice    \"Mouse0\" \"CorePointer\"\n        Option         \"Xinerama\" \"0\"\nEndSection\n\nAnother possible location for the problems could be in RandR configuration which gets loaded during gnome startup. You can completely reset the RandR configuration by deleting ~/.config/monitors.xml.\n\nA: I found a tool here that automatically wraps the mouse between separated screens.\nIt worked for me when I had trouble getting the mouse to move between screens.\n\nA: You've got two different graphics devices, one with -intel, one with -displayport, and want to stitch them together so the mouse moves seamlessly across them.  Xinerama is what stitches multiple screens together, so you need that enabled.\nHowever, Xinerama mode for -intel is not really that well supported (should be getting better though).  Maybe you'll be lucky with it, but as far as I know it's not expected that this should work.\nYou probably can get it to work if you use the -nvidia proprietary binary driver though.\n", "Q: Where should I install sagemath? Sage's installation instructions basically tell me to just untar it and run it from wherever I'd like. Not being experienced with the Linux way of where things should go in the filesystem, I'm kind of at a loss where I should best put it. Putting it somewhere in my home directory feels wrong.\nWhere would you extract it to? /opt?\n\nA: /opt is a viable option. Some people install it under /usr/local/\n\nA: I use SAGEMATH too. \nActually, you can put it anywhere you like.\nI usually just put it in my home foler. Exp, '~/Softwares/SAGE'.\nAnd of course, you can make some links for convinence.\n\nA: The Linux Filesystem Hierarchy Standard that is part of the Linux Standard Base recommends to use /opt. I have only had good experience with that. Many commercial packages go into opt as well and stay to their own folder in there. \n", "Q: Remove online status menu, but keep the logout menu? In the upper right panel there is by default a drop down menu where you can set your online status, interact with Ubuntu One, etc. It is placed right next to the drop down menu which lets you logout, reboot, shutdown etc.\nFor me personally I have no use for the online status menu, so I usually remove it. The problem is that it seems to belong to the same panel applet as the actually wanted logout menu, since that menu too disappears. I believe we are talking about the \"Indicator Applet Session\".\nIs there some way I can hide or disable the online status menu, but still keep the neighboring logout menu?\nI am running Ubuntu 10.04.\n\nA: Open the \"Ubuntu Software Center\" (under the Applications menu).  Search for \"indicator-me\" and remove it.  Log out and back in to see the change.\nThis will remove it for all users on your system.  I don't believe there's a way to merely hide it for yourself.\n", "Q: Sane path to distribution upgrades I'm using Hardy (server) on quite a few machines and I'd like to upgrade to the latest LTS. Is it safe to edit my sources.list file to just point to the new LTS, or should I do a succession of dist upgrades until I reach the latest LTS?\n\nA: I believe you can upgrade directly from LTS to LTS, see e.g. https://help.ubuntu.com/community/LucidUpgrades\n\nA: No. You should never just edit sources.list. Use the update-manager, or if you use command line, use do-release-upgrade. You can upgrade safely from LTS editions to other LTS editions, or otherwise, you need to step via each release. Only those pathways are supported, and prevent some issues that can otherwise occur with improper upgrades.\n", "Q: What is the easiest way to strip a desktop edition to a server edition? We have installed Ubuntu desktop edition on our development server. Now that we have it in a data center we would like to strip it down to a server edition.\nIs there an easy way of doing so rather than just going in and uninstalling packages by hand?\n\nA: If you want to just not run the DM and WM on startup but keep the ability to run them at will you can run:\nsudo systemctl set-default runlevel3.target\n\nthen reboot.\nThe system will boot to runlevel 3 (init 3) which does not start the DM and WM and all the other stuff related to the desktop environment, but starts everything else.  When the system boots into the tty1 terminal at the console, you can log in then\nsudo init 5\n\nto get to the desktop environment login.\nOn the ubuntu and xfce4 desktops I was testing with the GUI logout button hung my system.\nOn the ubuntu desktop, the power down and restart buttons worked fine; the xfce4 desktop only has a logout button.\nThe safe way to exit back to tty only is to open a terminal and run:\nsudo init 3\n\n\nA: It's possible to do it the other way around, but I've never seen anyone who was able to do this simply by installing a metapackage or something.\nYour best bet is either:\n\n\n*\n\n*a clean install\n\n*manually removing unneeded packages and installing the server components you need\n\n\nA: You can remove ubuntu-desktop and simultaneously auto-remove all its orphaned dependants:\nsudo apt-get autoremove ubuntu-desktop\n\nAdd the --purge option if you also want to remove the configuration of the affected packages (and not keep it for possible later reinstallation).\nIf you have any other Desktop remove them as well. if you reboot after this you should have no GUI to log into. If you purge a program rather than just removing it you also remove any config files that may remain. \nAs Rinzwind suggests try sudo apt-get remove gnome-*.\nBefore Ubuntu 16.04 it also provides a special kernel package for server installations, linux-image-server:\n\n\n*\n\n*sudo apt-get install linux-image-server and reboot.\n\n\nThen I suggest you install the server applications you want, like ssh-server.\n\nBut as always it's better to make a clean install. It gives less risk of errors and broken packages. \n\nA: Note:  as stated in comments, tasksel should only be used to install tasks, not remove them. In this specific task (remove desktop -> install server) it seems to work fine. So  use it with caution. \n\nYou can try tasksel. With it, you can do what you want by selecting Basic Ubuntu Server and unchecking Ubuntu desktop.\nsudo apt-get install tasksel\n\n\n", "Q: What's the easiest way to set up a LAMP stack? I set up a new VPS instance of Ubuntu and am wondering what the easiest way is to get up and running with a basic LAMP stack (i.e. which packages are required, which configuration options need to be tweaked, if any, etc.).\n\nA: The packages are apache2 and libapache2-mod-php5. php5 has a number of additional modules, you may need some. List them with apt-cache search php5\nTry revising your search or\nsudo apt-get install apache2 libapache2-mod-php5\n\nEnable php5 with\nsudo a2enmod php5\n\nRestart apache\nsudo service apache2 restart\n\nThe following wiki pages can be very helpful if you are starting with apache.\nhttps://help.ubuntu.com/community/ApacheMySQLPHP\nhttps://help.ubuntu.com/11.10/serverguide/C/httpd.html\nNote- This answer was migrated from elsewhere. To add mysql install\nsudo apt-get install mysql-server php5-mysql\n\n\nA: Install Apache\nsudo apt-get install apache2\n\nInstall PHP\nsudo apt-get install php5 libapache2-mod-php5\n\nAs fo 16.04, the number is dropped:\nsudo apt-get install php libapache2-mod-php\n\nInstall MySQL\nsudo apt-get install mysql-server\n\nInstall phpMyAdmin\nsudo apt-get install libapache2-mod-auth-mysql php5-mysql phpmyadmin\n\nAs with the PHP installation, in 16.04, the number is dropped:\nsudo apt-get install libapache2-mod-auth-mysql php-mysql phpmyadmin\n\nCombined installation\n16.04:\nsudo apt-get install apache2 php libapache2-mod-php mysql-server libapache2-mod-auth-mysql php-mysql phpmyadmin\n\nBefore 16.04:\nsudo apt-get install apache2 php5 libapache2-mod-php5 mysql-server libapache2-mod-auth-mysql php5-mysql phpmyadmin\n\n\nA: The easiest way to install LAMP with PHPMyAdmin is using:\nsudo apt-get  install lamp-server^ phpmyadmin \n\nYou don't even need to install taskel. More details can be found here, which gives this:\nTo access PHPMyAdmin, open terminal & type:\nsudo -H gedit /etc/apache2/apache2.conf\n\nAdd this line somewhere in that file:\nInclude /etc/phpmyadmin/apache.conf \n\nFinally restart Apache using:\n/etc/init.d/apache2 restart\n\nor\nsudo service apache2 restart\n\n\nA: http://www.apachefriends.org/en/xampp-linux.html\nIt has LAMP as well as phpmyadmin integrated along with perl modules. Installs in /opt/lampp so can be installed/removed easily...\n\nA: My Swiss Army knife command:\nsudo apt-get install apache2 mysql-server mysql-client libapache2-mod-auth-mysql php5 php5-mysql libapache2-mod-php5 php5-mcrypt php5-curl php5-cli php5-gd phpmyadmin\n\n\nA: PHP7.0 is standard on Ubuntu 16+\nHeres the rundown: \n1 As Always\n sudo apt-get update\n\n2 Install Apache2\n sudo apt-get install apache2\n\n3 Install mysql-server\n sudo apt-get install mysql-server\n\n4 Install PHP 7.0\n sudo apt-get install php7.0 libapache2-mod-php7.0 php7.0-mysql php7.0-curl php-mbstring php7.0-mbstring php-gettext php7.0-json php-xml\n sudo a2enmod php7.0\n\n5 Install phpmyadmin\n sudo apt-get install mcrypt\n sudo apt-get install phpmyadmin\n\nNote, you'll need to add Include /etc/phpmyadmin/apache.conf to the file you'll open with the following command. (credit)\n sudo gedit /etc/apache2/apache2.conf \n\nOptional\n sudo a2enmod rewrite\n\n\nA: In Synaptic, click edit and mark by task. Then select LAMP Server and hit apply. Done.\n\nA: sudo apt-get update\nsudo apt-get install tasksel\nsudo tasksel install lamp-server\n\nIt will install all the basic LAMP stack for you, prompt for MySQL root password, etc.\nMore specifically it will install the following packages, and their dependencies.\nmysql-client-core-5.1 libwrap0 apache2  \nlibaprutil1-dbd-sqlite3 tcpd  \nlibapache2-mod-php5 apache2.2-common  \napache2-utils php5-common  \nlibaprutil1-ldap libaprutil1  \nphp5-mysql mysql-server-core-5.1  \nlibdbi-perl libplrpc-perl mysql-server  \napache2.2-bin libdbd-mysql-perl  \nlibhtml-template-perl  \nlibnet-daemon-perl libapr1  \nmysql-server-5.1 libmysqlclient16  \nssl-cert apache2-mpm-prefork  \nmysql-common mysql-client-5.1  \n\nYou might also want to take a peek at the Ubuntu Server Guide.\n\nA: I personally always find that installing the MySQL server and then PHPMyAdmin will install all the parts I need\nsudo apt-get install mysql-server\n\n(doing this first means it asks for the root account password to be set in advance)\nthen\nsudo apt-get install phpmyadmin\n\nIt also gives you all the tools you'll need to administrate your MySQL server once it's installed :)\n\nA: On commandline the simplest way is probably to use tasksel:\nsudo tasksel install lamp-server\n\n\nA: Open terminal\nCtrl + Alt + T\nType\nsudo apt install synaptic\n\nThis will install synaptic on your system\nType\nsudo synaptic \n\nto open it.\n\nGo to search box\n\n\nIn the search field type apache and click on Search button\n\nThe following field appears\n\nScroll down to Apache2 and select the box left to it.\n\nClick on apply\n\nSelect all dependencies and follow on screen instructions to install.\nIn a similar way install\nphp7.0 and mysql-server one by one\nDuring installation of mysql-server system asks for root password. Provide it.\nAfter everything is complete, close synaptic.\nNow open your browser and in the address bar type localhost and press Enter\nIf the following page appears\n\nthen Apache2 installation is successfull\nIn terminal type\napt install vim\ncd /var/www/html\nvim testphp.php\n\nPress\ni\nType\n<?php phpinfo(); ?>\n\nPress\nEsc : x Enter\nGo to your browser and in the address bar type localhost/testphp.php\nIf the following page appears\n\nThen php7.0 installation is successfull\nGo to terminal and type\nmysql --version\n\nIf you get the following prompt (version numbers for you system may be different):\nmysql Ver 14.14 Distrib 5.7.18, for Linux (x86_64) using EditLine wrapper\n\nThen your mysql-server installation is successful.\nType\nmysql -u root -p\n\nYou will get:\nEnter password:\n\nGive the password.\nIf you get the following prompt\n \nThen you are now successfully able to login\nType\nmysql> quit\n\nto logout.\nCongratulations, you now have a full working LAMP Stack\nOptional:\nYou can also install phpmyadmin using synaptic. During installation it will ask for default server to use. Select apache2. Follow other on screen instructions.\nThen open your browser and in the address bar type localhost/phpmyadmin\nThe following page appears\n\nIn the username field type root and in the password field type the password for root user you have selected during mysql-server installation. \nClick on Go button.\nThe following page appears\n\nNow you have successfully installed phpmyadmin on your system.\n\nA: You can install Bitnami lampstack.(Package containing all necessary sub packages of LAMP).\nFirst of all create an account in bitnami website to download the bitnami-lampstack-5.5.30-1-linux-x64-installer.run file.\nThen copy the file to your desktop (for convenience ). To provide read and exicution permission, Open terminal (Ctrl + Alt + T).\nand type\nchmod 755 chmod  755 'location of bitnami-lampstack-5.5.30-1-linux-x64-installer.run\n\nBetter drag and drop the .run file from your desktop after typing chmod 755, press enter.\nNow double click on the .run file. It will guide you through the installation process.\nThank you.\n\nA: I have a script for this task: lampi\nUsage:\nsudo lampi -i -s -n example.com.local -dr ~/example-site\n\nWhat does it do:\n\n\n*\n\n*Install the LAMP stack (-i flag)\n\n*Setup and configure apache2, mysql, php, phpmyadmin\n\n*Then set up a custom site named example.com.local (-n option)\n\n*Set ~/example-site directory as it's document root (-dr option)\n\n*Enable SSL (https) for this site (-s flag)\n\n\nNow, the site can be accessed with http://example.com.local or https://example.com.local\n\nA: If you are on Ubuntu 16, it is simple with one command:\nsudo apt-get install apache2 mysql-server php libapache2-mod-php php-mcrypt php-mysql phpmyadmin\n\nAnd just follow the instruction on screen to enter password for mysql, phpmyadmin configuration\nYou can see more details on my blog   http://tvivu.com/install-lamp-stack-ubuntu-16-04/ \n\nA: Follow All Steps\nsudo apt-get update\nsudo apt-get install apache2\nsudo apt-get install mysql-server\nsudo apt install php7.0-cli\nsudo apt-get install phpmyadmin php-mbstring php-gettext\nsudo phpenmod mcrypt\nsudo phpenmod mbstring\nsudo systemctl restart apache2\nsudo apt-get update\n\n(Note If phpmyadmin is not working after Than Try this last three line code)\ngksu gedit /etc/apache2/apache2.conf\n/etc/init.d/apache2 restart\nsudo apt-get install gksu^C\n\n\nA: I have a made an easy to use, simple bash script that installs LAMP stack on your system automatically.\nJust run this command in your terminal to use the bash script:\nwget --no-cache -O - https://gist.github.com/EmpireWorld/737fbb9f403d4dd66dee1364d866ba7e/raw/install-lamp.sh | bash\n\nAlso phpMyAdmin installation included in the gist.\nCheck out the Gist\n\nA: Try EHCP (easy hosting control panel) ...\nehcp installation on a clean server will do the dirty job for you ...\n", "Q: What is the performance loss if you run Ubuntu desktop edition on a server machine? We have installed Ubuntu desktop edition on our dev server.\nI was wondering if there is any noticeable performance loss compared to the server edition.\n\nA: Beyond the fact that an X server is running on the machine (and things like ubuntu-one-client once a user is logged in locally), there's really no difference nor performance impact.\nThere isn't a \"server\" version and a \"desktop\" version of Ubuntu where one magically limits the number of connections you can have to a machine (like some other \"workstation\" and \"server\" operating systems of years past).\nThe different install flavors are simply a different set of starting packages.\n\nA: As far as I know, there is no performance lost as far as overhead and whatnot. It mostly depends on what you have installed. You can turn desktop Ubuntu into server Ubuntu by installing the same security/monitoring/visualization programs. The server edition just comes with a better set of pre-installed packages suited to a secure, easily maintained server.\nEither way, I would recommend NOT installing X server and a desktop environment (GNOME, KDE, etc). This reduces boot time and memory/CPU usage.\n\nA: The significant performance factor in Ubuntu Desktop is the inclusion of Gnome. Ubuntu Desktop is fine for a server (although a more lightweight desktop environment may be desired), but if you do not need a graphical environment, Ubuntu Server would be preferable.\nThis is not strictly performance related, but Ubuntu Desktop also contains several packages which would simply not be useful in a server environment, such as OpenOffice and GIMP. These can always be removed however.\n\nA: Almost all of the difference between Ubuntu Desktop and Ubuntu Server is in the default set of packages installed.\nThe only real code difference is in the kernel package - the linux-image-*-server packages have a slightly different kernel configuration to the desktop kernels.  Such kernel options include enabling PAE mode (for accessing > 4GiB memory on 32bit systems) and changing the default pre-emption level (which prioritises CPU throughput over task latency).\nThese won't generally have a major performance impact.\n\nA: The Desktop & Server editions have different kernels that might result in different performance, especially under some specific load conditions.  One example reason being that task switching happens more often in the desktop edition's kernel because that improves responsiveness, but task switching incurs some overhead and thus also slightly lowers the performance of (some) applications.\nIn practice, it's unlikely that you will ever see this difference on a development system, and IME such a system is not under a heavy load, and it probably has other configuration differences that affect performance anyway.\nIf you want to minimize differences related to the kernel, it's always possible to use the server kernel in the desktop edition.\nAnd of course, in most cases permanently running a desktop system probably has as much or more impact on performance as using a different kernel anyway...  ;-)\n\nA: https://www.makeuseof.com/tag/difference-ubuntu-desktop-ubuntu-server/\n“... After Ubuntu 12.04, both Server and Desktop variants use the same kernel. Previously, Desktop and Server used different kernels. Because both Ubuntu Desktop and Ubuntu Server employ the same kernel, you can add any packages to either variant. This means that while default installation varies, you can customize your Ubuntu flavor accordingly.\nSo you might start with Ubuntu Server and install a desktop environment if you decide you can’t run it headless. Alternatively, you could begin with Ubuntu Desktop and add the necessary packages to create a server. Since Ubuntu Server and Desktop share a core Ubuntu kernel, default installation differences don’t preclude future software package installs.”\n\nA: TLDR: I experienced 15% performance improvement going from desktop to server version.\nI have a reasonably high load recursive program written in c++. It generates and traverses a few million tree nodes which all store various \"states\", and tries to find a \"good enough\" solution.\nFor a single input that we use as a benchmark, the program used to consistently take about 14 seconds on an average on the desktop. With the server, the average is closer to 12 seconds. That's almost 15% improvement. (a side note on this benchmark. We use it internally consistently to measure any performance regression resulting from any code changes. Or judge the efficacy of builds / platforms. For example a Linux release build is about 5 times faster than Linux debug. And Linux debug is about the same speed as Windows release, which is about 15 times faster than Windows debug).\nThis is on exactly the same hardware, and each example running as a headless server. I needed to reinstall Linux (because the machine was going to move zones, and I didn't want any private information accidentally sitting on it), and decided to install the server version on a whim. I don't know enough about other programs that the desktop might have been running in the background, and hence slowing down the task at hand. Mine is only a single data point - so take it for what's it worth. Though in my defense, it's a real world usage example. Would love for someone to construct some lab tests and share benchmarks.\n", "Q: When installing I'm given the option of encrypting my home folder -- what does this do? \n*\n\n*Does encrypting my home folder make my computer more secure?\n\n*Do I have to enter my password more if my home folder is encrypted?\n\n*What else should I know about encrypting my home folder?\n\n\nA: Simply\n\n\n*\n\n*Encrypting your home folder doesn't actually make your computer more secure - it simply makes all the files and folders in your home folder more secure from unauthorized viewing.\n\n*\n\n*Your computer is still \"vulnerable\" in a security standpoint - but it becomes very difficult for your content to be stolen (unless the attacker has your password).\n\n\n*You won't need to actually enter your password any more than you normally do - when you log in to your computer your files are seamlessly decrypted for just your session.\n\n*There is a possibility (depending on your computers hardware) that this will affect the performance on your machine. If you're worried about performance more than security (and you're on an older machine) you may wish to disable this feature.\n\n\nTechnically\nUbuntu uses \"eCryptfs\" which stores all the data in a directory (this case the home folders) as encrypted data. When a user is logged in that encrypted folder is mounted with second decryption mount (this is a temporary mount that works similar to tmpfs - it's created and run in RAM so the files are never stored in a decrypted state on the HD). The idea is - if your hard drive is stolen and the contents read those items aren't able to be read since Linux needs to be running with your authentication to create the successful mount and decryption ( The keys are SHA-512 encrypted data based of several user aspects - the keys are then stored in your encrypted key ring ). The end result is technically secure data (as long as your password isn't cracked or leaked).\nYou will not have to enter your password any more than usual. There is a slight increase of Disk I/O and CPU which (depending on your computer specs) may hinder performance - though it's quite seamless on most modern PCs\n\nA: Less technically answer as requested by OP.\nSecurity benefits of encrypted Home via ecryptfs as in Ubuntu:\n\n\n*\n\n*Will not require any additional passwords or keys to be remembered or entered.\n\n*Does not make your computer more secure on a network, e.g. on the internet.\n\n*If the computer is shared between several users, provides an additional barrier against other users accessing your files. (Difficult technical discussion.)\n\n*If an attacker gains physical access to your computer, e.g. steals your notebook, this will protect your data from being read by the thief. (If the computer is off they cannot read your data without your password. If the computer is switched on and you are logged in, it's possible for a thief to steal your data, but requires a more advanced attack, is therefore less likely.)\n\n\nA: What else you should know about encrypting your home folder is that the data in it is not accessible when you are not logged in. If you have some automated or external process (like a crontab) that tries to access this data, it will work great while you are watching it, but fail when you are not watching it. This is very frustrating to debug.\n\nA: The security of your actual system isn't determined by the security of your files, folders, and documents...all it does is makes them slightly more secure from prying eyes....\n\nA: There's a nice article on the topic written by the Ubuntu developer himself, please see: http://www.linux-mag.com/id/7568/1/\nSummary:\n\n*\n\n*A combination of LUKS and dm-crypt are used for whole-disk encryption in Linux.\nUbuntu uses the Enterprise Cryptographic File System (ECryptfs) from version >= 9.10 to enable home drive encryption on login.\n\n\n*An upper and lower directory are created, where the upper directory is stored unencrypted in RAM, granting access to the system and current user. The lower directory is passed atomic, encrypted units of data and stored in physical memory.\n\n\n*File and directory names use a single, mount-wide fnek (file name encryption key). The header of each encrypted file contains an fek (file encryption key), wrapped with a separate, mount-wide fekek (file encryption key, encryption key). The Linux kernel keyring manages keys and provides encryption via its common ciphers.\n\n\n*Using an eCryptfs PAM (Pluggable Authentication Module) does not break unattended reboots, unlike typical full-disk encryption solutions.\n\n\n*The eCryptfs layered filesystem enables per-file, incremental, encrypted backups.\n", "Q: How to configure mail server to report a hostname distinct from server name I have a VPS set up with Ubuntu 10.04 Lucid running exim4 as the MTA.  The machine name itself is something easily recognizable to us (in this case, 'Fermat'), but the machine itself is responsible for serving up one of our domains (i.e. www.example.com).\nWhen generating an email from exim, the email headers are reporting the server name (Fermat) instead of the domain name (example.com).\nIs there a way to 'force' exim to report the server name as example.com without changing the machine's host name?\n\nA: Make sure the content of /etc/mailname is example.com. If not, change it and reboot:\nsudo nano /etc/mailname\nsudo reboot\n\n\nA: Reconfigure exim4:\nsudo dpkg-reconfigure exim4\n\nOne of the questions it'll ask you is for the \"System mail name\". You want to change that. \n", "Q: Resetting gnome panel How does one reset the gnome panel to the initial state?\nDuring use, gnome panel applets move and get replaced with the ones users like. After some time the panel becomes so cluttered that it requires a cleanup. The easiest way would be to reset the panel to the original state that it was in after install. Is there an easy way of doing that?\n\nA: Run rm -r ~/.gconf/apps/panel in a terminal, then log out of Gnome and log back in.\n\nA: Move the old configuration directory out of the way, and it'll get reset. Of course, to take effect, you'll have to restart the panel.\nmv ~/.gconf/apps/panel ~/gnome-panel-backup\ngnome-panel --replace &\n\n\nA: You can reset the panel by running\ngconftool-2 --recursive-unset /apps/panel\n\nin a Terminal or by hitting Alt+F2 and pasting this command in the textfield and then hit run. After that gnome-panel needs a restart and therefore it has to be killed with the command\npkill gnome-panel\n\nthe same way as the command before. The reset gnome-panel will start again automatically.\n\nA: gconftool-2 --recursive-unset /apps/panel\npkill gnome-panel\nnohup gnome-panel --replace </dev/null &>/dev/null &\n\nThis formula is based on the above answers. This works slightly better.\n", "Q: KATE keeps forgetting I have the shell plug-in enabled I'm using Kubuntu (Karmic) and KATE is my favorite editor. I don't enable many plug-ins, but I really like the inline shell. \nThe problem is, across re-starts, KATE seems to forget that I enabled this plug-in. I've checked across all sessions and the behavior is the same. \nIs there some easy way to fix this?\n\nA: This is a bug with Kate. But if you disable the session auto save, it loads the plugins. You can do this by changing the Application Startup Behavior to Start new session. Application Startup Behaviors can be changed from Settings > Configure Kate > Sessions. This is not a fix, just a walk-around.\n", "Q: How do I change how long notifications are displayed? Is there a way to change how long the libnotify notifications last? I've googled around for this for months and no still no luck. \nI'm actually starting to think that you can't change it. I can't even find anywhere in the API where developers can control this.\n\nA: crude but effective and then some - caveat this also kills pending notifications\nthis can only shorten display times just change the 1.5 in sleep 1.5; below:\nref:\ndetails in Close button on notify-osd?\nx-ref:\nExpiry time in notify-send notifications\ndbus-monitor \"interface='org.freedesktop.Notifications'\"            \\\n| grep --line-buffered  \"member=Notify\"                             \\\n| sed -u -e 's/.*/sleep 1.5; killall notify-osd/'                   \\\n| bash\n\nBookmarks:\nself - How do I change how long notifications are displayed?\nExpiry time in notify-send notifications \n\nA: The duration of the notification is, I believe, dependent on the length of the message.\nFrom the perspective of someone who was worked with it indirectly (by using the pynotify module in Python), I have discovered that specifying a duration for a message is not possible.\n\nA: You can't do this normally. However, there is a patched version of notify-osd that supports it:\nFrom Ubuntu 16.04 onwards:\nYou'll need to add two PPA's:\nsudo add-apt-repository ppa:leolik/leolik\nsudo add-apt-repository ppa:nilarimogard/webupd8\nsudo apt update\n\nThen install it like this:\nsudo apt-get upgrade\nsudo apt-get install notifyosdconfig\n\nThe configuration dialog should be in Applications->Accessories or notifyosdconf from the terminal. There's a setting for the standard notification duration as per screenshot above if you don't set it the --expire-time parameter.\nExample:\nnotify-send --urgency=LOW --expire-time=1 --icon=face-laugh \"test\" \"1 second\"\n\nOlder versions: (9.10-14.10)\nYou'll need to add two PPA's:\nsudo add-apt-repository ppa:leolik/leolik\nsudo add-apt-repository ppa:amandeepgrewal/notifyosdconfig\nsudo apt-get update\n\nThen install it like this:\nsudo apt-get upgrade\nsudo apt-get install notifyosdconfig\n\nThe configuration dialog should be in Applications->Accessories or notifyosdconf from the terminal. There's a setting for notification duration as per screenshot above.\nExample:\nnotify-send --urgency=LOW --expire-time=1 --icon=face-laugh \"test\" \"1 second\"\n\n", "Q: How to log out if the session applet is missing from the top panel? For some reason, sometimes when I log in the top panel applets appear garbled. For instance the session applet is missing its icon, and the current username is repeated twice. This doesn't happen very often, but when it does the session applet is not responsive so I can't get to the log out menu option.\nIs there any other way to log off the current user other than using the (non working) session applet?\n\nA: If you enable Ctrl+Alt+Del, you can use that to kill the X server, which will log you out. To enable this, go to System -> Preferences -> Keyboard, then go to the Layouts tab and click Options. Expand the \"Key sequence to kill X server\" and check the box.\n\nA: Press Alt+F2, type gnome-session-save --logout, then hit enter. If an application is blocking logout, try gnome-session-save --force-logout\n", "Q: How do I submit wallpapers to be considered for inclusion in Ubuntu? I take photos from time to time, and if I take an exceptionally beautiful one, I'd like to submit it for inclusion in Ubuntu. Where do I send/upload it?\n\nA: Add it to the Ubuntu Artwork pool, here: http://www.flickr.com/groups/ubuntu-artwork/\nA team of judges will select somewhere around 15 photos from this pool for the default wallpapers.\n", "Q: Going from a shared NFS /home to a full LDAP solution I recently deployed about a dozen Ubuntu (Karmic) desktops in a small office. Everything was going great, but storage became an issue. I then moved /home to an NFS mount which solved the immediate problem.\nMonths later, I'm regretting this. The company is extremely disorganized with high turnover, people never stay at the same desk for long and now I have 12 machines that anyone needs to access at any given time. This gets crazy with conflicting UID/GID's as well.\nI'd like to just use LDAP and make the problem go away. The issue is, they want to be self sufficient, so I need some (easy) way for the office administrator to manage users. Preferably something GUI driven and simple/intuitive to use.\nWhat are my options?\n\nA: You can try eBox for the server, it has a very straightforward web interface, you can install it from the repositories, and has all the functionality you need. The whole process is documented in the Ubuntu Server Guide, check https://help.ubuntu.com/10.04/serverguide/C/ebox.html.\nHowever you still would have to take care of the configuration in the client workstations.\n", "Q: Indicator Applet: How to get rid of the clock? There are currently 2 clocks on my panel: one in the \"Indicator Applet\" and one in the \"Clock\".  The one in the \"Indicator Applet\" is redundant and isn't as good as the \"Clock\".  \nDoes anyone know how to get rid of the clock in the \"Indicator Applet\"?\n\nA: You must have somehow installed the new, under development Ubuntu clock. Go into Synaptic, and remove the package indicator-datetime. That should fix it.\n", "Q: How can I make Empathy retry connecting when it has a network problem I have added Empathy to the list of applications that open by default, and it's configured to auto-connect to MSN  when started, but when I login to my laptop the wifi connection takes a few seconds to be ready. Before the net is up, Empathy has already started, tried to login to MSN and failed, and I can't get it to connect after that. \nThis seems to be a bug in Empathy, but how can I get a fix for it, or if not possible, how can I delay its start until the network is up?\n\nA: Apparently this is a known bug in Empathy, so I decided to launch Empathy from a script that checks if the network is up (connecting to http://www.google.com, internet's true heartbeat :) If the network is not working, it will sleep for 5 seconds and retry, until it tried 30 times\nThis is the script (named waitfornet.py)\n#!/usr/bin/python\n\nfrom urllib2 import urlopen, URLError\nfrom subprocess import Popen\nfrom time import sleep\nfrom sys import argv\n\nMAX_TRIES = 30\nDELAY = 5\n\nif len (argv) < 2:\n    print ('Check for network connectivity and run a command once the net is up')\n    print ('Tries up to %d times waiting %d seconds between each try' % (MAX_TRIES, DELAY))\n    print ('\\nUSAGE: python waitfornet.py <command to run>')\nelse:\n    while True:\n        MAX_TRIES -= 1\n        if MAX_TRIES < 0:\n            raise ValueError ('Reached the max iteration count and the net is still down')\n\n        try:\n            data = urlopen('http://www.google.com')\n        except URLError:\n            # if there's a problem connecting to google, that must mean\n            # that the net is still down, so sleep 5 seconds and try again\n            print ('Internet is down... retrying...')\n            sleep (DELAY)\n            continue\n\n        # if you got here it means that the urlopen succeded\n        pid = Popen([argv[1], ' '.join(argv[1:])]).pid\n        break\n\nand this is how I launch it from the \"Startup Applications\" menu:\n~/scripts/waitfornet.py empathy\n\n\nA: It sounds like Empathy may need a patch to do this kind of thing internally. But you should be able to poke Empathy to do the right thing by disconnecting from your network and reconnect.\nI've seemingly had bugs with Empathy refusing the connect to a bunch of networks at various times. But it should give a count down \"Will retry in X seconds.\"\nBut that will take code and if you want it, a bug report needs to be made.\n\nA: I wrote a script specifically to overcome this problem. This script (which is based on python and D-Bus) will connect empathy to the network every time when the network is online. Even if the connection goes down and reconnects, the script will automatically reconnect empathy again. \nHope you'll enjoy it. Please leave a comment if you need any improvements.\n", "Q: Upgrade experiences from 8.04 LTS to 10.04 LTS? I am running 8.04 desktop as a server and hosting my own web server, has anyone experienced any issues with upgrade from 8.04 to 10.04?\n\nA: Yes, I upgraded a production system, and worked fine.\n\nA: While I haven't, that is one thing that gets heavily tested in LTS releases prior to their release.\n\nA: I upgraded a production system from 8.04 to 10.04. I had to switch from gdm to kdm because gdm would not find any users to log in (but one could log in through a VT.)\nI've filed the bug in Launchpad but it was never even triaged, not even with a request for more info! At least it saved me from having to reinstall the box.\nOtherwise no hiccups. I removed Flash and Nvidia binary blobs from the machine (user requested it) before upgrading and then reinstalled them from the packages later. The new nouveau drivers are slick (VTs actually work with nouveau.)\n\nA: Done on a VM, using the desktop edition.\n Seen no issue.\n\nA: I had some issues on Desktop Edition once, something about the packages I had installed made the upgrade process go a little funky, and it kinda screwed up my python (had to manually find and compile module dependencies, and then I ended up having to reinstall later anyway to rid myself of wubi, and everything went fine there). On a clean install, or a production server, that shouldn't be an issue.\n\nA: I’m having problems with a new install of 10.04 on an old AMD machine with a small memory footprint. It runs fine but installing a new kernel causes GRUB2 and/or the Kernel to become unbootable, I just get dumped at the Grub command line prompt. No warnings no error message just……..\nI can still manually boot the original kernel but nothing since.\nLooking at the bug list there are lots of people having similar problems but little apparent activity to resolve the problem.\nI am very sad as the very heavily updated 8.?? was working fine with no problems just a bit of a dirty disk.\n\nA: I actually upgraded from 8.04 to 10.04 but not in the replacement sense. Instead, I did a fresh install of 10.4 in a dual-boot configuration. I did experience problems (see my other postings here) but I eventually solved all of them. The experience is amazing and very rewarding. Highly recommended.\n\nA: I have tested this myself on a VM. And as Andrew said, this was heavily tested before the release.\n\nA: I installed the desktop version of 10.04 as a triple-boot option on a system with both 8.04 and Vista.  I ran into two issues, both of which surprised me as I am used to Ubuntu installations running absolutely smoothly.  Firstly, GRUB2 identified my Windows recovery and Vista partitions incorrectly and wouldn't boot either. This was fixed by customizing the boot menu using the correct drive identifiers.  The second problem was that after the first update the machine wouldn't boot at all with the error message \"udevadm trigger is not permitted while udev is unconfigured\".  The latter issue was fixed using information posted on the web.  All three operating systems now seem to be functioning flawlessly. \n", "Q: How do I enable full-color support in Vim? I have a lovely Vim colorscheme (xoria256) and it looks brilliant in GVim, but when I use normal vim in Terminal, the colorscheme is only partially supported -- for example, the default semi-transparent aubergine background color is used. How do I make Terminal faithfully render my Vim colorscheme?\n\nA: GNOME Terminal supports 256 colors, but doesn't advertise its support.  You can override vim's autodetection by putting the following:\nif $COLORTERM == 'gnome-terminal'\n  set t_Co=256\nendif\n\nin your ~/.vimrc.\nNote: if you use GNU screen, it will happily eat those 256-color codes and convert them to basic 16 colors.  A better fix is to change TERM to xterm-256color before launching screen/vim.\nUpdate for 2017: if you have a sufficiently recent Vim (7.4.1799 or newer), and a sufficiently advanced terminal emulator (xterm, or gnome-terminal based on a sufficiently recent version of VTE), you can :set termguicolors and terminal vim will use full 24-bit colors as defined by your vim theme using highlight guifg=#rrggbb guibg=#rrggbb.\n\nA: A more general solution is to install the term type \"xterm-256color\". In 10.04 I think it's installed by default. Previously you needed to install \"ncurses-term\" to get it.\nThen set the term type in .bashrc with something like the following:\nif [ -n \"$DISPLAY\" -a \"$TERM\" == \"xterm\" ]; then\n    export TERM=xterm-256color\nfi\n\nIf you'd prefer to only have the 256 colour capability for certain programs (perhaps it confuses some others) use instead:\nTERM=xterm-256color myprogram\n\nand perhaps set that as an alias for the program.\nThen check your terminal colour capabilities with:\n$ tput colors\n256\n\nYou still may need the vim setting above to have vim recognise it. Most applications will recognise the 256 colours automatically (if they can use them).\nEmacs also has colour themes that are much better with 256 colours. To check if it 256-colour capable run:\nM-x list-colors-display\n\n256colors.pl is Perl script that will display all the colours in your terminal.\n\nA: Just include the line below into your $HOME/.bashrc (preferably in the last line of the file):\nexport TERM=\"xterm-256color\"\n\nAnd save it. After, restart your gnome-terminal. This change will be available not only in vim, but for all your terminal applications.\nTo check if it works, run this little script:\n#!/usr/bin/env python\n# Copyright (C) 2006 by Johannes Zellner, <johannes@zellner.org>\n# modified by mac@calmar.ws to fit my output needs\n# modified by crncosta@carloscosta.org to fit my output needs\n\nimport sys\nimport os\n\ndef echo(msg):\n    os.system('echo -n \"' + str(msg) + '\"')\n\ndef out(n):\n    os.system(\"tput setab \" + str(n) + \"; echo -n \" + (\"\\\"% 4d\\\"\" % n))\n    os.system(\"tput setab 0\")\n\n# normal colors 1 - 16\nos.system(\"tput setaf 16\")\nfor n in range(8):\n    out(n)\necho(\"\\n\")\nfor n in range(8, 16):\n    out(n)\n\necho(\"\\n\")\necho(\"\\n\")\n\ny=16\nwhile y < 231:\n    for z in range(0,6):\n        out(y)\n        y += 1\n\n    echo(\"\\n\")\n\n\necho(\"\\n\")\n\nfor n in range(232, 256):\n    out(n)\n    if n == 237 or n == 243 or n == 249:\n        echo(\"\\n\")\n\necho(\"\\n\")\nos.system(\"tput setaf 7\")\nos.system(\"tput setab 0\")\n\nThereafter, you will see something like the following (depends on your gnome-terminal theme):\n\n\nA: Well, you can always configure Gvim to make it look like Vim. You just have to create a ~/.gvimrc file and paste in it these customisation tricks:\nset guioptions-=r  \" no scrollbar on the right\nset guioptions-=l  \" no scrollbar on the left\nset guioptions-=m  \" no menu\nset guioptions-=T  \" no toolbar\n\nI don't think this solves your problem, but who knows ;-)\n\nA: I made a separate profile for Vim which uses a solid, opaque color in the background. I just manually switch to it whenever I use Vim. Not sure whether or not there's a better method. I'd like to think so.\n", "Q: Keeping multiple workstations in sync I work with multiple computers for various reasons. I want to keep those computers in sync configuration wise. I already have a VCS based setup that allows me to manually update configurations on multiple hosts. But i'm looking for a way to do this automatically.\nWhat I'm looking for is:\n\n\n*\n\n*A way to sync configuration (vim, ssh, evolution)\n\n*keeping certain directories in sync (like ~/Documents)\n\n\nThis is all user configuration and not system configuration. At times the workstation can be offline or behind a slow link, so being able to detect that and act accordingly is a plus.\n\nA: If you don't have any confidential data in those files, you could use Dropbox to keep them automatically in sync across multiple machines. The Dropbox daemon will synchronize one folder, usually ~/Dropbox, but you can include other files or directories in the synchronization by symlinking them into that folder. (I think Dropbox may also offer some other method to keep multiple folders in sync, but I can't find the directions right now)\n\nA: While I'd recommend Dropbox (a better cross-platform solution) if all your workstations are Ubuntu-based you could use Ubuntu One. If you're looking for something more powerful have a look at rsync.\n\nA: Landscape is paid service by canonical for managing and monitoring multiple ubuntu systems.\nWhat's better is that by paying for it you also support Ubuntu!\n\nA: Another free service you could use is Spideroak, which is a bit less simple than Dropbox and UbuntuOne but on the other hand more flexible: You can select any folder you want for backup and decide which folders to sync. This allows nicer configurations because you can use the service for backing up data that you don't want to synchronize on all machines.\nAnother advantage (although it is hard to check whether this is really true): All data is encrypted, they have a \"zero knowledge policy\" which means they don't even know the names of your files.\n\nA: You could create a shared Git repository on a private server with SSH access. For example, I am using a nearlyfreespeech.net account for this, and cost is very low. \nIf you want to get fancy you can create a cron script to automatically push/pull changes every so often, always keeping your files up-to-date. As long as you don't work on two machines simultaneously, then you should never encounter any merge conflicts.\n", "Q: How can I prevent myself from getting logged out automatically in a multi-user setup? I am using my machine with multiple accounts logged in at the same time. I am using KDM desktop manager and KDE desktop. Ever since I upgraded to Karmic, when using one user the second user, who is active on another virtual terminal, gets logged out automatically. I have looked through the logs and can't find anything that would cause this. \nWhat should I be looking into to figure it out? Is there some sort of feature that was turned on through the upgrades? (the machine has been through many releases..).\n\nA: You can check that you have enough TTY's:\nOpen a terminal and do:\ngrep tty /etc/default/console-setup\n\nIt should show (check the last number, it should say 6):\nACTIVE_CONSOLES=\"/dev/tty[1-6]\"\n\nIf not, edit the /etc/default/console-setup file by typing:\ngksudo gedit /etc/default/console-setup\n\nAnd look for ACTIVE_CONSOLES, and make the line look this:\nACTIVE_CONSOLES=\"/dev/tty[1-6]\"\n\n\nA: In the end I lived with this for a while and ended up upgrading Ubuntu to a newer version and it went away. So not sure what it was but probably a bug somewhere.. \n", "Q: What's the difference between package managers? What are the differences between apt-get, aptitude, and synaptic, and which one is the recommended choice for normal day-to-day package management?\nThis is a basic question, but I think it'd be good information to have on the site, and besides I am relatively new to Ubuntu so I could use an expert explanation.\n\nA: I personally prefer apt-get because it's a command-line program. And the syntax for installing packages is very simple:\n\nsudo apt-get install packagename\n\nI use apt-get on a day to day basis for installing and removing packages.\nSynaptic is GUI-based and aptitude is text-based.\n\nA: Basically, they only differ in how low-level they are.\ndpkg: not even a proper package manager, apt uses it\napt-get: command-line, only if you know the package name\naptitude: text-based, but user friendly\nsynaptic: equivalent of aptitude in GUI\nSoftware Center: for everyday users\nBTW, these are all front-ends of apt (except dpkg), which is the only package manager on Ubuntu.\n\nA: The Debian FAQ has a pretty good explanation of the different package managers. (dpkg, apt-get, aptitude, tasksel, synaptic)\n\nA: As an addition to mac9416's excellent answer, Kubuntu offers the same command-line tools as Ubuntu, namely dpkg, apt-get, and aptitude. There are also two graphical package managers:\nAdept is a straightforward GUI for apt-get, which lets you edit the source lists, browse packages by category or by name, see their status, and install/uninstall them.\nKPackageKit is a simple GUI for PackageKit, which is a newer, cross-distribution package management system that uses apt-get behind the scenes. It lets you search for programs by various criteria, install and uninstall programs, make routine upgrades, and edit the source lists.\n\nA: Probably the most popular package managers are apt-get, aptitude, synaptic, and Software Center. There are others (Linux Mint has its own, and there are some designed for KDE), but these are the ones you'll run into most often.\napt-get is a simple command-line tool. It's handy if you know the exact package name of what you want to install and don't want to spend time clicking through a GUI to get it.\naptitude is very similar to apt-get, and I've heard that it deals better with crazy dependency situations. Which one is really better is debatable.\nsynaptic is a low-level GUI. This is a good choice if you are a fairly advanced user but are not comfortable with command-line utilities.\nSoftware Center is a very high-level, new-user-friendly GUI. Software is nicely categorized so that, if you're not exactly sure what app you want, you can find what you need quickly.  The Software Center also stands out in that it is the only package manager in this list that allows you to purchase commercial applications.\ndpkg is a lesser-used, low-level package manager standard for most Debian-based systems.  In reality, apt-get, aptitude, synaptic, and the Ubuntu Software Center are all just front-ends to either dpkg or apt, which is in itself a front-end to dpkg.\nIn answer to your question, \"which one is the recommended choice for normal day-to-day package management\", I would say that Software Center is recommended for most uses. But as you gain more experience, you will find some of the features of lower-level package managers useful.\n\nA: One other tool that has hardly received mention is tasksel. It's used for selecting specific tasks, mark them for installation, and then installing them (possibly using aptitude -- not sure).\nRun tasksel --list-tasks to have a look at what tasks are available.\n\nA: One key difference between aptitude and apt-get which has escaped notice above is that aptitude, unlike apt-get, will offer you different options in case there is a dependency clash. apt-get will simply fail. aptitude is much more flexible and versatile for that reason.  Having never used a GUI package manager, I don't know how Synaptic and others handle such situations.\n", "Q: How can I get Gmail notification in my indicator applet (without leaving Evolution open)? I'd like to have a Gmail notification service in my Epiphany indicator applet, without leaving Evolution open in the background all the time.  Right now I only get notifications if Evolution is open.  Strangely, this is not the case with Google calendars in Evolution -- evolution can be closed yet I still get applet notifications through the clock/calendar applet.\n\nA: I use CloudSN (Cloud Services Notification). It supports gmail, google reader, pop3, imap, twitter, identi.ca\nhttp://chuchiperriman.github.com/cloud-services-notifications/ (PPA available)\nThe best part is that it supports multiple accounts.\n\n\nA: I've had good luck with CheckGmail. Has a nice GUI, cool toaster popups, and allows you take actions on emails from the tray. \nsudo apt-get install checkgmail; checkgmail &\n\n\nA: Check out GMailWatcher. It is still in early development stage, but works quite well. I am using it for over a month now. Recommended.\nIntroductory Blogpost: owaislone.org/blog/2010/jul/gmail-watcher\nLaunchpad URL: https://launchpad.net/gmailwatcher\nPPA  \n$ sudo add-apt-repository ppa:loneowais/ppa \n$ sudo apt-get update && sudo apt-get install gmailwatcher\n\n\nA: Gmail Notifier is probably the best option for what you are trying to accomplish.\n", "Q: How to rollback to PHP 5.2? I have just installed a 10.04 LTS on my development server but the system that I need to run on it (Magento ecommerce) is not compatible with PHP 5.3 which ships with the newest version of Ubuntu. Is there a safe and upgrade-proof way of getting PHP 5.2 installed or will it be easier to use an older version of Ubuntu?\n\nA: It is possible to use karmic packages and pin them with aptitude. This can be done by using this commands:\n# remove all php packge\nsudo aptitude purge `dpkg -l | grep php| awk '{print $2}' |tr \"\\n\" \" \"`\n# use karmiс for php pakage\n# pin-params:  a (archive), c (components), v (version), o (origin) and l (label).\necho -e \"Package: php5\\nPin: release a=karmic\\nPin-Priority: 991\\n\"  | sudo tee   /etc/apt/preferences.d/php > /dev/null\napt-cache search php5-|grep php5-|awk '{print \"Package:\", $1,\"\\nPin: release   a=karmic\\nPin-Priority: 991\\n\"}'|sudo tee -a /etc/apt/preferences.d/php > /dev/null\napt-cache search -n libapache2-mod-php5 |awk '{print \"Package:\", $1,\"\\nPin: release a=karmic\\nPin-Priority: 991\\n\"}'| sudo tee -a /etc/apt/preferences.d/php > /dev/null\necho -e \"Package: php-pear\\nPin: release a=karmic\\nPin-Priority: 991\\n\"  | sudo tee -a     /etc/apt/preferences.d/php > /dev/null\n# add karmic to source list\ngrep 'main restricted' /etc/apt/sources.list|grep -v \"#\"| sed s/lucid/karmic/g | sudo tee             /etc/apt/sources.list.d/karmic.list > /dev/null\n# update package database (use apt-get if aptitude crash)\nsudo apt-get update\n# install php\nsudo aptitude install -t karmic php5-cli php5-cgi\n# or (and) sudo apt-get install -t karmic  libapache2-mod-php5\nsudo aptitude hold `dpkg -l | grep php5| awk '{print $2}' |tr \"\\n\" \" \"`\n#done\n\nGot this from link text\n\nA: There's a great blog post about this at http://civicactions.com/blog/2010/may/26/ubuntu_1004_and_drupal?page=1#comment-3717\n\nA: I've recently tried to solve the same problem myself. Instead of making changes to the package management I compiled PHP 5.2.17 from the source code myself and then used the program Checkinstall to install the new .deb package on my system.\nI wrote up the steps in a blog post, Compiling PHP 5.2 for Ubuntu 10.10, but the steps basically involved the following:\n\n\n*\n\n*Download PHP source (http://php.net/downloads.php) to /usr/local/src\n\n*Configure source, reading INSTALL doc and output from ./configure --help\nmy configure command looked like this:\n./configure --prefix=/opt --with-apxs2=/usr/bin/apxs2 --with-curl=/usr/lib --with-pgsql --with-pear --with-mysql --with-gd\n\n\n\n*\n\n*Compile the source using 'make'\n\n*Install the compiled package using 'checkinstall'\n\n\nAnd that was it. I had already installed Apache2 using Synaptic (you need to use the apache2-mpm-prefork package for use with PHP). Also if you had any PHP5 pacakges already installed you would need to uninstall them before trying to install your own compiled package.\nCompiling the package yourself really doesn't take long at all and is a good experience if you haven't done it already on your Ubuntu machine.\n\nA: You can use my ppa, that I have created for this purpose. Please take notice of the pinning that is necessary. Also, aptitude will not recognize the pinning. You must use the aptitude specific method if you want to use it.\nNote - this is for 10.04 (lucid) only\n", "Q: How do file permissions work? Can you explain briefly the main concepts and command line tools used to manage file permissions?\n\nA: \nWarning: Changing permissions of files and directories is potentially harmful and may render your system unusuable. When run recursively as root on the wrong path we may come to a point from where we will have to reinstall Ubuntu. It is therefore a good idea to not change permissions outside of HOME directories, and running the commands recursively as root should be avoided whenever possible.\n\nFile permissions\nUbuntu has inherited the concept of permissions from Unix when for files or directories there are three tasks we can permit or deny:\n\n*\n\n*r (read) file/directory may be opened for read access.\n\n*w (write) file/directory may be opened for write/edit access.\n\n*x (execute) file may be executed as a program/directory may be traversed.\n\n(Traversing a directory essentially means using it as part of a path name.  See https://unix.stackexchange.com/a/13891 or https://unix.stackexchange.com/questions/21251 for more explanations.)\nIn addition we have three cases as to whom we grant a permission:\n\n*\n\n*u (user) the owner of a file is granted any of the permissions.\n\n*g (group) group the file belongs to is granted a permission.\n\n*o (other) all others are granted a permission.\n\nNow to get the combination of these sorted we use a binary system where each bit defines a permission. This can be best shown in the following Table\n    Permission | Binary | Octal  | User  | Group | Other |\n    ======================================================\n      r        |  100   |   4    |       |       |       |\n      w        |  010   |   2    |       |       |       |\n      x        |  001   |   1    |       |       |       |\n    =======================================================\n    Number\n\nNow if we want for example\na) the owner of a file (= user) has read, write, and execute permission,\nb) the file's group granted read and execute permissions, and\nc) all others should only have read access.\nThen the resulting file permission will be:\n u   g   o\nrwx r-x r--\n\nTo get this in the octal numbers, eg. for the chmod command or when we have to understand an error message we need to fill above table as below:\n    Permission | Binary | Octal  | User  | Group | Other |\n    ======================================================\n      r        |  100   |   4    |   4   |   4   |   4   |\n      w        |  010   |   2    |   2   |   0   |   0   |\n      x        |  001   |   1    |   1   |   1   |   0   |\n    ======================================================\n    Numbers add to                   7       5       4     \n\nEach permission number needs to be added to sum up for a user (4+2+1=7), group (4+0+1=5), and other (4+0+0=4). The resulting number then is:\n u   g   o\n 7   5   4\n\nWe now have two options to change the permission bits with chmod:\nchmod u+rwx g+rx o+r filename\n\nor much simpler with\nchmod 751 filename\n\nBoth commands will do the same.\n\nThe default permission of a newly created file in our home will be 664 (-rw-rw-r--).\n\nIf we want files to be executable as programs we will have to change this permission.\n\n*\n\n*Note that we will also have to change the permission of the directory this executable may be in. Only if both, the file's and the directory's executable bit are set we will be allowed to run this file as a program.\n\n\n*When copying a file to our home it will lose it's permissions which will be replaced by our own default permissions (unless we copy using advanced options e.g. an archive option).\n\n\n*Also note that file may inherit their permission from their mount point, resp. mount options. This is important when mounting Windows formatted drives which do not support  Unix permissions.\nUsers and Groups\nWe soon realize that this was only half of the story. We also need to sort out belongings. To do this each file or folder has a defined owner, and a defined group membership.\nEach time we create a file we will be the owner of a file, and the file's group will also be us. With ls -l we can see permissions, ownership, and group as seen from the following example output:\n-rw-rw-r--  1 takkat takkat    4096 Sep 12 20:25 test\n\n\n\n*\n\n*We are only allowed to change permissions, groups or ownership of a file that is our's.\n\n\nIf we are not the file owner we will get a Permission denied error. Only root can change this for all files. This is why we have to use sudo when editing permission of files that are not ours. There are two commands to do so chown for users and groups and chgrp for groups only.\nTo change a file ownership from anybody to user takkat and - optionally - the group takkat we may issue this command:\nsudo chown takkat[:takkat] testfile\n\nTo only change a file's group to takkat we issue\nsudo chgrp takkat testfile\n\nRead the manpages of the commands for more details and options. There also is this  nice more elaborate guide recommended for further reading:\n\n*\n\n*Ubuntu Community Help: File Permissions\nAlso find some related questions here:\n\n*\n\n*Change folder permissions and ownership\n\n*What is \"umask\" and how does it work?\n\n*How can I get octal file permissions from command line?\n\n*How do I use 'chmod' on an NTFS (or FAT32) partition?\n\n*'chmod u+x' versus 'chmod +x'\n\n*How can I become the owner of a file that origins from another pc / user?\n\nA: Each file has rights for three different categories:\n\n\n*\n\n*the owner of the file,\n\n*the group associated with the file, and\n\n*everybody else.\n\n\nRights mean the right to read the file, the right to write to the file, or the right to execute the file in case of a script or program.\nOn the CLI, you may\n\n\n*\n\n*change the owner with chown, e.g. chown guillermooo\n\n*change the group with chgrp, e.g. chgrp root\n\n*change the rights with chmod, e.g. chmod u+w filename.ext (Adds writing permission for the owner of the file filename.ext)\n\n\nIf you'd like to know more about each of these tools, open a terminal and type man [tool], e.g. man chmod.\n", "Q: How do I create an Ubuntu live USB using a Mac? I'd like to create an Ubuntu live USB stick on a Mac to use to install Ubuntu on another machine. How do I accomplish this?\n\nA: Taken from here:\n\nWe would encourage Mac users to download Ubuntu Desktop Edition by\n  burning a CD. But if you prefer to use a USB stick, please follow the\n  instructions below.\nNote: this procedure requires that you create an .img file from the .iso file you download. It will also change the filesystem that is\n  on the USB stick to make it bootable, so backup all data before\n  continuing.\nTip: Drag and drop a file from Finder to Terminal to 'paste' the full path without risking typing errors.\n  \n  \n*\n  \n*Download Ubuntu Desktop\n  \n*Open the Terminal (in /Applications/Utilities/ or query Terminal in Spotlight)\n  \n*Convert the .iso file to .img using the convert option of hdiutil. Example:\nhdiutil convert -format UDRW ~/path/to/target.iso -o ~/path/to/ubuntu.img\n\nNote: OS X tends to put the .dmg ending on the output file\n  automatically.\n  \n*Run diskutil list to get the current list of devices\n  \n*Insert your flash media\n  \n*Run diskutil list again and determine the device node assigned to your flash media\n  (e.g. /dev/disk2)\n  \n*Run \ndiskutil unmountDisk /dev/diskN\n\n(replace N with the disk number from the last command; in the previous example, N would be 2)\n  \n*Execute the following command while replacing /path/to/downloaded.img with the path where the image file is\n  located; for example, ./ubuntu.img or ./ubuntu.dmg).\nsudo dd if=/path/to/downloaded.img of=/dev/rdiskN bs=1m\n\n  \n  \n*\n  \n*Using /dev/rdisk instead of /dev/disk may be faster.\n  \n*If you see the error dd: Invalid number '1m', you are using GNU dd. Use the same command but replace bs=1m with bs=1M.\n  \n*If you see the error dd:/devdiskN: Resource busy, make sure the disk is not in use. Start the Disk Utility.app and unmount (don't\n  eject) the drive.\n  \n  \n*Run diskutil eject /dev/diskN and remove your flash media when the command completes\n  \n*Restart your Mac and press Alt while the Mac is restarting to choose the USB-Stick\n  \n\n\nA: You could try following the instructions on ubuntu.com.\nHow to create a bootable USB stick on OS X\nUseful Links\nAdditionally, you could try looking at some of these links for help:\n\n\n*\n\n*How to install Ubuntu on MacBook using USB Stick (help.ubuntu.com)\n\n*How To Create A Portable Ubuntu Installation USB On The Mac (makeuseof.com)\n\nA: You can do it really easily with unetbootin which is available for Mac OS - the upside being it doesn't need more than a few clicks on a simple GUI.\n(note this is only for newer Intel Mac's, and won't work with older PowerPC machines unfortunately.)\n\nA: Follow these steps:\n\n*\n\n*Download the latest Ubuntu ISO from here and UNetbootin from here.\n\n\n*Insert your USB drive.\n\n\n*Make UNetbootin executable from file properties.\n\n\n*Run it.\n\n\n*Now click in Diskimage. Give the path of the downloaded Ubuntu ISO.\n\n\n*Then select your pen Drive from the list.\n\n\n*Then press OK.\n\n\n*Wait until finish.\nAfter that you are able to boot or install Ubuntu from that pen-drive.\n\nA: You can use the Linux USB Creator.  The Linux USB Creator for Mac has been released. This is the easiest way to create a live linux USB on a mac.\nIf you use OSX Lion, you can Download this file, and if you use OSX Snow Leopard, you can Download this file\nFor more information on the Linux USB creator, just visit the Website\nThe other option is to use UNetbootin.\nIf your Mac is a G4 or G5 take a look at this.\n", "Q: Ubuntu and Interactive Media Installations I'd like to create an interactive media experience powered by Ubuntu, incorporating projected video, music, and assorted strange input devices. Has anyone used Ubuntu to orchestrate something like this? Can you recommend any specific software/hardware?\n\nA: Here are instructions for getting Ubuntu to detect a Wii remote, which could easily be hacked into an artistic prop or some inconspicuous object.\nYou could use Motion to detect the movement of people walking through your installation.\nI haven't used it personally, but here is an interesting DIY project for an automated NERF turret, which detects a moving target, tracks it, shoots and plays sounds.\n\nA: Are you talking about setting a machine as a Media Center / DVR (Digital Video Recorder, aka PVR)?\nHere are three interesting solutions for this:\n\n\n*\n\n*Mythbuntu:\nMythbuntu is an Ubuntu derivative containing MythTV which is an open source DVR. It is very complete and has a growing community.\nYou can watch/record/manage your TV shows, movies, music, etc... It has a very full-featured media library.\nOfficial website: www.mythbuntu.org\n\n*Moovida (aka Elisa)\nMoovida is a media center application that allows you to easily create your digital library and watch any of your media (DivX, h264, avi, asf, wmv, mkv, flv, mov, ogg, and almost any audio format...) on your TV.\nIt has a Youtube Feature, covert art for your music, Last.fm support. You can play your music by genre, rating and even acoustic similarity. Moovida 2.0 is available in over 20 languages.\nOfficial website: www.moovida.com\n\n*Enna\nEnna is a Media Center application and is based on the powerful Enlightenment Foundations Libraries (EFL) as for its graphical user interface and GeeXboX libraries as for multimedia playback and information retrieval.\nIts main features are Music/Video playing, Bookstore (GoComics and OneManga), Photo gallery, Weather, Media database...\nOfficial website: enna.geexbox.org\n", "Q: How can I completely remove Ruby + Rails + Gems? I have messed up my Ruby dev environment on Ubuntu 10.04.\nWhat is the best possible way to remove these packages from my system?\n\n\n*\n\n*Ruby\n\n*All Gems\n\n*RubyGems\n\n\nTo start fresh, I would like to re-install Ruby using RVM.\n\nA: If you are using RVM why bother even uninstalling the system ruby?\nI install both 1.8.7 and 1.9.2-rc via RVM.\nAfter you have installed RVM you can set the RVM 1.8.7 to be your default ruby installation. Just don't install RVM as root.\nFor those wondering, https://rvm.io/ has the RVM install instructions.\nMake sure you read the instructions on what packages you need to install for Ubuntu before installing 1.8.7 via RVM. If you don't install them you may have issues with some gems.\n\nA: Using synaptic, you can remove the Ruby packages (select \"completely remove\" option).\nI guess this is the equivalent of the commandline: sudo apt-get purge\nNow for the gems: they are not considered as packages. You will need to delete them manually (unless you want to use Ruby to do it, but since you say it's broken...)\nBy default, the Ruby gems are installed in your home folder, under the .gem folder.\nIf you really want to get things clean, just delete ~/.gem, and it should be enough.\nWhen you reinstall Ruby and everything, the folder will get created again, and you will be good to go.\n\nA: If you're using Ubuntu Packages run sudo apt-get purge <packages>\nSo that should be something like:\nsudo apt-get purge ruby rubygems\nFrom the apt-get man page:\n\n  purge\n      purge is identical to remove except that packages are removed and purged (any configuration files are deleted too).\n\n\n\nA: If you have installed Ruby using RVM then the following command will completely remove RVM installed directory:\n rvm implode\n\nRunning this command will ask for your confirmation to delete the .rvm directory.\nAfter it completes deleting the .rvm directory, you get the following message which is worth notable:\n\nNote you may need to manually remove /etc/rvmrc and ~/.rvmrc if they\n  exist still.\nPlease check all .bashrc .bash_profile .profile and .zshrc for RVM\n  source lines and delete or comment out if this was a Per-User\n  installation.\n\nRemove Ruby Gems\ngem uninstall rvm\n\n", "Q: Is there a way to reset all packages/sources and start from scratch? I have been playing with package management by adding sources from older Ubuntu releases in order to get older versions of some software (e.g. PHP). Unfortunately at some point I must have overdid it as now every attempt to use apt-get or synaptic ends in an error message being displayed saying that there is no candidate available to install.\nI would like to start fresh - remove all the installed packages and added sources. Is there a quick way to do this, or do I need to reinstall the OS?\n\nA: You can do an installation of Ubuntu over top of an existing installation. You'll lose all of your (non-local [1]) system files and applications, but it will preserve everything in /home.\nSelect the advanced partitioning option from the menu of either the desktop CD installer or the alternate CD installer. Set the mountpoint of your existing root partition to / and make sure the format box is not checked. Repeat these steps for your home partition, if you have one.\n1: Where local system directories would be /usr/src, /usr/local, and /var/local.\n\nA: You could always remove all packages (making a few exceptions for apt-get, etc.)\nThen run:\nsudo apt-get install ubuntu-desktop\n\nThis installs the desktop metapackage which has pretty much every other package as a dependency.\n\nA: Remove all but the current release of Ubuntu you're running from /etc/apt/sources.list. Then sudo apt-get update; sudo apt-get dist-upgrade. Let me know if you still have trouble. \nYou may have to reinstall. \n", "Q: Will Haskell Platform be available in 10.10? \n\nI've been waiting for a couple years to be able to do an\napt-get install haskell-platform\n\non Ubuntu. Will a haskell platform-package be available on Ubuntu 10.10?\n\nA: Yes, it's already packaged and released in maverick (the development branch of Ubuntu): \n$ rmadison haskell-platform\nhaskell-platform | 2010.1.0.0.1 | maverick/universe | source, all\n\n\nA: Yes\nhttps://launchpad.net/ubuntu/+source/haskell-platform\n", "Q: Sound comes out of my speakers even when headphones are plugged in I was playing music with my headphones plugged in. The music was coming out of the headphones, but I also noticed that my speakers were playing the same music.\nWhy is this, and how can I fix it?\n\nA: This is probably an alsa issue. I had the same problem, but it got reported as a bug and fixed. \nlink to bug report\n\nA: I had the same issue. It appears that the new kernel did not correctly detect the sound card model that you have. You will have to edit the /etc/modprobe.d/alsa-base.conf file and set the model manually with\noptions snd-hda-intel model=<model>\n\nUnfortunately, finding the correct sound card model can take a little guess work. I took me several tries to find the sound card model that would detect the headphones correctly.\nThis link gives a list of sound card model:\nhttp://ubuntuforums.org/showthread.php?t=1043568\nMore information can be found on the Ubuntu Wiki.\n", "Q: How can I best retest a bug in a newer or development release? I have reported a bug that occurs in Karmic on launchpad, and I have been asked to re-test it on lucid or maverick. How can I do this best? \n\nA: Three routes:\n\n\n*\n\n*Install Ubuntu in a VM. \nPros: Your installation is persistent, and you can switch back and forth between the VM and your normal desktop with ease.\nCons: It'll be slow. \n\n*Use a LiveCD. \nPros: Most straightforward, same method as when you first installed Ubuntu. \nCons: No persistence of session, your environment is lost when you restart. \n\n*Install on a separate machine. CD read times are sloooow. \nPros: Persistence, speed. \nCons: Expensive if you don't have the hardware. \nPersonally, I'd go the VM route. You'll need to do with a LiveCD or physical install if your bug involves the hardware.\n\nA: This depends on what bug you're trying to re-test.  For almost all bugs, testing in a VM is great.  As mentioned on another answer, Testdrive is good for that.\nFor hardware related bugs you'll need to run on the real hardware, which means that a LiveCD is a more appropriate method.\n\nA: I depends on what kind of bug it was (estethic, a program crash, etc) but the simplest way would be to download Lucid's live cd, boot it and see if you can reproduce the bug. \nIf it's something that requires a real installation and it's not enough booting a live cd, then install Lucid on a virtual machine using VirtualBox, and you can test almost anything in there without affecting your current environment.\n\nA: For testing Maverick, testdrive is easiest. It'll automatically download the latest Maverick daily and run it in a Virtual Machine.\nsudo apt-get install testdrive virtualbox-ose\ntestdrive\n\n\nA: Without upgrading? You may need to setup a Virtual instance of Lucid or Maverick or install that specific version under a new partition on your machine. I find that VirtualBox works well (and is free) for Ubuntu.\n", "Q: GUI for iptables? I would like to secure my server and it seems that IPtables is one of the first steps. Unfortunately editing the rules in a terminal is a bit complicated and dangerous (those who ever did an iptables -F will know what I mean ;) ). Could you recommend any good graphical interfaces for managing my IPtables rules?\n\nA: For most purposes, ufw (Uncomplicated FireWall) is an excellent way to build simple iptables firewalls.  The rules produced are decent, though there may be features of iptables that you need that ufw doesn't cover.\nsudo apt-get install ufw\n\nIt's a command line tool, but there is also gufw if you want a GUI version.  \n\nA: Firestarter has always worked well in my opinion. It supports a robust GUI and supports all options of iptables. \n\nsudo apt-get install firestarter\n\n\nA: Iptables-Editor-Gui is a gui for iptables (requires ruby and ruby-gtk2)\nSource: Linuxhacks.org\nDisclosure: I am the owner of Linuxhacks.org\n\nA: Try Firewall Builder.\nsudo apt-get install fwbuilder\n\n\nA: I've never taken time to understand iptables, but I believe gufw does the job. Even I was able to set up a firewall within a couple of minutes.\n\nA: Firestarter's still in Raspbian Stretch at least.  If you look at https://netfilter.org/ which is the effective homepage of iptables it's copyright 2014, the task hasn't changed.  Iptables probably isn't changing.  There is such a thing as maturity in software.\nThere are 233 repositories on Github mentioning Firestarter https://github.com/search?q=firestarter.  What's in Raspbian Stretch is Firestarter 1.0.3 copyright 2005 by Thomas Junnonen.  There are undoubtedly forks of the original Firestarter, I'm happy using the original.\nI'd be wary of oversimplified software that may leave out useful features.  I've been studying iptables for a day or so, I just wanted a \"second opinion\".  I'll take what Firestarter comes up with and use it as a starting point.  I'm impressed that it recognized my internet connection EasyTether and seems willing to build NAT stuff for wifi.  I have an old DSL router I'll probably use for output, I just wasn't sure how to bridge from EasyTether to the router.  Iptables can do it, if it's at all like OpenBSD's pf.  Not a typical application, glad Firestarter wants to solve the problem.  It's Gnome but nobody's perfect.  Works fine in LXDE with some Gnome libs installed.\nFirestarter homepage, found in help -> about http://www.fs-security.com/   Yeah, OK, it's maybe a little flaky.  I can't get to his official download page.  More importantly I can't see the iptables code it generates.  It doesn't copy, it doesn't run, it considers the gateway I'm actively using to be offline.\n\nA: I’m using Elastic Firewall …worked like a breeze so far! \nPlus it works on multiple machines.\nYou can go with a free account with them or try one of the paid plans for enhanced power. either way, the thing does a pretty good job at very reasonable rates.\nUnfortunately editing the rules in a terminal is a bit complicated and dangerous (those who ever did an iptables -F will know what I mean ;) )\nI know what you mean, appending rules through the command line can be time consuming and prone to so many errors, so having a firewall manager to automate Linux iptables policies can save you a lot of time and nerves.\n", "Q: Is there a identd-like package in Ubuntu that supports IPv6? Of those identd daemons available in Ubuntu 10.04, can any of them be made to work with IPv6?\nIf so, a nudge in the right direction regarding how to configure the IPv6 support would be nice.\n\nA: oidentd supports ipv6, but said support doesn't seem to be documented very well (or, y'know, at all...).\nAfter installing it, you'll need to edit /etc/default/oidentd and change this:\nOIDENT_OPTIONS=\"-mf\"\n\nto this:\nOIDENT_OPTIONS=\"-mf -a ::\"\n\nand restart it, then it should listen on all your interfaces (both IPv4 and IPv6).\n", "Q: How do I get and install more themes, icons, and pointers? I've downloaded some nice themes, icon packages, and pointers from sites like gnome-look. Now what do I do?  Where else can I get these kinds of things?\n\nA: Installing cursors/icons/themes in 11.10 and above:\nWhen you found a nice icon or cursor packages you download it, right click on it and choose 'extract here'. Then you open Nautilus with root previleges gksu nautilus and copy/move the extracted folder to the folder /usr/share/icons/.\nFor theme packages you copy/move the extracted folder to /usr/share/themes.\nThen you go to the Software Center and install the gnome-tweak-tool. Afterwards open the Dash with the Super(Windows)-Key and type tweak and choose the 'advances preferences' (or so, I'm not on an English system). Under 'theme' you should be able to change your cursor/icons/theme to whatever you like/installed.\n\nA: In Ubuntu 11.04 and earlier System > Preferences > Appearance\nThen click \"Get more themes online\" which points to: http://art.gnome.org/themes\nUbuntu 11.10 has a simplified Appearances preference that dosen't include a button for getting more themes.\n\nA: Installing new themes in Ubuntu 11.10 and 12.04 LTS\nUbuntu 11.10 and later versions switched to GNOME 3, and in the process lost the ability to add new themes easily through the Appearances window. However, new themes can be installed in other ways.\n11.04 and earlier uses GTK+2 themes; for Ubuntu 11.10 and up, you'll want GTK+3 themes. These can be found easily at a site like gnome-look.org.\nOnce you have your themes, extract them to the appropriate folders.\n\n\n*\n\n*GTK+3 themes go in ~/.themes (or /usr/share/themes to be available for all users)\n\n*Icon themes go in ~/.icons (or /usr/share/icons to be available for all users)\n\n\nTo install and use the themes you download, you'll need to either:\n\n\n*\n\n*install the GNOME Tweak Tool. You may also want to install the User Themes Extension (gnome-shell-extensions-user-theme); see the source below for more information.\n\n*install MyUnity\nUse these instructions to change to your newly installed theme.\nSource: http://maketecheasier.com/install-custom-gnome-shell-themes/2011/09/27\n\nA: Installing new themes in Ubuntu 10.10 and below\nTo install the themes open the Theme Manager which can be accessed from System > Preferences > Appearances then just drag the theme/icons etc on to the window.\nOnce installed you can either directly use the theme or modify it to use individual components like icons, borders, etc in the Theme Manager.\n", "Q: How do I avoid the \"S to Skip\" message on boot? After upgrading my laptop from karmic to lucid, my fat32 partition won't mount automatically. I get the message:\nThe disk drive for /osshare is not ready yet or not present\nContinue to wait; or Press S to skip mounting or M for manual recovery\n\nFunny thing is, if I skip, then /osshare/ is mounted once I log in. \nI've a similar setup on my desktop, and it works fine. Fstab on desktop:\nUUID=4663-6853  /osshare        vfat    utf8,umask=007,gid=46 0       1\n\n/etc/fstab on laptop:\nUUID=1234-5678 /osshare vfat utf8,auto,rw,user 0 0 \n\n\nA: You should add the option nobootwait to your /etc/fstab. So that it looks like:\nUUID=1234-5678 /osshare vfat utf8,auto,rw,user,nobootwait 0 0 \n\nFrom fstab(5):\n\nThe  mountall(8) program that mounts filesystem during boot also recognises additional options that the  ordinary  mount(8)  tool  does  not.\n         These  are:  bootwait  which  can  be applied to remote filesystems\n         mounted outside of /usr or /var, without which mountall(8)  would  not\n         hold up the boot for these; nobootwait which can be applied to non-remote filesystems to explicitly instruct mountall(8) not  to  hold  up\n         the boot for them;\n\n\nA: It sounds like you might need to edit your fstab tables as an extra drive is messing with your boot-up, give the following a try:\n\n\n*\n\n*Alt+F2\n\n*Type gksudo nautilus and hit the run button\n\n*Navigate to /etc/fstab\n\n*Open file and edit out the extra drive that is launching\n\n*Save the file when done and close\n\n*Restart machine\n\n\nThis should stop the extra drive from interrupting your boot-up process.\n\nA: Another option for /etc/fstab mounts appears to be the \"bg\" option, which not only backgrounds the nfs mount, but also attempts retries at a regular interval after boot finishes.  So when the nfs server comes back online, your mounts will eventually come back online.\n\nA: I believe you need to change the options from auto to noauto\n", "Q: How do I get involved with testing and QA with Ubuntu? I'd like to get involved with Ubuntu QA by creating automated tests. Is there an ongoing effort to create these tests? Where can I learn more?\n\nA: There are a couple ways to get involved in writing automated tests. The quality team is involved in writing autopkg and autopilot tests for ubuntu packages.\nAutopkg\nAutopkg tests are run at build time automatically by the buildbots for the package. The goal of these tests is to provide system and integration testing to guarantee basic functionality. You can see the live output of the current autopkg tests here. If your interested in writing these tests, see:\n\n\n*\n\n*How do I contribute an autopkg test to ubuntu?\nAutopilot\nThese tests are written in python using the autopilot framework. The goal of these tests is to provide higher level application and functional testing. The tests are written in python and can be user executed or scripted via a test runner such as UTAH or jenkins to run and publish results automatically. For more information on autopilot, check out the project on launchpad as well as the documentation for the project. If your interested in writing these tests, see:\n\n\n*\n\n*How do I contribute an autopilot test?\nGetting Help\nFor more information or to get help, email the ubuntu-quality list or visit #ubuntu-quality on freenode.\n\nA: A project does exist at https://wiki.ubuntu.com/Testing/Automation for this - I'm not sure how much it currently covers, but there is also automated upgrade testing done to test out upgrading various package combinations.\n\nA: You can get involved with testing by joining the QA team, their mailing list - ubuntu-quality, and their launchpad page.\nThe last link will take you to the autopilot launchpad site which is thier automatated testing package.\nSee my answer here for additional details on how Ubuntu automated testing works.\n\nA: Usually automated testing is done on a per project basis and the quality of those tests are highly dependant on the project's organisation and quality control. Tests can be tied into the building of debs and such but as far as I know I've never heard of any external testing framework outside of any particular project.\n\nA: The QA team does extensive automated testing - it's part of the requirements for hardware to get Ubuntu certified.\nThe project they use is Checkbox.  Don't be fooled by the quite cut-down version shipped in the checkbox-gtk package - the full suite contains a huge range of tests.\nThe Ubuntu QA mailing list is where you want to go for checkbox questions, or to discuss merge requests. This link discusses about the complete set of tools used by the QA team for automation.\n\nA: There is http://qa.ubuntu.com/ - which links to e.g. http://mago.ubuntu.com/\nWhile I cannot point at something specific, this appears to be a good starting point.\n", "Q: What are the multi-touch netbooks/tablets that work with Ubuntu? I will be going to University soon and am looking for a tablet/netbook on which I can use a stylus to write notes (Chinese characters mostly).  I have only found 2 netbooks (with swivel screens and full keyboards) that might work for me.  One is the ASUS Eee PC T101MT, and the other is a Gigabyte Touchnote. \nDoes anyone know of tablets (keyboardless) that Ubuntu fully works on?\n\nA: Please see this to get help with MultiTouch in Ubuntu: https://wiki.ubuntu.com/Multitouch#Community%20Help\nThe same page has a section dedicated to devices currently supported or being tested by the community. Your two choices don't seem listed there but I'd encourage you to file bugs:\nubuntu-bug utouch\nIf you can do so from any of the devices, within a 10.10 live CD, that would be best.\n\nA: Try Touchbook.\n\nA: I currently use a Lenovo X61 Tablet pc with Xournal as my handwritten notes application.  There was some custom configuration I had to do, but for the most part it worked fine.\n\nA: Well Ubuntu is working on multitouch and it should be in either the next release or the release after. Synaptics is making it too but I dont know if thats ready yet. \nThe touch screens will work it will just move the mouse to the place you touch it just wont do anything special.\n", "Q: Where can I find a list of computers guaranteed to work with Ubuntu? Before I buy my next laptop, I'd like to make sure that it will work perfectly with Ubuntu. Is there a list of completely supported computers anywhere?\n\nA: It's too general a question to make one specific recommendation so your best solution is to look at the Ubuntu Certified Hardware page.\nYou can review which laptop best suits your requirements by the manufacturer of your choice.\nIt lists all the laptops certified for Ubuntu by release as well\n\nA: There is a wiki page of supported hardware, but I don't think it's fully exhaustive. The motherboard I'm using works fine and doesn't appear anywhere on that list.\n\nA: There is an ongoing QA effort for Laptops and Desktops in the Ubuntu Community - you can find that information here:\nOld Ubuntu Laptop Reports and for everything 11.04 and onwards, Laptop Testing Site\nYou can find the reports for Lucid tested Laptops tests here: 10.04 Lucid Laptop Tests. The best course of action is to find a handful of laptops you're interested in then check the Reports on each.\nIf you feel compelled to help you can find more information at the Laptop Testing page.\nFinally there is a detailed list of compatible systems on the Ubuntu Certification page.\n\nA: This page on ubuntu.com has the breakdown of certified machines by manufacturer and model type.\n\nA: If you get a computer with Ubuntu preinstalled, it's guaranteed to work with Ubuntu. Dell and System76 are the two most recommended companies from which to get Ubuntu computers.\n\nA: Another way is get some flashdrive with ubuntu and test at the store\n\nA: Laptop compatibility information here : http://www.linux-laptop.net/\nSome details about DELL compatibility with Ubuntu here: http://www.linux-laptop.net/dell.html\nBut alas, no mention of the Inspiron 13z.\n\nA: Another retailer for preinstalled Ubuntu systems is ZaReason.\n\nA: There is an open hardware validation programme for laptops, desktops, and netbooks called Ubuntu Friendly. It is still under works, and will probably will launched for 11.10.\nThe launchpad project is located here\nThe idea is to allow anyone to test any hardware, and report the results back. Multiple positive results for the same hardware will result in a Ubuntu Friendly certification.\n", "Q: Is there a Paint.NET alternative? Does anyone know of a simple Image Editor, with functionality comparable to Paint.NET,  for Ubuntu?  I've always found GIMP to be overkill and too complicated for what I want to do.\n\nA: Are you looking for something like TuxPaint?\n\n\nA: Yes, try Pinta\n\nPinta is a drawing/editing program modeled after Paint.NET. It's goal is to provide a simplified alternative to GIMP for casual users. It is currently early in development.\n\n\n\n*\n\n*Homepage\n\n*PPA\n\n\nA: mypaint \n is also great and simple. It is in the software center.\n\nA: You might also want to check out Krita or for plain photo editing digikam with its plugins.\nBoth are packaged in Ubuntu. Also for kids related drawing tuxpaint is great.\n\nA: There's Pinta as David points out, which clones the user interface and took the same open sourced code to implement image adjustements and effects. There are other lightweight alternatives that might fit the bill if you don't require features such as layers or filters: Gnome Paint and KolourPaint for KDE. \nThe Gnome Paint site hosts a DEB file, so you can download that and double click to install. To install KolourPaint:\nsudo apt-get install kolourpaint4\n\nOr search for it on the Software Center. Note that if you don't currently have any other KDE app, then installing KolourPaint will also install other KDE specific libraries that will take a considerable amout of disk space. That being said, I found KolourPaint more feature complete than Gnome Paint.\n\nA: Krita is a good alternative for paint.net, for it resembles paint.net most in term of look & feel (and functions). \nI worked with paint.net for years (on Win7), now changed to Ubuntu 18.04 and do work with Krita as I have been used to with paint.net\nDo NOT use Pinta. \nWhile the original recommendation for this tool might have been true at the time of writing, this does no longer apply. Development for Pinta stopped in 2015, see: [Pinta] (https://pinta-project.com/pintaproject/pinta/releases/1-6) \nPinta is unstable at least for Ubuntu 18.04.\n\nA: uh. now there are many, here is my list:\n\n*\n\n*pinta\n\n*inkscape\n\n*paintsupreme3d\n\n*kolourpaint\n\n*krita\n\n*pixelorama\n\n*paintPP\n\n*rx\n\n*vectr\n\nand if you want paint for 3d objects here is another list:\n\n*\n\n*goxel\n\n*blender\n\n*openscad\n\n*titania x3d\n\nPS: you can also use libre/open office draw to create graphics ;)\n", "Q: Is there Split Pane support in Gedit? I know some other text editors like Notepad++ enable split pane to edit to files side by side.  Is there any way I can add this functionality to Gedit?\n\nA: In gedit, choose Documents > New Tab group or Ctrl+Alt + N  your gedit will split vertically. And you can drag tabs.\n\nA: Not yet, but it's in development see here (Gedit/Multiviews - GNOME Live!), someone's working on it (among other features) as a GSOC project as far as I know.\n\nA: \nUpdate: Gedit has now added this feature. I'm keeping my answer around for those using older versions of the application.\n\nGedit does not come with this feature.\nBut there is a plugin you can get:\nSplitview plugin (Archived page from Gedit/Plugins - GNOME Live)\nSplitview plugin source code (Archived page)\n\nA: The new developments don't seem to go anywhere, but at least in Ubuntu 16.04 there is a workaround using also tabs as requested by the OP and with a read-only side:\n\n\n*\n\n*Open the file in a first window.\n\n*Go to Documents->New Tab Group (or press Ctrl+Alt+N) as suggested by @thangdc94. This will vertically split the window opening a new document as a tab on the right side.\n\n*Open a second window and open again the same file: gedit --new-window file. It will tell you that the file is opened somewhere else and ask you if you want to edit the file anyway. My suggestion is to use \"Don't Edit\", otherwise you'll be overwriting your own changes from one window to the other. It's better to use one for writing an the other for reading/copying.\n\n*The tricky points: Open a new tab in the second window, so now you can see tabs instead of only the document.\n\n*The tricky points: Drag from the second window, the tab of your document and drop it as a tab in the right side of the original window.\n\n*Now you can close the second window and remove the undesired tabs of the right side of the original window.\n\n", "Q: Is there a Gnome applet for IMAP mail accounts? In the spirit of this question...\nIs there an indicator applet that tells me when I've received an email through any IMAP service? If so, where can I get it?\n\nA: It is not a real gnome applet per se,  but you can use gnubiff, it sits near the clock, in the notification/indicator applet:\n\ngnubiff checks for mail within a file,\n  a qmail or MH style dir,  or an IMAP4\n  or POP3 or APOP server.  It can\n  display headers (number,  sender,\n  subject, and date) when new mail has\n  arrived.  While gnubiff is\n  implemented as a GNOME panel applet,\n  it also runs as an  independent icon\n  on the desktop in other environments.\n\n\nA: Use CloudSN (Cloud Services Notification). It supports gmail, google reader, pop3, imap, twitter, identi.ca\nhttp://chuchiperriman.github.com/cloud-services-notifications/ (PPA available)\nThe best part is that it supports multiple accounts and notify-osd.\n\n", "Q: Is there a simple guide for how to set up a demo cloud? I would like to be able to demo a UEC cloud at a presentation. Is there a simple guide regarding the hardware I need, and how I need to configure the UEC in order to create a nice presentation?\n\nA: These are the minimum requirements (for a one-machine setup) for setting up an Ubuntu Enterprise Cloud:\n\n\n*\n\n*Machine: at least 1 (though 2 or 3 is highly recommended, to separate controllers and nodes)\n\n*CPU: +2Ghz (dual core recommended)\n\n*Memory: +2Gb ram\n\n*Disk Space: 100Gb\n\n\nNote that with those minimum specs, this will still be SLOW.\nYou can find a quick tutorial located at: http://www.ubuntu.com/cloud/private/deploy\nAs well, there is a complete community guide at https://help.ubuntu.com/community/UEC\n", "Q: Where can I find F# packages? I'm currently install F# manually by downloading the binary distribution from Microsoft, downloading the Mono key, running the Mono installer, then fiddling with my path. Is there a PPA with F# packages that can make my life easier?\n\nA: The F# license appears to be non-free as it only allows non-commercial use, so it wouldn't be legal to distribute this in a PPA. At best, there could be an fsharp-installer package created, which would automate those steps of downloading & installing it.\n\nA: Ubuntu (.deb) packages for fsharp can be found at http://fsxplat.codeplex.com/\n\nA: I believe Microsoft said they might open source F# in the future.\n\n", "Q: How to burn a dual layer dvd iso from the command line How do you burn a DVD-DL iso from the command line?\n\nA: growisofs -speed=2 -dvd-compat -Z /dev/dvdrw=dvd_image.iso\n\nReplace /dev/dvdrw with your dvd writer path and dvd_image.iso with the iso filename\nIf you do not have growisofs installed you will need to install the dvd+rw-tools package with the following command\nsudo apt-get install dvd+rw-tools\n\n", "Q: Firmware update for iPod Touch (iPhone)? I need to update firmware of my iPod Touch (iPhone) in Ubuntu and as I have jailbroken iPod Touch I need iTunes to install apps, but unfortunately haven't found any ways to do that in Ubuntu yet. I know that it is possible to use VirtualBox or Wine, but still in the most of the times iTunes doesn't want to work on Wine and for VirtualBox I need to install again that Windows from which I switched into Ubuntu just a few months ago and don't want to go back to it.\nWhat do Linux users who have iPod Touch(iPhone) do in this case?\nAny suggestions to solve the problem will be pleased.\nAnd finally,how long will it be before Apple develops iTunes for Linux OS? \n\nA: While some older versions of iTunes can currently be made to work with Wine (or Crossover), they cannot be used to update or sync newer iPods\nThe reason is that Wine lacks a handler for Windows USB device drivers, and the iPod acts as a custom USB device.  This is the same reason that software that requires a special key dongle also doesn't (yet) work in Wine.  There are some preliminary patches available for this, and you can read more history on the Wine wiki, however don't expect anything to work.\nThe only iPods that currently work in Wine are really old iPods that act as simple USB mass storage devices.  And even then you still need to find an older, working iTunes.\nBecause of this problem in Wine, to do the firmware upgrade you'll need to either setup a virtual machine with Virtualbox or VMware or, perhaps more simply, borrow someone else's computer.\n\nA: I don't know if this works with your iPod touch, but it works for my older iPods:\nhttp://code.google.com/p/ipod-update/\n\nA: Looking at the Crossover page for iTunes, a couple of versions have been reported to work somewhat. Crossover costs money, but it may be worth it for you.\n\nA: Firmware-Upgrade didn't work for me: Ubuntu 8.04 LTS with vmplayer and an old XP with iTunes.\nNo chance. the iphone was out of order for the rest of the day until i pluged it on my windows pc at my job-side. \nFrom this point of view: apple-products are an absolutely No-Go! Why do i need a windows or mac with itunes for having a phone? Where is it stated that on buying that 'thing-a-magic' i need a running iTunes to make it work? Who knows the costs on before?\n\nA: libimobiledevice\nIt's still experimental but you should check libimobiledevice. There is no GUI as of yet, but they're working on getting ipod touch models to work on Linux (including software up and downgrade).\n\nEdit: According to the Ubuntu Wiki this is the default since at least 14.04 and implemented in various projects. Check the news and status on the libimobiledevice project page for details. Currently they claim that they support iOS 9, which was still in beta at the time of writing.\n\nA: I tired to update my iPhone firmware form v2 to v3 using iTunes running in VMware. The process stoped mid stream and the iPhone was rendered useless. I hooked it up to a friend's windows machines and after several update attempts it came back to life.\nUpdates withing the same major versions worked fine in iTunes/VMware though.\n", "Q: How can I change the login screen theme in GDM? How can I change the Login screen theme? Is there a graphical way or no?\n\nA: U can use GDMtweak to change theme and Icon. see the link http://www.webupd8.org/2011/05/change-gdm-theme-background-in-ubuntu.html\n\nA: Use this command in the terminal:\nsudo cp /usr/share/applications/gnome-appearance-properties.desktop /usr/share/gdm/autostart/LoginWindow\n\nLogout, and you will be prompted with the Appearance window. change the theme as you change it for the desktop, and login back, and type this command:\nsudo rm /usr/share/gdm/autostart/LoginWindow/gnome-appearance-properties.desktop\n\nThat's it.\n\nA: This depends on what you want to do with the login screen. You can configure some basic options in the Login Screen Settings app (System/Administration/Login Screen) - whether a user should be automatically logged in, the default session etc.\nHowever to change the login screen more graphically Ubuntu Tweak can be used to change the background, logo etc.\n\n\nA: I'm not aware of a graphical tool to automate the process but is not overly complicated to change the theme of gdm.\nTake a look at Gnome-Look GDM, most of the themes there come with good instructions on how to install them.\n\nA: There is a graphical tool for this. It's called GDM2Setup. You can get it from this PPA: https://launchpad.net/gdm2setup\n\nA: Theme Support for GDM has been terminated since UBUNTU 9.Sorry..!!\n\nA: *\n\n*Copy the image you want to use into the /usr/share/gnome-shell/theme folder.\n\n*Run \nsudo -H gedit /usr/share/gnome-shell/theme/gnome-shell.css\n\n\n*Search for the following section\n#lockDialogGroup { \n\nbackground: #2e3436 url(noise-texture.png); \n\nbackground-repeat: no-repeat;\n\n\n*Change the name of the image to your image and set background to repeat or no-repeat.\n\n*Save the file.\n\n*Logout and your new background is there.\n\n\nThis works for Ubuntu GNOME, for other flavours it might not work.\n", "Q: How can I install just security updates from the command line? sudo apt-get upgrade installs all updates, not just security updates. I know that I can use Update Manager to select only important security updates, but is there a way to do this from the command line?\n\nA: On Debians I use this command to do only security updates:\napt-get install -y --only-upgrade $( apt-get --just-print upgrade | awk 'tolower($4) ~ /.*security.*/ || tolower($5) ~ /.*security.*/ {print $2}' | sort | uniq )\n\n\nA: replace /etc/apt/preferences with the following:\nPackage: *\nPin: release a=lucid-security\nPin-Priority: 500\n\nPackage: *\nPin: release o=Ubuntu\nPin-Priority: 50\n\nnow a simple apt-get upgrade will upgrade all security updates only.\nWhy (and how) this works: The preferences file will pin all packages from Ubuntu distribution to priority 50, which will make them less desirable than already installed packages. Files originating from security repository are given the default (500) priority so they are considered for installation. This means that only packages that are considered more desirable than currently installed ones are security updates. More information about pinning in the apt_preferences manpage.\nYou can temporarily promote a certain distribution for updates with the --target-release option that works with apt-get and aptitude (at least) which will allow you pin certain releases so that they are eligible for upgrade.\nIf you wish to use this for scripts only and not make it default for the system, you can place the rules in to some other location and use this instead:\napt-get -o Dir::Etc::Preferences=/path/to/preferences_file upgrade\n\nThis will make apt look for the preferences file from a non-default location.\nThe preferences file given as an example doesn't apply to third party repositories, if you wish to pin those too you can use apt-cache policy to easily determine the required keys for pinning.\n\nA: Although its pretty ugly, you could disable all the repositories apart from the security repository and then do:\nsudo apt-get update && sudo apt-get upgrade\n\nI haven't tested it, but in theory it would only find updates in the security repo and apply them...\n\nA: *\n\n*apt-get update: \njust read the entries in repository - acording to existing list. Needed to check what is new.\n\n*apt-get upgrade: all updates for installed packages without kernel modules. No release update. \n\n*apt-get dist-upgrade: all updates for installed packages also with kernel modules. No release update. \n\n*apt-get with parameter -s: test only, no changes performed.\n\n\nA: The package unattended-upgrades provides functionality to install security updates automatically.\nYou could use this, but instead of configuring the automatic part you could call it manually:\nsudo unattended-upgrade -d --dry-run\nsudo unattended-upgrade -d # Idem --debug\n\nIf you want to run it quietly instead:\nsudo unattended-upgrade\n\nNote: When you call unattended-upgrade you leave the \"s\" off the end (on newer versions there is a symlink to avoid this).\nThis assumes that the package is installed by default, which it probably is. If not, just do:\nsudo apt install unattended-upgrades\n\nSee also /usr/share/doc/unattended-upgrades/README.md.\n\nA: Here's a script that achieves this in a few different ways:\n#!/usr/bin/env bash\nset -e\n\n# List upgradable packages\napt-get update\napt list --upgradable 2>/dev/null\n# List security upgrades\ntest \"$(apt-get upgrade -s -y)\" && (apt-get upgrade -s -y)\n# List upgradable apt packages then upgrade\napt-get update && apt-get upgrade -y  -V | grep '=>' | awk '{print$1}' && test \"$(apt-get upgrade -y)\"\n\n\nA: A Few Tips On How To Manage Updates\nThis applies both to Debian and Ubuntu, but more specific instructions for Ubuntu follow.\n\n\n*\n\n*Show security updates only :\napt-get -s dist-upgrade |grep \"^Inst\" |grep -i securi \n\nor\nsudo unattended-upgrade --dry-run -d\n\nor\n/usr/lib/update-notifier/apt-check -p\n\n\n*Show all upgradeable packages\napt-get -s dist-upgrade | grep \"^Inst\"\n\n\n*Install security updates only\napt-get -s dist-upgrade | grep \"^Inst\" | \n    grep -i securi | awk -F \" \" {'print $2'} | \n    xargs apt-get install\n\nNotes: \n\n\n*\n\n*Sometimes Ubuntu shows security updates as if they're coming from $release-updates repository. This is so, I'm told, because Ubuntu developers push security updates to $release-updates repository as well to expedite their availability.\nIf that's the case, you can do the following to show security updates only:\nsudo sh -c 'grep ^deb /etc/apt/sources.list | \n    grep security > /etc/apt/sources.security.only.list'\n\nand\napt-get -s dist-upgrade -o Dir::Etc::SourceList=/etc/apt/sources.security.only.list -o Dir::Etc::SourceParts=/dev/null  | \n    grep \"^Inst\" | awk -F \" \" {'print $2'}\n\n\n*Check what services need to be restarted after package upgrades. Figure out what packages you are going to upgrade beforehand and schedule your restarts/reboots. The problem here is that unless you restart a service it still may be using an older version of a library (most common reason) that's been loaded into memory before you installed new package which fixes a security vulnerability or whatever.\ncheckrestart -v\n\nHowever, keep in mind that checkrestart may list processes that shouldn't necessarily be restarted. For example, PostgreSQL service may be keeping in its memory reference to an already deleted xlog file, which isn't a valid reason to restart the service.\nTherefore, another, more reliable, way to check this using standard utils is the following little bash script that I shamelessly stole from https://locallost.net/?p=233\nIt checks if running processes on a system are still using deleted libraries by virtue of keeping copies of those in active memory.\nps xh -o pid |\nwhile read PROCID; do\n       grep 'so.* (deleted)$' /proc/$PROCID/maps 2> /dev/null\n       if [ $? -eq 0 ]; then\n               CMDLINE=$(sed -e 's/\\x00/ /g' < /proc/$PROCID/cmdline)\n               echo -e \"\\tPID $PROCID $CMDLINE\\n\"\n       fi\ndone\n\n\nA: The following is confirmed in Ubuntu 14.04 LTS.\nUse the unattended-upgrade package.\nLook at the file /etc/apt/apt.conf.d/50unattended-upgrades. There should be a section at the top that is:\n// Automatically upgrade packages from these (origin:archive) pairs\nUnattended-Upgrade::Allowed-Origins {\n    \"${distro_id}:${distro_codename}-security\";\n//  \"${distro_id}:${distro_codename}-updates\";\n//  \"${distro_id}:${distro_codename}-proposed\";\n//  \"${distro_id}:${distro_codename}-backports\";\n};\n\nNote how it has been configured to only allow unattended upgrades for security packages, by default.\nModify the file /etc/apt/apt.conf.d/10periodic similar to:\nAPT::Periodic::Update-Package-Lists \"1\";\nAPT::Periodic::Download-Upgradeable-Packages \"1\";\nAPT::Periodic::AutocleanInterval \"7\";\nAPT::Periodic::Unattended-Upgrade \"1\";\n\nThis will run automatic unattended security upgrades, once per day.\nNow, to run manually: sudo unattended-upgrade.\nTo test as a dry-run, without doing anything: sudo unattended-upgrade --dry-run.\nSource: https://help.ubuntu.com/14.04/serverguide/automatic-updates.html\n\nA: If you wish to install only security updates the following will work. First it lists all upgradeable packages, filter out only the ones coming from a security repo, cut the returned strings at the first field, and then passes them to apt-get install for package update.\nsudo apt list --upgradable | grep security |cut -d\\/ -f1|xargs sudo apt-get install -y\n\n\nA: I can't find an option in either apt-get or aptitude, however someone had the same question on SuperUser. The only response is:\nCheck and adjust /etc/apt/apt.conf.d/50unattended-upgrade. \nDid you replace 'karmic' with the code name of your Ubuntu?\n\nNo reply as to whether that worked however.\n", "Q: Where can I find documentation on the /etc/environment file format? From System-wide environment variables:\n\n  \n*\n  \n*/etc/environment - This file is specifically meant for system-wide environment variable settings. It is not a script file, but rather consists of assignment expressions, one per line. Specifically, this file stores the system-wide locale and path settings. \n  \n\nI'm looking for an ABNF and/or a more detailed description of behaviour, or anything that isn't forum hearsay really.\nIf it's on Google, it's eluding me.\n\nA: You can find good information in the environ man page.\nIt is accessible from a terminal, by typing  man 7 environ in it.\n\nBy convention the strings in environ have the form \"name=value\".\n\nYou can also read it from your browser: http://manpages.ubuntu.com/manpages/lucid/en/man7/environ.7.html#toptoc2\nAnd it gives you some examples of usage and more details.\n\nA: I'm not sure why this isn't made more clear, but /etc/environment isn't parsed by any single bit of code or any particular shell (or necessarily any shell at all) (try grep -r \"/etc/environment\" /etc and you'll see what I mean). pam in particular parses it directly, not putting it through a shell.\nBy convention, and I do mean convention, it's pure key-value pairs, with values optionally quoted. You can't put anything that tries to do e.g. variable expansion or command execution in there and expect it to work.\nI'd be surprised if you can find a strict, formal grammar definition anywhere.\nProbably the closest to an authoritative answer you can come is the pam_env docs: http://www.linux-pam.org/Linux-PAM-html/sag-pam_env.html\n", "Q: What are the advantages and disadvantages of different docks? For example: Avant Window Navigator, Docky, DockBarX and Cairo dock.\n\nA: Personally I use Docky, which replaces the bottom panel containing active applications and such. \n\n\n*\n\n*I like the Mac/Win7-style mixing of shortcuts and active applications.\n\n*I'm in love with the enhancements it can give icons (for example - displaying cover art, track length in place of the Rhythmbox icon).\n\n*It has support for widgets although I haven't found many available for it except the built-in ones.\n\n*The same can be said for themes, although I might not have looked hard enough.\n\n*It's a simple, yet configurable dock that comes with several useful plugins and looks good out of the box.\n\n\nA: I personally use AWN replacing both panels because:\n\n\n*\n\n*It has a tray area, so I can remove the panel (Docky didn't last time that I tried and was a no-go).\n\n*Great performance (even in my netbook)\n\n*Each applet is a different process, if one locks, AWN doesn't\n\n*It's beautiful and highly customizable.\n\n*Has a nice remember the milk applet, and loads of others (where loads > docky but loads < Cairo Dock).\n\n*I can put it on the top or on the left of the screen (my petty favorites places).\n\n*Last versions have Zeitgeist integration (icons display last and most used items)\n\n*It works with python applets (fanboy disclaimer).\n\n\nAnyway, I agree it's a highly subjective post and there is no such thing as a correct answer.\n\nA: I personally use Cairo Dock because:\n\n\n*\n\n*It has a slew of customizable options\n\n*It has good performance\n\n*It works well with Compiz\n\n\nA: Looking for more info on AWN, I found this article that compares AWN, Cairo Dock, and Docky.  It may be of some help.\nAWN vs Cairo Dock vs Docky: Mac Style Linux Docks Reviewed\n\nA: i'm using docky because it comes with pinguy os (ubuntu based) and i like how the icons jump to call your attention at certain specific moments, or how they jump if you click on them, i really don't know whats the best dock...i read that awn is better because lots of people dont want to use mono, and docky it has something related with mono, im trying in this moment awn, and i still prefer docky i hate that awn has some good options that docky doesnt.\n\nA: cairo dock have his own session in lightDM and can work with compiz. it use same compiz profil as gnome-classic session. you can in this session load unity 2d panel and have something like unity but istend launcher and dash, you have cairo-dock.\npretty good, low resourse usage compare to unity 3d\nlook in the link\n\nA: AWN is fantastic, but it seems to be being removed from the main distributions latest versions. Hope it gets supported again.\n", "Q: Where can I find the Brother HL-2170W 64-bit printer driver? I'm looking to install drivers for my \"Brother HL-2170W\" network printer. I can't seem to find the correct driver on the Brother site. Any help would be appreciated. I'm running on Ubuntu 10.04.1 LTS x86_64.\n\nA: This guy at: http://mikebeach.org/2010/06/ubuntu-and-brother-hl-2170w/\nsays there is a problem in 10.04 with a fault in the cups drivers, at least for the HL-2170W.  \nText worked okay but printing graphics took a long time.  This was true for me.  I followed his advice precisely and now my pdf files are printing great.  I have only tested one page, probably should test a few more complex graphics but for now I'm a very happy camper.  So I wanted to share the wealth.\nLots of other people on the ubuntu forums seem to be complaining about slow printing so I suspect that it is not only the HL-2170W printer driver that is bad.  But step 8 in his instruction list will need to be changed, I think for printers other than HL-2170W.\nHope this helps.\n\nA: I've (mostly) solved this problem, by doing something simple. I went into printer properties  and changed the \"Device URI\". I chose \"LPD/LPR Host or Printer\" and used my ip address instead of one of the network printers Ubuntu suggests. \nThis solves my general printing slowness as pages go to the printer immediately. The only exception is PDFs that still take a while to print.\n\nA: I don't have any experience with this printer, but from what I've found it either \"just works\" when you plug it in using USB; if you'd like it to communicate over a network it needs to be configured and there is only software for Windows or Mac. This means you'll need to either use a Windows or Mac computer or VM to configure it, and then be able to use it from Ubuntu.\nFrom UbuntuForums.org:\n\nI have that printer. WHen hooked up with USB, it just works, however, the printer does not have a control panel built in and requires Windows or Mac based software to configure it for use with a wireless network. I used Windows XP in VirtualBox to configure it, the printer configuration in Ubuntu was able to see it on the wireless network and connected just as easily as it did via USB. Its a great printer, just sucks that you have to use windows to configure the network...\n\n(source)\nFrom another thread I found a link to a PPD file that can be used to install your printer, however those posters were using Ubuntu 8.04, although it could be worth trying.\n\nA: Without any specific knowledge of this printer -- does the printer support Postscript?\nIf so you can try a generic ps driver.\n", "Q: Command to list services that start on startup? Is there a command to list services that run on startup? I imagine it would involve parsing /etc/init.d/, and the various /etc/rc.* directories.\n\nA: On 12.04 we could use:\nsudo apt-get install chkconfig\nchkconfig --list\n\nbut it was removed in 12.10.\nSample output:\nacpi-support              0:off  1:off  2:on   3:on   4:on   5:on   6:off\nacpid                     0:off  1:off  2:off  3:off  4:off  5:off  6:off\napparmor                  0:off  1:off  2:off  3:off  4:off  5:off  6:off  S:on\n\n\nA: Besides system services and scripts under:\n\n/etc/init.d/\n/lib/systemd/system/\n/etc/systemd/system/\n\nThere are probably AutoStart Applications too, for example:\nfind / -name \"*autostart*\"\n\nls -1 \"/etc/xdg/autostart\" \"/home/$USER/.config/autostart\" \"/usr/share/gdm/autostart\"  \"/usr/share/gnome/autostart\"\n\n\nA: The quick answer is:  It depends on your init system.\nThe long answer is:  For current versions of Ubuntu, you probably have a mix of Upstart, and SystemV.  Newer versions of Ubuntu after 15.04 \"Vivid Vervet\" (and other Linux distros like RHEL/CentOS 7) are moving to use SystemD.\nUpstart\n\n*\n\n*Upstart Documentation\nTo list all services:\nsudo initctl list\n\nTo list all Upstart services and run initctl show-config on them, this one-liner may be helpful:\nsudo initctl list | awk '{ print $1 }' | xargs -n1 initctl show-config\n\nSystem V\n\n*\n\n*SysV Runlevels Documentation\nTo list all services:\nsudo service --status-all\n\nOR:\n# for init scripts:\nls /etc/init.d/\n\n# for runlevel symlinks:\nls /etc/rc*.d/\n\nSystemD\n\n*\n\n*SystemD for Upstart Users\n\n*FedoraProject SystemD Documentation\n\n*RHEL 7: Managing Services with SystemD\n\n*RedHat: SystemD Overview\nTo list all services:\nsudo systemctl --all list-unit-files --type=service\n\nOR:\nls /lib/systemd/system/*.service /etc/systemd/system/*.service\n\n\nA: For Ubuntu 18.04 use :\nsystemctl list-units --type=service\n\ninstead of initctl.\nSince Ubuntu 16.04, initctl has been replaced by systemd (source, in French).\nIf it can help @sanjay-manohar.\n\nA: The /etc/init.d and /etc/rc.* directories have been superseded by the 'upstart' init tool. Although scripts in these directories will be executed as expected, the new method for running things on init is defined by files in /etc/init/\nYou can list all of the upstart jobs with by querying upstart over dbus:\ndbus-send --print-reply --system --dest=com.ubuntu.Upstart \\\n        /com/ubuntu/Upstart com.ubuntu.Upstart0_6.GetAllJobs\n\nYou may have to change 0_6 to reflect the version of upstart you have. This command works on my lucid install.\n\nA: If you want a nice graphical representation of services and time it takes to boot try:\nsudo apt install bootchart\n\nFor systemd (since 16.04) try systemd-bootchart instead:\nsudo apt install systemd-bootchart\n\n\nA: You can simply use the initctl list shell command to list the contents of /etc/init rather than the suggested dbus-send command.\n\nA: Id use initctl show-config <servicename> to really get the details of when/if your service will start during boot.\nLike so:\n$ initctl show-config myservice\nmyservice\n  start on runlevel [2345]\n  stop on runlevel [!2345]\n\nOr for NFS4 idmap-daemon:\n$ initctl show-config idmapd\nidmapd\n  start on (local-filesystems or mounting TYPE=nfs4)\n  stop on runlevel [06]\n\nchkconfig is only preferable on RedHat based systems imho.\n\nA: Using gawk:\nls -l /etc/rc*.d/* | gawk 'match($0, /rc([0-6S]).d.*\\/(.*)$/, a) {l[a[2]]=l[a[2]]a[1]\",\"}; END{for(v in l){print v,substr(l[v],1,length(l[v])-1)}}'\n\nSample output:\n$ ls -l /etc/rc*.d/* | gawk 'match($0, /rc([0-6S]).d.*\\/(.*)$/, a) {l[a[2]]=l[a[2]]a[1]\",\"}; END{for(v in l){print v,substr(l[v],1,length(l[v])-1)}}' | egrep README\nREADME 0,1,2,3,4,5,6,S\n\n", "Q: Under what license is Ubuntu? Can it be legally modified and distributed? What license does Ubuntu fall into (GPL, MIT, a mix)? Would it be legal to modify it and redistribute my modified version?\n\nA: from http://www.ubuntu.com/project/about-ubuntu/licensing\n\nUbuntu is a collection of thousands of computer programs and\n  documents created by a range of individuals, teams and companies.\nEach of these programs may come under a different licence. This\n  licence policy describes the process that we follow in determining\n  which software will be included by default in the Ubuntu operating\n  system.\nCopyright licensing and trademarks are two different areas of law, and\n  we consider them separately in Ubuntu. The following policy applies\n  only to copyright licences. We evaluate trademarks on a case-by-case\n  basis.\nCategories of software in Ubuntu\nThe thousands of software packages available for Ubuntu are organized\n  into four key groups or components: main, restricted, universe and\n  multiverse. Software is published in one of these components based\n  on whether or not it meets our free software philosophy, and the level\n  of support we can provide for it.\nThis policy only addresses the software that you will find in main and\n  restricted, which contain software that is fully supported by the\n  Ubuntu team and must comply with this policy.\nUbuntu 'main' component licence policy\nAll application software included in the Ubuntu main component:\nMust include source code. The main component has a strict and\n  non-negotiable requirement that application software included in it\n  must come with full source code.\nMust allow modification and distribution of modified copies under the\n  same licence. Just having the source code does not convey the same\n  freedom as having the right to change it. Without the ability to\n  modify software, the Ubuntu community cannot support software, fix\n  bugs, translate it, or improve it.\nUbuntu 'main' and 'restricted' component licence policy\nAll application software in both main and restricted must meet the\n  following requirements: Must allow redistribution. Your right to sell\n  or give away the software alone, or as part of an aggregate software\n  distribution, is important because: You, the user, must be able to\n  pass on any software you have received from Ubuntu in either source\n  code or compiled form.\nWhile Ubuntu will not charge licence fees for this distribution,\n  you might want to charge to print Ubuntu CDs, or create your own\n  customised versions of Ubuntu which you sell, and should have the\n  freedom to do so.\nMust not require royalty payments or any other fee for\n  redistribution or modification.It's important that you can exercise\n  your rights to this software without having to pay for the privilege,\n  and that you can pass these rights on to other people on exactly the\n  same basis.\nMust allow these rights to be passed on along with the software. You\n  should be able to have exactly the same rights to the software as we\n  do.\nMust not discriminate against persons, groups or against fields of\n  endeavour. The licence of software included in Ubuntu can not\n  discriminate against anyone or any group of users and cannot restrict\n  users from using the software for a particular field of endeavour - a\n  business for example. So we will not distribute software that is\n  licensed \"freely for non-commercial use\".\nMust not be distributed under a licence specific to Ubuntu. The\n  rights attached to the software must not depend on the program being\n  part of Ubuntu system. So we will not distribute software for which\n  Ubuntu has a \"special\" exemption or right, and we will not put our own\n  software into Ubuntu and then refuse you the right to pass it on.\nMust not contaminate other software licences.The licence must not\n  place restrictions on other software that is distributed along with\n  it. For example, the licence must not insist that all other programmes\n  distributed on the same medium be free software.    May require source\n  modifications to be distributed as patches. In some cases, software\n  authors are happy for us to distribute their software and\n  modifications to their software, as long as the two are distributed\n  separately, so that people always have a copy of their pristine code.\n  We are happy to respect this preference. However, the licence must\n  explicitly permit distribution of software built from modified source\n  code.\nDocumentation, firmware and drivers\nUbuntu contains licensed and copyrighted works that are not\n  application software. For example, the default Ubuntu installation\n  includes documentation, images, sounds, video clips and firmware. The\n  Ubuntu community will make decisions on the inclusion of these works\n  on a case-by-case basis, ensuring that these works do not restrict our\n  ability to make Ubuntu available free of charge, and that you can\n  continue to redistribute Ubuntu.\nSoftware installed by default\nWhen you install Ubuntu, you will typically install a complete desktop\n  environment. It is also possible to install a minimal set of software\n  (just enough to boot your machine) and then manually select the\n  precise software applications to install. Such a \"custom\" install is\n  usually favored by server administrators, who prefer to keep only the\n  software they absolutely need on the server.\nAll of the application software installed by default is free\n  software. In addition, we install some hardware drivers that are\n  available only in binary format, but such packages are clearly marked\n  in the restricted component.\n\n\nA: It's a mix. Each package may be licensed under different terms. \nIt's generally legal to modify it and redistribute every package in main and universe, some packages may have restrictions on this, for example the firefox name and logo are trademarked so cannot be used without permission from Mozilla.\nYou can look at individual packages licences in /usr/share/doc/*/copyright\n\nA: Ubuntu is under a mix of licenses, each individual package has its copy right file under /usr/share/doc/PACKAGE/copyright, e.g. /usr/share/doc/gnome-panel/copyright\nAll packages in main & universe are free software & can be modified & redistributed - restricted & multiverse packages fall under other licenses which may not allow this.\nSee http://www.ubuntu.com/project/about-ubuntu/licensing for more details\n\nA: It is entirely legal.\nExamples of custom Ubuntu's that are released:\n\n*\n\n*Linux Mint\n\n\n*Elementary OS\nAlso, Ubuntu itself wouldn't be in existence if it wasn't for Debian.\nMore on that relationship here\nThere is a page on Ubuntu licensing, in particular:\n\nSoftware installed by default\nWhen you install Ubuntu, you will typically install a complete desktop\nenvironment. It is also possible to install a minimal set of software\n(just enough to boot your machine) and then manually select the\nprecise software applications to install. Such a \"custom\" install is\nusually favoured by server administrators, who prefer to keep only the\nsoftware they absolutely need on the server. All of the application\nsoftware installed by default is free software. In addition, we\ninstall some hardware drivers that are available only in binary\nformat, but such packages are clearly marked in the restricted\ncomponent.\n\n(emphasis mine)\nThere is the problem of Ubuntu Branding.\nThe trademark policy explains this:\n\nPermitted use Certain usages of the Trademarks are fine and no\nspecific permission from us is needed.\nCommunity advocacy.\nUbuntu is built by, and largely for, its community. We share access to the\nTrademarks with the entire community for the purposes of discussion,\ndevelopment and advocacy.\nWe recognise that most of the open source\ndiscussion and development areas are for non-commercial purposes and\nwill allow the use of the trademarks in this context, provided: the\nTrademark is used in a manner consistent with the Usage Guidelines\nbelow there is no commercial intent behind the use what you are\nreferring to is in fact Ubuntu. If someone is confused into thinking\nthat what isn't Ubuntu is in fact Ubuntu, you are probably doing\nsomething wrong there is no suggestion (through words or appearance)\nthat your project is approved, sponsored, or affiliated with Ubuntu or\nits related projects unless it actually has been approved by and is\naccountable to the Ubuntu Community Council\n\nSo (in this non-lawyers opinion), as long as you make it clear that this is a Ubuntu derivative  (similar to how Ubuntu is based on Debian), you're fine.\nHowever, I am NOT a lawyer, so this could be a flawed interpretation.\n\nA: According to wikipedia, Ubuntu for the most part is GPL Licensed: \n\nThe only exceptions are some proprietary hardware drivers.[24] The\n  main license used is the GNU General Public License (GNU GPL) which,\n  along with the GNU Lesser General Public License (GNU LGPL),\n  explicitly declares that users are free to run, copy, distribute,\n  study, change, develop and improve the software. On the other hand,\n  there is also proprietary software available that can run on Ubuntu.\n\nSource: http://en.wikipedia.org/wiki/Ubuntu_(operating_system)#Features\nThere are specific packages that aren't included  (e.g. restricted drivers) that provide different licensing.\nOn the official ubuntu.org website, you can also find more on this topic.\nIt also explicitly indicates that there are 4 types of licenses offered in ubuntu packages: \n\nThe thousands of software packages available for Ubuntu are organised\n  into four key groups or components: main, restricted, universe and\n  multiverse. Software is published in one of these components based on\n  whether or not it meets our free software philosophy, and the level of\n  support we can provide for it.\n\n\nA: http://www.ubuntu.com/project/about-ubuntu/licensing\nAs per this link, Ubuntu is a collection of a number of computer programs and each one of them may come under a different license.\nAs far as I know, the underlying Linux kernel is released under GNU GPL version 2:\nhttp://en.wikipedia.org/wiki/Linux_kernel\nAnd if you want to look up the license agreement for each one of the programs, then you can find it on a Ubuntu machine at this location:\n/usr/share/doc/*/copyright\n\n", "Q: How to force installation of kernel updates when using apt-get upgrade? To update my server I use apt-get upgrade.\nBut when there are kernel updates I always need to do apt-get install linux-.... because apt-get update does not install them.\nIs there a way I can tell it to install those too? I tried -f but it does not work.\n\nA: if you want to install aptitude then please go ahead - but it has its dependencies and imho you can get away quite well without it - especially if you want to keep your server install lean(er).\nWhen you run sudo apt-get upgrade it tells you about packages that weren't upgraded in the following way:\nThe following packages have been kept back:\n  linux-generic linux-headers-generic linux-image-generic\n\nSo, if you are connected using an ssh terminal, it's just a matter of copy+paste to enter the following command:\n$ sudo apt-get upgrade linux-generic linux-headers-generic linux-image-generic\n\nwhich upgrades just the packages that were kept back. Use uname -r to display the kernel version before and after the reboot (necessary to refresh the running kernel) and don't forget to run purge-old-kernels after the reboot.\n\nA: you're looking for \nsudo apt-get dist-upgrade\n\n\nA: So, with regard to the comments: Sorry, you were right, I was completely mis-reading what apt-get was telling me (and I'm using the English version! :)).\nAfter a little research, what you probably want to use is aptitude safe-upgrade, which does install new kernels. Really! I double checked! :)\nYou should probably prefer aptitude in general to apt-get anyway, unless you specifically need something in apt-get.\nnknight@nkubuntu1004:~$ sudo aptitude safe-upgrade\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nReading extended state information      \nInitializing package states... Done\nResolving dependencies...\nResolving dependencies...\nThe following NEW packages will be installed:\n  linux-headers-2.6.32-24{a} linux-headers-2.6.32-24-generic{a} linux-image-2.6.32-24-generic{a} \nThe following packages will be upgraded:\n  apt apt-transport-https apt-utils base-files firefox firefox-branding firefox-gnome-support gdm google-chrome-stable \n  icedtea-6-jre-cacao linux-generic linux-headers-generic linux-image-generic linux-libc-dev openjdk-6-jre openjdk-6-jre-headless \n  openjdk-6-jre-lib software-center thunderbird ureadahead xulrunner-1.9.2 \n21 packages upgraded, 3 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 129MB of archives. After unpacking 188MB will be used.\nDo you want to continue? [Y/n/?] \n\n", "Q: How to I move MySQL data files onto different partition? I have my hard drive partitioned with two partitions, so I can easily re-install Ubuntu and try out different versions without losing my home directory data.\nIt is setup like this:\n20GB  -> /     (root)\n180GB -> /home \n\nI do a lot of development work, so I have my /var/www folder symlinking to /home/valorin/workspace. \nBut I want to do this with my MySQL data files as well, as I am getting annoyed that each time I reinstall my machine I need to do a full SQLdump and then restore all the DB's before I can do more work.\nWhat is the best way to do this without breaking MySQL?\n\nA: Super user has a nice step by step instructions on how to solve this probelm\nHere is an other set of instruction on doing the same thing\nhttp://www.ubuntugeek.com/how-to-change-the-mysql-data-default-directory.html\nHere it is reposted. Go and up vote the original if you can on super user. \nAfter some general confusion about permissions I realized that the problem wasn't that I didn't have my permissions and paths right but that AppArmor was preventing mysql from reading and writing to the new location.\nThis is my solution:\nFirst stop MySQL so nothing weird happens while you're fiddling:\n$ sudo stop mysql\n\nThen move all the database directories to their new home:\n$ sudo mv /var/lib/mysql/<all folders> /new-mysql-dir/\n\nDon't move the files, they will be generated by mysql, just move the folders (which are the databases).\nThen politely ask AppArmor to allow mysql to use the new folder:\n$ sudo vim /etc/apparmor.d/usr.sbin.mysqld\n\nadd lines:\n/new-mysql-dir/ r,\n/new-mysql-dir/** rwk,\n\nThen tell mysql that the datadir has moved:\n$ sudo vim /etc/mysql/my.cnf \n\nchange the line:\ndatadir=/var/lib/mysql\n\nto:\ndatadir=/my-new-db-dir/\n\nNOTE: Depending on your database setup you might need to change innodb-data-home-dir etc. as well.\nThen restart AppArmor to read the new settings:\n$ sudo /etc/init.d/apparmor restart\n\nAnd start up MySQL again using the new datadir:\n$ sudo start mysql\n\nHope this helps!\n\nA: Well, actually there is a potential Ubuntu specific answer to this question.\nAs mentioned by Gergoes link, this is basically about modifying /etc/mysql/my.cnf and set a new value for datadir = in the [mysqld] section. So far the unspecific part of the answer.\nAssuming you are running a somewhat modern version of Ubuntu you might very well have AppArmor installed by default, with a profile for /usr/sbin/mysqld in enforced mode. That default profile will most likely not accept your new datadir.\nLet us assume that your new datadir will be /home/data/mysql.\nIf you open the file /etc/apparmor.d/usr.sbin.mysqld you will among the rules find these two lines.\n/var/lib/mysql/ r,\n/var/lib/mysql/** rwk,\n\nAssuming our example above, they will have to be replaced or (probably preferable) complemented by these two lines.\n/home/data/mysql/ r,\n/home/data/mysql/** rwk,\n\nBefore we can startup our MySQL server, with its new datadir, we will also have to explicitly reload our new apparmor profile.\n$ sudo apparmor_parser -r /etc/apparmor.d/usr.sbin.mysqld\n\n\nA: This really isn't Ubuntu specific. Nevertheless, here is something that might help: http://developer.spikesource.com/wiki/index.php/How_to_change_the_mysql_database_location\n\nA: For those who like me work with VirtualBox and need to move the MySQL datadir to a shared folder on the host system, follow the simple tutorial at http://vacilando.org/en/article/moving-mysql-data-files-virtualbox-shared-folder\n\nA: This won't work just like that.\nuser mysql has to have the right to write to the new dir:\nsudo chown -R mysql:mysql /newdatadir\nsudo chmod -R 754 /newdatadir\nsudo chmod 754 /newdatadir/..\n\n", "Q: What does the Ubuntu Firefox Modifications extension to firefox do? I'm presently running Firefox 3.6.8 on Ubuntu 9.04. My Firefox extensions include Ubuntu Firefox Modifications 0.9rc2. I've upgraded Firefox on this install a few times; as far as I can recall, some version of this extension was present when I initially installed Ubuntu 9.04. I have disabled it, mostly because I didn't know what it provided me, nor was I able to find out when I tried a bit.\nWhat does the extension do? \n\nA: It came with xul-ext-ubufox :\n\nUbuntu-specific configuration defaults and apt support for Firefox.\nAdds Ubuntu-specific modifications to Firefox.\nIntegrates the browser with Ubuntu to:\n  \n  \n*\n  \n*Enable searching for missing plugins from Ubuntu software catalog  \n  \n*Add the following options to the Help menu:\n  \n  \n*\n  \n*Get help on-line\n  \n*Help translating Firefox\n  \n*Ubuntu Release Notes  \n  \n  \n*Set homepage to Ubuntu Start Page\n  \n*Display a restart notification after upgrading Firefox \n  \n*Add ask.com to the search engines.\n  \n  \n  You can uninstall this if you prefer to use a pristine Firefox install.\n\nHomepage: https://launchpad.net/ubufox\n\nA: The files here show some of the changes that Ubufox provides (custom branding, search preferences, etc.)\nhttp://bazaar.launchpad.net/~mozillateam/ubufox/trunk/view/head:/defaults/preferences/ubuntu-mods.js\n\nA: It enables Firefox addons to be installed through the package manager.\n", "Q: How to set Ubuntu to synchronize my clock with a time server? I would like Ubuntu to automatically synchronize my system clock with a timeserver at startup.\nHowever, my PC isn't connected to the Internet until after I've logged in (plus 5 - 10 seconds for good measure).\nHow can I set it to do this?\n\nA: If you go to \"System->Administration->Time and Date\", you will get a GUI to set the date/time.\nAn option is provided for using time servers. If you check it and NTP is not installed, it will ask if you want to install it. Just click \"yes\", and let it do its job :)\n\nA: You can do this using at and ntpdate.  at is probably already installed, but ntpdate may not be.  (apt-get install ntpdate).  \nFirst create a small script that runs ntpdate, lets call it update_time.sh.\n#!/bin/bash\nntpdate pool.ntp.org\n\nIn your .bash_login file (which you may need to create) add this:\nat -f ~/update_time.sh now + 1 minute\n\nThat should do what you want.  You can change the delay that at uses to be 5 minutes, 10 minutes etc.\nEDIT: I just realized that you'll need to be root to run ntpdate.  You'll need to set the SUID bit on the update_time.sh script that I mentioned.  You can do that by running this from the command (only needs to be run once):\nsudo chmod 4711 update_time.sh\nsudo chown root update_time.sh\n\n\nA: It's generally recommended to run a service that uses NTP (Network Time Protocol) to regularly synchronize your computer's clock with a server. In recent versions of Ubuntu (at least since 18.10, or possibly earlier but I'm not sure), this is taken care of by the systemd-timesyncd service, which is installed and enabled by default, so there's no need to do anything special. If the service is available and active, running\ntimedatectl status\n\nshould tell you so.\nFor older versions of Ubuntu, you can follow instructions to set up an NTP daemon. There are several choices available but the \"standard\" one is in the package ntp. According to the instructions at the linked page,\nsudo apt-get install ntp\n\nwill get everything set up to synchronize with Ubuntu's NTP server.\nIf you really do only want to synchronize the time once at startup and never again (until the next startup), see e.g. mfisch's answer. But again, this is not recommended and there's rarely any reason it would be beneficial.\n\nA: Since Ubuntu 16.04 timedatectl / timesyncd (which are part of systemd) replace most of ntpdate / ntp. See Time Synchronization.\nYou might need to activate time synchronization using:\n$ sudo timedatectl set-ntp on\nIf you want to use chrony:\n\n\n*\n\n*If you require a one-shot sync use: $ chronyd -q\n\n*If you require a one-shot time check, without setting the time use: $ chronyd -Q\n\n*For continuous syncing, the recommended solution is chrony:\n\nchrony(d)\nThe NTP daemon chronyd calculates the drift and offset of your system\n  clock and continuously adjusts it, so there are no large corrections\n  that could lead to inconsistent logs for instance. The cost is a\n  little processing power and memory, but for a modern server this is\n  usually negligible. Installation\nTo install chrony, from a terminal prompt enter:\n$ sudo apt install chrony\n\nYou might also need to activate \nsudo timedatectl set-ntp on\nUpdate: Another method if the above doesn't work is to set a cron job to run $ chronyd -q\n", "Q: Install adblock using synaptic or through firefox's addons menu? I want to install adblock for Firefox and I see it is in Synaptic.\nShould I install it with Synaptic or the regular way with the Firefox add-on manager?\nDoes it make any differences at all?\n\nA: The version in the Ubuntu repositories will only receive bug fixes during a release cycle, not new features. This version has been tested with your version of Firefox, and is fairly stable. \nIf you use the unpackaged version via Mozilla Addons or elsewhere, it'll receive all new updates by the maintainer of the addon. These may cause breakage, depending on the level of testing upstream puts their code through. In Adblock's case, I suspect the level of QA is high, so this is not a very pressing concern, but one to take into account nevertheless. \nFirefox will refuse to install a newer version of the addon if said version no longer supports your browser version, so you don't have to worry about that. \nThe main difference is that the Ubuntu-packaged version is feature-stable (its behavior does not change) as well as reliability-stable (it will work consistently) throughout the release, whereas you don't get those guarantees from using AdBlock's extention installed externally. \nIf you're installing it for more than one user, by all means, use the packaged version. But if it's just for you, I think the locally installed version is fine. \n\nA: No, the Ubuntu Firefox Modifications Extension allows this to easily be done without any problems.\nTo answer your question: no, it doesn't matter.\n\nA: The only difference is that the version in the Ubuntu repositories will usually take a day or two longer to be updated.\nIf you install using the Add-On manager (as opposed to going to the website) it's my understanding that it installs from the Ubuntu repositories anyways due to the ubufox plugin.\n\nA: I have more 60 extensions installed and I always get them From Mozilla. Some updates might cause problems but they are usually fixed right away, specially AdBlock and NoScript.\n\nA: I would recommend using firefox's addons menu, as it is updated IMMEDIATELY when the developer of the addon pushes out a new version to Firefox. Whereas with the Ubuntu repos, it takes days/weeks/even months, depending.\n", "Q: What's your recommendation on drive partitioning schemes for a desktop and home server? What partitioning scheme do you recommend for a desktop? I've always created three or four primary partitions -- root, swap, home, and sometimes a separate boot partition. Ubuntu's default install offers LVMs. I've never had to add additional drives or space, so it never seemed like a big deal. Whenever I do a fresh install, though, I always think there might be a better way.\n\nA: For server installations, best practice is to use LVM, so you can expand your storage space easily if you run out of free space. My suggestion is:\n\n\n*\n\n*/boot\n\n*/\n\n*LVM (if you add more disks, just resize LVM and there you go).\n\n\nNOTE: if you use multi-user environment, it is good practice to create /home on LVM.\n\nA: *\n\n*/  (i.e. the root filesystem)\n\n*swap\n\n*/home\nThe biggest reason to do this is that you can do anything to your Ubuntu install and it won't affect your music/videos/whatever in your home. I especially enjoy this when a upgrade to a new Ubuntu version and the installation goes weird.\n\nA: I use:\nPrimary partition:\n\n\n*\n\n*/boot = 1 GB\n\n\nExtended partition with LVM:\n\n\n*\n\n*/ = 5 GB\n\n*/var = 3 GB\n\n*/var/spool/cache = 2 GB ReiserFS (local squid disk cache for all my browsers)\n\n*/home = +500 GB for users including a public folder (shared both locally and remotely with smb).\n\n*/tmp = 128 MB (ramFS).\n\n*swap = twice my RAM.\n\n\nI've been using this scheme for years and I'm very happy with it. Suggestions always welcomed.\n\nA: On my home server, I prefer to create /, /swap, and /var/log. Since I do run a firewall and log all activity to /var/log, creating the log as a separate partition ensures that even if the logs run rampart, it won't block me from booting. \n\nA: Generally speaking, you shouldn't bother with a separate /home or /boot partition unless you're running multiple Linux distributions at once.\nThe Ubuntu installers for both the desktop CD and server/alternate CD have the ability to install over an existing system, preserving your home directory (and the local system driectories: /usr/local, /usr/src, and /var/local).  This functionality also reuses the user ID and group ID of an existing user, if it has the same username as the user you're creating during installation.\nTo use this option when installing, choose the option for advanced partitioning, then select your existing / or /home partition.  In the box that appears, make sure the filesystem selected matches the existing filesystem of that partition, and that the format box is not checked.  Proceed as normal through the rest of the options.\nIn Ubuntu 10.10 we had hoped to add an option to the installer that detected when you had an existing copy of Ubuntu installed and offered to replace it with the newer version you were attempting to install (using the aforementioned functionality behind the scenes).  While it did not make the final cut, it is likely to arrive in Ubuntu 11.04.\nAs for a separate /boot partition, that's a relic of hardware constraints of the past (the bootloader 1024 cylinder limit).  I can think of no practical advantage a separate /boot would have on a modern system, and if not given an arguably excessive amount of space, it will potentially fill up and create problems of its own, given that Ubuntu does not automatically remove old kernels.\n\nA: If you plan to install several distributions and want to use the same home folder you can install with a separate /home partition and use the same username for each distro. But if you are only using Ubuntu there is no need to have a separate /home partition. \n\nA: I always do a fresh install of newer versions of Ubuntu, so for me it makes sense to have a separate /home, since I won't have to backup my home folder every time.\n\nA: *\n\n*/ (i.e. root filesystem) - for your operating system\n\n*swap - swap space, which should be a little larger than the amount of RAM you have\n\n*/home - for your data files\nYou only really need a separate /boot partition if you are using the alternate installer to set up full disk encryption. Currently the files in /boot need to be unencrypted so the operating system can start.\nGenerally speaking, you might add other partitions if you want to:\n\n\n*\n\n*Preserve the partition through a re-installation of the operating system - this is the usual reason for having a separate /home partition. A separate /usr/local or /opt might also be useful if you install lots of applications by compiling them from source.\n\n*Limit the space that files on a partition can use - for example, a separate /home partition will prevent your operating system grinding to a halt when you fill up your home directory because you will still be able to log in as root and delete some files from your home directory.\n\n*Use a different file system - I use a faster, less resilient file system for /tmp, but I keep /home on a slower, journaling file system for better data protection.\nAs suggested by Asmerito, you should consider putting all your partitions other than /boot on LVM. This will allow increased flexibility in resizing your partitions or even expanding them on to other disks. But you might not expect to require this functionality.\nIf you use the full disk encryption in the alternate installer, it will automatically create a /boot partition, a swap partition and another partition to hold the encrypted data. This encrypted partition is then used to hold a LVM partition. This LVM partition is then used to hold all your additional partitions. Initially this is just your root partition.\nHope this all helps.\n\nA: Well, at a minimum you need a root partition and a swap partition. I highly recommend a home partition because then when you run out of space on your home partition, it won't affect your applications and more importantly, core components.\nI discovered this the hard way when I ran out of space on the root partition - and I couldn't even start the Gnome desktop. I had to log in through the terminal and delete some stuff :(\n\nA: On my Notebook Desktop:\n\n\n*\n\n*8GB allocated to / (i.e. root of the filesystem)\n\n*2 times installed RAM allocated for swap (e.g. 3GB RAM = 6GB allocated for swap)\n\n*Remained of disk allocated to /home\n\nA: *\n\n*/root\n\n*swap\n\n*/mnt/storage -- somewhere to store any media that you download. If it gets full if won't fill up root. (I guess that this is similar to the idea of making /home a separate partition.)\n\n", "Q: How can I show or hide boot messages when Ubuntu starts? Is there a way to easily turn on/off showing the boot messages (loading the services) when Ubuntu starts? Is it something in Grub2?\nI am running 10.04.\n\nA: If you remove quiet option from GRUB_CMDLINE_LINUX_DEFAULT to show boot messages it's sometimes necessary to also set loglevel option to higher value. Otherwise some drivers may flood your tty with notice messages. I use this line to enable boot messages:\nGRUB_CMDLINE_LINUX_DEFAULT=\"loglevel=4\"\n\nThis way only significant system messages will be printed to the console.\n\nA: I may be out of subject, but you can just press \"escape\" during boot, to show/hide the plymouth splash screen...\n\nA: You didn't identify whether you are on a server system or desktop, so I'll address both.\nIf you add splash to /etc/default/grub/ in GRUB_CMDLINE_LINUX_DEFAULT, Ubuntu will present you with a splash screen, either a simple text based progress bar or graphically via plymouth, which I describe below. \nUsing plymouth, a graphical startup animator, you can provide a pretty bootscreen that is well suited to desktop machines. You might not want to do this on a server, but it's up to you. \nsudo apt-get install plymouth-theme-ubuntu-logo\n\n\nA: I use GRUB_CMDLINE_LINUX_DEFAULT=\"noplymouth\" to tell my laptop to not show me the startup picture but the boot messages … still works for 11.10\n\nA: You would need to edit the file /etc/default/grub.  In this file you'll find an entry called GRUB_CMDLINE_LINUX_DEFAULT.  This entry must be edited to control the display of the splash screen.\nThe presence of the word splash in this entry enables the splash screen, with condensed text output.  Adding quiet as well, results in just the splash screen; which is the default for the desktop edition since 10.04 (Lucid Lynx).  In order to enable the \"normal\" text start up, you would remove both of these.\nSo, the default for the desktop, (i.e. splash screen only):\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\" #Hide text and show splash\n\nFor the traditional, text display:\nGRUB_CMDLINE_LINUX_DEFAULT=        #Show text but not the splash\n\nFor the splash, but the ability to show the boot messages by pressing Esc:\nGRUB_CMDLINE_LINUX_DEFAULT=\"splash\"\n\nOr, finally, for just a (usually) black screen, try:\nGRUB_CMDLINE_LINUX_DEFAULT=quiet   #Don't show Ubuntu bootup text\nGRUB_CMDLINE_LINUX=\"console=tty12\" #Don't show kernel text\n\nAfter editing the file, you need to run update-grub.\nsudo update-grub\n\nFor more details, see this: https://help.ubuntu.com/community/Grub2\n\nA: There's a simple way of hiding all boot messages. In /etc/default/grub, adjust the following:\nGRUB_TIMEOUT=0 # Do not show the GRUB menu at all\nGRUB_CMDLINE_LINUX_DEFAULT=quiet\nGRUB_CMDLINE_LINUX=\"console=tty12\" # Redirect the kernel output to another tty\n\nAfter that, just sudo update-grub, and it should be done.\n", "Q: How can I sync music with my iPhone 3G? What is the best way to sync music with my iPhone 3G?\n\nA: I'm not sure if it's the best way, but Rhythmbox with libimobiledevice (both installed by default in lucid) works for me. There are a couple of glitches to be aware of, however:\n\n\n*\n\n*There's no full-library sync.  You have to manually drag individual songs to the iPhone.\n\n*About 10 seconds or so after Rhythmbox transfers the songs, the iPhone screen switches to \"Sync in Progress.\" You have to wait until after that screen goes away before you eject the iPhone, or the music won't actually get synced. This usually takes 5-10 minutes for me (more if I transfer a lot of songs)\n\n*The first time you go to the \"Music\" app on the iPhone, you have to wait for it to rebuild the library.\n\n\nA: I am using gtkpod ipod Manager to sync my music and videos. Sadly, you have to do some manual stuff to sync videos, in this case you have to set the video length by hand.\n", "Q: Is there a working uPnP client/server combo? I have videos stored on one machine; I'd like to watch them on another machine. Both are running Ubuntu 10.04 64-bit.\nSo far I've tried MediaTomb, MythTV, and python-coherence. None of the clients seem to see the servers and I definitely have connectivity between the client and server machines (so it's not a network issue).\n\nA: Here's a working combination I found:\nMediaTomb as the server (package mediatomb). I think almost any of the available uPnP servers should work but this is the one that was working when I found a client.\nFor clients I used Totem (for video) and Rhythmbox (for audio). I had to install and enable plugins for each of these to be used as a client.\nThe \"Coherence DLNA/uPnP Client\" plugin for Totem is packaged in totem-plugins-extra. Once you have installed and enabled it, uPnP servers are shown in the sidebar, a fact that does not appear to be documented and is not easy to discover.\nfor audio, the \"DLNA/uPnP sharing and control support\" is packaged in rhythmbox-plugin-coherence. Once enabled, a \"Shared\" category appears on the left hand side (under Playlists) listing the uPnP servers.\n\nA: If you can cope without using uPnP, I've used SSHFS and VLC Multicasting or Unicasting to achieve the same results.\nI used SSHFS by doing the following:\nsudo apt-get install sshfs vlc\nsshfs user@server/path/to/video_store /local/directory\nI then navigate to that directory with VLC and pick the files I want to watch with that.\nIf you don't have a reliable network link, then you might get some stuttering with this, but it does work.\nIf you've got a flat network, you might also want to consider using unicasting or multicasting from VLC.\nHere's the link to how to stream using VLC:\nRTSP live streaming - Command Line Examples | VideoLAN Wiki\nAlternatively, you can set up multiple \"channels\" to watch using this howto: \nStreaming HowTo/VLM | VideoLAN Wiki\nIf you need to use uPnP I've had good results streaming to my PS3 using the PS3 Media Server, although it isn't packaged in the Ubuntu repos, it is just a simple Java application that you tell it where all your video files are. It will perform some transcoding if you need that, and will transfer video, photos and music without any issues.\n\nA: If you would like to browse you videos on your PS3/XBOX and possibly your TV you can use a DNLA enabled server like TwonkyMedia. ( http://blog.gruenewaldt.net/en/software/ubuntu-linux/set-up-twonky-media-server-dlnaupnp-for-playstation-3-ps3-on-ubuntu-linux-for-video-streaming/ )\nYou can see a comparison between various Media Servers here: http://www.rbgrn.net/content/21-how-to-choose-dlna-media-server-windows-mac-os-x-or-linux\nThere is a DLNA plugin for Rhythmbox: http://coherence.beebits.net/wiki/RhythmBox\nI haven't tried any of this in Ubuntu, but I have TwonkyMedia running on my WD MyBook World Edition with great results.\n\nA: I've had ok results (can crash) with rygel, at least it works with my xbox, no configuration required. Getting my Panasonic G20 to discover it however is turning out to be a lost cause, I just might give up and fudge a USB gadget to create a pseudo hard drive and attach that to the TV.\nCan anyone comment on what the dominant DNLA project for Linux is? I want to contribute bug fixes but not to a dead end. Thanks.\n\nA: My recommendation for a DLNA enabled media client/server system is Plex.\nhttp://www.plexapp.com/\nIt's gone closed source as they are obviously trying to make some money out of it now but it's as close to flawless as I've found.\n", "Q: Does Ubuntu have support for the TRIM command for use with SSD? SSD drives need to be \"cleared/reset\" after the drive fills up to maintain performance. This is done through the TRIM command for new SSD drives. Does Ubuntu support the TRIM command (through hdparm etc) for clearing/resetting of these drives?\n\nA: Linux has support for automatic TRIM with ETX4 file system since kernel 2.6.33. \nThe first Ubuntu release with automatic TRIM support is 10.10 (Maveric), but it has to be activated in fstab (as described here).  \n\nA: In general, yes, because there are a bevy of ways to obtain newer kernels.  If we clarify your question to read, \"Does 10.04 LTS have support out of the box for the command?\" then the answer is no.  However, both Maverick's and Natty's kernels (-generic, -generic-pae, -server, and -virtual flavors) have been backported to 10.04 LTS and are available from $release-updates in the Ubuntu repositories, e.g., linux-image-generic-lts-backport-maverick is Maverick's backport to Lucid.\n\nA: Looks like there is support for the TRIM functionality in the 10.10 and newer releases:\n\n\n*\n\n*How do I optimize the OS for SSDs?\nAlso, the TRIM stuff happens automatically - empty blocks are automatically released when they're no longer needed (eg, you delete a file), if the disk reports that it supports TRIM. You don't have to manually issue a hdparm command for this to work.\n\nA: Jeremy's answer is not entirely accurate AFAIK. I've been running the latest stable kernels on Lucid for some time now and have been following the status of TRIM quite keenly as I have an OCZ Agility as my main disk.\nHere's what (I think) I know:\n\n\n*\n\n*The kernel has TRIM support as of 2.6.33 (Maverick is 2.6.35).\n\n*EXT4 has TRIM support but only when journaling is turned off.\n\n*The way TRIM works in the kernel is very basic and quite slow. Disks following the specs can accept multiple ranges but the kernel currently can only do one range at a time. This comes from something I read perhaps a month ago. I wish I had the source as this might not be true or might no longer apply.\nJournalling is what kills it for me. Data corruption is a PITA.\nHowever the newer versions of hdparm (v9.25 - Maverick is at v9.27) come with a script called wiper.sh which performs a quick analysis of a drive and then trims all the empty space. Rather than lose features, I find it much easier to cron wiper.sh to run once a week (or once a day/month/whatever). SSD degradation for an OS drive doesn't happen that fast unless you're constantly tearing things up. You don't need realtime TRIMming.\nThere is also a GUI frontend called DiskTRIM which doesn't appear to be in the repos. Less experienced users might find this easier to use than setting up cron jobs.\nThere are PPAs for hdparm and disktrim and all can be run on Lucid (and further back) without need for 2.6.33+ kernels.\n\nA: I'm running 11.04 and it doesn't look like TRIM is working according out of the box.\nI tested using the instructions here to create a file, delete it, and see if the sectors get zeroed out/deleted.\nI tried to enable TRIM using the instructions here, but no dice\nI run wiper.sh, I get\n\n/sbin/wiper.sh --verbose --commit /dev/sda1\nwiper.sh: Linux SATA SSD TRIM utility, version 3.3, by Mark Lord.\nrootdev=/dev/sda1\nfsmode2: fsmode=read-write\n/: fstype=ext4\nfreesize = 13785252 KB, reserved = 137852 KB\nPreparing for online TRIM of free space on /dev/sda1 (ext4 mounted read-write at /).\n\nThis operation could silently destroy your data.  Are you sure (y/N)? y\nCreating temporary file (13647400 KB)..\nSyncing disks..\nBeginning TRIM operations..\nget_trimlist=/sbin/hdparm --fibmap WIPER_TMPFILE.9689\n\n/dev/sda:\ntrimming 27294800 sectors from 462 ranges\nsucceeded\nRemoving temporary file..\nSyncing disks..\nDone.\n\nHowever if I run it again, it shows the same number of sectors/ranges need to be trimmed, and reports success again. I get exactly the same thing every time. It doesn't look like the sectors are ever deleted/freed. Reading them still shows the same data.\nCurious if anyone else has got it to work.\n", "Q: How are applications selected as defaults? Whenever I install Ubuntu there are certain applications I automatically install, instead of using Ubuntu's default (VLC comes to mind).\nMy question is about how some software is chosen over others to a  . Is it by the community?  Is there a committee?\n\nA: All applications to be included must be in main, and therefore must undergo the Main Inclusion Process. \nIf there's a good justification for a specific application, it dosen't pull in too many deps, and provides a increase in usability, it'll get included. \nTo discuss your specific example, I personally love VLC but its UI can be daunting at first. \n\nA: Generally changes are proposed and debated by the community at the Ubuntu Development Summit. See, for example, the\nMaverick Desktop Application Selection blueprint.\nThere are some rules; the application must be in the main repository (which means it will be officially supported) and it and its dependencies must fit on the install CD. Applications can be moved into main by going through the main inclusion process.\nThe Ubuntu Desktop Team is ultimately responsible for supporting and maintaining the default desktop applications. They conduct their weekly meetings openly on IRC and post the minutes to the ubuntu wiki.\n\nA: Well, first of all, only the applications that are included with the CD / ISO can be set as the default. And because there is little overlap between the included applications, there is little choice to be made as to the default.\nThe real underlying question is \"How are the included applications chosen?\"\n\nHere is some helpful information from Wikipedia:\n\nAt the beginning of a new development cycle, Ubuntu developers from around the world gather to help shape and scope the next release of Ubuntu. The summit is open to the public, but it is not a conference, exhibition or other audience-oriented event. Rather, it is an opportunity for Ubuntu developers, who usually collaborate online, to work together in person on specific tasks.\n\n\nA: Although I'm unsure how it was first done, the default packages that are in each release ISO are the same as the previous release ISO. Sometimes there is a need to change a package (default package is broken, there is a much better package now, etc). If this happens, there will be a session at UDS to discuss changing the default package (reasoning, changing it to what, how would that affect support/upgrades/etc). The discussion is open to anyone that wants to discuss it. It looks like the last time this was discussed was UDS-P (12.04). Here are the notes from it.\n", "Q: How do I get a patch applied to a package, when the upstream maintainer does not seem active? I know of bugs where there is a fix available, which has been posted upstream. However, the upstream maintainer hasn't responded to the patch, or applied it to the project's source code.\nWould it be suitable to submit the fix for inclusion in Ubuntu, and if so, would I go about doing this?\n\nA: The proper way to do this is to first make sure that the package uses a patch system, and if it doesn't set it up to use Quilt.  There should be answers on this site for how to do that.\nThen, create a new version of the package using dch -i.  Add your changes (such as use of a patch system) to the changelog, add your patch into the patch system, and then test the package (locally or in a PPA).\nFrom there, you can attach a debdiff to the bug report, tag it \"patch\", and start hunting for a sponsor.  A debdiff makes it very easy for a developer to just see your latest version of the package (patch included) and upload it themselves.\nYou could skip some of these steps and just attach the patch to the upstream source code to the bug report, but then your sponsor would need to do them all for you, and that means it'll probably take longer and it'll be harder to find a sponsor (since your package seems like an uncommon one, it's likely no developers are even familiar with it and thus might be reluctant to apply a patch).\n\nA: The patch can be submitted in from of a bug report, or if a report of the issue already exists , as an comment at launchpad. Please make sure to mark the uploaded file as a patch (there is a checkbox for that), because this will make it easier for us to find patches.\n\nA: Here's a pretty decent rundown for historical linkage: https://wiki.ubuntu.com/Bugs/HowToFix\n", "Q: Why does my Kubuntu session take considerable time before responding after resume? I have a Dell XPS M1330 running Kubuntu 10.04. \nWhen I resume from suspend, \n\n\n*\n\n*I get the blank lockscreen I set up, but I can't move my mouse, it's in the upper left hand corner of the screen. \n\n*The computer takes some time, some toaster notifications flash (above the screensaver for a second, then hiding)\n\n*I hear the \"welcome back\" tones. \n\n*I can move my mouse and log in.\n\n\nThis whole process can take anywhere between 15 and 45 seconds. Is there a way to figure out what is causing this delay, and to hopefully resolve it? \n\nA: Depending on the speed of your drive, 'paging in' the contents of running application's memory from disk can take a considerable amount of time when the system wakes up.\nThis also depends on what the kernel has 'paged out' (to swap) prior to going into the suspended state. You'll probably also notice that even once you can move the mouse around, going back to certain applications produces another slight pause while the drive activity light comes on for a few moments. \nI see the same behavior on my netbook, more prominently when I have 30+ tabs open in Chrome prior to suspending. \n\nA: This is not dependent on Dell hardware, as it also happened on my Lenovo X201. Apparently, this is an issue caused by timeouts in the networking stack (e.g. an unconnected eth0 waiting for a DHCP answer). For me, it was fixed by removing the \"auto eth0\" line from /etc/network/interfaces, as described here:  https://bugs.launchpad.net/ubuntu/+bug/217846/comments/23\n\nA: You could profile the backend KDE components causing the symptom. Start by using the pm-utils hooks.\n", "Q: How can I save my favourites in KNR search and launch page? Using lucid Kubunu Network Release, every time I reboot some of my favourites are missing. Do I have to log out in order to save them? How can I do that without  logging out?\n\nA: I think the favourites in Kickoff and S&L are separate lists.  Click the gold star on the ones you find on the S&L page to put them in the Favourites section.  If they're not staying put, report a bug.\n", "Q: How do I access an encrypted home folder from a dual-boot machine? (This might not be an Ubuntu-specific question?)\nWhen I installed 9.10, I opted to encrypt my home folder using ecryptfs, but then I discovered this locked me out of my ext3 partition when I tried to access it from Windows on my dual-boot machine (using some free ext2/3 driver that I got somewhere, not even sure which one).\nIs there a way to mount an encrypted home folder in Windows?\n\nA: Unfortunately, it looks like no Windows support for ecryptfs is planned: \nIs there a windows port of this available or in the works? \n\nA: If you use something like TrueCrypt you can access your drives from both Windows and Linux as long as you know the password. If you formatted it as ext2/3 you will need a ext2/3 driver to access it from Windows.\n", "Q: What guidelines should one follow when customizing their install in order to maintain an upgrade path? In the past, I've gone hog wild customizing my Ubuntu installation, only to be unable to upgrade it once the time came.  So how does one go about customizing their install without running into issues upgrading?  Is it possible to do so without relying solely on the Ubuntu repositories for software?\n\nA: One important factor in making upgrades run smooth is not to do anything which confuses the package manager. That is, you shouldn't yourself touch areas of the system which the package manager expect to be its domain. A few concrete examples.\nIf you compile/install programs yourself using the ./configure; make; make install method, don't put them directly under /usr. It is better to use /usr/local or /opt, alternatively (even better) to roll your own deb packages.\nWhen you remove packages you can either do a normal removal or an explicit purge. Unless you purge the package the package manager might leave files behind under /etc, /var and so on. Do not delete these files yourself, as the package manager expects them to be there. Instead use your package manager to explicitly purge the remains of the package.\nUsing deb package from third party repositories should theoretically be safe, assuming they are carefully built etc. Yet, to be on the safe side you might want to consider removing those packages and/or repositories before you perform an upgrade to a new Ubuntu release. \n\nOk, let me see if I can add some more meat to this answer...\nFirst of all, everything you do in your home directory is perfectly safe in regards to the package manager. It will never touch anything under /home.\n(Of course, you can still cause yourself plenty of confusion by doing bad thing to your home directory. Luckily that is usually be recovered from by removing the broken configuration files from your home directory, and let them be re-created from default at the next use. Do note that the automatic re-creation of default config only goes for your personal configuration files, not the system wide stuff under /etc)\nIn the role of a (power) desktop user I guess the most common system wide creativity will be installing extra applications, libraries, emacs modes, etc? Again, the really important part is to always put none deb package stuff under /usr/local instead of under /usr; to use /usr/local/bin instead of /usr/bin, to use /usr/local/share/emacs/23.1 instead of /usr/share/emacs/23.1 and so on.\nOnce you start playing around with server daemons you will soon be confronted by the system wide configuration under /etc. While you generally can modify files under /etc, you should \"never\" actually remove a file or a directory there, unless it was you who created it yourself. Likewise should you be careful about yourself creating new files in there, in case they would later on collide with a configuration file the package manager want to create. That being said, there are definitely files which you can (and should) be created under /etc. On of the more common examples is defining your Apache VirtualHosts under /etc/apache2/sites-available.\nThere might be times when you want create files or directories under /var. While it is a completely different place than /etc, still consider the same rules about being careful and doing things on individual consideration.\nIn case you want to know more, it won't hurt you to take a peek at the Filesystem Hierarchy Standard (FHS) or in the Debian Policy Manual. While it might be completely overkill in answering your original question, it is still a good read.\n", "Q: Help getting the Flash player working on second screen? I have a dual screen setup. I have a notebook LCD and a 17\" monitor plugged into the VGA port on the notebook.\nI have a GeForce 8400M GS video card with the NVidia 195.36.24 kernel module installed. I also have Compiz installed and enabled.\nHere is the problem: when I try to view a webpage that uses the Flash player, the control is empty. For controls that play sound, I can actually hear the sound, but I can't see anything.\nIt works fine on the primary (LCD) monitor.\nI'm using Ubuntu 10.04 64-bit.\n\nA: Run nvidia-settings and make sure that you are using Twin-View rather than Xinerama or a \"Separate X screen\". If that doesn't solve your problem, check and see if disabling flash hardware acceleration solves the problem (keep in mind that flash has little to no benefit from linux hw-accel as of this post).\n", "Q: Netbook Edition battery life - Ubuntu vs. Kubuntu? I've been running UNR on my eee 1000 pretty much since it came out over a year ago (I was using easy-peasy before that), but I'm curious about the new Kubuntu netbook edition.\nUltimately, KDE is better looking, and has some really friendly software, but I'm worried about performance - that display has got to be a processor hog (and by association, battery!), no?\nHow much does Kubuntu netbook edition impact battery life?\n\nA: Kubuntu Netbook Edition, running on my Asus eeePC 1000H is flat out unusable. The interface is so slow, I can sit and wait for 30 seconds for a button to press, or the task switcher to come up.\nI've switched off all graphic enhancements, and I still can't see me using this thing. Makes the whole battery issue moot. Next up: Jolicloud!\n\nA: The battery life should be relatively the same for each of them. Sure there will be a difference but it will be negligible.\nThe bigger issue here, I think, is your concern over the importance of battery life.\nWhich is more valuable:\n\n\n*\n\n*the battery life\n\n*using a desktop environment that you are more comfortable in and familiar with\n\n\nA: I suggest LUbuntu, it is a lighter OS so will allow your CPU to run slower, this adds up to longer battery life :)\n", "Q: Does installing packages manually with dpkg prevent a future upgrade path? I manage a private network which has no internet connectivity due to the security policy of the customer. This network has a single Ubuntu 10.04 LTS Server installation (soon to be several more) and I've been trying to customise it with software - however, I'm having to manually install packages with dpkg because of the lack of internet connectivity.\nDoes this prevent me from upgrading to a newer version of Ubuntu Server (LTS) when it becomes available, since the packags I've installed aren't ont he current distribution CD, they're unlikely to be on the newer releases also.\n\nA: Just for completeness: when you upgrade, if your packages are not supported anymore, or incompatible with newer packages (broken dependencies, etc), then the upgrade process will ask you if you want to remove those packages.\n I'm not sure what happens if you don't uninstall them - probably they will not work anymore.\nIn any case, you will be able to upgrade.\n\nA: AptOnCD might be a useful tool for you in this case: http://aptoncd.sourceforge.net/\n\nA: No. Installing packages from the official repositories using dpkg will not give you any problems down the road.\nIn fact, from a technical point of view, installing a package via dpkg is no different than if you had run sudo apt-get install package. The same things happen.\nThe only problem with installing packages with dpkg is that you will have to make sure that the dependencies are installed in the right order. If not, you could wind up with a corrupted package database.\nI know this happens from personal experience...\n\nA: It might be a better idea, considering you'll be adding more servers soon, to set up a local repository. This way, you can add the repo to the apt sources of each server and then point them all to a local repository that is just a mirror of the real ubuntu repos. \nThen when it is time to install or upgrade packages, you just use the standard ubuntu tools to handle this operation. Another benefit is that you just have to update the centralized local repo every once in a while with a couple of DVDs or hard drive that you can bring into the closed environment and sync with the repo's directories. Then each server will alert you to the packages that they have installed that have upgrades available on your local repo... meaning you have a lot less administrivia to maintain. The tools are allowed to do what the tools are good at.\nAlan Pope, ubuntu evangelist and one of the team behind the Ubuntu UK podcast, wrote a post on creating a mirror of the official ubuntu repositories that should help. You can find it here.\n", "Q: Panel applet to show current network traffic in text? I'm using the System Monitor panel applet to show me graphs of current ram usage and network traffic. However, I want something like iStat Menu's text version of this.\nIf I hover over my current app, it shows that instant's traffic, but does not update. \nIs there something that will display a number (not graph) of real-time network traffic?\n\nA: At least for network traffic, you can use GNOME Netspeed Applet\nsudo apt-get install netspeed\n\nI couldn't find anything for memory usage to be reported in this manner on gnome-panel, though it seems like it should be an option of the default system-monitor applet.\n\nA: You can use Conky, it's a lightweight system monitor, and highly configurable. You can choose from a wide list of parameters to display, not only network data, but memory, processor, etc. However information is displayed on your desktop background, so I'm not entirely sure it fits your needs.\nHave a look at Conky – a light weight system monitor for Ubuntu Linux Systems, it has some screenshots and directions on installing it on Ubuntu (via repositories). The configuration is easy, but is made through text files, so you have to be prepared to fire up your favorite editor.\n", "Q: How do I get vim to keep its undo history? If I'm editing two files with vim, changing to the other file ( :bnext, :bprev ) seems to drop the undo history from the open file - hitting the 'u' key reports \"Already at oldest change\".\nFor example:\n\n\n*\n\n*vim testfile1 testfile2\n\n*add some stuff to testfile1\n\n*:w\n\n*:bn\n\n*:bp\n\n*u\n\n*eep! can't undo!\n\n\nIs there any way to keep this history for non-visible buffers?\n\nA: The newest version of vim (7.3) has persistent undo, so that you can make a change, close vim completely (even shutdown and restart), restart vim, and undo. In your .vimrc:\n\" tell it to use an undo file\nset undofile\n\" set a directory to store the undo history\nset undodir=/home/yourname/.vimundo/\n\n\nA: Looks like this will do it:\n:set hidden\n\n(in .vimrc)\n\nA: You can use Viewports. \n\"vim -o testfile1 testfile2\" - open files in splitted window. \n\":sp filename\" - split and open \"filename\". \n\":vsp filename\" - vertical split and open \"filename\". \n\"Ctrl+w+arrow\" - Change viewport. \n", "Q: Backup bash script is not gzipping its tarball I have a bash script that runs as a cron to backup files on the server.\n#!/bin/bash\nFILE=/path/to/backup_$(date +%Y%m%d).tar\ntar -cf $FILE /backup/this /and/that /and/someotherfiles\ngzip $FILE\n\nWhen I run the script directly using:\nsudo bash ./backup-files.sh\n\nIt gzips the file, but last night when the cron ran it left it as a tar. Would the cron have saved a log somewhere that'd point to why this may be the case?\n\nA: Is the partition where backup is located at its limits?\nYour script has created the tarball, but gzip didn't have any space left to compress it.\n(you can combine both commands with -z flag for tar)\nWoops, I forgot one thing: add -v flag to your tar command. It will display what it does. \n\nA: As Pierre has mentioned, you may want to use the -z flag.\nGenerally, I always use tar zcvfP for backing up entire directories and preserving their structure and permissions. The v flag is there too, also useful.\n\nA: If it happens again that your script doesn't do what you want, you can add set -x on top of your script. It will output exactly what it does and this output is often helpful to find bugs. If you call it as a cronjob make sure that $EMAIL is set appropriate.\n", "Q: Photo management with video support F-spot is great, but does not have video support. Picasa is arguably even better, but although mov support is possible, avi and mpeg support is unavailable.\nIs there a photo management app that can also work with videos ?\nThanks\n\nA: This is included in Shotwell .8, which you can get here.\n\nA: Take a look at gwenview , it just may be what you are looking for.\n\nA: DigiKam, unfortunately is a KDE app. It will handle videos but its not intended for that purpose. Also you should notice that it might be a bit to much for photo management, but i haven't found an app that can handle photos and videos in an efficient way.\nPersonally I have given up for now, and I'm using different apps for photos and videos. It's also worth noting that Shotwell is going to have video support, eventually.\n\nA: I did some research, and it looks like digiKam supports videos and photos. Although a KDE app, I think it's fairly robust and works well even in a GNOME environment. \nAs some have mentioned, it's UI can be a bit daunting, but once you learn to use it, it can save you a lot of time and hassle in comparison to alternatives. I don't think there are any other apps that support both photos and video at this time on Linux. \n\nA: Personally, at a time when the availability of professional quality photo organizers and video editing software for Linux is still up in the air, I find using a dedicated photo downloader to be a much-needed source of consistency in my photo workflow.\nFor this I strongly recommend checking out Rapid Photo Downloader. It has powerful options for sorting and renaming photos and videos as they're imported on to the computer, and it can import from multiple memory cards simultaneously while creating backups on the fly.\n\nJust to be clear, this is a program that is designed to be used side-by-side with your preferred photo organizer. All it does is transfer your photos and videos on to the computer; what you do next with them is up to you.\nIf you want a more recent version than that in the repositories, you could use the following PPA:\nsudo add-apt-repository ppa:dlynch3\nsudo apt-get update\nsudo apt-get install rapid-photo-downloader\n\nBefore using any PPAs, please read this:\n\n\n*\n\n*Are PPA's safe to add to my system and what are some \"red flags\" to watch out for?\n", "Q: Why was F-Spot replaced with Shotwell in Ubuntu 10.10? What are the advantages of using Shotwell? What are the disadvantages?\n\nA: Essentially the choice was made upstream (by Gnome). But there are a lot of advantages:\n\n\n*\n\n*No Mono\n\n*It's lightweight and crash free\n\n*Better integrated with the Gnome Desktop\n\n*It has support for the RAW format\n\n*Some basic editing capabilities\n\n\nAs stated on the comment above the elimination of Mono from the default install would be a huge bonus, less occupied space, and less conspiracy theories evolving Microsoft and .Net running about.\n\nA: The specification for this decision is here\nHere (Sorry, this show has been removed from Blip.) is a video clip where we discussed Shotwell (and other apps) at the Ubuntu Developer Summit.\n", "Q: How can PPAs be removed? I've added many PPAs using the add-apt-repository command. Is there a simple way to remove these PPAs? I've checked in /etc/apt/sources.list for the appropriate deb lines but they aren't there. \nThis is on a server system so a command line solution would be great!\n\nA: You can use y-ppa-manager\nInstallation :\nsudo add-apt-repository ppa:webupd8team/y-ppa-manager\nsudo apt-get update\nsudo apt-get install y-ppa-manager\n\nUse :\nOpen Y PPA Manager and select Manage PPAs\n\nSelect the PPA you want to remove and click the Remove button\n\n\nA: You can manage your repositories in System > Administration > Software Sources\nYou can also remove them in /etc/apt/sources.list.d/ where you'll find a <repo>-ppa-<distro>.list file You can remove that file or simply comment out the deb line\n\nA: In Linux Mint there is no --remove or -r switch\non add-apt-repository. If you want to remove a repository, you'll have to do it manually. It's not hard:\n\n\n*\n\n*List all installed repositories.\nls /etc/apt/sources.list.d\n\nThis lists, for example:\ngetdeb.list  natecarlson-maven3-trusty.list  official-package-repositories.list\n\n\n*Find the name of the repository you want to remove.\nIn my case I want to remove natecarlson-maven3-trusty.list.\n\n*Remove the repository.\nsudo rm -i /etc/apt/sources.list.d/natecarlson-maven3-trusty.list\n\n\n*List all the GPG keys.\napt-key list\n\nThis lists, for example:\n/etc/apt/trusted.gpg\n--------------------\npub   1024D/437D05B5 2004-09-12\nuid                  Ubuntu Archive Automatic Signing Key <ftpmaster@ubuntu.com>\nsub   2048g/79164387 2004-09-12\n\npub   1024D/FBB75451 2004-12-30\nuid                  Ubuntu CD Image Automatic Signing Key <cdimage@ubuntu.com>\n\npub   4096R/46D7E7CF 2009-05-15\nuid                  GetDeb Archive Automatic Signing Key <archive@getdeb.net>\n\npub   1024R/3DD9F856 2011-04-15\nuid                  Launchpad PPA for Nate Carlson\n\n\n*Find the key ID for the key you want to remove. The key ID is the part after the /.\nIn my case I want to remove the Nate Carlson key, so the ID is 3DD9F856.\n\n*Remove the key.\nsudo apt-key del 3DD9F856\n\n\n*Update the package lists.\nsudo apt-get update\n\nDone!\n\nA: There's a command, add-apt-repository -r.\nBut deleting the file and re-running sudo apt-get update is also fine.\n\nA: Apart from the solution mentioned already: If you still have software installed from that repository, it is best to revert them to the original version supplied with ubuntu: the one from the ppa will not get (security and other) updates anymore.\nThere is a tool that will do just that: ppa-purge\nhttps://packages.ubuntu.com/search?keywords=ppa-purge\n\nA: It depends. If you've installed a new application from a ppa, then you can uninstall it normally. However, if you've enabled a ppa to get a newer version of a program that you've alredy installed (Firefox 4,newer Xorg drivers,etc), then you need to use a program called ppa-purge.\nPpa-purge is available in the repositories for Maverick and newer. A backport is available for Lucid users. Just install it and then run\nsudo ppa-purge ppa:repository-name/directory\n\nThe above command will disable the ppa from your software sources and then reinstall the official version of the upgraded application from the Ubuntu repository.\n\nA: OMG!Ubuntu! mentioned that this feature had been added to the 'Tweak' PPA. \nPresumably once it's in universe, you'll be able to use it to remove itself :)\n\nA: You can use Ubuntu-Tweak, which makes it very easy to edit ppa. You can delete the ppa's manually or when Ubuntu-Tweak know it just click a button.\n\nA: You can try those command below and it works very well for me to remove Linux kernel 3.5 (ppa:xorg-edgers/ppa).\nsudo apt-get install ppa-purge\nsudo ppa-purge ppa:<XXX>/<YYY>\n\n\nA: Most simple way to delete all of your PPA'a is this:\ncd /etc/apt/sources.list.d && sudo rm -i *list*\n\nIt will first take you to the directory which contains sources.list.d and then rm (remove) basically all files with word list in their name.\n\nA: The answers to this question will help you.\nYou can manage PPAs in System > Administration > Software Sources or by removing files in /etc/apt/sources.list.d/.\nYou can also use a package called ppa-purge.\nAnd, as I commented on the question I linked to above,\n\nThere is a bug on Launchpad requesting a --remove argument for the add-apt-repository command. I've submitted a merge request to get the feature implemented, but it hasn't yet been accepted. Hopefully you'll have this feature soon though.\n\n\nA: add-apt-repository now accepts a --remove argument.\nhttps://bugs.edge.launchpad.net/ubuntu/+bug/446216\nI proposed adding a rm-apt-repository command as well:\nhttps://code.edge.launchpad.net/~bryceharrington/software-properties/rm-apt-repository/+merge/25988\n\n\nA: Some people might prefer to add and remove repositories via a GUI. As of Ubuntu 10.10, this requires a bit of extra work. An explanation is available on the wiki. In order to try and have all answers for this question available in one place, I will try and summarize the important details here. Be sure to check the wiki (especially once a new version of Ubuntu is released) to ensure that this process is still valid.\nFirst, you will want to re-enable 'Software Sources' in the System->Administration menu. Right click on the Applications/Places/System menu and click 'Edit Menus'.\n\nThis will open a window, scroll down and click on 'Administration'. Check the box next to 'Software Sources' and then click the 'Close' button.\n\nGo to System->Administration and you should see 'Software Sources' in the menu.\n\nIn the window that opens, click on the 'Other Software' tab at the top.\n\nYou should see all of the repositories that you have added (including the PPAs added via add-apt-repository). You can temporarily disable a repository by unchecking the box next to it. To remove a repository permanently, highlight it and click on the 'Remove' button. When you are done, hit the 'Close' button.\nAs Marcel Stimberg noted earlier:\n\nThis will remove the PPA from the\n  repository list but if the package is\n  a newer version of one in the standard\n  repos, you have to manually downgrade\n  the package afterwards. ppa-purge (see\n  other answer) does that for you.\n\nHopefully, this will help.\n\nA: Simply run apt-add-repository again with the --remove option to remove a PPA added via the command-line. For example:\nsudo apt-add-repository --remove ppa:kernel-ppa/ppa\n\nThen update with:\nsudo apt-get update\n\n\nA: All these answers are fine, but to me the easiest way is still to remove them directly using rm -rf.\nImagine that apt update gives you the following error:\nW: Failed to fetch http://ppa.launchpad.net/ondrej/php5-5.6/ubuntu/dists/trusty/main/binary-amd64/Packages  403  Forbidden\n\nThen you can fix it doing something like :\nsudo rm -rf /etc/apt/sources.list.d/andrej*\n\n\nA: ppa-purge is your friend.  It automatically uninstalls whatever you installed via the ppa and then removes the ppa.\nInstall ppa-purge via:\nsudo apt-get install ppa-purge\nand the use it like this:\nsudo ppa-purge ppa-url\nViola.\n\nA: Since Ubuntu Maverick (10.10) add-apt-repository accepts a -r or --remove parameter which removes the PPA in the same way you installed it. :)\nSo:\nInstall: sudo apt-add-repository ppa:user/repository\nUninstall: sudo apt-add-repository -r ppa:user/repository\n\nA: Alternately, as ppas are stored in /etc/apt/sources.list.d you can find the one you want to remove by entering:\nls /etc/apt/sources.list.d\n\nThen when you have noted the name of that offending ppa (e.g. myppa.list), you can enter:\nsudo rm -i /etc/apt/sources.list.d/myppa.list\n\nTake care with rm (hence why I have used the interactive switch so you can confirm your actions. Then run sudo apt-get update afterwards.\nThis method merely removes the ppa .list file; it does not remove any other files or sort out any other problems caused by the ppa; for that you could use ppa-purge after you have got your update ability back (I know you mentioned this in your question, but I am adding this point for future readers): see here for more information on ppa-purge.\nAlso take into account that if you previously added the key of the repo as trusted you should remove it:\n# list the trusted keys\nsudo apt-key list\n# remove the key\nsudo apt-key del KEY_ID\n\n\nA: Run Ubuntu Software Center and from the menu choose \"Software Sources\" - there you can add/edit/remove repositories.\n\nA: Create this function (add it to wherever you store your functions) and then run with the appropriate ppa name:\nrmppa()\n{\n    sudo -- sh -c 'rm /etc/apt/sources.list.d/\"$1\".list ; apt-get update'\n}\n\nrmppa snagglepuss\n\nAdd error checking (non-existent parameter, for example) if you desire...\n\nA: There are a number of options:\n\n*\n\n*Use the --remove flag, similar to how the PPA was added:\nsudo add-apt-repository --remove ppa:whatever/ppa\n\n\n\n*You can also remove PPAs by deleting the .list files from /etc/apt/sources.list.d directory.\n\n\n*As a safer alternative, you can install ppa-purge:\nsudo apt-get install ppa-purge\n\nAnd then remove the PPA, downgrading gracefully packages it provided to packages provided by official repositories:\nsudo ppa-purge ppa:whatever/ppa\n\nNote that this will uninstall packages provided by the PPA, but not those provided by the official repositories. If you want to remove them, you should tell it to apt:\nsudo apt-get purge package_name\n\n\n\n*Last but not least, you can also disable or remove PPAs from the \"Software Sources\" section in Ubuntu Settings with a few clicks of your mouse (no terminal needed).\n\nA: Run these commands:\nsudo add-apt-repository --remove ppa:kernel-ppa/ppa \nsudo apt-get update\n\n\nA: You can use the\nsudo ppa-purge ppa:repository-name/subdirectory\n\ncommand in a terminal.\nYou will first need to install ppa-purge to use this command. To do so, use sudo apt-get install ppa-purge or click this button:\n\n(source: hostmar.co)\nFind out more about it here.\n\nA: Depending if add-apt-repository was invoked with a full sources.list line or a ppa it appends the line to /etc/apt/sources.list or a new file in the /etc/apt/sources.list.d/ directory. If it's a ppa it will then import the ppa GPG key into apt's keyring\nTo reverse the actions done by add-apt-repository you can either manually remove the apt line or use a tool like \"Software Sources\" to do it and then remove the GPG key using apt-key like so:  \n\"sudo apt-key list\" to find out the id for the repository you want to remove and then\n\"sudo apt-key del id\" where is looks like 7FAC5991. The id is the part after the \"/\" character.\n\nA: Using add-apt-repository\nNote: This solution does not remove/downgrade packages associated with the repository.\nThe add-apt-repository command has an option to remove a repository, which is specified with -r. You just need to know the PPA you want to send on its way. Use the command below:\nsudo add-apt-repository -r ppa:REPOSITORY/HERE\n\n... changing \"PPA/HERE\" to the PPA you are removing.\nSource: HOW TO USE A LAUNCHPAD PPA (ADD, REMOVE, PURGE, DISABLE) IN UBUNTU\n\nUsing ppa-purge\nNote: This solution will purge PPA, & downgrade all packages from it.\nTo install use:\nsudo apt install ppa-purge\n\nTo use ppa-purge you'd do:\nsudo ppa-purge ppa:REPOSITORY/HERE\n\n... changing \"REPOSITORY/HERE\" to the repository you are removing.\nSource: REMOVE OR PURGE PPA REPOSITORIES VIA COMMAND LINE [QUICK UBUNTU TIP]\n\nUsing Software&Updates\nNote: This solution does not remove/downgrade packages associated with the repository.\nSearch \"Software & Updates\" (or software-properties-gtk) & launch it then choose tab -> \"Other Software\". To remove a repository, uncheck it, then click \"Close\", & lastly \"Refresh\".\n\n\nA: If you are talking about the actual applications installed via a PPA, they will be listed just as any other application and  you would uninstall it the same way.\nThe PPAs (repositories) themselves will be listed under the 'Other Software' tab of the Settings->Repositories menu. They can be removed just like any other source.\n\n\nA: You can go into directory /etc/apt/sources.list.d and delete the related entries eg.\n(note that 2 entries exist for the same entry)\n\n*\n\n*sudo trash yann1ck-ubuntu-onedrive-bullseye.list\n\n*sudo trash yann1ck-ubuntu-onedrive-bullseye.list.save\n", "Q: Upgrading Ubuntu Server 9.10 to 10.04 A quick Google found this page about how to upgrade but my question is how do I make sure all configurations remain intact (Samba, Apache, SVN) and also, is it worth it to upgrade? Will 9.10 continue to have bugfixes/security updates and the like released to it via the package managers?\n\nA: 9.10 will continue to have security and regular bugfixes released until April 2011. The server version of 10.04 will have fixes released until April 2015 as it's a Long Term Release (LTS). At the moment your covered but you will have to upgrade from 9.10 after April 2011 if you wish to receive security and regular updates.\nI've always chosen to do clean installs when upgrading versions and saved my configuration files separately so I'm unaware if upgrading will overwrite configuration files.\n\nA: As part of the package upgrade process, if you have modified a configuration file you will be asked if you wish to keep the modified file, or install the new version, and have the opportunity to view the differences.\nThis wiki page shows the support periods of all the Ubuntu versions - wiki\nStandard releases, e.g. 9.10, are supported for 18 months.  LTS releases are supported for 3 years on the desktop and 5 years as server.  Upgrading to 10.04 has the advantage of this being LTS.\n", "Q: Is there something like Trixbox CE for Ubuntu Server? In an effort to keep things consistent, I've been slowly but surely replacing CentOS and *BSD servers with Ubuntu Lucid. I've come across a few that I'll have problems migrating, in particular several Trixbox CE servers that are based on CentOS.\nWe'd like to bring everything we have under one management roof, either by using Landscape or something similar that we nail together in house.\nIs there something like Trixbox that will work on Ubuntu? Either Asterisk or Freeswitch, preferably pre-packaged by a vendor in .deb format? I dug through Launchpad PPA's in hopes of finding a port of either, but I did not find anything.\nAny suggestions?\n\nA: As trixbox is open source, it should be possible to port the management interface to Ubuntu?\nOr FreePBX (I think Trixbox actually uses the FreePBX admin tools).\nSeems like FreePBX installation page mentions Ubuntu.  (There is also more to be found on Google...)\nFreePBX also works with FreeSwitch on an embeded system with Ubuntu 10.04.\n\nA: You can try Asterisk or Sipwitch that you can find in repository. If you want GUI, you can use gastman (GUI tool for Asterisk administration and monitoring).\n\nA: Elastix is another Asterisk based PBX that works 100% on Ubuntu, have several CPUs running it and make PBX servers with Elastix on Ubuntu.  Main reason is the CentOS versions will not allow updating, but the one's that work on Ubuntu do.\nOMR\n", "Q: How do i create my own php 5.3.3 package/ppa? I really would like to create a package for php 5.3.3 and then make a ppa for it (I would like the php-fpm support but inside the newest release), however this question goes further than this.\nI would like to be hand walked through the whole process of compiling and packaging for ubuntu as I do have an intrest in the whole MOTU project but I feel a little bit out of my depth at the moment.\n\nA: Regarding creating your own packages, you might want to take a look at the PackagingGuide. A good start is probably the Hands-On session. See also the Launchpad PPA documentation Building a source package and Uploading a package to a PPA.\nIn your case, the easiest/best thing to do is to base your package of the current Ubuntu PHP source package.\nA complete walk through might be none trivial. How about if you start experimenting some, and then ask more specific questions?\nIf you are interested in MOTO work you might also want to consider joining the mailing list ubuntu-motu as well as the IRC channel #ubuntu-motu (freenode).\n\nA: There is dotdeb.org, which provides recent packages for the LAMP stack, including PHP.\nSee the list of PHP-tagged updates.\nIt is targeted at Debian and not officially supported for Ubuntu, but works quite flawlessly on my Ubuntu boxes.\n", "Q: Strange behavior of flash in Google Chrome I have the last version of Chrome 5.0.xx. and my Ubuntu is also of the last version 10.04.\nWhat I usually do is to open two instances of Chrome and divide the screen into two parts. In one part my son watches cartoons in Youtube and in the other part I just read some news. \nSo, sometimes, when I close some pages of the news I have being read the video which was being played in youtube crashes and immediately stops. I need to refresh youtube page and see the video again. \nWhat is the problem? How to solve it\n\nA: The problem is most likely caused by the flash plugin crashing. Chrome is protected through separation from crashing itself, but the effect is visible the way you described. Since Flash player is proprietary software, there is no way to directly fix the problem. Although there are numerous workarounds floating around the internet. None of these workarounds are complete fixes and only fix specific issues.\nMore generic solution is to utilize the HTML5 feature of chrome. Various websites allow one to enable the HTML5 features. Youtube can be HTML5 enabled here: http://youtube.com/html5\nThere are also HTML5 enabling extensions for chrome that convert embedded videos to HTML5 elements where applicable and so reduce the amount of flash elements in websites.\n\nA: Chrome (and chromium) does a lot of threading (runs multiple processes), one or two processes for rendering and javascript (maybe more if you have a lot of open windows), and other processes for window management, gapping input and so on. When the render crashes all the windows (or tabs) that this render was in charge of will crash and chrome will show the \"Aw, Snap!\" page. It can be caused by a lot of things but basically means that a render thread has crashed. It might be a flash problem and it might be some fatal error in rendering html javascript ect.\nFlash might also be the problem, but it might as well be that chrome doesn't yes fully support the flash plugin - If firefox doesn't crash at the same pages it's properly not a flash bug since they use the same plugin.\nIf you use chromium remember to report bugs ;)\n\nA: I run Firefox if I plan on using flash-heavy stuff like Youtube or Homestar Runner, or if flash crashes while I'm using Chrome.  It's pretty much the only time I use Firefox any more, but the workaround does the job for me.  I'm open to any other solutions, though.\n", "Q: Is it safe to remove completely keyrings from Ubuntu? To be honest I didn't like how keyrings work in Ubuntu and removed them completely. \nIs my action safe and won't it harm any part of the system?\n\nA: Keyrings are only made to store passwords so that you don't have to always type them. It will do no harm to delete them except for the hassle of typing them all again.\n", "Q: What do windows' users like most after migrating into Ubuntu? \nThis question is not deleted because it has historical significance, but it is\n  not considered a good, on-topic question for this site, so please do\n  not use it as evidence that you can ask similar questions here.\nMore information: https://askubuntu.com/faq\n\nThe title says for itself. \nThere are a lot of interesting new features in Ubuntu. For example, after migrating into Ubuntu the most interesting feature for me was Centralized application installation via Synaptic (users do not need to search for an application, download it from somewhere, install it, and if it is pirated software to search keygens and stuffs like that). \nWhat else could be added to the list?\n\nA: When doing a fresh install, most users are also attracted by the fact that (almost) everything works out of the box, whereas on Windows you have to spend dozens of hours trying to figure out which drivers you need, where to get them and to install them.\n\nA: The feeling of controlling my OS, and not my OS controlling me.\nUpdate 6 years later:\nI've been using a Mac the last year due to work, and it's a great machine. But I'm temporarily using my old ThinkPad X201 running Linux and I'm like a happy child again. The feeling of freedom is back. I've rediscovered the Free and Open Source Software world, if only temporary.\n\nA: Ubuntu doesn't require restarting it after installing new applications.\n\nA: As someone who uses a lot of virtual machines for the development and testing of our own bespoke software, the biggest thing for me was the lack of 'activation'. I can create a new VM, install Ubuntu and start using it. No messing around with keys and no worries about activation.\nIt just makes the whole develop/test/deploy cycle a bit less painful. :-)\n\nA: A few days using applications that they use in Windows: Firefox, Chrome, Thunderbird, OpenOffice, Songbird, Skype.\nThats why I advise to users before migrate into Linux, use as many as possible cross-platform applications in Windows.\n\nA: I like the Ubuntu Software Center. Compiz. And of course how much I spent for buying Ubuntu $0.00\n\nA: One of the first features that struck me was the short installation time when compared with Windows.\n\nA: UI, especially since 10.04. THey like its smoothness & unobtrusive fashion. Even left handed window controls are accepted.\n\nA: If they're coming from an several year old installation of Windows, they're excited to say goodbye to the sluggishness and have a responsive desktop.\n\nA: Personally I like the power to customize pretty much everything.\n\n\n*\n \n* Panels (or Task bars)\n \n* Choosing between Graphical Environments (KDE,GNOME)\n \n* Wallpapers, Splash Screen, Login screen \n \n* and many more that I'm forgetting right now\n\n\n\n  And the best of all is that is simple, and free.\n\n\nA: I love having multiple desktops, and being able to access them with a hotkey. \n\nA: At work, we moved some people from Windows machines to Ubuntu. The praise that I heard most is that Ubuntu is fast. Yes, there are usually a couple of woes too.\n\nA: In my experience it's a combination of:\n\n\n*\n\n*Software Center -- \"You mean all this is free?\"\n\n*The fact that it isn't infected with malware.  Many users are migrated when they come to me for help after catching some nasty virus and malware that requires a whole reinstall\n\n*The community.  People actually feel like it's easier to get help with Ubuntu than Windows.\n\n\nIn many cases their old applications work fine using Wine, so they often have little to complain about.\n\nA: A few things off the top of my head:\n\n\n*\n\n*After running XP & Windows 7, my six year old Sempron box is suddenly a fast system again.\n\n*I love having Unix command line tools available. In Windows, I was always mucking about with GnuWin32 or Cygwin. But they never seemed to really fit in.\n\n*\"Hmmm, I think I want to start learning Scala\". A simple apt-get and I'm off. Being able to install anything I need without having to track down the most recent download or worrying about viruses is priceless.\n\nA: Personally:\nIt's free.\nWay faster on my machine than Windows ever was.\nFinding, installing and most importantly uninstalling software, is so much easier.\nNo pesky pre-installed trial software.\nI don't have to worry about viruses.\nI know that if I had the knowhow I could do pretty much anything I wanted.\nAlso, it looks pretty.\n\nA: apt-get is by far the most amazing thing I have found since I moved to ubuntu.\nAnd the following are a few more things which are must have:\n\n\n*\n\n*Gnome - Do\n\n*GVim (this is also available on windows btw)\n\n*Banshee\n\n\nA: *\n\n*A stable OS\n\n*An awesome terminal / console\n\n*Access to lots of great open source software\n\n*An os more akin to our development servers to deploy websites\n\n\nA: From an user perspective I would recommend Ubuntu because of:\n\n\n*\n\n*Support for old hardware (old printers, scanners, whatever), although old video cards can be a PITA\n\n*Centralized Package Management (easier program install, upgrades, and security fixes)\n\n*Faster install (much much faster than Windows)\n\n*Faster startup\n\n*No bloat ware, no system tray madness (this contributes a lot to startup time in Windows)\n\n*More security\n\n\nA: Defintely playing with Compiz effects, especially the Compiz Cube.\n\nA: No more weekly checks if all installed software is up-to-date, downloading the latest updates and manually installing all the stuff. I have so much more spare time now to do other things than staring at those installation programs!\n", "Q: How can I install a package without root access? I have no root access on this machine.\nI would like to know if there is a way I can download Ubuntu packages and install them as non-root?\nProbably in my ~/bin or ~/usr/share or something like that? Would that work?\n\nA: I assume you want to install jedit. First you have to find the package and download it. I just take the deb file from some mirror and open a console/terminal:\n\n\n*\n\n*mkdir /tmp/jedit && cd /tmp/jedit -- Makes a new diretory in tmp and changes into it.\n\n*wget http://mirrors.kernel.org/ubuntu/pool/universe/j/jedit/jedit_4.3.1.dfsg-0ubuntu1_all.deb -- Download package\n\n*ar x jedit_4.3.1.dfsg-0ubuntu1_all.deb or, easy to type, ar x *.deb -- this extracts the file contents\n\n*tar xvzf data.tar.gz -- the file data.tar.gz has all the stuff which you need for executing the software\n\n*usr/bin/jedit opens the editor\n\n*done :-)\n\n\nYou can move the files to some point in your home directory and execute them from there. \n\nA: Apt doesn't support it directly, but there are ways to do it:\n.deb Approach\napt-get download package_name  # replace `package_name` with the name of the package.\n\ndpkg -x package.deb dir\n\nIf the deb isn't in the Ubuntu repositories, apt-get package_name won't work, but you may be able to download it from a web site.\nThis will extract the .deb package to dir/. Then you can export the PATH where the binary is. As long as all dependencies of the binary are installed, it should run as normal.\nschroot Approach\nAnother approach is to use schroot to create a non-root chroot. This is a somewhat involved process, but one you should be able find community help for as many developers set up chroot environments for compiling code.\napt-get source Approach\nFinally, you could use the apt-get source command to fetch the source of the package and configure it to install locally. Usually this looks something like:\napt-get source package\ncd package\n./configure --prefix=$HOME\nmake\nmake install\n\nThe disadvantage to this approach is that you need the development environment available for this approach to work at all, and you might find yourself compiling dozens of packages in order to resolve all the dependencies.\nHistorical Approach\nIt used to be possible to install package.deb with dpkg into one's home directory.\ndpkg -i package.deb --force-not-root --root=$HOME\n\nThe disadvantage to using dpkg like this is that error messages are likely to be cryptic; dpkg doesn't automatically resolve dependencies or create the directory structure it expects.\n\nA: I wrote a program called JuNest which basically allows to have a really tiny Linux distribution (containing just the package manager) inside your $HOME/.junest directory.\nIt allows you to have your custom system inside the home directory accessible via proot and, therefore, you can install any packages without root privileges. It will run properly under all the major Linux distributions, the only limitation is that JuNest can run on Linux kernel with minimum recommended version 2.6.32.\nFor instance, after installing JuNest, to install jedit:\n$>junest -f\n(junest)$> pacman -S jedit\n(junest)> jedit\n\n\nA: I find the accepted answer lacks a concrete example. This is a full working example:\n# - opam (snap, no sudo)\n# ref: https://askubuntu.com/questions/339/how-can-i-install-a-package-without-root-access\napt-get download opam\n#apt-get download opam_1.2.2-4_amd64\n#ls | less\nmkdir -p ~/.local\ndpkg -x opam_1.2.2-4_amd64.deb ~/.local/bin\nexport PATH=\"$HOME/.local/bin:$PATH\"\necho 'export PATH=\"$HOME/.local/bin:$PATH\"' >> ~/.bashrc.user\n\ntr ':' '\\n' <<< \"$PATH\"\n\nopam --version\n\nin particular you need to be careful because apt-get download might now give you the .deb fine with the exact name you expect.\nNote this one usually also works:\n# - install the bin then put it in path and restart your bash\nmkdir ~/.rbenv\ncd ~/.rbenv\ngit clone https://github.com/rbenv/rbenv.git .\n\nexport PATH=\"$HOME/.rbenv/bin:$PATH\"\necho 'export PATH=\"$HOME/.rbenv/bin:$PATH\"' >> ~/.bashrc\necho 'eval \"$(rbenv init -)\"' >> ~/.bashrc\n#    exec $SHELL\n#bash\n\nrbenv -v\n\n", "Q: Alternative for Mac OS X Automator? I once tested Mac OS X and something that called my atention was Automator, a software to visually create scripts to automatize tasks on the desktop. Is there any Linux alternative for this software?\n\nA: Well, there's xnee and its version with a GUI gnee.\nYou can find it in the software center or install it via\nsudo apt-get install gnee\n\nScreenshots and documentation are available on the GNU xnee page.\n\nA: If you're feeling adventurous, you could try out Sikuli. It's a computer-vision-based, cross-platform GUI automator with a slick IDE. It wasn't developed on Linux, so the Linux documentation is a little thin; however, it's pretty intuitive, and most of the non-Linux documentation applies.\n\nA: As a third solution, you can take the trip to the Java world by taking a look at Actions, which closely mimics Automator look and feel.\n\nA: There is Gnu Xnee, which enables you to record and replay actions on the desktop. You can install it from the software center.\n\"GNU Xnee is a suite of programs that can record, replay and\ndistribute user actions under the X11 environment. Think of it as a\nrobot that can imitate the job you just did.\"\n\nA: The options mentioned above all sound okay, and I've tried gnee - but Xpresser seems to be quite reliable and easy to use, if you don't mind a bit of scripting. \nYoutube Video Demo\nUbuntu Wiki\n", "Q: How do I install pyjamas? When Ubuntu 10.4 was in alpha stage, there was pyjamas package, which didn't work. I posted a bug on launchpad and the only resolution, was removing this package altogether.\nDoes anyone know, how to easily install pyjamas on Ubuntu 10.4? I tried downloading debs from debian repositories, but there were some broken dependencies.\n\nA: The pyjamas package is available for Lucid from this ppa. Although there is no pyjamas-desktop package :/ To add the ppa and install you can do\nGUI Method\nOpen the Ubuntu Software Center, choose the \"Edit\" menu and select \"Software Sources ...\". Select the \"Other Software\" tab in the dialog box and click on the \"Add ...\" button. Then enter the text \"ppa:fabricesp/ppa\" and click \"Add Source\". Then click \"Close\" and wait for the update to finish. Then you should be able to use the search box to find pyjamas and install it.\nCommand Line Method\n$ sudo apt-add-repository ppa:fabricesp/ppa\n$ sudo apt-get update\n$ sudo apt-get install pyjamas\n\n\nA: This may be useful.\n\nA: You could try installing it from Maverick or Debian unstable/testing.\nSee https://launchpad.net/ubuntu/+source/pyjamas - which contains links to the .deb files, which you can try using for a manual installation (e.g. via dpkg -i path/to.deb).\n", "Q: What is the best remote desktop tool to connect to Windows from Ubuntu? I've used rdesktop in the past.  Is there something better?\n\nA: Ubuntu ships by default with tsclient. It works pretty well for me.\n\nA: rdesktop\nrdesktop is an open source client for Windows NT/2000 Terminal Server and  Windows Server 2003/2008. Capable of natively speaking its Remote Desktop Protocol (RDP) in order to present the user's Windows desktop. Unlike Citrix ICA, no server extensions are required.\nTo install rdesktop in all currently supported versions of Ubuntu open the terminal and type:\nsudo apt install rdesktop\n\nA typical command looks like this.\nrdesktop 192.168.1.23 -k de -g 1500x1150  -r disk:mydisk=/home/soma\n\nParameters:\n-k de............................ set keyboard layout\n-g 1500x1........................ set resolution of the rdesktop window\n-r disk:mydisk=/home/soma.........share your home directory with the remote machine\n\n\nA: KRDC, which comes as part of Kubuntu, allows better control of the appearance of the remote window than just using rdesktop or tsclient.  In particular, it allows a full screen view that you can minimise, unlike the other two, which (as far as I can tell) require you to log out to return to your Ubuntu session if you are using full screen.\n\nA: Have you tried TeamViewer?\n\nA: Although TightVNC 2 does not have a Linux version, you can still get the old version (1.3.10) here.\nI have used TightVNC before and it is quite fast. (Of course, I do it the other way around - I log into my Ubuntu box from Windows.)\n\nA: 'rdesktop' seems to work pretty well in general. If you miss ClearType fonts (like I do), then this might solve your problem:\nhttp://katastrophos.net/andre/blog/2008/03/10/rdesktop-connect-to-windows-vista-with-cleartype-font-smoothing-enabled/\n\nA: If you have control over the server side, I suggest installing and using Real VNC - http://www.realvnc.com/\n\nA: gnome-rdp is available in the ubuntu repositories. It supports RDP, VNC and SSH protocols and allows you to configure and store multiple sessions.\n\nA: You can try remmina. While it uses the same backend as tsclient and friends (the backend being rdesktop). It has a more pleasing UI when compared to tsclient.\n", "Q: How do I move the window buttons back to the right for all users? I know I can edit gconf to move the [Minimize,Maximize,Close] buttons back to the right-hand side, but is there a way to do this for all users?\nIdeally at install time so I don't have to explain this to every user every time I set up a new machine.\n\nA: gconf-editor has an option to do this. Just right-click on a value you want to set for all users, and click \"Set Default\". PolicyKit will open and ask you for your password. After that every new user will have that value.\n\nA: I don't know about install time, but when new users are created, the files from /etc/skel are copied to the new home directory. You could add a file \n/etc/skel/.gconf/apps/metacity/general/%gconf.xml\n\nwith the contents\n<?xml version=\"1.0\"?>\n<gconf>\n<entry name=\"button_layout\" mtime=\"1273173410\" type=\"string\">\n    <stringvalue>:minimize,maximize,close</stringvalue>\n</entry>\n</gconf>\n\nto /etc/skel.\nOr you could create the perfect user-setup (let's name him perfectuser) on a new account, and replace\nSKEL=/etc/skel\n\nwith\nSKEL=/home/perfectuser\n\nin /etc/adduser.conf.\nThat way, each new user you create would have the same configuration as perfectuser.\nMaybe the install CD could also be modified in a similar way?\nTo change the setting for all users, you could write a script that adds\n<entry name=\"button_layout\" mtime=\"1273173410\" type=\"string\">\n    <stringvalue>:minimize,maximize,close</stringvalue>\n</entry>\n\nto all /home/[user]/apps/metacity/general/%gconf.xml.\n\nA: Download UbuntuTweak go to Window Manager Settings and click \"Right\"\nEdit: I'm not exactly sure if this does it for all users but it is easy.\n\nA: For people arriving late like me when the above solutions may not work anymore, you can also use gsettings for this:\ngsettings set org.gnome.desktop.wm.preferences button-layout 'appmenu:minimize,maximize,close'\n\nFrom\nhttps://wiki.gnome.org/Projects/Metacity\n", "Q: How can I type accented characters like ë? Currently I use the character palette applet in gnome panel to put special characters into text.\nThis is okay, but I have to stop typing, select the character I want from the applet and then copy and paste.\nIs there a way to simply type special characters with different key combinations? If so, how do I do it?\n\nA: Note for dummies like myself. It took me a while...\n\n\n*\n\n*Press Cont & Shift & u together\n\n*Let go of all three keys\n\n*input code (for example: 00e1 for á)\n\n*Enter\n\n\nA: If you are on Ubuntu 20.04 :\nGo to Setting > Region and language > on the Input Sources Click on \"+\" button and choose English (United States) then English(US,intl.,with dead keys).\n' + e -> é \n\" + e -> ë \n` + e -> è \netc.\n\nA: If you know the unicode value of the character you'd like to type, hit CTRL+SHIFT+u\nand then type the unicode.\nExample:\nCTRL+SHIFT+u 0 3 b b ENTER\nresults in λ.\n\nA: You can use Ctrl + U and type Unicode number of the sign you want to type. So for ē you have to type Ctrl + U + 113.\n\nA: Here is an answer close to 1st answer, with a little alternative: I do not need to use compose because I set my keyboard to English US international instead of English US or English UK.\nSo I use the following combo:\n\" then e for ë\n'  then e for é\n` then e for è\n` then a for à\n~ then n for ñ\nand\n\" then spaceBar for \"\n' then spaceBar for '\n` then spaceBar for `\n~ then spaceBar for ~\nAlt Gr plus 5 for €\n\nA: The easiest way I've found to do this is to set your keyboard layout to USA International (AltGr dead keys), then use Right-Alt+whatever to get the character you want. Obviously this does not work for all international/special characters, so if you need one that's not available through this method, use one of the other methods listed here.\nWikipedia gives us a handy diagram of the available characters and the keys they are mapped to.\n\nA: Often this is easier with the compose key. With that configured you use key combos to get the special characters. For instance:\n\n\n*\n\n*For ë you press Compose+\", e.\n\n*For ẽ you press Compose+~, e.\n\n*For ô you press Compose+^, o.\n\n*For á you press Compose+', a.\n\n*For à you press Compose+`, a.\n\n*For € you press Compose+=, e.\n\n*For £ you press Compose+-, l.\n\n\nNote that you do not have to hold down the compose key; just press each key in order.\nTo set the compose key go to System -> Preferences -> Keyboard, then Layouts -> Options. Open up Compose Key Position and choose a key. I use Right-Alt.\n\nA: The compose key it's defined to do key combinations. It's Used to produce special characters like tildes and accents. To see the list of key names open /usr/share/X11/xkb/rules/xorg.lst and search for \"compose\".\nThis technique was tested in Lubuntu. Two ways to enter special characters:\n\n\n*\n\n*Call setxkbmap to define compose key in the current session\n\n*Define compose key permanently\n\n\n1). Command line $ setxkbmap -option \"compose:rwin\". Example to define compose key right 'Win'.\n2). Open file /etc/default/keyboard and add line XKBOPTIONS=\"compose:rwin\" (requires restart).\nExample to write character ã after defining compose key. Press the compose key, then key 'a' and finally the tilde (AltGr + 4).\nhttps://www.eovao.com/en/a/special%20characters%20ubuntu%20linux/5/how-to-enter-special-characters,-accents-and-tildes-in-ubuntu\n\nA: Change your keyboard layout to us. intl with dead keys\nGo to\nControl center > keyboard > layout > add > set country to us > Select us intl. with dead keys.\n", "Q: Is it possible to tell what packages I've installed that aren't in the vanilla install? I've upgraded Ubuntu on my laptop all the way from 7.04 to 10.04 without ever wiping the disk. I have a sneaking suspicion that means I have a bunch of crufty packages that I don't use and that are just taking up disk. Is there any way to get a list of all the packages included that are beyond the base install?\n\nA: The debfoster and deborphan packages are very useful for this purpose. You can do \n$ deborphan\n\nto get a list of libraries that have no package depending on them. You often get extra libraries left behind after an upgrade. You can also do\n$ deborphan -a\n\nto see all packages that have no other packages depending on them. Some of them you will have installed yourself, but any you don't recognise you could check the details and uninstall if they seem unnecessary.\nMeanwhile debfoster will go through the packages and show you what packages and keeping lower level packages installed. This is a bit more dangerous if you don't know what you're doing, and has to be run as root or using sudo.\n\nA: This lists all installed packages, stripping out those which were automatically installed:\naptitude search '~i!~E' | grep -v \"i A\" | cut -d \" \" -f 4\n\nIt's probably the closest thing to what you want. It'll still include libraries which were pulled in as dependencies of packages, but it won't contain any of the packages in the default system. \n\nA: After doing a little googling I came up on this link : http://ubuntuforums.org/showthread.php?t=261366\nBasically he uses \ndpkg --get-selections > installed-software\n\nto list all the installed packages , now if you can get a list from someone who just installed ubuntu or get it from a fresh VM install and compare the list you have the packages that are not in the vanilla install.\nAlso if you just want to remove unused packages use the janitor  ( System > Administration > Compter Janitor) :-)\n\nA: I found a great answer to this on a related question. It uses the release manifest for the default package install list.\nI also found this duplicate question.\nI would love to see this as a filter in the Ubuntu Software Center. In Windows \"Add/Remove Programs\" serves this purpose.\n", "Q: Stopping the menu icon flicker Every time I click on the application or system menus, I notice that no icons show up for a second, then they page in. Is there some way to explicitly tell Ubuntu to cache this? My SuSE (GNOME) desktop doesn't have this problem, but I don't know whether that's because they're doing something custom, or because it's a setting I'm missing.\n\nA: You'll need to manually tell Ubuntu to update the icon cache. This command should accomplish that for you: \ngtk-update-icon-cache -f /usr/share/icons/THEMENAME/\n\nReplacing THEMENAME with your theme name, of course. \n", "Q: When to use packages in aptitude versus CPAN/Gems/PyPI? What's the general rule for when to install a package from the official .deb repositories, versus when to install with the language's package manager? The ones in the upstream repositories are frequently at least slightly out-of-date, but I also don't want to have my packages colliding with the \"official\" ones, and it seems that aptitude is going to force me to install the official ones in many cases anyway.\n\nA: This is a difficult question to answer in generality.\nThe official .deb packages give you stability and full support by the Ubuntu community . If you don't need the latest version, you might be better off with this solution. You also have the package manager support for updates, removal, etc.\nIf you need support from upstream, or need the latest features, you are better off getting it from the distributions systems like CPAN , gem, pear, etc.\n\nA: In my (admittedly not-to-vast) experience, language-specific package managers don't do anywhere as good a job as .deb ones in tracking dependencies that are totally outside the language's boundary (I'm especially thinking of dependencies on C-coded libraries which a package wraps for use in Python, Perl, Ruby, etc).\nIf (say) a Pypi Python package 'barfoo' requires some library libfoobar in order to build the _bf.so Python extension which the package uses, and needs libfoobar to be at least at release 5.2, it's up to you to track down which .deb supplies suitable releases of libfoobar (and you might not find one, if the Pypi package is tracking close to upstream's latest and greatest) -- and somehow keep track of it in case you uninstall barfoo later (so the libfoobar supplier gets \"orphaned\" and could/should be removed).\nI don't think that the problem of integrating Pypi/CPAN/etc with other package distribution systems can yet be considered a \"solved\" one.  For minimal administration headaches, if you can get by with an official .deb (don't need latest-and-greatest feechurz &c), I think that would be advisable; at the other extreme, of course, for a package you do want to be super-updated (e.g., you're one of the package's upstream authors/maintainers;-), there is the option of keeping a fresh repo in whatever version control system the package uses (svn, hg, git, bazaar, ...) and keeping it built from sources.  Pypi/CPAN/&c are \"in the middle\".  Surely some of the time this middle way will be advisable, too.\nAnd, one option that might be considered is to build your own .deb package (based on either the Pypi/CPAN/&c one, or even on upstream sources) and keep your repository of such packages (for those packages for which you find official .deb repos too poor or backwards). It's not much more trouble than installing otherwise (manually tracking outside-the-language dependencies) and would help with identification of \"orphan packages\" and the like (plus, if you publish your packaging, you can also help other people;-).\n\nA: I've truly been against using Aptitude to manage packages from another Package Manager. CPAN, Gems, Pecl, Pear, etc are Package managers for their respective languages. They are what you should default to - in my opinion - because that's what they are designed for. Not to mention most all of those handle upgrades and updates now (gem update, gem upgrade, etc). It would be like using yum to install Apache on your Ubuntu Machine.\nThat being said there are a few occasions when the Aptitude version reigns supreme. One such is when an installation of a module from a languages package manager fails (this is typically because of varying configuration issues) I rarely come across this issue - but when I do the correlating package from Aptitude does the trick.\nPriority in my opinion Language Package Manager > Aptitude.\n", "Q: Is there an equivalent to Windows Remote Assistance/iChat screen sharing? \nPossible Duplicate:\nRemote Desktop similar to Teamviewer? \n\nI'm used to being able to help my parents through iChat screen sharing on OS X and Remote Assistance on Windows. Is there something that has the same workflow (no setup, works through NATs and firewalls) available for Ubuntu? I'd be very nervous about migrating them to Ubuntu without the ability to help them remotely.\n\nA: Ubuntu has been shipping Empathy for a few releases. It uses the Telepathy framework, which does all the heavy lifting. All you need to do is set up your parents to use gtalk (or some other jabber service) in the chat application, and then when they want to ask you for help, they right click on your name in the name list, and select Share my desktop. My answer to this question has more information.\nHere is some information on the feature\n\nA: remmina \nRemmina is a remote desktop client written in GTK+, aiming to be useful for system administrators and travellers, who need to work with lots of remote computers in front of either large monitors or tiny netbooks. Remmina supports multiple network protocols in an integrated and consistant user interface. Currently RDP, VNC, NX, XDMCP and SSH are supported.\nRemmina is released in separated source packages:\n\n*\n\n*remmina, the main GTK+ application\n\n*remmina-plugins, a set of plugins\n\nRemmina is free and open-source software, released under GNU GPL license.\n\nA: You may try Team Viewer. I have personally used it successfully on Ubuntu  \n\nA: Kinda. If you have a router with uPNP activated, the share desktop option on the preferences menu will work seamless through the NAT. You only need to check autoconfigure net, the last of the security options.\n", "Q: Why do my clock, indicator applets, and notification area sometimes move around when I restart? How can I prevent that? I have all of them locked to the panel, but they keep moving around upon logging out and back in.  So, for example, sometimes the Indicator Applet Session is farthest to the right, but sometimes the Clock/Calendar is, and occasionally the Notification Area is.  This is a small issue, but annoying.\n\nA: There is no real solution except to wait for bug #44082 to be fixed. However, there is a (very hackish) workaround. Put your panel applets where you want them, then run gconftool-2 --dump /apps/panel panel_backup.xml. When the applets get messed up, run \n gconftool-2 --load panel_backup.xml\n killall gnome-panel\n\n\nA: I use a simpler and more user friendly solution, IMO, than dumping to XML and restoring (which didn't always work for me, btw).\nSo, the answer to life, universe and everything is (not 42):\n1. Install \"Lockdown Editor\" using Ubuntu Software Center (or whatever you prefer)\n2. Launch \"Lockdown Editor\" under \"System->Administration\"\n3. Under \"Panel\" enable \"Lock down the panels\"  \nWhenever I want to make changes to the panels I disable the setting, make the changes and enable it again. Worked like a charm for me so I hope it helps others too.\nCheers!\n", "Q: How can I change/customize the icons in my notification area? Currently, I can change themes and icons through the Appearance dialog, but this leaves things like the Skype, Dropbox, and Firestarter icons in the notification area unchanged.  Where are these stored?  How do I change them?\n\nA: It really depends on the application. The Skype icon is unchangeable. There is an experimental version of Dropbox that you can change the icon on. You might be able to change the Firestarter icon, but you'd probably have to rebuild from source.\n", "Q: How do I reset my keyboard layout? How can I reset my keyboard layout after modifying it with xkbcomp?\nIs there a way to do this without restarting X?\n\nA: Try:\nsetxkbmap us\n\n(Replacing us with the keyboard layout you want). If using a variant (e.g. intl), try\nsetxkbmap -layout us -variant intl\n\nHere's a list of keyboard layouts.\n\nA: Check current layout and options:\nsetxkbmap -print -verbose 10\n\nReset layout to US and reset options:\nsetxkbmap -layout us -option\n\n(Without the empty -option parameter, no options would be reset.)\nUse the first command to check the result.\n\nA: Use setxkbmap -layout us. It looks to completely reset the changes \n", "Q: Tips to extend battery life for laptops and notebooks \nThis question is present as a matter of historical interest.  While you are encouraged to help maintain its answers, please understand that \"big list\" questions are not generally allowed on Ask Ubuntu and will be closed per the FAQ.\n\nIs it possible to greatly extend the usage time of a laptop or notebook running on battery by disabling various services and installing various packages?\nWhat tricks or tips do people have for getting an extra hour or two out of their batteries?\n\nA: In addition to dimming the display, turning off bluetooth, etc. I sometimes use the CPU Frequency Scaling Monitor to limit the power my processor cores use. You can add it to a panel by right-clicking on a panel, selecting Add to Panel, and finding it in the list.\n\nA: Use powertop to see which programs are doing unneeded background processing such as beagle/tracker, weather notifications, gnome-do, and (if you don't need the internet) network-manager, mail-notifications. \nRun sudo powertop --auto-tune to set all tunable options to their GOOD settings.\n\nA: You can use the terminal app called powertop to find out what is making the cpu \"wake up\". simply install by doing sudo apt-get install powertop and then run by doing sudo powertop\n\nA: Install the package laptop-mode-tools.\nThis package is not necessary on newer versions of Ubuntu:\n\n\n*\n\n*Is \"laptop-mode-tools\" still relevant for 12.04 and the 3.x kernels?\n\nA: Ubuntu provides simple power management under System -> Preferences -> Power Management.  From there, you can configure what happens when running on battery versus on AC power, including screen brightness and sleep/hibernate modes.   Tweaking these settings can give you improved battery life without having to install or configure any extra packages.\nKubuntu has similar options in System Settings -> Advanced -> Power Management.\n\nA: To access power settings click on the battery icon in the status indicator and you can change power preferences.\nThere's also other tools like the gnome cpu-throttler applet if your cpu supports dynamic scaling. power-top can give you an insight into what the most power-hungry applications/services are...\ni've also heard rumors, though seen no evidence myself, that the opensource graphics drivers for nvidia/ati do not support power-saving mode, which would lead to lower battery life. in this case, it might make sense (though i generally wouldn't recommend it) to use the proprietary graphics drivers for your system, as they may have better power-saving.\n\nA: It might be a bit late, but I've just found this out myself. Just search for quiet splash in /boot/grub/grub.cfg and add pcie_aspm=force behind it.\nIt lifted my battery life from 45 minutes to 1 and a half hour! :D\nBe warned\nOn some systems (including my own), the pcie_aspm=force parameter kills the battery in the long run, to the point of it becoming practically useless (10 minutes on a full charge).\n\nA: The Ubuntu Kernel team has written some notes on how to save power here: https://wiki.ubuntu.com/Kernel/PowerManagement/PowerSavingTweaks\nAlso, there are notes on how to identify applications and services that may be sucking power here: https://wiki.ubuntu.com/Kernel/PowerManagement/IdentifyingIssues\n\nA: I've been able to more than double the battery life of my netbook by turning off a bunch of services I don't need, and unloading their kernel drivers.\nUse service --status-all to see what's running on your system, and service <service-name> stop to shut it down.\nUse lsmod to see what kernel modules are loaded, and rmmod <module> to unload it.\nIf/when you want to bring things back, easiest way is to simply reboot.\nSometimes you also need to kill daemons or programs that are using the service or driver before they can be turned off.  Look at output from ps aux to see what's running, and kill -9 <pid> to terminate them.\nServices I usually turn off include:  Ubuntu One, ssh, apache, databases, avahi, pulseaudio, cups, apparmor, acpi-daemon, bluetooth.  Modules I unload:  The whole audio stack, usb_storage, webcam drivers, wireless, bluetooth.  (Some services like audio don't die easily.)\nI've even gone as far as shutting down x (service gdm stop) and working entirely just from consoles, which let me stretch my netbook battery life to nearly 8 hours.\n\nA: Here are a few ideas:\n\n\n*\n\n*Turn off WiFi and Bluetooth\n\n*Reduce screen brightness\n\n*Reduce desktop effects (System->Preferences->Appearance->Visual Effects->None)\n\n*Use Hibernate rather than suspend power features (System->Preferences->Power Management->On Battery Power)\n\n\nA: If you are using an ATI graphics card change to the FLGRX driver. It runs a lot cooler with this driver and so uses a lot less power. There is a bug for this on launchpad.\n\nA: Turn down brightness and shut of wireless , leave screen saver as blank and lower the time when display shuts off on idle.\n\nA: You can install bumblebee if you have an Optimus technology laptop with a nVidia GPU. It will extend your battery life to very good extent.\nTo install it go to  https://wiki.ubuntu.com/Bumblebee\nIt extended my battery life from 2.00 hours to 4.30 hours.\n\nA: Improve Power  Usage / Battery Life In Linux With TLP\nI will Update my answer on Is there a power saving application similar to Jupiter?, please have a look\n\nA: Apart from using Jupiter, I was using TLP and it helped a little. Plus, it is my advice to not use Wubi as it sometimes drains battery faster than the standard install.\nAlso, keeping your drivers updates and installing most stable proprietary drivers helps.\nAnyway, to install TLP use this:\nsudo add-apt-repository ppa:linrunner/tlp\nsudo apt-get update\nsudo apt-get install tlp tlp-rdw\nsudo tlp start\n\n\nA: As I tell with all my clients with laptops - if you have a laptop make sure you are properly discharging and recharging your battery. This greatly extends the life of your battery.\nUbuntu has some great power saving options (System > Preferences > Power Management) Which will allow you to setup functions to help save your batteries life while away from A/C\nOther things to take into consideration - if you're not using Bluetooth or Networking turn off those services (some Vendors even include hardware buttons for this) Dimming your Laptop Display is also a good way to conserve battery power. Lastly straying away (when possible) from CPU/GPU intensive operations will help to conserve battery power.\nEDIT:\nUsually it is said that Lithium ion battery has no memory effect. I read that a lot of times in several different places and chose to believe in it and charge my notebook battery randomly. Don't know if that is the reason, but in two years I ended up with a lousy battery (doesn't last more then 10/20 minutes). On the other side, for my smartphone I almost only recharge when the battery is around 5%, and after two years I almost can't notice any difference in the battery state. I would say it is good luck with the phone, but then I stumble across this article. It is a Nature publication and though I haven't read it all, it says that lithium ion battery do present a memory effect. So be aware that it is relevant to spare your battery of unnecessary charge cicles.\n\nA: You could do something like this to limit cpu-speed\nsudo -i\ncat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_min_freq > /sys/devices/system/cpu/cpu0/cpufreq/scaling_max_freq\n\nThe applet constantly reads stats, not much but is still uses power ;) i often do this in the summer not because I'm away from the plug, but for not overheating my computer.\n\nA: I have 2 hard drives - an SSD which stores / and a larger spindle for storage.\nI set hdparm to spin down the storage drive after 10 minutes of inactivity. In /etc/hdparm.conf put e.g.:\n/dev/sdb {\n    spindown_time = 60\n}\n\nThis works well because I mostly keep music & movies on the storage drive so when I'm in hardcore work mode I don't access it at all.\nAs well as saving power, this makes the laptop noticeably cooler and often the fan will turn off completely if I'm not doing anything too strenuous, giving completely silent running!\n\nA: Are you running through wubi? I find that this makes Ubuntu run slower, lag more, and cause faster battery drains. \nI solved this by keeping my screen dimmest as possible, allowing it to dim to save power, keeping wifi switched off often and closing background programs. \n\nA: You can also use (for example from the Gnome menu-bar) the CPU widget, that offers scheduling options depending on your CPU.\n\nA: Here is some simple tips I use to save my battery :\n\n\n*\n\n*Install TLP :\nsudo add-apt-repository ppa:linrunner/tlp\nsudo apt-get update\nsudo apt-get install tlp tlp-rdw\nsudo tlp start\n\n\n*Disable Bluetooth at startup \nUsing TLP\nsudo nano /etc/default/tlp\n\nUncomment the following line :\nDEVICES_TO_DISABLE_ON_STARTUP=“bluetooth”\n\nUsing Rc.local\nsudo nano /etc/rc.local\n\nAdd the following before the line with exit 0 :\nrfkill block bluetooth\n\n\n*Disable keyboard brightness\n\n*Reduce screen brightness\n\n*Disable networking when not using it (watching movie etc...)\n\nA: For laptops with two or more graphics cards, using the integrated one can save significant amounts of power. \nFor NVIDIA cards, going to PRIME Profiles and switching to Intel (Power Saving Mode) in nvidia-settings cut my power consumption in half and doubled my battery life. \n\nA: A lighter desktop environment will use less power. Take a look at Ubuntu-supported \"flavors\" https://ubuntu.com/download/flavours and consider using a non-GNOME DE.\n\nA: if you want save battery life. click on the battery icon on the task bar then press power saver. really works. if ur gonna go somewhere your not going to use your internet switch if wifi and your internet connection. lower the screen brightness. mute the volume if your not gonna use volume . lower it or just mute it. don't put your laptop on something that's like a blanket bed dirty desk, etc. because these things can heat your laptop and make the fan work more so that will reduce battery energy too. hope this works!!! :)\n", "Q: Why do I need root privileges to umount a drive at the command line, but not in Nautilus? How to change that? When I insert a thumb drive, media card, or USB hard drive, to unmount it via the command line, I need to use:\nsudo umount /media/the_device\n\nBut, I can unmount the device in a file manager like Nautilus simply by clicking the eject button or using the right-click context menu on the device.\nWhat is the rationale for the difference? How can I change it so that I can unmount from the command line without needing root privileges? Is changing it a bad idea? \nEdit:\nIn case it has changed, I am running 9.04. I've run most versions 5.10--9.04, and as far as I recall, it has always been this way.\n\nA: The situation might have changed -- in current Ubuntu 10.04 umount works without sudo for USB drives. Generally I think that the command \ngvfs-mount -u /media/the_device\n\n(gvfs-mount is in the gvfs-bin package) should always work.\n\nA: Nautilus doesn't unmount the device directly; it talks over DBus to a system daemon (udisks-daemon) and asks it to unmount.\nThe daemon checks if you're allowed to do that, by contacting another system daemon, PolicyKit.\nPolicyKit uses the configuration defined in /usr/share/polkit-1/actions/org.freedesktop.udisks.policy (unless the local system administrator overrides it in /etc/polkit-1).  That file tells PolicyKit that users with active console sessions can detatch drives, so PolicyKit talks to a third daemon, ConsoleKit, to see if you have active console sessions.  Logging in via gdm counts as a console session; logging in via ssh doesn't.\nThere's a command-line tool udisks that lets you unmount devices without using sudo, using the same mechanism:\nudisks --unmount /dev/sdb1\n\nthat unmounts the filesystem; I can also detatch the whole device with\nudisks --detach /dev/sdb\n\nwhich makes the LED on my USB key go dark.\n\nA: Current answers are deprecated. Try with GIO command line tool.\ngio mount --unmount *mounted location*\n\nGet the current mounted partitions with, for example:\nlsblk | grep media\n\nReference\n\nGio is a GTK library providing useful classes for general purpose I/O, networking, IPC, settings, and other high level application functionality.\n\n\nGIO provides a portable, modern and easy-to-use file system abstraction API for accessing local and remote files; a set of low and high level abstractions over the DBus IPC specification; an application settings API; portable networking abstractions; and additional utilities for writing asynchronous operations without blocking the user interface of your application.\n\n\ngio mount\nProvides commandline access to various aspects of GIO’s mounting functionality.\nMounting refers to the traditional concept of arranging multiple file systems and devices in a single tree, rooted at /. Classical mounting happens in the kernel and is controlled by the mount utility. GIO expands this concept by introducing mount daemons that can make file systems available to GIO applications without kernel involvement.\n\n", "Q: How do I map unmapped keys on a keyboard? My laptop's keyboard has keys that don't do anything when I press them.  How would I enable the keys, and add functionality to them?\nFor example, the mute key doesn't do anything at the moment.\n\nA: You can use xmodmap. It's how I get my Zboard keys to work. For actual keys not media keys.\n\nA: There's a keyboard shortcuts editor in System->Preferences.\n", "Q: How do I install KDE? I want to have both KDE and Gnome shells on Ubuntu. Ubuntu only has Gnome installed by default. How do I install KDE?\n\nA: If you want to log in from KDE run sudo apt-get install kdm, sudu apt-get remove gdm, and dpkg reconfigure kdm.\n\nA: Just try the following command in a terminal\nsudo apt-get install kubuntu-desktop\n\nThen just select KDE on the login manager.\n\nA: You need to install the kubuntu-desktop package for the full install with the following command.\nsudo apt-get install kubuntu-desktop\n\nThen the next time you login you can choose what to use from the login screen (under Session).\n\nA: On 30/09/2015:\nTo install KDE on Ubuntu  (12.04,14.04,14.10,15.04,15.10) (plasma 5.3)\nsudo add-apt-repository ppa:kubuntu-ppa/backports\nsudo apt-get update && sudo apt-get dist-upgrade\nsudo apt-get install kubuntu-desktop\n\nTo install KDE on Ubuntu (15.04,15.10) (plasma 5.4)\nsudo add-apt-repository ppa:kubuntu-ci/stable\nsudo apt-get update && sudo apt-get dist-upgrade\nsudo apt-get install kubuntu-desktop\n\nNote: To install plasma 5.4,you need to remove backports ppa.\nlaunchpad.net/backports\nlaunchpad.net/~kubuntu-ci/stable\n\nA: Just open synaptic (If not installed yet, install it by ubuntu software center) and search for desktop environment and install plasma-desktop\n\nA: I think the most complete answer is here. According to what you want to install (only the GUI or GUI+some packages).\nCiting the content of the answer:\n\nplasma-netbook and plasma-desktop differ only by whether they\n  install the netbook or the desktop interface. kde-workspace is\n  identical to plasma-desktop.\nkde-plasma-desktop will install a few KDE programs: Dolphin,\n  Konqueror, kde-baseapps, konsole, kwrite, and kde-passwd.\nkde-standard installs a bunch of stuff on top of kde-desktop:\n  Akregator, Ark, Dragonplayer, gnupg, Kaddressbook, Kate, KDE\n  wallpapers, Kmail, etc.\nkubuntu-desktop installs even more than kde-standard. kubuntu-desktop\n  is the package you would download from the Ubuntu website if you\n  wanted Kubuntu, but if you only want the Plasma interface, not any of\n  the default programs, plasma-desktop might be sufficient.\n\nChoose the package you want and then run sudo apt-get install package-name\n\nA: To get just the plasma environment (on 12.04 and newer):\nsudo apt-get install plasma-desktop\n\nIt worked fine for me on 15.10\n", "Q: What Ubuntu server administration books does the community recommend? What book would you recommend as a reference for Ubuntu server administration?\nI'd like to not limit this to server-edition. I'm biased toward development environments that need to strike a balance somewhere between desktop & server.\nOne book per answer, please - vote answers up/down as you feel appropriate. If you feel the book is biased towards/good for particular tasks, please mention them.\n\nA: I recommend the Official Ubuntu Server Book.\n\nA: If you work with your Ubuntu Local team you can get a free copy of the Ubuntu Server book as Jono mentioned and is posted on the Fridge here: http://fridge.ubuntu.com/node/2094.\nAlso I enjoyed this one: Beginning Ubuntu LTS Server Administration: From Novice to Professional even though it is a bit older\n\nA: The Ubuntu Server Guide(PDF) is free and written by the Ubuntu developers.\n", "Q: What does \"Ubuntu\" mean? What does \"Ubuntu\" mean, and why did they choose that particular name?\n\nA: When I started using Ubuntu I have also found this definition:\n\nI am who I am, because of who we all are.\n\nSlightly shorter than the previous answer ;-)\nAnd the name was chosen by SABDFL.\n\nA: Ubuntu means: \n\"A man can't be a man without the help of other men\"\n\nA: The word of Ubuntu is very difficult to explain in one word in English. Some people say it means \"humaness, to be human\", some describe it as \"Humanity in humility\".\nSee the discussion in the ubuntu forum\nBishop Tutu has describe Ubuntu as:\n\nA person with Ubuntu is open and\n  available to others, affirming of\n  others, does not feel threatened that\n  others are able and good, for he or\n  she has a proper self-assurance that\n  comes from knowing that he or she\n  belongs in a greater whole and is\n  diminished when others are humiliated\n  or diminished, when others are\n  tortured or oppressed.\n\nand \n\nOne of the sayings in our country is\n  Ubuntu - the essence of being human.\n  Ubuntu speaks particularly about the\n  fact that you can't exist as a human\n  being in isolation. It speaks about\n  our interconnectedness. You can't be\n  human all by yourself, and when you\n  have this quality - Ubuntu - you are\n  known for your generosity.  We think\n  of ourselves far too frequently as\n  just individuals, separated from one\n  another, whereas you are connected and\n  what you do affects the whole world.\n  When you do well, it spreads out; it\n  is for the whole of humanity.\n\nNelson Mandela describes it as\n\nA traveler through a country would stop \n  at a village and he didn't have to ask for food \n  or for water. Once he stops, the people give him \n  food, entertain him. That is one aspect of Ubuntu \n  but it will have various aspects. Ubuntu does not \n  mean that people should not enrich themselves. \n  The question therefore is: Are you going to do so \n  in order to enable the community around you to be able to improve?\n\nfound in wikipedia\n\nA: Ubuntu:\n\"I am Because we Are\"\ni also find it a great slogan for Ubuntu.\n\nA: Our work is driven by a belief that software should be free and accessible to all.\nWe believe that every computer user:\nShould have the freedom to download, run, copy, distribute, study, share, change and improve their software for any purpose, without paying licensing fees.\n    Should be able to use their software in the language of their choice.\n    Should be able to use all software regardless of disability.\n    Our philosophy is reflected in the software we produce, the way we distribute it and our licensing terms, too - Ubuntu Licence Policy.\nInstall Ubuntu and you can rest assured that all our software meets these ideals. Plus, we are continually working to ensure that every piece of software you could possibly need is available under a licence that gives you those freedoms.\nFree software\nUbuntu software is free. Always was, always will be. Free software gives everyone the freedom to use it however they want and share with whoever they like. This freedom has huge benefits. At one end of the spectrum it enables the Ubuntu community to grow and share its collective experience and expertise to continually improve all things Ubuntu. At the other, we are able to give access to essential software for those who couldn’t otherwise afford it – an advantage that’s keenly felt by individuals and organisations all over the world.\nQuoting the Free Software Foundation's, 'What is Free Software,' the freedoms at the core of free software are defined as:\nThe freedom to run the program, for any purpose.\nThe freedom to study how the program works and adapt it to your needs.\n    The freedom to redistribute copies so you can help others.\n    The freedom to improve the program and release your improvements to the public, so that everyone benefits.\nOpen source\nOpen source is collective power in action. The power of a worldwide community of highly skilled experts that build, share and improve the very latest software together - then make it available to everyone.\nThe term open source was coined in 1998 to remove the ambiguity in the English word 'free' and it continues to enjoy growing success and wide recognition. Although some people regard ‘free’ and ‘open source' as competing movements with different ends, we do not. Ubuntu proudly includes members who identify with both.\nhttp://www.ubuntu.com/project/about-ubuntu/our-philosophy\n\nA: To quote the About Ubuntu page on the website:\n\nubuntu |oǒ'boǒntoō|\nUbuntu is an ancient African word meaning 'humanity to others'. It also means 'I am what I am because of who we all are'. The Ubuntu operating system brings the spirit of Ubuntu to the world of computers.\n\nTo quote Benjamin Mako Hill:\n\nUbuntu's original name was, and I'm serious, \"no-name-yet.com\"\nFinally, Mark settled on the name Ubuntu which he though represented\n  the spirit of sharing and cooperation that he found appealing in Free\n  Software.\n\nAnd finally, to quote Mark Shuttleworth himself in the Ubuntu 4.10 Warty Warthog announcement:\n\n\"Ubuntu\" is an ancient African word for \"humanity towards others\", and\n  we think it's a perfect name for an open source community project.\n\nHopefully, these quotes help clear up any confusion about the name, 'Ubuntu', that you might have had.\n\nA: Don't forget the humorous definition! :)\nUbuntu is an ancient African word that means \"I can't configure Slackware\"\n", "Q: How to run Windows XP inside Ubuntu There are several programs only available on Windows. \nWine can be a negative experience, so I want to run Windows inside Ubuntu using a virtual machine. It seems that Virtualbox is the standard way, but I don't have any experience with it.\n\nA: Virtualbox is a great choice if Wine doesn't work with a particular application. However, if a program does work well in Wine, Virtualbox may not be preferable, due to the inherent performance loss and the need to boot a full Windows OS. It can also be tricky if you do not have an extra copy of Windows available for installation, because it does involve a fresh install.\nI was going to say that DirectX 3D games and apps were out of the question, but research seems to indicate that it now has Direct3D support.\n\nA: VMWare workstation and VMWare player (free) are also options.\n\nA: I use Virtual Box and it works great.\nIt's pretty simple to use.  After installation, just click the \"New\" button in the toolbar, and a wizard will walk you through creating the VM.\nAfterwards, click \"settings\", go to \"storage\" and mount the installation media (either as an .iso or the physical drive itself).  Click \"ok\".\nNow you can start the VM and it should allow you to install the OS.\nHere is an introduction article on virtualization on workswithu.com.  Click on the tags at the bottom of the article for even more info.\n\nA: In addition to VirtualBox being a perfect solution by technical means, I also find the user experience to be better. If you use a Windows application with Wine, you suddenly have some window on your Ubuntu desktop which may look completely out of place. Technically it runs in Ubuntu, but it often doesn't behave like your remaining Ubuntu applications.\nWith VirtualBox the separation between both environments is a bit more clear, because you expect the applications inside VirtualBox to behave like Windows applications. This makes the \"mental switching\" easier and therefore improves your user experience.\n\nA: Virtualbox is excellent. And  strangely Windows XP for me runs quicker in Ubuntu (as a guest) than it ever did in real life! Also oddly the Windows XP recognised my sound card, wireless etc. without the fiddling I had to do when I was using it for real! I have to say that Wine can be useful but the \"real thing\" works quicker in a virtual XP - I love Ubuntu just that it can't do certain things (Windows is the same) - nothing wrong with that; I tend to think that certain Linux users take a special pride in avoiding Windows at all costs, and stick with some pretty shaky Wine emulations just to say it works (just)! Top tip for installation of Virtualbox seems a minor point - make sure your Windows CD is nice and clean and you've got it in the correct CD Draw (if you have two) - for some reason any tiny flaw on the CD seems more likely to upset the virtual machine than it would in a real installation. Secondly my Windows is a OEM version and it worked, just have your product code to hand - and it works, and activates the product via the internet. What's great if you try to install your OEM windows on a different computer it will often go mad, and you may lose your drivers for onboard sound etc. - with Virtual Box XP no problems - works right out the box. \n\nA: The best way is to run it as a VM. So yes, virtualbox is a good choice.\n\nA: You can give Virtual Box (http://www.virtualbox.org/) a try. It sets up a virtual machine inside your XP opeating system without losing anything. Moreover Virtual Box is free.\n\nA: I highly recommend at least testing the applications in Wine before virtualizing them.  When Wine does work there are some important benefits over virtualization: performance is noticeably better, they're easier to run (links right off the Application menu), and they become integrated with the system (easy access to the files in your home folder, no windows in windows, and if they have a system tray icon it sits in the panel).\nIf every app you need works in Wine, then you also get the added benefit of not needing a copy of Windows for your virtual machine.\nAn alternative to testing them in Wine is to look them up in Wine's application database: http://appdb.winehq.org/\nCurrently, I also recommend using my packages from the Wine PPA rather than the packages that come with Ubuntu (which are also mine).  You can get instructions here: https://wiki.winehq.org/Ubuntu -- on 14.04, 16.04, and 17.10 you can install either the wine2.21 or wine3.3 (beta) packages.  The 2.21 one will remain stable, while the 3.3 will receive updates as new Wine releases come out -- which means 3.3 will generally work with more apps, but might break on an update as well.\nThe main advantage of using the PPA packages is that you can find an exe file and just right click->open with Wine without having to manually set it as executable.\n\nA: QEMU and KVM worked great for me.I installed Windows 10 inside Ubuntu 18.04, and\nI can not notice much difference from running a normal installation.\nA good tutorial is here:\nhttps://dennisnotes.com/note/20180614-ubuntu-18.04-qemu-setup/\nTo avoid Windows installation errors, I needed to allocate enough disk space (32 Gb for Windows 10). To avoid 10-30x times slowdown I needed to enable virtualization in BIOS before the installation started.\n\nA: Oracle VM VirtualBox is a program that allows you to create operating systems on virtual machines, i.e. to use Windows programs on Linux. If a program doesn't work under WINE, for example, it will probably work in its native environment, Windows. Using VirtualBox would be a better and easier alternative than installing a separate partition for Windows on a Linux machine. \n", "Q: Is there a way to add Mozilla Thunderbird to the messaging menu? I use Thunderbird instead of Evolution for my mail client, so I'd prefer if I could replace Evolution with Thunderbird in the messaging component of the Indicator applet.  Does anyone know how to do this?\n\nA: If you want to install the plugin for all users, it's better to use the upstream's PPA:\nsudo add-apt-repository ppa:ruben-verweij/thunderbird-indicator\nsudo apt-get update && sudo apt-get install xul-ext-indicator\n\n\nA: You want the Mozilla Notification Extensions, aka messagingmenu-extension.  \n\nBut it will not delete the evolution entry, to do that you need to remove /usr/share/indicators/messages/applications/evolution\nThe upstream source for the addon is available on Launchpad if you care to inspect it. \nRelated: \n\n\n*\n\n*How can I remove \"Set Up Mail\" and other entries from the message indicator?\n\nA: You could also use the generic email notifier 'Popper'. It works with all kinds of POP or IMAP accounts and can launch all email clients (Evolution, Thunderbird, whatever you want). You will find it here: https://launchpad.net/popper\nArticles and reviews are available at: http://www.omgubuntu.co.uk/\nJust search for 'popper'.\n\nA: My add-on was made to replace to evolution, but If you want remove the evolution indicator and maintain the evolution, only you need deinstall evolution-indicator package (sudo apt-get remove evolution-indicator)\nIf you want the evolution-indicator back, reinstall evolution-indicator (sudo apt-get install evolution-indicator). You need restart your session after uninstall or reinstall the package\n\nA: I understand that this is the simplest way to do it: An add-on for thunderbird that works excellent: http://danjared.wordpress.com/proyectos/ubuntu-thunderbird/ the site is in Spanish but use a simple translate and you'll be able to understand. I do have one question: If I eliminate the panel indicator for Evolution mail client, how can I bring it back. I don't plan on removing Evolution, I just want it out of the panel.\n", "Q: How to remove an uninstalled package's dependencies? I want to install a package (DigiKam), but it has a lot of dependencies. If I decide I no longer need this software and uninstall it, will the now unnessary dependencies be removed?\nIf not, how can I do it manually?\n\nA: You can use the command apt-get autoremove. It will remove packages that are installed as automatic dependencies, but are not depended anymore.\napt-get has a flag --auto-remove that can be used to automatically remove the automatically installed packages when removing a manually installed package:\napt-get remove --auto-remove packagename\n\nCertain other tools are also capable of doing this, for example aptitude will automatically suggest that you remove the packages that have been orphaned.\nThe automatically installed packages tracking is built in to apt so the tracking should work no matter which tool you use to install the packages.\n\nA: The Computer Janitor, in the system menu can do this too.\n\nA: I use ubuntu tweak, it has a very effecient app cleaning utility that has never removed more then it should.\n\nA: sudo apt-get remove --auto-remove \n\nOnly run this.\nInstall BleachBit from Software Center. When you clean ur system using it, BleachBit will automatically run this command to clean the apt cache.\n\nA: aptitude purge digikam\ndeborphan\naptitude purge $(deborphan)\n\ndeborphan lists packages which are not used or do not depend. So you can safely uninstall them. I tend to use purge as option of aptitude because it removes also config files and other stuff.\n\nA: I had the same problem. Here is what I did:\nsudo apt-get check\n\nThis command will provide the name of dependencies. E.g. my system had chromium-browser-l10n.\nThen enter the following command \nsudo apt-get remove --auto-remove chromium-browser-l10n\n\nIt will remove the dependencies completely from your system \n", "Q: What is the proper way to patch Wine for a custom PPA? I've been manually applying patches to Wine for use on my own machine, but I want to put it in a PPA for my friends and relations.\nCurrently I follow this procedure:\n\n\n*\n\n*Get the latest source from an upstream PPA via apt-get source\n\n*Use patch to apply my unofficial, unsupported patches.\n\n*Create a package using dpkg-buildpackage -rfakeroot -uc -b\nThis is fine for creating a package that will run on my local machine. However I now want to distribute this custom build to others via a PPA.\nIs this procedure sufficient, or is there a more correct and/or easier to maintain procedure I should be following specifically for Wine?\n\nA: The Ubuntu Packaging Guide has all the information how to package for Ubuntu including howto deal with patches.\n\nA: You're pretty close with your example steps, but here's what I'd suggest:\n\n\n*\n\n*Grab the sources with apt-get source wine and cd into the new directory\n\n*Find what sort of patch system the wine package is based on: what-patch; in this case, it tells us we that the wine package uses quilt for patch management\n\n*Since we're using quilt, add your custom patch(es) to the quilt series: QUILT_PATCHES=debian/patches quilt import <your-patchfile.patch>If you have multiple patches, do this for each patch, in the order that you want them applied.\n\n*Add a suitable entry to the debian/changelog file - you'll need to alter the version number to ensure that your PPA version is differentiated from the official version. Typically, you should increment the last version number, and add a tilde (~) followed by your custom version string (eg ~jbowtie1). The dch -i command can help with this too.\n\n*Build the source package:debuild -S\n\n*Upload your source package to the PPA build system: dput ppa:<your-ppa> ../wine*.changesThe <your-ppa> parameter is specified on the launchpad page for the PPA you want to upload it to (you'll have to create this beforehand).\n\n\nIt's usually a good idea to do a test build before doing the dput - the pbuilder command allows you to recreate what the PPA build system would do with your package (ie, start from a clean install, add required deps, then build).\nIn this case you would have to set up pbuilder first (see https://wiki.ubuntu.com/PbuilderHowto), then do this before the dput:\nsudo pbuilder build ../*.dsc\n\nA: You need to first build a source package-\nhttps://wiki.ubuntu.com/PackagingGuide/Basic#Building%20the%20Source%20Package\nPushing it to a PPA is very easy for Ubuntu 9.10 or later\nJust go to Terminal and type\ndput ppa:your-lp-id/ppa <source.changes>\n\n\nA: Jeremy's answer is straight to the point.\nAlternatively, you can use bzr to handle the source, patches and building/upload.\nSee https://wiki.ubuntu.com/DistributedDevelopment, starting with https://wiki.ubuntu.com/DistributedDevelopment/Documentation.\nWhile is simplifies some steps, e.g. merging for new upstream versions (if you plan to get ahead of the original Ubuntu package), the original \"apt-get source\" approach is probably more straight and easier in the end.\n\nA: From the winehq website:\nOpen the Software Sources menu by going to System->Administration->Software Sources. Then select the Third Party Software tab and click Add.\nThen, copy and paste the line below.\nppa:ubuntu-wine/ppa\nThen run sudo apt-get update and after it's done sudo apt-get install wine\n\nA: Ubuntu Tweak includes a PPA for Wine, once it is selected in Ubuntu Tweak it will stay updated via regular updates\n", "Q: How do I make Evolution check and notify new emails, without keeping main UI open?   How do I make Evolution keep checking my emails and notifying in the indicator applet without keeping the main UI open?\n\nA: As far as I know this is not possible at the moment. There is already a bug report at launchpad: https://bugs.launchpad.net/ubuntu/+source/evolution-indicator/+bug/508608\n\nA: You could try installing 'mail-notification-evolution', its supposed to provide support for Mail Notification. I had some problems using it, but some people have had better luck than me.\nsudo apt-get install mail-notification-evolution\n\n\nA: sudo apt-get install alltray\n\nThen start Evolution from AllTray. That'll give Evolution the ability to hide in the Notification Area.\n\nA: Use this program, it integrates with current ubuntu notification (envelope becomes green when new mail arrives):\nhttps://launchpad.net/cloudsn\n", "Q: Something similar to Eyefinity? Is there anything simular to Eyefinity for Ubuntu?  More the idea of turning 3 smaller monitors into one big monitor\nThanks\n\nA: The newly released (proprietary) 10.7 Catalyst drivers from ATI specifically support Eyefinity under Ubuntu 10.04 (Lucid).\nThe proprietary NVidia drivers also support multiple monitors rather well, allowing you position them in relation to one another.\nIn theory the Monitor Preferences also supports configuring multiple monitors in this way, but reports on the Ubuntu forums are mixed and I have no way to test this personally.\n", "Q: How to shutdown the computer when hitting the Power button? I have a Xubuntu Lucid 10.04 computer plugged in to my TV. I use the command line to administrate it.\nRight now when I hit the power button it just opens a Logout screen.\nHow can I set it up so that I can shut it down by hitting the power button?\nI know it has something to do with acpi or acpid.\nI want answers to be command-line only as I do not have any keyboard or mouse connected to that computer.\n\nEdit:\nIsn't there a way to modify the default behavior of the xfce4 power manager when pushing the power button?\nAlso instead of using the GUI to do so, can I do it by creating/modifying a configuration file?\njbowtie had an interesting answer but I cannot find the xfce4-power-manager.xml file. If someone knows where to find that file or how to create it, I would be interested.\n\nA: When you hit the power button, the script /etc/acpi/powerbtn.sh is called. So one option is to modify this script to just call the shutdown script, bypassing the power management daemon. This works across all distributions and environments that I know of.\nSince you're using Xubuntu, you can however just change the setting 'power-switch-action' in xfce4-power-manager.xml to the shutdown action - the default value is the ask action.\n\nA: I found a solution. jbowtie put me on the right tracks. Kudos to him.\nThe problem was I did not have any xfce4-power-manager.xml file and I did not know exactly where to find the file and how to modify the file, but I found that I needed to copy the file from /etc/xdg/xfce4/xfconf/xfce-perchannel-xml/xfce4-power-manager.xml and use xfconf-query to modify it properly.\nThe shutdown action for /xfce4-power-manager/power-button-action seemed to be 4.\nHere's what I did:\ncp /etc/xdg/xfce4/xfconf/xfce-perchannel-xml/xfce4-power-manager.xml $HOME/.config/xfce4/xfconf/xfce-perchannel-xml\nDISPLAY=:0.0 xfconf-query -c xfce4-power-manager -p /xfce4-power-manager/power-button-action -s 4\n\n\nA: You are indeed right about ACPI.\nThis forum post is exactly what you're looking for.\nIt details the steps you need to take far better than I ever could explain it :)\nEdit: Basically, the solution was to install acpid.\n", "Q: FTP connection problems in Nautilus - seems to time out after a while I have no trouble connecting to my FTP server by going to Places > Connect to server...\nI can then browse the FTP site to my heart's content with Nautilus for a few minutes.\nAfter a few minutes of inactivity, if I try to bring up a folder on the site, Nautilus just displays a blank page.\nThe only remedy is to unmount the FTP site and reconnect.\nThis is quite annoying - is there some timeout issue at play here? Is there some way that I can prevent this from happening?\n\nA: You could probably extend the timeout in your system. Open the gconf-editor using sudo gconf-editor and navigate to desktop -> gnome -> session. There you find a key idle_delay. You can change that value by double-clicking on it. Depending from how long you are typically inactive you change it. So if you usually don't have FTP activity for half an hour set it to a value larger than 30.\nThere is also an entry in Ubuntus bug tracker and in GNOME bug tracker. GNOME seems to work on a fix.\n\nA: Probably not preventable easily on your end, and a timeout issue is the most likely cause. \nThat's a bug against gvfs, which would have to be modified to automatically handle such a situation. In the interim, I'd just remount as you've been doing. \nYou can report a bug against gvfs on Launchpad.\n", "Q: Why will Ubuntu no longer measure file size unit as byte, megabyte, gigabyte, etc? I read on somewhere that Ubuntu will no longer use the familiar file size units we all know by now (kB, MB, GB, TB) and switch to a different IEC standard (KiB, MiB, GiB, TiB). If this is true, I would like to know what's the reasoning behind this change, and the impact (if any) this change has, especially with multiplatform applications or applications run with Wine.\n\nA: Short answer is yes, the prefixes change. But it doesn't really make a difference.\nReasoning\nThere has always been confusion because decimal-style units like KB, MB, GB were used with binary data - KB meant 1024 bytes, not 1000 bytes as might be expected. And of course many people throughout the world use the actual decimal prefixes in their daily lives under the metric system.\nNetwork engineers and long-time computer users of course are trained to understand the difference, but the ongoing confusion meant applications were inconsistent in their usage; one application might use MB to mean 1,000,000 bytes (using the decimal prefix), while another might mean 1,048,576 bytes (using the binary interpretation).\nThis led to Ubuntu eventually adopting a new units policy.\nImpact\nThe impact is really just a display issue. File sizes and network bandwidth will be displayed using the decimal prefixes, so a 5kB file will actually be 5000 bytes. This is actually in line with what many (most?) people expect.\nMemory usage and some low-level utilities will display sizes using the binary prefixes (KiB, MiB, GiB, TiB). This may cause some initial confusion but is actually better than the status quo where we have one prefix meaning two different things.\nSince Windows still uses the old, ad-hoc system a Wine application might display slightly different file sizes for the same file. However I at least often see different sizes displayed anyway due to rounding methods, so I'm not convinced it's a major issue.\nSee also:\n\n\n*\n\n*What file size units do applications on Ubuntu use?\n\nA: IT IS SOOOO... SIMPLE!!!\nA few years ago there was very little confusion about this. Because the notation\n\n\n*\n\n*1 KB = 1024 bytes\n\n*1 MB = 1024 KB\n\n\nwas taught, learned and used in all universities and almost all the industry (software and hardware) around the world, during many years.\nThe stupid idea of counting in base 1000 (not even base 10) is only another symptom of the stupidity of our times and modern life.\nWhat makes things much much worse is the more stupid idea of trying to establish (and continue to do it) the old notation for the unpractical 1000-base units. THAT HAS CREATED ALL THE CONFUSION. If they had only adopted the convention that\n\n\n*\n\n*1 KiB = 1000 bytes\n\n*1 MiB = 1000 bytes\n\n\nthen there would be much less confusion and the problem would be much smaller.\nThey should have tried to establish that\n1KB = 1024 bytes\n1MB = 1024 KB\n\nand\n\n1 Ikb or ikb or Kib = 1000 bytes\n1 IMb or imb or Mib  = 10^6 bytes\n\nThere is absolutely no need to use base-1000 units. Probably the idea started in a stubborn mind that said \"oh, no, if kilo is 1000 and mega is 1,000,000, we are going to use kilo and mega in base-1000 for information units (base 2!)\". All that just because one day, but that was much longer time ago, someone had the unfortunate idea (not so bad, though) of calling kilobytes (kb) a bunch of 1024 bytes. If he had chosen k2b and m2b, and call them  kitwo bytes and mitwo bytes (or kookie bytes, mookie bytes and gookie bytes), for example, all this retarded idea  of using base-1000 for all the applications and a whole operating system, and imposing it as the normal way of talking about measures in HW and SW to the peolpe, wouldn't be happening, which makes things much worse.\n\nA: It is indeed confusing what happened regarding the changes of designation of sizes back in 1998 and would have been much simpler if they had simply added a new set in powers of 10 as a new designation but sadly they did not do so because the reasoning at the time was centered around correcting the etymology of the word used \"Kilo\" so all the original sizes based on powers of 2 (1024) were all given new names and new designations and then the new power of 10 numbers assumed the pre-1998 original label names.\nSo let the confusion begin:\nPrior to 1998, a Kilobyte meant 1024 bytes and was designated as K or KB.\nAfter 1998, the original pre-1998 Kilobyte was renamed to Kibibyte and \ngiven the new designation K or KiB and a brand new post 1998 Kilobyte\nwas created which is 1000 bytes and has the shorthand designation KB\nso that today we have the following:\n1 KB =  1000 Bytes   (KB cannot be shortened to K)\n1 KiB = 1000 Bytes   (KiB may be shortened to K) \nThe designations were all amended so that KB is the official shorthand that refers to the current Kilobyte (1000) while K and KiB officially are the official shorthand designations for Kibibyte (1024).\nIt gets especially confusing because most of us who were around the early days long before 1998 grew up used to calling Kilobytes as 1024 bytes and writing either KB or K as the shorthand designation but today that is wrong and all of us doing this are actually referring to \"Kibibytes\" when we say \"Kilobytes\" and often using the wrong designation per officially inacted world standards set forth by the IEC back in 1998 which is confusing a bit but would not be so bad except that there is now even 18 years later many people who still do not realize that K and KB are NOT the same and are totally different.\nSo there really is actually a difference between \"K\" (1024) and \"KB\" (1000)!\nThis incidentally is also the very reason why hard drives always seem to have much less space than they advertised but the hard drive manufacturers are the ones who are correct and are using the present day proper standards when they write \"Terabyte\" on the packaging when the person buying the drive is actually however thinking in terms of Tebibytes and expecting space as such.\nIncidentally, the difference between a 2 TB (Terabyte) and a 2 T or 2 TiB drive (Tebibyte) is a very sizable huge 199,023,255,552 bytes smaller than what a 2 T or 2 TiB drive would be and is the difference smaller of the magnitude of a little over 185 G or GiB (Gibibytes) which is what most people ironically actually think of most often when they say \"Gigabyte\" albeit mistakenly.\nThis is one of the weird side lessor known FYI's in the computer world that is a good footnote to know and explains a few of the odd discrepancies that many people today are often completely unaware.\nMany people are thinking of and saying the name \"Kilobyte\" (1000) when they actually are thinking of the unit \"Kibibyte\" (1024) and it gets more confusing as people write the shorthand interchangably but this is incorrect, the modern Kilobyte should be marked \"KB\" and should not be \"K\" or \"KiB\" anywhere in any documentation or program which as just explained would actually refers to Kibibyte (1024).  \nThe shorthand designations K (1024) and KB (1000) are no longer the same thing and in the case of Kibibyte, either K or KiB may be used but not KB.\nThis is your brain, this is your brain on Kibibytes -- fried yet?\nLOL\n", "Q: Is there an apt-get package for Sphinx search? I would like to know if there is a package for Sphinx search hiding out there somewhere. Their download page shows various RPM's, but I was not able to find anything for Ubuntu.\nThe install from source is super easy, but it would be nice to have it under package management.\n\nA: You can use checkinstall when installing from source; it will create a .deb file and install the generated package.\nThere are more details on the wiki, but, briefly, instead of:\nsudo make install\n\ndo:\nsudo checkinstall\n\nand Sphinx will be under package management.\nNote that the generated package is really only good for the machine you created it on as it's only for one architecture and lacks most of the important metadata needed for distribution (like prerequisites). However it will allow you to upgrade or uninstall cleanly.\n\nA: You can add latest stable build releases for 2.2.* of sphinx search to your system.\n$ add-apt-repository ppa:builds/sphinxsearch-rel22\n$ apt-get update\n$ apt-get install sphinxsearch\n\nmore info about repository: https://launchpad.net/~builds/+archive/ubuntu/sphinxsearch-rel22/\nPS: Sorry for responding to old question, but ubuntu still thinks the ,,best'' version is 2.0.4 and i needed 2.2.7 (latest) and after some research i found this solution.\n\nA: sudo apt-get install sphinxsearch\nUbuntu Packages: Sphinx Search (Lucid)\n\nA: The apt-get install sphinxsearch gives you version 0.9.8, at the download site from Sphinx itself it's at 2.0.8... You might want to not use the apt-get version if you want up-to-date search capabilities.\n\nA: From the sphinx documentation \nInstalling Sphinx packages on Debian and Ubuntu\nThere are two ways of getting Sphinx for Ubuntu: regular deb packages and the Launchpad PPA repository.\nDeb packages:\nSphinx requires a few libraries to be installed on Debian/Ubuntu. Use apt-get to download and install these dependencies:\n$ sudo apt-get install mysql-client unixodbc libpq5\n\nNow you can install Sphinx:\n$ sudo dpkg -i sphinxsearch_2.2.1-beta-0ubuntu11~precise_amd64.deb\n\nPPA repository (Ubuntu only).\nInstalling Sphinx is much easier from Sphinxsearch PPA repository, because you will get all dependencies and can also update Sphinx to the latest version with the same command.\nFirst, add Sphinxsearch repository and update the list of packages:\n$ sudo add-apt-repository ppa:builds/sphinxsearch-daily\n$ sudo apt-get update\n\nInstall/update sphinxsearch package:\n$ sudo apt-get install sphinxsearch\n\nSphinx searched daemon can be started/stopped using service command:\n$ sudo service sphinxsearch start\n\n2.4. Installing Sphinx packages on RedHat and CentOS\nCurrently we distribute Sphinx RPMS and SRPMS on our website for both 5.x and 6.x versions of Red Hat Enterprise Linux, but they can be installed on CentOS as well.\nBefore installation make sure you have these packages installed:\n$ yum install postgresql-libs unixODBC\n\nDownload RedHat RPM from Sphinx website and install it:\n$ rpm -Uhv sphinx-2.2.1-1.rhel6.x86_64.rpm\n\nAfter preparing configuration file (see Quick tour), you can start searchd daemon:\n$ service searchd start\n\n", "Q: How can I keep a folder synchronized to an external USB hard drive? I have a growing music collection which I manually keep in sync with an external USB drive. Sometimes I edit their ID3 tags, add or delete a file in either the hard drive or the USB drive, and I would like to keep those changes synchronized between both.\nDoes Ubuntu has something available that would help me with this scenario? Preferably something easy to use with a UI.\nUpdate: To clarify my question, changes may happen on both the local hard drive or the USB drive, so the sync process must be on both directions.\n\nA: I know it's an old question, but, as it might be an answer for someone, I wanted to say I'm giving FreeFileSync a try, an opensource application bundled with another utility, named RealTimeSync. This last one triggers a command (presumably, FreeFileSync, but I believe you can actually execute any command line) whenever the contents of a folder is changed (or when that folder becomes available).\nI will update outcomes, but, at first glance, looks promising (despite the scarce and windows-oriented documentation).\nUpdate: seems to work well. I set RealTimeSync to watch for availability and/or changes of two folders (source and destination) and run a Sync job when that happened, and all went well. Deletions propagated, too, with a (I think) nice feature: deleted files (those deleted by FreeFileSync as a result of the syncing) go to a folder inside trash (or inside a folder of your choice), named with FFS+time-date stamp.\nStill have to test it under hard conditions (large syncing jobs, over a large amount of files) to check speed of file comparison. Will do tomorrow.\n\nA: I think the best software for this situation would be DirSyncPro (V1.4). You can check their website here. This software is written using java, hence it does not have to be installed and is very portable. It has several features like backup, synchronizing files, mirroring drives and is a freeware solution. \nIt is under active development and you can guarantee to get new features frequently.The software is mature, stable and an ideal backup software. Give it a try without any hassle of installation.\nI have attached a screenshot of the software below.\n\nIt works both bidirectional and mono-directional making it an ideal backup software. You can also schedule backups, create exception and save the job preferences thereby not having to create one every time you want to backup something.\nI am just a user of this software, very impressed by its reliability and features that it possesses. \n\nA: Well, rsync is a great command-line tool for this.\nYou mentioned that you wanted a GUI, so I recommend Gadmintools which contains gadmin-rsync.\n\nUpdate: Try giving Unison-GTK a try.\n\nA: I usually use rsync in these scenarios; there is a GUI version called grsync but I don't know how easy it is to use.\n\nA: This is a bit of an old question, but (in 2021) I just found Syncthing.\nSeems to be exactly what I am looking for and it has a big open source community behind it.\n", "Q: How do I check / modify LVM state on a pre-installed system? So I just got a nice little home server (not 100% a server, it's also destined to run a few GUI jobs, but, mostly) configured to my specs, and it came with Ubuntu 10.4 pre-installed by the guys who put it together (who aren't Ubuntu specialists, but do that for customers who don't want to purchase Windows).\nNow, I'd like to check (and perhaps modify) exactly how they installed it (maybe it would be wiser to reinstall from scratch, but first I'd like to understand exactly how it's configured now, anyway).\nIn particular, how do I check if and how LVM is installed/configured?  I'd prefer a command-line approach, but GUIs are fine too -- and pointers to docs and tutorials on the subject are welcome too.\n\nA: LVM is a pretty complex system and requires some knowledge before you can fully start to inspect the state. There are quite a few howtos lying around on the subject, but here is a crash course:\nFirst of all, LVM is structured so that you pool physical partitions or volumes in to groups that then get split to logical volumes that are used by the operating system. All of these can be inspected with their own set of tools. Physical partitions (or volumes) can be inspected and modified with the pv* tools. Volume groups are inspected and modified with the vg* tools and finally the actual volumes that are used as filesystems can be inspected with lv* toolset.\nHere is a good example on LVM structure\nFor inspecting the state of LVM you can use lvs, vgs or pvs commands. This will allow you to see how much space is used and where that space is allocated.\nYou can alter the size of logical volumes with the lvresize command, but be very careful when doing so. The LVM doesn't allow data to be stored outside of the logical volume like regular partitions. So if you shrink a partition by mistake and make it smaller than the filesystem, you will loose the data outside of the partition. Also when you resize a partition you need to resize the filesystem too, it is not automatically resized.\nFinally, here is a full LVM HOWTO covering the bits I've left out here.\nLVM is really powerful and useful. Once you get to know it, you don't really want to use anything else.\n", "Q: How do I find the package that provides a file? Simple enough question: is there some shell command (or GUI method) I can use that, given the path to a file on my system, tells me what package put it there? Assuming the file did in fact come from a package, that is.\nBonus question: what if it's a file that isn't installed on my system? Is there, say, a website that will let me look up a file and see what packages, if any, provide it?\n\nA: This is an extension to Alexx Roche's excellent answer. I tried to make an edit to that answer, but it got rejected (though not by Alexx)\n\nI was trying to track down what installed which on my system. After a little work I created /usr/local/bin/apt-whatprovides\n#!/bin/sh\n#apt-whatprovides ver. 201801010101 Copyright alexx, MIT Licence\n#rdfa:deps=\"[realpath,apt-file,grep,which,sh,echo]\"\n\nBINARY=\"$(realpath $(which $@) 2>/dev/null)\"\n[ -z \"$BINARY\" ] && BINARY=\"$@\"\necho Searching for $BINARY\nPACKAGE=\"$(apt-file search $BINARY|grep -E \":.*[^-.a-zA-Z0-9]${BINARY}$\")\"\necho \"${PACKAGE}\"\n\nThough for most THINGs that are installed you can just use:\napt-file search $(realpath $(which THING)) | grep 'THING$'\n\nFor THINGs that are not installed, you can use:\napt-file search THING | grep '/THING$'\n\nThe apt-whatprovides script works for files that are and are not on your system. For example, my system lacked dig but had ping so this it what resulted:\npi@raspberrypi:~ $ apt-whatprovides ping\nSearching for /bin/ping\ninetutils-ping: /bin/ping\niputils-ping: /bin/ping\n\npi@raspberrypi:~ $ apt-whatprovides dig\nSearching for dig\ndnsutils: /usr/bin/dig\nepic4: /usr/share/epic4/script/dig\nepic4-help: /usr/share/epic4/help/8_Scripts/dig\nknot-dnsutils: /usr/bin/dig\n\nNotice that Searching for is a complete path for ping (installed) and just the binary name for dig not installed. This helped me discover that I needed to install dnsutils without needing to go search https://packages.ubuntu.com/#search_contents\n\nA: You can use dpkg command to find out which installed package owns a file:\nFrom man dpkg:\n\n-S, --search filename-search-pattern...\n                  Search for a filename from installed packages.\n\nExample:\n$ dpkg -S /bin/ls\ncoreutils: /bin/ls\n\nYou can either search with a full path or with just the filename.\nIf you wish to search for files not yet installed on your computer, you can use the Ubuntu Packages Search, or apt-file as described in a different answer.\n\nA: There's also apt-file for looking up files in packages that aren't installed. For example:\napt-file list packagename\n\n\nA: I was trying to track down what installed which on my system. After a little work I created apt-whatprovides\n#!/bin/sh\n#apt-whatprovides ver. 201801010101 Copyright alexx, MIT Licence\n#rdfa:deps=\"[realpath,apt-file,grep,which,sh,echo]\"\n\nBINARY=$(realpath $(which $@))\nPACKAGE=$(apt-file search $BINARY|grep -E \":\\s*${BINARY}$\")\necho ${PACKAGE%:*}\n\nThough for most THINGs you can just use\napt-file search $(realpath $(which THING))|grep 'THING$'\n\n\nA: The apt-file command can do this for you from the command line. I use it frequently when building packages from source. For files provided by packages that are already installed on your system, apt-cache is another choice.\nTo install apt-file, do:\nsudo apt-get install apt-file\n\nThen, you need to update it's database:\nsudo apt-file update\n\nAnd, finally, search the file:\n$ apt-file find kwallet.h\nkdelibs5-dev: /usr/include/kwallet.h\nlibkf5wallet-dev: /usr/include/KF5/KWallet/kwallet.h\n\nHowever a much friendlier way is to use the Ubuntu Packages Search website. They have an option to \"search the contents of packages\" for a specific filename.\n\nA: You can use apt to do it.\n$ apt contains /bin/ls\ncoreutils: /bin/ls\n\nThe output is same as:\n$ dpkg -S /bin/ls\ncoreutils: /bin/ls\n\n\nA: You can search the contents of packages included in the various Ubuntu releases on the Ubuntu Packages website. Look under the heading \"Search the contents of packages\".\nFor example, here are the search results for libnss3.so in focal (20.04):\nhttp://packages.ubuntu.com/search?searchon=contents&keywords=libnss3.so&mode=exactfilename&suite=focal&arch=any\n\nA: One reason you might have to do this is if you are compiling software which there already is an ubuntu package, you can run apt-get build-dep $PACKAGENAME. That will install all packages you need to compile $PACKAGENAME.\n\nA: You mean, which package and not which application. The application is your package manager, e.g. Software Center.\nUsing dpkg:\ndpkg -S /usr/lib/tracker/tracker-store\ndpkg -S tracker-extract\ndpkg -S tracker-miner-fs\n\nExample\n% dpkg -S /usr/lib/tracker/tracker-store\ntracker: /usr/lib/tracker/tracker-store\n\n\nUsing apt-file: \napt-file search /usr/lib/tracker/tracker-store\n\nor also possible:\napt-file search --regex /tracker-extract$\napt-file search --regex /tracker-miner-fs$\n\nExample\n% apt-file search /usr/lib/tracker/tracker-store\ntracker: /usr/lib/tracker/tracker-store\n\n\nOr online here, in the section Search the contents of packages.\n\nExample\n\n\nA: Why:\nDifferent distro has its own way, too many commands to remember  o(╥﹏╥)o\nHow:\nA universal solution: pacapt -Qo file_path\nOutcome:\nOn ubuntu:\n$ pacapt -Qo /usr/bin/iostat\nsysstat: /usr/bin/iostat\n\nOn centos:\n$ pacapt -Qo /usr/bin/iostat\nsysstat-10.1.5-19.el7.x86_64\n\nEven can find path itself:\n$ pacapt -Qo iostat\nsysstat: /usr/share/man/man1/iostat.1.gz\nsysstat: /usr/bin/cifsiostat\nsysstat: /usr/bin/iostat\nsysstat: /usr/share/man/man1/cifsiostat.1.gz\n\nWhat is pacapt:\n\npacapt is a wrapper for many package managers\n\nInstall:\nSimply download the portable script:\nwget -O $HOME/bin/pacapt https://github.com/icy/pacapt/raw/ng/pacapt\n", "Q: What do I need to do that I can access google calendar on thunderbird? I tried to install the provider plugin for thunderbird, but it said my release was too old. I have the lastest release of thunderbird in the lucid archives.\n\nA: For Ubuntu 10.10+\nInstalling the necessary components is just a matter of running:\nsudo apt-get install xul-ext-lightning xul-ext-gdata-provider\n\nThis will install the Lightning Calendar extension and the Google Calendar provider.\nFor Ubuntu 10.04\nUnfortunately, Lightning is not available in the Ubuntu repositories for 10.04 LTS users. If you are running Ubuntu 10.04 LTS, you have 2 options:\n\n\n*\n\n*32-bit users can install a version of Lightning compatible with Thunderbird 3.1 from https://addons.mozilla.org/en-US/thunderbird/addon/lightning/versions/?page=1#version-1.0b2\n\n*You can install the latest stable version of Thunderbird, following the instructions in How do I install the latest stable version of Thunderbird?. The thunderbird-stable PPA also has a compatible version of the Lightning extension for Ubuntu 10.04 LTS users.\n\n\nI would strongly discourage disabling the addons compatibility checker, as advised in another answer. The check is there for a very good reason, and disabling it could make Thunderbird unusable.\n\nA: I just tried it out, and you'll need\n\n\n*\n\n*Lightning\n\n*Provider for Google Calendar\nTo disable compatibility checking for extensions, open Thunderbird's preferences, switch to the \"Advanced\" tab and in the \"General\" subtab, start the config editor. (source)\n\nAdd a new boolean value via right click named\nextensions.CompatibilityCheck.[VERSION]\n\nset to false.\n[VERSION] stands for your Thunderbird version, e.g. 3.1, if you're using 3.1 stable, 3.1a if you're using 3.1 alpha, or 3.1b if you're using 3.1 beta. (source) \nThen you can just install your extensions.\nShould the Config Editor be unavailable for any reason whatsoever, you can always manually edit ~/.mozilla-thunderbird/[somecharacters].default/prefs.js.\nAdd the following lines as necessary:\nuser_pref(\"extensions.checkCompatibility\", false);\nuser_pref(\"extensions.checkCompatibility.3.0\", false);\n\n\nA: You need the 'Lightning' extension for Thunderbird (http://www.mozilla.org/projects/calendar/)\n and the google provider plugin (https://addons.mozilla.org/en-US/thunderbird/addon/4631/).\nYou can then ask the creation of a new \"network\" calendar, and identify it using the \"private URL\" that Google Calendar gives you (in the calendar's preferences).\n\nA: if you have a fairly new thunderbird + lightning combination (or the standalone calendar program sunbird) you can use caldev to have a two-way sync.\nfor a detailed explanation and howto you can read this blogpost by aaron toponce\n", "Q: Is there a plugin for KOrganizer that allows me to access google calendar? Where can I find such a plugin?\n\nA: yes, akonadi-kde-resource-googledata, and its in the repos\nsudo apt-get install akonadi-kde-resource-googledata\n\n", "Q: How can I play encrypted DVD movies? My machine can't play encrypted DVDs on a fresh install.  How do I add this capability?  Another useful bit of information would be what programs are best for playing DVDs, once I'm able to do so.  See the similar question here.  Will I be able to play DVD movies from any region?\n\nA: You can add the medibuntu repository. It will add some other niceties like the ability to play some windows-only codecs.\nYou can find a how-to here : https://help.ubuntu.com/community/Medibuntu\nPlease note that installing this packages can be illegal in some jurisdictions. You can always buy Power DVD from canonical web store, if your concerned about it.\n\nA: Commercial DVDs are copy protected to ensure that you aren't able to backup your legally acquired movies, but instead have to buy new ones if they break. You also aren't allowed to enjoy them in just any manner you please; you may only watch them on certain devices with pre-installed decryption keys. Unless those devices are too old, of course; Then  you have to buy new ones.\nTo get around this, install libdvdcss.\nFrom help.ubuntu.com:\nInstalling libdvdcss\n\nLegal Warning: Check with your local laws to make sure usage of libdvdcss2 would be legal in your area. *[Unless you live in Somalia or some other place with no rule of law, it's not legal]\nUbuntu 10.04 (i386, amd64), 10.10 and 11.04 (i386, amd64)\n[edit: This method has been used successfully in 11.10 and 12.04 as well]\nWorks for old releases that are no longer supported if you have repositories on Cd/Dvd or somewhere. So, anything from 9.04 onwards. The latest LTS, 10.04, and the radically different 11.04 also work this way.\nInstall the libdvdread4 package (no need to add third party repositories) via Synaptic or command line: \nsudo apt-get install libdvdread4\n\nThen open a terminal window and execute: \nsudo /usr/share/doc/libdvdread4/install-css.sh\n\nRebooting may be necessary. \nAfter this, VLC will automatically use it. Some programs may need recompilation.\nIf after doing all this, you still get messages about not being able to play DVDs, check that the DVD drive has a region set (see below). \n\nA: If you want to avoid legal issues with libdvdcss, you'll need to install Fluendo DVD Player ($24.95) from Ubuntu Software Center.\n\nA: I used AcidRip DVD Ripper and all my problems with playing DVD are gone.\n\nA: Ubuntu 20.10 and later\nIn Ubuntu 20.10 and later DVD-Video playing library - installer (libdvd-pkg) can be quickly and easily installed from the default Ubuntu repositories. Open the terminal and type:\nsudo apt install libdvd-pkg libdvdnav4 libdvdread8  \nsudo dpkg-reconfigure libdvd-pkg\n\nUbuntu 20.04\nIn Ubuntu 20.04 DVD-Video playing library - installer (libdvd-pkg) can be quickly and easily installed from the default Ubuntu repositories. Open the terminal and type:\nsudo apt install libdvd-pkg libdvdnav4 libdvdread7  \nsudo dpkg-reconfigure libdvd-pkg\n\nUbuntu 16.04-19.10\nIn Ubuntu 16.04-19.10 DVD-Video playing library - installer (libdvd-pkg) can be quickly and easily installed from the default Ubuntu repositories. Open the terminal and type:\nsudo apt install libdvd-pkg libdvdnav4 libdvdread4  \nsudo dpkg-reconfigure libdvd-pkg # to allow DVD playback\n\nThis package provides libraries (including libdvdcss2) that are needed for playing video DVDs with a media player (such as VLC, SMplayer, Totem, etc.). It automates the process of downloading source files, compiling them, and installing the binary packages.\n\nA: To Enable Playback:\n\n*\n\n*Install libdvdread4:\nsudo apt install libdvd-pkg\n\nNote: You may have to enable multiverse to install this package.\n\n\n*Then install libdvdcss:\n\n*\n\n*Ubuntu 20.04 onward\nSee this answer instead.\n\n\n*Ubuntu 15.10 to 19.10\n sudo dpkg-reconfigure libdvd-pkg\n\nThen follow the instructions to let it download and compile.\n\n\n*Ubuntu 12.04 to 15.04\n sudo /usr/share/doc/libdvdread4/install-css.sh\n\n(More about libdvdcss here.)\nBest Players:\nAccording to the Ubuntu Wiki, Kaffeine, MPlayer, xine, Totem-xine, VLC, and Ogle will play DVDs with libdvdread and libdvdcss installed.\nI use both Totem and VLC to play DVDs. It's useful to have both installed, because sometimes one will have a playback quirk that the other will not.\nRegions:\nI believe playback will work in any region.\n\nA: Fluendo produces a binary-only DVD player for purchase that (supposedly) works in Ubuntu quite well. You can get it from their webshop.\nPlease note that in some jurisdictions (Finland at least) even engaging in discussion about circumvention of copy protections is illegal.\n\nA: In my case, at a command line launch of vlc I was seeing:\n[mpeg2video @ 0x7f5608002a80] hardware accelerator failed to decode picture\n\nFor my AMD Radeon R9 290 I resolved it by downloading and installing the latest drivers.\n\nA: I had troubles with one german dvd with new all-in-player from asus, and only help was to change the region-code:\nhttps://help.ubuntu.com/community/RestrictedFormats/PlayingDVDs#Ubuntu_15.10_and_newer\n", "Q: What's the easiest way to get started with LaTeX? I'd like to learn and use LaTeX on Ubuntu.  What packages do I need?  What is the best editor for LaTeX code on Ubuntu for a new LaTeX user?  I'd also like the ability to see the code in one pane and the results in a second pane, if possible -- not necessarily WYSIWYG, though. \n\nA: Not necessarily a tool specifically for Ubuntu but we have a sister TeX Stack Exchange on this network that has great information for those of us still learning LaTeX.\n\nA: You can install all the necessary latex packages via texlive-latex-base. There are also additional options available.\nYou can always use emacs as editor, it has a lot of latex utilities available. However, any editor you are comfortable with works. \nIf you like to have specialized editors (that actually have wysiwyg), you can look into lyx, or if you use KDE you can use KILE which is an IDE for latex.\nKILE gives you additional help with LaTex utilities like bibliography etc. You can automatically start all the compilation necessary etc.\n\nA: I while back I wrote a blog post comparing 8 different free LaTeX editors, all of which are available for Ubuntu. (Of course, I was using Ubuntu when I wrote the post!)\nThe post is about six months old at this time. I think a lot of the information there will be worthwhile, even though some of it is out of date, or new things have been added in the meantime not mentioned there. (E.g., Texmaker(x) has a built in preview now, gedit has become more SyncTeX compliant -- I guess evince now has some SyncTeX features, though I've never figured out how to use them.)\nIf you're not hurting for disk space (beware, it's over 2 GB!), I recommend installing the texlive-full package, or even skipping Ubuntu's package manager and installing TeXlive directly from CTAN/TUG. That way you never have to worry about missing pacakges.\nSeveral people have mentioned Texmaker, but if you're considering that, I highly recommend going for the TexmakerX fork instead, which has a lot more features, or at least I did when I compared.\nIn the meantime, I've settled on using vim, but without the vim-latex suite. I've written some custom scripts, including one that provides vim with a live-update-as-you-type preview panel using mupdf. If anyone is interested, I'll post instructions for using that with Ubuntu somewhere. However, I don't really recommend trying to master both vim and LaTeX at the same time. They each have a huge learning curve (though they're both worth it!), and trying to do them both simultaneously would make the most patient person scream.\n\nA: Just install the texlive package, this will pull in all the essentials. Additionally you can install documentation in your language, eg. texlive-doc-en. If you're writing in a language different from English, you should also add the respective language package, e.g. texlive-lang-french. There are also nice topic oriented packages like texlive-science or texlive-humanities -- but if you want to learn the basics of LaTeX you certainly don't need them.\nIf you just need basic editing support like syntax highlighting, any text editor will do, including the standard GNOME text editor gedit. More advanced options include:\n\n*\n\n*texworks : A LaTeX editor with a quite clean and simple interface, featuring an integrated PDF viewer and synchronisation between the editor and the viewer (i.e. you can jump to the same position in both)\n\n*kile : a powerful editor for KDE (can be installed under GNOME and works fine apart from changing some configuration details to use the GNOME pdf viewer for example)\n\n*texmaker : Similar in scope to KILE, but more \"GNOME-like\" (e.g. less buttons in the toolbar ;-) ), a bit fewer features than KILE probably\n\n*latexila : Like KILE, but targeted to GNOME.\n\n*lyx : not really a LaTeX editor but more a word processor that uses LaTeX internally -- opinions differ whether this is the best way to learn \"real\" LaTeX.\n\nMost of these editors don't really have a preview pane but this is not really necessary: Just keep evince open with the document you are working on, evince will automatically refresh its content as soon as you \"compile\" your latex document\n\nA: You might want to try TeXlipse, a plugin that adds TeX support to the Eclipse IDE. \n\nA: \nGummi is a free, open source, cross-platform, program, featuring a live preview pane.\nFeatures included in the latest stable release of Gummi:\nLive preview pane for the compiled document\nHelpers to generate tables/matrices/graphics\nLaTeX error checking\nSyntax highlighting\nSpellchecking\nDocument statistics\nBibTeX integration\nPersistent configuration\n\nFeatures currently included in our development branch:\nMulti-tab/document project support\nSupport for additional build LaTeX systems rubber & latexmk\nCompiling through DVI & Postscript\nMakeindex support\nContinuous PDF preview mode\nFilter bibliography entries\nSyncTeX support\n\nGummi is still under active development.\n\nA: Vim is one of the best editors, but you need to learn a bit before you can use it (start vimtutor in a terminal), and learn more to use it efficiently. It has an extension vim-latex in the vim-latexsuite package. You can use the graphical version of vim, the gvim.\n\nA: \nTexmaker is a free, modern and cross-platform LaTeX editor for linux, macosx and windows systems that integrates many tools needed to develop documents with LaTeX, in just one application.\nTexmaker includes unicode support, spell checking, auto-completion, code folding and a built-in pdf viewer with synctex support and continuous view mode.\nTexmaker is easy to use and to configure.\nTexmaker is released under the GPL license .\n\nA: If you just want to install the base stuff you should install texlive-latex-base\nsudo apt-get install texlive-latex-base\nIf you want the whole shebang, including extensive documentation, you go for texlive-full\nsudo apt-get install texlive-full\nIf you want a lightweight editor, you could just install gedit-latex-plugin\nsudo apt-get install gedit-latex-plugin\nwhich adds LaTeX functionality to the default text editor.\nIf you want something with more functionality, you could give texmaker a try\nsudo apt-get install texmaker\n\nA: As other have mentioned texlive-latex-base and texlive-full are the best way to get the latex packages on your system. I also install texlive-latex-extra as it makes even more packages available.\nLately for a latex editor I have been trying out TeXworks. With TeXworks you can have your latex code open in one window and in the window next to it you can have your compiled document. When you make an update and rebuild the document the document view will stay at the point you where looking at so this can be useful for seeing your change took effect. \n\nA: As a LaTeX distribution, you can use texlive. There's a metapackage called texlive-full that will install the entire distribution for you, but of course you can install individual packages as you need them. As for the editor, there are several options and you should probably try afew and see which one you prefer. I personally use either Emacs with auctex, or texworks. Other popular editors are vim, texmaker, and many more.\n\nA: Without wanting to start a (religious) war I can highly recommend emacs combined with  AUCTeX. It provides fantastic facilities for moving around the document, managing references and citations, inserting template (LaTeX) markup for different environments (tables, figures, and so on) and compiling the document and previewing it. \nAUCTeX is really excellent for long documents -- writing my thesis in it was what got me to learn emacs and, sadly, use my beloved vim less. \n", "Q: How can I use my Garmin device in Ubuntu? Specifically, I have a Garmin Forerunner 305 (a GPS-enabled, hear-rate-monitor for runners).  I plug it in to the USB port and it is not recognized by Ubuntu at all.  I'd like to be able to have it recognized, so that I can pull the exercise record from the watch.  This would allow me to upload it to the Garmin Connect website, or perhaps use a Linux exercise software option.  I'd also appreciate suggestions for exercise software to use with the Garmin.\n\nA: Maybe these will help you connecting to your Garmin device.\n\nA: I have found that all my Linux systems will mount my Garmin 500 and I can access the device like a USB drive.  \nTo import my activities into Strava, I just go to the device and within the Garmin/Activites folder there are all the *.fit files.  The file names are in the format YYYY-MM-DD-XX-XX-XX.fit. I just select the file for that particular activity and upload it.  \nThere is nothing magic about the Garmin uploader and it really is a terrible way to get data into Garmin connect.  I don't particularly like that site, so I use Strave for everything.  However, if you want to use Garmin, you can upload the files by following the instructions here\nThe manual upload is so much faster and way less hassle, even if I used Garmin to track my history, I would still do it manually rather than via Garmin connect.\n\nA: I can highly recommend trying Linux Garmin Communicator Plugin. This is a \"native\" ubuntu solution and there is a ppa repository.\nHaving just got an Edge 500, I installed this plugin on Natty and it worked fine with Chrome and Firefox. The Garmin Connect upload button finds the device and uploads activities as requested. \n\nA: I am also looking for a good pure Linux answer to this. I've owned a Garmin Edge 305 for 2 years and have been a full time Ubuntu user for 3-4 years. This is (sadly) how I do it:\nInstall VirtualBox, then create a windows virtual machine. From there it's pretty straightforward. Install your favorite drivers and software for dealing with your training data and use it from there. (This question has a bit more on the install step if you haven't used VirtualBox at all)\nSome caveats: Once you have booted into your virtual machine and selected the Garmin device from the USD devices drop down to 'plug into' the virtual machine (shows up as an 'unknown device' for me), the Garim will not immediately work. It will show up in the device manager, at this point you need to disable it and re-enable it, then you are good to go.\nClearly this isn't a pure Ubuntu solution, but given my software of choice doesn't work under linux yet, I didn't have much choice. (Zone 5's SportTracks, though supposedly they are getting close to running under Mono) There are other solutions, but this has basically been the most efficient way to deal with training data from a Garmin I've found.\n\nA: I wrote gols just for that, feel free to test it and send bug reports, \nLong story short you install it like you would for any python package, then you create a systemd service that will automount your watch and launch the script on USB insert, as simple as that. \nThat blog post explains how it works, you'll find the link to the repo inside too. \nhttps://medium.com/@euri10/gols-garmin-on-linux-sucks-f1f065f7529a#.sbwv5zqbk\n\nA: *\n\n*First, use Software Manager or sudo apt-get from the terminal to install the garmin-forerunner-tools package.\n\n*Next sudo vi or sudo nano or sudo gedit /etc/udev/rules.d/51-garmin.rules and\nadd the content SYSFS{idVendor}==\"091e\", SYSFS{idProduct}==\"0003\", MODE=\"666\" as detailed in http://www.gpspassion.com/forumsen/topic.asp?TOPIC_ID=124627 \n\n*Reboot\n\n*Plug in your garmin 305 and make sure it is powered on.\n\n*Type garmin_get_info and you should see xml output \n\n*Create a container directory for example mkdir garmin and cd into it\n\n*Type garmin_save_run and it will create subdirectories for each year and the months under each year and finally track/workout files under each month, each in gmn format.\nYou can convert each to gpx format if you wish by using garmin_gpx ... very nice.\n\n\nThanks much to txwikinger.\n", "Q: Any PPAs for Google's Go Language? Do you know of any URLs for PPAs of Google's Go Language?\n\nA: Currently, there is no PPA for the latest upstream version of Go available. To install the current Go version you can use godeb, which automatically installs the latest upstream version as a .deb package:\n\n\n*\n\n*Prepare the envorinment by creating a directory and setting the GOPATH and PATH variable:\nmkdir -p ~/.go/bin\necho \"GOPATH DEFAULT=\\${HOME}/.go\" >> ~/.pam_environment\necho \"PATH DEFAULT=\\${PATH}:\\$GOPATH/bin\" >> ~/.pam_environment\n# Re-login your user so the variables are applied\n\n\n*Download, unpack and install the latest Go version with godeb:\nwget -O /tmp/godeb-amd64.tar.gz https://godeb.s3.amazonaws.com/godeb-amd64.tar.gz\ntar xfz /tmp/godeb-amd64.tar.gz -C ~/.go/bin\ngodeb install\n\nGo is now ready to use. For more information, see godeb --help.\n\nA: I've not been able to find a PPA, but the gccgo developer has posted .deb packages on his sourceforge site.\nIndividuals have been working on packaging upstream Go in Debian, see the WNPP bug for more info. You might be able to build a deb from the hg repo as folloows: \nhg clone http://hg.debian.org/hg/collab-maint/golang/\ncd golang\ndebuild -us -uc\n\nI'm not terribly familiar with using hg to build debian packages, and keep in mind this is development packaging you're working with. \n\nA: I used this one ppa:ubuntu-lxc/lxd-stable that has the near to latest version\n\nA: 2023 answer: If you're using Ubuntu between 16.04 and 22.04 on amd64, arm64, armhf or i386, you can use the recommended ppa:longsleep/golang-backports.\nIt provides Golang from version 1.8 to 1.20\nYou can read more info on https://launchpad.net/~longsleep/+archive/ubuntu/golang-backports.\nTo sum it up:\nsudo add-apt-repository ppa:longsleep/golang-backports\nsudo apt update\nsudo apt install golang-go\n\n\nNote that golang-go installs latest Go as default Go. If you do not want that, install golang-1.19 instead and use the binaries from /usr/lib/go-1.19/bin for example.\n\n\nA: Here's a PPA for Go. It worked for me, just now, and is maintained with golang versions for 10.04-12.04. \n\n\n*\n\n*https://launchpad.net/~gophers/+archive/go\nsudo add-apt-repository ppa:gophers/go\nsudo apt-get update\nsudo apt-get install golang-stable \n\nSubstitute golang-weekly or golang-tip if you want more up to date snapshots.\nReferences: \n\n\n*\n\n*https://wiki.ubuntu.com/Go\n\n*What are PPAs and how do I use them?\nEDIT: unfortunately the Gophers archive is now discontinued (see the PPA description and http://blog.labix.org/2013/06/15/in-flight-deb-packages-of-go), now replaced by a custom binary that can be used to generate Go deb packages from source.\nHowever, the golang package currently in Trusty is relatively recent (1.2.1 at the time of this writing). If you are still on 12.04, you might want to use this backports PPA:\n\n\n*\n\n*https://launchpad.net/~bcandrea/+archive/ubuntu/backports\n sudo add-apt-repository ppa:bcandrea/backports\n sudo apt-get update\n sudo apt-get install golang\n\nwhich I maintain trying to keep up with stable updates in official Ubuntu repositories.\n\nA: gccgo has official .deb packages in Debian experimental now.\nThis should be all you need to compile go code into an executable.\nMore info and links here:\n\n\n*\n\n*Go (golang) intro incl. availability of packages in main distributions\nAs latest Ubuntu is usually a pull from experimental, then it should certainly be in 11.04 Natty Narwhal.\nIf you want roll you own .deb for a previous Ubuntu version, then comment from @lfaraone will get you access to debianized selection of google's own source.\nIf you want to pull the source direct from Google then there is a recent article by @mirwing telling you how to do that.\n\nA: Go versions 1.4 through 1.11 for Ubuntu Trusty, Xenial, Bionic, Cosmic and Disco can be installed from here:\nhttps://launchpad.net/~gophers/+archive/ubuntu/archive\nsudo add-apt-repository ppa:gophers/go\nsudo apt-get update\nsudo apt-get install golang-1.11-go\n\n \nNote: After install, you will need to add /usr/lib/go-1.X/bin (or maybe /usr/lib/go-tip/bin) to your $PATH, or you can just invoke /usr/lib/go-1.X/bin/go directly.\n\nA: I got gpg failure gpg: keyserver receive failed: No name\nInterestingly it on snap, so snap user can easily type\nsudo snap install go --classic but remember if you already have go you should apt remove go-lang before install go\n\nin case someone faces 404\n\n", "Q: What is better: Win7 host running VMware with Ubuntu guest or visa versa? I need both running on one computer\n\nA: \nI develop on Ubuntu, yet work oriented communication which happens all day still requires Office.\n\nIt depends:\n\n\n*\n\n*virtualization takes much of the pain out of O/S upgrades and maintenance; I'd virtualize the environment that changes most rapidly\n\n*virtualizing your development environment allows you to back it up and restore it more easily\n\n*but, depending on how heavy-weight your software stack is, the performance hit from virtualization may be unacceptable\n\n\nAssuming sufficient disk space, you could run Ubuntu and Windows instances under an Ubuntu host.\n\nA: Well, \"it depends\".\nWhich  do you see yourself spending more time in? That should probably be your primary OS. \nKeep in mind that device support for VMs is still a bit lacking, so for example it's complicated to sync your iPhone with Windows in a VM on Ubuntu, so that'll also factor into your decision.\nThere is no right answer, only which works for you. \n\nA: If you only need Windows for Office, you should probably look at Crossover. It's wine polished, with some tricks and licensed bits (like fonts) to run some applications. It's way cheaper than a windows license and the folks that sell it are the main funders of Wine.\nDepending on the version of Office that you need and the exact programs (Word, Excel and Outlook are usually much more polished than Frontpage) it could be a better solution than a VM.\n\nA: I've been running Ubuntu as my host for a year now. Running Microsoft world in VM's. Only issues are limited 3D support in the guests, but that seems to be an issue with my video card and drivers.\n\nA: I use VMware Workstation (currently using version 7.1) on Ubuntu to run both Windows 7 and Windows XP guest virtual machines. I am primarily running Linux applications so I find that it works quite well, but I've never run VMware with a Windows host OS so I can't really compare. \nIn cases where I need to run just one particular application I really like the Unity mode of VMware Workstation (which hides the guest desktop and displays open guest windows directly on the host desktop). It is my understanding that Unity works with either a Linux or Windows guest OS.\nWhen running something like Microsoft Office on a Windows guest virtual machine, I recommend making sure that the host computer has a enough RAM available to run both the host and guest comfortably.\n\nA: \nI develop on Ubuntu, yet work oriented\n  communication which happens all day\n  still requires Office.\n\nThen I would say Ubuntu as host. Especially if:\n\n\n*\n\n*you are using heavy tools like app servers and Eclipse\n\n*you are compiling C/C++, or a lot of Java.\n\n*what you are developing has networking features\n\n", "Q: Best rootkit removal tool for a server? and what schedule/sysadmin routine is recommended?\n\nA: There are no automated rootkit removal tools for Ubuntu, only tools to check for rootkits. \nchkrootkit and rkhunter are fairly robust tools when it comes to detecting rootkits, but they're only as good as their rules. Also look into tripwire, which checks critical files for changes. \nYou should have all of the above run regularly via cron. \n\nA: If your system has a rootkit, you should:\n\n\n*\n\n*Collect any information about running processes on your machine.\n\n*Make a copy of RAM and your harddrive.\n\n*reformat/repartition your harddrive(s)\n\n*Install a new system/restore your backup.\n\n\nThe first two points are useful, if you want to investigate in that issue. Maybe it is also useful to don't touch the system until your investigation has ended.\nIn case of a rootkit some other person had probably full access of your computer. So it is important to completely remove the old system. Thatswhy you should reformat your drive. If your lucky and have a recent backup, you have to restore it and you're done. If not, you have to reinstall the system. This is the only way to securely remove the rootkit and to come up with a clean system.\n", "Q: Is there a compelling reason to upgrade from Ubuntu 8.04 (Hardy Heron)? Both my desktop and server installation are okay. Am I missing something important that would make an upgrade worth the hassle?\n\nA: It depends what your needs are. Certainly, on desktop you are more likely to upgrade because applications and features change more and faster.\nHowever, also the server has some new upgrades that can cut both ways. For instance php5 has been upgraded to 5.3 which has a lot of very relevant new features to the php language (namespacing, magic functions for static methods in objects etc.). However, a lot of older php applications are not compatible with php5.3. Therefore, you need to weigh if any of your old applications are effected and if you need those new features.\n\nA: The short answer would be:\n\n\n*\n\n*Server: no\n\n*Desktop: maybe\n\n\nThe old saying \"If it ain't broken, don't fix it.\" is especially true when dealing with servers. While I did upgrade my server from 8.04 to 10.04, that was only because there were quite a bunch of new libraries I really wanted. Except for that 8.04 is still a solid release, and if there is nothing you explicitly feel is missing I definitely thing you should stay with it.\nRegarding the desktop the choice is less obvious. The new 10.04 will most likely give a nicer and more polished \"desktop experience\". Also, you will notice a lot more improvements in the included desktop software than you generally do with the typical server daemons.\nStill, your 8.04 desktop is working for you and while the same will probably go for the 10.04 desktop, a change always comes with the risk of something going wrong. What I guess it comes down to is how burdensome/possible it would be for you to re-install the 8.04 desktop in a worst case scenario.\n\nA: Yes, a huge amount of proactive security work was done between Hardy and Lucid. Just compare the security features list. For example, many security flaws would be exploitable on Hardy are at most a denial of service on Lucid.\n", "Q: What is stored in the \"/var/lib/dpkg/updates\" folder? I've seen some folks have errors relating to files in /var/lib/dpkg/updates. All I can find about the directory is that the files in it are numbered 0000, 0001 etc. and that the error messages often mention \"trouble parsing one of the files\".\n/var/lib/dpkg/updates folder is empty on my system, so I can't see what's in the files. I've not been able to find information about what is stored in this directory, only many forum posts and bug reports mentioning the directory. \nSo, what is this directory for?\n\nA: During the update dpkg stores status of the installation/update there. This is how an incomplete installation process can be detected and decided what are the next packages going to be installed, So that the system can ask to use dpkg-configure -a if anything happens before completing installation or update.\nNormally after a successful installation, the directory should be empty.\n", "Q: Why is the tree command not included in Ubuntu server? Is installing the tree command line utility on Ubuntu server has security issues?  It's not included by default on the server.\n\nA: What I will be describing now is most likely a very hypothetical situation.\n\n\n*\n\n*Assume you are running tree on a part of the filesystem where any user can create files, such as under /tmp or /var/tmp.\n\n*Assume that a malicious user has created very explicitly special file names in that location. That could either have been done by having an actual user account on the system or by \"tricking\" a slightly vulnerable and publicly available server daemon.\n\n*Assume there is a actual vulnerability/weakness in tree regarding how it deals with \"odd\" file names.\n\n\nUnder such circumstances it is possible that tree could be tricked into running unintended instructions with the privileges on your user account. Obviously that damage would be far worse assuming tree had been called with root privileges.\nYet, this is nothing different from what you expose yourself to every time you use any application to handle data created by an external/unknown party. No matter if you viewing a web page in your browser, listening to a mp3 file in your music player or editing a document in your word processor you still need to trust your application to handle incoming data in a sane manner.\nThis is by the way why security vulnerabilities in a web browsers are such a big deal, since they are constantly exposed to input from external/unknown parties. The same, even more, goes for server daemons, where a potential attacker has a constant opportunity to feed you \"bad\" input data. Compare this to your calculator, where you yourself are the one inputing all the data as you feed it numbers.\nSummarize: \nYes, there is a theoretical security consideration in installing and running tree, just like with pretty much any other software.\nThat being said, the majority of applications you find in the Ubuntu repositories will be reasonable safe to install and to use. As long as we are talking about regular user applications I don't think you should worry to much.\n(Save your worries for publicly reachable server daemons.)\n\nA: I suspect tree is not installed by default because it is in universe (applications have to be in main before they can be installed as default).\nA quick look through the changelog doesn't show a record of security issues, and there are no bug reports in Ubuntu, even going back as far as Dapper.\nSo my advice would be to just go ahead and install tree on your server, it's probably safer than a lot of popular server applications.\n", "Q: How to get .NET 2.0 SP2 running in wine? I just can't seem to get the .net 2.0 Framework installed using wine / winetricks.\nI typed:\n\nwinetricks\n\ninto the terminal, selected dotnet20sp2, and proceeded to install it.\nUnfortunately, I can't get it to work. After accepting the license agreement, it says \"Installing\" for about 5 seconds, and then reports:\n\nSetup Error\n\n(Yes, that's all it says. Silly Microsoft!)\nHow should I go about installing it.\n\nA: This looks quite a bit like the winetricks bug 70. The issue reports the root cause being in a wine bug, but I didn't go in to more detail in my investigations. If this is indeed the case, you might want to add additional information there and follow the bug for new changes in the bug status.\n\nA: Have you considered using Mono? http://www.mono-project.com/\n\nA: Try PlayOnLinux to install .net 2.0 over Ubuntu. It may help you.\n", "Q: How do I develop .NET apps on Ubuntu? at college we use Microsoft .NET for developing applications. I recently switched to Ubuntu and would like to know similar tools for making apps on/for ubuntu.\n\nA: The Vala language is a programming language very similar to C#. It is still very young, but already has a lot of bindings to existing libraries (for example, GTK). It compiles to native binaries, so your users don't need an additional runtime, as they would for .NET.\nSee an introduction to Vala for C# programmers.\n\nA: I see no reason for all these suggestions that you switch application platforms/languages.  Use what you're used to and you'll be more productive than having to spend time learning another language.\nMonodevelop will give you a better experience of Mono development - its no Visual Studio, but its the best integrated IDE for mono you're gonna get on Ubuntu.  Visual design of GTK forms and their controls is a big win (think Winforms but Linux style).\n\nA: You can program in .NET on ubuntu too. Well, sort of. There is an open source implementation of the .NET platform available called MONO. MONO apps can run on Ubuntu/Linux, Windows and Mac OS. Look for MonoDevelop in Ubuntu Software Center. Learn more about Mono in Ubuntu.\nAnother option is Quickly. In my opinion Quickly is better for Ubuntu centric app development. You can code you app and release it to a PPA (launchpad-repository) in minutes. Quickly is also available from Ubuntu Software Center. Get started writing apps with Quickly.\n\nA: There are all sorts of tools available on Linux which allow you to create rich desktop applications. Bowline is an mvc framework which allows you to create desktop applications in ruby. Shoes is another framework which allows you to create desktop apps in ruby, and it is by far the easiest desktop app framework. \n\nA: Start learning Qt. It's a framework based on C++. It's cross platform and also works fine in windows. Even it has an add-in for Visual Studio. It's usually used for KDE platform. For GNOME, you can learn GTK#.\nFrom Wikipedia,\nIn place of the Qt toolkit, GTK+ was chosen as the base of the GNOME desktop.\n\nA: To develop apps specifically for Ubuntu, head to Ubuntu's developer website. Among other things you can: \n\n\n*\n\n*Make snaps\n\n*Make apps with QML and HTML5\n\n*Create scopes with JavaScript, C++ or Go\nThey have a framework called Quickly.\nThere are good references in the other answers to Qt and GTK. An interesting source for guidelines is Gnome's developers website. \nThe framework/IDE to use will depend on the language you use. You can use MS Visual Studio Code on Ubuntu.  \n\nA: Please always cross reference CoreCLR (.NET Core runtime) with Mono. Furthermore, Please see this question collected related people and official opinion for CoreCLR and project Mono relationship after Microsoft open-sourced the .NET\nI think one of good thing from Giants of IT Industry is Official Documentation.\nThe following command is copy from Getting Started with .NET Hello World Console Application in Ubuntu, except added narration and opinion at the last. Possibly refer the above link, if any of the command failed.\n\n\n*\n\n*Prerequisite: Getting Started with .NET Hello World Console Application in Ubuntu. The instruction here assumes you're running Ubuntu 16.04 LTS.\nIn order to install .NET Core on Ubuntu or Linux Mint, you need to first set up the apt-get feed that hosts the package you need. So, setup apt repository with these commands.\nsudo sh -c 'echo \"deb [arch=amd64] https://apt-mo.trafficmanager.net/repos/dotnet-release/ xenial main\" > /etc/apt/sources.list.d/dotnetdev.list'\nsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 417A0893\nsudo apt-get update\n\n\n*Install .NET Core SDK\nsudo apt-get install dotnet-dev-1.0.1\n\n\n*Initialize a sample Hello World application\ndotnet new console -o hwapp\ncd hwapp\n\nLook the style, it is almost easier to getting started as Node.js, it is like the CLI tools for all new generation development tool like Spring Boot, Angular 2 etc, which you can just initialize an Hello World apps with command:\n\n*Run the app\ndotnet restore\ndotnet run\n\nThe first command will restore the packages specified in the project file, and the second command will run the actual sample:\n\n*Finally, If you can go through slightly complicated, but if you required UI, I would think this will be easier than working with other C++/C# UI Library. You can choose to work with either .NET or Node.js to communicate with Electron's Web Browser provide UI Through HTML5, CSS.\nElectron UI with .NET and Node.js\n\nA: Quickly can help you make cool apps using Python (pretty easy to learn and very popular) quickly!\n", "Q: How can I fix my problems with fonts in Firefox? Ever since I reinstalled Ubuntu a few hours ago, I've experienced major visual artifacts with smaller font sizes in Firefox. The fonts end up looking like this:  \n\nOr even like this:\n\nThis only occurs in Firefox; other applications are unaffected. It also occurred on the LiveUSB I used for installation, making me suspect a hardware or driver issue. The output of lshw on my computer is here: http://pastebin.com/LnSt6veT.\nAny idea what might be causing this, or how I can fix it? \n... and \"Use Google Chrome\" is not a valid answer. ;)\n\nA: The problem was with the Nouveau driver I was using; for whatever reason it wasn't rendering fonts correctly in FireFox. Switching to the proprietary Nvidia driver fixed it.\n\nA: Removing 'msttcorefonts' might also fix it.\n\nA: You seem to have managed to solve your problem.\nStill, if you're referring to a recent bug in Firefox that makes it 'disobey' the system-wide font settings in Ubuntu, this may help you out: http://www.uluga.ubuntuforums.org/showpost.php?p=8193420&postcount=11.\nIn short, the bug makes Firefox always render website fonts (and its chrome GUI fonts) anti-aliased (AA). The link above demonstrates how you can edit this and make Firefox always render all fonts crisp and pixel-ish, without any AA (this is especially good for webdesigners and people like me who hate anti-aliased fonts because of their visual artifacts).\nThe fix requires that you have root (a.k.a. admin) privileges (many tutorials on how to 'go root' are available online).\nBTW, I'm a total newbie at Linux and Ubuntu is my fist Linux distro, which is why I approach such annoying 'bugs' from an end-user point of view (i.e. quick fixes). Despite this, Ubuntu 10.10 has been a mostly great experience for me and I wholeheartedly recommend it (as well as support all GNU/Linux distros and the open-source and free software movements). :)\nI hope this helps. Cheers.\n\nA: Have you tried tweaking your font hinting settings in Preferences > Appearances?  \nGo to the Font tab and click Details...  See if a different setting improves the situation.\n", "Q: How do I know if my firewall is on? I installed Firestarter, and configured my firewall.\nBut I'm in doubt : On boot, I sometimes see a [FAIL] marker, and to the left, I guess it was something like \"start firewall\". I can't  be sure because the message is seen for less than a second, so I wanted to know if there is a way, without starting the whole firestarter software, to know if the firewall is on and working, or not.\nEither a gadget, or better, some console instruction, the exact name of the firewall process/daemon, or bash script, will do.\nEdit: I already tested my computer with the \"Shield's Up\" http://www.grc.com feature, which marks my computer as \"Stealth\", but as I am behind a router, I'm not surprised. Still, apparently, my computer answers to pings... Strange...\n\nA: First of all, you can review the syslog for any error messages from services with sudo less /var/log/syslog. That may give you a clue as to why the firestarter service didn't start.\nYou can manipulate services with the service command. To check whether a service runs, use service [service_name] status. In your case, I guess service_name is just firestarter. You can use tab-completion to get a list of available services (service TAB TAB), or take a look at the contents of directory /etc/init.d (every file is a script to manage a service). \nUbuntu has its own firewall system, called Uncomplicated Firewall (ufw). Maybe it's easier to use that one within Ubuntu. If you install the package gufw, you can access the configuration in System -> Administration -> Firewall configuration.\nThe iptables command mentioned above works on any Linux system. All Linux firewall configuration tools (like ufw, firestarter, and many others) are basically front-ends to iptables.\n\nA: There are basically 2 ways of seeing if the firewall is configured. You should use both of the methods and verify that the firewall is both configured and configured the way you wish it to be.\nFirst, check that the firewall rules have been applied. Pretty much all modern Linux firewall solutions use iptables for firewall. You can see that there are rules in place with iptables command:\niptables -L\n\nThis will return the current set of rules. There can be a few rules in the set even if your firewall rules haven't been applied. Just look for lines that match your given rulesets. This will give you an idea of what rules have been entered to the system. this doesn't guarantee the validity of the rules, only that they have been understood.\nNext, you will use a second computer to test for connections against the host in question. This can be easily done with the nmap command (found in nmap package). Quick and dirty way of checking is:\nnmap -P0 10.0.0.10\nnmap -P0 -sU 10.0.0.10\n\nReplace the IP address 10.0.0.10 with your destination hosts IP address.\nThe first line will scan for TCP ports that are open and available from the second computer. Second line will repeat the scan but this time with UDP ports. -P0 flag will prevent the host from being tested with a ICMP Echo packet, but might be blocked by your firewall rules.\nThe scan might take a while so be patient. There is also a GUI frontend for nmap called zenmap which makes it a bit easier to interpret the scan results if there is a lot of output.\n\nA: You can use this command:\nufw status  \n\n\nA: To check Firewall status use command:\nsudo ufw status\n\nTo enable the firewall use command:\nsudo ufw enable\n\nTo disable the firewall use command:\nsudo ufw disable\n\n", "Q: Is there a way to have Debootstrap automatically configure locales? I like to use Debootstrap for making sparse systems (usually a base for something embedded) or paravirtualized Xen guests.\nI'm familiar with how to tell Debootstrap what packages I want beyond the typical minimal base, but I have yet to find the right combination of tools to let me specify and auto generate locales after the base system has been installed.\nDo I need to do this in my own scripts, or is there a way to tell Debootstrap what locales I want and have it just generate them?\n\nA: I would suggest using grml-debootstrap. This is a wrapper script around debootstrap and comes from the grml live cd. This script has a file /etc/debootstrap/locale.gen where you can put your locales and they are generated at the right time. grml-debootstrap also has lots of more advantages and its worth to look at.\n", "Q: Tips for getting to grips with the command line When I first migrated from Windows to Ubuntu, by far the most daunting thing I had to do was use the command line.\nTyping commands is an alien experience when you've only ever been used to pointing and clicking.\nWhen I talk to new Ubuntu users, they are often uneasy with the idea of talking directly to their computer.\nIs there a simple and friendly guide to help new users get acquainted with the command line?\nDo you have any tips to make the experience easier or more fun?\n\nA: Switch to zsh!\nWhile it is very much like bash, it has a lot of nice additional features out of the box (like for example typo correction, even in a preceding path component or a useful widget to call help for the current command (via run-help; I press ESC-h after e.g. having typed mplayer, and it opens the man page. After closing it I'm back at the old line)).\nI recommend the following book, which covers zsh, bash and some other shells:\nFrom Bash to Z Shell: Conquering the Command Line.\nWhile it is a few years old already, I'm glad this had not turned me away from buying it.\nThis recommendation also holds if you do not want to switch to zsh.\nI have been using the command line a lot since a few years (locally and via SSH), I've only recently made the switch to zsh myself (mostly because of my custom bash prompt, which is not compatible).\nHere is my zsh config (integrated in my dotfiles repository).\nYou can use chsh -s /bin/zsh to switch your shell (via /etc/passwd), or just call it from your current shell, i.e. type zsh in your bash prompt (you likely have to install it first though (sudo apt-get install zsh).\n\nA: \"apropos\" (or it's equivalent: \"man -k\") to find a command to do something.\n$ apropos [my query]\n\nFor instance, to find the command to copy files:\n$ apropos copy\n\nwill list a bunch of commands, of which\ncp (1) - copy files and directories\n\nis one.\n\"cp\" is the command and \"1\" is the section from the manuals where it appears. Section 1 is general user commands (other sections include things like library calls, which you won't be interested in). To restrict the search to just section 1 use:\n$ apropos -s1 [my query]\n\nTo then find out more about the command use \"man\". e.g.\n$ man cp\n\n\nA: Try using fish\nfish is a user friendly command line shell for UNIX-like operating systems such as Linux.\nAmongst other things it features more advanced tab completion than bash which can be very helpful while learning.\n\nhttps://www.pablumfication.co.uk/2010/02/26/fish/\nhttp://fishshell.org/index.php\n\nA: history | grep SOMETHING — finds command you used before that contains SOMETHING.\nfortune ­— :-)\n\nA: To learn how to use a command add a space and then \"--help\" to the end of it - this tells you how to use it and gives a list of options.\ne.g.\ncp --help\n\n\nA: The Ubuntu Pocket Guide and Reference features a chapter on using the command line.  It'll quickly get you up and running with the command line.\nAlso it is free to download or read online.\n\nA: I recommand to use CLI Companion:\n\nCLI Companion is a tool to store and run Terminal commands from a GUI. People unfamiliar with the Terminal will find CLI Companion a useful way to become acquainted with the Terminal and unlock its potential. Experienced users can use CLI Companion to store their extensive list of commands in a searchable list.\n\n\nYou get it by running:\nsudo add-apt-repository ppa:clicompanion-devs/clicompanion-nightlies\nsudo apt-get update\nsudo apt-get install clicompanion\n\nIf you don't want to add the PPA try this file for 12.04 (latest version 1.1-6, released on 2012-04-14 - check this page for newer versions.) - or remove the PPA after installing with sudo add-apt-repository -r ppa:clicompanion-devs/clicompanion-nightlies .\n\nA: If you are looking for a good guide to learn the command line, my favorite is LinuxCommand.org\nThe guide will show you the basics of the command line, and will even guide you into writing useful shell scripts.\nThat said, most user will not need to use the command line for most day to day operations. I do not think that the command line should discourage users from migrating to Ubuntu. But once you learn the power of the command line, you won't be able to live without it!\n\nA: Here are some common commands for manipulating the filesystem:\n\n\n*\n\n*cp [src] [dest] - copies src to dest\n\n*mv [src] [dest] - moves src to dest (also used for renaming)\n\n*cd [dir] - changes current directory to dir\n\n*pwd - prints the current directory\n\n*cat [file] - prints the contents of file to the screen\n\n*rm [file] - removes a file1\n\n*rmdir [dir] - removes an empty directory\n\n\nPrefixing any of the commands with sudo causes the command to be executed as the root user.\n1 - don't type sudo rm -rf / as it will erase the filesystem\n\nA: 1) Tab completion:\nA giant time saver. If you are typing a command, you need only type enough of the command to provide an initial segment that can only be extended in a single way and then can press TAB once to expand your initial segment to the entire command. So, for instance, on my system umo TAB expands to umount. (On my system as what initial segments are extendable only in one way is a function of what you have installed, etc.) If you do not type enough to make the completion unambiguous, TAB will not expand, but a second TAB will display a list of possible completions. So, on my system, um TAB TAB yields:\numask       umax_pp     umount      umount.hal\n\nTab completion also works on paths: cd /home/me/docs/reallylo TAB will, if unique, expand to cd /home/me/docs/reallylongdirname and, if not unique, offer a list of candidate continuations as with um above.\n2) man some-command or some-command --help or some-command -h:\nIf you cannot recall how a command works, you can get documentation right there in the shell. man usually provides the most detail. Usually one or both of the --help and -h arguments to a command provides a short summary.\n3) head:\nman some-command takes over the terminal and prevents you from entering commands while the man text is displayed. man some-command | head will display the first 10 lines. man some-command | head -n will display the first n lines. In both cases, you get your prompt back, so that you can have the man text on screen as you enter your command.\n\nA: Find an Ubuntu book with good command line index, zerox it and place it near the computer. Force yourself to use it.\nA good resource is the book \"Ubuntu Linux Toolbox 1000+ commands\", covers all you need to know (http://www.amazon.com/Ubuntu-Linux-Toolbox-Commands-Debian/dp/0470082933)\nHowever, if you don't run a server, in Ubuntu desktop almost everything is available with the GUI.\n\nA: I learned a ton about using the command line and getting comfortable with working within it from reading The Bash Cookbook from O'Reilly and Associates. It's a book about Bash scripting, but the bite sized chunks of the cookbook format make it very accessible. As a side benefit, if you think \"Gee, I'd sure like to do X, but I don't know how,\" you can use the table of contents to look up X (and Y and Z for that matter) and get a good idea on how to do it (and a decent explanation of how it works with pointers to other recipes and resources that can further expand your understanding).\n\nA: I have been reading Official Ubuntu Server Book, The (2nd Edition) to learn system administration, and not only have I become more adept at using the command line, but I've also begun to learn the inner workings of the OS itself.\nUsing the Ubuntu Server Edition helps me to learn the command line easier, because I don't have the GUI to fallback on.\n", "Q: Where would I find a PPA for the newest version of GIMP? Does anyone know of a PPA that has the development version of GIMP?\nI would like to try out the new single window mode.\n\nA: I haven't been following GIMP development very closely, but it appears that in the latest development version, 2.7.1, \"it is not possible to start up in single-window mode yet\" (2.7.1 release notes). I guess it's possible to enable it after starting though.\nThere is a tutorial on How-To Geek explaining how to install 2.7.1 from a PPA and enable single-window mode.\nA summary of how to add the PPA and upgrade Gimp:\nsudo add-apt-repository ppa:matthaeus123/mrw-gimp-svn\nsudo apt-get update\nsudo apt-get install gimp\n\n", "Q: List of free Ubuntu books \nThis question exists because it has historical significance, but it is not considered a good, on-topic question for this site, so please do not use it as evidence that you can ask similar questions here.\n\nWhat free ebooks do you recommend to learn more about Ubuntu? \nOne book per answer, please - vote answers up/down as you feel appropriate. If you feel the book is biased towards/good for particular tasks, please mention them.\n\nA: The Official Ubuntu Documentation is worth a look as well.\n\nA: The Ubuntu Wikibook.\n\nA: The guys who wrote the Server Documentation in the help have done a great job as well: https://help.ubuntu.com/10.04/serverguide/C/index.html, it is also available in PDF.  The good thing is this documentation gets updated every release by the Documentation team\n\nA: \"A Complete Beginner’s Manual for Ubuntu 10.04 (Lucid Lynx)\" is available at \nhttp://www.ubuntugeek.com/download-free-ubuntu-10-04-lucid-lynx-pdf-guide.html\n\nA: It is for Ubuntu 9.10,but still relevant..\nKarmic Guide\nFor Ubuntu 10.04, you grab Ubuntu Manual from \nGetting Started with Ubuntu 10.04\n\nA: Getting Started with Ubuntu  (The Ubuntu Manual)  \nBash - Guide for beginners (On the command line used in Linux, PDF)\nLinux - Inside the boot process (IBM manual in HTML and PDF)\nLinux - Network Administration guide\nAnd if you're a masochist, don't forget the ultimate manual for Linux: \nLinux - Advanced Administration (Kernel, local/network/server admin, ... 545 pages of knowledge! :-)) \n\nA: There is one in German available by Galileo Computing for Ubuntu 10.04 LTS. It can also be downloaded and purchased as a real book. Most of the stuff in there is targeted to beginners.\nThere are also some videos available for the book, but they are outdated by now. \n", "Q: How can I run Ubuntu inside Windows 7? I have Windows 7. I want to run Ubuntu inside it and don't want to loose any data.. How can I do this?\n\nA: Besides VMWare and Virtualbox, there is the Ubuntu Wubi installer.\n\nA: You need to download and install Vmplayer and also download an ubuntu ISO . You then need to build a new virtual machine while providing it the ubuntu ISO . After installation allow VMplayer to install VMTools to enable feature like copy paste and drag and drop across the virtual machine and the host.\n\nA: Use Vmware workstation (commercial) or VirtualBox (free)\n\nA: If you get VMware (Player or Workstation), you can get a pre built Ubuntu machine and you won't have to go through the hassle of installing it your self (even though its pretty easy)\nVMware Virtual Appliance Marketplace\nAlso, the Linux Machines should be free of charge (I don't see any paid ones)\n\nA: Just downloaded Ubuntu 10.04 a week ago using the Wubi windows installer. It was about 1 hour download, and Wubi effortlessly installed it leaving everything in tact. When you reboot you have choice to dual boot into your current system or choose Ubuntu and hit enter. Simple!\n\nA: refer to this link\nhttp://www.psychocats.net/ubuntu/virtualbox\nfor running linux inside windows 7 or any Microsoft based operating system \n", "Q: List of blogs to learn more about Ubuntu Add blogs and websites that are useful in the quest to know/learn more about Ubuntu.\nOne blog per answer, please - you can vote answers up/down as you feel appropriate. If you feel the blog is biased towards or is good for particular tasks, please mention them.\n\nA: Full Circle Magazine \nNot a blog as such, but is a free monthly (PDF) magazine with a particular emphasis on how-to articles and reader submitted stories. It does feature some news stories too.\n\nA: OMG! Ubuntu!\n\nA: Ubuntu Geek\n\nA: The Fridge \nUbuntu's official news source. It includes the Ubuntu Weekly Newsletter and other blog posts.\n\nA: Ubuntu Linux Tips & Tricks Discontinued\n\nA: 2buntu.com\nIt's a newer site that's growing fast. They talk about Ubuntu, and to a certain extent Linux in general. \nDisclaimer: This is one of the many, many blogs that I contribute to from time to time.\n\nA: Web Upd8\n\"A blog on Linux (mostly Ubuntu) and open source / web applications and news\". It is regularly updated, and the posts are always useful and well-written.\n\nA: Planet Ubuntu is a blog aggregator. Not every post will be about Ubuntu but there's a good selection of blogs within it.\n\nA: Jonobacon\n\nA: apt-get install debian-wizard\nDisclaimer: This is my blog, I'm a Debian developer and Ubuntu member and write articles for Debian/Ubuntu users and contributors.\n\nA: Works with U points to The Var Guy\n\nA: Debuntu \nSite provides how-tos, tutorials, tips and tricks for Debian-based distribution such as Ubuntu and Knoppix.\n\nA: Ubuntu Vibes\n\nA: Ubuntu Weblogs is another aggregator for Ubuntu-related blogs. It stays pretty much on-topic at the cost of fewer updates. According to their \"About\" section:\n\nUnlike Planet Ubuntu, this Planet is\n  open to anyone who writes about Ubuntu\n  or any derivative.\n\n\nA: Tuxradar\n\nA: Tech Drive-in 'Technology, Linux, Ubuntu FTW'\n\nA: www.ubuntubuzz.com \nDiscover what's new in ubuntu\n - It's provide news, article, how to, and update PPA,  you can also participate by writing article/news there, come in .\n\nA: Canonical Design Blog \nA great place to learn about upcoming design changes and why they are being made, provide feedback, or even get involved in the design of Ubuntu.\n\nA: Linoob\nIt's a pretty decent blog on Ubuntu. It's not updated as often as the blogs listed above, however has many good articles for learning Ubuntu as well as few good tips and tricks.\n\nA: Bodhizazen Blog ...................\n\nA: How To Geek Ubuntu\n\nA: Mark Shuttleworth Blog\nFounder of the Ubuntu Project.\n\nA: Ubuntu UK Podcast\nUbuntu podcast from the UK. \n\nA: I have my own site (DorkBlog) but it's private at the moment.\nShould you desire to view it, I'd need to allow your IP. \nOr anyone's for that matter. :)\nProbably the best I have found is *nixCraft\nand Commandlinefu\nNot necessarily Ubuntu-specific, but good none-the-less to sharpen one's teeth on.\n\nA: There's The Linux Action Show which isn't an Ubuntu specific video podcast exactly, but they do cover everything that's new in the Linux/Unix community in general (and there's something happening to Ubuntu quite often these days). \nIt's a weekly show which is being recorded live every Sunday. Every monday the show (+- 50 minutes) is delivered through rss and available on their website in every format you'd care about.\nTopics range from Linux gaming in general, to reviewing Ubuntu 10.10 and derivatives like Mint.\nThey do have their own opinion and are (sometimes painfully) objective and stick to their own principles. If you can handle that, you're bound to appreciate their sense of humor.\n\nA: Linux North\nInformation on installation and use of Ubuntu Linux 10.04 LTS (long term support version).\n\nA: Ubuntu Tutorials Discontinued\n\nA: UpUbuntu Blog They cover so many topics but i liked installing kernel 3.3.4\n", "Q: Trouble creating a package for my PPA So I tried following the steps here to create a package to upload to my PPA. I ran dh_make and edited the files. However, when my package gets generated by debuild, none of the programs files show up in the package.\nHere is the output of debuild:\n\n...\n  dpkg-source: warning: ignoring deletion of directory share\n  dpkg-source: warning: ignoring deletion of directory share/pixmaps\n  ...\n\nHere is what the filesystem looks like:\n\nbuild_root\n      - packagename_1.2.orig.tar.gz\n      - packagename-1.2\n           - debian\n               - control\n               ...\n\nThe application is written in Python, if that means anything.\n\nEdit:\nHere is what the packagename_1.2.orig.tar.gz looks like:\n\npackagename-1.2\n       - src\n           - somefile.py\n           - someotherfilefile.py\n       - images\n           - test.png\n\n\nUnfortunately, I'm still struggling...\nHere is my debian/rules file:\n#!/usr/bin/make -f\n# -*- makefile -*-\n\n# Uncomment this to turn on verbose mode.\n#export DH_VERBOSE=1\n\n%:\n    dh  $@\n\noverride_dh_auto_build:\n\noverride_dh_auto_install:\n\n...and here is my package.install file:\n\nsrc/myapp.server /usr/lib/bonobo/servers\n  src/myapp /usr/lib/myapp\n  images/test.png /usr/share/test\n\n\nA: You don't seem to use any build system, I think that's why you're not getting any files in your package. Have you tried looking at changing your debian/rules file?\nIt should be pretty easy to do if you simply put a mypackage.install file in debian/ and use the format specified in man dh_install. With appropriate substitutions, that file could look like this:\nsrc/somefile.py usr/share/mypackage/\nsrc/someotherfile.py usr/share/mypackage\nbin/myexecutable usr/bin\nimage/test.png usr/share/icons/some/icon/dir/\n\nIf you do use a build system, override the dh_auto_* targets as explain in the link above  (Python Packaging Guide) so that you're installing only these files and the build system (e.g distutils) doesn't interfere with files in your package.\n", "Q: What's the difference between Wubi and a regular \"alongside Windows\" installation? \nAt this time, Wubi does not work with Windows 8 default boot-loader. Thus at this point Wubi would not work on a new Windows 8 machine.\nCitation fom WubiGuide\n\nQuestion\nRecently I've learned of Wubi, a way to install Ubuntu right from Windows.\nBesides installing from Windows, I would like to know key differences between a regular \"alongside Windows\" or Dual-boot Ubuntu installation and one done with Wubi. Are there any disadvantages (for example a performance penalty) or incompatibilities I should look out for when using Wubi?\n\nA: Compared with a regular installation, a Wubi installation faces some limitations. Hibernation is not supported and the filesystem is more vulnerable to hard reboots. Also, if the Windows drive is unmounted uncleanly (most commonly because of a Windows crash), Ubuntu will not be able to mount the Windows drive and boot until Windows has successfully booted and shut down. If the Windows system cannot be booted after the crash, the user also cannot boot Ubuntu.\nPerformance related to hard-disk access is also slightly slower, more so if the disk image file is fragmented, on a Wubi install compared to a normal one.\n\nA: Not key, but tiny difference out of the box without any modification, a Wubi install will leave windows as the default boot (so if you hit power and walk away you get Windows), a normal install will default to Ubuntu.  Because of this and the issue noted above, I usually look at it this way.\nWindows user who wants to play with Ubuntu on occasion or see how they like it on more than a LiveCD basis, I recommend Wubi.\nSomeone who is tired of Windows but may need to access some old program for something important at some random time in the future, then shrink the Windows partition and make it an Ubuntu box.\n\nA: You can expect disk performance to be a bit lower (bouncing through NTFS isn't exactly ideal), and you're still somewhat at the mercy of Windows. If your Windows install goes pear-shaped, you may lose access to your Wubi install, too. The reliance on NTFS would also give me heartburn in general, but that by itself probably won't be a serious reliability problem.\nOther than that, I can't think of anything that should be different. If you do find a problem, report a bug! :)\nThere is one other catch noted on the Wubi FAQ in addition to performance/reliability: Hibernation isn't supported.\n(I'll note for the record, however, that even with native installs, I've rarely had reliable suspend or hibernation support in any Linux distribution, including Ubuntu.)\n\n\n*\n\n*What performance differences are there when installing with Wubi?\n\nA: One big advantage to Wubi to a new user looking to test, is that it installs, un-installs like any other Windows program through the add/remove programs... But runs much better then running it off a live disc... Kinda like the best of both worlds...\nObviously the best long term solution is dual booting, if you have the disc space, but if you are just wanting to test it out, see if it runs well on your computer or install it for short term then Wubi will fit your needs...\n\nA: Phoronix published a decent article on the performance impact of running Ubuntu as a WUBI installation. \nThe most interesting results are from the disk and database benchmarks where the WUBI installation appears to outperform the standard installation, sometimes by a factor of 24(!) It's a pity that the article doesn't attempt to explain this huge performance delta, but one of the commenters in the article's discussion offers up a plausible explanation. The relevant quote is reproduced below:\n\nWhen linux is installed \"on top\" of something, writes requiring a fsync (sync to disk) are cached instead of being performed.\n  this operation is very slow, and used for every single transaction in databases such as postgresql or sqlite unless disabled (and it's not)\n\nTo summarize the results from that article:\n\n\n*\n\n*Running Ubuntu as a WUBI installation incurs a slight performance hit.\n\n*Don't run mission critical databases on a WUBI installation, as fsync does not flush the data to the disk and still leaves it cached. This dramatically improves performance at the expense of reliability. This shouldn't impact normal apps.\n\n\nThe biggest advantage of WUBI is that you can easily uninstall Ubuntu if you finally decide that it's not for you.\n\nA: if you install ubuntu on windows file system many of the linux included software will not apply including so many file system check tools and permissions too so you will not really have a secure system as i know linux does not support windows file system NTFS so permissions like read write and execute will be limited. but for a regular user who want to test ubuntu he will not see any major differences  \n\nA: Actually, Ubuntu does have disk swap and it does have a separate disk partition. And so what if it doesn't! Just go into the command line interface in windows and type\ndiskpart disk_partition_name\nI've even seen it have it. If I go into my disk partitions right now and see, I'll see:\n\n\n*\n\n*Layout: simple, type: basic, status: Healthy (active, Recovery Partition), Capacity: 1.46 GB, free space: 1.46 GB, % free : 100%, fault tolerance: no, overhead: 0%\n\n*Layout: simple, type: basic, status: Healthy (active, Recovery Partition), Capacity: 11.72 GB, free space: 11.72 GB, % free : 100%, fault tolerance: no, overhead: 0%\n\n\nAnd then I see my hard drive partition.\nIf you install Ubuntu and go into computer management\\storage\\disk management and look at your partitions, you will see your partitions and you may see Ubuntu there. You can even\n\n\n*\n\n*Open the partition,\n\n*Explore the partition,\n\n*Mark the partition as active,\n\n*Change the drive letters and paths,\n\n*Shrink the volume,\n\n*Look at its properties, and\n\n*Get help.\n\n\nYou can not\n\n\n*\n\n*Format the volume,\n\n*Extend the volume,\nor\n\n*Add a mirror.\n\n\nA: For the most part they are the same.  Hibernation is not supported.  Your performance bottlenecks may be different since the filesystem is compressed (with a fast processor and slow disk your performance might actually be slightly better).  You'll be at the mercy of the fragmentation of the underlying NTFS system, so be sure to thoroughly defragment before installing (Ultradefrag (available on sourceforge) does a much more thorough job than the built-in Windows one).  \nThe one gotcha that I have noticed in all the versions I have used is that power failures while running the Ubuntu install quite often leave Ubuntu in an unbootable state.  Fixing it, while possible, is something of a pain.  As such, if the purpose behind using wubi is to test and see if you can use Ubuntu for your purposes, and the machine on which you are using it has two or more processor cores, I usually recommend VirtualBox instead as being more reliable and more useful for testing since you can switch back and forth instantly instead of having to reboot.\n\nA: I never found any performance issues with Wubi installation. Wubi is great for those who don't want to have lots of hassles on Ubuntu Installation.\nNot every person wants hibernation.\nThe main problem with Wubi installation is disk allocation, which is limited to 30 GB max. But in normal installation you can use the whole drive (80 GB or more).\nYes if windows goes off, Ubuntu may not work.\n", "Q: iPod is not visible to Banshee 1.5.0 I have a brand new ipod nano, and if I plug it in to my media center running Ubuntu 9.10, it gets mounted and I can see it in Nautilus.\nBanshee, however, does not list it anywhere. Under preferences/extensions, I've checked that the ipod plugin is enabled.\nRhythmbox could see it okay. I found some forums suggesting uninstalling Rythmbox might help, but it hasn't.\nAny other suggestions about why Banshee won't see it? \nIs the ipod too new?\nThanks.\n\nA: Banshee upstream is currently moving to libgpod, which is the same library that Rhythmbox uses, when this move is complete you should have better ipod support.\nThe Banshee team publishes stable releases in a PPA here: \n- https://launchpad.net/~banshee-team/+archive/ppa \nHowever I am not sure if they will backport all the necessary bits to this PPA when the move is complete.\nUnfortunately the ipod support in libgpod as shipped in 9.10 is not as good as 10.04, this is one of those cases where an upgrade will probably help you out to get support in Rhythmbox, and in the future (10.10 timeframe) Banshee will improve in this regard as well.\n", "Q: Setting up a build system for Python app In trying to sort out this issue, I have run into the following problem.\nI have a Python script that gets installed to /usr/lib/. But I need to get this script into a build system so that I can get it working with my package.\nAny help would be appreciated. Although I've worked a bit with Makefiles when writing C++ applications before, I've never created any kind of Makefile for Python files (nor do I even know where to start).\nHow would I go about setting up a build system for my app?\n\nA: Well, like I explained on the other question, you don't need a build system and in that particular case, may be better off without one.\nHowever, the most standard one is distutils. Just provide the metadata (i.e. name, description, etc) and a list of (python) packages, modules and scripts (all of them are optional) and it's done.\nFinally, if you'd like to generate a debian package out of your project, then you can very easily do that by using python-stdeb (uses dh7, which I like better) or python-mkdebian (uses cdbs). There are many more differences between these tools, but I'll let you discover them yourself. Just note that both require using distutils. (python-mkdebian is part of the python-distutils-extra package in Ubuntu, I haven't used -extra much, but you can try that as well if you'd like)\n\nA: Scons is a build system which uses Python as it's language (I generally prefer it over makefiles for any project), I think it should be capable of what you want to do.\nIt has a very good User Guide.\n\nA: Umang has the right answer, though perhaps not in as much detail as you might seem to need as a complete beginner.\nFor a Python program, you need to start by creating a setup.py file. The bulk of the file will be a call to distutils.core.setup - this is discussed in detail in part 2 of the distutils documentation.\nAll other packaging systems for Python (such as py2exe, setuptools, or Distribute) build on top of the distutils package, usually by extending setup() in some way (with additional parameters or commands).\nBefore converting this into an Ubuntu package, you can test the setup script by running sudo setup.py install. It should install the files into their expected locations; if it doesn't you may need to check your configuration. In particular, sections 2.5 (scripts) and 2.6 (package data) of the distutils documentation probably apply to your situation.\nOnce that's done, you can then look at layering on the Ubuntu packaging according to the Ubuntu Packaging Guide for Python. The python-stdeb and python-mkdebian tools suggested by Umang simplify the generation of the various files required for Ubuntu packaging.\n\nA: Make sure to check out: \nhttp://pypi.python.org/pypi/modern-package-template/1.0\nFor a good default package layout including a starter setup.py file\nhttp://pypi.python.org/pypi/virtualenv\nFor blocking off your dev environment from the rest of your system. Running something like\npython setup.py develop\nWill build/setup your command into your virtualenv so you can test it out. \n", "Q: What's the best Mind Mapping Software? Back in the dark days when I used to run windows I used to use MindJet Mindmanager and I found it to be very good. \nSince I have been using Ubuntu as my main operating system I have been trying to find a replacement mind map software to use but have not had any luck finding a good replacment. \nSo far I have tried VYM, kdisset and Semantik. I have either found them not to be very good or have a nasty habit of crashing. \nSo I was wondering could anyone recommend good mind mapping software to use under Ubuntu?\n\nA: Mindmeister — online lightweight mind mapping tool.\n\nA: I like FreeMind  very much, which is a Java mindmapping tool. Colleagues of me like XMind most.\n\nA: After browsing through the various options here, which mostly aren't in 16.04 repos I think, I tried xournal, which I noticed Yann LeCun uses in his lectures.  It works pretty well.  I modified it slightly so its easier to autorecognize lines https://github.com/hughperkins/xournal/tree/easier-autolines\n\nA: Minder is available as a flatpak in Pop!_OS, so it should work similarly in Ubuntu: https://github.com/phase1geo/Minder\nIt is styled after Elementary OS\nThese answers should be updated as many of these programs appear to be obsoleted. Here is a more current list: https://www.fossmint.com/free-mind-mapping-software-for-linux/ which does NOT include Minder for some reason (probably due to naming, it is difficult to search for \"Minder mind mapping software\" without a search auto-correcting you away from intended results due to assuming you had a typo or duplicate word)\n\nA: You could always try running MindJet MindManager under Wine.  Apparently some people have had some success doing so.  If all else fails, you could run a windows guest system on an  Ubuntu host via Virtualbox.\n\nA: XMind has better graphics than Freemind but it's much heavier.\nPro's include:\n\n\n*\n\n*Good customizable GUI.  \n\n*Available for any major platform.\n\n*There's a portable version for the USB.\n\n\nCon's:\n\n\n*\n\n*It's java based. That makes it a bit slow.\n\n\nA: Try using Freeplane .\nFreeplane is a powerful and free software for building the mind maps. It is a redesigned version of the well known FreeMind, and is created by one of FreeMind's key developers. I prefer it over FreeMind since there are more options. Also, questions or problems with the program are answered and fixed MUCH faster.\n\nA: Another good one to try is Personal Brain, it has a free flow feel to it.\n\nA: I've tried Freemind and really didn't like it.\nThe one I liked the most on Ubuntu was Semantik, both for its ease of use and because Semantik mind-maps are exportable to ODT as outlines.\nOne downside is that it's a KDE app so it wouldn't integrate with your desktop  well.\n\nA: It is VUE Visual Understanding Environment whic can be download from: https://vue.tufts.edu/download/index.cfm, I use it in Windows 7 & love it and having a Ubuntu version is an add to the software...\n\nA: I started using VYM (View your Mind) http://www.insilmaril.de/vym/\n\nA: Labyrinth is a lightweight mindmapping tool in the ubuntu repository. It's features are not much compared to freeplane. But it can do basic mind mapping.\nInstall it with sudo apt install labyrinth \n", "Q: Input language switching keys only accept shift-alt instead of alt-shift On my Ubuntu UNR install, for some reason, I'm only able to switch the input language if I press Shift and then Alt. This is quite the opposite of what usually works -- on Windows and other Ubuntu/other Linux systems -- where I press Alt and then add Shift.\nAnyone know why this is?\n\nA: If it's only happening on your netbook, the issue is probably an incorrect keymap. Low-level tools for examining a keyboard include xkeycaps and showkey; this should at least tell you what keycodes are getting generated.\nAt a guess, you may the Alt key mapped as AltGr or a dead key; in that case the use of Shift first might be modifying it back to an Alt key. If that was the case however you would typically see this behaviour with only the left or right Alt (I've never seen a keymap with two AltGr keys).\n\nA: Try this:\n 1. System\n 2. Preferences\n 3. Keyboard\n 4. Layouts (Tab)\n 5. Options...\n 6. Key(s) to change layout\n 7. Change to the key combo you want :D\nI otherwise have no idea why it would be in a different order. I can only suggest swapping key combinations and then back to Alt+Shift.\n\nA: Unfortunately, there are a number of long-standing bugs in handling switching between keyboard layout. I, for one, had problem with those in 9.10. For me they were fixed in 10.04. (FYI, this is the bug that bit me.) Perhaps and upgrade to 10.04, which is a stable one after all, might fix this. Alternatively you might use a different key - I use the menu key, which has no use whatever for me.\n\nA: This is most likely a papercut.\nsee https://launchpad.net/hundredpapercuts\n\nA: In my case it seems to be doing this whenever I set any Shift keys to toggle or cancel Caps Lock under the Miscellaneous compatibility options in the Keyboard Preferences (Keyboard Layout Options).\n", "Q: Starting a guest session from the login screen I was wondering what is the best way to start the guest session from the login screen (GDM).\nCurrently, I created a new user called 'ubuntu-guest' (has to be something other than 'guest'). Then added the following script to the Startup Applications.\n\n#!/bin/bash\n/usr/share/gdm/guest-session/guest-session-launch &\n/usr/bin/gnome-session-save --logout\n\nThe problem with this method, is that when you log in as 'ubuntu-guest', you have to start up two gnome sessions: one for 'ubuntu-guest' and one for the actual guest account.\nPlease let me know if you have any other better ideas. Thanks!\n\nA: 1. Never allow any Temporary User without a password to gain Access Control of your computer!\nFIRST Make a policy to prevent the single user guest from making system wide changes\nopen text editor gksu gedit /etc/polkit-1/localauthority/50-local.d/10-desktop-policy.pkla\ninsert text\n[guest-policy]\nIdentity=unix-user:guest\nAction=*\nResultAny=no\nResultInactive=no\nResultActive=no\n\n2. open terminal and start typing\nsudo addgroup --system --quiet --gid 126 guest\nsudo useradd -c Guest,,, -d /tmp/guest-home.UBUNTU -m -s /bin/bash -g guest guest\nsudo usermod --uid 117 --gid 126 guest\n\nto create blank password for this account:\nsudo usermod --password U6aMy0wojraho guest\n\nto create Not asked for password on login for this account:\nsudo usermod --groups nopasswdlogin guest\n\nEdit /etc/gdm/gdm.schemas\ntype:\ngksu gedit /etc/gdm/gdm.schemas\n\nand add guest to greeter/Include\ndefault\n    <schema>\n      <key>greeter/Include</key>\n      <signature>s</signature>\n      <default>guest</default>\n    </schema>\nnow sudo restart gdm\nNOTE: you will no longer be abel login to guest sessions from user accounts\nthis is the new guest session\nand you will only be able to login from login screen any changes to this account will remain on logout until the computer restarts.\nto restore open terminal and type:\nsudo userdel guest\n\nthen sudo restart gdm\nto copy your settings for guest session\nsudo cp -R ~/.gconf/desktop /etc/gconf/gconf.xml.system/\nsudo cp -R ~/.gconf/apps /etc/gconf/gconf.xml.system/\nsudo chmod 777 -R /etc/gconf/gconf.xml.system/desktop\nsudo chmod 777 -R /etc/gconf/gconf.xml.system/apps\n\n\nA: There are forum posts and bug reports a-plenty on this. In one bug report, someone described a redneck guest session account they set up that might work for you.\n\n1.- Create a count without privileges (example Guest). Then password = guest\n:P Any easy.\n2.- Configure this count (Guest).\n3.- Add all files (included hidden) to a .tar file and save it (example /etc/init.d/guest.tar)\n4.- Create this file /etc/init.d/guest.sh\nWith this context:\n#!/bin/sh\nrm -rf /home/guest\nmkdir /home/guest\nchown guest:guest /home/guest\ntar -C /home/guest -xvf /etc/init.d/guest.tar\n\n5.- In terminal:\nsudo chmod +x /etc/init.d/guest.sh\nsudo update-rc.d guest.sh defaults\n\n\n\nA: Lock Down\nYou might want to look into this answer if you want to »Lock Down« a user account.\n", "Q: How do I set up printer sharing with a Windows 7 machine in Ubuntu? I have a Brother HL-2040 plugged into my Ubuntu 10.04 machine and an HP DeskJet 6540 plugged into a Windows 7 machine on the same network.  Out of the box the Windows machine does not see the Ubuntu-attached printer and the Ubuntu machine does not see the Windows-attached printer.  \nI right clicked and Shared each printer on its own machine.  I selected System --> Administration --> Printing --> Server --> Settings and checked the publish printer and show other printer options.  I believe I set up sharing on the Windows machine as well.  Still, neither machine see the other printer.\nHow do I set up printer sharing, so that each machine can see the other printer?\n\nA: This is a two part question, requiring 2 part answer.\nFirst, Windows -> Ubuntu:\nTo begin with, you need to make sure that your windows host allows connecting to the printers. There are various things that could disallow access, the most common one being Windows Firewall.\nHere is a quick howto\nNow that you have a working share on your windows host, you need to add the printer to your Ubuntu host. This can be accomplished by going to System -> Administration -> Printing and by selecting the + Add button. From there the wizard will guide you through adding the printer. You will need to know the IP address or name of the windows host and name of the printer being shared to complete the wizard.\nNext Ubuntu -> Windows:\nThe easiest way to accomplish this is by using IPP share to connect to the printer. Start by enabling Internet Printing Client as described in this knowledge base article\nbrowsing to http://IP.OF.UBUNTU.HOST:631/printers/ and select the printer you wish to connect to and make a note of the full URL of the printer. Now go to Printers and Faxes on the windows host and start adding a network printer. At one point of the installation wizard you will be asked for the location of the printer, in the IPP field enter the address for the printer found on the webpage.\nWhen the wizard asks for the driver to be used for the printer, use the CUPS Windows driver available from CUPS download page\nContinue through the wizard and fill in the rest of the information normally.\nYou can also use the native driver for the printer, but you will then need to edit the CUPS mimetype support to include RAW printing which is done by editing /etc/cups/mime.convs file and uncommenting this line:\napplication/octet-stream application/vnd.cups-raw 0\n\nYou will also need to edit /etc/cups/mime.types and uncomment the line\napplication/octet-stream\n\nAfter editing the files and restarting CUPS, you are able to print with native drivers as well.\n", "Q: What scientific plotting software is available? I am currently doing some experimental work and I have a lot of data to trawl though. I use Gnumeric, and it's very good, but often I feel there has to be something better.\nIdeally I would like the maximum number of features with a minimal learning curve, but really I'd just like to know if there is something better than Gnumeric that I can use for manipulating and plotting data.\nWhat would you recommend?\n\nA: Sage might be good for that. It ties together a lot of open source math tools to create a very extensive and flexible app.\n\nA: I've used qtoctave.  It is similar to MATLAB if you've used that before.\nYou can install it from the repositories: sudo apt-get install qtoctave\n\nA: gnuplot and xmgr/grace are probably the oldest Unix scientific graphing programs. I still use gnuplot from time to time (BTW it is not GNU and some consider it not free), because I know it and I've been using it for many years, but it hasn't changed much in this century and it's not user-friendly according to today's standards.\nI think that the most promising programs now are QtiPlot, LabPlot and Veusz.\nThe first two are similar to Origin (the most popular plotting software on Windows). QtiPlot has a full-time developer and it seems to be developed more actively. Veusz is different than Origin clones and unlike other programs it is written in Python. It's not in the distro yet, but it has PPA.\nAnother program that I use for plotting data is fityk. It is specialized in curve fitting and I use it for plotting mostly because I know it well (I wrote it), but I guess in most of cases QtiPlot or Veusz will be the best choice.\n\nA: I used SciDavis, Scilab and MatplotLib. However lately I am using ParaView, but this is not an easy to use program. The previous ones are easy.\n\nA: I am a Physics student and found that the best scientific plotting software for Ubuntu is QtiPlot. It is very similar to Origin, and works really well.\n\nA: Numpy and Matplotlib make a good combination for processing and displaying data.\n\nA: I would suggest Gnuplot. It has a nifty set of features and is good documented. So if you take some minutes to skim through the documentation you'll get the basic idea. I use gnuplot for nearly all my plots, only when I don't need the full set of features I tend to use TikZ from LaTeX.\n\nA: I would suggest DataScene. It produces really cool graphs and chart animations. I found the learning curve is fairy flat because of the Wizard and tutorials. You may find more information on DataScene at:\nhttp://www.cyber-wit.com\n\nA: MagicPlot is also available for Linux, it requires Java. It is very useful for creating good-looking graphs and some processing. And it is free for students.\n\nA: Veusz is the best open source plotting tool I could find so far. It allows to set very detailed attributes of scientific plots, like minor and major tick size. It also provides operations to manipulate data sets. It supports SVG export and can be remotely controlled from other programs. Furthermore, my experiences with the support have been very good. The author answered my question within a day and implemented a feature request within two weeks. \n\nA: The R language is also quite popular and can be combined with Sweave for use with Latex.\n\nA: Ggplot2\nIs one of the best data visualization programs available. It implements the ideas of Edward Tufte, author of classics in graphical design and scientific communication as 'Beautiful Evidence' and 'The Visual Display of Quantitative Information'.\nThe Deducer GUI makes it possible to use ggplot2 without requiring knowledge of the R programming language in which ggplot2 is implemented. If you can use excel, you can use Deducer. Your statistical analyses will be valid and your graphs (thanks to ggplot2) will be effective and pretty.\n#dependencies\nsudo apt-get install r-core\nsudo apt-get install rJava default-jdk\nsudo R CMD javareconf\nsudo R\n#to install deducer\ninstall.packages('JGR')\ninstall.packages('Deducer')\nlibrary(JGR)\nJGR()\n#in JGR\nlibrary(Deducer)\n\n\nA: MATLAB might be the best but it's not only for plotting and it's not free (actually it's expensive however if you are student, you can probably get it from your school).\n\nA: R would be best for both statistical tests and graphs. If you're fine with programming, go for R. It's open-source and powerful.\nOr give BioVinci a try if programming costs you too much time. It lets you drag and drop your data to run statistics and create plots. I like the modern plot types it offers, like violin plot and interactive 3D scatter plot (with hovering info). Plus there's PCA -- really helpful for scientific research. One more, it supports Ubuntu 16.04, 18.04, and Debian 9.\nHope this helps!\nHere's a screenshot of its PCA 3D plot.\n\nA: I would like to suggest the supermongo for scientific use. Although it is expansive but you can get it from your institute or research center. This is very user friendly and easy to operate. You can plot your data with high resolution and advanced settings.\n", "Q: Parental controls with different settings for different users Does anyone know of a good way to set up some sort of parental controls so that one user account is subject to them, but not another?\nA couple of friends of mine use Ubuntu and have kids (7 to 10 years old) who use the family computer. They'd like to have some blocking of adult sites. They're not going to supervise all the time, which I know might be ideal, but there we go. And they're not particularly technical, so they don't want to have to run scripts to turn the parental controls on and off regularly, but they can cope with having different accounts for different people. I haven't found a great way of doing this. I am pretty technical, so I'm happy to spend some time at the command line to set it up, but then it needs to just work.\nPlease don't just link to DansGuardian. If your answer doesn't address the different user account aspect, I will vote it down. If you want to talk about general parental controls that apply to all users then please start a new question - I'm sure that plenty of people would be interested in it, and I'll link to it from this question.\n\nA: DansGuardian ;-), but with a twist \n-- the trick is to set up\ntransparent proxying (filtered by DansGuardian) and use iptables to\nredirect children's accounts only to the proxy.  Parents would have\nnormal direct connection to the network.\nHere's a sketch of how to do it:\n\n\n*\n\n*Set up DansGuardian and Squid for transparent proxying. Ignore all\nthe iptables/redir setup, because we're doing it in later steps.\n\n*Set up a netfilter chain for transparent proxying:\n iptables -t nat -N transparent-proxy \n iptables -t nat -A transparent-proxy -p tcp --dport 80 -j DNAT --to-destination :8080\n\n(Assuming you have configured DansGuardian to listen on port 8080.)\n\n*Now you should set up an iptables chain so that only packets\noriginating from selected local accounts are sent to the transparent\nproxy; all the others flow undisturbed. Netfilter has a owner match\nfor this:\niptables -t nat -A OUTPUT -m owner --uid-owner child_uid -j transparent-proxy\n\n\nA: There are several firefox addons that offer content filtering. I believe this is a good solution for what you want because browser extensions are installed on a per-user basis.\nYou can find such addons on the firefox addons site. An example of a content filtering extension is ProCon Latte.\nBesides web safety, children should have a seperate non-administrator login, to prevent them doing system changing activities such as installing new software (such as a different browser to bypass the parental controls).\n\nA: Gnome Nanny looks like it would meet the needs of your friends perfectly. To quote the website:\n\nGnome Nanny is an easy way to control what your kids are doing in the computer. You can limit how much time a day each one of them is browsing the web, chatting or doing email. You can also decide at which times of the day the can do this things. Gnome Nanny filters what web pages are seen by each user, so you can block all undesirable webs and have your kids enjoy the internet with ease of mind, no more worries!\n\n\n\nAs you can see, Nanny can set different restrictions for each account. nanny 2.29.4-0ubuntu4 is available in the maverick and natty universe repositories. It is also part of Edubuntu. Screenshots of Nanny running on Edubuntu are available on the Edubuntu website.\n", "Q: How to move /usr to a new partition? My /usr folder needs to get moved to a new partition. How can I do this without erasing the contents?\nCan this be done while Ubuntu is running, or do I need to use the LiveCD for this?\n\nA: Since most libraries that are used are in /usr, I would not recommend to move this directory while running Ubuntu. In fact, you probably get error messages when you try to do this. Hence, the best is to use the LiveCD.\nYou can use several possibilities to move/copy the files cp, rsync etc. you want to make sure that any symlinks are created and not just copied. cp and rsync both have options for this.\nAfter moving the files to the other partition you need to add another mount in /etc/fstab to mount the new partition to /usr.\n\nA: It would be safest to use a Live CD, but you could do:\n\n*\n\n*copy all the files to a new partition, making sure that the contents of /usr do not change while you are doing this.\n\n*edit /etc/fstab so that /usr will be mounted on the next reboot\n\n*reboot\n\n*delete the old files\n\nSee below for details on each step.\nNote that you can't mount the new partition on /usr while running as there will be lots of files in /usr that will be open.\nCopying the files\nI would use cp -a. -a is the archive option. From the man page:\n-a, --archive\n          same as -dR --preserve=all\n...\n-d     same as --no-dereference --preserve=links\n...\n-P, --no-dereference\n          never follow symbolic links in SOURCE\n...\n--preserve[=ATTR_LIST]\n          preserve      the      specified      attributes       (default:\n          mode,ownership,timestamps),  if  possible additional attributes:\n          context, links, xattr, all\n...\n-R, -r, --recursive\n          copy directories recursively\n\nEditing /etc/fstab\nYou need to know the UUID of your new partition. You can see the mapping by doing:\n$ ls -l /dev/disk/by-uuid/\n\nor\n$ sudo blkid\n\nAnd then add this line to /etc/fstab:\nUUID=634c31a5-e27c-4e33-ac67-2e22491a30c2 /usr           ext4    defaults        0       2\n\nChange the UUID to your UUID, and change ext4 to be the file system type you are using - you should know this if you have set up the partition.\nDelete the old files\nAfter the reboot, the old files in /usr on the root partition will be hidden by the new partition mounted on /usr. But we can use some mount bind trickery to get to the old files and then delete them.\n$ sudo mount --bind / /mnt\n$ sudo rm -rf /mnt/usr/*\n$ sudo umount /mnt\n\nBut some slight mistyping (say, hitting Enter when you'd only typed sudo rm -rf /mnt ) could cause disaster, so I would only use this method if you were very confident in what you were doing, really couldn't deal with any downtime, or had no physical access to the machine and hence were unable to boot off a live CD or live USB stick.\n\nA: This is how I've done it (following the Hamish's answer and the comments):\n\n*\n\n*Copy all the files the newly created partition (replace with the location of your partition, it should look similar to mine):\n rsync -avz /usr/* /media/aleksandar/750b84e2-e65f-4309-ade5-5af0033a937c \n\n\n\n*Edit /etc/fstab (same as in Hamish's answer, of course, replace xxxxxx with your UUID)\n UUID=xxxxxx/usr           ext4    defaults        0       2\n\n\n\n*Reboot the system\n\n\n*After rebooting, open System Monitor or similar application to see whether your new /usr partition is mounted, and to safety-check whether everything went as planned.\n\n\n*After checking that everything is alright, you can delete your old /usr partition. I will keep mine just in case something goes wrong.\n", "Q: What support does Ubuntu have for the Apple Magic Mouse? Does Ubuntu support the full functionality of the Apple Magic Mouse? What bluetooth adapters work best? What are the caveats?\n\nA: Please see this to get help with MultiTouch in Ubuntu: https://wiki.ubuntu.com/Multitouch#Community%20Help\nThere is a section dedicated to the Apple Magic Mouse, I also have that device and am interested in documenting any multitouch information there.\nThe above page also includes information on testing and using demos for multitouch.\nIf you want to see the current gestures available in Ubuntu 10.10 you will need to install the Netbook edition (Unity). On a standard desktop you don't need to reinstall, just add the ubuntu-netbook package, logout, and login again making sure you choose Ubuntu Netbook Edition at the bottom of the login screen (after choosing your user).\n\nA: Ubuntu supports using it as a standard mouse (move the cursor and left/right clicks). As far as I know, all bluetooth adapters work out of the box.\nThe driver updates in the next version (Maverick, 10.10) are expected to support scrolling and might support multitouch.\nAccording to this forum post someone has backported the scrolling support to Lucid, but it doesn't appear to be available in a PPA yet.\n", "Q: How can I sync my Ubuntu One music to an mp3 player? Is there a way to automatically sync just my Ubuntu One music (and not the rest of my Music Library) to my Sansa Fuze mp3 player?\n\nA: Here is my solution:\nPlaced the following autorun script in the root directory of my mp3 player, and run it when I plug it in.\n#!/bin/bash\n\n# sync Ubuntu One music\nrsync -avz -stats --ignore-existing ~/.ubuntuone/Purchased\\ from\\ Ubuntu\\ One/ MUSIC/Ubuntu\\ One\n\n\nA: I found this https://launchpad.net/rhythmbox-playlist-sync Which allows you to Sync playlists with external devices. You could use the Purchased Music list and sync only that list with your portable device.\nI have not tested this actual plugin and can not speak to its validity. This is simply a hypothetical-type answer.\n\nA: Unfortunately that is not possible at the moment as there are no MP3-player clients of UbuntuOne.\nHowever, you could try the synchronisation feature for music players of Banshee. This feature would synchronise your player each time you would connect it to your Banshee-running computer with the playlist you selected, or your whole music library.\nI'm not sure if Rhythmbox has a similar functionality. \n", "Q: Is it possible to delete files when another filesystem is mounted on the path? Having just written an answer about moving /usr to a new partition I was wondering about deleting files once a new partition has been mounted. To use the example from the question, is it possible to mount a new partition on /usr and then delete all the files under /usr on the root partition to free up space on the root partition.\n\nA: Not directly, but there is a way around that: mount --bind is your friend:\n# Existing directory with a couple files in it\nroot@nkubuntu1004:~/test# ls testdir\nbar  foo\n\n# Mount a filesystem over existing directory\nroot@nkubuntu1004:~/test# mount -o loop testfs testdir\nroot@nkubuntu1004:~/test# ls testdir\nlost+found\n\n# Bind mount root filesystem to another directory\nroot@nkubuntu1004:~/test# mount --bind / bindmnt\n\n# Can now get to contents of original directory through the bind mount\nroot@nkubuntu1004:~/test# ls bindmnt/root/test/testdir/\nbar  foo\n\n# Remove a file\nroot@nkubuntu1004:~/test# rm bindmnt/root/test/testdir/bar\nroot@nkubuntu1004:~/test# ls bindmnt/root/test/testdir/\nfoo\nroot@nkubuntu1004:~/test# ls testdir\nlost+found\n\n# Unmount filesystem\nroot@nkubuntu1004:~/test# umount testdir\n\n# Observe the change having taken effect\nroot@nkubuntu1004:~/test# ls testdir\nfoo\nroot@nkubuntu1004:~/test#\n\nSee also man mount -- search for \"bind mounts\".\n", "Q: Blurry fonts after upgrading to 10.04, Nvidia issue? Recently I upgraded from 8.04 LTS to 10.04. \nThe previous version had some problems regarding screen settings. X only recognised 1024x768 as resolution of my monitor, mainly because the monitor was not identified correctly. \nWith 10.04 the monitor and its resolutions are identified correctly and the system chooses a better resolution. \nBut now the fonts seem blurry. They are hard to read. I tried a larger font size which improves the situation a bit. I also played around with nvidia-settings. If I choose 1024x768 again, the fonts look good. \nAlso some resolutions with specific refresh rates seem better. Another thing I tried was to change hinting settings. However the best variant was already chosen.\nSo I've run out of ideas for a solution. Do you have any hints? \nMy graphics card is nVidia Corporation C68 GeForce 7050 PV / nForce 630a (rev a2).\n\nA: You might be using wrong settings for subpixel hinting - it might be turned on when it shouldn't be, depending on your monitor. I've found that 10.04 defaults to having it turned on with LCD panels (haven't tested a CRT in a while.)\nYour panel might be also returning the wrong information about the color order.\nCheck the Appearance settings. nvidia-settings may override the Free Software stack - there's a lot of points where nvidia driver does odd things. Try temporarily removing the nvidia driver to let nouveau drive the hardware and see if the situation improves.\nAs of note nouveau in Ubuntu 10.04 does not have 3D acceleration, but is quite fine in 2D.\n\nA: I've read that in 8.04 all vertical lines in fonts are drawn sharply, but in following releases, vertical lines in fonts are blurred a little. It may or may not be the problem you're having, but it's worth looking at. This blog post explains how to revert the setting.\n\nA: Try changing the font rendering options.\nStart with...\nSystem > Preferences > Appearance > Fonts > Details\n\n... and play with the smoothing and hinting options. I know I played a while until I felt the fonts were well rendered.\n\nA: I played around with my installation in the last few days. What seemed to help was uninstall all nvidia stuff, remove the old /etc/X11/xorg.conf and reinstall nvidia again. I'll have to go through this old xorg.conf. Maybe there was some strange setting.\nI could manage to start the Nouveau driver, but there was no real improvement regarding font settings. The only drawback it had, was the missing 3d acceleration. Thatswhy I went back to nvidia binaries. However in a few weeks I'll try nouveau again. Maybe it has improved in some way.\n", "Q: How do I set up Ubuntu Server 10.04 LTS to serve as a samba Primary Domain Controller uses pam modules to authenticate against an LDAP server? I'd like to have a Samba server that appears as a Primary Domain Controller (PDC) to a bunch of windows lab computers. But instead of having the users have accounts with passwords stored on this Samba PDC, I'd like to have all the account information stored on our functioning LDAP server.\nSo, when a user logs into a Windows lab machine, they can do so with their LDAP username and password. If I have to change their password, I just have to do it in the LDAP server. The next time they log into this \"proxy PDC,\" they'll be able to use their new LDAP password.\nI have a functioning LDAP server and a server that I can use to create the Samba PDC. I've played around with Samba before, but I've always had to have a local Linux account for each user that I wanted to access samba and I had to create a corresponding Samba account for each of those users. Those are the steps that I'd like to avoid if possible.\n\nA: There are guides like this one which look at this issue thoroughly.\nI find this quite difficult to answer, given all the variables. Since samba and openldap need some extra configuration, an answer here might not be complete.\n\nA: I found a pretty easy howto here and although it was written for Ubuntu 7.10 it still works i just tested it.. Even though i didn't install webmin, i better like editing the DNS (bind9) config files by hand.\n\nA: Have a look at the Ubuntu Server Guide. It explains the integration of Samba and LDAP and many other topics. It's updated for every Ubuntu Version.\n", "Q: Clock applet stops after login I realized a second strange thing after upgrading from 8.04 LTS to 10.04. My (GNOME) panel contains the clock applet. This applet shows current date and time. The time is not upgraded after I start a GNOME session. When I remove the applet and insert it again, it works fine. But at some point it stops again. Has anyone seen this? Is there a workaround? Several other people seem to have the same problem, but as far as I saw it they had no solution.\n\nA: In a bug report on this issue one commenter says that a workaround for another bug fixed the clock freezing problem for him. The workaround delays the startup of gnome-panel for three seconds. (Strange, eh?)\nHere is the workaround:\n\n\n*\n\n*Create a script called delayed-gnome-panel.sh in your home directory and mark it as executable.\n\n*Edit the script to look like this:\n#! /bin/bash\nsleep 3 && gnome-panel &\nexit\n\n\n*Then edit /usr/share/applications/gnome-panel.desktop so that exec=bash /home/<user>/delayed-gnome-panel.sh.\n", "Q: Where can I find alternatives to...? There has been a couple questions here regarding alternatives to certain programs, and I'm sure as more people start using Ubuntu, and join this site, there will be more people looking for alternatives to programs they used in their previous operating system.\nTherefore I figured I start a thread to list different sites that list alternatives to programs.\n(Please just post one link per answer).\n\nA: osalt - open source as alternative \nFrom website:\n\nOur mission is to provide easy access to high quality open source alternatives to well-known commercial products. And remember that open source software is also a freeware alternative.\n\nJust like the other sites suggested it gives alternatives to proprietary programs.\n\nA: alternativeTo\nFrom website:\n\nAlternativeTo is a new approach to finding good software. Tell us what application you want to replace and we give you great alternatives, based on user recommendations\n\nThis site has a sizable list of alternatives for a sizable number of programs.\n\nA: LinuxAlt - The Linux Alternative Project\nFrom the website:\n\nMy goal is to provide an informational website available to all linux users. The website is currently in beta form and I will periodically update the database with Windows software and the Linux equivalents and alternatives. \n\nThe site has a very lengthy list of Windows programs and their Linux alternatives. The website is apparently still under active development.\n\nA: sudo apt-get install synaptic\nKeyword search every package available from the apt-get repositories as well as any ppa installed on your system.\n", "Q: What is Ubuntu SSO? At login.ubuntu.com it says Ubuntu Single Sign On.\nWhat are its uses?\nHow is it useful?\n\nA: login.ubuntu.com is a service used by various Ubuntu websites that allow you to use a single account for login instead of creating a separate account for each.\n", "Q: How can I contribute to Ubuntu? I would like to know what kinds of contributions someone can make to Ubuntu. Such as Programmer, User, Proofreader, etc.\n\nA: The Ubuntu Beginners Team is a team focused on helping new users and users who want to become more involved in the community.\n\nA: https://wiki.ubuntu.com/ContributeToUbuntu can give you some ideas.\n\nA: There are many, many ways to contribute to Ubuntu. Some require technical knowledge, but many do not.\nBefore contributing to Ubuntu, you should read the Ubuntu Code of Conduct, which lays out a standard of behavior for contributors.\n(Mostly) Non-technical:\nPerhaps the easiest way to contribute to the Ubuntu community is to provide support. Besides helping out friends and family, you can answer questions on IRC, the Ubuntu Forums, or on this exchange!\nA new project that is looking for contributors is the Ubuntu Manual project. According to their website, \n\nGetting Started with Ubuntu is a complete beginner's manual for\n  Ubuntu, featuring comprehensive guides, How Tos, and information on\n  anything you need to know after first installing Ubuntu.\n\nTheir Get Involved page says they are looking for authors, editors, translators, programmers, and designers -- there's something for everyone!\nAnother project for writers is the Documentation Team. They write the documentation that comes with Ubuntu and work on the help wiki.\nThe One Hundred Papercuts project calls for users to submit bug reports on small usability problems (paper cuts). This requires almost no technical knowledge and has a direct affect on the Ubuntu experience.\nUbuntu strives to look good, and it takes artists to make that happen. Submitting art is an easy way to make a visual impact on Ubuntu. Check out the Artwork wiki page for information about that.\nA really fun way to get involved is to join and participate in your Local Ubuntu Community (LoCo). You can check out the list of Ubuntu LoCos to see if there is an active community near you. If there is none, you can start one yourself!\nAs Javier Rivera commented below, multilingual users should look at contributing translations. Someone new to translations can get started with the Translations Quick Start Guide.\nMore Technical:\nIf you're the programming sort, there's plenty of room for you to pitch in. I'm not an Ubuntu developer myself, but the Developers page on the Ubuntu website is a good place to get started.\nAt the beginning of a new project called Operation Cleansweep, there were over two thousand potential bug fixes on Launchpad just waiting to be applied. This project works to review those patches and get them applied to their projects.\nConclusion:\nThere are innumerable ways to contribute. These are only just a few! Technical knowledge is helpful, but not absolutely necessary.\n\nA: You can start from here if you know any language other than English.\n\nA: There are many ways how you can be useful for the ubuntu community in general. Some aspects require technical knowledge and others don't. Each and every one of the community members have something they can contribute back if they so wish. A good place to start looking for your own place in the community is in the community page. This page lists various good places to start looking for something that you can help with.\nYou should keep in mind that even if you can't find anything you can do on that page, it doesn't mean that you can't still be a useful community member.\n\nA: Contributing to any Open Source/Free Software project does not necessarily require technical skills. Of course one main part of developing software is writing code. Here you will indeed need technical skills. But the user of that software is usually a non-technical person. So if you want to contribute you can take the role of that user and test the software. If there is something which annoys you or if there is a bug, you should inform the developers about it. Send them a detailed description of what you want to improve or how the bug occurs and can be reproduced. This will help to make the software better.\nAnother thing what usually helps a lot is writing documentation. How can/should the software be installed; what first steps should a user do; are there special settings which ease the use of this software etc. Also important is to translate existing documentation into another language.\nUbuntu uses Launchpad for most of those tasks. You can get a login there and contribute. Give it a try! \n\nA: One way to start would be by joining your local Ubuntu Local Team. Find your local team at http://loco.ubuntu.com/\n", "Q: What are windicators? I heard 10.10 will have windicators, what are they? How will they look?\n\nA: This article explains it best with mockups, etc. The jist of it is though. Much like the new Indicator Applet, Windicators will actually be an Indicator that sits on the window likely occupying whatever space the window controls (Min, Max, Close) aren't. They can display status messages like whether the current screen isn't save, the application is busy, or a variety of other indicators. This should take the guess work out of some applications and help streamline others - the intent upon which is to make the UI more accessible to the user.\n", "Q: Why aren't multimedia codecs included by default? Are there any legal reasons for that?\n\nA: Some are for legal reasons - some video/audio formats require further license agreements or don't quite fit under the Ubuntu license schema. You can read more about this on the Ubuntu Wiki: Restricted Formats page.\nI know that Ubuntu Studio comes with a lot of these codecs and \"drivers\" already installed. However for an average desktop user it's a lot of overkill as it's designed for multimedia market.\n\nA: Medibuntu.org provides an easy way to install many \"non-free\" codecs and multimedia applications that are not available in the main distribution for legal or philosophical reasons.  It is up to you to ensure that it is legal to use such codecs in your country.\n", "Q: How do I set different settings for different mice? I have two different mice (one is always used on the system, the other is wireless and moves between systems as needed). Unfortunately, the wireless one is much more sensitive than the wired mouse, and the mouse settings panel doesn't seem to have a way to set different settings for different mice.\n\nA: You can have multiple hardware-specific configurations now, in /etc/X11/xorg.conf.d/.\nSee X/Config, or New configuration world order which has some more specific examples.\nIf anyone is interested in helping improve X via wiki editing, a really easy thing to do would be to copyedit the directions at X/Config to be in the form of xorg.conf.d snippets instead of whole xorg.conf's.  If not, us developers will get to it eventually, but it could save time that developers could then spend on fixing more X bugs.  :-)\n\nA: You'll probably want to write a simple script that is run automatically or that you run whenever you switch mice. It'll need to simply swap out one config file for another, back and forth whenever it is run. \nI don't know which config files this info lives in, or if there's a hook to run scripts when mice are plugged in, but maybe that's a start.\n", "Q: How do you show the desktop in a blink in Ubuntu? We know you can either click on the show desktop icon or use CTRL+ALT+D to ask Ubuntu to show the desktop. Unfortunately, this does not always show the desktop in one action. \nSometime, and this is true for at least the last 4 version of the OS, it brings up first to the front all the windows, THEN, with a second click, show you the desktop.\nThis is very annoying, as when you show the desktop it generally to quickly click on a shortcut.\nTo understand what I'm talking about, open 7 windows, minimize some, bring some to the front, maximize one, then show the desktop. Then do that on Windows. You'll see the difference.\n\nA: There seems to be a problem when compiz (\"desktop effects\") is enabled:\nhttps://bugs.launchpad.net/ubuntu/+source/gnome-panel/+bug/236376\nI'm afraid for now the only workaround is to disable all desktop effects.\n\nA: On my system I use compiz to show desktop. I install simple compizconfig and open the last tab called \"edges\", I choose one edge and tell it to show my desktop. So when I move the mouse to that edge, it either hide all apps (screenlets included) or show them all.\n\nA: if u r using gnome-shell i installed a gnome-shell extension comes with a icon on the panel toggles shows desktop :\nuse this link to install : https://extensions.gnome.org/extension/64/show-desktop-button/\n", "Q: How do I make Nautilus windows stick for drag & drop? When you drag and drop a folder with nautilus, you must carefully set both windows on non overlapping areas of your screen, otherwise selecting one folder will bring the windows to the front, hiding the second one.\nOn Windows, doing so will stick the explorer.exe windows to the back and let you drag and drop the folder. I suppose it detect a long click to decide whether or not bring the window to the front.\nIs that possible with Ubuntu?\nNow I know that Nautilus now has split panels by pressing F3, but that not handy. Most of the time, you open a folder, THEN decide to copy. With split panel, you must decide, THEN split the panel and go to the right folder.\n\nA: While you're dragging hold your mouse over the taskbar icon of the nautilus window, and it'll be raised to the top so you can drop your files in it.\n\nA: If you drag down to the taskbar, the window will be raised so you can drop into it. Also, you can right-click on the window bar or the taskbar entry of the window you want to drag to, and select \"Always on top\".\n\nA: As mentioned in other answers, you can drag the file to the taskbar and the window will be raised, but that is not the only solution to your problem.\nYou can also use more generic solution: you can set auto raise window in window manager settings which can be found in system -> preferences -> windows. By setting a timeout forauto-raise, you will only need to move your mouse over certain windows to raise them to top. \nThis is a rather convenient feature when you combine it with focus follows mouse option. You can easily switch from application to application just by moving your mouse over to the other application.\nOf course, this forces you to adjust to a different way of working, but what doesn't?!\n\nA: Well, now that Unity is the default desktop in Ubuntu, there is no way to do this anymore, as there is no taskbar. Bugs have been filed to cover this issue (https://bugzilla.gnome.org/show_bug.cgi?id=76672 for example), but GNOME developers seems to have decided to just ignore the problem (this bug was reported in... 2002!).\nToo bad, no easy drag and drop between Nautilus windows for Ubuntu Natty users...\n\nA: I think it is now easier in Unity. Drag and drop on Unity bar (left). It works for multiple windows too. Drag your file on icon - if there are multiple windows then they will be shown with expo view - and drop where you want to.\n", "Q: How do you use a shell other than bash at a terminal as default? When you drop to the terminal via Applications -> Terminal or Ctrl+Alt+F1 etc. bash is used by default to interpret your commands. If you wish to use another command interpreter (like zsh or fish), how do you get this to start as default?\n\nA: Change your default shell. There is a command-line way to do this:\n$ sudo usermod -s /path/to/newshell username\n\nbut it might be easier to do it from the GUI settings.\nSystem -> Administration -> Users and Groups -> [select user] -> Advanced Settings -> Advanced\nthen choose the shell from the drop down list.\nIf the shell you want isn't in that list then it's probably not installed.\nYou'll need to log out and back in again for this to take effect. You can check which shell you are running in a new terminal by running \"ps\".\nIf you're very curious, the default shell is stored in /etc/passwd (which doesn't really have passwords despite the name).\n\nA: If you want to change your shell as a user, type:\nchsh -s /path/to/your/shell\n\nor simply\nchsh\n\nYou'll have to enter your password and your login shell is set to the one you chose. You can only select a shell which is listed in /etc/shells.\n", "Q: Which language is ubuntu-desktop mostly coded in? I heard it is Python\n\nA: Poked around in Launchpad: ubuntu-desktop to and browsed the source for a few mins. It appears to be a mix of Python and shell scripts.\n\nA: I think the question referred to the language used to write the applications running on the default installation.\nIt's hard to say which language is used the most, but i would guess C or C++. This is just a guess and since all languages are pretty equal in terms of outcome, it doesn't really matter.\n\nA: ubuntu-desktop is a meta packages that only has one purpose, which is to install a collection of packages by the Debian package system. Therefore, the package itself has no source code in this sense, but only information for the package system.\nWhat you probably really mean is about the packages that are installed when you install ubuntu-desktop. However, this is a very broad question, since it is a collection of packages.\nSome packages are written in C++ (as the main Gnome windows libraries are). Other packages use the Python gtk bindings and are hence written in Python. There are also packages that are written in mono. \nI do not think, that there is a list that is kept keeping count of how many applications are written in which language. This would also be difficult to keep maintained, since the set of packages being \"part of\" ubuntu-desktop vary from release to release.\n\nA: The primary languages are C and Python, with Go making significant inroads. C++ is merely a means to an end which is why Qt is tolerated so well. It's more like Qt's judicious use of C++ gives it a good name :-).\n", "Q: root running emacs Today, after about 20 minutes of logging in my Ubuntu 10.4, I notice the CPU and hard disk usage going up. top revealed that root was running emacs23.\nIt is basically the same behavior described at Ubuntu Forums\nbut there is no answer there. Any clue about this? \n\nA: There is a cron job that executes emacs weekly for updating AUCTeX auto-loads.\nYou can expect that behaviour if you installed auctex. To confirm, check out if the file /etc/cron.weekly/auctex is pressent.\n", "Q: How to change the format of the date & time displayed in top panel? By default date and time is displayed by the clock applet on the top right of the gnome desktop in Ubuntu. For me this displays something like \"Tue Aug 3, 19:45\". I would like to change it to make the date terser and to include e.g., ISO week number - to something like 03/08-19:45-W31.2\nIs there anyway I can specify a \"format string\" for how the date-time is displayed ?\n\nA: You might also be interested in looking at some examples other people have done with the same process. See: http://www.omgubuntu.co.uk/2009/11/gnome-panel-clock-themes.html\nI used the first one and couldn't be happier, but now that you mentioned week number, I need that too.\n\nA: *\n\n*Open gconf-editor by pressing Alt+F2 and typing gconf-editor\n\n*Navigate to apps -> panel -> applets.\n\n*Look for your applet. In my case it is called applet_3, on another computer its name is clock_0. Maybe a good way is to search (Strg+f or for US keyboards Ctrl+f, activate both fields in the search menu) for ClockApplet (case must match).\n\n*Go to prefs. Change the value of format to custom and change custom_format to whatever you like. The syntax comes from strftime().\n\n*The format will immediately change if you enter some values.\n\n\nNote: This option will not work in 10.10's netbook edition, see this question for a solution.\n\nA: Here is my custom time format.... <sup> <span font_desc=\"Droid Sans 14\"  color=\"green\"> %a  %b %d </span> <span font_desc=\"Droid Sans 20\" weight=\"Bold\" color=\"green\"  >%l:%M %p</span></sup> ....Works well with a dark panel color. Change the color code to suit your needs. \n\n", "Q: Is there a way to have an extended Desktop in Ubuntu a la Windows? I have Ubuntu 9.10 set up with multiple monitors.  Unfortunately, the way that Ubuntu handles multiple monitors by default in 9.10 is by having a separate desktop displayed on each monitor (it is not possible to drag a window from one monitor to the other).  I would like to set it up so that I can move applications from one monitor to the other.  Is this possible (does 10.04 support it)?\n\nA: I have this setting as default. I have two monitors and they make just one desktop. I can move windows from one to another moving then from bottom to top, and I can even manually stretch a window to use both monitors.\nI used the monitor app in the preferences menu to set it up. I expect all the cards that support xrandr work the same. \nSo the answer is usually yes, at least with most cards.\nBTW mine is an Intel.\n\nA: If you have a dedicated graphics card you may find that the proprietary drivers make this easier to set up.\nMost of the machines I run Ubuntu on (and all the ones with multi-monitor configurations) have nVidia cards in them. I am using nvidia's x server settings (nvidia-settings) to manage the displays. This lets me choose between having separate x servers on each screen (completely independent displays) or 'TwinView' which creates a single desktop across both displays. (this allows dragging between windows, stretching across the whole desktop, etc)\nTo install the proprietary drivers, you can go to System > Adminstration > Hardware Drivers (as pointed out by @themusicalduck in the comment below).\nIf, however, you want the latest drivers (which typically offer bugfixes and performance improvements) and don't mind the hassle, you can go here for nvidia or here for ati. Put your card's model in there, choose 32bit / 64bit for your setup and download.\nps. I don't know about the ATI driver, but but the nvidia driver comes as a script to run that will install the driver automatically, compiling the kernel modules as required etc. However, you need to shut down the display before you can update its drivers, which can be scary. Just follow the steps in this guide and it should be fine! ('Logging in as root' means typing sudo su (or prepending sudo to all subsequent commands)\n", "Q: How do I set environment variables? I'm trying to set up Apache Tomcat on my pc, and it wants me to set up an environment variable for CATALINA_HOME.  Does any know how to do this?\n\nA: The best place for this depends on how and where you've installed Tomcat, what applications you want to pick up this setting and how global you want the scope to be. \nThe Ubuntu documentation on Environment Variables discusses the pros and cons of the various options.\n\nA: To set permanent environment variables in latest Ubuntu versions (from 14.04 and above)\nadd the variables to /etc/environment. For that follow the below instructions,\nOpen the terminal and run\nsudo -H gedit /etc/environment\n\nthe provide your password, then in the prompted text file\nthen add the variables like\nANT_HOME=\"/opt/ANT/\"\n\nSample of the /etc/environment is given below\nPATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\"\nJAVA_HOME=\"/usr/lib/jvm/java-8-oracle/\"\nAXIS2_HOME=\"/opt/axis2-1.7.4/\"\nANT_HOME=\"/opt/apache-ant-1.9.7/\"\n\ndon't forget to logout and login again to enable the environment variables.\n\nA: Environment variables should already work\nIf you are using the tomcat6 package from the Ubuntu repositories, then the CATALINA_HOME and other environment variables are already set, in the /etc/init.d/tomcat6 startup script.  \nIf you are installing tomcat outside the package manager (hopefully in /opt or somewhere else outside the managed file system), then running the TOMCAT/bin/startup.sh should use the relative location to define the CATALINA_HOME.\nSetting the Environment variable\nIf for some reason you still need to set an environment variable you can open a terminal window and type in the command:\nexport CATALINA_HOME=/path/to/the/root/folder/of/tomcat\n\nThis environment variable will now work within that terminal window, but if you open another window or logout/login you loose that setting.\nMake the environment variable permanent\nTo make the environment variable setting permanent, there are several places you can define the setting.  \nTo be really sure the setting is being picked up, add the above setting to one of the startup script for tomcat:\nyourtomcatfolder/bin/startup.sh\n\nyourtomcatfolder/bin/catalina.sh\n\nNote: startup.sh calls the catalina.sh.  You should add the setting at the start of one of these files (after any initial comments)\nThe standard way for global environment variables would be to add an entry in /etc/environment (you do not use the command export in this file as it is not a normal bash script)\nCATALINA_HOME=/path/to/the/root/folder/of/tomcat\n\nNot recommended\nYou can set the environment variables in the bash (command line shell) configuration files, but these are not recommended as they are not always picked up (eg. if you are running a server that you dont login to to run tomcat):\n~/.bashrc |\n~/.profile |\n/etc.bash.bashrc |\n/etc/profile\n\nA: In bash you can set variables like this:\nexport CATALINA_HOME=/opt/catalina\n\nmost other shells follow this convention, but not all. You can set it permanently in ~/.profile for bash (and as before, other shells have other locations)\n\n\n*\n\n*https://help.ubuntu.com/community/EnvironmentVariables\n\n*Where to declare environment variables?\n\nA: Open your Bash runcom file:\nnano ~/.bashrc\n\nThis will most likely contain quite a bit of data already. Most of the definitions here are for setting bash options, which are unrelated to environmental variables. You can set environmental variables just like you would from the command line:\nexport VARNAME=value\n\nSee How To Read and Set Environmental and Shell Variables on Linux\nI tested it on Ubuntu 16.04. Works great.\n\nA: After going through Ubuntu Documentation on Environment Variables, I came up with following workaround:\n##Save & run the following in a shell script,\n\nexport ENVIRON_VAR_NAME = Value\n# any other initializations like\nexport PATH=$PWD:$PATH\nbash\n\nThe last line creates a child shell, which inherits Environment Variable values from parent shell (which have just been set).\n\nA: As above, I will use the export to save an environment variable with a small difference. I prefer to save them in a local file.\necho \"export POSTMARK_SERVER_TOKEN=sekritvalue\" >> .env\n\nIn this way, anytime and from any terminal, your variable will work and be there with your project. Don't forget to include .env to your .gitignore, DO NOT push them to Git.\n", "Q: How do I make cron email my @gmail account I have a couple of cron jobs that sometimes produce error output and would like to get a notification in my \"real\" email account, since I don't use my user's mailbox in my Ubuntu laptop, but cron (or is it postfix maybe) keeps trying to email the local root account.\nI know I can add the MAILTO variable to the crontab:\nricardo@ricardo-laptop:~$ sudo crontab -l\nMAILTO=redacted@gmail.com\n# m h  dom mon dow   command\n*/5 * * * * /home/ricardo/mrtg/cfg/run.sh\n\nBut it doesn't seem to pay any attention to it\nI also tried adding my email to the /etc/aliases file and running newaliases\nricardo@ricardo-laptop:~$ cat /etc/aliases\n# See man 5 aliases for format\npostmaster:    root\nroot:          redacted@gmail.com\nricardo:       redacted@gmail.com\n\nstill, whenever cron wants to send an email it's still sending it to root@my.domain.com:\nricardo@ricardo-laptop:/var/log$ tail mail.log\nAug  3 16:25:01 ricardo-laptop postfix/pickup[2002]: D985B310: uid=0 from=<root>\nAug  3 16:25:01 ricardo-laptop postfix/cleanup[4117]: D985B310: message-id=<20100803192501.D985B310@ricardo-laptop>\nAug  3 16:25:01 ricardo-laptop postfix/qmgr[2003]: D985B310: from=<root@144-68-247-190.fibertel.com.ar>, size=762, nrcpt=1 (queue active)\nAug  3 16:25:03 ricardo-laptop postfix/smtp[4120]: D985B310: to=<root@144-68-247-190.fibertel.com.ar>, orig_to=<root>, relay=smtp.gmail.com[74.125.157.109]:25, delay=1.5, delays=0.38/0.02/0.9/0.18, dsn=5.7.0, status=bounced (host smtp.gmail.com[74.125.157.109] said: 530 5.7.0 Must issue a STARTTLS command first. d1sm12275173anc.19 (in reply to MAIL FROM command))\n\nAny suggestions? I'm running Ubuntu 10.04, with everything up-to-date\n\nA: It would appear that you have configured smtp.gmail.com as your smarthost for the mail server. You need to remove the smarthost configuration or edit it so that your server is at all capable of sending mail to the outside world.\nThe configuration you have now for the mail forward appears to be working, but is failing because smtp.gmail.com is rejecting the mail.\nUpdate: For future reference, the problem was in /etc/mailname which listed a name that wasn't in the mydestinations list of postfix. This caused all mails to be considered foreign and the mail bypassed /etc/aliases processing.\n\nA: Solution extracted from question\n(thanks to Ressu)\nThe problem was with the file /etc/mailname\nThis file was created by the Ubuntu installer and contained the wrong server-name. Once I changed it to match \"ricardo-laptop\" postfix realized the emails were intended for local delivery and started to follow the aliases\n\nA: thought I'd add on for people who discover this as I did. An easy alternative if you want all your mail from your root account is to run this command:\n\nsudo nano ~/.forward\n\nYou can then put in a single email or separate more than one with commas. This will forward all of your root emails (assuming you're using the root) to the email address(es) in this file.\nOnce you've added the emails, Press Ctrl+X then Y to save the changes.\n", "Q: Authentication problem with my PPA I created a package and uploaded it to my PPA. After it got built, I went to install it, but was faced with this message:\n$ sudo apt-get install stackapplet\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following NEW packages will be installed:\n  stackapplet\n0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\nNeed to get 17.7kB of archives.\nAfter this operation, 106kB of additional disk space will be used.\nWARNING: The following packages cannot be authenticated!\n  stackapplet\nInstall these packages without verification [y/N]?\n\nWhy is it warning me about the packages not being verified?\n\nA: Most likely this is caused by a missing PGP key in your APT keyring. You can add the key with the following command:\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 72D340A3\n\nOf course you need to replace the key with your PPA key.\nAlso, the following command will add the key automatically:\nsudo add-apt-repository ppa:user/ppa-name\n\nAfter adding the key, you need to run apt-get update to download and verify the signature.\n", "Q: Coolest looking terminal IRC client I am looking for a IRC client for the terminal that has colors, user list and just generally looks awesome ;)\nAny recommendations? There are loads of IRC clients in the repositories and I don't want to download them all to find the best one.\n\nA: IRSSI - The client of the future http://www.irssi.org/\nsudo apt-get install irssi\n\nSay no more\n\n\nA: Always used Epic with the SplitFire script myself.\nFrom their site:\n\nEPIC's development model is to provide\n  tools to scripters rather than\n  features to end users. Out of the box,\n  EPIC behaves much the same way\n  ircII-2.8.2 did in 1994. To truly\n  leverage EPIC, you will need a script pack.\n\n\nA: I would prefer weechat. Apart from having colors and looking awesome it is very customizable.\n\nA very small IRC client is ii, but has no colors out of the box. It is good for using in shell scripts etc.\n\nA: Quassel is a really good client in this way. In addition, it can be split in core and client and hence allow multiple computers all connected with the same user name.\n\nA: I think one of the best IRC clients (ncurses based) is BitchX. It's included by default in the Fedora distros and it might be, in the future, shipped with Ubuntu.\nBitchX had several security vulnerabilities, which were fixed lately. You can check BitchX 1.2 (NEW flavor, very nice) on GitHUB: Bitchx is awesome!\nI recommend it for all of you who are nostalgic about good old times, also for those eager to experiment.\nAnother interesting IRC client is IRCII, you can find it here: ircII is awesome!\nThanks to all for them!\n", "Q: Trouble creating library package I am having some trouble creating a package for a shared library.\nI ran dh_make and edited the files. However, when I go to build the package, I get the following:\n\n******@******-laptop:~/Documents/temp/jsoncpp/jsoncpp-0.5.0$ debuild\n dpkg-buildpackage -rfakeroot -D -us -uc\ndpkg-buildpackage: set CFLAGS to default value: -g -O2\ndpkg-buildpackage: set CPPFLAGS to default value: \ndpkg-buildpackage: set LDFLAGS to default value: -Wl,-Bsymbolic-functions\ndpkg-buildpackage: set FFLAGS to default value: -g -O2\ndpkg-buildpackage: set CXXFLAGS to default value: -g -O2\ndpkg-buildpackage: source package jsoncpp\ndpkg-buildpackage: source version 0.5.0-1\ndpkg-buildpackage: source changed by ****** \ndpkg-buildpackage: host architecture amd64\n fakeroot debian/rules clean\ndh  clean\n   dh_testdir\n   dh_auto_clean\n   dh_clean\n dpkg-source -b jsoncpp-0.5.0\ndpkg-source: info: using source format `1.0'\ndpkg-source: info: building jsoncpp using existing jsoncpp_0.5.0.orig.tar.gz\ndpkg-source: info: building jsoncpp in jsoncpp_0.5.0-1.diff.gz\ndpkg-source: info: building jsoncpp in jsoncpp_0.5.0-1.dsc\n debian/rules build\ndh  build\n   dh_testdir\n   dh_auto_configure\n   dh_auto_build\nmake[1]: Entering directory `/home/******/Documents/temp/jsoncpp/jsoncpp-0.5.0'\ntest -d obj || mkdir obj\ng++ -I ./include -c -o obj/json_reader.o src/lib_json/json_reader.cpp\ng++ -I ./include -c -o obj/json_writer.o src/lib_json/json_writer.cpp\ng++ -I ./include -c -o obj/json_value.o src/lib_json/json_value.cpp\nar -r libjsoncpp.a obj/json_reader.o obj/json_writer.o obj/json_value.o\nar: creating libjsoncpp.a\nmake[1]: Leaving directory `/home/******/Documents/temp/jsoncpp/jsoncpp-0.5.0'\n   dh_auto_test\n fakeroot debian/rules binary\ndh  binary\n   dh_testroot\n   dh_prep\n   dh_installdirs\n   dh_auto_install\nmake[1]: Entering directory `/home/******/Documents/temp/jsoncpp/jsoncpp-0.5.0'\nsudo cp -r include/json --target-directory=/usr/include\nERROR: ld.so: object 'libfakeroot-sysv.so' from LD_PRELOAD cannot be preloaded: ignored.\ncp libjsoncpp.a /usr/lib/libjsoncpp.a\ncp: cannot create regular file `/usr/lib/libjsoncpp.a': Permission denied\nmake[1]: *** [install] Error 1\nmake[1]: Leaving directory `/home/******/Documents/temp/jsoncpp/jsoncpp-0.5.0'\ndh_auto_install: make -j1 install DESTDIR=/home/******/Documents/temp/jsoncpp/jsoncpp-0.5.0/debian/tmp returned exit code 2\nmake: *** [binary] Error 29\ndpkg-buildpackage: error: fakeroot debian/rules binary gave error exit status 2\ndebuild: fatal error at line 1340:\ndpkg-buildpackage -rfakeroot -D -us -uc failed\n\nThe problem seems to be here:\n\nERROR: ld.so: object 'libfakeroot-sysv.so' from LD_PRELOAD cannot be preloaded: ignored.\n  cp libjsoncpp.a /usr/lib/libjsoncpp.a\n  cp: cannot create regular file `/usr/lib/libjsoncpp.a': Permission denied\n\n...but I haven't the faintest idea what the problem is.\nThe makefile is here if needed.\n\nA: The Makefile you are using is not respecting the DESTDIR variable - packages should never install directly into /usr at build time, but instead put files into a temporary tree.\nYou've mentioned that you added the Makefile yourself - the usual case is that you'd need to make it use the DESTDIR variable as a prefix for all install paths.\nHaving looked at the package build instructions, the package uses scons as a build system, which is a replacement of sorts for make. dh_make most likely doesn't have a template for building packages with this, so you should look for packages that do use it for building, such as yafray, and look at their debian/rules\nAs package builds are never done as root, it is better to have this error shown & corrected rather than having a package overwrite important files as the package is being built on an unsuspecting developer's system.\n\nA: As you figured the problems lies here:\ncp libjsoncpp.a /usr/lib/libjsoncpp.a\n\nYou are calling debbuild as normal user, who has no rights to write to that directory. If you try sudo debbuild it should work.\n", "Q: What tools and techniques can I use to make GTK themes? I'm trying to make a new gtk theme using the murrine engine, using Humanity (default in ubuntu 9.10) as a template.\nYou can grab the code in http://github.com/tutuca/themes \nHowever, I found cumbersome the process of creating a new theme with it. There is no central starting point. \nThe documentation of both, the engine options (gtkrc's and stuff), and general theming practices (the format of the index.theme files, folders, bla bla) is scarce, How to's and tutorials are often old or subject to lots of opinionated debate and results confusing (to me, having a web developer background, at least :-).\nSo... I wanted to ask to the fellows gtk themers and artist out there:\nWhich tools you use to create a new theme, and how does your average workflow looks like?\n\nA: There is the widget laboratory from one of my cohorts, Isaiah Heyer. That may be of use to you.\n\nA: The widget laboratory or the widget factory  is only for viewing your theme, to edit your theme graphically, try to use gnome color chooser. It's fun apps for experiment.\n\nA: \nGTK programmers will tell you that writing a GTK theme is easy. If you\n  have a full understanding of how GTK is put together, then that may be\n  so, but if you don’t have a great knowledge of the GTK API and you\n  want to change the visual appearance of your GTK applications.  Its\n  not difficult stuff, but can appear to be somewhat random and\n  non-intuitive due to its close correlation with the underlying widget\n  structure.1\n\n1Source: developer.gnome.org\nThere are many websites out there that has information on how to create GTK themes.  It would be a hassle to include information from all of them, and try to cite everything.  I will be leaving you with a couple of links at the end, that will help you in your process. \n\nGTK themes in Gnome 3 have a new syntax that is different from GTK2.\n  The new CSS syntax in GTK3 makes it easier to create themes. Though it\n  is easy to understand the CSS syntax than the old gtkrc syntax, it is\n  not enough to know just CSS. \nYou probably won't want to get a theme up and running from scratch.\n  You probably should start by modifying an existing theme. The theme\n  that you choose, will affect the quality, ease of customization and\n  maintainability of your theme. \nChoose a GTK3 engine\nThe theme engine is what draws the theme. Different theme engines may\n  support different features and syntax. \nThe Adwaita engine is from the official Gnome project. If you want to\n  make a simple theme, choose this. Read on..2\n\n2Source:forums.fedoraforum.org\nThe GTK+ Project\nGtk Theme Creation Guide\n", "Q: How do I add a program that must be run from within its own directory to the panel or main menu? Some programs can only be run from within their own directories. If I go to System --> Preferences --> Main Menu --> Add Item and select the file, it will not work. Similarly, if I right click on the Panel and choose \"Add to Panel...\", choose \"Custom Application Launcher,\" and then point to the file, it will similarly fail. How can I add a launcher to my panel and an entry in my Main Menu that will successfully launch this kind of program?\n\nA: Have you tried using a script to launch the app instead?\nSomething like:\n\n#!/bin/bash\ncd /my/dir\nmyprogram\n\nSelect the script instead of the file.\n\nA: So what I did is this:\nI created a plain text file and wrote the following bash script for a Latin translation program I use, called Words:\n#! /bin/bash\n\ncd ~/latin/latin.words/\n\n./words\n\nAfter saving it in my home folder, I made it executable, which can be done in one of two ways.  I right clicked on it, choose Properties->Permissions, and check the \"Execute\" box for your user name.  Or I could have used the command line and entered chmod +x file.name .  \nThen I right clicked on the panel and chose Add to Panel, select Custom Application Launcher. I entered the name, in this case Words, and the path to the script I just wrote in the Command field.  Because Words is a command line program, I selected Program in Terminal from the drop-down menu. I then clicked on the icon and selected an appropriate one and with that I was done adding it to the panel.\nNext I clicked System->Preferences->Main Menu, selected the folder I wanted to put the menu launcher into, and then clicked Add Item.  I then repeated the process I just performed, above.  \nAnd now I have a custom launcher that works for a program that must be run from its own directory, both on my panel and in the menu!\n\nA: cd /path/to/dir/ && gksudo bin_file\nThat should do the trick.\n", "Q: Is there a GUI in xorg for changing the video driver? I was under the impression there was a GUI app for changing the Xorg video driver. If so, where is it? I don't see it in 10.04.\n\nA: If you're looking to switch between the proprietary and Free driver for your video card (e.g. if you have an ATI or NVidia card), try jockey.\nOn the default Ubuntu desktop this is in:\nSystem - Administration - Hardware Drivers\nYou can enable and disable hardware drivers there.\n\nA: If you mean a GUI for changing display-related properties, then you can find that at System->Preferences->Monitors.\nIf you are referring to a GUI tool for editing xorg.conf, I am not aware of one - you're better off editing the file directly (details here).\n\nA: Perhaps you're looking for dpkg-reconfigure. It's terminal-based GUI for reconfiguring software. You should be able to change your xorg driver settings with sudo dpkg-reconfigure xserver-xorg.\n", "Q: Change boot order for Wubi I've setup Ubuntu via Wubi recently for a friend and he came back with a complaint: On reboots the Windows partition is always selected by default, figured this was just a need to update Grub but realized that Wubi writes to the Windows Boot Manager and does not use Grub.\nThough this is technically a \"Windows\" question I wasn't able to find a clear answer for this.\nHow to do I modify the boot/selection order for Operating systems (Mainly Ubuntu via Wubi) on the Windows Boot Manager?\n\nA: The Wubi Guide on the Ubuntu wiki (manual uninstall section) gives some hints on how to edit the Windows Boot Manager boot order in Vista and XP.\nIn Windows Vista you can either use EasyBCD or modify the boot menu via Control Panel (Classic View) > System > Advanced system settings; then choose \"Settings...\" under Startup and Recovery.\nIn Windows XP, edit C:\\boot.ini.\nAccording to this Wubi HowTo, the default OS can be changed in Windows 7 by going to Control Panel > Advanced System Settings, and in the Default operating system drop-down selecting Ubuntu instead of Windows.\n\nA: Click start and run msconfig(in Windows). Look for the Boot tab and change the order of the OS. I can't remember what it looks like its been a while, but its pretty self explanatory.\nGood Luck and happy Ubuntuing!\n", "Q: How do I set networking enabled by default? When I log into my computer, networking is disabled.  I always have to enable it so I can connect to the internet.  Does anyone know how to set it to enabled by default?\n\nA: From the network-manager applet menu (right click), select edit connections. Edit the connection you wish to automatically connect and select the connect automatically checkbox.\nIf you wish to start a connection before you log in, select the available to all users checkbox. This is most useful with wireless connections which usually are available only after login.\n", "Q: How can I share files over a Windows network? I have a media computer which I recently reformatted to Ubuntu 10.04. I am probably just missing something obvious but I can't figure out how to share folders and files, so that I can browse to them on my Windows computers in order to copy files to/from the computer.\nHow do I do this?\n\nA: Right-click a folder and select \"Sharing Options\". Then check off \"Share this folder\".\n\nA: You've to right-click folder, Sharing Options, check Share this folder and mark the two options related with guest-acess and allowing of file management operations. Then click Create Share\nIn Windows, just go to Start Menu > Network > YourUbuntuComputer > YourSharedFolder. If your Ubuntu computer isn't showing there, try Super Key (or Windows Key) + R, and write \\\\ComputerInternalIP or \\\\YourComputerHostname.\n\nA: If you are trying to share hard drives on a network, you need to go to /media and find the drives, right click on the drive you want to share and select \"sharing options\" as above.  That way you can share the drive across your network.  \nDick Smith\n\nA: Get an update first by typing sudo apt-get update\nand then install samba by typing sudo apt-get install samba then go over to the folder that you want to share and right click it and select sharing options, u should be able to to share access the files now if you network is running.\n", "Q: How to get .so file to show up in package? As many of you know by now, I'm building a package :)\nI am so close to getting it finished so I can upload it to my PPA, but there is still one slight problem: the shared library (.so file) doesn't want to go into the package.\nOkay, here is what I have in my control file:\n\nSource: jsoncpp\nPriority: extra\nMaintainer: ****** \nBuild-Depends: debhelper (>= 7)\nStandards-Version: 3.8.3\nSection: libs\nHomepage: http://jsoncpp.sf.net\n\nPackage: jsoncpp-dev\nSection: libdevel\nArchitecture: any\nDepends: jsoncpp0 (= ${binary:Version})\nDescription: JSON parsing library for C++\n jsoncpp is a C++ library that makes it easy to\n read / write JSON data.\n .\n This package contains the development tools necessary\n to create applications that use jsoncpp.\n\nPackage: jsoncpp0\nSection: libs\nArchitecture: any\nDepends: ${shlibs:Depends}, ${misc:Depends}\nDescription: JSON parsing library for C++\n jsoncpp is a C++ library that makes it easy to\n read / write JSON data.\n\nNow, jsoncpp-dev builds fine and the development files show up in the package but the shared library does not show up in its package.\nHere is what jsoncpp0.dirs looks like:\n\nusr/lib\n\n...and jsoncpp-dev.dirs:\n\nusr/lib\nusr/include\n\nMy updated Makefile is here.\nPlease let me know if you need further information.\n\nA: You really want to be using the build system (scons) that jsoncpp uses, since it's probably well-tailored for the package. \nFirstly, the package names that you are using should be prefixed with lib, such as libjsoncpp0 (assuming that the resulting file is /usr/lib/libjsoncpp.so.0)\nTo install the files, you need to have these files listed in the .install files, eg debian/libjsoncpp0.install would have /usr/lib/lib*.so.* to install the right file. libjsoncpp-dev would have the files in /usr/include/* and /usr/lib/lib*.so\nThe library packaging guide at http://www.netfort.gr.jp/~dancer/column/libpkg-guide/libpkg-guide.html can be complex, but it has some important information about the right way to package libraries so that they integrate well in Debian & Ubuntu.\nAlso, there are often people available on #ubuntu-motu or #ubuntu-packaging on irc.ubuntu.com to help with questions you may have.\n\nA: This was the result of a rather bad mistake on my part. Somehow jsoncpp0.install got renamed to jsoncpp0install (without the period).\nAnyway, it works now.\n", "Q: How do I update grub to grub2 if legacy grub is installed in boot partition sector, not MBR? I'm trying to move to grub2 and while chainloading from legacy grub works fine, I'm not sure how to move completely. Old grub was installed in boot sector of swap partition, /dev/sda3, and was working fine there. I want new grub to be installed there as well but during upgrade-from-grub-legacy it suggest to install at MBR or at ubuntu root partition, /dev/sda4. How do I force it to install at /dev/sda3? Can I just do grub-install '(hd0,3)' instead of upgrade-from-grub-legacy?\n\nA: If you have verified that the new grub2 setup works, you can use grub-install safely.\nThe only significant thing upgrade-from-grub-legacy does is this:\nrm -f /boot/grub/{{xfs,reiserfs,e2fs,fat,jfs,minix}_stage1_5,stage{1,2}}\n\nwhich essentially removes the grub-legacy files from /boot/grub, you can also remove /boot/grub/menu.lst if it doesn't contain anything important to you.\n", "Q: What are the benefits of using Grub2 over Grub? Why would one move from Grub to Grub2?\n\nA: GRUB 2's major improvements over the original GRUB include:\n\n\n*\n\n*New configuration file structure\n\n*Scripting support including conditional statements and functions\n\n*Dynamic module loading\n\n*Rescue mode\n\n*Themes\n\n*Graphical boot menu support and improved splash capability\n\n*Boot Ubuntu LiveCD and some other ISO images directly from hard drive\n\n*Non-X86 platform support (such as PowerPC)\n\n*Universal support for UUIDs (not just Ubuntu)\n\n*Improved internationalization, including support for non-ASCII characters\n\n\nA: Grub legacy is no longer being maintained, so distros would have to do all the work of patching it to support newer file systems like Ext4 and btrfs. That's a lot of really unnecessary work for them, and diverts dev time away from doing more useful things.\n\nA: This question is not really relevant anymore, since Ubuntu 9.10 and later already have GRUB2 installed.\nsudo update-grub just has still prevailed as the standard command.\nsudo update-grub and sudo update-grub2 are equivalent, so it doesn't matter which one you run. /usr/sbin/update-grub2 is just a symbolic link to /usr/sbin/update-grub.\nThere are no relevant benefits for the end-user. Only developers and distribution-maintainers benefit from grub2 over grub (see yevhenes answer)\n", "Q: How I can limit Download/Upload bandwidth? How I can limit Download/Upload bandwidth for:\n\n\n*\n\n*Entire OS.\n\n*One network interface.\n\n*Single application.\n\n\nA: Although this is an old question, I came across this when looking for an answer to the same question. The OS and interface limits are already addressed in an earlier answer, so here is a way to set up application specific limits. Use an application called trickle. So do sudo apt-get install trickle. You can limit upload/download for a specific app by running\ntrickle -u (upload limit in KB/s) -d (download limit in KB/s) application\nThis will launch the application with the specified limits. You can also specify \"smoothing\" time, so that trickle samples over the desired time period in case your application has bursts of bandwidth consumption and you'd like the bursts to be allowed so long as the average is within your specifications. \n\nA: If you want to limit bandwidth for a specific IP address, you can use this:\ntc qdisc add dev eth1 root handle 1: htb default 12\ntc class add dev eth1 parent 1: classid 1:10 htb rate 2500kbps\ntc class add dev eth1 parent 1: classid 1:11 htb rate 2500kbps\ntc class add dev eth1 parent 1: classid 1:12 htb rate 5000kbps\n\ntc filter add dev eth1 protocol ip parent 1:0 prio 1 u32 match ip dst 192.168.2.105 flowid 1:10\ntc filter add dev eth1 protocol ip parent 1:0 prio 1 u32 match ip dst 192.168.2.106 flowid 1:11\n\n\nA: Limiting single interface is easy, but global rate limits need more complex rules as do application based rules. I'm not saying that it can't be done, but it requires quite a bit digging in to the internals of the networking. \nHere is a quick How to on setting up a per interface limit\nIf you really want to set up application based rules, you should look in to some firewall framework, like shorewall, which have helper features to configure shaping. Even with these tools, it requires quite bit of forethought and testing to get it in to place. Doing something like this ad-hoc is not yet quite that easy.\n", "Q: How do you start-up in the login screen with Num Lock on? \nPossible Duplicate:\nHow to enable numlock at boot time for login screen? \n\nI use numbers in my password and would therefore like to start Ubuntu with Num-Lock enabled. This would also be handy in a terminal window, that is Ctrl+Alt+F1.\n\nA: Many (most?) systems have a BIOS setting for this.  This can be set in the BIOS and will apply to all OSes installed on the system.\nYou will need to consult your system documentation or your system vendor for information about how to enter the BIOS and what the setting is named.  (Though often pressing one of F1, F2, F10, or F12 during boot will access the BIOS settings where you can look for something like \"startup numlock behavior\" or similar.)\n\nA: I think the correct place to set this is \n/etc/kbd/config\n\nLine 65-66 look like this\n#Turn on numlock by default\n#LEDS=+num\n\nUncomment line 66 to look like this\n#Turn on numlock by default\nLEDS=+num\n\nEDIT: Having looked into this further you can enable numlock at the GDM level (if you wish) by installing numlockx like this\nsudo apt-get install numlockx\n\nand setting the configuration in /etc/gdm/Init/Default like this\nif [ -x /usr/bin/numlockx ]; then\n      /usr/bin/numlockx on\nfi\n\nThere is also this blog post that might be useful\n\nA: You can alter the numlock state with setleds command. The setleds manual lists an example how to alter TTY states so that numlock is on by default:\n        INITTY=/dev/tty[1-8]\n        for tty in $INITTY; do\n             setleds -D +num < $tty\n        done\n\nYou can put that in /etc/rc.local and it is set during the startup of your workstation.\nFor GDM you can follow the guide here:\nhttps://help.ubuntu.com/community/NumLock\n", "Q: How do I remove Windows but keep Ubuntu? I want to keep Ubuntu but remove Windows.\n\nA: Assuming you have installed Ubuntu on a separate partition, all you have to do is remove your Windows partition and remove the Windows option from your GRUB boot menu. \n\n\n*\n\n*Make sure your backups of your documents (and other important files, such as ebooks, videos, music, and so forth) are current. If you are going to expand the Ubuntu partition to take up the space freed by removing your Windows partition, then this is especially important, as there is always some risk (though small) of data loss when performing dynamic partition resizing. However, even if you are not planning to do this, unless you are highly experienced with repartitioning, there is a significant risk that you may make a mistake (you probably will not, but if you do, you want the consequences to be minimally bad).\n\n*Boot from an Ubuntu live CD/DVD or live USB flash drive (as it is not considered safe to edit a physical disk's partition table from within any of the operating systems installed on the physical disk). Select Try Ubuntu rather than Install Ubuntu.\n\n*Use GParted, the GNOME Partition Editor, to edit the partition table on the hard disk, removing the Windows system.\n\n\n*\n\n*Start GParted (System > Administration > GParted, or if you're using a live system of Ubuntu 11.10 or later, press the Super, i.e., Windows key, type gparted, and click the search result that appears).\n\n*Select your Windows partition (it will be of type NTFS and will probably have a pale green border).\n\n*Delete it (Partition > Delete).\n\n*Optionally, resize your Ubuntu partition to take up the freed space. You may be able to do this by selecting it (it's of type ext4) and using Partition > Resize/Move. However, if it is contained in an extended partition (a kind of container partition for other partitions) and the Windows partition was not contained in the extended partition, then you may need to expand the extended partition first, and then expand the Ubuntu ext4 partition contained within it.\nWhile this step is optional, the space that Windows occupied will not be available to your Ubuntu system if you skip it. (However, if you just want to use the space for storage, you could create a new partition for that purpose where your Windows partition used to be, instead of expanding Ubuntu's ext4 partition.)\n\n*Apply your changes (Edit > Apply All Operations).\n\n\n*Quit GParted and reboot (click the power icon at the upper-right corner of the screen and click Restart or Shut Down). Once you have booted back into the Ubuntu system installed on the hard drive, update your GRUB menu to remove the Windows option, by running sudo update-grub in a Terminal window (Ctrl+Alt+T). When you run that command, you might be prompted for your password. As you enter it, you won't see any placeholder characters (like *). That's OK--just type it in and press enter. After you've run that command, Windows should no longer appear as an option to select in the boot menu.\nHowever, unless your Windows partition is seriously damaged or infected with viruses, I wouldn't recommend removing it. Instead, shrink your Windows partition, leaving space for your data plus an extra gigabyte for virtual memory (the versions of GParted that come with all currently supported Ubuntu releases are able to resize NTFS partitions). You never know when you'll need to use an application that only works with Windows.\n\nA: If you installed Ubuntu in a separate partition you can easily format the drive with Windows.\nAfter that remove Windows entry from grub config.\nIf you use Wubi you can do one of these: \n\n\n*\n\n*Copy you user home folder to save most of settings.\n\n*Use OneConf from Maverick.\n\n\nAnd reinstall Ubuntu after that.\n\nA: If you have Installed Ubuntu using WUBI then probably trying to remove windows will remove Ubuntu, as Windows installed Ubuntu into its root directory unless you haven't specified a different directory at the installation time.\n\nA: Here is a graphical tool to easily remove any OS (Windows, or Ubuntu, or else): OS-Uninstaller\n\n", "Q: How can I find out what is causing my gnome-panel to freeze? About once a day my gnome-panel freezes.\nHow can I produce some sort of debug information to:\n\n\n*\n\n*Figure out what is causing the freeze or\n\n*File a bug or see if its an existing bug\n\n\nWhen gdb is attached to gnome-panel and the bug occurs I cannot get a stack trace out of gdb. \nReading symbols from /lib/libbz2.so.1.0...(no debugging symbols found)...done.\nLoaded symbols for /lib/libbz2.so.1.0\n0x00007f7cefe10f48 in poll () from /lib/libc.so.6\n(gdb) c\nContinuing.\n\n^C\n^C\n\nThe \"^C\" is to show that once the bug occurs gdb stops responding to Ctrl+c and kill -INT.\n\nA: The comments on this bug report on the same issue first point the reporter to a wiki page entitled Debugging a Program Crash and then to a page describing how to get a backtrace. Perhaps those will help you get the debugging info you need.\nI answered a question about a similar problem with a workaround that may help you. It goes like this:\n\n\n*\n\n*Create a script called delayed-gnome-panel.sh in your home directory and mark it as executable.\n\n*Edit the script to look like this:\n#! /bin/bash\nsleep 3 && gnome-panel &\nexit\n\n\n*Then edit /usr/share/applications/gnome-panel.desktop so that exec=bash /home/<user>/delayed-gnome-panel.sh.\n\nA: Attach to the panel after it's frozzen.\n$ gdb --pid=`pidof gnome-panel`\n(gdb) bt full\n\nAlso make sure you have the necessary debugging symbols installed. At least libglib2.0-0-dbg and libgtk2.0-0-dbg.\n\nA: To debug the gnome-panel from the beginning you can try:\n$ gnome-session-remove gnome-panel\n$ gdb gnome-panel\n...\n(gdb) run\n\nYou would need the debugging symbols in order to get something readable (ie gnome-panel-dbg).\n", "Q: How can I make the fan in my computer turn off when it's suspended? When my computer is suspended, the GPU, CPU and power supply fans all continue to run.\nI don't think I've ever been able to get them to turn off, short of hibernating or turning the computer off. I have some theories as to where to begin, but what I'd like are some more solid ideas.\nI built this computer myself, so I think it's possible that I didn't connect the fans to a proper power supply, so one theory is that I need to open the computer, and move the fan's wire somewhere else on the motherboard. If this is correct, is there a way to know where to move it? <-- This theory doesn't make sense now that I realize it's three different fans that keep running.\nMy other theory is that I need to do something in my BIOS to make this change, and my third theory is that this is an Ubuntu thing that I need to fix on the software side.\nDoes anybody know how to figure out why the fans never turn off, or what to do to fix them? They DO turn off when the computer is hibernating, but I don't like doing that because it takes a very long time to boot up from hibernation.\n\nA: I had the same problem, and solved it by going to BIOS into \"Power Management Setup\" set \"ACPI Suspend Type\" to \"S3 (STR)\".\nSTR stands for \"Suspend to RAM\", screenshot and more in here\n\nA: This may depend on how old your computer is. I believe that this must be a supported mode in newer BIOSes (I believe that you may want to search for \"S3 Standby\" somewhere in your BIOS options).\n\nA: I was having the exact same problem with my computer. I would suspend, but the power supply, case and cpu fans would continue running. It turns out that I needed to change a setting in the BIOS to properly enable the suspend to RAM. In my BIOS the setting was located in the ACPI settings page. On that page there was a setting, \"Suspend to RAM\", that needed to be set to \"Auto\" instead of \"Disabled\". I have seen other BOISes that abbreviate this setting to STR. After I made the change and rebooted, suspend was working correctly, i.e. all fans and the power supply now turn off when the computer is suspended.\n\nA: After multiple researches and several attempts of trial and error, I found that Vista x-64 will not turn off the fans in standby mode unless all \"advanced power settings\" are either set to \"Disabled\" when available, or set to \"Maximum Power Saving\" when available.  Once you establish a profile that has these characteristics, then the standby mode will shut down the fans.  That's true whether you use the Power Button, or the command \"rundll32.exe powrprof.dll, SetSuspenState\".  Make sure you turn Hibernate state off by either using the disk cleaning utility or by setting it to off using the line command \"powercfg -h off\".\nGood luck and hope this helps.\n", "Q: What is Ubuntu Advantage? What is Ubuntu Advantage and how can it help my business?\n\nA: Ubuntu Advantage is paid support for Ubuntu Server and Desktop. It will provide support, legal assurance, a knowledge base, and Landscape. Landscape is management and monitoring tool to assist you with managing your servers and desktops. By legal assurance they will take care of intellectual property infringement legal claims brought against customers in their use of Ubuntu\n\nA: Ubuntu Advantage is a layered enterprise support service provided by Canonical to businesses.\nThese services can help your business successfully deploy and run a Ubuntu environment with expert assistance at hand when you require it.\nDesktop and Server packages are broken down into a number of features, all covering:\n\n*\n\n*Technical Support\n\n\n*Access to the Canonical Knowledge base\n\n\n*Landscape (Online systems management tool providing update management, scripting and monitoring across all your Ubuntu systems)\n\n\n*Legal Assurance (Canonical will cover intellectual property infringement and any legal claims brought against customers in their use of Ubuntu)\nFurther to the above there are a number of layered additional options for different support coverage on both Desktop and Server.\nUbuntu Advantage Desktop is broken down into two packages, Standard & Advanced.\nUbuntu Advantage Server is broken down into three packages, Essential, Standard & Advanced.\nYou can find the full description of these packages and the program in general on this page on the Ubuntu website.\n", "Q: How to run scripts every 5 seconds? I have a script that needs to be run every five seconds. I know that cron can do tasks by the minute, but is there a way to run something every second?\n\nA: Cron only allows for a minimum of one minute. What you could do is write a shell script with an infinite loop that runs your task, and then sleeps for 5 seconds. That way your task would be run more or less every 5 seconds, depending on how long the task itself takes.\n#!/bin/bash\n\nwhile true; do\n  # Do something\n  sleep 5;\ndone\n\nYou can create a my-task.sh file with the contents above and run it with sh my-task.sh. Optionally you can configure it with supervisor as a service so that it would start when the system boots, etc.\nIt really does sound like you're doing something that you probably shouldn't be doing though. This feels wrong.\n\nA: You could use a SystemD timer unit, which will trigger a service - that you'd set up to do what you want - every 5 seconds.\nSuppose your service unit is called mystuff.service and is installed in /etc/systemd/system (check out SystemD user services if you want to replace a user's crontab), then you can write a timer unit to run the service at boot time and then every 5 seconds, like this:\n/etc/systemd/system/mystuff.timer\n[Unit]\nDescription=my stuff's schedule\n[Timer]\nOnBootSec=5\nOnUnitActiveSec=5\n[Install]\nWantedBy=timers.target\n\nThen reload the systemd configuration, enable the timer unit and start it.\n\nA: You could have a cron job kick-off a script every minute that starts 12 backgrounded processes thusly:\n* * * * * ~/dostuff.sh\n\ndostuff.sh:\n(sleep 5 && /path/to/task) &\n(sleep 10 && /path/to/task) &\n(sleep 15 && /path/to/task) &\n(sleep 20 && /path/to/task) &\n(sleep 25 && /path/to/task) &\n(sleep 30 && /path/to/task) &\n(sleep 35 && /path/to/task) &\n(sleep 40 && /path/to/task) &\n(sleep 45 && /path/to/task) &\n(sleep 50 && /path/to/task) &\n(sleep 55 && /path/to/task) &\n(sleep 60 && /path/to/task) &\n\n\nMy question, though, is What on EARTH could you be doing that needs to run every 5 seconds?\n\nA: Just use a loop:\nwhile true ; do ./your-script & sleep 5; done\n\nThis will start your-script as a background job, sleep for 5 seconds, then loop again.\nYou can use Ctrl-C to abort it, or use any other condition instead of true, e.g. ! test -f /tmp/stop-my-script to only loop while the file /tmp/stop-my-script does not exist.\n\nA: Minimum configuration in cron is minutes, you can't set it for 5 seconds. You could use Quartz which does allow seconds. http://www.quartz-scheduler.org/docs/tutorials/crontrigger.html\n\nA: Use cacti to monitor router and switch,but Cron only allows for a minimum of one minute,so\n if one port/device down,there is no warning until two minutes past.\n\nA: You could use the GNU package mcron, a \"Vixie cron\" alternative.\nhttp://www.gnu.org/software/mcron/manual/mcron.html#Top\n\"Can easily allow for finer time-points to be specified, i.e. seconds. In principle   this could be extended to microseconds, but this is not implemented.\"\n\nA: I've done this sort of thing very successfully (and the end result rans weeks at a time, till the machine is rebooted).  As for what I was doing right now, updating information and putting it into cache - updating every 10 seconds.\n#!/bin/sh\n\nSLEEP=5\n\n# do stuff\nsleep $SLEEP\n\n# do stuff\nsleep $SLEEP\n\n# do stuff\nsleep $SLEEP\n\n# do stuff\nsleep $SLEEP\n\n# echo and restart...\nexec $0\n\nThe 'exec $0' restarts the script, but replacing the running script.  It can be initially started with a crontab '@reboot' line.\n", "Q: Comparizon between text editors in Ubuntu: Vim vs. Emacs vs. Nano I was wondering the difference between these text editors and which is best used with Ubuntu?\nWhat are each of them good for? Are there better ones?\n\nA: I know that this is not a \"manly\" terminal text editor, but gedit is nice. You can make gedit looks and feel a little bit like TextMate. This article is a bit dated, but will still give you the basic idea... http://rubymm.blogspot.com/2007/08/make-gedit-behave-roughly-like-textmate.html\n\nA: I love Vim. It's so powerful and effective and perfect in every way. However, most of the time I just use gedit, because I'm not as powerful and effective as Vim.\n\nA: Gedit is simple and lightweight, yes, but does it have any actual advantages over Geany? You have to install a bunch of plugins just to catch up with ordinary built-in features of Geany, like code folding etc.\nWhereas Geany plugins will give you extras like version control integration, optional and non-intrusive project management, jumping between function definitions and declarations, etc. And the configurable keybindings available in Geany allow you to set it up pretty much exactly how you like - though the defaults are pretty good too. Gedit can bundle a Python interpreter, but Geany bundles an entire virtual terminal.\nGeany doesn't come with Ubuntu, but it's available from the repositories, it's tiny (10MB) + fast, and it provides enough features to compete with full-powered IDEs; less bells and whistles, but better support for actual text editing.\n\nA: Nano is the easiest to use and learn. A lot of people will swear by Vim and Emacs but Nano is a very good text editor. Nano is good for editing a config file but if you are going to program you'll be better off using Vim or Emacs. Nano supports highlighting. But this is very subjective.\nEveryone is going to have their favorite editors for some reason. Find the one that you like the best and use it.\n\nA: Vim takes time to learn, but by the time you've got the hang of it (not just which key to hit when, but getting used to looking at the text that way), you stop about how to type and you can really focus on what to type. It becomes so natural that regular text editors will too hard to use. \nUse gvim and choose a theme you like a lot before you start learning, it can make it a more pleasant experience. Eventually you'll find yourself composing your emails in vim!\n(Ten-finger touch typing makes vim much easier to learn, so you may like to spend an hour or two with gtypist before trying vim, if you aren't already comfortable with touch-typing)\n\nA: Emacs is pretty good. It has syntax highlighting and supports extensions\nand is extensible through its embedded dialect of Lisp (elisp). It also has modes for many statistical programs, support for tex, a calendar, mail reading utilies, tetris and even a psychiatrist. Emacs (or Vim, but thats less good for stats) are worth learning as they are both cross platform and support almost every programming language in the world. \n\nA: I like vim because it makes coding feel like a video game. It's worth the learning curve. Why don't more applications behave like vim?\nTry the vimperator plugin for firefox.\n\nA: Vim can be found on virtually any Linux system, including your embedded devices. It's also very powerful (once you've learned how to use it).\n\nA: Simple answer is ...\nNano is a simple text editor.\nEmacs is a full fledged text editor with features for programming. This one is usually easier to learn but is still confusing. This is because advanced features are key combinations like crtl + e (goto end of line).\nVim is like Emacs only it uses a much different form of input. Vim is modal meaning that each key means something different in a different mode.\nBasically, Nano is for normal users. Emacs and Vim are for programmers. Take your pick (I'm not taking Vim vs Emacs side for this post lol)\n\nA: Another good one to use is Geany, found in the Ubuntu package manager or at geany.org . Has really good features and the built-in terminal window is really nice. I use it for most programming projects. I use VIM alot too, mostly when ssh'd into a server. The built-in Gedit is useful for quick edits and config files.\n\nA: I recommend gedit. It's got color coding for programming code which makes everything from HTML/CSS to PHP easier to read and edit. Emacs can do it, but it takes some effort to learn how to set up and use. Gedit is usable on your first attempt with no documentation required.\n\nA: I don't know anything about Nano and Emacs, but you can configure and extend Vim almost endlessly and it is available on most platforms. On the downside I can't imagine a texteditor with a steeper learning curve.\nOh, and don't forget Ubuntu's default text editor, Gedit. It has a lot of features built in and can be extended via plugins (try sudo apt-get install gedit-plugins)\n\nA: I use geddit with a combo of preferences and plugins. \nOn a new machine I check all the boxes on the first two tabs of preferences, set the tabs to use 4 spaces.\nI found the snippets plugin to be a rocker. It does not gives you the whole power of vi or emacs but it's almost there, and uses the same keybindings than any other app in gnome, it's more \"understandable\" :) at least IMO.\n\nA: Note. Geany is an excellent editor if you have to edit XML-(configuration)-files!\n\nA: My preferred one is gEdit. If you want to beef up to the level of TextMate you can do it this way:\nsudo apt-get install gedit gedit-plugins\ncd ~/Downloads\ngit clone http://github.com/gmate/gmate.git\ncd gmate\nsh ./install.sh\n\nOh and check the plugins to enable the cool features you need.\n\nA: I use nano with a whole load of customization for the languages I write. I get a simple UI with as many features as I want.\n\nA: I prefer gedit over all of those. \nAdmittedly I have spent next to no time trying vim but the other two I would not bother with. \nGedit is light but still has all the handy features you want like \nsyntax highlighting tabbed pages and word/bracket completion.\nHere are some screenshots from their site:\n \nI find emacs really horrible to use.\n", "Q: Simple software to show and modify GPS tracks I have GPS tracks (in gpx format) that I usually use to geotag photos. Is there a simple software to view these tracks (i.e.: not use Google Earth)? A bonus would be simple modification, like deleting waypoints. TangoGPS seems to offer GPS track import only in connection with geotagging for pictures.\n\nA: Try Viking - you can download and edit your tracks, and also add OpenStreetMaps, Terraserver or DEM layers. It also allows to have georeferenced map layers and some other features.\n\nA: I've found Merkaartor (in the repos) to be the simplest. But JOSM is the most used and widespread, it's a PITA to find the right version to use.\nI'd say give Merkaartor a shot :)\n\nA: Instead of installing software I used the free online GPX Studio which suited my purposes just fine (combining 3 GPX files and deleting a few waypoints). For the record I have no affiliation to the software, just a happy user.\n\nA: I would recommend GPSPrune. It is a Java application and support multiple platforms. I used it in Ubuntu, Windows and MacOS.\nMyself don't like multiple workflow and prefer sticking to same app where ever PC available to process and upload to OSM.\n", "Q: Choppy video playback During the last couple of months I have had major problems playing high-definition videos in Ubuntu. Generally it's 1080p videos that I have problems with, but I do recall having the same kind of problems with a 720p video a while back. This occurs on both my laptop (with an integrated Intel video chip) and my desktop (Nvidia Geforce 250GTS). It's strange, because I don't think I've had this problem in earlier versions of Ubuntu, and it works fine in Windows on the same machine(s).\nThe problems occur when trying to play a video that has been encoded to/with \"avc1\" in an mkv container. I'm not very knowledgeable when it comes to video codecs and such, but from what I've read, avc1 seems like a pretty old codec. How come I have problems with that, when Xvid works just fine? \nSuggestions on how to fix this problem?\nEDIT: So I've now tried all of the solutions proposed. None of them really worked, although some did lessen the choppiness. I even tried a 720p video using the same encoding, and that was also very choppy. Could someone explain to me why this just will not work, when I can play back other 1080p videos flawlessly? \n\nA: You can boost your preformance on the machine with the Nvidia chip by enabling VDPAU, which offloads some of the video rendering to your GPU instead of the CPU.\nInstall the package libvdpau1 and try using Mplayer to play your video. You'll need to have recent proprietary Nvidia drivers too.\n\nA: Newer X drivers are often available from the xorg-edgers repository:\nhttps://edge.launchpad.net/~xorg-edgers\nHowever, be aware those are just snapshots of upstream code, and not supported by Ubuntu.  They can sometimes have bugs and you might find it challenging to revert back to stock Ubuntu stuff, so only install them if you either feel very lucky, or you are skillful enough you can undo any damage they might cause.\n\nA: When I play high-definition content (720p to 1080p) on my computer which I bought in 2006, it struggles sometimes. I use mplayer for this, and when it detects a slow rendering of the video, it hints me to use the following command to play the video:\nmplayer -vfm ffmpeg -lavdopts lowres=1:fast:skiploopfilter=all video-1080p.mkv\n\nThis is just enough for me, in the case of my desktop computer, to watch 1080p videos. I hope this might be helpful to you.\nI'm not sure what all the options mean (haven't bothered to read the man page), but it seems like it's doing something right. :)\n\nA: Try xbmc\nI installed the latest nVidia drivers from the ubuntu repository along with the libvdpau1 package from a private package archive (nvidia-vdpau).\nWhilst I have had no luck with playback in totem, VLC or mplayer, using xbmc works just fine and plays 720 and 1080p movies very well.\nThe xmbc packages I am using are in a private package archive.  I used the following guide to install xbmc http://wiki.xbmc.org/?title=HOW-TO_install_XBMC_for_Linux_on_Ubuntu_with_a_minimal_installation_step-by-step\n\nA: I know I'm proposing just a workaround but... What about converting your video?\n\nA: You may not have any acceleration enabled in you xorg.conf based around your card.\nGoto Terminal and type:\nsudo service gdm stop\n\nLogin\nNow type\nsudo bash\n\n(you may be asked to enter your password)\nnow type:\nXorg -configure\n\n(Yes, the capital \"X\" is needed)\nNow type:\nsudo mv xorg.conf.new /etc/X11/xorg.conf\n\nand enter into GUI mode (with acceleration) by:\nservice gdm start\n\nAnd you will have all the modules and drivers you need to have best performance with your card. Horay!\n", "Q: Debugging OpenOffice crashes This is partly an OpenOffice question and partly a Ubuntu question. I'm running OpenOffice 3.2.0 and Ubuntu 10.04. I get frequent crashes of OO, especially the Calc app, although I get crashes in the word processor as well. They are very abrupt and accompanies by no warning or error message. I'm just typing away and then the app is gone. Sometimes I even end up thinking I'm typing in OO and discover that OO has crashed and I'm typing in whatever application was under OO. However, I can't reproduce these crashes on demand. They seem random. I can open the same file and do the same exact thing but it does not crash. \nIn Ubuntu how do I trace, track, or diagnose these types of crashes? Is there software I can invoke to help diagnose? Can I start OO from a command prompt with debugging of some sort enabled? \nNote: if someone could add the tag OpenOffice, I would appreciate it\n\nA: Here are the debugging procedures for Ubuntu. Here are the ones particular for OpenOffice. One of the first things to do, is to install the dbg packages, since they allow proper stack traces. \n", "Q: What does it mean that a package is \"set to manually installed?\" When packages are already installed and I run an apt-get install <package-name>, sometimes it will print a line <package-name> is set to manually installed.\nWhat does that mean?\n\nA: It means that a package was manually selected and not automatically by another packages or a meta-packages. The difference it, that the latter can be auto-removed, when the package that triggered this install is not anymore present (after an upgrade, or because it was removed). A manually selected package should not be removed in this way.\nThis has no impact on the ability to upgrade package when such upgrades are available or the notifications thereof.\n\nA: You can use sudo apt-mark auto $PACKAGES to mark packages as automatically being installed again, if you accidentally mark them as manually installed.\nAutomatically installed packages can be removed using apt-get autoremove (or using similar processes, e.g. via Synaptic).\n\nA: If you install a package, all packages that that package depends upon are also installed. For example if you install the package vlc, it will automatically install vlc-nox. The automatically installed packages (in this case, vlc-nox) are set as \"automatically installed\" -- if you remove vlc, the package manager will suggest to remove vlc-nox as well (aptitude will do this automatically, if you use apt-get you can remove all automatically installed packages with apt-get autoremove).\nNow, if you do apt-get install vlc-nox you will get the message that vlc-nox is now set to \"manually installed\", i.e. the package manager now thinks that you want that package specifically and not just installed it because vlc needed it. If you remove vlc, vlc-nox will therefore not be automatically removed.\nThis does not affect updates in any way.\n", "Q: How can I make my windows \"burn\" when I close them? I have CompizConfig Settings Manager installed, but I don't know how to make windows burn when I close them. How can I make this so?\n\nA: *\n\n*Install CompizConfig Settings\nManager, and\nCompiz-Plugins-Extra.\nsudo apt-get install compizconfig-settings-manager\n\n\n*\n\n*Warning: What are some of the issues with CCSM and why would I want to avoid it?\nsudo apt-get install compiz-plugins-extra\n\n*Launch CompizConfig Settings\nManager by searching from the dash\nin Unity, or Preferences >\nCompizConfig Settings Manager in\nUbuntu Classic.\n\n*Enable Animations, and\nAnimations Add-On.\n\n\n\n\n\n*\n\n*Open Animations, and switch to\nthe Close Animation tab.\n\n\n\n\n\n*\n\n*Double-click the first item in the\nlist.\n\n\n\n\n\n*\n\n*A new window will appear, change the\nClose Effect to Burn.\n\n\n\nPlease make sure you have the cellphone number of the nearest Fire Brigade available, because your system is about to catch fire... literally.\n\nA: OK first you need to install the \"CompizConfig Settings Manager\" either go to the Ubuntu Software Centre and install the Advanced Desktop Effects Settings (CCSM),\nor use the command:\nsudo apt-get install compizconfig-settings-manager\nWhen that is done go to the System > Preferences and start the CompizConfig-settings Manager\nGo to the Effects section and enable the Animations Add-on.\nYou can then go into the Effect settings by clicking on the name to the right of the check box, under the Burn heading are all the options to tweak the animation. Hours of pointless fun playing with this.\n\nA: Just do it from Synaptic\nSearch for compiz-fusion-plugins-extra package\nWhen you see it just mark it for install and a few seconds and here you are \nall effects are shown up\n\nA: On Ubuntu MATE 20.04 the \"Animations add on\" is not under \"Effects\" I found it under ? Uncategorized.\nClicking it will enable it and the rest of the instructions work just fine.\n\n", "Q: Weather notification attached to clock applet I am unable to get the weather notification that comes with the clock applet to work.\nI have it set to Ottawa,  Canada. What seems to be the problem.\nCanada jokes to the minimum please :)\nPlease and thank you.\n\nA: The Canadian location that I have in the Weather tool on my computer includes the province.\nWhen I go to the Choose Location screen and type \"Ottawa\" I get a suggested entry of \"Ottawa, Ontario, Canada\". Using the suggested location results in the weather icon beside the placename, but if I enter \"Ottawa, Canada\" no weather information is displayed.\nTry adding a new location and make sure to select the name suggestion that should appear when you type \"Ottawa\". I have found some quirks with the weather locations on the clock menu, at least on my system. (I have explained them below.)\n\nOn my Ubuntu system, in order to get the weather icon I had to actually select the suggested location name rather than typing the full name. \nIf Ubuntu has not recognized the location the full \"text of the \"Location Name\" field (e.g. \"Ottawa, Ontario, Canada\") will be displayed. If the location has been recognized the display will shorten that to just \"Ottawa\". The weather icon only seems to appear when Ubuntu recognizes the name.\nHere is what I did: \n\n\n*\n\n*I went to the Locations tab of the Clock Preferences and added a location named \"Ottawa, Canada\" with a time zone of \"Eastern Time (GMT-5 / GMT-4)\".\n\n*I then edited the location I just added, and changed the location name to \"Ottawa, Ontario, Canada\".\n\n*Without clicking on the suggested name that popped up, I clicked OK. \n\n\nAt this point the Locations list displayed \"Ottawa, Ontario, Canada\" without weather.\nFinally, I edited the location again, and backspaced some letters to get the suggestion popup to reappear. I selected \"Ottawa, Ontario, Canada\" from the popup and clicked OK again. Now the Locations listed displayed \"Ottawa\" with a weather icon.\nI even tried copying all of the information from a working location entry (including the latitude and longitude) into a new location. The only way I could get the weather icon was by actually selecting the appropriate name from the suggestion popup.\n\nA: It could be that it's not getting any data from your local whether station, I guess. Have you tried setting it to a different location - just to see if it works at all?\n\nA: You may want to try setting Ottawa airport code (YOW) as weather station. It usually works for me (LEAS, Asturias, Spain) when any other weather stations are down or don't work.\nGood luck!\n", "Q: How can a user avoid entering password on boot? Is there a way to avoid entering a password in the process of booting up?\nI am using a new and latest installation of Ubuntu, with Gnome desktop in it.\n\nA: System → Administration → Login Screen. Unlock the dialog and choose what account to log in automatically as.\n\nA: You might have installed Ubuntu with the whole partition being encrypted. This will require you to enter a password before it can boot the system. If you want to avoid this, you should not choose the option for full partition encryption.\nSee also here\n\nA: Do you mean the password request to unlock your keyring? If so, refer to this - How can I stop being prompted to unlock the 'default' keyring on boot?\n", "Q: todo list and memory usage applet on desktop? I would like to have information on my desktop in a very simple text mod or memory usage and processor activity and daily to do lists.\nI was wondering what kind of applications are available on Ubuntu for that?\nPlease and thank you.\n\nA: todo.txt with Conky is my favorite setup. Command line todo list hotness, displayed on your desktop!\n", "Q: Can I set up Portage and USE flags? I'm rather familiar with portage and USE flags in Gentoo. After a quick google search, I didn't see any way to setup Portage in Ubuntu. Is there a way? Is there an equivalent to USE flags in Ubuntu?\n\nA: It is theoretically possible to setup portage on Ubuntu or any other linux. However for that to be useful, portage would have to be able to interact with apt somehow (at the very least be able to find packages installed by apt), which it's not. There's also no extension to portage that allows something like that, so this is not a good idea.\nAnd no, apt does not have anything like USE flags, as it uses binary packages so it's too late to specify any compile flags. However sometimes there are multiple packages of the same software with different features enabled. For example there's nethack-console, nethack-x11 and nethack-qt, which in portage are all covered by one package with different USE flags.\n\nA: You can install almost any ubuntu software from source if you like.  You first have to enable the source repositories:\nSystem -> Administration -> Software Sources\nMore details here:\nhttps://help.ubuntu.com/community/Repositories/Ubuntu\nThen you can install and build from source like so (fetches dependencies automatically):\napt-get build-dep some-package-name    \napt-get source -b some-package-name\n\nThis will download, unpack, and build the given package into a .deb that can be installed. While there is no direct equivalent of the portage 'USE' flag, you can get access to any of the build flags for the package and rebuild it after your initial download. \nIf you want to later remove the package, you can do:\napt-get remove some-package-name\n\n", "Q: Why are Flash applications so sluggish/crashy? I've noticed that Flash applications tend to be more sluggish under Ubuntu than they do under Windows on the same machine. This is particularly noticeable when watching HD video or playing graphics/physics-heavy games. Are there any ways of improving the performance of Flash under Ubuntu, or is this just an issue with the Linux version that I will have to live with?\nCurrently I'm just cutting down on the number of tabs open, blocking flash ads, and closing other programs, but I'm looking for ways to affect Flash itself.\nOther things I have already been doing include using Youtube's HTML5 feature and playing videos straight from /tmp in VLC. I was wondering if there was some way of streamlining Flash itself though. Perhaps not.\nMore Specific Question: Is there anything I can do in mms.cfg to boost performance?\n\nA: Alternatively you can use Gnash or Lightspark.\n\nA: This is an issue with the Flash Player - the Linux version has some performance issues with playing video.\nYour best bet for sites like YouTube that support HTML5 video is to use that instead. (See here for details.) The performance is much better.\n\nA: I would hope your using Ubuntu. Its pretty straight forward if you use the installer given to you from the adobe website. \nIt might just be a low on processing power since flash is processor extensive process, also more ram might help.\nAlso going to System > Administration > Hardware Profiles and making sure your graphics drivers have the correct settings helps.\n:)\n\nA: Try disabling desktop effects.\n\nA: In addition to the suggestions above - try disabling compiz, using chrome, making sure the fastest graphics drivers are installed - you could try to override the Flash plugin's detection for hardware acceleration. I can't vouch for the usefulness of this hack, though.\n\nA: Hardware acceleration in flash for video and graphics is currently only supported on Windows platform. See: http://www.adobe.com/devnet/flashplayer/articles/fplayer10.1_hardware_acceleration.html\n\nA: Try using Google Chrome browser. I found it to be faster than Firefox in Ubuntu, for normal pages or those with Flash.\n\nA: If for instance you want to play a youtube video there is a workaround!\nFlash buffers the video to you disk, that file will be in /tmp/ and called something like FlashXXp0sHC0, that is Flash + 8 random chars. You can play it in a normal player, or even copy it somewhere else for offline viewing (Note that in most countries it is illegal to copy the file since it a breaches copyright).\nThis approach will work on a lot of sites but depends on what the streaming format is. If in doubt you can use the file utility to detect what is in the file\nuser@host:~$ file /tmp/FlashXXp0sHC0\n/tmp/FlashXXp0sHC0: ISO Media, MPEG v4 system, version 2\n\nuser@host:~$ file /tmp/FlashXXLE3wCf\n/tmp/FlashXXLE3wCf: Macromedia Flash Video\n\n\nA: I am running Ubuntu 12.04 64-bit with an Nvidia GeForce 8400 GS.  I have had Flash-related issues since performing a clean install of 12.04.  Just like you, I have installed the proprietary drivers, but System Settings > Details lists Graphics as \"Unknown.\"   \nI was having speed issues, but most annoylingly, the same issues as reported in Flash video appears blue on this forum. Following the workaround posted at the previous link stopped the unwanted behavior of all Flash video being tinted blue, but ended up causing the Flash plugin to crash nearly every time I attempted to watch a video online.\nThe solution for me was to look back at /etc/adobe/mms.cfg and remove everything but one line, which should read:\n OverrideGPUValidation=true\n\nIf you are not sure how to do this, you can use your favorite text editor (for me it's vi) or you could pop open gedit with the following terminal command:\nsudo gedit /etc/adobe/mms.cfg\n\nWrite in the OverrideGPUValidation=true line from above, save the file, and quit gedit.  Restart your browser and see if this solves the problems you are having.\nThis idea and others are discussed on ubuntuforums, and many other places. Please try changing your mms.cfg (or creating it, if it does not already exist) and post back with your results. Good luck!\n\nA: If you're using the AMD64 build of Ubuntu, try downloading the beta AMD64 flash player.  The x86 build is run through an emulation layer that I've had tons of problems with.\n\nA: I experienced the same annoyance under Ubuntu 12.04.3 on my netbook [Asus 1005PE, Intel GMA3150 video chipset, linux-generic-lts-raring kernel + xserver-xorg-video-intel-lts-raring]\nIn addition to the /etc/adobe/mms.cfg file workaround, I went to compizconfig settings manager (if not installed, sudo apt-get install compizconfig-settings-manager) and completely disabled the \"dim windows\" option under Effects, at the bottom section.\nLess load on the system (without even giving up on Unity nor adobe-flashplugin), and voilà, fullscreen flash videos don't stutter now.\n\nA: Flash video files are no longer in /tmp\nthis is a script that will locate and play the streaming flash video file using the Player of your choice\npastebin.com/dFamyLd5\nIf the stream is not fast enough there is no buffering the player will just stop or exit\n\nTo use it pause the streaming media and run the script\nI use this command on a launcher with it\nvideo smplayer \"-close-at-end -fullscreen -minigui\"\nI saved the script to /usr/local/bin/video\nIf you use echo for the player parameter it will print the path to the video\n\nThis will not work on streams use DRM\n\nTechnically the answer to the question is cause flash is a piece of junk that should have died off a few years ago.\n", "Q: Songbird Alternatives I like the songbird player very much, and it used to be my only choice for all plataforms, but they have discontinued GNU/linux support for some time now, due to lack of people to help with the linux port.\nI would like to know what are the alternatives with similar features and usability out there.\n\nA: Banshee is the best. Amazon, ubuntu one, and ITUNES IMPORT plugins to start.\n\nA: It would be worth keeping an eye on the nightingale project.\nThey aim to continue to develop and maintain a Songbird version for linux.\n\nA: I really like mpd, a music playing daemon. The idea is that you have the daemon running which can play music and you can connect with multiple clients. ario is a nice one, and sonata is a very nice simple one. You even have cli clients if that is your deal(it sure is mine), the best cli one is ncmpcpp, and I agree it's a shitty name\n\nA: Rhythmbox is installed by default (Applications > Sound & Video > Rhythmbox Music Player)\nBanshee can be installed from the Software Center (Applications > Ubuntu Software Center) or from the terminal (sudo apt-get install banshee) or if your browser supports apt links: apt:banshee\n\nA: Clementine Music Player: A very simple yet feature rich music manager.\nFeatures:\n\n\n*\n\n*Search and play your local music library\n\n*Listen to internet radio from Last.fm, SomaFM, Magnatune, Jamendo and Icecast\n\n*Create smart playlists and dynamic playlists\n\n*Tabbed playlists, import and export M3U, XSPF, PLS and ASX\n\n*CUE sheet support\n\n*Visualisations from projectM\n\n*Lyrics and artist biographies and photos\n\n*Transcode music into MP3, Ogg Vorbis, Ogg Speex, FLAC or AAC\n\n*Edit tags on MP3 and OGG files, organise your music\n\n*Fetch missing tags from MusicBrainz\n\n*Download missing album cover art from Last.fm\n\n*Native desktop notifications on Linux (libnotify) and Mac OS X (Growl)\n\n*Remote control using a Wii Remote, MPRIS or the command-line\n\n*Copy music to your iPod, iPhone, MTP or mass-storage USB player\n\n\n\n\nA: I've become a huge fan of Minitunes. Minimalistic, still lacks advanced functionality, but its premise and direction are fantastic.\n\nA: My favourite player is Amarok, although it isn't particularly similar to Songbird..\n\nA: Okay, I misunderstood the question.\nI recommend MediaMonkey for managing your music and playback.\nNote: MediaMonkey is a Windows application, but according to the website, it runs fine under wine.\n\nA: If your after something similar to the filter panels found in Songbird and iTunes, Guauadeque is probably more suited to former Songbird user.  Works pretty well for me, and is regularly updated. :-)\n", "Q: How should a server be secured? Talking towards Ubuntu 10.04, server edition, what tools/practices would you recommend to secure the server?\n\nA: Awesome answer by Richard Holloway. If you are looking for a specific step by step guide checkout the following 2 part guide from Slicehost library.\n\n\n*\n\n*http://articles.slicehost.com/2010/4/30/ubuntu-lucid-setup-part-1\n\n*http://articles.slicehost.com/2010/4/30/ubuntu-lucid-setup-part-2\nI use it almost everywhere when I have to setup an Ubuntu Server instance. I am sure you would love it.\nOther great source is the Linode Library at http://library.linode.com/\nDo check out the articles at both places. Loads of informations is available there and you will be armed with enough knowledge to handle your server just fine.\nPS: In no way, a library can be a substitute for a great sys admin's intuition, insight and decision making capabilities. \n\nA: This a bit non-specific, but in general you will need to \n\n\n*\n\n*Run a firewall like iptables or ufw to manage connection to open ports.\n\n*Only install software your require.\n\n*Only run services that are essential to the running of the server. \n\n*Keep that software up to date with all security patches. \n\n*Set up new users with the least privileges they require to perform their duties. \n\n*Run denyhosts or fail2ban to check for brute force attacks.\n\n*Run logwatch to email you of any anomalies in log files.\n\n*Check your logs often for suspicious activities. \n\n*Use sudo always and use strong passwords.\n\n*Disable weak and medium strength ciphers in SSL for apache, exim, proftpd, dovecot etc.\n\n*Set services to only listen to localhost (where appropriate).\n\n*Run chkrootkit daily.\n\n*Run clamscan as often as is required to check for windows viruses (if appropriate).\n\n*Be vigilant, know your server, know what it should be doing and what it shoudn't be doing.\nYou will only keep things secure by constantly checking and securing. If you don't know what something does or how or why, or something looks suspicious, just ask others for advice.\n\nA: Something I don't see mentioned is \"use 64bit\". This makes sure you've got NX memory protections, among other things.\n\nA: Three things I tend to recommend are:\n\n\n*\n\n*Mount all globally writable areas (/tmp, /var/tmp) as 'noexec':\nThis for the most part is safe without quirks, except (as of writing) unless you choose to upgrade your system. See bug #572723 on Launchpad for more details there.\n\n*Don't install any compilers or assemblers unless absolutely necessary:\nI think this self explanatory.\n\n*Get started with AppArmor:\nAppArmor can be seen as an alternative to SELinux, and is great feature of Ubuntu to sandbox running applications to ensure they don't have any more access than what they need. I recommend reviewing the guide on the forums if you are interested. http://ubuntuforums.org/showthread.php?t=1008906\n\nA: *\n\n*Install and configure iptables with an appropriate ruleset for your environment. Filtering both inbound and outbound traffic.\n\n*psad to detect and alert about any port scans against your system. \n\n*Use fail2ban to prevent brute force login attempts against SSH.\n\n*Disallow remote access using the root account, as this amongst other things means that if an attacker is going to attempt to brute force access to your server they have to workout both the username and the password.\n\n*Use strong passwords for all user accounts. \n\n*Limit SSH access to only be available from certain IP addresses if possible. \n\n*Use Tripwire of another Host-based intrusion detection system.\n\n*Monitor the server with a network monitoring program like nagios. \n\n\nA: If I were you, I'd look into iptables (standard Linux firewall) and see what services are running.  Basically you want to only be running the services you need, i.e. not running a web server when you just want to setup an email server, and to only have the ports open that you actually require.  Everything else should be locked down!\nGuide to iptables: https://help.ubuntu.com/community/IptablesHowTo\nHope this helps!\np.s If you need more help get on irc and hit the #ubuntu-server channel on freenode\n\nA: For firewalls you could have a look @ Firestarter or ufw with gufw.\n", "Q: How would you explain that Ubuntu is fine for many people How would you explain that Ubuntu if fine for most people who just want to browse the web, write e-mail, and so on?\n\nA: I like to bring along a non-technical person, and have them explain Ubuntu is fine.\nYou can argue until you're blue in the face, but most people will just think, \"Well, you're a technical person, of course it's easy for you.\"  But when someone that they consider a peer who has their same (or less) computer experience tells them in a heartfelt way, \"Ubuntu is plenty good\", that's the best sales pitch.\n\nA: This is the sort of question better directed to the Ubuntu Marketing Team - not only is it their entire reason for being, but they can also provide materials, mentoring and research data to back up assertions.\nIn particular you should read the Activism Guide and look at the materials available  on the Spread Ubuntu site.\nI personally like to show people the Ubunchu! manga, it goes over well in my social circles.\n\nA: Let the people forget about the os! Nobody works with the os. As you write in your question it goes about writing e-mail or browsing the web: there are the applications who are curcial. So, firefox is know very well to browse the web but what email-client would you promote?\nIf these apps are usable on windows, like firefox, let the people try them and if it comes to the point that they should pay for an app like outlook people reminds that there exists an app for free.\nTime comes where a computer must be replaced and that will also be a point of decision. If the experience with the apps are positive it will be a small step to save some money and choose a free os.\n\nA: Just show them.\nRemember that Ubuntu is different, but you need it to be better for people to consider it.  Much like switching from a right-hand scissor to a left-hand scissor.  Can do the same, but is different, and it needs to be better to be considered.\n\nA: I would just show them the efficiency of ubuntu on my dual boot machine with windows and to compare the difference for themselve.\n\nA: I like to show them Compiz. :)\n\nA: People are so entrenched in using Windows that telling them ubuntu is better for their basic tasks is not enough, you have to show them how ubuntu can be better/easier performing whatever it is they are trying to accomplish.\nYou can set up a fully configured Ubuntu box for them and show the differences on their daily usage. \nYou can show to them how a particular Ubuntu / linux app is more suited / easier / cheaper\nfor them.\n\nA: How you did know that yourself? If someone told you and it worked, it's very likely that it works for some other people :) Let them to try it for themselves, help them to clean that «uncleanable» virus in their pendrive, show them that great Compiz effect... and tell them they also can do that easily.\nAlso, you may want to join a LoCo Team near you and get involved in spreading Ubuntu in your community.\n", "Q: Change Primary monitor How do I change my primary monitor without using the command line?\n\nA: For most video cards:\nGo to the monitors preference panel.  On a default desktop install this is:\nSystem - Preferences - Monitors\nUncheck the \"Same image in all monitors\" box and hit \"Apply\".\nHold the Alt key and drag the top and bottom panels to the screen that you want to be the primary display.\nFor NVidia video cards:\nRun the NVidia settings tool.  On a default desktop install with the NVidia proprietary drivers enabled, this is:\nSystem - Administration - NVIDIA X Server Settings\nSelect \"X Server Display Configuration\".\nChoose the display you want to be the primary display and check \"Make this the primary display for the X screen\" and hit \"Apply\".\n\nA: Quickest way is to just switch the cables on the back of the computer.\n\nA: I just deleted ~/.config/monitors.xml and logged out and back in, then went to Setting / Monitors and re-saved. This created a new monitors.xml file - and that fixed the problem. \n\nA: Until Ubuntu Brainstorm Idea #17526 becomes a reality, it seems there is no way for non-NVIDIA users to change the primary display (not just move the panels) without resorting to the command line. \n\nEdit 2014-05-30: That answer is a little outdated now. Ubuntu Brainstorm no longer exists. And other answers to this question have better solutions, both for Ubuntu, and other distros. \nIn MATE, \"Preferences > Monitors\" has a \"Make Default\" button. That's what you're looking for. \nIn GNOME 3, \"Settings > Display\" doesn't have a \"Make Default\" button. Instead it has a toolbar-looking bar at the top of one of the displays. Drag that to the display that you want to be primary.\nI believe Unity is similar to GNOME 3, but the toolbar is on the side -- I don't know for sure though; I'm not running Unity myself.\nIn KDE, under \"System Settings > Display and Monitor\" there is a star on each display that you can click to set which is primary.\n\nEdit 2015-02-25: It's heart-warming to know that Linux desktop environments are progressing. \nUbuntu GNOME 14.10 features GNOME 3.12. Open Displays, and choose the secondary display. A list on the left lets you set the display to \"Primary\", \"Secondary Display\" (selected), \"Mirror\", or \"Turn Off\".\n\nUnity no longer has an equivalent of primary desktop. You can set \"Launcher placement\" to either of your displays, or all displays.\n\nUbuntu MATE and Kubuntu are unchanged.\n\nA: In Ubuntu this can be solved as follows:\nClick on the Gear Icon on the Unity launcher (the bar on the left side of the screen).  The icon is labeled System Settings\nLook under the Hardware Section and click the Displays icon\nTurn off Mirror Displays (optional)\nCLick on one of the display rectangles and drag the displays around to whatever order you prefer\nSet any other desired options. For example, you can set the Launcher to only show up on one display\nClick Apply\nYou will now have the primary monitor setup as desired - all without using the command line as mentioned in your question.\n\nA: In Unity with 14.04LTS nothing of this works. The monitors.xml is well written and has the primary well and positions well defined but when reboots, it ignores the primary and position.\nThis seems to help \nhttp://bernaerts.dyndns.org/linux/74-ubuntu/309-ubuntu-dual-display-monitor-position-lost\nAltough i am unable to make the suggested script to run on reboot. I added the command to run it in the startup but it does not appear to work. But after reboot even if i increase the delay of execution; if i run manually the script it corrects the monitors.\n\nA: I was having problems with the primary monitor reverting on reboot. Was getting pretty annoying. So I did some searching around and was able to find a solution of my own.\n\nFirst select your primary display.\n\nMake sure you save your settings, then close.\nNext you need to edit the monitors configuration file.\ngedit ~/.config/monitors.xml\n\nFind the display you wish to make primary, and change to\n<primary>yes</primary>\n\nAnd make sure to change the other monitor to\n<primary>no</primary>\n\nNow save the files, and reboot.\nExample config\n<monitors version=\"1\">\n  <configuration>\n      <clone>no</clone>\n      <output name=\"DVI-I-0\">\n      </output>\n      <output name=\"DVI-I-1\">\n      </output>\n      <output name=\"TV-0\">\n      </output>\n      <output name=\"DVI-I-2\">\n          <vendor>SYN</vendor>\n          <product>0x0022</product>\n          <serial>0x00000326</serial>\n          <width>1360</width>\n          <height>768</height>\n          <rate>60</rate>\n          <x>0</x>\n          <y>312</y>\n          <rotation>normal</rotation>\n          <reflect_x>no</reflect_x>\n          <reflect_y>no</reflect_y>\n          <primary>no</primary>\n      </output>\n      <output name=\"DVI-I-3\">\n          <vendor>ACI</vendor>\n          <product>0x24f2</product>\n          <serial>0x01010101</serial>\n          <width>1920</width>\n          <height>1080</height>\n          <rate>60</rate>\n          <x>1360</x>\n          <y>0</y>\n          <rotation>normal</rotation>\n          <reflect_x>no</reflect_x>\n          <reflect_y>no</reflect_y>\n          <primary>yes</primary>\n      </output>\n  </configuration>\n</monitors>\n\nNow when you reboot the display should be selected as primary.\nMy setup is as follows:\n\n*\n\n*Ubuntu 12.04.1 (64-bit)\n\n*nVidia GTX 260 (using latest drivers)\n\n\nA: Worked for Xubuntu 14.04 Trusty tahr nvidia gtx 760 using proprietary driver 331.38 on x86_64.\n\"Settings manager\" -> \"Session and Startup\" -> \"Application Autostart\" register -> add following command:\n xrandr --output HDMI-0 --primary\n\nspecify title yourself so you recognize if changed later on. You can give even further arguments to it.\nTo know which monitor is which you can either call xrandr -q on the commandline or install arandr (available in the settings-manager too) to list the monitors.\n\nA: To move them all at once, turn off the secondary monitor, confirm, and turn it on again - and all programs will be on the primary monitor. \n\nA: In the Screen Display manager, both your monitors must be shown side-by-side. You can drag the left one to the right side to switch the primary monitor between them.\n\nA: With Ubuntu 16.04.2, I had to define, in first, the screen primary by xrandr command :  \nxrandr  --output  Monitor_ref°  --primary\n\nand then drag and drop the right screen to the left.\nThe ~/.config/monitor.xml file was then updated.\nI didn't find any other solution, without a command line.\n°Monitor_ref can refer to various outputs VGA-0, DVI-0 etc. The output of xrandr -q will list them.\n", "Q: How can I stop being prompted to unlock the 'default' keyring on boot? Whenever Ubuntu boots up, a dialogue pops up asking me to unlock my default keyring.\nIs there some way this can unlock automatically through PAM or some other magical way?\n\n\nA: Using Ubuntu 11.10 with Unity: \n\n\n*\n\n*Open \"Passwords and Keys\" application\n\n*In the Passwords tab, right click on the password icon\n\n*Select \"Change Password\" \n\n*Enter your current password as the \"Old Password\"\n\n*Leave the \"New Password\" and \"Confirm\" fields empty\n\n*Click \"Ok\"\n\n*Confirm to \"Use Unsafe Storage\"\n\n\nHope that works for you\n\nA: For Ubuntu 12.10 and onwards\nThe interface of the \"Password and Keyring\" manager changed slightly in 12.10. When you open it, you won't immediately see the \"Login\" keyring as described in other answers. The interface will look like this:\n\nIn order to view the Login keyring, you need to open the View menu, and choose By Keyring. Once that's done, your interface will look like this:\n\nRight-click on the \"Login\" entry at the top and choose Change Password. You'll need to enter the current password, which should be your user account password, before continuing. When you do that, you'll get a dialog where you will be asked to enter the new password twice:\n\nLeave this blank, choose \"Continue\", and choose it again to confirm you desire to continue without a password.\n\nA: For Ubuntu 21.04 If your error is like\nWARNING: Keyring is skipped due to an exception: Failed to unlock the \n\nkeyring!\n\nA popup will show on the screen everytime click on classic encrypted then finish. It will ask you the password Please type no password and confirm it will again ask you syntax must be filled something.\nIf you created you password and it will prompted every time.then do like this\nStep\n\n*\n\n*Go and search password/keyring/seahorse\n\n\n\nYou will find like this password and keys\n\n\n*Click  on login and click right mouse buton select change password\n\n\n\n\n*Type your login user password\n\n\n\n\n*Leave Blank\n\n\n\n\n*Click Continue\n\n*Again continue\n\n\n\nA: For versions up to 12.04: (for 12.10 onwards, see this answer)\nThe method is similar to previous Ubuntu versions, but I also include a command-line alternative at the end.\n1. Using the Gnome Keyring Manager (Seahorse)\n\n*\n\n*Press Alt+F2, type seahorse and press Enter to start the Gnome Keyring Manager:\n\n\n\n*Alternately, open a terminal with Ctrl+F2+T, type seahorse & and press Enter.\n\n\n*The \"Passwords and Keys\" window should come up as shown below. Under the Passwords tab, select login, right-click on it, and then click on Change Password:\n\n\n\n*The \"Change Keyring Password\" box will come up. Type your old password, and then leave the new/confirm password fields blank. Then press OK, and the information box shown below will pop-up; read it, and then click on Use Unsafe Storage to not have to enter your password at each login:\n\n\n\n*Close the keyring manager. After you log out/reboot, you won't be asked for your password any more.\n2. Disable the login keyring password from the command-line\nAs an alternative to all the above steps, simply open a terminal, and type/paste the below, changing MYPASSWORD to whatever your current password is; that's it!\n\npython -c \"import gnomekeyring;gnomekeyring.change_password_sync('login', 'MYPASSWORD', '');\"\n\n\nA: As the other answers say, disable auto-login and ensure that the keyring password is the same as the login password.\nIf it still doesn't work then you may be missing the required package.  On Ubuntu 19_10 I had to run\nsudo apt-get install libpam-gnome-keyring\n\n\nA: Simply delete your default keyring. (Backup the passwords first!) You don't need it. You can keep all your keys in the login keyring. \nThe login keyring is unlocked when you login. All keys in it will be available, you don't have to enter more passwords again. \nIf you are using auto-login, then when you want to access something that needs a key from the login keyring you will be prompted for the password, of course, but only once.\n(As many answers already pointed out) your keyrings are in System / Preferences / Passwords and Encryption Keys\n\nA: For Ubuntu 13.10:\n\n\n*\n\n*Open Applications -> Accessories -> Password and Encryption Keys\n\n*Click View -> \"By keyring\"\n\n*Right-click on the \"login\" keyring\n\n*Select \"Change password\"\n\n*Enter your old password and leave the new password blank\n\n*Press ok, read the security warning, think about it and if you still want to get rid of this dialog, choose \"use unsafe storage\".\n\n\nA: Be warned that this will make your keyring accessible without a password. Period. You don't have to be logged in to view it\nWith that being said,\nI think the simplest way is to set the password for the keyring to an empty password -- you will not be prompted for a password then:\n\n\n*\n\n*Open Applications -> Accessories -> Password and Encryption Keys\n\n*Right-click on the \"login\" keyring\n\n*Select \"Change password\"\n\n*Enter your old password and leave the new password blank\n\n*Press ok, read the security warning, think about it and if you still want to get rid of this dialog, choose \"use unsafe storage\".\n\n\nAgain, as the message says: This will expose all your passwords (e.g. email passwords) that you chose to save in the default keyring to anyone using your computer or having access to your files and is therefore not recommended.\nAddendum for Ubuntu 11.04:\n\n\n*\n\n*In the default Unity session, you can start the application by clicking on the Ubuntu logo in the top left corner, then typing Password, and selecting Password and Encryption Keys from the search result.\n\n*In the classic session the path to start the application has changed to System → Preferences → Password and Encryption Keys\nAddendum for Ubuntu 11.10:\n\n\n*\n\n*In the default Unity session, you can start the application by clicking on the Ubuntu launcher (the first item) in the Unity launcher bar on the left side, then typing Password, and selecting Password and Encryption Keys from the search result.\n\n*In the classic session (from the gnome-session-fallback package) the path to start the application has again changed to Applications → Other → Password and Encryption Keys\n\nA: Use this if you have forgotten the old password and is ok to delete items in the old keyring, but want to safeguard new keyring with matching password.\nFor Ubuntu 14.04, I used the following.\nRemove old keyring:\ncd .local/share/keyrings/\nrm *.keyring\n\nRestart the system to have the new keyring created:\nsudo shutdown -r now\n\nVerify the new keyring exists:\ncd .local/share/keyrings/\nls -ltr *.keyring\n\n\nA: You need to get the password for your login key ring to be the same as your normal login password.\nTo do this follow the path:\nOpen Applications > Accessories > Passwords and Encryption Keys\n\nYou will see under the passwords tab a list of keyrings. One should be called \n\"Passwords: login\"\nClick on the + and you should see a list of accounts that require passwords such as you Gwibber details, Evolution passwords etc.\nThis means when you log in all of these accounts will be unlocked by this login keyring.\nTo get the keyring to unlock when you log into Ubuntu, right click on \"Passwords: login\" and choose \"Change Password\"\nYou will then need to enter your current keyring password and set your new keyring password to be the same as your normal login password.\nTo test: Log out, log back in and open Evolution to prove that this has worked.\n\nA: open passwords and keys then \n\n\nThen you need to enter your current password (old password). Don't enter any password for your new one, or leave it blank.\nYou need to confirm that you will store unencrypted password. If you are sure that it is what you want, then just click \"Use Unsafe Storage\" button.\n\nA: I have solved this problem through terminal.There is a directory under /usr/lib , called gnome-keyring. Under that directory there are a directory 'devel' and two files gnome-keyring-prompt and gnome-keyring-prompt-3.I don't know much about the directory 'devel'.So I removed only the two files and solved the problem.The corresponding commands are here-\ncd /usr/lib/gnome-keyring\n\nThen\nsudo rm gnome-keyring-prompt gnome-keyring-prompt-3\n\nAnd then reboot your computer to see the effect. \n", "Q: How do I  configure Ubuntu for a public computer? How would you set up Ubuntu on a computer that will be used as public computer in a library?\nI need the following features and user restrictions:\n\n\n*\n\n*On boot, a guest user should automatically be logged in.\n\n*Only Firefox, Chrome and OpenOffice should be available for the guest user.\n\n*The guest user should be able to write files to his/her USB stick, but never to the computer's hard drive.\n\n\nAny guidelines on how to set up something like this? Is there perhaps a remix of Ubuntu created for this exact purpose?\n\nA: *\n\n*Setting up the Guest account is pretty straight forward: System > Administration > Users and Groups Then follow this: Ubuntu StackExchange: How can user avoid entering password on bootup?\n\n*After uninstalling all the software using Applications > Ubuntu Software Center get Google Chrome from here: Google Chrome for Linux and install it.\n\n*This is really the tricky part. By default they're only allowed to download to the \"Guest\" home folder. You could change the home folders permissions or ownership to something else (baring in mind that the settings folder should remain owned by Guest. An alternative would be to have a script which re-created the Guest home folder on each login. For the USB drive reading that shouldn't be a problem as it's allowed by default.\n\n\nA: This is a summary of an email from Oslo public library, describing their setup:\n\n\n*\n\n*The public PCs run Lubuntu\n\n*They use LXLauncher\n\n*The public PCs boot off a server image (using PXE, I guess?)\n\n*They follow the Libki and koha projects closely (I do not know how/if they use them)\n\n\nThe library IT people will create a detailed description of their setup. I will edit and add links when I know more.\n\nA: This is pretty similar to what I did for some computers in our Student Center. They were WinXP machines with admin access. On a college campus. Shudder!  I'm sure they had more virii than... well, you know.\nAfter spending about 15 minutes trying to clean up the horrible mess, I decided to switch the machines to Ubuntu. At first we just had a \"student\" user that was automagically logged on, but we had some high school kids come in who had no problems standing at the computers for 3+ hours a day. So I created an .xsession script that made absolutely nothing start up except for my custom pyGTK+ script that gave them... I think it was 15 minutes, and then automatically logged them out. They could launch firefox and browse the web, but that was it. Once they closed firefox, my program would pop back up and lock the screen for 5-10 seconds (it's been a while since I've looked at it). This effectively annoys anyone who wants to stand there and just log back in, but that's about the time it takes for one user to move all their stuff, leave, and the next guy/gal to take their place.\nMarco's idea is pretty solid, though.\n\nA: You might want to have a look at these two programs: pessulus and sabayon\nEspecially sabayon is interesting, though it is a bit confusing! It can recreate a predefined session for a user at every startup, this session can then be totally restricted with pessulus. Then you just need to setup auto-login (Through the menu System>Administration>Login Screen) and you're ready to go.\n", "Q: Re-add the default top panel I accidentally deleted the default top panel in ubuntu 10.04. \nHow can I restore it without completely re-building it one panel object at a time?\n\nA: See this post. It has step by step instructions as well as a well recorded video. He provides a script that can restore your top and bottom panels. Just in case you do it again :)\n\nA: See this post. It will restore your panels back to their defaults. It doesn't discriminate in that any edits to your bottom panel will also be lost.\nOpen a terminal session by:\npressing Alt F2 > then type gnome-terminal > click on Run\nThen enter the following code:\ngconftool-2 –-recursive-unset /apps/panel # might be optional\nrm -rf ~/.gconf/apps/panel\npkill gnome-panel\n\nEdit: Updated for gconftool-2\n", "Q: How can I convert videos for my Sansa Fuze? The Sansa Fuze mp3 player can only play videos in its own special format, how can I convert videos to this format using Ubuntu?\n\nA: Use the Video4Fuze application.\n", "Q: Ubuntu and VLC - make default and hue I have recently installed VLC. I have found that when I play videos on VLC, the hue of the color of the video is off. I have to constantly readjust it. \nAlso how can I make VLC my default player for *.avi files?\n\nA: To change the hue and make it \"stick\":\n1. go to \"Tools->Preferences\"\n2. click \"Show settings->All\" (lower left corner)\n3. expand \"Video\" & click on \"Filters\"\n4. enable \"Image properties filter\" under \"Video filter module\"\n5. expand \"Filters\" & click on \"Image adjust\"\n6. set hue to your preference and press \"Save\"\n7. restart vlc\n8. ??!...\n9. profit!\nboy, i never thought i'd need to figure this one out.\nTo set VLC as default player for AVIs:\n1. On an avi file right click and go to \"Properties\" then to the \"Open With\" tab\n2. select \"VLC media player\"\n3. ...more profit!\n\nA: Find an avi file [right click] > Properties > click Open With tab and then select VLC.  This should make vlc open all avi files.\n\nA: I don't know about the problem with the Hue. But to make VLC your default player for *.avi files you can just [right-click] one > Properties > Open with tab and select VLC as the default player.\n", "Q: Firefox Middle Mouse Button Scroll How can I get the middle mouse button to behave correctly in Ubuntu? Clicking the middle button does not show the arrow which allows me to scroll the page by moving the mouse.\nInformation:\n\n\n*\n\n*Firefox 3.6.8\n\n*Mouse: Microsoft Intellimouse Explorer 3.0\n\n\nA: Edit 2022-01-28: this answer is verified with Firefox 96.0b3\nEdit 2020-11-23: this answer is verified with Firefox 62.0.3\nEdit 2018-03-14: this answer is verified with Firefox 58.02\nJust to precise, since version 57 of Firefox the path is the following: Menu ➜ Preferences ➜ General, then all the way down in the Browsing section check the box Use auto scrolling.\nYou can also just type auto in the search field once you're in the Preferences window.\nSee this screenshot:\n\n\nA: For recent versions of Firefox (version 96+) see this answer.\n\nOriginal answer\nEdit ➜ Preferences ➜ Advanced ➜ Check 'Use autoscrolling'\n\n", "Q: Common Desktop Login via Network (like AD for Windows) One of the reasons we use Windows in the office at work is Active Directory. It makes it a piece of cake to bring up a new workstation and have a new or existing user login and do their work. Once all the Applications are installed, a user can login on any workstation and have all their documents and settings available to them.\nIs there any way of doing this on Ubuntu?\nSure, there are syncing programs like Ubuntu One that sync the files (and hopefully eventually settings), but as far as I am aware it still requires each workstation the user wishes to log onto to already have their user account set. Also, any time a user changes their password it needs to be changed on each machine the user logs into.\nIt would also be useful if this applied to servers as well, so a user can SSH into a server and have the same files as on their desktop in their home directory.\nDoes this sort of ability existing in Ubuntu currently?\n\nA: You can use OpenLDAP for authentication and nfs in combination with automount for mounting their home directory to the desktop.\nAnother possibility is to use the LTSP server project to run all the application from a server and run only thin clients. Which solution is the best, depends on your particular requirements. \n\nA: Ubuntu also has the Likewise client, which is not just like Active Directory but is an Active Directory client, so you can use your Windows domain logins on Ubuntu.\n\nA: OpenLDAP or Fedora Directory Services will provide you with what your looking for. FDS gives you a nice interface by default iirc. However, this will work well for Linux, *BSD and OSX systems. As far as I know, windows systems will not by default ( ie without adding software ) Authenticate against OpenLDAP so if you have a a mixed environment you would essentially need to run 2 servers. I believe it's possible to sync openldap/fds with AD however I've never tried it. \nThe Likewise client will auth against AD directly however since AD is only really concerned with windows you will probably sacrifice some of the functionality that you would otherwise get with openldap/fds. YMMV. \n", "Q: What is the meaning of the default directories in the Linux filesystem hierachy? Having installed various Linux distros for tinkering, I'm puzzled by the installers offering partition layouts - for an easy way out I just use the whole available disk space.\nSome of the partitions offered have cryptic names, including /var, swap, /usr, and /home. The installers don't really explain these to me - what purpose do they serve, and which, if any, should be used?\n\nA: When installing, many distributions give you the options to put different directories on different partitions. For example, a lot of users choose to have the /home directory on a different partition than the rest of the installation. This is because everything in the /home directory belongs to a user--documents, videos, and all other user-specific data goes here. By putting the /home directory on a separate partition, and the actual OS files on another, if a user decides to do a fresh install of his Linux operating system, he can just rewrite the main partition and leave his /home partition (and all of his files) intact. \nThis also allows a user to install multiple Linux distributions on different partitions, all sharing the same /home partition. This way, a user can access his files no matter what Linux version he's using.\nA casual user shouldn't really have to worry too much about assigning a separate /var, swap, /usr, etc. All of these directories are part of the OS, and have little to do with the user's files.\n\nA: The brief answer about directory names: type \"man hier\" into a terminal :)\nThat's the man page for the filesystem hierarchy, which explains the general purpose of the directory names and what they hold. You can see a web version here. \nThere's also more reading on Wikipedia: \n\n\n*\n\n*http://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard\nThose links will explain everything about what partitions are called what and what they are (or were historically) used to store.\nThe answer about using seperate partitions rather than just directories in the same partition comes back to maintainability and expandability. If you've got one partition with, say, / and /home on it, Joe User can fill up his /home/joe folder, and the entire machine will run out of disk space and stop working (I'm simplifying here, but that's the general result). If you've got / and /home on different partitions, Joe User can fill up his /home/joe folder, and the /home partition will be full, but the machine will continue to operate because / is not affected.\nSo expand that principle out to almost all different directories being on different partitions, and you can see how it would be useful, particularly when a machine is running 24/7 in a multi-user and multi-service role.\n\nA: Using the whole available disk space is a perfectly valid (and probably the recommended) option for Personal computers.  Partitioning the filesystem like that is in my opinion a layover from ancient times before RAID or virtual volume management were practical in software.  \nIn UNIX-like systems the filesystem starts at the root directory '/'.  In the DOS/Windows terms that would be 'C:'\nWhile in DOS/Windows you add drives to dive letters D:, E:, etc. In UNIX-like systems you 'mount' drives into directories.  Back in the day when you had 10 or 10 megabyte hard drives you could mount various directories in different drives and partitions to give the illusion of a single large drive.  Pretty much a poor-man's RAID 0.\nThere are many reasons to partition out the various root directories but one popular idea is that since the swap and /var partitions were written to the most they have the highest chance of failing.  By separating them out into different partitions it's really easy to just add another drive from backup and re-mount it.\nAlso having a separate /home parition can be really great if you run multiple versions of linux on one machine.  (For example Ubuntu and Red Hat).  Since Unix/Linux programs place the user's settings inside his or her home directory.  This works much better in theory than in practice though.  Because you need to thoroughly understand the permissions implications.\nHere are a few important directories for UNIX-like operating systems and their explanations.\n\n\n*\n\n*/bin - Basic system executable files\n\n*/lib -  Basic system libraries (.so in Linux, .dlls in Windows).\n\n*/boot - Where you're kernel lives.  Computer wont start without this one. \n\n*/var - Directory were services can store files.  Like log files and mailboxes\n\n*/etc - System configuration files\n\n*/usr - Non-essential user applications.  (A unix-system can boot without a /usr (for recovery purposes) but it would not be very fun.  In older systems this is the same as /home.)\n\n*/home - User's home directories.  Normal users can only write to their own home directory.\n\n*swap (not a directory) This is usually a separate partition in UNIX. There is no swap directory, although you can make swap-files in Linux.\n\n\nA: You can find a very detailed description on the pages of The Linux Documentation Project: Linux Filesystem Hierarchy\n\nA: Well, swap is used a swap space. It's like a page file in Windows. It kinda supplements RAM. \n/home is used for user data like My Documents in Windows, \n/usr is where most of the programs are much like C:\\Windows, and   \n/var contains data that is changed when the system is running normally.\nAs for why the are in separate partitions I think it's mainly if your OS goes down your data does not go down with it. But I'm really not sure.\n\nA: You can make separate partitions during install. \na /home partition will mean everytime you install Ubuntu your personal user settings will remain.  \n/ - is the root.\n/var - (explained above)\n/dev - contains \"links\" to registered devices.  i.e. /dev/Video0 is a capture card...  \n/bin /sbin - contain applications\nbetter yet Wikipedia has a great page http://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard\nThe biggest thing I find is having a 2nd partition (the largest) for your stuff and like I said everytime you reinstall or upgrade.   Select that partition again and make sure you uncheck the format box and then everything is back.  Even your wallpaper!\n\nA: Historically, it's considered best-practice to have /home, swap, and other critical nodes reside in different partitions, different physical disks, or even different physical machines. Although for convenience (for better or worse), and with the advent of cheap external or cloud-based backups, everything now live in one single large partition and you just do backup of your personal things to elsewhere.\n/usr, stands for Unix System Resources\n/sbin, System Binaries\nContrary to popular beliefs, /etc does not stand for et cetera. Instead, it stands for Extended Tool Chest. But, contrary-contrary to popular beliefs, it's still a matter of debate.\nHere's some more info on those folders and how they're organized.\n\nA: The swap partition is also used for hibernation.  If you want to put your laptop or desktop in hibernation, you need a swap partition or swap file that is big enough to hold the running operating system and your open applications.\nIt is often suggested that the swap partition be the same size as your RAM memory.\n\nA: Swap should be kept separately if you use it. And use 1.5-2.0 x your ram size for it.\nThe rest can be kept together, and doesn't really matter (Linux/Unix is not windows and have single directory hierarchy, whether your /var directory is separate partition or not, it looks exactly the same). The main purpose of partitioning is to use different filesystems and to split possible \"disk full\" scenarios (so, for example, if /var fills with logs of some crazy app, /home stil works)\nAs a sidenote, I strongly recommend using LVM which allows one to create as many freely resizeable and removable partitions as one likes, and even adding new hard disks to the family. Still, it requires learning some command-line so is not for the total beginner.\n", "Q: Using Kate's terminal plugin, how can I clear the terminal's history? I want to clear all the history that I can scroll to,  so that I start with a terminal without anything in it exempt the prompt. clear only creates a clear screen, but does not delete the scroll history.\n\nA: Ctrl-Shift-x\nWorks for normal terminal and also the kate plugin :)\nOops I had originally put Ctrl-Alt... too late at night it seems\n", "Q: Ubuntu 10.04 server as a transparent proxy filter (plus dans guardian) I've installed the Server on a desktop with two network cards. \nI've installed dnsmasq, squid, shorewall, ssh, and dansguardian.\nhow do I get this device to talk to DSL modem and my network (through my router)\nI've configured the network cards to separate networks.\nI've set up the DHCP/DNC settings  (I did not install dhcp3-server, using dnsmasq).\nI've tried following these instructions as guide line.\nhttp://taksuyama.com/?p=16\nAny help would be great.  These are great devices when they work for homes with kids! \n\nA: If you already have a router hooked up to your DSL modem by way of the router's \"internet\" port, then this complicates things. Essentially you want to replace that router with a linux router that has the desired capabilities.\nSo the recommended setup would be\n(internet)=----=[dsl modem]=----=[server w/ 2 nics]=-----=[LAN port of router/wifi AP/etc]---> all of your computers\nDoing it this way should make the linked HOWTO work. You'll need to disable DHCP and UPnP on the router too, as that may interfere with your Linux's server's functioning.\n\nA: You can configure your firewall (shorewall) in such a way that all outgoing packages that represent web traffic, i.e. ports 80, 443 will be forwarded to the same host (127.0.0.1) and the port on which your dansguardian process is listening too. This way there is no direct connection for these ports to the outside anymore, but all are filtered by dansguardian.\n", "Q: Connecting PPPOE DSL modem to server? I'm setting up a transparent proxy/filter server, I've encountered many issues.\nMy Question.  With a PPPOE DSL modem how do I negotiate a connection from my server. \nI am putting the server between the modem and the router (now just a switch and wifi AP)\nThe router did the PPPOE login for me.  \nMy modem can be put into the following modes.  PPPOE on modem, PPPOE on computer(router), & bridge.  \nI thought I could connect to the modem with a static IP with my 2nd NIC with the PPPOE on the modem.  This didn't seem to work.  For example the modem's ip is 192.168.0.1 so I set a static IP of 192.168.0.2  This has worked in the past to connect and configure the modem.\nAny help would be great!\n\nA: You probably need your server up to do the pppoe authentication. Look at these instructions. I think they will help you to do this,\n\nA: Maybe you will need the pppoeconf command.\n", "Q: What is needed to use Ubuntu as a TV I wish to occasionally use my ubuntu computer as a television.  I am in the US and would like to watch over the air (HD)TV shows.  The ideal situation would be the TV show in one window with some mouse & keyboard controls for volume & channel.  I do not want or need a \"from the couch\" remote driven interface.\nWhat hardware will I need to buy?\nWhat software packages should I install?\n\nA: You might be interested in Mythbuntu which has MythTV integrated into Ubuntu. As for hardware have a look at the Requirements list. I hope this assists in your adventures for a TV Computer machine.\n\nA: You'll need a tuner card such as this one to use Ubuntu as a cable TV.\n\nA: If you are planning to use your system as IP-TV. You may want to look at http://www.boxee.tv/\n", "Q: Why will Unity have a Global Menu OS X style? Please explain to me why it was choosen,\nwas it due to ubuntu copying Mac OS X or some other factor(s)?\n\nA: Mainly to save on space since it targeted towards netbooks. Read more about the rationale here: http://www.markshuttleworth.com/archives/383\n\nA: The announcement lists reasons and design goals. It's named the Application Menu (as global menu was the name of an older project).\nFor testing plans and more technical details see this page.\n\nA: To help take advantage of the limited vertical space netbooks (and widescreen resolutions) have they are integrating the menu bar into the top panel. \nAlso with Mac OS X you have to bring focus to an application (usually by clicking it) to switch the menu to that application, but with Unity you will be running applications full screen so there is no confusion as to what application's menu you are accessing.\n", "Q: What is Ubuntu One? are there any paid subscriptions available for Ubuntu One?\nWhat additional features does it have?\n\nA: Ubuntu One is an online file hosting service. It offers 2GB of space free with an option to upgrade to 50GB of storage for $10 a month.\nWith the Free Version you can:\n\n\n*\n\n*Sync up to 2 GB of files, contacts,\nnotes, bookmarks, purchased music,\nand Gwibber broadcast messages\n\n*Automatically sync your digital life\nto your personal cloud and with all\nof your computers Mobile Contacts\nSync\n\n*Mark any directory in your home\nfolder for sync\n\n*Share folders with trusted contacts\nor publish files to the Internet with\nconvenient short URLs\n\n*Sync purchased songs from the Ubuntu\nOne Music Store\n\n*Integrated with your Ubuntu computer\n\n*Convenient web browser access to your\npersonal cloud\nWith the Paid Version you get:\n\n\n*\n\n*50 GB total of storage to sync more\nof your digital life\n\n*Keep your address book updated when\nyou're on the move with  Mobile\nContacts Sync \n\n*Mobile sync supports\nthousands of phones including\nsmartphones like iPhone and Android\n\n*Synchronize your contacts with more\napplications (like Thunderbird) and\noperating systems (Windows and OS X)\n", "Q: What does the Ubuntu Foundation do? I heard that it was some sort of emergency fund or something.\n\nA: In order to gain acceptance as a commercially supported operating system, there was the promise made that LTS (long term support) releases would be supported for 3 years on the desktop and 5 years on the server. \nBusinesses needed to know that the support behind Ubuntu provided by Canonical was not about to disappear. \nThe first LTS release was 6.06 Dapper Drake in 2006 and at that time there was some doubt that Canonical could promise this support commitment at all. \nWould they even exist in 5 years time?\nMark Shuttleworth put his money where his mouth is and put up $10M to hire Ubuntu Community Members as the Ubuntu Foundation so if Canonical disappeared as a Company the community would have the resources to continue to support the distribution.\nI am not sure what has happened since then but this public promise allowed doubts of the viability of LTS releases to be put aside and helped the adoption of Ubuntu.\nDistroWatch discussed this back at the time. \n\nA: From http://en.wikipedia.org/wiki/Ubuntu_Foundation\n\nThe Ubuntu Foundation is a purpose\n  trust founded by Mark Shuttleworth and\n  Canonical Ltd. to ensure the long-term\n  maintenance of the Ubuntu Linux\n  distribution independently of the\n  commercial activities of Canonical\n  Ltd. Its initial funding commitment is\n  $10M\n  Its current advisory board is made up\n  of chairman Mark Shuttleworth, founder\n  of Canonical Ltd., and representatives\n  of the Ubuntu Community Council and\n  the Ubuntu Technical Board.[1]\nAlthough it was originally announced\n  that the Ubuntu Foundation would\n  employ core members of the Ubuntu\n  community[2] as of 2008, the\n  Foundation remains dormant. Mark\n  Shuttleworth describes it as an\n  \"emergency fund\" in the event that\n  Canonical's involvement in the Ubuntu\n  project ends.\n\n", "Q: How are release codenames chosen? What criteria is used to select an Ubuntu release codename, and who is ultimately responsible for the decision?\n\nA: Note: this answer is primerally aimed at Why is Ubuntu 16.04 LTS Xenial Xerus? which was marked as a duplicate of this question before I could finish my answer.\nUbuntu codenames follow the form <adjective> <animal>, this started as a joke but it stuck. After Breezy they also decided to move upwards through the alphabet to make things less confusing. At the time they said they \"might skip a few letters\" but they have only actually done that once (from Breezy to Dapper). Often the first part of the codename is used on it's own (most notablly in the apt repos).\nThe adjective sometimes says things about the goals of the release. LTS releases tend to have an adjective that brings feelings of strength and stability. Earlier non-lts releases tended to use adjectives that have a more bleeding edge feel while more recent ones seem to have moved to more neutral adjectives.\nCompare:\nDapper, Hardy, Lucid, Precise, Trusty, Xenial (lts releases)\nWarty, Hoary, Breezy, Edgy, Feisty, Gutsy, Intrepid, Jaunty, Karmic, Maverick, Natty, Oneiric, Quantal, Raring, Saucy, Utopic, Vivid, Wily  (non-lts releases)\nMarks reasoning on the name Xenial Xerus can be found at http://www.markshuttleworth.com/archives/1479\n\nWhat fortunate timing that our next LTS should be X, because “xenial” means “friendly relations between hosts and guests”, and given all the amazing work going into LXD and KVM for Ubuntu OpenStack, and beyond that the interoperability of Ubuntu OpenStack with hypervisors of all sorts, it seems like a perfect fit.\nAnd Xerus, the African ground squirrels, are among the most social animals in my home country. They thrive in the desert, they live in small, agile, social groups that get along unusually well with their neighbours (for most mammals, neighbours are a source of bloody competition, for Xerus, hey, collaboration is cool). They are fast, feisty, friendly and known for their enormous… courage. That sounds just about right. With great… courage… comes great opportunity!\n\n\nA: The Ubuntu Wiki has lots of information about the naming system at https://wiki.ubuntu.com/DevelopmentCodeNames. According to Mark Shuttleworth, the \"Adjective Animal\" system started as a joke and stuck. It's Mark that announces the new names, usually on his blog at http://www.markshuttleworth.com/\n", "Q: How can I install Windows software or games? Can .exe and .msi files (Windows software) be installed in Ubuntu?\n\nA: Short answer\n.exe files are not binary-compatible with Ubuntu. There are, however, compatibility layers for Linux, such as Wine, that are capable of running .exe.\n\nDetailed answer and solutions\nThe underlying problem:\nUbuntu is a completely different system than MS Windows. Not only it looks differently, but it also uses different mechanisms for its core functions.\nThe problem with .exe files is that they are specific to Windows. No other system is capable of running them, because their contents are designed to work on a Microsoft's system. Linux uses different standards, different concepts, and therefore Ubuntu applications need to be adapted to them to work correctly.\nIf you have just migrated from Windows and are doing your baby steps with Ubuntu, you may be indeed surprised that .exe files fail to run. There may be different symptoms, either an error message may appear, or there may be no effect at all when double-clicking an .exe. This all happens, because Ubuntu has no idea what should it do to run that file. Ubuntu is not knowledgeable about how MS Windows works \"behind the curtain\", and therefore it can't execute the code that's within them. In technical jargon, one says that Windows and Linux executables are not binary-compatible.\nLooking for alternatives\nThe first thing you should do is to realise that most likely you do not want to run that .exe file. Most Windows applications you are used to have their Ubuntu alternatives in Ubuntu Software Center. \nTherefore the very first step when you try to run an .exe file is to check whether there is a Ubuntu version of the same application (like Firefox - it has both a Windows and Ubuntu edition), or a close alternative, which is not the same app, but does 99% the same stuff. For example, if you want to compose a document, instead of MS Office you will want to use LibreOffice.\nHow can I find an alternative?\nHere are some tips.\n\n\n*\n\n*Search Ubuntu Software Center.\n\n\n*\n\n*Launch the Ubuntu Software Center, type in the search box what kind of application you are looking for. For example, typing in \"photoshop\" finds The GIMP, which is a great advanced image editing tool, and is a great substitute for Adobe Photoshop.\n\n*Many Windows applications are also available for Ubuntu, and have their identical version in Ubuntu Software Center, which is the preferred way of installing software in Ubuntu.\n\n\n*Search Ask Ubuntu (this very site).\n\n\n*\n\n*There are many questions here that explain what applications can be used as substitutes. Also, do not forget to ask a question if you need software-recommendation. \n\n\n*This Ubuntu Help page contains great tips when seeking for alternatives.\n\n*http://ubuntuguide.org/wiki/Alternatives\n\n*http://alternativeto.net/\nOkay, but not all applications have alternatives. There are a number of cases where you will want to run the .exe program anyway. Examples include:\n\n\n*\n\n*You are trying to run an application of which alternative makes no sense. In case of most video games you will want to run them and not an alternative.\n\n*You may want to run the original application instead of an alternative, because the alternative is not good enough. For example, many people consider Photoshop to be a much better editor than The GIMP.\n\n*This is a very Windows-specific program, that makes little sense on Linux.\n\n\nLuckily, you can get .exe files to run on Ubuntu.\nRunning .exe files on Ubuntu with WINE\nWhat is Wine? Well, technically it's a compatibility layer. What it means is that it provides an environment similar to Windows to any .exe application you try to run. Therefore, with WINE .exe files will run on Ubuntu.\nWINE is not installed by default. You can get it either by:\n\n\n*\n\n*Searching for \"wine\" in Ubuntu Software Center.\n\n*Running the command: sudo apt-get install wine.\n\n\nDetails on installing WINE can be found in this question.\nOkay, so I installed WINE. Now what?\nProceed to launching your .exe file! Double-click it, and with a bit of luck everything will seem like on Windows. Voilà!\nWARNING: Not all applications will behave correctly when run with WINE. WINE is by no means perfect, and because it pretends to be a Windows environment instead of actually being a real one, some applications may malfunction. Common problems may include incorrectly displayed fields, fullscreen issues with video games, copy-protection problems. Some of them can be solved with litte hassle, make sure to check the WINE application database and use google to find hints in case your .exe does not work correctly.\nRunning Windows applications on Ubuntu with PlayOnLinux\nThere is another tool you may like which aids you in running Windows applications.\nIt's called PlayOnLinux (website) and it supports quite a wide range of software (browse).\nWhat it does is it runs a specific version of Wine which is known to work best with the application you are willing to run. It also installs additional paths to provide maximum compatibility with Ubuntu. But you don't need to know about that; everything is done automatically.\nBecause of that, PlayOnLinux tends to provide the best results in case of running a widely known piece of software, including many video games.\nInstalling PlayOnLinux:\n\n\n*\n\n*Find it in Ubuntu Software Center, or\n\n*Run sudo apt-get install playonlinux\nUsing PlayOnLinux:\nInstead of double-clicking the .exe (which launches it with WINE), run PlayOnLinux application. Select \"Install\" button on the toolbar, and choose what application you wish to install. PlayOnLinux will guide you through the installation process (of course you will need installation media).\nOnce it's done, your installed application will be displayed in PlayOnLinux main window. Double click to launch it!\nCommercial solutions\nIf you are not satisfied with WINE, there are some commercial softwares that runs Windows applications on Linux. One of the most well-known is CrossOver. In some cases it has significantly better results, yet it is not available for free.\n\nA: Well windows 'exe' file won't run on linux it's different breed of operating system. \nYou could install wine an then try again. Works very well in most of the cases.\nAnd give ubuntu a fair chance, you don't need Windows in most of the cases. You are just under impression that this is necessary part of computer experience.\n\n\n*\n\n*How do I install wine?\n\nA: You can if you first install the \nWine compatibility layer  from the Software Center, you can install Windows applications in Ubuntu. Be warned though that not all applications work perfectly or without glitches. Some applications are even unusable, while others work perfectly (see the Wine Application Database for a good idea of how well various programs work). see How to install and configure Wine? to help you to install this.\nOnce Wine is installed, you can simply double click an .exe or .msi file to run it. If this doesn't work for some reason, right-click the file and select \"Open With Wine Windows Program Loader\". Of course, only run executables from sources you trust to avoid Windows malware.\n\n\n\nIf you run into compatibility issues, you may wish to try the latest Wine Beta version from the ppa:ubuntu-wine/ppa software source (see What are PPAs and how do I use them?).\nYou might also consider installing Winetricks , CrossOver  or CrossOver Games  to install and use software more easily.\nTo see the debug output of Windows software (in case something goes wrong) run it from a terminal using wine msiexec /i file.msi or simply wine file.exe.\n\nA: Aside from a WINE implementation, if you've got a copy of windows laying around, you may also want to look into VirtualBox or some other virtualization technology.\nHere is link on getting setup:\nhttp://www.ubuntugeek.com/create-and-manage-virtual-machines-using-virtualbox.html\nA con in using a VM(virtual machine) is that they are generally reserved for upper end machines as they are an OS inside of your OS that takes up additional OS resources.\na pro would be that they are easier to backup and re-instate in-case of a catastrophic software failure. \nWikipedia has an article on both VirtualBox and Virtualization. I can only post one link until I get more cool points so I figured the tutorial would be a better link as it has a brief description \n\nA: Run:\nsudo apt-get install wine\n\nThen simply double click on exe\n\nA: You should try wine:\nwine msiexec /i your_msi_file.msi\n\n\nA: The Wine PPA indicated above is helpful, however I will note that you don't have to use beta packages if you're using the PPA.  The wine1.5 package will give you the latest beta package, however the wine1.4 package will keep you at the stable Wine 1.4 release and not expose you to regressions.  You can also just install the wine package for the latest stable version.\n\nA: Also, if you want to get updates from the Wine developers so that more and more Windows software is supported, go to System->Software Sources and go to the other Software tab.  Click the Add button and copy+paste this into it: ppa:ubuntu-wine/ppa\n\nA: Yes, as others have said, you can use wine to run Windows programs.\nOnce wine is installed, you can run a Windows executable by right clicking it and clicking 'open with wine Windows program loader' or using the terminal as explained above.\nYou should check here to see if/how the program can be run in wine. Lots of programs will not work perfectly or will need extra configuration to run. A program called winetricks (see http://wiki.winehq.org/winetricks) may make things a bit easier.\nAlways try to use native software or free alternatives if possible. You can search for applications in Ubuntu Software Centre - programs from here will work much better and will need little configuration. You can also look on this website: http://www.osalt.com/ for free software alternatives to proprietary products.  \n\nA: As others have said, Wine is usually the best option, but in some cases you can see better performance using Mono.  However, for the program to run under Mono, the program must be a .NET application, and even that isn't a guarantee that the program will run without some hand holding.\nTo recap, Wine is a safe bet, but Mono is installed by default in Ubuntu and can handle many simple .EXE files that are .NET applications.\n\nA: Maybe a proper error message should tell you that .exe files are specifically create to run in a Windows environment. There are plenty exciting ways to handle this situation but they all need a little time and effort to get informed and understand. If you anyways plan to use Windows which is perfectly fine because you are free to chose then it might be advisable to just wait for your Windows installation and then you can run your .exe files. \nIn case you decide differently and want to learn more about Ubuntu and how to run executable files you should know that there are\n\n\n*\n\n*different file formats to run natively in Ubuntu\n\n*may native programs in ubuntu which are very easy to install \n\n*solutions (like wine) to run even windows program in Ubuntu\n\n\nGood luck and decide carefully!\n\nA: yes by using wine.\nget it by going to the Ubuntu software center.\nhere is a link to the ppa\nhttps://launchpad.net/~ubuntu-wine/+archive/ppa\nhere is a video on how to install\nhttp://www.youtube.com/watch?v=hZgjgeDQVo4\nhere is a video on installing basic applications\nhttp://www.youtube.com/watch?v=RLRLWEfdFqY&feature=related\nand here is wine wiki which will provide you with some more information.\nhttp://wiki.winehq.org/HowTo\nif you wish to play a game from a CD you can install play on linux which is also available in the Ubuntu software center. hope this helps\n\nA: Run sudo apt-get install wine, then configure wine using winecfg command \nThis will let you right click any .exe file to open with wine loader.\n\nA: You'll first need to install the Wine Compatibility Layer, it will allow you to run Windows appliactions on Ubuntu:\n\n\n*\n\n*Open the Ubuntu Software Centre\n\n*Search for \"Wine\"\n\n*Install \"Wine Microsoft Windows Compatibility Layer\"\n\n\nNext you need to tell Ubuntu that this is a program. \n\n\n*\n\n*Right click the .exe file and select Properties\n\n*Go to Permissions and check Allow executing file as program\nNow you can run the program\n\n\n*\n\n*Right click the .exe file and select Open with Wine Windows Program Loader\nThat's all, the program should now run fine. I've tested this using various pieces of Windows software, including the Windows version of Mono.\n\nA: For applications that do not work in Wine, you can use Virtualbox by installing a Windows in the virtual machine. 3D acceleration is supported in Virtualbox.\nSee also these questions:\n\n\n*\n\n*How do I install the VirtualBox version from Oracle to install an Extension Pack?\n\n*How do I install Guest Additions in a VirtualBox VM?\n\n*Launch an application in Windows from the Ubuntu desktop\n\nA: Wine is not a perfect answer, as you will probably many compatibility problems. You might consider first checking up on your application at WineHQ.org. Platinum is the best level, then Gold, Silver, Bronze, and finally Garbage.\n\nIf you want to run games, you can try special versions of Wine like PlayOnLinux (free) or CrossOver (payed). Otherwise, common applications should work well enough with a little configuration.\n\nA: First of all an .EXE file is a Windows Executable file. In Linux and other *nix based systems we do not use .EXE as file extension for program executables. Rather we set the permission for the program to be executable by using chmod command.\nSecondly your question is too broad. Which '.EXE file' by which I assume you are trying to run a Windows Application are you trying to run? There a program called WINE which has ability to run Windows Programs to a various levels of success.\nHowever you are strongly suggested to use a native alternative app, because it will perform better and better integrate with the desktop.\n\nA: You should be aware that Ubuntu is a totally different OS to Windows. The file structures are incompatible. So .exe files are designed for Windows, not Linux. Therefore they won't work.\nHaving said that, there are some .exefiles that work well in Linux (Ubuntu) through a program called wine. The latest stable version should be in the software centre.\nMy strongest recommendation though - before installing wine - is to go to the developers website and familiarise yourself with what it can and can't do, and what windows programs are known to work with it.\nFinally, there are 1000's of apps that are designed for linux that do much the same things that windows apps do. Many are cross-platform, like VLC, Firefox to name a couple.\n", "Q: Is there a simple way to get Django 1.2.* (latest stable) installed? I want to start developing for it. I could easy_install or pip install but I'd prefer a proper repo.\nIs there a PPA that's up to date?\n\nA: Django 1.2 is included in Maverick Meerkat (still under development), but it appears that an unofficial backport of it exists in a PPA.\nI haven't tested the package, but it appears to be a simple rebuild of what's in maverick.\nAn official backport to lucid has been requested & will hopefully happen sometime soon.\n\nA: For most kinds of software packages, I agree with you that getting them from the repository is preferable. I would argue that it's different with python development related packages, though - you mostly want the latest (stable or development) version, dependency checks are figured out automatically for you. If I were you, I'd just go with using pip.\n", "Q: What is a MOTU? Also,how can I become one? \n\nA: From the launchpad page https://launchpad.net/~motu\nThe MOTU Team looks after all of the packages in Universe and Multiverse in Ubuntu.\nhttp://wiki.ubuntu.com/MOTU\nThe Masters of the Universe take care of the Ubuntu Universe packages, fix bugs, add new packages, or remove obsolete ones from the Ubuntu archive.\nIf you want to join, be sure to read https://wiki.ubuntu.com/MOTU/GettingStarted to understand what is required from you. We look forward to see you in the team soon!\n--\nAlso some more info here\nhttp://behindthecircle.org/\n", "Q: How can I create a software RAID drive and install Ubuntu Desktop on that drive? Since GParted does not support RAID, what tools can we use to create a RAID drive (0,1,5 etc) and then install Ubuntu onto that drive? Assume we are starting on fresh system with no OS.\n\nA: I am assuming you mean Linux Software RAID rather than hardware RAID.\nThe alternate CD supports installation onto a Linux Software RAID setup. Here's a link to a screencast I made showing how to do it.\nhttp://screencasts.ubuntu.com/MoS2007/10_Installing_Ubuntu_Part_2\nAlternatively you might want to try the new palimsest disk utility on the live CD as this has some options for configuring Linux Software RAID. \nIt is also possible to install on Linux Software RAID using the Live CD and the mdadm utility. Boot from the Live CD and then \"sudo apt-get install mdadm\" which is the tool required to create the RAID setup. You'll need to use fdisk (or gparted) to create the partitions and then mdadm to create the RAID array(s).\nThere are plenty of guides to using mdadm online.\n", "Q: Can I sync with my iOS4 device such as iPhone 4 and iPad? If Ubuntu can't do this natively, are there any workarounds?\n\nA: *\n\n*Open up the Synaptic Package Manager\n\n*Go to the Repositories (Under Settings)\n\n*Add this source -  ppa:pmcenery/ppa\n\n*Click Close and then click the 'Reload' button at the top left of the Synaptic Package Manager\n\n*After it's finished reloading search for - libimobiledevice1\n\n*You will see two package in the list, install both of them\n\n*Now click the 'mark all upgrades' button and click 'mark' when the popup appears then click the 'Apply' button of the Synaptic Package Manager.\n\n*The software packages will then be downloaded and installed.\n\n*Restart your computer and login back in.\n\n*The 1st time you connect you ipod/iphone/ipad with rhythmbox open it will unmount. Just close rhythmbox then disconnect and reconnect you ipod/iphone. You should now see your ipod/iphone/ipad listed under Devices in rhythmbox.\nNotes -  Always best not to have rhythmbox open before you connect your ipod/iphone/ipad\nRhythmbox is only supported, rhythmbox may say the songs are transferred but the 'Sync in Progress' is usually shown on the ipod/iphone/ipad after so just wait till you no longer see this displayed.\nFor a more detailed how to, see hee - http://forums.linuxmint.com/viewtopic.php?f=42&t=53489\n\nA: \nLucid natively supports both iPhone\n  and iPod Touch 1G, 2G, 3G and 3GS\n  models (iPad should also work) running\n  up to firmware 4.0 without the need to\n  jailbreak.\n\nIf you want to use you iPhone for USB tethering check out this blog post.\nMore information can be found at https://help.ubuntu.com/community/PortableDevices/iPhone.\n\nA: I have actually had success in syncing my iPhone 4 (iOS 4.2.8), with Rhythmbox on Ubuntu 11.04. I still however, cannot get Banshee to work (and that is by far my favorite player, it feels MUCH more polished). Read the all the steps before you begin, some steps are more than one procedure and require information to complete. Here is what I did:\n\n\n*\n\n*Installed all the libraries/applications indicated above (libmobiledevice, iFuse etc).\n\n*Then, as you are Jailbroken, Download iFile (easy) or SSH to your iphone (pain) and locate and edit  /System/Library/Lockdown/Checkpoint.xml. Find the DBVersion key, and change its value from 5 to 4. Save and reboot your iPhone. \n\n*Then, you can use this page (http://ihash.marcansoft.com/) to generate a HashInfo file for your device and manually copy it to your phone. There will be instructions on that link above, that tell you where the hashinfo file goes after you create it. Note* You will need to have your UIDID. \nIt is a PAIN to get the UIDID from your phone unless you have iTunes, obviously we are using Linux (no iTunes), BUT there is a simple command to find it on your Linux machine: in the terminal with your iPhone connected, type:   \nlsusb -v\n\nIt prints a TON of text that seems to repeat, but keep scrolling down until you see \"iSerial: (40 letters and numbers in random sequence)\" Copy that serial/uidid info into the website hashgenerator above, and copy it to itunes_control/Device as per the sites' instructions. After all is done above, open Rythmbox, and you're set!\nIf it still does not work, I can try to clarify the steps further. It was a ROYAL PAIN for me to hunt these down until it worked, but it works flawlessly in Rhythmbox. (Banshee would be better.... but beggars cant be choosers! :)\n\nA: Banshee and Rhythmbow don't work with an iPad 2 at this point. I did not try the step above though ( https://askubuntu.com/a/62479/35622 ).\nBut it is possible to copy mp3 (m4b not supported, don't know about other formats) to Good Reader with Ubuntu and play them.\nAVPlayerHD is even better ( http://itunes.apple.com/en/app/avplayerhd/id407976815?mt=8 ), this supported m4b and it is easy to copy files with file browser or via wifi.\n\nA: Here's an easy way to connect an Iphone or Ipad to Ubuntu:\n\n\n*\n\n*Open up the Synaptic Package Manager\n\n*Go to the Repositories (Under Settings)\n\n*Add this source - ppa:pmcenery/ppa\n\n*Click 'Close', and then click the 'Reload' button at the top left of the Synaptic Package Manager \n", "Q: How can I customize the gnome panels in Ubuntu NetBook edition? I'm using Ubuntu Netbook edition, and I want to change the panel's layout (remove or move applets). But all applets are \"locked\" and I have no way to change that...\nIs there a way to make them \"unlocked\" again, so I can play with it?\n\nA: The beginning of post should help you out: http://www.webupd8.org/2010/06/how-to-get-most-out-of-ubuntu-netbook.html\n", "Q: What is the Ayatana Project? What does it do?\n\nA: \nThe Ayatana Project is the collective\n  project that houses user interface,\n  design and interaction projects\n  started by Canonical.\n\nFor example they have designed:\n   * Application Indicators\n   * The Me Menu\n   * Messaging Menu\n   * Notify OSD\n   * Unity\n\nMore information: https://launchpad.net/ayatana\n", "Q: What is a paper cut? The One Hundred Paper Cuts project says it will fix 100 'paper cuts' in each release cycle. What is the definition of a paper cut?\n\nA: From the papercut website:\n\nThe One Hundred Paper Cuts project exists to work on the little\n  annoyances in Ubuntu. These bugs are normally considered too low\n  priority for the developers of the apps in question, who already have\n  more than enough to work on, and so the One Hundred Paper Cuts project\n  comes along and picks them up. In each release cycle, the project aims\n  to fix 100 of these little bugs and in doing so, give Ubuntu a layer\n  of polish that is not typically found in other Linux distros.\n\nAs for the definition of a paper cut:\n\nPut briefly, a paper cut is a trivially fixable usability bug that the average user would encounter in default installation of Ubuntu Desktop Edition.\nIf you prefer a more detailed, itemized definition, a paper cut is:\n  \n  \n*\n  \n*A bug, or an unintended problem occurring within an existing piece of\n  software,\n  \n*the presence of which makes a computer more difficult or less\n  pleasant to use,\n  \n*that is easy to fix,\n  \n*that the average user would encounter...\n  \n*in a default installation of Latest release of Ubuntu or Kubuntu, Desktop Edition. \n  \n  \n  If a potential paper cut fails to meet any of the criteria above, it is not a paper cut.\n\nAll the information on how to get involved is on the site too. \nSee One Hundred Papercuts - Ubuntu Wiki for more information.\n\nA: The definition of a paper cut\nPut briefly, a paper cut is a trivially fixable usability bug that the average user would encounter in a default application included on the Ubuntu desktop. If you prefer a more detailed, itemized definition, a paper cut is:\n\n\n*\n\n*A bug, or an unintended problem occurring within an existing piece of software,\n\n*the presence of which makes a computer more difficult or less pleasant to use,\n\n*that is easy to fix,\n\n*that the average user would encounter,\n\n*in a default application of the current Ubuntu, LTS or development release.\n\n\nIf a potential paper cut fails to meet '''any''' of the criteria above, it is '''not''' a paper cut.\nHow can I tell if a bug is easy to fix?\nA bug is easy to fix if it can be fixed by one person in one day. In practice, one or more people might work together over the course of a week to fix a paper cut, but if one competent developer cannot fix the bug in a single day, the bug cannot be considered a valid paper cut.\nMany complex bugs become trivially fixable right before they are fixed. If a bug appears too complex to be considered a paper cut at first, it may turn out to be trivially fixable if it has a working patch that could be cleaned up and merged by one person in one day.\nIt often takes a good deal of technical experience to know whether or not a bug is trivially fixable. If in doubt, send a message to the Paper Cut Ninja mailing list, or ask in #ubuntu-desktop IRC channel on Freenode, where someone will be able to point you in the right direction.\nWho is the average user?\nIf you are reading this answer, or reporting a paper cut on Launchpad, chances are that you are not the average user. To understand who the average user is, check out the following articles:\n\n\n*\n\n*Wikipedia article on Personae\n\n*What is an Average Computer User: Classic Linux User Thinking…\n\n*Five crucial things the Linux community doesn't understand about the average computer user - Part 1 and Part 2\nWhat is not a paper cut?\n\n\n*\n\n*A new feature is not a paper cut, a paper cut is a problem with an existing piece of functionality, not the addition of a new one.\n\n*The addition or removal of a package is not a paper cut. \"Replace F-Spot with Solang\" is not a paper cut, neither is \"Install simple-ccsm by default.\"\n\n*A bug that the average user encounters once or never is not a paper cut. The more times a day the average user experiences the problem, the more likely it is that it's a paper cut.\n\n*A paper cut is not merely a really annoying bug. Just because a bug is really bothersome, and has gone unfixed for years, doesn't make it a paper cut — it's probably like this because it's difficult to resolve and no one has the courage to tackle it.\n\n*Localisation issues are not paper cuts. For a bug to be a paper cut, it must affect the majority of average users and localisation issues will only affect users in that locale.\n\n*\n\n*Issues affecting any English text, such as badly worded app descriptions in the Software Centre, can be considered valid paper cuts since the English text string are used as the baseline for all localisations. If the English is wrong, then the translation will be wrong.\n\n\n\nCaveats\nWhile a paper cut does have a definition, it's not too strict. If an issue lies on the border of being a paper cut and not being one, then report it anyway and the Paper Cut Ninjas will take it from there. If it satisfies one of the criteria for not being a paper cut yet you think it should be considered, then report it anyway and the Paper Cut Ninjas will decide what to do with it.\nThe paper cut team has a very open mind. If something looks and sounds like a paper cut, it probably is.\n", "Q: Installing Netbeans 6.9 I downloaded the latest Netbeans installer (6.9) which is not yet available on 10.04. \nI tried to\n\"sudo ./netbeans-6.9-ml-linux.sh\" \n\nbut it does not install anything. I get the following messages before the installer quits silently:\nConfiguring the installer...\nSearching for JVM on the system...\nExtracting installation data...\nRunning the installer wizard...\n\n\nA: At a guess you probably need a pre-requisite the Sun JDK rather than the OpenJDK delivered by default. You'll find it in the Canonical Partner repository. Here's a blog post which talks about it:-\nhttp://www.clickonf5.org/linux/how-install-sun-java-ubuntu-1004-lts/7777\n\nA: I have experienced been some problems with the Netbeans installer not displaying properly on the Ubuntu Netbook remix.  The same problem some times happens if you have the 3D effects on your desktop (Compiz).\nYou can start netbeans using the MToolkit (or add to the start up script)\nAWT_TOOLKIT=MToolkit /usr/local/netbeans-6.5/bin/netbeans\n\nOr just turn off compiz whilst you install netbeans.  \nIf you run the netbook remix, logout and select the Gnome session before login back in again and you have the normal desktop.  You should then be able to install netbeans.\nI also had a problem with running netbeans under the netbook remix, having to either unmaximise netbeans or run in full screen.\nHave a look at the community information for Netbeans on Ubuntu.\n\nA: Its not clear which symbolic link you replaced, but if you have more than one java virtual machine installed, its recommended to manage them with the alternatives system in Ubuntu (debian).\nTo see the list of installed java virtual machines on you system, run the command:\nsudo update-java-alternatives -l\n\nTo set the sun java virtual machine to the be the one used, then use the command:  \nsudo update-java-alternatives -s java-6-sun \n\nChanging symbolic links could cause you problems if there is a package update and the link get reinstated by the package manager.\nHave a look at the Java on Ubuntu page for more details.\n\nA: Check for any \"netbeans\" folder in /usr/local. It might the launcher which is not correctly created.\nIf you have updated openjdk6 to openjdk7 then revert back to openjdk6.\nCheck whether you have the correct java path variable association. I use java and javac on terminal to check java installation. Just open terminal and type javac and hit enter. If there is some problem nothing will show up.\n", "Q: Reinstall Ubuntu with encrypted home directory? I have Ubuntu 10.04 installed with encrypted home directory. /home is on a a separate partition. Can I just boot from a 10.10 CD, reformat / and install as usual? Should it work if I use the same password? Is there anything else to keep in mind?\n\nA: You should take a note of your mount passphrase. This is covered on the page\nhttps://help.ubuntu.com/community/EncryptedPrivateDirectory - \"Recovering Your Mount Passphrase\"\n\nA: It will work as long as you use the same username and password.  \nActually you won't need the passphrase, just the password that will be asked when you first login after the installation.\n\nA: I have previously done this on Ubuntu and Mandriva. \nThis will work and you will be able to mount your existing /home partition even if it is encrypted as long as you know the passphrase.\nThing to keep in mind is to set up the mount points correctly and don't accidentally format your /home partition.\n", "Q: Who is SABDFL? What does he do? what is the meaning of SABDFL?\n\nA: Self-Appointed Benevolent Dictator for Life\nWikipedia:\n\nBenevolent Dictator For Life or BDFL is a title given to a small\n  number of open source software development leaders.\n\n\nA: SABDFL stands for Self Appointed Benevolent Dictator For Life, and is the nickname and IRC nick of Mark Shuttleworth, the guy who started the Ubuntu project.\nhttp://en.wikipedia.org/wiki/SABDFL\n", "Q: How to make a window transparent in Gnome? I'm working with many GIS applications under Gnome. It sometimes is very convenient to place one map over another to quickly spot differences.\nThere used to be a KDE trick to make any window (not just a terminal!) transparent, thereby allowing me to make one map semi-transparent and place it on the window of the other mapping software. Is there a similar trick for Gnome?\n\nA: I am not sure about Gnomw itself, but in Compiz, there is a plugin called \"Opacity, Brightness and Saturation adjustments\", which allows you control transparency of windows any way I can imagine, including Alt + {sroll} as Andrea Lazzarotto said.\n\nA: For newer versions of Gnome (Gnome 3/Gnome Shell), you can use this extension to make windows transparent:\n\nEDIT: To install in Gnome 3.14+\nGnome extensions have a file containing which version of Gnome they are compatible with - this is not always correct as the extension may work for other versions not specified in the file, so you need to get the extension from outside the gnome extension site, and modify the file and install it manually - this works a lot of the time with other extensions.\n\n\n*\n\n*Go the the extension page, and download the extension zip file.\n\n*Extract it, and modify the shell-version line in the /transparentwindows-master/transparentwindows@ellen/metadata.json file to make sure it includes your shell version (e.g. 3.14):\n \"shell-version\": [\"3.10\", \"3.12\", \"3.14\"], \n\nYou can find your shell version if needed using gnome-shell --version\n\n*Move the extracted files to ~/.local/share/gnome-shell/extensions, so it looks like this:\n\n\n*The extension should now work, though you may need to restart the shell with Alt+F2+r+Enter, and enable it in Gnome Tweak Tool or similar.\n\n\nAlso note that you can do a issue/bug report to the developer to ask for the extension the Gnome Extension site to be updated - in this case there is one here. You can also make your own commit to the extension to include 3.14+ versions.\n\nA: Gnome extensions are OK, but if someone want use opacity/transparency occasionally - it is better use xprop command.\nRun:\nxprop -format _NET_WM_WINDOW_OPACITY 32c -set _NET_WM_WINDOW_OPACITY 0x7FFFFFFF\n\nand then click on window to set it to 50% opacity.\n\n\n*\n\n*0x7FFFFFFF - 50% opacity\n\n*0xFFFFFFFF - 100% opacity\n\n\nSet opacity via providing window id (obtained from xwininfo):\nxprop -id 0x3a00006 -format _NET_WM_WINDOW_OPACITY 32c -set _NET_WM_WINDOW_OPACITY 0x7FFFFFFF\n\n\nA: Hold down the Alt key and then scroll with your mouse wheel.\n", "Q: Stop Gwibber and Empathy from scrolling to new messages Gwibber and Empathy constantly scrolls to a new message as soon as they arrive, making it hard to read older messages, especially on IRC.\nIs there a way to tell Gwibber and Empathy to not jump to a new message as soon as it arrives?\n\nA: There's a bug ( https://bugs.launchpad.net/gwibber/+bug/327172 ) filed for this, but it has since been fixed. Updated packages should arrive soon!\n", "Q: Sound, stopping between multiple programs I fiddled about with pulseaudio, I think in my config files. Now i can't play 2 things one after each other from 1 window ton another. E.g. on Rhythmbox when i listen to a song then switch to youtube, youtube won't have any sound, and when i do it the otherway round rhythmbox won't play at all, its playback slider doesn't move.\n\nA: You can reset your PulseAudio settings following the point 1 of part A of this guide.\nhttp://ubuntuforums.org/showthread.php?t=789578\n", "Q: What is btrfs? What advanced features does it have? I heard that Kernel 2.6.35 will have btrfs and that Ubuntu 10.10 could have btrfs by default.\nWhat will be its features?\nWill I be able to migrate my data from my current ext4 partition?\n\nA: \n  \n*\n  \n*Online volume growth and shrinking\n  \n*Online block device addition and removal\n  \n*Online defragmentation\n  \n*Online balancing (movement of objects between block devices to balance load)\n  \n*Transparent compression (currently zlib)\n  \n*Subvolumes (separately-mountable filesystem roots)\n  \n*Snapshots (writeable, copy-on-write copies of subvolumes)\n  \n*File cloning (copy-on-write on individual files, or byte ranges thereof)\n  \n*Object-level (RAID1-like) mirroring, (RAID0-like) striping\n  \n*Checksums on data and metadata (currently CRC-32C[13])\n  \n*In-place conversion (with rollback) from ext3/4 to Btrfs[14]\n  \n*File system seeding[15] (Btrfs on read-only storage used as a copy-on-write backing for a writeable Btrfs)\n  \n*User-defined transactions\n  \n*Block discard support (reclaims space on some virtualization setups or improves wear leveling on SSDs by notifying the underlying device that storage is no longer in use)\n  \n  \n  Planned features include:\n  \n  \n*\n  \n*Object-level (RAID5-like and RAID6-like) parity-based striping\n  \n*Online and offline filesystem check\n  \n*Incremental dumps\n  \n*Data deduplication1\n\nFrom Wikipedia\nI'm sorry i can't answer your other questions as i don't know much about it.\n\nA: btrfs or Butter FS is a filesystem and has some interesting features:\n\n\n*\n\n*You can have snapshots. It is like a freeze of the filesystem at some point of time.\n\n*btrfs is a extent-based filesystem. This means there are no lists of pointers. btrfs tracks contiguous blocks, so called extents, together.\n\n*btrfs makes checksums of data and metadata. Therefore it can detect errors in the filesystem in \"realtime\".\n\n*You can switch from ext3/4 to btrfs.\n\n\nA: Btrfs has and plans a number of rock star features:\nhttp://en.wikipedia.org/wiki/Btrfs#Features\nThese are mostly the features that ZFS has. ZFS is native to Sun's Solaris and OpenIndiana. ZFS can be used with Linux, but ZFS can't be distributed with Linux. There are licensing issues. ZFS on Ubuntu can be obtained through the Ubuntu ZFS PPA. (Here's some information about PPA safety.) ZFS's licensing issues are one of the reasons users may prefer to use btrfs.\nOn big feature of btrfs is deduplication. That means that any data repetitions on your system will be stored only once no matter how many times you repeat it. So you can make 100 copies of a large folder (say 1 TB) and make small modifications to each one but the amount of disk occupied will still be around 1 TB. This is useful for things like running a local cloud with 100s of VMs. The filesystems of all the VMs are mostly the same data with some minor differences. So would need only 1 unit of disk space instead of 100s of units.\nDeduplication is still a planned feature in Btrfs.\n", "Q: How can I manage saved complete web pages and their directories (e.g n.html and n_files) in Nautilus Using an arbitrary web browser, e.g. firefox, you can save a web page (complete web page),  for which it saves the html file, say n.html, and web page elements in a corresponding directory, n_files.\nIn Win7, if you copy, move, rename either the folder of the html file, they are modified as a single unit.  However, Nautilus (the default Gnome file manager), does not do this.\nIs there a Nautilus script available to enable this functionality?  Is there an alternative way to achieve the same thing?\n\nA: You can download the entire thing using wget.\nwget -r --level=0 --convert-links --page-requisites --no-parent http://url.com\n\n-r means it's recursive\n--level=0 means it goes down an infinite amount of levels (so http://url.com/pictures/babes/pics.html will be saved, not just the top level page)\n--convert-links means it converts the links from <a href=\"http://url.com/page.html\">link</a> to <a href=\"page.html\">link</a>\n--page-requisites means it downloads everything that's required to display the page properly. Like images, javascripts, etc.\n--no-parent means it doesn't download pages that are \"higher up\". So if you want http://url.com/graphics/index.html and \"below\", http://url.com/index.html won't be downloaded.\n\nA: I suppose the renaming functionality in Explorer is based on special attributes in the filesystem that Explorer recognises (that's how most of such functionality in explorer works).  It would be possible to implement something similar in GNOME / Nautilus (provided you're using a filesystem that supports extended attributes), but AFAIK it doesn't exist currently.\nAnother possibility would be to write a nautilus plugin that uses some heuristics to detect such html file + corresponding directory and do what you want, but again I don't know of an existing solution (it's also not trivial to implement correctly).\n\nI suggest using the UnMHT addon for Firefox to save the page in one file (maybe there is something similar for other browsers too).\nUnlike the Mozilla Archive Format (aka MAF), MHT (aka MHTML) is standardized in an official specification (RFC2557) and it is also supported by IE and other applications, which makes it more future-proof.  There are also MHT-viewing plugins for Opera & Safari.\nhttp://www.unmht.org/en_index.html (Firefox extension + viewers for Opera, Safari & QuickLook)\nThe Firefox addon is also on Mozilla's addon-site.\n\nA: There's a firefox extension for saving a web page and all it's supporting stuff in a single file: Mozilla Archive Format (with Faithful Save) .\nI haven't used it personally, but it sounds like what you want.\n", "Q: Refresh thumbnails in nautilus How does one refresh thumbnails in nautilus? In my videos folder I have some MKVs and only half of them have the movie border and a excerpt from the movie and the others (also MKVs encoded in the same way) just have the ordinary film icon.\n(F5 doesnt do it.)\n\nA: Easily force reloading the thumbnails by simply touching the file(s).\ntouch *\n\nMake sure you cd to the folder first.\nIf you want more control on what you touch (eheh), just update the glob to taste, e.g. *.mkv.\nNo need to put your hands in automated configuration folders.  \nThe problem often happens because the thumbnail manager is called as soon as the file is created, often fast enough that it is not completed yet. When creating (encoding videos, creating plots, merging documents, etc.) large files, the thumbnail manager may (try to) create the thumbnail (and fail) before the file is complete.\nThe command touch updates the 'last edit' time. The thumbnail manager finds the thumbnail to be obsolete (you 'edited' the file since it was last taken) and updates it.\nEXTRA: if you happen to need more control on the files (e.g. include subfolders, file patterns, etc.), you can use something like this:\nfind . -name '*finished*.mkv' | while read f; do touch \"$f\"; done\n\n\nA: do do not need to killall nautilus...  after running rm -R ~/.thumbnails/fail simply pressing F5 while the desired nautilus window is active to force a reload.. otherwise it will reload next time you access said folder...\nif its something your doing often... you can have it run automatically via cron https://help.ubuntu.com/community/CronHowto\n\nA: Updated for 14.04 LTS (or later)\nFrom 12.10 onward, thumbnails are stored at ~/.cache/thumbnails\nCorrected commands:\nrm -r ~/.cache/thumbnails\n\nThen either restart, or:\nkillall nautilus\n\n\nOriginal answer: (for 12.04, and earlier)\nHere the commands:\nrm -r  ~/.thumbnails\nkillall nautilus\n\n\nA: Use this CLI script to quickly either overwrite or generate (in parallel) a large number of thumbnails. \nusage: thumbnails.py [-h] [--overwrite] [--dotfiles] paths [paths ...]\n\nA tool for generating Gnome thumbnails in parallel.\n\npositional arguments:\n  paths        The path(s) to thumbnail (typically one or more folders)\n\noptional arguments:\n  -h, --help   show this help message and exit\n  --overwrite  Overwrite existing thumbnails.\n  --dotfiles   Don't ignore directories prefixed with '.'\n\nIf I get 10 votes, I will make this an apt-packaged utility.\n\nA: easier way just delete the failed to cache icons by deleting the following directory.\nIt will make nautilus to refresh only those thumbnails which currently have folder like thumbnail. It will not help if you want to refresh for file/folder which currently have any thumbnail. \nMost of the time you should delete this then deleting all the thumbnails.\n~/.thumbnails/fail\n\nA: There is a hidden directory in your home called .thumbnails.\nIf you delete a file (or all) there, its thumbnail will be recreated by nautilus the next time that you visit the dir where it's stored.\nI don't know if there is some more convenient way.\nEdit: Nautilus will store the thumbnails in memory. You will need to close and start again Nautilus to force it to recreate them.\n\nA: On 14.04 and beyond\nIf this happens to you often you can automate the process on login by editing your ~/.profile file with your favorite editor and adding the following code to the bottom of the file.\n# dump failed thumbnails\necho tag > /home/\"$USER\"/.cache/thumbnails/fail/gnome-thumbnail-factory/tag\nif [ -d /home/\"$USER\"/.cache/thumbnails/fail/gnome-thumbnail-factory ] ; then\nrm /home/\"$USER\"/.cache/thumbnails/fail/gnome-thumbnail-factory/*\n\nThe echo line is only there so that something exists in the failed thumbnail directory to avoid reporting an error at login.\nThe next 2 lines just check for the existence of the failed thumbnail directory\nand if it exists, deletes the entire contents of that directory.\nSources:\nhttps://www.gnu.org/software/bash/manual/html_node/Bash-Startup-Files.html#Bash-Startup-Files\nhttps://askubuntu.com/a/795098/225694 \nhttps://askubuntu.com/a/20122/225694\nHow to regenerate a specific thumbnail in Nautilus?\ntesting\n", "Q: Using SquashFS to edit a Live CD? I've been messing around with Ubuntu Customization Kit recently and I would like to create my own bash scripts to customize Ubuntu ISOs. How would I use SquashFS to edit mount and edit the iso?\n\nA: A three-part Paranoid Penguin series in Linux Journal entitled Customizing Linux Live CDs will probably be helpful.\nIt explains how to tinker with a live CD's SquashFS for the purpose of improving security. But I'm sure the instructions can be used to make other modifications as well.\n\nA: I'm not sure about SquashFS, but you could use ISO Master (available from the ubuntu software centre) to edit ISO images.\n\nA: You cannot use squashfs to edit a filesystem.  Squashfs is a filesystem and also the program that creates and extracts a filesystem.  If you want to customize your live CD, check out:\n\n\n*\n\n*https://help.ubuntu.com/community/LiveCDCustomizationFromScratch\n\n*https://help.ubuntu.com/community/LiveCDCustomization\nYou can mount a squashfs filesystem, but you cannot edit it.  Squashfs is a readonly filesystem, so to edit it you will need to extract it first.\n", "Q: How do I install the Google Wave server software? Now that the news is all around that Google will stop Wave development, and I like to keep using it, I was wondering how I can install their software. For example, is there a .deb package?\n\nA: DJango version? http://code.google.com/p/pygowave-server/\nJava: code.google.com/p/wave-protocol/wiki/Installation\n\nA: There seems to be some progress being made by the Google Team towards \"Wave in a Box\". The latest seems to be : https://groups.google.com/group/wave-protocol/browse_thread/thread/99434acbce5d807d\n", "Q: What are the pros and cons of the repository system concept used in Ubuntu (et al)? How is it better than Windows and Mac system of downloading and installing applications from the Web?\n\nA: First of all there isn't really one \"linux repository system\". Each linux distribution decides for itself which package management system to use (or whether to use one at all) and, usually, has its own repositories.\nUbuntu uses the dpkg/apt package management system from debian with Ubuntu's own repositories. How this works is basically: For each application that you can install through apt, there's a dpkg-package which is basically a zipped archive containing the application's files (with the executables compiled for Ubuntu) and some metadata, which (among other things) contain a description of the package and the package's dependencies so the package manager knows which other packages need to be installed before this one can be installed (e.g. a game might need opengl and SDL to be installed, a gnome-application would obviously need gnome to be installed etc.).\nNow a repository is a place where packages for a specific Ubuntu version are uploaded by Ubuntu's package maintainers. Apt then browses the available repositories, to find the package you want to install and its dependencies, download them and install them.\nThis is better than downloading everything yourself because a) you don't have to download everything yourself b) you don't have to hunt all through the web to find all the dependencies and c) you don't get situations like in Windows where each game installs its own version of DirectX.\n\nA: Perhaps a better question would be:  what's the difference between x and y package managers? \nA Mac OS package manager:Darwinports\nWindows package manager: Windows_update\nMore and more the move is towards repo's and away from downloading from webpages, and you're asking \"why?\".  Really, the best way to look at this stuff is to read what's already written:\n\"Impact\nIan Murdock has commented that package management is \"the single biggest advancement Linux has brought to the industry\", that it blurs the boundaries between operating system and applications, and that it makes it \"easier to push new innovations [...] into the marketplace and [...] evolve the OS\".[1]\"\n-wikipedia, package management\nReliability is, I would argue, is the primary benefit from package management, with the added plus of increased security.  It also happens to be quite easy to surf on over to http://packages.ubuntu.com and see, literally, every single supported piece of software.  You can expect that, so long as you play within the box of the package manager, things will auto-magically work and be secure.  With the standard caveat emptor proviso, of course.  If it really worked perfectly there'd be no need for mailing lists.  \nCompare that to \"fixing\" the registry, or maintenance like that when there's no package manager.  On the mac, it's quite notable that there's no \"official\" package manager for third party software, however, my reading of wikipedia is that Mac OS utilities are in a package manager of some sort, although I don't know the name of it.\n\nA: There are good things and bad things about installing software from one central repository.\nGood:\n\n\n*\n\n*It's all in one place, so you know where to look.\n\n*It enables really easy catalogue-type applications (e.g. aptitude, synaptic)\n\n*Good distros maintain their repos fairly strictly, so there's a fair bit of quality control, meaning you can trust the software from the repo more than from untrusted sources\n\n*It enables you to do some very fancy auto-resolving of software dependencies (well, allows you to do it more easily at least)\n\n*Single source of updates - you don't have to check each individual app (or app's website) for updates, they all come via one place\n\n*It allows mirroring of all the known-good software for an OS to different servers around the world (e.g. the place I work maintains a Ubuntu repo mirror)\n\n\nBad:\n\n\n*\n\n*It's not as easy to install from other sources outside the repo\n\n*It's very geared towards open-source software, rather than proprietary\n\n*It feels restrictive; if you're not in the repo, you're not on the radar (even though, yes, you can still install software from outside the repo, it's so much harder that not a lot of people bother)\n\n\nOverall, the Pros outweigh the Cons for most linux distros (in fact, probably most unixes), which is why it's used a lot in the unix world. Used in a lot of different ways too; ubuntu's deb/apt repositories, fedora/redhat/others rpm/yum repos, *bsd's ports tree, gentoo's portage, pkgsrc, the list goes on. Some of them do a better job than others :)\n", "Q: Wondering how to get OEM Config to work with my custom distro I'm not sure how to get the OEM install mode working with my Ubuntu remaster. I'm using Remastersys to make the remastered Ubuntu 10.04 distro and I don't know how to make sure OEMs can use it. I have tried running sudo oem-config-prepare after installing the remaster (with oem-config, oem-config-gtk, oem-config-remaster and oem-config-debconf installed from Synaptic) in a new account called \"oem\" with the password also \"oem\". It tells me that I have to restart to show the system setup. So I did that, but it would not start into it. I pressed the Escape key at Plymouth to view the bootup in verbose mode and it told me this:\nTraceback (most recent call last):\nFile \"/usr/bin/ubiquity-dm\", line 476, in <module>\n  dm = DM(vt, display, username)\nFile \"/usr/bin/ubiquity-dm\", line 78, in __init__\n  self.uid, self.gid = pwd.getpwnam(self.username)[2:4]\nKeyError: 'getpwnam(): name not found: live'\n\nmultiple times and that I could make a new account from the boot prompt. I attempted to do this but it was choppy and my key presses didn't appear to do anything until I pressed Enter when it displayed only some of the key presses so setting up an account from the boot prompt was futile. I have also tried setting the live username to \"oem\" but the regular 7-step, non-oem installer shows up when I run Ubiquity.\nI really need this to work as soon as possible!\nThanks in advance!\n\nA: That error reported looks like It's not created the user 'live' and that user has no password. Did you configure your install scripts correctly? Or did you edit the usernames correctly?\n\nA: Old thread, buy I have the same question. This has been answered here: http://ubuntuforums.org/showpost.php?p=9893658&postcount=2, apparently all you have to do is specify the user as oem in Remastersys.\n", "Q: Why is Ubuntu more secure than Windows or Mac OS X? Please give some solid reasons.\n\nLinked Question\n\n\n*\n\n*How safe is Ubuntu?\n\nA: There has been a lot of debate over whether a open environment is intrinsically more secure than a closed environment. The problem being that when we compare the security of Windows with Linux the argument is always trotted out that because Windows has such a market domination, that the attackers target Windows and if Linux had the same level of usage then it would be found just as vulnerable.\nThe key point to take here is that it is the mono-culture that is really at fault. One of the key advantages of Linux is that there are a plethora of different distributions, while an attack may be exploited across a number of different distributions rarely will it affect all. We can see this from the vulnerability reports that are reported, in that even if a widely used application or library is found to be vulnerable that exposure is usually limited because of configuration options to only a few distributions. The same doesn't seem to apply to the Windows family as the configuration of librarys and applications are the same across variants.\n\nA: The answer is easy and for sure Ubuntu is much safer than Windows and also Mac OS. \n\n\n*\n\n*Windows users are often working as root, although it is not recommended by MS since a long time they make/made it possible and lazy users say proudly this is a big advantage \n\n*Sudo: for installation or system changes you need to enter a password not just say yes as in Vista or Win7. Users tend to just click yes without reading\n\n*Kernel build in firewall in Linux in Windows one has to install some crappy personal firewalls\n\n*In former and still widely used Windows versions most ports are open in default for convenience reasons, in Ubuntu they are mostly closed in default\n\n*In Ubuntu one is installing signed software using the package management, in Win or Mac one is downloading unsafely from internet.\n\n*In Ubuntu mostly required software is already pre-installed, in Windows one has to unsafely download even the basic graphics drivers! \n\n*Without additional software the home folder can be encrypted in Ubuntu also Ubuntu has a guest mode if another person is using it\n\n*SSH for maintenance in Ubuntu\n\n*Open Source: everybody has access to the source code in Ubuntu and can complain if there is a security threat\n\n*Windows is just to complex and opens security gaps everywhere, although MS employs a lot of security staff the cannot keep it secure\n\n*Windows comes mostly installed with third party bloadware which are a security threat\n\n*Windows updates are just crap, every fresh install of Windows is a big security threat until it is patched up to date. Unfortunately this update process takes several day while windows in unprotected!\n\n*Since updates are crap in Windows most often users are not updating at all which is even a bigger security threat. In Ubuntu updating takes just a few minutes and one is updating always to the newest \n\n*Ubuntu fixes security relevant bugs much quicker than Windows. Mac OS is know to fix it in half year cycles.\n\n*In Windows in default users are using unsafe and old MS IE\n\n\nConclusion: Windows is completely unsafe since it has unchangeable architectural issues and Microsoft's politic to always let the users bypass all security attempts due to \"convenience for the users\" reasons. Also it is most widely used OS and so it is well exploited by criminals. It is a easy target for them. \nMac OS is much safer but Apple is keeping all issues in secret and tends to fix issues quite late, much later than even MS. Just because its low market share is is not such an attractive target. \nMost safe is a Linux like Ubuntu. But keep in mind if someone really wants to hack your computer it is still possible. Maybe just harder. If someone has physical access to your computer it is still quite easy. So even if using Ubuntu you are still not safe from secret service, competing companies, employers and \"friends\". \nThe biggest security threat is still the user. The tendency to download some hacked software from internet, to click links in emails, ...\nAnd furthermore most users even don't see a problem having male-ware on their computer. Nowadays male-ware is not like old time viruses breaking ones system. And as long as users still can use their computers for surfing, chatting and facebook they just don't care if it is used in a bot net. \n\nA: *\n\n*Windows has had a single-user ethos for a very long time. Even with the invention of NT and a role/privilege system, default installs would plonk users as king of the hill. Their account (and, more importantly, anything running as their account) could do anything to any file without a check.\nThis is huge because any application, any exploit in an application could run as Administrator. \nIt's only since Vista where that's trying to be reversed and tightened with things like UAC...\n\n*Source access is a double-edged sword. Open source enthusiasts usually tout security but it does also let people right into the system. They don't have to report anything they find, they could just write exploits for the hole.\nThankfully, most people do report any flaws they find. Even better is they sometimes include patches that can be immediately tested and distributed. \nThe turnaround for patching security holes does seem shorter than closed source software.\n\n*There are just fewer of us.\nSounds bleak but there are fewer people using one particular open source application. It's hard to justify writing an exploit, trojan, worm, etc when you could write one for Windows in the same time and catch a lot more people.\nBut we can't be complacent. There's no reason why a trojan or worm can't work in Linux. A malicious app running as a limited user can still do a whole load of damage. And the real flaw in all of this is the users.\nUsers are idiots who can be convinced to do almost anything if you dress it up with enough pomp or make it look like they're going to get something worthwhile from the process.\nRead: Linux isn't invulnerable. Don't say it is. (Disclaimer: my post, my blog)\n\nA: A chain is only as strong as its weakest link or a chain is as secure as its unsafest link. The user is the weakest link, not the OS. Linux-people do know what a computer is, do have a notion of computer-security. Most people don't. Give them any computer, it will be infected in no time, Windows, Mac Os-X, Linux, ...\n\nA: IMHO:\n\n\n*\n\n*Windows was designed, back in the day, as a single-user system. Linux, on the other hand, was built with a multi-user architecture.\n\n*In Linux, all your system files are owned by root. They're locked down and can not be edited by the casual user. Windows gives free range to the system files.\n\n*Windows UAC is the current implementation to restrict access to these system files and settings, it's a patch to try resolve a fundamental design flaw. Linux has this security built in from the ground up, making it more reliable and tightly integrated into the user experience.\n\n*It is Open Source, which means the code can be looked over by anyone (mostly developers). This is Linus' Law, which states that \"given enough eyeballs, all bugs are shallow\".\n\n*A default Linux install is locked down: only essential services start. Windows used to have many exploitable services running (but they've tightened up on that front a bit). \nWe can't judge just on OS alone, plenty of security flaws relate to bad user practices, social engineering and just plain ignorance. A chain is only as strong as it's weakest link.\nAlso, regardless of OS, no system is secure if you have physical access to it ;) \n\nA: More secure than Windows: \n\n\n*\n\n*Privileges\n\n*Social Engineering\n\n*The Monoculture Effect\n\n*Audience Size\n\n*Number of  \"Eyeballs\"\nFor more explanation about the above points please refer pcworld.com/why_linux_is_more_secure_than_windows\n\nA: To make a generic point; Mac OS-X is partly open source. The closed source parts are, unsurprisingly, the most attacked bits by Mac Virii. Make of that what you will. \n", "Q: What is ubiquity? Where is Ubiquity used in Ubuntu?\n\nA: Its the wizard  you see that installs ubuntu. It also handles the slideshow in the package 'ubiquity-slideshow' which Is made from HTML files. :D\n\nA: It is the installer program.\n\nA: There is a Ubiquity Firefox Extension, the project is halted by Mozilla Labs right now.\nIt is like a Gnome-Do for Firefox.\n", "Q: What is Kernel Mode Setting? What happens when KMS fails?\n\nA: Mode setting is basically setting up the screen resolution and the depth mode for the graphics card. \nFrom Wikipedia:\n\nMode-setting can be done in kernel space or in user space. Doing mode-setting in kernel-space is more flexible. Doing kernel-based mode-setting allows displaying an error in the case of a fatal error in the kernel, even when using a user-space display server. User-space mode-setting would have needed superuser privileges for direct hardware access. So kernel-based mode-setting increases security because the user-space graphics server does not need superuser privileges.\n\nFrom Ubuntu Wiki on Kernel Mode Setting:\n\nKernel mode-setting (KMS) shifts responsibility for selecting and setting up the graphics mode from X.org to the kernel. When X.org is started, it then detects and uses the mode without any further mode changes. This promises to make booting faster, more graphical, and less flickery.\n\nIf KMS were to fail, I would think that X would do its own modesetting; instead of having the kernel do it. But that might require you to first disable KMS. More information specifically for different graphics gards can be found on the Ubuntu Wiki article I linked to eariler.\n", "Q: How do I encrypt my home partition? With Ubuntu 9.10 I did not have any encrypted partitions set up, I have since installed a fresh Ubuntu 10.04. \nI have 3 partitions: OS root (/), home and swap. How do I enable encryption on my existing /home partition?\n\nA: Ubuntu Help: Encrypted Home points to this article here: Migrating to an Encrypted Home Directory which was written about a year ago. Though this article actually appears to still be valid in how to approach this.\nYou won't be encrypting the entire /home partition but rather each individual home folder. In future user setups you can pass the --encrypt-home flag on the useradd command. (adduser --encrypt-home new-user-name)\n", "Q: How can one get more than 12 commands in Compiz->Commands? How can one get more than 12 comands in Compiz->Comands?\nIt's mainly for screen bindings.\n\nA: System > Preferences > Keyboard Shortcuts\nThat allows you to add conceivably an infinite amount of key bindings.\n\nA: I don't know if Compiz will accept this, but these settings are stored in gconf.\ngconf-editor\n\nRun that, then navigate to /apps/compiz/plugins/commands/allscreens/options/\nTry right-click -> New Key\nName it command12 and make it of type string  For value, put the command you want to run\nAdd keys named\n\n\n*\n\n*run_command12_button\n\n*run_command12_edge\n\n*run_command12_key\nAlso of type string\n\nFor edge, you can set any of the following:\n\n\n*\n\n*TopLeft\n\n*Top\n\n*TopRight\n\n*Left\n\n*Right\n\n*BottomLeft\n\n*BottomRight\n\n*Bottom\n\n\nIf you want it to make it able to activate on top or bottom, put it like Top|Bottom\n\nFor button, if you want it to activate when you left click on the top edge, that'd look like <TopEdge>Button1 or if you wanted it to be for Ctrl+Alt+Click, that'd be <Control><Alt>Button1\nExtrapolate from there\n\nFor key, you're probably getting the pattern.  <Super>Q to make it Win+Q, etc.\n\nI have no evidence that Compiz will read past command11, but if it just reads everything in that part of GConf, then this could work.\n", "Q: What is Upstart? Which operating systems besides Ubuntu use it?\n\nA: Upstart is an event-based replacement for the /sbin/init daemon which handles starting of tasks and services during boot, stopping them during shutdown and supervising them while the system is running.\nThe SysV boot process is strictly synchronous. Things happen one at a time, blocking future tasks until the current one has completed. If anything in the boot process takes a long time, everything else has to wait. Additionally tasks only run when the init daemon changes state (such as when the machine is powered on or off).\nUpstart is a new init daemon that allows services to be started in response to events rather than in bulk runlevels. With each job file in the /etc/init directory being responsible for launching a service or for a specific component of system initialisation. There is no fixed sequence; instead each job specifies the events to which it will react. When an event occurs, Upstart starts all jobs that have been waiting for this event, in parallel.\nYou can theoretically use it even after the system is up and running. Upstart is eventually slated to take over tasks such as or plugging in external devices like thumb drives (currently handled by udev and hal), or running programs at specific times (currently handled by cron). \nUpstart was originally developed for the Ubuntu distribution, but is intended to be suitable for deployment in all Linux distributions as a replacement for the venerable System-V init.\n\nA: Upstart is a modern init replacement and is event driven.\nCurrent users are Ubuntu, Fedora, OpenSUSE, Maemo, Palm's WebOS.\n\nA: Upstart is the replacement for the traditional init.d style System-V bootup scripts. However, upstart is more than just a collection of bootup scripts. It allows in fact a minute planning and control of the start of different daemons. For instance, in order to automount network drives, you need first a working network. While before upstart these situations often led to race conditions, in the upstart declaration the prerequisite of a running network can be included. \nUpstart is in fact based on an event monitoring system. When a certain hardware condition occurs, or another process sends an event, one or more of upstarts scripts might be triggered. This allows i.e. particular actions being automatically triggered when an usb stick is inserted or removed.\nI believe all major Linux distributions are migrating System-V init to upstart step-by-step. In fact, upstarts can also trigger the start of the traditional init scripts, therefore, the transition does not have to occur all at once. \n\nA: Upstart is a replacement for init.\nopenSUSE, Chrome OS and Maemo uses it.\n\nA: Upstart is another effort spearheaded by ubuntu to replace the traditional SysV init system.Its however not a standard though its been adopted by some distributions as Debian,Fedora,Nokia's Maemo platform\nPalm's WebOS,Google's Chromium OS,Google's Chrome OS\nFor more information check fromm http://upstart.ubuntu.com/\n", "Q: Do android phones sync with Ubuntu? Some models only or all models?\n\nA: As said, it's seen like an USB drive by Ubuntu, but the system is designed to sync over the net. Most of the stuff don't need a computer, for example my contacts and phone numbers sync with my gmail and facebook account. Pics with picassa, Files with Dropbox, task with Remember the Milk, etc...\nI really only attach it to a computer to make backups when I do system updates (I own a HTC Magic with the latest Cyanogenmod RC). All the other syncing is done magically over the net.\n\nA: I only tested with one model (Motorola Milestone, called \"Droid\" in the US). But as far as I know, this is true for every android phone.\nIt actually syncs very well. It is seen as a USB drive by the system, but Ubuntu finds it has pictures and music on it, and then you can access it through Rythmbox and F-Spot, and synchronize your music and photos with it very easily.\n\nA: Android phones aren't like iPhones. They don't require a client running on your computer to sync, instead they tend to sync with online services over the air (via wifi or cell network). \nHaving said that, there is a Dropbox client for Android that will sync your files without requiring you to plug your phone in.\n\nA: Syncing over the net with google services is much more useful that by cabel.\nYou can sync you calendar, contacts, tasks and much more with Ubuntu, Thunderbird and other apps.\n", "Q: How to make program autostart only in GNOME I use both GNOME and KDE SC. In GNOME, I use Docky but I do not use it with KDE. So, I would like Docky to start up only when I login into GNOME not KDE. In KDE, there is an option to make a program autostart only in KDE. But I cannot find any such option in GNOME.  \nHow can I do this?  \nThanks in advance.  \n\nA: I don't have kde installed to verify this but I believe adding the application here:\nSystem -> Preferences -> Sessions -> Startup Programs is gnome specific.\nIf that doesn't work you can always put the program in a wrapper script that checks the value of the environment variable $DESKTOP_SESSION. Something like this:\n#!/bin/bash\nif [ $DESKTOP_SESSION == \"GNOME\" ];then\n        myApplication\nfi\n\nHope this answers your question!\n\nA: You can edit the startup object in ~/.config/autostart and add this to the end:\nOnlyShowIn=GNOME\n\nIt's a poorly named option, but it will cause KDE not to start the application.\n\nA: If you cannot find the entry that starts a program, you might also find it in /etc/xdg/autostart instead. I know they finally fixed Nautilus automatically starting in KDE using the OnlyShownIn setting. Changing files in this directory is system wide, so you may want to copy the file of the offending application to ~/.config/autostart/\nInstead of using OnlyShownIn, you can also us NotShownIn. This can allow you to not something for the one desktop, but show it for all others. For this example, you can load Docky in all desktop managers except KDE, by using the following:\nNotShownIn=KDE;\nIf you don't want it to start on any desktop, you can change it to OnlyShownIn=;\nLines in .desktop files are supposed to end with a semicolon. The semicolon is also used to separate values for settings that take more than one value at the same time.\nThis trick would mean that you have to list every desktop shell you use to keep something from running at all. So using NotShownIn=Unity would be fine if you only have Unity installed, but it would still start if you later installed KDE or Gnome.\nIf the desktop file in your user autostart folder does not stop an application from starting, you will need to deal with the desktop file in the xdg directory. For this, I would make a backup copy of the file. Instead of copying it with a bak extension, or something standard that may get overwritten later do this for the imaginary application called badapp for this example.\nsudo cp /etc/xdg/autostart/badapp.desktop /etc/xdg/autostart/badapp.desktop.stop\nYou may then edit the original desktop file. If something breaks and you end up starting in a text boot, you can then rename the file back to the original name.\nsudo cp /etc/xdg/autostart/badapp.desktop.stop /etc/xdg/autostart/badapp.desktop\nAlso, the default user autostart folder for KDE is ~/.kde/Autostart/ because KDE does things the KDE way.\n\nA: System > Preferences > Startup Applications This is the Gnome alternative to the KDE Startup Manager.\n\nA: The other way to edit the autostart file is with a line like:\nOnlyShowIn=GNOME;Unity;\n\n", "Q: How to map a VPN (tun0) network adapter on host Ubuntu to a VirtualBox guest Windows? I have a Ubuntu 10.04 running Oracle VirtualBox 3.2.6 with a Windows XP guest.\nI use a VPN that I would like to be accessed by the guest VM, on a ifconfig it shows as:\ntun0      Link encap:UNSPEC  HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  \n          inet addr:5.192.10.99  P-t-P:5.192.10.99  Mask:255.255.255.255\n          UP POINTOPOINT RUNNING NOARP MULTICAST  MTU:1362  Metric:1\n          RX packets:14151 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:19860 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:500 \n          RX bytes:4415271 (4.4 MB)  TX bytes:17949982 (17.9 MB)\n\nUsing NAT or Bridge adapters on the VM only gives me the non-vpn adapter.\nHow can I map the tun0 adapter to VirtualBox?\n\nA: I met the same problem, and googled around but found no answer.  at last I found my solution: \n\n\n*\n\n*in windows, open the VPN connection using VPN GUI.\n\n*in VM configuration, add a new Network:  Internal network.\n\n*restart VM.\n\n\nthen I can access the resource in VM.\n\nA: Setting /etc/sysctl.conf: \nsysctl net.ipv4.ip_forward=1\n\nThen running: \nsudo sysctl -p\n\n(Should not be necessary but) I rebooted after that.\n", "Q: Why is defragmentation unnecessary? Why is defragmenting unnecessary in Ubuntu?\n\nA: See this link. It gives quite a detailed explanation of how files are stored in Windows and in Linux, and why Linux filesystems usually do not need to be defragmented.\n\nA: The underlying filesystems used by Ubuntu, like ext2 and ext3, simply don't need defragmenting because they don't fragment files in the same way as NTFS. There are more details at ext3 - Wikipedia, the free encyclopedia\n\nA: Some argue that it's actually a myth that we don't need defragmentation. It's argued that we do in fact need it, but only once the filesystem gets pretty full (i.e. less than ~10% free space). Tools are available for defragging such as e2defrag.\n\nA: Ext4 Howto - Ext4\nAccording to this article ext4 defragments on the fly but they are working on a defrag tool.  I personally don't think it is needed except maybe for file servers that get heavy use.\n\nA: Fragmentation is the product of writing files in the first available open blocks on a drive. Over time, as files get created and deleted, small sections of disk open up, which causes newly written files to be split over several such openings. This can reduce performance, although it was much more of a problem in the past with slow hardware and slow disks.\nThe default filesystem in Ubuntu, ext4 (and until recently, ext3) are designed to limit fragmentation of files as far as possible. When writing files, it tries to keep the blocks used sequential or close together. This renders defragmentation effectively unnecessary.\n", "Q: 5.1 surround sound Ok, So I’ve always had trouble with enabling 5.1 in Ubuntu. \nRunning alsamixer:\nI have: Master, Headphones, PCM, Front, Front Mi, Front Mi, Surround, Center.\nAll are at 100%\nCard:HDA Intel\nChip:Realtek ALC888 (This is my onboard sound, Its a dell studio, with 7.1 integrated sound)\nRunning speaker-test -c6 -twav I only get the front 2 speakers (Right/Left) making any noise. The others make no noise at all. \nI have no other sound card to use as all my PCI slots are used up.\nDaemon.conf:\n; daemonize = no\n; fail = yes\n; allow-module-loading = yes\n; allow-exit = yes\n; use-pid-file = yes\n; system-instance = no\n; enable-shm = yes\n; shm-size-bytes = 0 # setting this 0 will use the system-default, usually 64 MiB\n; lock-memory = no\n; cpu-limit = no\n\n; high-priority = yes\n; nice-level = -11\n\n; realtime-scheduling = yes\n; realtime-priority = 5\n\n; exit-idle-time = 20\n; scache-idle-time = 20\n\n; dl-search-path = (depends on architecture)\n\n; load-default-script-file = yes\n; default-script-file = \n\n; log-target = auto\n; log-level = notice\n; log-meta = no\n; log-time = no\n; log-backtrace = 0\n\nresample-method = speex-float-1\n; enable-remixing = yes\n; enable-lfe-remixing = no\n\nflat-volumes = no\n\n; rlimit-fsize = -1\n; rlimit-data = -1\n; rlimit-stack = -1\n; rlimit-core = -1\n; rlimit-as = -1\n; rlimit-rss = -1\n; rlimit-nproc = -1\n; rlimit-nofile = 256\n; rlimit-memlock = -1\n; rlimit-locks = -1\n; rlimit-sigpending = -1\n; rlimit-msgqueue = -1\n; rlimit-nice = 31\n; rlimit-rtprio = 9\n; rlimit-rttime = 1000000\n\n; default-sample-format = s16le\n; default-sample-rate = 44100\n; default-sample-channels = 6\n; default-channel-map = front-left,front-right\n\ndefault-fragments = 8\ndefault-fragment-size-msec = 10\n\n\nA: You could try this in terminal:\nsudo alsamixer\n\nYou should see separate \"volume\" sections (eg, Front, Line-In, Center/LFE, etc) that you can mute and unmute (pressing the 'm' key) or change the volume with the arrow keys.\nIf that doesn't work, then would you gladly clarify if you have a sound card (other than your motherboards sound). :D\n\nA: Try this:\nSelect sound preferences from sound indicator menu, go to hardware tab and select the applicable surround option from the profile menu.\nIf all goes well, you should have a working 5.1 sound.\n", "Q: How do I set up VLAN forwarding? I have a DAAP server with multiple VLAN interfaces. I would like to get traffic forwarded on all of the VLANs. Forwarded from eth0 to eth1.010* I've got the switch configured to be a trunk port with the correct VLANs, and I enabled /proc/sys/net/ipv4/ip_forward\nBut that doesn't seem to be doing the trick.\nIs there anything else I need to do? \nHere is my ifconfig results, as you can see the VLAN interfaces aren't really getting any traffic:\neth0      Link encap:Ethernet  HWaddr 00:14:d1:10:ca:fc  \n          inet addr:192.168.1.20  Bcast:172.21.255.255  Mask:255.255.0.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:536 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:259 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:264232 (258.0 KiB)  TX bytes:37425 (36.5 KiB)\n          Interrupt:20 Base address:0xe000 \n\neth1      Link encap:Ethernet  HWaddr 00:1c:c4:31:28:22  \n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:303 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:202 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:225213 (219.9 KiB)  TX bytes:47118 (46.0 KiB)\n          Interrupt:17 \n\neth1.0101 Link encap:Ethernet  HWaddr 00:1c:c4:31:28:22  \n          inet addr:172.17.1.20  Bcast:172.17.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:9076 (8.8 KiB)\n\neth1.0102 Link encap:Ethernet  HWaddr 00:1c:c4:31:28:22  \n          inet addr:172.18.1.20  Bcast:172.18.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:9076 (8.8 KiB)\n\neth1.0103 Link encap:Ethernet  HWaddr 00:1c:c4:31:28:22  \n          inet addr:172.19.1.20  Bcast:172.19.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:9076 (8.8 KiB)\n\neth1.0104 Link encap:Ethernet  HWaddr 00:1c:c4:31:28:22  \n          inet addr:172.20.1.20  Bcast:172.20.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:9076 (8.8 KiB)\n\neth1.0105 Link encap:Ethernet  HWaddr 00:1c:c4:31:28:22  \n          inet addr:172.21.1.20  Bcast:172.21.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:9076 (8.8 KiB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:16436  Metric:1\n          RX packets:113 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:113 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:20777 (20.2 KiB)  TX bytes:20777 (20.2 KiB)\n\nHere is my /etc/network/interfaces file:\n# This file describes the network interfaces available on your system\n# and how to activate them. For more information, see interfaces(5).\n\n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# Automagically configured network interfaces\nauto eth0\nauto eth1.0101\nauto eth1.0102\nauto eth1.0103\nauto eth1.0104\nauto eth1.0105\n\niface eth0 inet static\n   address 192.168.1.20\n   netmask 255.255.0.0\n   gateway 192.168.1.3\n   network 172.21.0.0\n   broadcast 172.21.255.255\n\niface eth1.0101 inet static\n   address 172.17.1.20\n   netmask 255.255.255.0\n\n\niface eth1.0102 inet static\n   address 172.18.1.20\n   netmask 255.255.255.0\n\n\niface eth1.0103 inet static\n   address 172.19.1.20\n   netmask 255.255.255.0\n\n\niface eth1.0104 inet static\n   address 172.20.1.20\n   netmask 255.255.255.0\n\n\niface eth1.0105 inet static\n   address 172.21.1.20\n   netmask 255.255.255.0\n\nThank you for any help, I've been working on this for quite a while.\n\nA: I haven't done this on Ubuntu but here's my research so far:\nYou need to stick  \nvconfig add eth1 101  \nvconfig add eth1 102  \nvconfig add eth1 103  \nvconfig add eth1 104  \nvconfig add eth1 105\n\nin a startup script.\nThe interfaces file would look something like this:  \nauto lo\niface lo inet loopback\nauto eth0 eth1 vlan2 vlan3 vlan4 vlan5\niface eth0 inet dhcp\n\n# VLAN 1 - native management VLAN\niface eth1 inet static\n        address 10.0.0.1\n        netmask 255.255.255.224\n        vlan_raw_device eth1\n\n# VLAN 2 - DMZ\niface vlan2 inet static\n        address 10.0.0.33\n        netmask 255.255.255.224\n        vlan_raw_device eth1\n\n# VLAN 3 - Accounting\niface vlan3 inet static\n        address 10.0.0.65\n        netmask 255.255.255.224\n        vlan_raw_device eth1\n\n# VLAN 2 - DMZ\niface vlan2 inet static\n        address 10.0.0.33\n        netmask 255.255.255.224\n        vlan_raw_device eth1\n\n# VLAN 3 - Accounting\niface vlan3 inet static\n        address 10.0.0.65\n        netmask 255.255.255.224\n        vlan_raw_device eth1\n\n# VLAN 4 - Engineering\niface vlan4 inet static\n        address 10.0.0.97\n        netmask 255.255.255.224\n        vlan_raw_device eth1\n\n# VLAN 5 - Sales & Marketing\niface vlan5 inet static\n        address 10.0.0.129\n        netmask 255.255.255.224\n        vlan_raw_device eth1\n\nYou will use your own IPs in the interfaces file, obviously.\nLet us know if it worked.\nReferences:\n1\n2\n\nA: If I'm reading your question correctly, you are looking for bridging. Bridging forwards all traffic from one interface to another.\nYou will need to install bridge-utils package and setup your configuration as follows:\nauto br0\niface br0 inet static\n  address 192.168.1.20\n  netmask 255.255.0.0\n  gateway 192.168.1.3\n  bridge_ports eth0 eth1.0101 eth1.0102 eth1.0103 eth1.0104 eth1.0105\n\nNo configuration is required for the individual ports.\nThis will configure the ports to be in one bridge and should make everything accessible. You can see the state of the bridge with brctl command.\n\nA: It worked!  I've got a separate problem with DAAP now, but I think it's Avahi related.  I'll try to work through that myself. Thanks a ton.\n", "Q: CHOWN: What does \"id -u\" represent I am working to get Mongodb running on a Ubuntu server install.  In reviewing the instructions I needed to create a \"\\data\\db\" directory in the root drive.  At which point I needed to alter the owner using the CHOWN command as follows:\nsudo chown `id -u` /data/db\n\nWhen I issue that command as it appears in the quick start guide I receive \nchown: invalid user: 'id -u'\n\nI am new to Linux, so what I don't understand is what the 'id -u' was supposed to mean.  When I replace with my user name the command completes just fine and mongo runs.  Can someone help me understand what the short hand 'id -u' would communicate to an expert Linux user that it did not to me?\n\nA: The command id -u prints out your \"numeric user ID\" (short: UID); as you already noticed, it is the same as spelling out your username in full on the chown command line.  Indeed, the following command invocations should all have the same effect:\nsudo chown `id -u` /data/db\nsudo chown $USER /data/db\n\nThe reason why it did not work as expected has likely to do with the quotes: they have to be backquotes (ASCII char 0x60), whereas the chown error message suggests that you used single quotes (ASCII char 0x27).\nYou can find a very thorough explanation of UNIX shell quoting here. \n\nA: It returns your user id. Run man id for more information.\n\nA: id -u prints your user id on the system. As an alternative you can just run this command:\nsudo chown <user> /data/db replacing <user> with your username on the system.\n", "Q: Are there currently any plans to replace Rhythmbox with Banshee in \"Maverick Meerkat\" 10.10? Since years there are rumours that Rhythmbox will be replaced by Banshee as default application in the next Distribution-Release. Are there any plans for it to be replaced? The information that I have found is ambiguous.\n\nA: This hasn't been finalized yet. You can see on their whiteboard though that it's on the table for discussion: Ubuntu Blueprints: Desktop Application Selection for Maverick It comes down to several issues not only with the quality of the application, but it's size (for LiveCD), dependencies, and upstream's development cycle.\nThis shows a running log of discussions and inputs. As is noted at the bottom Banshee has some issues in the Upstream which might prevent it from making it's way into 10.10.\n\nA: Banshee will become the default music player in 11.04 (Natty Narwhal).  See also the whiteboard at https://blueprints.launchpad.net/ubuntu/+spec/packageselection-desktop-n-application-selection (please don't edit!).\n\nA: I think that will be decided during the upcoming Ubuntu Developer Summit in Florida.\n\nA: Banshee has replaced Rhythmbox on UNE 10.10 Alpha 3\n", "Q: Are there any fallbacks for Plymouth? If I am using the proprietary driver, I don't get a good boot screen.\n\nA: *\n\n*First open the software center\n\n\n\n\n\n*\n\n*Install v86d\n\n\n\n\n\n*\n\n*Now Press Alt + F2 and enter gksu gedit\n\n\n\n*\n\n*Now click on 'Open' and  Press the pencil button .\n\n\n\n\n\n*\n\n*Now paste /etc/default/grub\n\n*Now Replace the line GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\" (Line no 11 according to gedit) with \nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nomodeset       video=uvesafb:mode_option=1280x1024-32,mtrr=3,scroll=ywrap (you can replace 1290x1024 with your own resolution . \n-Also replace #GRUB_GFXMODE=640x480 (Line 25 according to gedit ) with GRUB_GFXMODE=1280x1024 \n-Now your grub file looks like this \n\n\n\n*\n\n*Save the file .\n\n*Now click open again and paste /etc/initramfs-tools/modules in the location .\n\n*Paste uvesafb mode_option=1280x1024-32 mtrr=3 scroll=ywrap at the end of the file (again you can replace 1280x1024 with your own resolution) .\n\n\n\n*\n\n*Now create a new file and paste FRAMEBUFFER=y and then save the file with the name splash to /etc/initramfs-tools/conf.d .\n\n*Now Open the terminal (Ctrl + Alt + T) and paste this. \nsudo update-grub2 && sudo update-initramfs -u\n\n*You are done!!\nSource\n\nA: There is also a workaround to make plymouth use framebuffer: http://news.softpedia.com/news/How-to-Fix-the-Big-and-Ugly-Plymouth-Logo-in-Ubuntu-10-04-140810.shtml\n\nA: This depends on your definition of \"good\".\nThere is a fallback: usplash and/or xsplash. These should load automatically. They do here on systems where Plymouth doesn't work.\nPlymouth requires KMS which is only available on open source drivers (AFAIK). This means if you're running the closed ATI/Nvidia drivers, you'll have an ugly boot experience.\nI personally just turn off quiet and splash from the kernel arguments and watch a load of text scroll up the screen. It's only there for a few seconds, lets me know what's going on and it doesn't waste time loading up images.\n", "Q: Since 10.04 the laptop's extended monitor shows a shaky/waving image My laptop is a \"Lenovo T60p\" with an ATI video card and it used to work fine on 9.10.\nThe external monitor works after full cycle of Function+Monitorkeys pressing, but the extended is not working properly.\nAnything I should try?\n\nA: Seems to be a KMS issue. See: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/562138\nIn short, add this to your kernel command (test it by holding left-control on boot, edit the command by pressing whichever key it says, control+x to boot):\nradeon.modeset=0 vga=771\n\nIf you already have a vga command in there, replace it.\nIf that works, that confirms you're suffering this bug. It's fixed properly in later kernels (2.6.34 and 2.6.35 should both work) so you're left in a position where you either make do with the kernel run arguments or you upgrade kernel.\nThe good news is this should be fixed by 10.10... But who knows what bugs it'll introduce!\n", "Q: How to learn vim on a high level? I know that vim (like emacs) is very powerful editor for programmers, as long as you know how to use it, its shortcuts, and so on. What steps can I take and what tutorials can I read to become an advanced vim user?\n\nA: *\n\n*Nice videos in high level\n\n*Step by step, full configuration\n\n*Vim Recipes is a free cookbook for Vim, the popular text editor. It’s available in:\n\n*VIM for (PHP) Programmers - Andrei Zmievski \n\n*Vim best tips\n\nA: This will sound silly, but get to know vim's help command. The help system is remarkably intuitive and easy to navigate. \nHelp is available by typing :help . You can find out about a specific topic by including that on the command line (eg :help insert). You can cycle through topics by hitting tab after typing one or more characters of topic. \nThe help is hyperlinked, with links denoted at either bold or coloured text. You can follow links by hitting <Ctrl-]> when your cursor is on it, and <Ctrl-t> to go back. To get out of help, type :q. \n\nA: Some great answers. Definitely try to integrate it into daily life and make sure you don't try to flood your brain with too much at a time. There's just too much to vim to learn it all in a week. \nAt first just start with one/two new commands/keys a week. Use them and ingrain them into your brain. You don't want to have to refer to a cheat sheet all day. \nI've got a sample vim config setup that's really well documented I publish for people:\nhttp://github.com/mitechie/pyvim\nDon't just copy/paste though. Make sure you understand what's going into your vim config so you don't forget/misunderstand what it's doing for you.\nand I've started doing some vim screencasts:\nhttp://lococast.net/archives/111\n\nA: PeepCode's Smash into VIM 1 & 2 are a great resource.  You can also check out Rob Conery's blog, he has some good VIM related information/blogs available there.\n\nA: I used a book that I found from Vim's website\n\nA: I know that I might get negative feedback for this answer, as it may hurt vim fans and users: First ask yourself what you want to do. And only if vim is the best tool for that specific task, do what all the other answers tell you.\nOr to say it with more images: You can try to get twice as fast or good with a hammer than you are now. But depending on the situation a screw driver may help more than the hammer. :)\n\nA: \"vimtutor\" form package \"vim\" is probably the best place to start.\n\nA: I haven't really learned Vim yet but I think that by doing all my browsing with the Pentadactyl extension for Firefox it will be less difficult when I get around to do so.  \nAny text fields and the command line can be treated like Vim normal mode with a Ctrl T (or automatically, if you change a setting); however, here's where it falls down at the moment for me since many actions are interpreted to be global e.g. attempting to paste with p opens a url with the text that's in the buffer and attempting to overwrite text with r  reloads the page. But you can open the text field in Gvim by pressing Control I, so it's not really an issue.\nAnother problem is that it makes websites like Gmail or Remember the Milk trickier to use since you have yet another mode to contend with.  \n\nA: See the answers on beginner's tips for learning Vim from Programmers SE\nTo reiterate my answer from that question:\n\nI learnt a lot from the O'Reilly book \"Learning the Vi and Vim editors\". It's the best Vim book I've read.\nI'd also recommend checking out:\n\n\n*\n\n*Derek Wyatt's Vim Screencasts: they're awesome.\n\n*vimcasts: more great videos.\n\n*Laurent Gregoire's Vim Reference Card: print it out; read it in your free moments.\n\n*the built in help\n\n\nA: Two things:\n\n\n*\n\n*Learn touch-typing. There's really no other way. Then bind ESC to \";;\" so you never have to leave your home row: inoremap ;; <esc>\n\n*Search github for other people's .vimrcs\nAnd a third: VimCasts\n\nA: Step 0: learn to touch type. Seriously - if your fingers don't know where the keys are then vim is going to be a pain. And even if you reject vim, touch typing will improve your programming (ask Steve Yegge) by making the mind to monitor link friction free. There is a lot of software that can help you improve your typing.\nStep 1: Use the keyboard preferences to swap Caps Lock and Escape - seriously, how often do you use Caps Lock? Using vim you will be using Escape all the time, and having it available on the home row makes a huge difference. With the standard Ubuntu desktop, go through the menus: System -> Preferences -> Keyboard -> Layouts tab. Then hit the \"Layout Options\" button, click on the triangle next to \"Caps Lock key behaviour\" and select \"Swap ESC and CapsLock\".  (Note how to do this has changed - see this for how to do this in 14.04.\nStep 2: use vimtutor to get you started. It is in gvim (under\nthe help menu I think) or you can just type 'vimtutor' at the command\nline. It will take 30-45 minutes of your time and then your fingers will\nknow the basics of vi/vim and you should be able to edit files without\nwanting to hurl your keyboard out of the window. \nStep 3: use vim everywhere. See this\nquestion from StackOverflow\nfor tips and links for using vim and vi key bindings at the command\nline, from your web browser, for composing emails, in your IDE ... You\nneed to use vim to embed the key bindings in your muscle memory.\nStep 4: learn more about vim. You will only have scratched the\nsurface with vimtutor. You can \n\n\n*\n\n*watch screencasts at vimcasts or those by Derek Wyatt;\n\n*watch this\nvideo or\nread this article (both about\nthe \"Seven habits of effective text editing\";\n\n*read\nabout\nsome\nof\nthe\nmany\ntips\nand\ntricks \non\nStackOverflow;\n\n*browse vimtips. \n\n\nLearn a litle often would be my advice - there is so much out there that\nsticking to bite-size chunks will be the best way to make the knowledge\nstick.\nStep 5: Profit :)\n\nA: http://www.linuxconfig.org/Vim_Tutorial\nThat is a pretty good tutorial. It has videos and such. \n", "Q: Delay when playing sound In a script I play a sound ( .ogg file) using /usr/bin/play.  The sound is played fine, but there is an annoying delay of a couple of seconds after the sound has been played before the program (play) terminates.  Why is that, and can it be fixed? \nThe script is a git-commit hook.  It just calls play -q filename.ogg.  I have the same experience from the command line. \nI'm on 10.04 if that’s relevant. \n\nA: There's no need to wait for the sound to be completed, right? So you could just\nplay file.ogg </dev/null &>/dev/null &\n\n(or look here for more intense detaching). Also try ogg123 or mplayer instead of play, or try a different audio output.\n\nA: I would attribute that to the time it takes for the application to shut down. It really depends how you wrote the script.\nThis might be more of scripting issue than a ubuntu one.\n", "Q: How do I share files on my home network? I would like to set up a home network with the various Ubuntu machines I have at my home. They are all running 10.04. It would have to be able to share files and maybe even chat. :)\nAny information on how to set this up would be beneficial.\nPlease and thank you.\n\nA: Networking in general with Linux is a wide field. It is one of those parts where the operating system is strong and offers lots possibilities. I would suggest different steps:\nGetting an IP address\nDHCP\nAt first every computer in your network needs an IP address. Most home networks have some kind of (DSL) router which offers DHCP. That means you'll get automatically an IP from your router and don't have to worry about.\nAvahi\nAvahi is another easy form to connect your computers in your home network. You need avahi-daemon installed. Furthermore the package libnss-mdns is needed. If the avahi daemon runs, you can connect to other computers in your network with computername.local. They will assign an IP and use their hostname for connections (If you forget the hostnames, open a terminal and type hostname.).\nFixed IP address\nIf the above is not the case the next easy solution (in my opinion) is to give every computer a fixed IP address. For me the easiest way is to edit etc/network/interfaces:\nauto eth0\niface eth0 inet static\n   address 192.168.0.42\n\nThose lines assign the IP 192.168.0.42 to the network interface eth0 on that computer. Other information like netmask, default router etc. can also be entered into that file.\nDHCP-Server\nAnother possibility is to install an DHCP server. This is usually more complex. I will not cover this here.\nGetting a name\nUnder normal circumstances only connecting via IP addresses is not nice. You have to remember all those numbers. So it gets easier with names. If you only have a few computers in your network, you can edit /etc/hosts like:\n127.0.0.1  localhost\n192.168.0.23 server\n192.168.0.42 laptop\n192.168.0.65 images\n192.168.0.123 router\n\nThe first entry is the IP address and the second is the name you want to use. Now you can use images to connect to the computer with IP 192.168.0.65. This file has to be on every computer in your network.\nIf you don't want to distribute that file across your computers, you can use a DNS server like BIND. But setting this up is too complex for my answer. ;)\nNow every computer has an IP address and a name. You can connect to them.\nShare files\nNautilus allows you to share files. Just click right on a folder and choose it too be shared. Eventually Ubuntu will install some missing files. Choose a name and access rights for that share and you're done. If you use the service-discovery-applet or ahavi-discover it is easy to access the files.\nA special application is giver. Every computer needs to run this software. With drag&drop you can share files between computers. Besides this you can also use Pidgin, an FTP server or Samba to access files.\nChat\nHere we need Avahi again. Install python-avahi and choose Pidgin as chat software (also Gajim is able to chat via Bonjour). Make a new account and choose Bonjour as communication protocol. If you start Pidgin and other Bonjour-users are active in your network, you'll see them and can chat.\nAs said before there are several other possibilities to chat. I chose only this. Furthermore you can configure those services in specific ways. If you have questions it would be the best to ask them in more detail. Have fun with your network. :-)\n\nA: It's really easy. Takes just a couple of minutes.\nCreating Network:\nJust click the network icon in the panel and click create new wireless network. Choose a name and password and click create. Now this wireless network should be available on all nearby machines. You can share files, chat, remote desktop, share internet connection etc. You can also create a LAN/Wired connection, to do that edit connections, then add a wired network and in the IPV4 tab, select shared to others or local link only. Shared to other will share your internet connection to other machine on lan. Local Link will not.\nEnabling Chat:\nTo enable chat on local network, add a people nearby account in empathy chat application on all machines.\nHope that helps.\n\nA: Easier way to do this IN 3 Easy Steps! \nFirst find out your Mac Address and current IP Address on you current connected network:\nOpen Terminal and type (keep terminal open for last step):\nsudo ifconfig\nyou will see an output of your network card information like this:\nLink encap:Ethernet  HWaddr 00:11:22:33:44:55 \ninet addr:192.168.1.2\n\nSecond, Set up your router as the DHCP server and bind a static internal IP address to your network card(s) or wireless card(s) MAC Address under the \"DHCP\" section of your router. In a browser go to: \nhttp://192.168.1.1 (usually the routers IP Address)\n(if your username & password is \"admin\" please change the password so nobody dosent mess with your router settings!!!!!!!!!!!!)\n192.168.1.2 = 00:11:22:33:44:55 MyComputer\n192.168.1.3 = 11:22:33:44:55:66 MyBrothersComputer\n\nThird Edit hosts file:\nsudo gedit /etc/hosts\n\nAdd your specific configuration:\n192.168.1.2 My Computer\n192.168.1.3 My Brothers Computer\n\nConfiguring BIND & DHCP in your computer system can be a pain, especially for newbies and dads & moms that know nothing about networking. Your router sets up static IP addresses for you automatically. Its a no brainer.\n\nA: You could run one of those in a server. Just install Ubuntu Server Edition and then install Samba (if you have Windows PC if not don't install) and you could have a local IRC server. A server would be a lot easier then connecting 5 (just guessing here). If you have 2 or 3 then just connect right to that PC but a server will make it a lot easier. \nTo connect just use the Network Location in Ubuntu and connect via SSH.\n", "Q: Record sound from web cast I want to record a radio webcast which does not offer MP3. The easiest way to do it seems to be recording all system sounds, playing the webcast and saving as MP3.\nThis is legal, by the way - I want to record a radio show in which my friend was interviewed. This is permitted by the radio station (and fair use according to Israeli law AFAIK).\nThanks,\nAdam\n\nA: You can record any audio you can play using OutRec: http://www.omgubuntu.co.uk/2010/07/quickly-record-soundcard-output-in.html\n\nA: You can use mplayer for this:\nmplayer -dumpaudio -dumpfile radio url://of.your/radio\n\nor \nmplayer -dumpstream -dumpfile radio url://of.your/radio\nYou can choose the filename radio on your own. After the stream has been saved, you can edit the file and convert it to a format which fits you.\n", "Q: How can I stop `gnome-screensaver` from resetting my keyboard to its default layout? I use xmodmap to alter my keyboard layout during session startup.\nHowever, each time the GNOME screensaver/lock screen is activated, it\nresets the keyboard to its default layout, and I have to run xmodmap\nagain to get my keybindings back.\nI understand that resetting the keyboard layout is the right thing to\ndo before presenting a password prompt, but Is there a way to stop the\nGNOME screensaver from doing it?  Or a way to tell GNOME to use a\ncustom keyboard layout all the time?\n\nA: Searching with gconf-tool, I found the setting /desktop/gnome/peripherals/keyboard/general/update_handlers, which apparently is a list of Xmodmap files to be (re)loaded each time the keyboard status is reset.\nSettiing this to .Xmodmap made the thing work for me (after logging out and back in).\n\nA: You can change GNOME keyboard layout options in System -> Preferences -> Keyboard.\nYou can edit key bindings in System -> Preferences -> Keyboard Shortcuts.\nThese may not have the same flexibility as xmodmap, but should work properly even after screensaver/lock screen.\n\nA: At log in the .Xmodmap (set up as user or globally) would read properly. However, when the monitor goes to sleep, and I log back in, it would be reset and keys would work as before .Xmodmap was loaded. No setting worked around until at some point I realized that my keyboard is plugged in to the monitor and thus all sittings are lost when the monitor goes to sleep or is turned off. What helped was to plug in the keyboard directly to the computer tower. Now the initial reading of .Xmodmap right after logging in is maintained independently of the monitor being on or off.\n\nA: I have custom key bindings stored in an xkb file, which I can load with xkbcomp. I have never experienced any problems with the screensaver resetting this config.\nYou can then put the xkbcomp command in your .xinitrc file to load the keymap whenever x starts.\n", "Q: Is there an alternative to Adobe AfterEffects? Is there a After Effects like software for Ubuntu (or for free)\nAdobe After Effects is a compositing, compositional and post-production video tool. If you think about green-screening, those cool titles/credits, overlays with people's names, infographics... it's all that stuff, and a lot more. Like motion photoshop, in full hd.\n\nA: There is lots of high end (and sometimes quite expensive) video software for linux.  \nThere is a wikipedia page that has a list of available software (both commercial & open source) for multiple operating systems.\nOne interesting software project which is not on that list yet is Ramen that is designed for 64 bits Linux operating systems.\n\nA: Although this is a rather old question, for the benefit of new users / searchers, I think blender needs a more prominent place in the answers than as in a comment.\nWith the finalization of project mango, called Tears of Steel, blenders abilities in regard to post production are stronger than ever -- the node based compositor is very powerful indeed. You need to get used to blender, but it's worth it.\nUpdate: Blender 2.69 was just released a couple of days ago, with many improvements in camera tracking, motion tracking, ...\n\nA: I've been an After Effects user for 12+ years and I have not found anything really comparable on linux platforms. Cinelerra is probably the closest and looks promising, but I have little experience with it (basically since my clients are dedicated to AE). The other apps listed by others above are primarily video editors; and as I'm sure you're aware, that is not After Effects primary niche. \nCinepaint, developed for the motion picture industry says that they may eventually add features in the direction of AE.\n\nA: There's PiTiVi which is included by default. And there is LightWorks which is opensource.\n\nA: There are several alternatives, see here.\nWhen looking for applications, don't forget to search/browse the Ubuntu Software Centre.\nAlso there is a website (http://www.osalt.com) that compares proprietary and open source software.  \n", "Q: Is Ubuntu based on Debian unstable or Debian testing? which of the two it is?\n\nA: Both.\nIn every Ubuntu release, there's an initial import from Debian unstable for many packages in main. After 9 weeks or so, that process is frozen and the versions are locked down.\nHowever, there is still tracking done by the MOTU team for universe. Many packages come across from testing. (Many packages are also wholly original too.)\nFor both sets of packages, bug tracking is done on Launchpad and custom patches will be introduced or backported from the previous Ubuntu release.\n\nA: Actually it depends. For LTS releases Ubuntu syncs with Debian Testing. For non-LTS releases, Ubuntu syncs with Debian Unstable.\n\nA: Neither, but it resembles Unstable more of the two.\nUbuntu syncs packages during the development cycle from unstable and those packages then get stabilized and/or modified before release. At the time of the release, Ubuntu has fallen behind of Unstable quite a bit, but it adds time to find and fix the bugs that have crept in.\n", "Q: When installing user applications, where do \"best practices\" suggest they be located? Occasionally I install applications manually, rather than using apt or another package manager. \nWhat location (/usr/, /usr/local/, /opt/, /home/, etc.) is suggested by \"best practices\" for the installation of user applications?\n\nA: I usually have a folder named \"Programs\" in my home where I install those programs, strange enough (or not) they are all java stuff right now.\nIt has one great advantage for me, when I reinstall or change computers they get moved with the rest of my home. It has a clear disadvantage, those apps are only available to my user.\n\nA: Install unstable programs like firefox devel in /home/user/opt/ makes it a lot easier to remove, and no confusion for other users as to what version they should use... So if it is not a program for global use, install it in a subfolder in your home directory (/home/user/).\nNever install programs in /usr/, it is likely to cause chaos, things installed in /usr/ is meant to be for distribution packages only. /usr/local/ is for packages locally compiled. And the structure works in exactly the same way! files in /usr/local/ will be prioritized over files in /usr/.\n/opt/ should be used for installation of pre-compiled (binary) packages (Thunderbird, Eclipse, Netbeans, IBM NetSphere, etc) and the like. But if they are only for a single user they should be put in your home directory.\nIf you want to be able to run a program installed in a \"weird\" location (like /home/user/opt/firefox/) without typing the whole path you need to add it to your $PATH variable, you can do this be adding a line like this in your /home/user/.profile\nexport PATH=/home/user/opt/firefox:$PATH\n\nThe folder name should be the one where the executable file you need to run is located.\n\nA: The Linux Filesystem Hierarchy Standard indicates /usr/local.\nFrom http://tldp.org/LDP/Linux-Filesystem-Hierarchy/html/usr.html:\n\nThe original idea behind '/usr/local' was to have a separate ('local')\n  '/usr' directory on every machine besides '/usr', which might be just\n  mounted read-only from somewhere else. It copies the structure of\n  '/usr'. These days, '/usr/local' is widely regarded as a good place in\n  which to keep self-compiled or third-party programs. The /usr/local\n  hierarchy is for use by the system administrator when installing\n  software locally. It needs to be safe from being overwritten when the\n  system software is updated. It may be used for programs and data that\n  are shareable amongst a group of hosts, but not found in /usr. Locally\n  installed software must be placed within /usr/local rather than /usr\n  unless it is being installed to replace or upgrade software in /usr.\n\n\nA: That depends, really. If the application has a makefile, or for example for Python apps if the application uses distutils (e.g., has a setup.py file), or a similar build/install system, you should install it into /usr/local/.  This is often the default behavior.\nFrom what I understand, /usr/local/ has a hierarchy that is similar to /usr/. However, directories like /usr/bin/ and /usr/lib/ are usually reserved for packages installed via apt. So a program expecting to get \"installed\" into /usr/ should work fine in /usr/local/.\nIf you just need to extract a tarball and run directly (e.g. Firefox) then put it into /opt/. A program that just needs one directory and will get all files/libraries relative to that directory can get one directory for itself in /opt/.\nFor reference, see the FHS.\n\nA: It's good to remember that /usr does not stand for user but rather unix system resources.\nAs such, I tend to figure that any distribution has the rights to stomp all over over contents of /usr, and that my specific additions to the system go in /usr/local, which I preserve before doing an upgrade.\nMeanwhile, applications and other things go in /opt.\nSome people feel comfortable putting stuff in /home, though I rarely follow that convention.\nAll that said, I let the distribution package manager do things its way first, and then do the above when hand rolling stuff.\n\nA: Use \"checkinstall\" to convert your alien package to a deb so that it is uninstallable using the package manager.  \nDo note that config files will often not be handled as config files (perhaps ignored, or perhaps treated as part of the app), and that pre- and post-install scripts sometimes get bungled, though it will usually warn you when it thinks the deb will have a bad pre- or post-install script.\n", "Q: How to set the terminal to open maximized I want to tell compiz, metacity, the gnome-terminal or whoever is in charge to open the terminal window maximized by default.\nHow can I do that?\nEDIT for the future: most of the answers were upvoted in older ubuntu versions, since 17.10 and on the most upvoted solutions do not work.\n\nA: Ubuntu 12.04 and 14.04 LTS\nRun ccsm (CompizConfig Settings Manager). Under Window Management enable Window Rules and open it, and in the Maximized field put class=Gnome-terminal. You may need to log out and log back in before the changes come into effect.\nIf you don't see Window Rules, then make sure you've got the compiz-plugins package installed.\nYou can do more. I use (class=Gnome-terminal) | (class=Evince).\n\nA: In Ubuntu 11.10 and up:\n\n\n*\n\n*Search > Keyboard > Shortcuts > Custom Shortcuts > Add (+ button) >\n\n*\n\n*Name: Launch Terminal Maximized\n\n*Command: gnome-terminal --window --maximize\n\n\n*Click Apply\n\n*Click on 'Disabled'\n\n*Shift+Ctrl+Alt+T\n\nA: The selected answer didn't work for me on fully updated Ubuntu 12.04 LTS, so I decided it was time for a more drastic approach. The solutions below are tested up to 16.04 LTS.\nMy old solution\n\n\n*\n\n*Rename original gnome-terminal executable to\ngnome-terminal-original:\ncd /usr/bin\nsudo mv gnome-terminal gnome-terminal-original\n\n\n*Create a new file in /usr/bin named gnome-terminal with the\nfollowing content:\n#!/bin/bash\n/usr/bin/gnome-terminal-original --maximize $@\n\n\n*Make it executable:\nsudo chmod +x gnome-terminal\n\nNow no matter how I open the terminal, it always opens maximized. The only downside I see for this approach is that you have to repeat these steps every time you might update gnome-terminal with a new version via update manager or apt-get upgrade.\nNote: the $@ parameter means that all arguments that might get passed to gnome-terminal will still get passed to gnome-terminal-original, along with --maximize argument.\nA better solution\n\n\n*\n\n*Install \"wmctrl\":\nsudo apt-get install wmctrl\n\n\n*Add this line to the very end of your ~/.bashrc file:\nwmctrl -i -r $WINDOWID -b add,maximized_vert,maximized_horz\n\n\n*Repeat the second step for other user's .bashrc files if needed, for example, for \"root\" user (/root/.bashrc).\nThis solution will not affect the size of the terminal window initially, but rather maximize it shortly after it opens, usually in a matter of milliseconds. You can try moving the line you added in the second step to the beginning of .bashrc file, to make the terminal maximize even earlier.\n\nA: gnome-terminal --full-screen\n\nYou could create a shortcut on your desktop or panel to this command.\n\nA: Launch gnome-terminal as such:\ngnome-terminal --window --maximize\n\n\nA: *\n\n*Open a Terminal.\n\n*From Edit menu select Profile Preferences.\n\n*Tick Use custom default terminal size and enter a default size that is too large for the screen e.g. 240 columns and 100 rows.\n\n\nClose, then open a new Terminal by clicking the icon (or press Ctrl + Alt + T): the new terminal window should be maximised.\nThis answer is based upon advice I was given here:\nHow to make terminal start maximized?\n\nA: If you want gnome-terminal to open fullscreen when you open it with Gnome Do or the Applications menu, put the following into a file named gnome-terminal.desktop and put that in ~/.local/share/applications.\n[Desktop Entry]\nName=Terminal\nComment=Use the command line\nTryExec=gnome-terminal\nExec=gnome-terminal --window --maximize\nIcon=utilities-terminal\nType=Application\nX-GNOME-DocPath=gnome-terminal/index.html\nX-GNOME-Bugzilla-Bugzilla=GNOME\nX-GNOME-Bugzilla-Product=gnome-terminal\nX-GNOME-Bugzilla-Component=BugBuddyBugs\nX-GNOME-Bugzilla-Version=2.32.0\nCategories=GNOME;GTK;Utility;TerminalEmulator;\nStartupNotify=true\nOnlyShowIn=GNOME;\nX-Ubuntu-Gettext-Domain=gnome-terminal\n\nThen log out and log back to apply the changes.\n\nA: If you just want the terminal to open full size on screen, use the GUI method of changing the default size through current profile preferences dialog appropriately. To do so, simply follow these steps:\n\n\n*\n\n*Open a terminal\n\n*Choose Edit\n\n*In the General tab, check \"Use custom default terminal size\"\n\n*You need to adjust these values so that they fit your screen \nby simple trial and error\n\n\nThe column setting is 128 for me. You should set the values that best suit you.\n\nA: In QTerminal, you can maximize the window and then close the terminal by the \"exit\" command. When you Ctrl+Alt+T again it will automatically open maximized.\nThis can be applied to any size, just set the size you want, \"exit\" and then open again.\n\nA: Just add a custom shortcut.\nGo to Settings > Devices >  Keyboard,  scroll down to the end of the list and click on the + to add your shortcut.\nGive it a name and in the command section type gnome-terminal --maximize and add your preferred keyboard shortcut combination. \n\nA: You can probably modify your shortcuts to use the maximize one so that it always starts that way.\nThe easiest way of doing so is to locate your application (in /usr/share/applications or ~/.local/share/applications) and to modify your .desktop file.\nIn that .desktop file, you will see the line that starts  with Exec=.... To start gnome-terminal maximized, all you need to do is to add --start-maximized to the end of the command.\n", "Q: How to easily resize images via command-line? I would like to know how to resize images in Ubuntu. What is the easiest tool to do so?\n\nA: GIMP is probably the easiest way, since it has a fairly simple UI for such common tasks. All you have to do is open up your image and go to Image → Image Size and then change accordingly. There are ways to do batch resizing using the GIMP as well, but I don't know them by heart.\n\nA: Install gthumb. Simple and easy for basic image handling and editing functions - viewer, resizing, cropping, rotate, flip, grayscale, etc with options to save in  JPEG, PNG, TIFF, TGA formats.  \nTo install gthumb:\n\n\n*\n\n*Open your terminal\n\n*Type sudo apt-get install gthumb\n\n*Accept the changes\n\n\nA: You can also use the ubiquitous ffmpeg (or avconv) tool to resize images:\nffmpeg -i image.jpg -s 4096x2048 image-resized.jpg\n\nAnd if you want really fast JPEG image resizing - try epeg (as mentioned here and there) - which needs to be built from source.\n\nA: For GUI, Phatch \"one click is worth thousand photos\" is the best for such quick job.\nIt is already in Ubuntu repository. It has plenty of actions and options as imagemagick.\nsudo apt-get install phatch\n\nUpdate:\nPhatch project is DISCONTINUED unfortunately, last code commit was on  2011-01-24. It is on LP/Launchpad (Frameworks: Python2/PyGTK2.8)\n\nA: There is a good multiplatform tool called XnConvert. Combine and choose between more than 80 different operations. The installation is simple through deb. file from the official website.\nIt is free but not opensource, perhaps that's just the beauty of it.\n\n\nA: First install ImageMagick via:\nsudo apt-get install imagemagick\n\nOpen a terminal and run this command:\nconvert  -resize 20% source.png dest.jpg\n\nIt will reduce the size to 20%.\nNote that the reduction is not by 20%.\nThe resulting image will be much smaller, 20% of the former size,\nnot 20% smaller than before, not much smaller.\nYou can also specify the size:\nconvert -resize 1024X768  source.png dest.jpg\n\nYou can also use: mogrify command-line tool from the same package.\n\nA: If you're just doing a couple of images, most image editors in Ubuntu (Gimp, F-Spot, etc) will let you do a basic resize.\nIf you want to edit tens, hundreds or thousands of images, I prefer Phatch. Phatch is a GUI-based batch photo editor that will let you perform a whole load of transformations on images. sudo apt-get install phatch\nImageMagick is good but it's a bit tedious if you don't know the setting names for things. You can very quickly learn Phatch by clicking around.\n\nA: nautilus-image-converter is a nautilus extension to mass resize or rotate images. To install nautilus-image-converter in all currently supported versions of Ubuntu open the terminal and type:\nsudo apt install nautilus-image-converter\n\nIt adds two context menu items in nautlius so you can right-click and choose \"Resize Image\".\n(The other is \"Rotate Image\").\nYou can do a whole directory of images in one go if you like and you don't even have to open up an application to do so.\nYou need to restart your nautilus to see new context menus, run nautilus -q and then click the Home folder icon to reload nautilus with the new plug-in.\n\nA: ImageMagick is the package you want. It contains a number of useful command line tools for this very purpose.\nHere's a simple tutorial explaining how to batch resize images:-\nmogrify -resize 320x240 *.jpg\n\n\nAfter this command is completed, all of the images will be replaced with resized version of themselves. Notice that in an effort to preserve the image aspect ratio, mogrify may not be produce images that are exactly 320x240. To force this to happen, modify the original command to by placing an exclamation point at the end of the desired resolution:\n\nmogrify -resize 320x240! *.jpg\n\n\nA: sudo apt-get install imagemagick\n\nThe command mogrify overwrites the original files with the resized images:\nmogrify -resize 50% *.png      # keep image aspect ratio\nmogrify -resize 320x240 *.png  # keep image aspect ratio\nmogrify -resize 320x240! *.png # don't keep image aspect ratio\nmogrify -resize x240 *.png     # don't keep image aspect ratio\nmogrify -resize 320x *.png     # don't keep image aspect ratio\n\nNote: You can add -auto-orient to automatically orient converted images.\n\nA: No need to install any new software just do this\nconvert -resize 50% myfigure.png myfigure.jpg\n\nor\nconvert myfigure.png -resize 200x100 myfigure.jpg\n\n\nA: At the moment nautilus-image-converter does not work in Ubuntu 13.10. Therefore I use imagemagick on the command line, which is very good workaround (at least for me).\nsudo apt-get install imagemagick\n\nKeep in mind the difference between these imagemagick tools:\n\n\n*\n\n*Mogrify does processing on the same image, it reads file modify file\nand writes the output to the same file.\n\n*Convert is meant to work on\nseparate images, reads file and modify and write to different\nfile/format. You can also use convert command to use output file same\nas input file.\n\n\nI often use mogrify to simply resize multiple images and overwrite the original files. I. e. this command would scale down the dimension of all JPG files to 40% of the original dimension:\nmogrify -verbose -resize '40%' *.JPG\n\n\nA: open the image in ImageMagick.\n\n\n*\n\n*click on the image command box will be open.\n\n*view->resize enter the pixel you want. click on resize button.\n\n*File-> save, enter the name. click on Format button choose the format you want and click select button.\n\n*click on save button.\n\n\nanother option is\nselect view -> original image and Drag the corners of the image to resize it. select File -> save.\n\nA: I use Pimagizer. It works great and it is the easiest application I have used. Tested on Ubuntu 14.04, 15.04, 15.10.\nsudo add-apt-repository ppa:vfrico/stable\nsudo apt-get update\nsudo apt-get install pimagizer\n\nSee : https://launchpad.net/pimagizer/ for more infos.\n", "Q: vmware/virtualbox 3d acceleration Can Ubuntu guests get 3d acceleration in vmware / virtual-box? I just want to enable desktop effects under virtualization, not 3D games.\n\nA: There is a nice tutorial for 3D acceleration in virtualbox here.\n", "Q: Execute script before shutting down When I shut down my computer I want to show some pending tasks that I have to do before leaving the office...  I did a local application to manage those tasks, basically I just want to run a command, and shut down after I kill the app executed.\n\nA: You could add your command to the file /etc/gdm/PostSession/Default before the exit 0 line.\n\nA: You can do this by creating a script in /etc/rc0.d (for shutdown) and /etc/rc6.d (for reboot).\nTo do this, run:\ngksu gedit /etc/rc0.d/K01mycustomscript\n\nEdit your shutdown script in the text editor then run:\nsudo chmod +x /etc/rc0.d/K01mycustomscript\n\nAnd if you want it to run on reboot also then run this:\nsudo cp /etc/rc0.d/K01mycustomscript /etc/rc6.d/K01mycustomscript\n\nSource: this forum thread\n\nA: Sounds like a question for superuser.com to me. Anyway, after some Googling I found How to run a script on logout? which says to add the script to $HOME/.bash_logout.\nIf that doesn't work, add\n$HOME/.bash_logout\n\nto /etc/gdm/PostSession/Default so it executes the logout script properly.\nSeeing as before shutdown the user is logged off anyway, this should cover both bases.\n\nA: If you do ./app-to-run && sudo shutdown -h now the computer should shut down once app-to-run is done.\n\nA: Almost same answer than Tommy Brunn but without the risk to hang with being asked the root password :\nsudo sh -c \"./app-to-run; shutdown -h now\"\n\n", "Q: When will GTK improvements land in Maverick? I want to see CSD(Client Side Decorations),Windicators and RGBA.\n\nA: It will land in Maverick when it is ready. No sooner, no later.\n", "Q: How can I make shutdown not require admin password? If more than one person is logged in on my computer, Ubuntu requires super user authentication when shutting down the computer. How can I make it so that any user can shutdown the computer without being asked for a password?\n\nA: This works on 14.04. An updated variation of the previous, IMO, correct answer by Flimm.\nsudo mkdir -p /etc/polkit-1/localauthority/50-local.d\nsudoedit /etc/polkit-1/localauthority/50-local.d/allow_all_users_to_shutdown_reboot_suspend.pkla \n\nPaste this inside:\n[Allow all users to shutdown]\nIdentity=unix-user:*\nAction=org.freedesktop.login1.power-off-multiple-sessions\nResultActive=yes\n\n[Allow all users to reboot]\nIdentity=unix-user:*\nAction=org.freedesktop.login1.reboot-multiple-sessions\nResultActive=yes\n\n[Allow all users to suspend]\nIdentity=unix-user:*\nAction=org.freedesktop.login1.suspend-multiple-sessions\nResultActive=yes\n\n[Allow all users to ignore inhibit of shutdown]\nIdentity=unix-user:*\nAction=org.freedesktop.login1.power-off-ignore-inhibit\nResultActive=yes\n\n[Allow all users to ignore inhibit of reboot]\nIdentity=unix-user:*\nAction=org.freedesktop.login1.reboot-ignore-inhibit\nResultActive=yes\n\n[Allow all users to ignore inhibit of suspend]\nIdentity=unix-user:*\nAction=org.freedesktop.login1.suspend-ignore-inhibit\nResultActive=yes\n\n\nA: Richard Holloway's answer is not actually the way PolickKit authorisations are meant to be granted. The files installed under /usr/share/polkit-1/actions are not meant to be modified. Instead, you should modify the authorities under /etc/polkit-1/localauthority/50-local.d/.\nHere's how you do it for this question:\nCreate a file named /etc/polkit-1/localauthority/50-local.d/allow_all_users_to_shutdown.pkla and edit it using sudoedit to look like this:\n[Allow all users to shutdown]\nIdentity=unix-user:*\nAction=org.freedesktop.consolekit.system.stop-multiple-users\nResultInactive=no\nResultActive=yes\n\nThen create another .pkla file in the same directory. Use any name you like ending with .pkla, for example, allow_all_users_to_restart.pkla, and fill it with these contents:\n[Allow all users to restart]\nIdentity=unix-user:*\nAction=org.freedesktop.consolekit.system.restart-multiple-users\nResultInactive=no\nResultActive=yes\n\nReferences:\n\n\n*\n\n*polkit Reference Manual: pklocalauthority\n\n*ArchWiki page on PolicyKit\n\nA: You do not need a workaround, just change the policy to allow you to shut down without authenticating as admin for shutdown and reboot when multiple users are logged in.\nEdit the file /usr/share/polkit-1/actions/org.freedesktop.consolekit.policy using your favorite text editor. You will need root permissions.\nChange the section relating to shutdown when others are logged in from\n  <action id=\"org.freedesktop.consolekit.system.stop-multiple-users\">\n    <description>Stop the system when multiple users are logged in</description>\n    <message>System policy prevents stopping the system when other users are logged in</message>\n    <defaults>\n      <allow_inactive>no</allow_inactive>\n      <allow_active>auth_admin_keep</allow_active>\n    </defaults>\n  </action>\n\nto\n  <action id=\"org.freedesktop.consolekit.system.stop-multiple-users\">\n    <description>Stop the system when multiple users are logged in</description>\n    <message>System policy prevents stopping the system when other users are logged in</message>\n    <defaults>\n      <allow_inactive>no</allow_inactive>\n      <allow_active>yes</allow_active>\n    </defaults>\n  </action>\n\nand the section relating to rebooting when others are logged in from \n  <action id=\"org.freedesktop.consolekit.system.restart-multiple-users\">\n    <description>Restart the system when multiple users are logged in</description>\n    <message>System policy prevents restarting the system when other users are logged in</message>\n    <defaults>\n      <allow_inactive>no</allow_inactive>\n      <allow_active>auth_admin_keep</allow_active>\n    </defaults>\n  </action>\n\nto \n  <action id=\"org.freedesktop.consolekit.system.restart-multiple-users\">\n    <description>Restart the system when multiple users are logged in</description>\n    <message>System policy prevents restarting the system when other users are logged in</message>\n    <defaults>\n      <allow_inactive>no</allow_inactive>\n      <allow_active>yes</allow_active>\n    </defaults>\n  </action>\n\nAnd that will allow you shutdown and reboot the PC when multiple users are logged in.\nWhether you want to do that is a different question.\n\nA: There is a better way. If you have dbus-send installed, you can shutdown via dbus without the need to escalate to root privileges.\nI can't remember the page where the documentation is, but one Archlinux user figured this out.\nShutdown:\ndbus-send --system --print-reply --dest=org.freedesktop.Hal \\\n          /org/freedesktop/Hal/devices/computer \\\n          org.freedesktop.Hal.Device.SystemPowerManagement.Shutdown\n\nReboot:\ndbus-send --system --print-reply --dest=org.freedesktop.Hal \\\n          /org/freedesktop/Hal/devices/computer \\\n          org.freedesktop.Hal.Device.SystemPowerManagement.Reboot\n\nSuspend:\ndbus-send --system --print-reply --dest=org.freedesktop.Hal \\\n          /org/freedesktop/Hal/devices/computer \\\n          org.freedesktop.Hal.Device.SystemPowerManagement.Suspend int32:1\n\nHibernate:\ndbus-send --system --print-reply --dest=org.freedesktop.Hal \\\n          /org/freedesktop/Hal/devices/computer \\\n          org.freedesktop.Hal.Device.SystemPowerManagement.Hibernate\n\nRegards.\n\nA: HAL seems to be now depcrecated and not installed in latest Ubuntu releases.\nYou must use ConsoleKit and UPower dbus services to manage power state\nShutdown:\ndbus-send --system --print-reply --dest=\"org.freedesktop.ConsoleKit\" /org/freedesktop/ConsoleKit/Manager org.freedesktop.ConsoleKit.Manager.Stop\n\nRestart:\ndbus-send --system --print-reply --dest=\"org.freedesktop.ConsoleKit\" /org/freedesktop/ConsoleKit/Manager org.freedesktop.ConsoleKit.Manager.Restart\n\nSuspend:\ndbus-send --system --print-reply --dest=\"org.freedesktop.UPower\" /org/freedesktop/UPower org.freedesktop.UPower.Suspend\n\nHibernate:\ndbus-send --system --print-reply --dest=\"org.freedesktop.UPower\" /org/freedesktop/UPower org.freedesktop.UPower.Hibernate\n\nThanks to Arch Linux forums.\nThis works for now in Precise and Quantal, but don't know for how long since the Freedesktop focus seems to be shifted from ConsoleKit to systemd. Don't know whether Canonical cares...\n\nA: There is no way to circumvent the prompt for a superuser password when rebooting while other users are logged in short of opening a terminal window and issuing the reboot command as root:\nsudo reboot\n\nEven still, if not configured to bypass password prompting for your user account, sudo will also prompt you for your password.\nDon't worry, these are GOOD things.  Rebooting should be rare and a simple admin password prompt saves accidentally hosing yourself!\n\nA: I believe this is only an issue when doing it through the command line. \nIf so here is a link that can help with your problem. \n\nA: Add halt and/or reboot into sudoers file assigned to the group/user you wish to allow to perform this task. That way you can still control who can shutdown, but without giving them full root access to the machine..\nhttp://linux.byexamples.com/archives/315/how-to-shutdown-and-reboot-without-sudo-password/\n\nA: Apparently, you are able to shut down without root from the GUI because gdm runs as root. Gnome tells gdm to shut down, and gdm does it.\nYou could do something similar with a script. I'm not sure how handy you are with BASH, but I believe one could write a script that runs as root and, when it receives a certain signal, runs the shutdown command.\nKeep in mind that this may pose a security problem.\n", "Q: How to setup a wireless connection with an Eee PC 1005? How to setup wireless in ubuntu 10.04 netbook edition in EEpc 1005? Do I need to install some drivers and how?\nPS I am running ubuntu dual boot with XP (in XP have wireless Internet)\n\nA: I have a 1005HA, and wireless worked out of the box. I did have to specifically enable wireless in the BIOS for it to work though, for some reason it came disabled!\n\nA: according to this link, wireless and various other pieces of hardware should work out of the box. If you install with wubi this might have causes some issues from my experience that is usually the cause. \nI hope the link is helpful.\n\nA: I think the wireless for that model needs to use Windows wireless drivers using ndiswrapper.\nThis forum thread discusses this issue for a similar model.\nAlso see this documentation.\n", "Q: What is the \"recovery\" option in the grub menu? I have a Ubuntu 10.04 and Windows 7 dual boot system. On boot, the grub menu appears. I see \"Windows 7\" and the normal \"Ubuntu 10.04\" but there's also a \"Ubuntu 10.04 (Recovery)\".\nWhat is the recovery option for? What does it do differently?\n\nA: Recovery mode boots up with basic services and drops you to a command line as root. From there you can repair any problems that are preventing you from booting Ubuntu normally.\nUsing recovery mode requires a little experience with the command line.\n\nA: The recovery option boots to a text mode screen which allows you to do some maintenance tasks. This can be useful if you need to reset your password, or your hard disk needs checking, or perhaps to troubleshoot an issue with the graphics driver.\n", "Q: How to create clickable notifications using pynotify? Is it possible to show notifications displayed in right top (like these about being connected to a wifi), that can be clicked? Right now I can either create a notification, that can't be clicked or create an ugly notification (a dialog box), that can. I would like to have something non-obtrusive, that can be clicked and perform some action then.\n\nA: Here are some Guidelines for developing Notifications\nUbuntu Wiki\n\nA: I don't think that's possible, as Notify-OSD doesn't support actions. \n\nA: This would be an ideal candidate for morphing windows. Unfortunately they are not implemented yet.\n", "Q: How can I install Ubuntu without CD? My CD drive is broken,so I can't install Ubuntu from a CD.\nAre there any workarounds for that?  \n\nA: There are several options for installing without a CD drive.\nWubi\nIf you have Windows installed already, you can use Wubi. Wubi installs Ubuntu as an application inside Windows.\nUSB Flash Drive\nAlternatively, you can also install Ubuntu from a USB disc. You'll need a USB flash drive, and Ubuntu live CD ISO, and a program to transfer it to the flash drive.\nMaking a USB startup drive\nIf you have Ubuntu installed, you can use the Ubuntu USB Creator, which is in the System > Administration menu.\nIf you only have Windows installed, you can use Unetbootin to do the same job.\nBooting the drive\nOnce you have a bootable USB drive, you simply have to plug it in and during bootup specify it as the boot device. There are instructions on the Ubuntu wiki On how to boot from a USB drive. Once it's booted, it acts just like a live CD.\n\nA: There are lots of possibilities. The easiest is probably using a USB stick. For more information of installation options please refer to https://help.ubuntu.com/community/Installation\n\nA: Wubi will allow you to install Ubuntu while keeping Windows installed. If at anytime you decides he does not like Ubuntu you can uninstall it just like a normal program and it will give him his space back. If you does any other install it will be much harder to uninstall. You'll have to use the Disk Management tool and delete the partition and then extend the Windows partition. In order to get Wubi you can download it at http://wubi-installer.org/ or download the current Ubuntu release and then use 7-Zip to extract the ISO and then click on wubi.exe. An installer should appear and he can follow the instructions from there. It's very simple for even the most non-tech users.\n\nA: I am using Unetbootin in order to  create a bootable USB.\n", "Q: Is there a directory of Wine compatible software? Is there a website that lists software that runs well, or not well, under Wine?\n\nA: Yes, you can find compatibility reviews at the Wine Application Database.\nNot only can you find compatible software, you can submit your own apps and reviews to help others.\n", "Q: How to sync iDevices on Pre Ubuntu 10.04? Is there any way to sync iDevices on Karmic,Jaunty and Hardy?\n\nA: Yes, there are instructions here: https://help.ubuntu.com/community/PortableDevices/iPhone\n", "Q: How to restart X Window Server from command line? How can I restart X Window Server from the command line?\nI'd really like to be able to restart my GUI without having to do a full system reboot.\n\nA: Since ubuntu 9.04 Ctrl+Alt+Backspace is disabled, however you can now type Alt gr + Print Screen + K.\nhttp://www.sudo-juice.com/ubuntu-11-10-restart-x-shortcut/\n\nA: For 11.04 and earlier:\nsudo service gdm restart\nFor 11.10 and later:\nsudo service lightdm restart\n\nA: NOTE: This will forcefully quit all graphical programs, you'll lose any unsaved work, and you'll be logged out. Non-graphical programs will not be affected.\nTL;DR: on systems with systemd (Ubuntu 15.04 and newer)\nsudo systemctl restart display-manager\n\nThis will restart the appropriate display manager service (lightdm till 17.04, gdm3 after, sddm in Kubuntu, etc.). You can replace display-manager with lightdm, gdm3, sddm, etc. if needed, but this should be enough.\n\nFor other Ubuntu versions, first find which display manager your ubuntu is having with following command:\ncat /etc/X11/default-display-manager\n\nThan depending on what display manager, you can use one of the following commands:\n\n\n*\n\n*Default Ubuntu (with LightDM)\nsudo systemctl restart lightdm  \n\n\n*Gnome (with GDM)\nsudo systemctl restart gdm\n\n\n*KDE (with KDM)\nsudo systemctl restart kdm\n\nNote: From 12.10 to 15.04, Kubuntu also uses LightDM.\n\n*For MDM (e.g. for Mint Cinnamon)\nsudo systemctl restart mdm\n\n\nA: Found out that you can do\nsudo pkill X\nand it seems to work for me!\n\nA: You can try pressing Ctrl+Alt+Backspace to restart X.\n\nA: Newest version of Ubuntu as of 24 Oct, 2012.\n\n\n*\n\n*Open Dash Home\n\n*Search for keyboard layout\n\n*Click Options\n\n*Expand tab labelled \"Key sequence to kill the X server\"\n\n*Enable it and Close.\n\n\nCommand Line:\nsudo restart lightdm\n\n\nA: For KDE:\nsudo systemctl restart sddm.service\n\n", "Q: How do I determine the total size of a directory (folder) from the command line? Is there a simple command to display the total aggregate size (disk usage) of all files in a directory (folder)?\nI have tried these, and they don't do what I want:\n\n\n*\n\n*ls -l, which only displays the size of the individual files in a directory, nor \n\n*df -h, which only displays the free and used space on my disks.\n\n\nA: This finds the size recursively and puts it next to each folder name, along with total size at the bottom, all in the human format\ndu -hsc *\n\n\nA: The answers have made it obvious that du is the tool to find the total size of a directory. However, there are a couple of factors to consider:\n\n\n*\n\n*Occasionally, du output can be misleading because it reports the space allocated by the filesystem, which may be different from the sum of the sizes of the individual files. Typically the filesystem will allocate 4096 bytes for a file even if you stored just one character in it!\n\n*Output differences due to power of 2 and power of 10 units. The -h switch to du divides the number of bytes by 2^10 (1024), 2^20 (1048576) etc to give a human readable output. Many people might be more habituated to seeing powers of 10 (e.g. 1K = 1000, 1M = 1000000) and be surprised by the result.\nTo find the total sum of sizes of all files in a directory, in bytes, do:\nfind <dir> -ls | awk '{sum += $7} END {print sum}'\n\nExample:\n$ du -s -B 1\n255729664\n\n$ find .  -ls | awk '{sum += $7} END {print sum}'\n249008169\n\n\nA: To see the sizes of all files and directories, use\ndu -had1 dir/\n\n(maybe like \"do you had 1\")\n\n*\n\n*du: device/disk usage\n\n*-h: human readable sizes\n\n*-a: show files, not just directories\n\n*-d1: show totals only at depth 1, i.e. the current directory's contents\n\nFor the current directory, the directory argument can be left off.\ndu -sh dir/* has the same effect but doesn't show hidden files and directories due to shell globbing.\n\nA: You can use the tool Dust:\nPS C:\\git> dust\n   0B       ┌── templates           │                                      █ │   0%\n   0B     ┌─┴ git-core              │                                      █ │   0%\n   0B   ┌─┴ share                   │                                      █ │   0%\n  76B   ├── readme.md               │                                      █ │   0%\n 156K   │   ┌── less.exe            │▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒█ │   2%\n 2.7M   │   ├── git-remote-https.exe│▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒█████████████████ │  42%\n 3.6M   │   ├── git.exe             │▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██████████████████████ │  56%\n 6.5M   │ ┌─┴ git-core              │███████████████████████████████████████ │ 100%\n 6.5M   ├─┴ libexec                 │███████████████████████████████████████ │ 100%\n 6.5M ┌─┴ .                         │███████████████████████████████████████ │ 100%\n\nMy example is from Windows, but Linux and Apple are also supported:\nhttps://github.com/bootandy/dust\n\nA: If your desired directory has many sub-directories then, use the following:\n$ cd ~/your/target/directory\n$ du -csh \n\n\n-c, --total           produce a grand total\n  -s, --summarize       display only a total for each argument\n  -h, --human-readable  print sizes in human readable format (e.g., 1K 234M 2G)\n\nwhich would then produce a overall total of the memory usage by all files/folders in the current directory.\n\nA: I'm conditioned to the ll command which is aliased to ls -alF. It is just missing a file count and size of files at the bottom. I played with du and tree but could not get the totals I needed. So I created lll to do that for me.\nIn your ~/.bashrc place the following:\nlll () {\n    ls -alF \"$@\"\n    arr=($(ls -alF \"$@\" | awk '{TOTAL+=$5} END {print NR, TOTAL}'))\n    printf \" \\33[1;31m ${arr[0]}\\33[m line(s).  \"\n    printf \"Total size: \\33[1;31m ${arr[1]}\\33[m\\n\"\n#    printf \"Total size: \\33[1;31m $(BytesToHuman <<< ${arr[1]})\\33[m\\n\"\n}\n\nSave the file and resource it using . ~/.bashrc (or you can restart your terminal).\n\nSample output\nThe nice thing about ll output is it's colors. This is maintained with lll but lost when using find or du:\n\n\nTL;DR\nA bonus function you can add to ~/.bashrc is called BytesToHuman(). This does what most console users would expect converting large numbers to MiB, GiB, etc:\nfunction BytesToHuman() {\n\n    # https://unix.stackexchange.com/questions/44040/a-standard-tool-to-convert-a-byte-count-into-human-kib-mib-etc-like-du-ls1/259254#259254\n\n    read StdIn\n\n    b=${StdIn:-0}; d=''; s=0; S=(Bytes {K,M,G,T,E,P,Y,Z}iB)\n    while ((b > 1024)); do\n        d=\"$(printf \".%02d\" $((b % 1024 * 100 / 1024)))\"\n        b=$((b / 1024))\n        let s++\n    done\n    echo \"$b$d ${S[$s]}\"\n\n} # BytesToHuman ()\n\nNext flip the comment between two lines in lll () function to look like this:\n#    printf \"Total size: \\33[1;31m ${arr[1]}\\33[m\\n\"\n    printf \"Total size: \\33[1;31m $(BytesToHuman <<< ${arr[1]})\\33[m\\n\"\n\nNow your output looks like this:\n\nAs always don't forget to re-source with . ~/.bashrc whenever making changes. (Or restart the terminal of course)\nPS - Two weeks in self-quarantine finally gave me time to work on this five year old goal.\n\nA: Recently I found a great, ncurses based interactive tool, that quickly gives you an overview about directory sizes. Searched for that kind of tool for years.\n\n*\n\n*quickly drilldown through file hierarchy\n\n*you can delete e.g. huge temporary files from inside the tool\n\n*extremely fast\n\nThink of it as baobab for the command line:\napt-get install ncdu\n\nEdit:\nYou can restrict the search to files in the same filesystem, use -x:\nncdu -x /\n\nthis will ignore other mounted filesystems outside where the root filesystem is hosted.\nA slightly optimization is using the '-q' option to increase the time between screen updates. The options can be combined:\nncdu -xq /var\n\nAs always, reading man ncdu is recommended.\n\nA: Enjoy!\ndu foldername\n\nMore information on that command here \n\nA: Below is what I am using to print total, folder, and file size:\n$ du -sch /home/vivek/* | sort -rh\n\nDetails\n ------------------------------------------------------------\n   -c, --total\n          produce a grand total\n   -h, --human-readable\n          print sizes in human readable format (e.g., 1K 234M 2G)\n   -s, --summarize\n          display only a total for each argument\n -------------------------------------------------------------\n   -h, --human-numeric-sort\n          compare human readable numbers (e.g., 2K 1G)\n   -r, --reverse\n          reverse the result of comparisons\n\nOutput\n 70M    total\n 69M    /home/vivek/Downloads/gatling-charts-highcharts-bundle-2.2.2/lib\n992K    /home/vivek/Downloads/gatling-charts-highcharts-bundle-2.2.2/results\n292K    /home/vivek/Downloads/gatling-charts-highcharts-bundle-2.2.2/target\n 52K    /home/vivek/Downloads/gatling-charts-highcharts-bundle-2.2.2/user-files\n\n\nA: For only the directory size in a readable format, use the below:\ndu -hs directoryname\n\nThis probably isn't in the correct section, but from the command line, you could try:\nls -sh filename\n\nThe -s is size, and the -h is human readable.\nUse -l to show on ls list, like below:\nls -shl\n\n\nA: The command du \"summarizes disk usage of each FILE, recursively for directories,\" e.g.,\ndu -hs /path/to/directory\n\n\n\n*\n\n*-h is to get the numbers \"human readable\", e.g. get 140M instead of 143260 (size in KBytes)\n\n*-s is for summary (otherwise you'll get not only the size of the folder but also for everything in the folder separately)\n\n\n\nAs you're using -h you can sort the human readable values using\ndu -h | sort -h\n\nThe -h flag on sort will consider \"Human Readable\" size values.\n\nIf want to avoid recursively listing all files and directories, you can supply the --max-depth parameter to limit how many items are displayed. Most commonly, --max-depth=1\ndu -h --max-depth=1 /path/to/directory\n\n\nA: tree is another useful command for this job:\nJust install it via sudo apt-get install tree and type the following:\ntree --du -h /path/to/directory\n...\n...\n\n33.7M used in 0 directories, 25 files\n\nFrom man tree:\n-h    Print  the size of each file but in a more human readable way, e.g. appending a size letter for kilo‐\n      bytes (K), megabytes (M), gigabytes (G), terabytes (T), petabytes (P) and exabytes (E).\n\n--du  For each directory report its size as the accumulation of sizes of all its files and  sub-directories\n      (and their files, and so on). The total amount of used space is also given in the final report (like\n      the 'du -c' command.)\n\n\nA: du /foldername is the standard command to know the size of a folder. It is  best practice to find the options by reading the man page:\nman du\n\nYou should read the man page (available online) before you use the command.\n", "Q: What's the advantage of using Ubuntu One vs. other services like Dropbox? What features does Ubuntu One provide that others services do not have? Can I use Ubuntu One only on Ubuntu machines? What about sharing data/folders with others who do not have Ubuntu One?\n\nA: One advantage of using Ubuntu One is that eventually many of your settings will be saved in a CouchDB database and shared between all your machines (should you choose to allow it). You can do this manually using Dropbox or similar services, but with Ubuntu One, it should be more or less automatic.\n\nA: One disadvantage of Ubuntu One is that you are stuck with a directory \"Ubuntu One\" (spaces and capitals, ugh) in your home directory that you can't remove. According to the Ubuntu bug tracker, the solution is to remove U1 completely. \nDropbox allow you to put their \"Dropbox\" directory anywhere.  I put it $HOME/.db/Dropbox then have a symbolic link  $HOME/dropbox to it. \n\nA: Ubuntu One has several advantages over Dropbox and other services.\nSynchronisation\nLike other services, Ubuntu One allows synchronisation of files across machines and does this by synchronising any file you put in the ~/Ubuntu One folder. In addition, it allows you to synchronise all of the files in any folder in your home folder. However, it lacks the ability to synchronise files using symlinks.\nA particular feature that Ubuntu One has that is lacking in other services is the synchronisation of your desktopcouch databases. Some applications use these databases to store data and settings. This allows automatic synchronisation between applications on multiple machines. Examples of such applications include Tomboy (which synchronises its notes) and Evolution (which synchronises contacts).\nStorage Amount and Pricing\nUbuntu One provides a relatively generous 5GB of free storage compared to 2GB provided by Dropbox and SpiderOak and 1GB provided by Wuala. With Ubuntu One you can add 20GB increments for 2.99 USD/month. This allows flexible pricing that is more cost effective than Dropbox or Wuala. (See Comparison).\nPlatform Support\nThe Ubuntu One client is available on Ubuntu and Ubuntu based distributions and should theoretically work on most other distributions. A beta is available for Windows. There are also apps available for Android and iOS. \nThere is also a rudimentary web interface for accessing and publishing files. The publishing feature allows you to share files with people who don't have Ubuntu One.\nThis is not as many platforms as, for example, Dropbox so this may be a disadvantage if you use multiple platforms.\nMusic\nUbuntu One provides a music store and allows music streaming via smartphone applications. The music streaming costs money. Other services do not support this.\nFreedom\nThe Ubuntu One client is free software, although the server is proprietary.\n\nA: The paid Ubuntu One service helps subsidize Canonical, which means that (theoretically) signing up with U1 helps improve the platform. \n\nA: For me, Ubuntu One has one very significant feature - share/sync any folder inside your home folder, so you don't need to use the main single folder like Dropbox does (I mean a folder which is used for all your Dropbox shares).\nRegards.   \n\nA: The most important thing for me is that I can sync all my config files - outside the ubuntu one folder. Dropbox can't.\nAnd the second thing is that Im supporting Canonical (Im a paid user).\n\nA: As for security, Dropbox does encrypt the files, but they possess the keys and reserve the right to allow the U.S state to see what you are holding. Since they possess the keys it means that hackers could also get them. Ubuntu One does no encryption. However it is possible to encrypt data on your own machine prior to syncing it with Ubuntu One and it will be safe since you alone would possess the key. There is another service called Wuala that does encryption, while making sure that they have no knowledge of the encryption key. They store the data in several European countries in a peer-to-peer thingy for redundancy, they offer a Linux client and the servers are run on 100% green energy!\n\nA: Canonical closed down Ubuntu One cloud file services 2014:\nhttp://blog.canonical.com/2014/04/02/shutting-down-ubuntu-one-file-services/\n\nA: Dropbox is cross platform. It has a html folder for hosting webpages. I believe you can only use ubuntu one on linux machines. \nUbuntu one is good for sharing between ubuntu machines; but if you have a dropbox account, you should be good. :)\n", "Q: What's the meaning of version numbering of Ubuntu? What's the meaning of the numbering for different versions? Do they signify something?\n\nA: It means the month it is released, ie 04 = April, 10 = october\n\nA: ...and don't forget the upcoming Point-Release 10.04.1 which summarize all the updates (and bugfixings) since the Release-Day. So you don't have to patch a new installed system with hundreds of MBytes. On August 12 2010 the 10.04.1 will be available.\n\nA: Ubuntu releases on a time based schedule. At the time Ubuntu was started the GNOME project had already established a regular release schedule every 6 months, usually September and March. So Ubuntu's schedule was \"when GNOME releases, plus a little bit more to put it into Ubuntu.\"\nThe way it worked out is Ubuntu released on Aprils (hence the .04) and Octobers (.10). And it's been that way ever since, with the exception for 6.06, which had to be delayed until June due to some delays.\nAs it ends up releasing in the spring and fall fits nicely in the calendar and there's never been a need to shift the schedule.\nAlso worth noting: the first number is the year of the release.\n\nA: Yes. The first number is the year the distribution was released (so 09 means 2009), and the second number is the month it was released. Therefore, the upcoming 10.10 version will be released in October 2010.\n\nA: Apart from the points mentioned in other answers, there are few more things to add:\n\n\n*\n\n*Starting with Ubuntu 12.04 LTS, LTS releases will be supported for 5 years on both the desktop and the server. Previous Ubuntu LTS (Long Term Support) releases are supported for 3 years on the desktop and 5 years on the server.\n\n*Each Ubuntu version has a fancy animal name, along with an adjective. Apart from those listed above, we have few more.\n\n\n\nAdjective        Animal         Version   \nQuantal          Quetzal        12.10\nRaring           Ringtail       13.04\n\n\n\n*\n\n*Quick references: \n\n*\n\n*Ubuntu Releases \n\n*Release Schedule \n\n*DevelopmentCodeNames\n\n*LTS\n\nA: Additionally they also have code names usually some sort of adjective and an animal name here is a list of all the Ubuntu versions including the next one.\n\nVersion    Name             Release Date  \n4.10       Warty Warthog    2004-10-20\n5.04       Hoary Hedgehog   2005-04-08\n5.10       Breezy Badger    2005-10-13\n6.06LTS    Dapper Drake     2006-06-01\n6.10       Edgy Eft         2006-10-26\n7.04       Feisty Fawn      2007-04-19\n7.10       Gutsy Gibbon     2007-10-18\n8.04LTS    Hardy Heron      2008-04-24\n8.10       Intrepid Ibex    2008-10-30\n9.04       Jaunty Jackalope 2009-04-23\n9.10       Karmic Koala     2009-10-29\n10.04LTS   Lucid Lynx       2010-04-29\n10.10      Maverick Meerkat 2010-10-10\n11.04      Natty Narwhal    2011-04-28\n11.10      Oneiric Ocelot   2011-10-13\n12.04LTS   Precise Pangolin 2012-04-26\n\n\nA: Ubuntu follows a regular 6 month release cycle. The version numbers are formatted in Y.MM (10.04: April, 2010). Every two years there is a Long Term Support (LTS) version release which will be officially supported for two more years.\nThe last LTS was 12.04, the current LTS is 14.04, and the next LTS is 16.04 - the three releases between these LTS releases culminate into the next LTS, ideally viewed as \"6-month baby releases that piecemeal towards the next LTS\".\n\nTypically after each non-LTS release a point release is made for the current LTS designed to maintain stability and backport changes keeping an LTS release 'supported' These are denoted as a third version number (12.04.[1-4]).\nThis chart and more information can be found on the Ubuntu Wiki: LTS article.\n\nA: The first number is the two last digits of the current year.\n", "Q: What are some useful keyboard shortcuts? I would like to learn some useful keyboard shortcuts. I have become a ninja of keyboard shortcuts in Windows. \nAny must-have tips for Ubuntu?\nFeel free to include Ubuntu defaults or custom ones you have found useful!\n\nA: When I found out about Alt + Mouse 1 on an open Window. I went nuts moving windows is easy now.\nI also use Ctrl + Alt + (Left|Right) for switching workspaces.\nLastly I find myself using Super + Space which is the default binding for Gnome Do which I love.\nAlt + F2 is very handy for starting programs, it has auto-completion and prevents you from clicking though the menus.\n\nA: In Nautilus, you can have an extra pane by pressing F3. You get a Norton Commander kind of look.\n(I learned this here: Add options to \"Move to\" (when you right click on a file).)\n\nA: ctrl+alt+l(lock) to lock your desktop.\n\nA: ALT + F1 : launch applications menu, probably the most used keyword combination in my laptop.  \nALT + Home : Jump to home folder.  \nALT + Enter : Show file/folder properties.  \nALT + F2 : Launch \"run application\" dialog box.  \nALT + F4 : Close Window.  \nALT + Left/Right : Go back/forward while navigation directories in nautilus.  \nALT + Up/Down :  Go up/down while navigating directories in nautilus.  \nALT + Tab : Browse through windows.  \nShift + Del : Permanently delete files, no backing up in trash folder.  \nF2 : Rename File/Folder.  \nF3 : Enable split view in nautilus.  \nF8 : Show/hide nautilus menubar.  \nF9 : Toggle nautilus side-pane.  \nSuper + Tab : \"Shift switcher\", need to enable it in CCSM.  \nSuper + M : Inverts all the colors.  \nSuper + A or W : Arrange windows in a nice panel like appearance(Need Compiz).  \nCTRL + L : View/Edit full location path.  \nCTRL + A : Select all.  \nCTRL + N : New window.  \nCTRL + Shift + N : New folder.  \nCTRL + H : Show/hide hidden files.  \nCTRL + ALT + L : Lock Screen.  \nFrom http://www.techdrivein.com/2010/08/20-useful-ubuntugnome-keyboard.html\n\nA: If your system has become complete unresponsive to where even hitting CTRL+ALT+F1 doesn't give you a terminal, it is possible to still gracefully stop your machine and reboot.\nALT+SysReq+r : Raw keyboard mode\nALT+SysReq+s : Sync the disk\nALT+SysReq+e : Terminate all processes\nALT+SysReq+i : Kill remaining process\nALT+SysReq+u : Remount all filesystems as read only\nALT+SysReq+b : Reboot\n(Another way to kill all processes: ALT+SysReq+k)\n\nA: Ctrl+W: Close Window/Tab\nCtrl+Q: Quit Application\nAlt+F2: Open Run Application\nSuperKey+Space: Runs Gnome-Do if installed (Very Cool App)\n\nA: Once you get Compiz Fusion installed there are a ton of nifty keyboard shortcuts. It's like Exposé on Mac OS X, but even more powerful. I have shortcuts set up to flip between desktops, zoom out/show all windows, show the desktop, launch the console, etc. If you've never used Compiz check it out:\nhttp://wiki.compiz.org/CommonKeyboardShortcuts\n\nA: You can set up whatever keyboard shortcuts you want through System -> Preferences -> Keyboard Shortcuts. This will also tell you the current shortcuts. \nPersonally, I activate Ctrl+Alt+Backspace to restart the x server, use Ctrl+Alt+T to open a terminal, Ctrl+Alt+X as the xkill command so I can click on non-responding window to kill it and Ctrl+Alt+Delete to open the system monitor (a la Windows) instead of bringing up the shutdown prompt.\nThere is also a whole load of keyboard shortcuts set by compiz, which can be \nedited using compizconfig-settings-manager1 (installable from repositories).\nI find keyboard shortcuts to be a personal preference and we are lucky that Linux is so customisable as to allow whatever configuration we want.\n\nA: Haven't seen any shell related shortcuts yet, so here's a few I use a lot in bash:\nCtrl+R: Search incrementally backwards through command history.\nCtrl+T: Exchange characters under and behind the cursor.\nAlt+.: Insert last argument from previous command.\n\nA: Another few helpful shortcuts while in terminal:\nCtrl+Shift+C: Copy.\nCtrl+Shift+V: Paste.\nCtrl+Arrow Left: Move to the start of the previous string (for long commands).\nCtrl+Arrow Right: Move to the next non-alphabet character (eg, '/', '.', '_', '-', etc).\nArrow Up or Arrow Down: Scroll through history of commands.\n\nA: There's a fairly substantial list on the Ubuntu community wiki.\nhttps://help.ubuntu.com/community/KeyboardShortcuts\n\nA: ctrl-alt-d is useful for quickly minimizing/restoring all the applications on the desktop.\n\nA: Some shortcuts relating to the mouse:\n\n\n*\n\n*Alt + Left Mouse Button: move window\n\n*Alt + Middle Mouse Button: resize window\n\n*Super + Middle Mouse Button (drag): zoom to region of screen (Compiz)\n\n*Super + Mouse Wheel: zoom in (Compiz)\n\n*Mouse Wheel when at left or right screen edge: move viewport left or right (Compiz) (howto)\n\n*Middle Click on scroll bar: scroll immediately\n\n\nA: Alt + F7 Move windows without using the mouse.  \nAlt + F8 Resize window without using the mouse.  \nAlt + F9 Minimizes the focused window.  \nAlt + F10 Toggles maximize.  \nAlt + Tab Cycle through open windows (bouth windows minimized and not-minimized)\n\nA: I like using Ctrl + arrow keys to switch workspaces. I do it a lot. It's fun. I use Ctrl + Alt + arrow keys to move windows.\nSuper-T to open the terminal.\nI took a note from the guy above, and made an xkill shortcut--I use Ctrl + Alt + X.\nAlt + Tab is handy as always, but less so, as I just put things on different desktops.\nAs noted above, using compiz config is wise.\nAnyway, there's a reason you're able to customize them all. Get a feel for what you need to do, and how you want to do it. Come on, man, you're using Ubuntu. Go nuts.\n\nA: These might not be a shortcuts but they do involve using the keyboard: turn on Mouse Keys in Keyboard Preferences and by pressing Fn + [keys that have the same colour as the \"Fn\" label] you can control the pointer and simulate clicks and click-holds. Keynav is a program in the repositories that is used to control the pointer by using the keyboard to divide a window in half continually. Thus one can click a link with no more than 10 key presses (in the rare case that Vimium/Pentadactyl/Vimperator can't do the job). Long winded it is, but I haven't touched a mouse or trackpad in ages! \n\nA: Only vaguely on-topic, but I like rebinding the Caps Lock key to the Compose Key. Preferences > Keyboard > Layouts > Options > Compose Key Position, set to caps lock. Try it! Done? Now press Caps Lock, then apostrophe, then e. Voila, e with an accent. \n\nA: Alt+F1 to pop up a main menu at your mouse pointers position.\nAlt+F2 to execute commands.\n\nA: If you haven't looked through the emacs tutorial yet, you might want to.  It's got a bunch of keyboard shortcuts that apply to the bash prompt and throughout linux in general.\n$ emacs\nC-h t\nGood luck!\n\nA: Well, you can get go on System then Preferences and then Keyboard Shortcuts. You will see the ones that are in use and you can also edit to any key/keys you like or can remember easily...\n\nA: \nDefault keyboard shortcuts in Ubuntu 13.10\n", "Q: add default route on boot I'm trying to add a default route on my ppp0 connection, I want the default route points to that connection. I tried to add it in /etc/rc.local but I don't think that is the right place to do so. I would like to know where is the right place to accomplish this.\n\nA: The right place should be the file /etc/network/interfaces. You add a line like:\nup route add default gw 192.168.0.1 dev eth0\n\nThe IP address is the one of your default gateway and the last entry is the device name of your device.\n\nA: Already long time ago, but none of the above described solutions worked for me. I finally found the solution in the comments in the ip-up file under the /etc/ppp directory in Ubuntu.\nI created a script in the /etc/ppp/ip-up.d directory, where I put the route add command in.\nThe script is picked up automatically after the pptp connection was created. It works like a charm.\n\nA: If you are using Network Manager, you can add a route via the Configure VPN... menu option under the networking widget. Then on the VPN, click on edit for the VPN you need to add a route to. Then under IPV4 settings, change Method to Automatic VPN. Then click on routes and add your route there (eg network 192.168.1.0 netmask 255.255.255.0 gateway 192.168.1.20) where the gateway is the VPN server you are connecting to.\n\nA: Your default route for your primary interface?  This should be done by default if you're using DHCP. If you have a statically configured interface, you'll need to add a stanza to /etc/network/interfaces. Assuming your interface is eth0 and network is 192.168.1.0/24:\n# The primary network interface\nauto eth0 \n\niface eth0 inet static\naddress 192.168.1.123\nnetmask 255.255.255.0\ngateway 192.168.1.1\n\n(Obviously these numbers would be adjusted for your network.)\nAdd this to /etc/network/interfaces and that's it.  Now if you want a static route that is NOT your default route, that is different.\n", "Q: Is there a way to link a VPN (tun0) adapter to a fake physical (ethX) adapter? Is there a way to link a VPN (tun0) adapter to a fake physical (let's say ethX) adapter?\n\nA: Create a bridge interface.  Lots of howto's for that exist (depending on if you want to do it with OpenVPN, /etc/network/interfaces, etc)\n", "Q: Unable to update thunderbird I recently installed Thunderbird 3.1 from some source that wasn't the ubuntu repos. I can't remember right now where I got it from (I think it was packaged as a deb), but I'm having a problem when it tries to auto-update.\nUnlike the versions that manage their updates via the repos, this one is supposed to update itself whenever it needs to, which seemed fine, but whenever it tries, it pops up an error: \n\nA recommended security and stability update is available, but you do not have the system permissions required to install it. Please contact your system administrator, or try again from an account that has permission to install software on this computer. You can always get the latest version of Thunderbird at: http://mozillamessaging.com/en-US/thunderbird\n\nIs there a way to give TB the permissions it needs short of opening it as root?\n\nA: Nope. The only way to allow Thunderbird to update itself is to launch it as root, or to find yet another source that built Thunderbird in such a way that you can install it entirely within your own home folder.\nA better option, if you want to run cutting-edge apps, is to try to find someone making builds on the in a Launchpad PPA. These can update through the normal Synaptic/Upgrade system, which means you won't end up with corner cases like this. As it happens, the Mozilla team maintains a PPA of newer versions of Firefox and Thunderbird, including even nightlies. If you install Thunderbird 3.1 from there, you should be golden.\n\nA: I just updated. In terminal launch thunderbird:\nsudo thunderbird \nThen it updated with out a problem\nGood luck\nAnthony\n", "Q: How to set up Ubuntu Server as a NAS? I am looking to set up Ubuntu Server as a headless NAS for my home. I would like to have file storage there, as well as a central hub for my MP3s and pictures.\nWhat are the best packages out there to handle this? Can someone post a link to a good tutorial or post some tips?\nOne constraint I have is that it has to be Windows 7 friendly. By that I mean the shares and streaming should work for a Windows machine.\n\nA: For the filesystem, I have software RAID 5 across my drives, and encrypt the resulting filesystem.  This way, I can use this system as a backup server as well.\nOnce the system is up, I use plain ol' NFS and Samba for the file level access.  (apt-get install nfs-kernel-server samba).  I also have a PS3 that I like to stream media to, so I use mediatomb for that (apt-get install mediatomb), and my wife uses iTunes on her Mac and netbook, so I also install mt-daapd (apt-get install mt-daapd) to share my music over the daap protocol, which rhythmbox can also use.\n\nA: You might want to take a look at the Ubuntu based TurnKey File Server appliance. If you don't need a full-fledged appliance, you could use it as a reference for configuration on your own server.\n\nA: I just finished doing this myself and I did it using Samba.  I'm able to mount the samba shares from my windows & ubuntu computers\nHere are some links that helped me get started:\nhttps://help.ubuntu.com/community/SettingUpSamba\nhttp://ubuntuforums.org/showthread.php?t=280473\n\nA: Simples:\n\n\n*\n\n*Install Ubuntu Server. Really helps if you can have the server with a keyboard and monitor for this bit... Although you can script a CD to auto-install if you want. More trouble than it's worth if you ask me.\n\n*Create a user, set up ssh (sudo apt-get install openssh-server), etc. Put your server in its final resting place and ssh in from your desktop.\n\n*Install & configure samba (see the manual configuration section)\n\n*Optionally install NFS for linux clients (faster, less taxing on the server CPU in my experience)\n\n*Relax. You're done.\n\nA: Posting this so I can find it in the future.\nInstall Ubuntu Cloud VM (add an extra disk 1TB or larger.)\nNote:  you should replace username with your user.\nMount and Format the disk:\nlsblk\nsudo fdisk /dev/sdc\nn\np\nEnter defaults for rest of options\n\nMake the filesystem\nsudo mkfs -t ext4 /dev/sdc1\n\nMake a mount path:\nmkdir /home/username/data\n\nUpdate Fstab\nsudo echo \"/dev/sdc1 /home/username/data ext4 defaults 0 2\" >> /etc/fstab\n\nInstall the tools you need:\nsudo apt install vim screen htop sysstat curl wget\nsudo apt install nfs-server samba\n\nUpdate Exports for NFS (I'm setting this based on subnet, you can change as needed)\nsudo echo \"/home/username/data 192.168.1.0/24(rw,no_root_squash)\" >> /etc/exports\nsudo exportfs -a\n\nMake Cifs share:\nsudo vi /etc/samba/smb.conf\nshift+g\no\n\nPaste the following\n[data]\ncomment = Data\nbrowseable = yes\npath = /home/username/data\nguest ok = no\nread only = no\ncreate mask = 0700\n\nGenerate smbpasswd (this will allow windows hosts to connect over smb, granted we are passing them in with the username account (smile))\nsudo smbpasswd -a username\n\nUpdate permissions if needed:\nsudo chown -R username:root /home/username/data\n\nDownload some data (this is a good dump of isos)\ncd /home/username/data\nwget -H -r --level=5 --restrict-file-names=windows --convert-links -e robots=off --no-check-certificate https://ftp.nluug.nl/os/Linux/distr/\n\n\nA: if you wnat DLNA support, then see: MiniDLNA - Community Help Wiki\n\nA: I made a Ubuntu based NAS with file sharing based on Samba and Nextcloud and works across Windows, Linux or Mac. I haven't yet setup a \"real\" streaming server (e.g. Plex), but I use Nextcloud which is something like a Google Drive clone, which allows easy viewing of photos, music and videos through web browser.\nMy Ubuntu NAS:\n\n*\n\n*Intel NUC PC\n\n*Ubuntu Server 20.04 (headless)\n\n*External RAID1 USB3 drive QNAP TR-002 (this whole drive is shared, LUKS encrypted ext4 partition)\n\n*Samba (for LAN file-share access)\n\n*Nextcloud (optional, for cloud access)\n\n*UFW firewall (optional)\n\n*iDrive (optional as cloud backup of all drives including RAID USB3)\n\nSamba Setup:\nFirst I mostly followed this guide to set up Samba users.\nI edit the samba config (sudo nano /etc/samba/smb.conf) and make 2 changes:\n\n*\n\n*Under [global] section I added inherit permissions = yes to make sure permissions for added files are correct.\n\n*Configure my shared folder by adding to the bottom as follows:\n\n[mynas]\n  comment = The Big USB drive\n  path = /media/usb0/\n  read only = no\n  browsable = yes\n  writable = yes\n  create mask = 0640\n  directory mask = 0750\n  valid users = vijay\n  hide files = /$RECYCLE.BIN/System Volume Information/thumbs.db/\n\nRemember to restart Samba after changes:\nsudo service smbd restart\n\nAnd if your server has a firewall, remember to allow it:\nsudo ufw allow samba\n\nAccess on Linux: smb://192.168.1.2/mynas/\nAccess on Windows File Explorer: \\\\192.168.1.2\\mynas\\\nIn my case I need to log in as \"vijay\" to access the shares, but the password can be saved on the client so it is only entered on first access.\nNextcloud Setup:\nI used the Snap package which is probably easiest. I usually avoid Snap but in this case it worked well.  You can also try Docker or manually set everything up if you are an advanced user.\nFor Snap version, I just ran the following after installation to allow access to USB drive and ports:\nsudo snap set nextcloud ports.http=81 ports.https=444\nsudo snap connect nextcloud:removable-media\n\nI then set up a reverse proxy (Haproxy) and SSL for secure external access over the web, but that is beyond the scope of this short guide.\n", "Q: Conky configuration woes I am having trouble setting up conky to display my google calendar or a basic todo list and various system stats mainly memory and processors activity. \nI would appreciate the steps to set this up.\nPlease and thank you.\n\nA: Check this one http://www.webupd8.org/2010/08/display-google-calendar-on-your-desktop.html\n\nA: To get google calendar to show up on your desktop install \"gcalcli\" from the repository and in your /home/yourusername/.conkyrc file put:\n${exec gcalcli --nc calw 2}\nthat will display your calendar for the upcoming two weeks\nto learn more type gcalcli into a terminal\nas for system stats this page helped me alot: http://conky.sourceforge.net/variables.html\n", "Q: Sound applet has dissappeared I recently removed and reinstalled pulseaudio and now I can't get my sound applet back on my panel.\nAny ideas how to get it back?\n\nA: This is bundled into the Indicator Applet. Restore it as follows:\n\n\n*\n\n*Right-click on the menu bar.\n\n*Select Add to Panel...\n\n*Select Indicator Applet (or Audio Mixer).\n\n*Click Add.\n\n\nThe applet appears on the bar.\n\nA: Try installing/reinstalling the package indicator-sound:\nsudo apt-get install indicator-sound\n\nAlso, make sure that PulseAudio Sound System is ticked in System -> Preferences -> Startup Applications.\n\nA: You may also press Alt+F2 and launch gnome-volume-control-applet command.\n", "Q: Does anyone have a solution to 10.04 LTS not recognizing blank CD/DVDs? After I upgraded to the latest version, and I'm fully up to date, I can no longer burn CDs or DVDs, the OS simply will not recognize any blank media. Has anyone else been experiencing this and if so have you found a solution?\n\nA: There has been a documented issue with this on the previous version of ubuntu. If you had upgraded your system the problem may still be persistent, simply due to the nature of the upgrade. \nI would recommend a clean install.\n\nA: Does it detect other CD/DVD media? if not then problem lies with CD/DVD drive - the hardware.\n\nA: I think this is a wide spread issue - there are lots of forum threads (eg. http://ubuntuforums.org/showthread.php?t=1544152, http://ubuntuforums.org/showthread.php?t=1539292) with similar issues.\nIt may help to update your kernel. Go to System -> Administration -> Update Manager and update all of your packages.\nIf there is no improvement, try installing the package linux (to install the latest kernel).\nIf there is still no improvement, you may need to use a ppa to install a newer kernel, that is not available from the repositories. I hear version '2.6.35' solves this issue with some people. \nTo install it, you need to add the repository: ppa:kernel-ppa/ppa\nto your software sources. Then install: linux-headers-2.6.35-14, linux-headers-2.6.35-14-generic and linux-image-2.6.35-14-generic.\n\nA: I Had the same troubles and did a firmware update with the DVD/CD-Drive and everything works well.\n\nA: I always get this problem when the laser optics start to get dirty. It would read OK but not recognize blank media let alone try to burn them. A quick blast of air always fixed the problem. Get a can of compressed air and try it.\n\nA: You do not give any clue what hardware you have. I had that problem (and suspend/hibernate issue) on an old Dell Inspiron 8200 laptop. It had a hot swap drive bay that had a DVD drive in it. But apparently because it could be hot swapped, Linux kept polling for a floppy drive, resulting in log errors attempting to read fd0, lack of auto mounting USB or CD/DVD's, and failed to suspend or hibernate because it could not put udisks-deamon to sleep, which kept polling for the non-existing floppy.\nSo if you have no floppy and are getting any fd0 errors in dmesg or /var/log/messages similar to \"end_request: I/O error, dev fd0, sector 0\", either disable the floppy in your BIOS, or if that does not work:\nAdd following to /etc/modprobe.d/blacklist.conf (use sudo or gksu to run your editor):\nblacklist floppy\nThen do: sudo update-initramfs -u\nThen reboot and see if USB and other removable media auto mounts when inserted.\nNote that other partitions on internal drives are not auto mounted unless you make proper mount points (usually in /media unless you want it mounted elsewhere) and entries in /etc/fstab (preferably using UUID). Although, they will mount if you have permission and select them in Places.\n", "Q: How do I get the microphone on a Sony Vaio cs33g working? my sony vaio cs33g microphone is working on windows7 but it does not work on Ubuntu, any suggestions ?\n\nA: You can also test your microphone in the Sound Preferences.\n\n\n*\n\n*Click the Indicator Applet's sound icon and select 'Sound Preferences...'\n\n*Select the 'Input' tab\n\n*In the 'connector' drop down, select one of the microphones and speak.  If it works you should see the 'input level' raise & change color.\n\n*If it doesn't work, try raising the 'input volume'.  Also make sure it's not muted.\n\n*If it still doesn't work, try another option in the the 'connector' drop down.\n\n\nHopefully this helps.  My mic wasn't working yesterday as well, and this is what I did to get it working.\n\nA: I recommend testing your microphone with Audacity instead of gnome-sound-recorder, because sound recorder sometimes fails even when everything else is working.  Here are some common solutions to microphone problems:\n\n\n*\n\n*The hardware profile sometimes defaults to one of the \"Output\" options, which disables the microphone. In sound prefs (Hardware tab), check to make sure the hardware profile is set to something that includes input.  \"Analog Stereo Duplex\" is a good guess if you aren't sure.\n\n*Check the input tab -- (a) make sure the mic is selected as your input device and (b) adjust the input volume to a  reasonable level.  Speak into the microphone and check the level indicator.  If the level indicator shows a signal, then the microphone is working and the problem is with the program you're using to record.\n\n*If the level indicator doesn't show anything, try installing the ALSA mixer (sudo apt-get install gnome-alsamixer) and play around with the input sliders (the ones with \"Rec\" check boxes underneath them).\n\n*If all else fails, it's possible that Ubuntu just doesn't support your sound card. This is less common than it used to be, but it still happens sometimes.\n", "Q: When will Ubuntu One for Windows be released? I wanted to know when will the Windows version of Ubuntu one be available? Does anyone have any information about it?\n\nA: We will be releasing a public beta of the Windows client within the next couple weeks. When it's ready, we'll be sure to announce it on the Ubuntu One blog: http://voices.canonical.com/ubuntuone\n\nA: Ahem... allow me to quote:\n\nRecognizing that many of us are sometimes forced to use legacy operating systems, Ubuntu One is coming to the rescue. You're invited to beta test our new Windows client for syncing files — just sign up for our free Ubuntu One Basic plan and install the software to contribute.\n\n\nA: The Ubuntu One Roadmap says that \"Windows file sync\" is coming as part of the Ubuntu 10.10 release:\n\nWindows file sync\n  \n  \n*\n  \n*Addresses the needs of the many\n  Ubuntu users who operate in a mixed\n  platform environment of Ubuntu +\n  Windows\n  \n*Will support syncing files\n  between Windows desktops and your\n  Ubuntu One personal cloud\n  \n\nAlso, see the the Ubuntu Weekly Newsletter, Issue 208 for the week August 22nd - August 28th, 2010., which says:\n\nUbuntu One taking care of Windows users ... not so much users of other\n  Linux distributions\nSteven Rosenberg, of Tech Talk\n  discusses Ubuntu One. A look at the\n  roadmap for Ubuntu One reveals the\n  following feature planned for Maverick\n  — Windows file sync: Addresses the\n  needs of the many Ubuntu users who\n  operate in a mixed platform\n  environment of Ubuntu + Windows ...\n  Will support syncing files between\n  Windows desktops and your Ubuntu One\n  personal cloud ... I wonder, what\n  about a free, open-source Ubuntu One\n  client that could be used in any Linux\n  distribution?\nTo read the full article go to:\n  http://www.insidesocal.com/click/2010/08/ubuntu-one-taking-care-of-wind.html\n\n\nA: I asked this question on one of the Ubuntu One developer's blog.\nIt turns out that there is work underway, but no date as of the time I asked.\n\nA: Ubuntu One for Windows (XP, Vista, Win7 and Win8) has been released. It may be downloaded from here.\n\nA: It already has according to their website:\nhttps://one.ubuntu.com/plans/\nBut only for subscribers.\n\nA: We are also extending our platform support to include a Windows client, which will be available in Beta very soon.\nhttp://voices.canonical.com/ubuntuone/?p=617\n\nA: Can we just assume that DropBox is the immediate solution: More space, less price, works on windows/linux/mac. I know its not a real \"answer\" but its my reason for not using ubuntu one. Also I could not even get it working since I think it wants some special Firefox plugin.\n", "Q: How do I configure WiFi to log in to WPA at boot time, regardless of user being logged in? How do I set a system wide wireless WPA password that starts at boot time, allowing me to SSH in to the machine from outside, for example?\nI'm running mythbuntu. Until I log in, WiFi doesn't connect, so I can't use SSH to log in from another computer, for example. When I have auto-login enabled, it asks me to enter my password to unlock my keyring before connecting. I've tried editing the connection and clicking \"Available to all users\", but then it just doesn't connect at all.\nHow do I go about debugging this problem, or how can I configure it totally manually?\n\nA: An easier solution: add the following lines to /etc/network/interfaces\nauto wlp1s0\niface wlp1s0 inet dhcp\n  wpa-essid wifiName\n  wpa-psk Password\n\nI have tested it on 16.04 LTS. May work on other versions.\nSource: https://ubuntuforums.org/showthread.php?t=1963404\n\nA: for \"regardless of being logged in,\" you'll need to edit your /etc/network/interfaces file...\nhttp://ubuntuforums.org/showthread.php?t=263136\nThat link describes the process pretty well...\n\niface wlan0 inet static\n  address 192.168.1.15\n  netmask 255.255.255.0\n  wireless-essid my_essid\n  gateway 192.168.1.1\n  pre-up wpa_supplicant -Bw -Dwext -i$IFACE -c/etc/wpa_supplicant.conf\n  post-down killall -q wpa_supplicant\n\n\nA: For the sake of completeness, I'll also mention wicd, an alternative to Network Manager. I believe that if you configure wicd to connect automatically to a wireless network, it will happily do so at boot time.\n\nA: When you are logged in and connected to the network, right-click the Network Manager icon.  (It should be in the upper right of the screen.)\nClick \"Edit Connections...\"\nFind the connection you want to make available without login.  Click it and click the \"Edit\" button.\nMake sure the \"Connect automatically\" and \"Available to all users\" boxes are checked.\nNow the connection will start up before anyone logs in and will be available to everyone on the system.\n\nA: Use wpa_ supplicant and dhclient\nYou will have to create a script that starts up at boot-time have a look here.\nHave it run the following 3 commands (possibly from a script og sorts)\nwpa_supplicant -B -i wlan0 -c /etc/wpa_supplicant.conf\nsleep 10\ndhclient wlan0\n\nThe contents of the wpa_supplicant.conf file should look something like this (using standard wpa-psk):\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=wheel\nnetwork={\n    ssid=\"network-essid\"\n    scan_ssid=1\n    key_mgmt=WPA-PSK\n    psk=\"very secret passphrase\"\n}\n\nlook at the man page for wpa_supplicant.conf for more encryption options.\nYou might need to tweak the sleep command depending on how fast your router/netcard is at negotiating the connection. 10 seconds should be enough, but 5 or even 2 may be enough.\n\nA: I have tried using the /interfaces or /interfaces.d/ to get to wireless with dhcp with wpa_supplicant but these did not work.\nBut the only option that worked for me was,\nAdding the lines physically in /etc/rc.local\n#!/bin/bash\nsudo wpa_supplicant -iwlan0 -c /etc/wpa_supplicant/wpa_supplicant.conf &\nsleep 10\nsudo dhclient -v\nexit 0\n~   \n\n", "Q: Where can I find SVG sources of the Ubuntu icons? I'm trying to make some modifications to the default Ubuntu iconset (mimetypes and some application icons) But can't seem to find the svg for these files - are SVG versions of these available? If so is it a package or already in my install?\n\nA: You can find a lot of mimetype SVG icons in /usr/share/icons/gnome/scalable. A lot of application icons are located in /usr/share/icons/hicolor/scalable/apps and /usr/share/pixmaps.\n", "Q: A fresh install and clean up? I started with Ubuntu around 3 years ago and have been a dedicated user ever since. During that time I tried out lots of apps, themes, etc. And, I've updated every version as it has come along so now I'm running Lucid. \nBasically, my system has gotten sort of \"messy\" and I'm planning a vigorous clean up and a fresh install. My /home is on a separate partition from everything else, so I can preserve that. I want to find and remove unused, unneeded apps (which I pretty much understand how to do). Also, I want to get back to the default desktop theme and build back up from there. And other messes surely exist.\nSo, my question is, What is a good, logical plan to clean up and freshly reinstall my system?\n(One note is that I have found many links in searches on this issue. There are many links on this topic and many are out of date. So, it's gotten rather confusing to say the least.)\nThanks.\n\nA: This all depends on personal preferences. But if this was my system, I would do a clean install - including reformatting /home.\nThe reason I would do this is because the 7.xx series used the ext3 filesystem, while the new 10.04 uses ext4. You can convert from ext3 to ext4, but it is much easier to reformat since I would be reinstalling anyways.\nYou will have to back up /home to a separate drive. I would backup just the files I need, and leave out the config files (hidden files like .gnome2, .gconf, etc.). After I reinstall, just copy the files back into place.\nThis may or may not be the best way to do. It depends on your preferences and objectives.\n\nA: When I want to start over Ubuntu I usually follow this steps:\n\n\n*\n\n*Boot from LiveCD.\n\n*Mount my home partition\n\n*Rename my home dir to something like javier-old.\n\n*Install, keeping my home partition, the install will create a new home for the default user (javier in this example)\n\n*After installing I move all my normal files from javier-old to javier.\n\n*Then I locate the config files from the programs that I want to keep settings and move then from javier-old to the new home (usually .thunderbird, .gnome2/gedit, .ssh, .Private, etc...)\n\n*Firefox gets special treatment. I left over the extensions folder and just copy the other files. Sometimes a do a more granularly copy of firefox files. Usually I just want the bookmarks and the passwords.\n\n\nAnd that is all. That way not only I start with a clean system, I reset most apps to their default, but the ones that I really want.\nFinally I keep the javier-old dir there just in case I want to recover some data or some configuration later.\n\nA: There are 4 things you generally want to preserve when you do a re-install.\n\n\n*\n\n*Your home directory - as mentioned, you have home on a separate partition.\n\n*Any customisations you've made in /etc. If you've made any, you probably did them by hand and therefore have some idea of what they are.\n\n*Your list of installed programs. Executing dpkg --get-selections | grep install > installed.txt will create a list of packages that are currently installed. In your case this doesn't sound like something you want to preserve, so you could skip this step.\n\n*Your /var directory. Some programs store important data here, so it's worth backing up. Things I've seen stored in /var include mail directories, databases, game save files, and web configuration files. Having a backup means you can selectively restore anything that turns out to be needed.\n\n\nSo, a plan would probably look something like this:\n\n\n*\n\n*Back up any customisations in /etc.\n\n*Back up your /var directory.\n\n*Either run dpkg --get-selections | grep install > installed.txt or run an eye over the Applications menu for the names of any applications you use regularly.\n\n*Re-install your system.\n\n*Install any missing applications. If you want to use the generated list, you can do:\nsudo dpkg --set-selection < installed.txt\nsudo apt-get install --yes dselect\n\n\n*Re-apply your customisations in /etc (if still needed).\n\n*Upgrade your home partition to ext4 (optional, see the Ubuntu wiki for details).\n\n*Restore anything that turns out to be needed from /var.\n\n\nI would recommend against wiping out the configuration files in your home directory; you'll lose things like your browser bookmarks and security keys, for example. A better strategy for getting back to default settings would be to create a new user account and compare their settings to the ones your normal account is using.\n\nA: jbowtie has provided a comprehensive method. I would like to add to it.\nBefore installing the packages you need to make sure the /etc/apt/sources.list file is copied over to the new system followed by an apt-get update. \nIn addition to the apt packages don't forget any manually compiled packages and any manually downloaded .deb packages which may not be available in the sources.\nIt might be useful to 'diff' the old backed up and the new bin folders to find these.\nBetter still it might be worth it to maintain a log of any manual operations to these system folders, enabling you to make the perfect clone.\n\nA: $ sudo tasksel remove desktop && sudo tasksel install desktop\nThat will remove all packages in the desktop set and then re-install them.  This will have the side-effect of removing all packages that depend on them, providing you with the purge you mentioned wanting.  You can see the package list using:\n$ tasksel --task-packages desktop | less\n\nA: I think you should wait for 10.10,BTRFS and such.\nAccording to Phoronix Benchmarks,BTRFS just murdered the competition.\nPhoronix UFS+J vs UFS+S vs ZFS vs Ext4 vs BTRFS\n", "Q: How can I have multiple terminal sessions through one single SSH connection? I have an Ubuntu server edition running and I can SSH into it to perform various tasks.  What I'd like is the ability to SSH into my server kick off a server application and then switch to another \"virtual\" session (with in the same SSH instance) and run client calls against the service.  When I start the service its a blocking call, so I can't run client calls against it without firing up anther SSH session. \nI was hoping there might be a slicker way, something like the UI does with virtual desktops.\n\nA: GNU Screen is the answer you've been looking for - but it's a lot like Vi. You've got a lot of learning of commands to setup a successful Screen environment. Here's some stuff to get you started. First of all you'll want this .screenrc http://paste.ubuntu.com/473764/ save it on the remote server in your users home folder. Next install screen on the remote machine (sudo apt-get install screen) Next you'll want to fire it up here are some commands for \"firing up screen\":\nscreen - This is pretty simple. It starts a new screen session\nscreen -ls - List all active screen sessions. Yes you can have multiple terminals inside multiple screens. SO SWEET.\nSample\nscreen -ls\nThere is a screen on:\n    16467.pts-0.ubuntu  (08/05/2010 07:47:53 PM)    (Detached)\n1 Socket in /var/run/screen/S-marco.\n\nscreen -x <pid> - This will resume a Detached screen session, IE: screen -x 16467\nOnce you're in a Screen (and you've employed my sample .screenrc file) You'll see the following along the bottom:\n(LOAD) 0$* bash\nWhich is the servers load and a list of all open \"terminal tabs\". Currently only one window. Type something then Press this Key Combination: Ctrl + A release, then press c. Ctrl + A is the escape sequence. All commands are started with this combination. c is create new tab. You'll notice the footer has (LOAD) 0-$ bash  1$* bash which shows that there is another tab open and the active tab is number 1. You can open a maximum of 60 tabs per screen session.\nIf you want to exit screen but keep it running use Ctrl + A then d which will detach your session. Finally you can close tabs by using Ctrl + A then k which will kill that tab (if it locks up) but typically you can just type exit as if you were in a terminal and it will close that tab.\nLastly to list all windows open you can type Ctrl + A then \".\nThere are a whole slew of options available for Screen you should pour over the man file for more. There are some drawbacks. You can't use your scroll bar in Screen you have to use buffer controls to roll back, however the above is enough to get you started to see if this is a viable option. A great thing about this and something I've dealt with a lot as a System Administrator - network connectivity. If your network drops out your operations won't be lost! Since screen is running on the server. You simply need to log back in via SSH then screen -ls and screen -x back into your session.\n\nA: What you want to use is screen or even better a user-friendly wrapper around screen called byobu.\nScreen allows you to run multiple virtual terminal sessions in the same ssh session. A tutorial and help pages are available.\nbyobu is a wrapper that allows to easily open new screens with a simple function key instead of key combination from ctrl-a. It also shows a status line with all the open virtual terminals which can be named.\nAnother nice feature is the fact that all your screen can stay up while your ssh connection is disconnected. You just connect again via ssh and call byobu and everything is like before. \nAt last some screenshots of byobu.\n\nA: If you're using Ubuntu Server Edition byobu is definitely your best option. The Ubuntu Server Guide has some useful documentation.\nIt's generally easier to learn and use than screen and it is installed by default.\n\nA: I use Emacs, so screen's default configuration makes my life difficult.\n$ cat /home/cjac/.screenrc \n\nescape ^\\\nTry that!\n", "Q: How to install relink wireless driver for LG X130 nebook how to install relink wireless driver for LG X130 netbook in Ubuntu 10.04\n\nA: Another possible option, while probably not as good as what the person above is suggesting, would be to use ndiswrapper to install the Windows driver. Only use this if the above suggestions don't work. You can download the XP driver from LG's official site at \nhttp://www.lg.com/ae/support/product/support-product-profile.jsp?customerModelCode=X130-G.ASB7E1&initialTab=drivers&targetPage=support-product-profile\nand uncompress it to whatever location you prefer. You can install ndiswrapper from the Software Centre. Once installed, you will see a \"Windows Wireless Drivers\" button under System - Administration. From there, just click install new driver and select the .INF file which you previously got from extraction. If everything went well, your wireless should be up and ready to go.\n\nA: I believe your wireless card is a Ralink rt3090.\nTo check this, you can run lshw -c net in a terminal.\nIf this is indeed your card, there is a ppa that someone has created for the driver. Unfortunately, it is only supported up to Ubuntu 9.10. However, there is anecdotal evidence that it works on Ubuntu 10.04.\nYou can attempt to add the ppa or download the .deb file and double-click it. This is not an ideal way to install it - it is better to install things through the official repositories, but it appears you have no other option.\nBefore you do any of this, make sure you update all of your packages (System -> Administration -> Update Manager) and check System -> Administration -> Hardware Drivers to see if there is an available driver there.\nppa\ndirect download (.deb file)\n", "Q: Ubuntu Server samba running as root? I recently installed Ubuntu Server 10.04. I selected samba file server from the install menu and everything works fine. The problem is, the samba daemon is running as root which has me a little nervous. \nI added a 'samba' group and a user called 'samba' to that group, but I can't get the daemon run under it.  MySQL from the LAMP seems to run as its own user.\n\nA: Running Samba is slightly different to running apache or mysql.\nWhen you connect to the web server all processes are run as user www-data, when you connect to mysqld all processes are run as user mysql.\nBut when you connect to samba a new process is forked with your user credentials.\nOnly root can fork processes as other users.\nIt is correct that samba is running as root. \n", "Q: Why can't I click on things (software-related issue)? After installing both Gmameui and the Sugar desktop session package I was not able to click on anything inside applications. I can close, minimize, and maximize windows and use the panel and desktop icons but the rest of the system is unusable. I have not deleted the partition in which this system is installed on, but have re-installed Ubuntu in a new partition, so if anyone can help me with this, it would still be of use to me.\n\nA: I had the same problem with Sugar, found the answer at ubuntuforums.org \n\nYou don't need to delete the whole\n  .gconf folder, edit the file\n.gconf/apps/metacity/general/%gconf.xml\n\ndelete the tag with name\n  \"mouse_button_modifier\", in my case\n  this 3 lines:\n<entry name=\"mouse_button_modifier\"\n\nmtime=\"1279125807\" type=\"string\">\n          disabled\n      \nand that's it.\n\nWorked like a charm.  Thanks, moiesk.\n", "Q: How do I see my mobile contacts in Empathy? In Pidgin and most other clients for instant messaging I've used, when my contact is logged in from a mobile phone, the client shows an icon by their name so I can differentiate between these buddies that are online from a phone and buddies that are online from a computer. Does Empathy have this feature?\n\nA: This is a known bug in Empathy and is currently being worked on.\nSo Empathy currently lacks this feature but it will likely show up in the next version of Ubuntu (10.10).\n\nA: You can't just yet. This feature is coming, likely in 10.10, and there was a blog post asking users about how this should be presented, so if you feel like it, you can give your opinion here.\n", "Q: Software to sync an iPod that auto converts audio and video to correct format? Does any software exists that actually convert audio to be fonctionnal on my iPod (ex : .ogg to .mp3) and convert videos to a format working on an iPod?\n\nA: Arista Transcoder is what you need.\nOne Click Install\n\nA: Avidemux is a decent choice for video.  Although Arista looks like might fit your bill for both jobs.  I haven't tried either yet personally.  I typically end up using ffmpeg or the like.\n\nA: For video nothing beats Handbrake. Amazing piece of software. Link to forum discussion. \n\nA: Last time I checked, Banshee transcodes files when transferring them; completely automatic: comes with a very nice interface for iPods/Android devices, too.\n", "Q: How do you change your screen's color temperature? How do I go about changing my laptop's display's color temperature? And I don't mean through something like the Red, Green, Blue sliders in the NVIDIA config menu. I'm talking about like adjusting in degrees, like editing a photo's white balance.\nSo now I've found Redshift and it's doing me pretty good. I thought it might be helpful if I out here the command I'm using.\nredshift -t 5000:5000 -g .5\n\nBy adding this to my start up commands I should be good.\nI'm still open to other suggestions, because I'd like something that actually edited my xorg.conf or something like that.\n\nA: If you've got any form of colour-calibration hardware (or can find a profile on the internet) then gnome-color-manager will load and apply monitor calibration system-wide.\nWindows drivers for monitors and laptops will often come with an .icm colour profile you can use, which, while not perfect, would almost certainly be better than nothing.\n\nA: redshift -O 5000 works for instantly turning on warm mode instead of messing with location data\n\nA: This follows @CornSmith answer :\n\n\n*\n\n*Check System Panel icon for RedShift App\n\n\n\n*Disable it.\n\n*Execute following command\n\n\n\nredshift -O 3000\n\n\n\n*Color temperature of your display should change\n\n*To revert, just go to System Panel and Enable it, Automatic Feature will be back!\n\n\nA: \nRedshift adjusts the color temperature of your screen according to your surroundings. This may help your eyes hurt less if you are working in front of the screen at night.\n\nI'm not sure if this is what you need because, as far as I know, it won't let you adjust the colour temperature manually. It may help though, so Here's the website anyway.\n\nA: In case you are using proprietary drivers, its quite easy with the built in gamma and color control, otherwise follow the methods listed above. Even Intel cards have GPU tools that can be installed via x-swat ppa.\n\nA: Another option is sct (set color temperature?).  If you like small, compact programs with few dependencies, sct might be a good option.\nhttps://packages.ubuntu.com/search?suite=all&searchon=names&keywords=sct\n\nA: LPROF http://lprof.sourceforge.net/ seems to be your best bet for adjusting color temperature via software.  There's also ArgyllCMS which looks to have an even steeper learning curve.\nI have not used either but LPROF is available as an ubuntu package.  sudo aptitude install lprof\n\nA: I installed the f.lux gui, but have scripted xflux a bit instead of using the gui, to just make the changes when I wanted. on 10.04, redshift was out of date.\n", "Q: Zune + Ubuntu, What are my options? I have a Zune HD (don't ask).\nIs there any alternative to using this in Ubuntu besides creating a virtual Windows environment (in say Virtual Box or VMWare) and running the Zune software there?\n\nA: From what I understand, no one has been able to crack the ZMTP protocol. So unfortunately you have no other options.\nMy poor friend is facing the same problem. :(\n\nA: Zune doesn't work with Wine (the Windows-Linux compatibility layer) and Windows Phone devices don't feature USB storage mode so your only option regarding Zune really is running it in Virtual Box + Windows.\nhttps://duckduckgo.com/?q=linux+zune+virtualbox\nDetailed information:\nHow to sync my music and photos with Windows Phone 7 device?\n", "Q: Unity launcher -- is it available as a separate package? Is the launcher (side dock) found in Unity available as a stand-alone package that can be added to other desktops? (like xfce)\nIf so, what's the package name? and is it available for 10.04 or only 10.10?\n\nA: Unity is available for 10.10, you just need to install the ubuntu-netbook package\nUnity is also available for 10.04 through the PPA named canonical-dx-team/+archive/une\nIn both cases this will add a new \"Netbook edition\" option in the login screen. I don't think the dock is available as a stand-alone package.\nMore information and detailled installation instructions can be found on the wiki :\nhttps://wiki.ubuntu.com/DesktopTeam/Unity\n\nA: The 2D Unity project comes with unity-2d-launcher which can serve as a stand-alone unity launcher\nPPA: https://launchpad.net/~unity-2d-team/+archive/unity-2d-daily\n\nA: You could use the Unite theme for dockbarx that is intended to replicate Unity. Dockbarx is available in a PPA although you will have to install the theme seperately. \n\n", "Q: How to upload package with dependencies to my PPA? I made a package for my PPA and uploaded it. It built without any problems.\nThen I made another package that depended on the first and uploaded it. It failed because it couldn't find the files in the first package. This leads me to believe that the first package wasn't even installed.\nHow can I make sure the first package is installed before it tries to build the second package?\nThe control file for the first package (libjsoncpp):\n\nSource: jsoncpp\nPriority: extra\nMaintainer: Nathan Osman \nBuild-Depends: debhelper (>= 7)\nStandards-Version: 3.8.3\nSection: libs\nHomepage: http://jsoncpp.sf.net\n\nPackage: jsoncpp-dev\nSection: libdevel\nArchitecture: any\nDepends: libjsoncpp (= ${binary:Version})\nDescription: JSON parsing library for C++\n jsoncpp is a C++ library that makes it easy to\n read / write JSON data.\n .\n This package contains the development tools necessary\n to create applications that use jsoncpp.\n\nPackage: libjsoncpp\nSection: libs\nArchitecture: any\nDepends: ${shlibs:Depends}, ${misc:Depends}\nDescription: JSON parsing library for C++\n jsoncpp is a C++ library that makes it easy to\n read / write JSON data.\n\nThe control file for the second (libsopp):\n\nSource: sopp\nPriority: extra\nMaintainer: Nathan Osman \nBuild-Depends: debhelper (>= 7)\nStandards-Version: 3.8.3\nSection: libs\nHomepage: http://stackoverflow.quickmediasolutions.com\n\nPackage: sopp-dev\nSection: libdevel\nArchitecture: any\nDepends: libsopp (= ${binary:Version}), jsoncpp-dev\nDescription: A C++ library for interfacing with StackExchange sites.\n so++ is a C++ library that wraps the functionality of the StackOverflow\n API. It provides access to all of the StackExchange sites.\n .\n This package contains the development files necessary to write software\n that uses so++.\n\nPackage: libsopp\nSection: libs\nArchitecture: any\nDepends: ${shlibs:Depends}, ${misc:Depends}, libjsoncpp\nDescription: A C++ library for interfacing with StackExchange sites.\n so++ is a C++ library that wraps the functionality of the StackOverflow\n API. It provides access to all of the StackExchange sites.\n\n\nA: Your second package (sopp) needs to specify that it needs the first to build; the dependency you have specified (with Depends:) will only handle installation.\nTo add a build dependency, add this to the top (Source:) section of your control file:\nBuild-Depends: jsoncpp-dev\nYou should then be able to drop jsoncpp from the Depends line, as the shlibs:Depends macro should work that out itself.\n", "Q: Automatically copy podcasts onto ipod I'd like to be able to plug my 5th gen iPod nano into my Ubuntu 10.04 box and have it sync podcasts. I'd like newly downloaded podcasts to be copied onto the iPod, and played podcasts to be removed from the iPod.\nI've tried syncing with:\n\n\n*\n\n*Rhythmbox detects the iPod when it's plugged in, but doesn't sync podcasts to it. \n\n*Banshee doesn't detect the iPod unless I kill Nautilus. It also doesn't sync podcasts without intervention.\n\n*gPodder doesn't seem to detect the iPod. It will sync, but only if I tell it to. And it marks podcasts as unheard. The gpo sync commandline app has the same problem.\n\n*gtkpod doesn't detect the iPod. It will sync with intervention, but it syncs podcasts as songs. \nThis feels like a problem that someone else would have encountered by now. How do I get my Ubuntu box to sync podcasts with my iPod? \n\nA: Interesting that you couldn't get it working with gPodder. I had this working with Ubuntu 10.04 but with an iPod 30GB video (a generation before yours?). I did have to fiddle a bit to make it work, but once working it was pretty much automatic. \nHave you tried a newer version of gpodder than we have in Ubuntu?\nThe gpodder authors ppa has 2.7, Ubuntu Lucid has 2.2\nhttps://launchpad.net/~thp/+archive/gpodder\n\nA: http://juicereceiver.sourceforge.net/ -- formally know as ipodder, now called juice provides the functionality your looking for. \n:)\n\nA: You cant really \"sync\" but you can copy,paste and move things to-and from the iPod. What you can do is set up a cron job to sync hourly. You would need to set up a script to see where the mount point of the iPod is and to copy to the appropriate folder.\n", "Q: Problems installing Ubuntu Tweak I'm new to Ubuntu and loving it already. I installed Ubuntu 10.04 LTS and want to download and install Ubuntu Tweak. I followed the following process: system>administrator>synaptic package manager...that were I can't proceed and received an error message:\nE: dpkg was interrupted, you must manually run 'sudo dpkg --configure -a' to correct the problem. \nE: _cache->open() failed, please report.\nWhat am I to do to rectify this problem, without reinstalling Ubuntu\nRegards, Hylton\n\nA: Please open a Terminal from Applications>Accessories>Terminal then copy and paste this following line\nsudo dpkg --configure -a\n\nEnter your password,wait some time and done.\n", "Q: Flash doesn't work right in Firefox. Won't respond to certain clicks I installed the Flash plugin in Firefox, and certain sites don't do what they should because certain things don't know they are being clicked on. Anything I can do about this? Will another plugin work better?\n\nA: You're probably affected by LP #410407\n\nA: This usually happens when you are using the 32bit plugin on a 64bit system. If this is the case, then you need to edit the npviewer file. \nOpen it with the command below:\ngksudo gedit /usr/lib/nspluginwrapper/i386/linux/npviewer\n\nThen add the following line before the last line of that file:\nexport GDK_NATIVE_WINDOWS=1\n\nThe file content should look like this:\n#!/bin/sh\nTARGET_OS=linux\nTARGET_ARCH=i386\nexport GDK_NATIVE_WINDOWS=1\n. /usr/lib/nspluginwrapper/noarch/npviewer\n\nSave the file and restart the browser.\nAlternatively, you could use the preview version of the 64bit plugin as already suggested.\n\nA: That's probably a problem of flash,try installing gnash or lightspark.\nGnash is in the repositories\nfor lightspark-\nhttp://www.omgubuntu.co.uk/2010/05/lightspark-open-source-flash-player.html\n\nA: If you're using Ubuntu 64-bit, you might solve your problem by installing the (not yet officially finished) 64-bit version of Flash. Anyway, that's how I solved my problem of some mouseclicks not being recognized.\nDownload it from here:\nhttp://download.macromedia.com/pub/labs/flashplayer10/libflashplayer-10.0.45.2.linux-x86_64.so.tar.gz\nThen copy libflashplayer.so to:\n/home/\"username\"/.mozilla/plugins (replace \"username\" with your username)\nIf the folder plugins isn't there yet, you have to create it.\nHope this will help.\n\nA: Just install the Flash-Aid plugin. It will choose the flash version for your browser version. It worked for me even when adobe said that they will not support flash for FireFox anymore. https://addons.mozilla.org/en-US/firefox/addon/flash-aid/\n", "Q: How to get a dual boot USB drive to work in Vista Hey I managed with the help of a friend to get 10.04 onto a 2TB WD USB drive for dual boot but it doesn't want to work on my Vista loaded laptop. Is there a fix? i don't have the choice of erasing Vista. The drive works on another Ubuntu laptop. I have yet to try it on my dad's XP machine.\n\nA: With some laptops, plug the USB drive in then turn on the power. Press F2 or Delete to enter the PC BIOS settings. \nThe setting you want is usually under the BOOT section (use left/right arrow keys to change sections) and check the boot device order, make sure USB is before hard drive.\nIf you are unsure about changing anything, have a look and write down what options you see, exit without saving and let us know what options there is.\n\nA: First,is the usb drive bootable, and did you select it at boot time from the BIOS boot screen ? Have you set the BIOS to put the USB drive first, or do you select from a menu each time you boot?\nIf you enter your BIOS, and move USB to the top of the boot order, it should select the USB Hard drive automatically at boot up.  \n\nA: If you have grub installed on the USB drive, you can boot unsupported operating systems (such as windows) by chain loading.  Find your way to the grub command prompt and enter these commands:\n\ngrub> rootnoverify (hd0,0)\ngrub> makeactive\ngrub> chainloader +1\n\n\nA: The Computer(s) you are tying to run Ubuntu on may not support booting from USB. If this is the case either update your BIOS or get a new Computer. If it is compatible then check the boot menu which varies from PC so look for the key Combination for \"Boot Menu\" or \"Boot Select\" at startup. If I works you should be able to see the 2TB drive.\n", "Q: How is Ubuntu different from Debian? Ubuntu is a derivative of Debian. It uses the same package format.\nIn what ways is Ubuntu different from Debian?\n\nA: Ubuntu syncs from Debian every six months (weeks before every releases). Any package that doesn't have any Ubuntu specific changes in Ubuntu (i.e. the previous version was also from Debian) or isn't in Ubuntu already, gets synced into Ubuntu's Universe (free and third-party). MOTU put a lot  of work into maintaining the Universe, but this isn't where Ubuntu differs from Debian the most.\nUbuntu's distinctive packages are those in the Main repository (free and Canonical supported). (There is a table of the various repositories on the Ubuntu Team Wiki). This is where Canonical comes into the picture. When you read articles on the cool new things that Ubuntu will have and change in the next release, you're probably reading about something that will arrive in main. This is where Ubuntu is different from Debian.\n\nA: So maybe its crazy for me to answer this, having just joined Canonical 3 months ago (today!) and having only run Ubuntu out of curiosity for the few years before joining Canonical. It might even be silly for me to answer it, given that I am on the server team, and Ubuntu definitely has a very large focus on making \"Linux for Humans\", ergo, the desktop.\nTo me, the release cycle is everything. Yes there are some things that will never go back to Debian, because these things are somewhat counter to Debian's philosophies. But these are by-products of the greater goal of usability.\nWhen Ubuntu was started, the idea was simple. Debian was awesome then, and is still awesome today. I ran it exclusively for several years and it served me well on laptops, desktops, and especially on servers, being a server kind of guy. But that release cycle was so slow that all of the cool whiz bang stuff that people were producing on Linux was just not making it into the stable releases, and the unstable development release that had all of these things was un-installable (no official isos) and broken quite often.\nSo by saying \"we're going to limit our focus to a couple of architectures, and a subset of packages\" (the \"main\" archive in Ubuntu), the Ubuntu project was able to commit to releasing a tested, stabilized OS with all of that cool new stuff in it. They were also able to commit to carrying a bit of a delta from Debian that was highly focused on usability. By committing capital investment to it, Canonical was able to commit to having the technical staff available to make that happen.\nOne awesome part of that was that they (I say they, because I am not an Ubuntu member yet) could still keep a lot of the wide breadth of Debian software by creating the \"universe\" archive. Even better, a community (MOTU) grew up around that to make sure it received some stabilization before release as well.\nSo, to sum it all up with an analogy.. Ubuntu is to Debian, as your local restaurant is to the local farmer's market. Chef Ubuntu goes to the Debian farmer's market periodically, finds the best fresh ingredients, mixes them with his own special blend, and produces food for his intended audience. For people who enjoy cooking, they can, and do, just go down to the market and get what they need.\n\nA: \nLike many popular conceptions, the common characterizations of Debian and Ubuntu are only partially true. Debian’s reputation as an expert's distribution is partly based on its state a decade ago, although it does provide more scope for hands-on management if that is what you want. Similarly, while Ubuntu has always emphasized usability, like any distro, much of its usability comes from the software that it includes — software that is just as much a part of Debian as of Ubuntu.\nSo what are the differences between these Siamese twins? Looking at installation, the desktop, package management, and community in the two distributions what emerges is not so much major differences as differences of emphasis, and ultimately, of philosophy.\n\nThat was a quote from Bruce Byfield who hits the nail on the head. In the comparison between Ubuntu and Debian, the philosophy behind the software is the key difference between the two.\nFull article\n\nA: For me personally the major difference it is actually a a lot about the release cycle. I find it a great benefit that I have the option of going for a kind-of-stable new release every six month, instead of having to choose between a potentially rather old stable release or the constant moving target of the testing release.\n\nA: Ubuntu is generally based on the \"unstable\" version (codename \"sid\") of Debian. They take Debian \"unstable\" every 6 months and stabilise it. Ubuntu and Debian packages are binary incompatible.\n", "Q: Installed Ubuntu-Tweak but there's no icon I installed Ubuntu Tweak, but I don't see an icon. \nAm I supposed to have a Tweak icon somewhere?\n\nA: Ubuntu Tweak is in Applications>System Tools\nFrom Unity, press the Super or Windows key, then type \"tweak\" to display it.\n", "Q: How come Power Manager Settings does not work when computer is under virtual console? I was wondering why power events does not work as expected when I'm using virtual console (or whatever the thing that appears after Ctrl-Alt-F1 is called).\nI've set my laptop to go to sleep when lid is closed and it is working fine when I'm in graphical interface. But when I switch to virtual console, closed lid just turns the screen off.\nHow it is possible, I thought such low level stuff is controlled by daemons and they do not depend on the type of interface I'm in?\n\nA: You'll find the answer in /etc/acpi/lid.sh. You are correct that there is an ACPI daemon that responds to things like closing the lid. However, if you look at the line near the top of the script:\nif [ `CheckPolicy` = 0 ]; then exit; fi\n\nyou'll see a line that cancels the whole thing. The CheckPolicy thing checks whether something like Gnome Power Manager is running on the current console. If so, it aborts, and lets the power manager handle it.\nSo, when GNOME is the active session, Gnome Power Manager handles the lid. When the console is the active session, the ACPI daemon handles the lid. If you read the rest of the lid.sh script, you'll see that all it does is blank the screen.\n\nA: Probably related to consolekit. Consolekit tracks who is logged in and where to deal with multiuser systems. Logging into the vt getty probably doesn’t register with consolekit. You can check with ck-list-sessions. G-p-m asks CK just the same as pulseaudio does. When you switch to a vt then audio cuts out.\n", "Q: How can I tell what date Ubuntu was installed? is there a command which will output the date that ubuntu (or any distribution) was installed?\n\nA: If you use ext2/ext3/ext4 and formatted the disk when you installed you can do this nifty trick.\nsudo dumpe2fs /dev/sda1 | grep 'Filesystem created:'\n\nYou might have to change the /dev/sda1 to reflect your setup.\nExample output\nFilesystem created: Fri Oct 14 22:40:09 2022\n\nRelying on the date of files, even the \"creation time\" (mtime) can give errors since upgrading packages might have replaced the file and made a new \"creation time\".\nSimilar tools and info might be available on other file systems as well, but I don't know of them.\n\nA: If the installation is recent, look at the oldest entries under /var/log, but after a few weeks the logs will have been rotated away.\nAnother thing to look at is the oldest ctime of a file on the root filesystem; but if the whole installation has been copied (e.g. rescued off a failing disk) at the directory tree level, this gives you the date of the copy.\nIf a heuristic is good enough, look at the date (mtime) of a file that was created during the installation and is unlikely to have been modified since. A good candidate is /etc/hostname; other candidates are /etc/hosts, /etc/papersize, /etc/popularity-contest.conf.\n\nA: I also don't know of a specific command or file. I'm using some heuristics to find the installation date:\nfor dir in {/etc,/usr,/lib}; do\n  sudo find $dir -type f -exec stat -c %z {} \\; | \\\n    sed -e 's,-,,g' -e 's, .*,,' | sort | uniq -c | sort -nr -k 2 | \\ \n    grep -Ev \" [0-9]?[0-9] \"\ndone\n\nThis small script looks for files in /etc and /usr and prints out the last changed date. It does some reformatting and lists the occurrences sorted by date (newest first). Usually the oldest entry is the installation date.\nThis assumes that after an installation are left unchanged. This is in most cases (according to my observation) true, but in special cases it can also give wrong results.\n\nA: the only command that worked for me is - \nsudo ls -alct /|tail -1|awk '{print $6, $7, $8}'\n\n\nA: You can check the installer logs and dates at:\n/var/log/installer\n\nA quick way to find the date through the command line would be by running:\nls -lt /var/log/installer\n\nThat lists in reverse chronological order so the oldest file is at the bottom of the list.\n\nA: The command sudo grep ubiquity /var/log/installer/syslog | less worked for me very well.\n\nA: I don't think there is. \nOn Red Hat / CentOS there is the install.log files that is generated when you install the system, but this doesn't exist on Ubuntu.\nAssuming your logs go back far enough ( mine do ) you can determine the date the base installation was done in /var/log/dpkg.log*\nFor example on my system the first two lines of my oldest dpkg.log file (dpkg.log.4.gz) are\n2010-04-19 11:40:55 startup archives install\n2010-04-19 11:40:55 install base-files <none> 5.0.0ubuntu18\n\nSo I installed this system on 19/04/2010 at 11:40:55. That is correct for this system.\nThere was also a brainstorm idea to add this born date.\n\nA: would it be simple (i may be wrong) just to check software centre, while in there click on 'history' and scroll down to the bottom of your installed updates. Mine shows april 23 2012 first installation. Which is about right when I started using ubuntu? \n\nA: You can type this :\n$ \\ls -lact --full-time / | awk 'END {print $6,substr($7,1,8)}'\n2021-09-08 18:15:47\n\nOr if you have ext2/3/4 filesystem on the / partition, you can type this :\n$ sudo tune2fs -l $(findmnt -n -o source -T /) | awk '/created:/{$1=$2=\"\";print substr($0,3)}'\nWed Sep 8 18:15:47 2021\n\nOr if the directory /var/log/installer still exists :\n$ \\ls -lact --full-time /var/log/installer | awk 'END {print $6,substr($7,1,8)}'\n2020-12-27 14:38:45\n\n\nA: Unfortunately most answers can be misleading for cloud services because they often have an image they created beforehand.\nIn that case the best bet might be delving inside /var/log files and finding evidence of your own earliest boots.\nLogs themselves may be from the image so you might need logs or file/dir creation dates unique to you.\n\nA: For my Linux Mint system the following worked:\n    sudo grep 'RTC time' /var/log/installer/syslog\n\nThe problem was my syslog didn't show years in the time stamps.\n", "Q: How to empty swap if there is free RAM? When I open a RAM-intensive app (VirtualBox set at 2GB of RAM), some swap space is generally used, depending on what else I have open at the time.\nHowever, when I quit that last application, the 2GB of RAM is freed up, but the same swap space use remains.\nFor example, right now, about two hours after having closed VirtualBox, I have 1.6GB free RAM and still 770MB in swap.\nHow can I tell Ubuntu to stop using that swap and to revert to using the RAM?\n\nA: The Linux kernel underlying Ubuntu will automatically \"swap in\" those pages from disk to RAM as needed, so in general I'd say just let it happen naturally.\nHowever, if you really feel that you need to force it, (I can see a scenario where you would want to know the system will be responsive later) you can momentarily disable and re-enable swap\nsudo swapoff -a\nsudo swapon -a\n\nOR alternatively as a single line\nsudo swapoff -a; sudo swapon -a\n\nBe careful doing this, as you may make your system unstable, especially if its already low on RAM. Be sure to have enough free RAM in your system, or you might not be able to free the swap and the OOM-Killer would end up killing some of your processes.\nNote that the swapoff may take a while. This is particularly true if you have lot of swap to be swapped off.\n\nA: I've found that emptying swap can help a lot on systems with slow disks and limited RAM. Of course, as already mentioned, the way to do this is to run sudo swapoff -a; sudo swapon -a. The problem here is that if there's insufficient RAM, doing so will cause all sorts of problems.\nI've written a script that I call toggle_swap that has worked for me for the last several years. It checks for enough free RAM before actually disabling the swap. Here it is:\n#!/bin/bash\n\nfree_data=\"$(free)\"\nmem_data=\"$(echo \"$free_data\" | grep 'Mem:')\"\nfree_mem=\"$(echo \"$mem_data\" | awk '{print $4}')\"\nbuffers=\"$(echo \"$mem_data\" | awk '{print $6}')\"\ncache=\"$(echo \"$mem_data\" | awk '{print $7}')\"\ntotal_free=$((free_mem + buffers + cache))\nused_swap=\"$(echo \"$free_data\" | grep 'Swap:' | awk '{print $3}')\"\n\necho -e \"Free memory:\\t$total_free kB ($((total_free / 1024)) MB)\\nUsed swap:\\t$used_swap kB ($((used_swap / 1024)) MB)\"\nif [[ $used_swap -eq 0 ]]; then\n    echo \"Congratulations! No swap is in use.\"\nelif [[ $used_swap -lt $total_free ]]; then\n    echo \"Freeing swap...\"\n    sudo swapoff -a\n    sudo swapon -a\nelse\n    echo \"Not enough free memory. Exiting.\"\n    exit 1\nfi\n\n\nA: After mucking around with swappiness for a couple of days, I've come to the conclusion that the kernel should be left to its own devices. It knows what it's doing, and it's optimized to give you the best experience. \nUnless you have a really good reason for wanting that disk back, I'd leave it be. \n\nA: Just because swap is allocated, doesn't mean it's being 'used'. Whilst programs like system monitor and top will show some of your swap space being allocated (in your example 770MB) that doesn't mean that the system is actively swapping in/out.\nTo find out if anything is swapping in/out you can use the vmstat command. Leave it running a few seconds to settle down and watch the si (swapin) and so (swapout) columns. If nothing is happening then there is no reason to be concerned.\nHere's the output of running vmstat 1, where you can see my machine is not swapping at all.\nprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa\n 0  0  78588 230788   9596  72196    0    0     0     0  543  652 12  6 78  0\n 0  0  78588 230780   9596  72196    0    0     0     0  531  410  1  0 99  0\n 0  0  78588 230796   9596  72196    0    0     0     0  300  335  1  1 97  0\n 1  0  78588 230788   9608  72224    0    0    40     0  737  762  4  4 84  8\n 5  0  78588 230788   9608  72224    0    0     0     0  415  385  9  3 84  0\n 0  0  78588 230540   9616  72224    0    0     0    44  611  556 55  5 31  0\n 0  0  78588 230532   9616  72224    0    0     0     0  574  662  1  6 89  0\n\nYet here in top you can see I have swap space allocated:-\nMem:    475236k total,   245076k used,   230160k free,     9720k buffers\nSwap:   491512k total,    78588k used,   412924k free,    72476k cached\n\n\nA: You can also set your \"swappiness\" value from the default of 60, this way the swap won't grow so large to begin with. Why the shipping default is set to 60 when the recommended value is 10 perplexes me. From the Ubuntu SwapFAQ:\n\nThe default setting in Ubuntu is swappiness=60. Reducing the default value of swappiness will probably improve overall performance for a typical Ubuntu desktop installation. A value of swappiness=10 is recommended, but feel free to experiment.\n\nBy changing this value to 10 or even 0, you can add a significant and perceivable speed boost to an older system with a slow drive. Setting this value to 0 does not turn swap off for Linux kernel 3.4 and below but with 3.5+ it does so you will want to use a value of 1 if you want to keep it on its lowest setting*.\nI see no reason not to set this to 0 since anything that hits disk is slower than RAM. I have 8 virtual cores, a fast SSD & 8 GB of memory and my swap is set to 0. As of this moment I have 3 virtual machines running, my memory usage is 7.1 of 7.7 GB, my used swap is only at 576KB of 952MB and all systems are running smoothly!\nFrom the Ubuntu SwapFAQ:\n\nThe swappiness parameter controls the tendency of the kernel to move processes out of physical memory and onto the swap disk. Because disks are much slower than RAM, this can lead to slower response times for system and applications if processes are too aggressively moved out of memory.\n  \n  \n*\n  \n*swappiness can have a value of between 0 and 100\n  \n*swappiness=0 tells the kernel to avoid swapping processes out of physical memory for as long as possible\n  \n*swappiness=100 tells the kernel to aggressively swap processes out of physical memory and move them to swap cache\n  \n\nBelow are basic instructions for checking swappiness, emptying your swap and changing the swappiness to 0:\nTo check the swappiness value:\ncat /proc/sys/vm/swappiness\n\nTo temporarily set swap to 0 (as suggested by SpamapS):\nThis will empty your swap and transfer all the swap back into memory. First make sure you have enough memory available by viewing the resources tab of gnome-system-monitor, your free memory should be greater than your used swap. This process may take a while, use gnome-system-monitor to monitor and verify the progress.\nsudo swapoff --all\n\nTo set the new value to 0:\nsudo sysctl vm.swappiness=0 \n\nTo turn swap back on:\nsudo swapon --all\n\nTo permanently set swappiness to 0:\n\n\n*\n\n*sudoedit /etc/sysctl.conf  \n\n*Add this line vm.swappiness = 0  \n\n*sudo shutdown -r now # restart system\n\n\n* With kernel version 3.5+ setting swappiness to 0 does turn it off entirely and a setting of 1 is recommended if you want the lowest swappiness algorithm. source: https://www.percona.com/blog/2014/04/28/oom-relation-vm-swappiness0-new-kernel/\n\nA: Tell the vm to not be so swappy, by resucing the swappiness, by\nsudo sysctl vm.swappiness=10\n\nor even not be swappy as much as possible by\nsudo sysctl vm.swappiness=0\n\nPlease read the documentation of swapfile here:\nhttps://help.ubuntu.com/community/SwapFaq\n\nA: It doesn't affect performance if your swap space is occupied. The only performance penalty is is stuff is going in/out of swap. If nothing is being swapped in/swapped out, then you don't have to worry about anything.\n", "Q: Send OSD notification messages to all systems on a network What I'm trying to do is send caller ID (CID) information from a system running Asterisk+FreePBX to all (3) MythTV frontend systems on my network. I'd like the CID information to pop-up over top of whatever is going on (eg, whether it's on a menu, or playing back a recording). Eventually there may be other information as well, but for now CID would be a great start.\nThe libnotify-style notifications are fine (though I probably need to increase text size to make it visible). I was thinking something like Growl, though this doesn't seem to exist for Linux.\nIdeally I'd just be able to do some kind of broadcast to the whole network, eg, from the FreePBX system I could run a command like:\nnotify --broadcast  --title \"Incoming Call\"  \"Smith J\\n613-555-1234\"\n\nAnd then on any mythtv frontend, it would appear somewhere on screen. \n\nNote: there is a MythNotify plugin, which I have used in a previous iteration of my setup, but it has a severe limitation (I believe based on the way MythTV's OSD stuff works) that it can only display notifications during video playback: not while in menus. I also remember it being a pain to get displaying properly: it uses XML for messaging then XSLT to change to mythtv's XML format. If you want to display something slightly differently, you have to make a small handful of new XML files and even then getting the \"callerid-from-phonebook.xml\" message to actually render to the (remote) \"callerid-from-phonebook-osd.xml\" file for display is some kind of black art. \n\nA: You could do it by using the command-line notification tools.\n\n\n*\n\n*Install the package 'libnotify-bin' on all of the systems on your network, which provides a tool called 'notify-send'.\n\n*Install the ssh server on all the systems on your network and make sure they are configured to allow passwordless ssh logins (see http://www.debian-administration.org/articles/152 for more information on this).\n\n*Set up your notification script on your server to execute notify-send, like this:\nssh username@system1 'notify-send \"Incoming call from Smith J\\n613-555-1234\"'\nssh username@system2 'notify-send \"Incoming call from Smith J\\n613-555-1234\"'\nThis will cause a notification popup on the systems named 'system1' and 'system2'.\n", "Q: How can I install Ubuntu without removing Windows? I need my pre-installed version of Windows 7 (or any other version of Windows), how could I install Ubuntu without erasing it?\n\nA: The instructions below are for Ubuntu 11.10.  Other versions will be similar but might have a slightly different appearance or order. You must make sure that Windows is correctly shutdown (no Hibernation, no Suspend, no Fast Boot) and your NTFS drive is healthy.\n\n\n*\n\n*Boot from your Ubuntu CD or USB stick.  When prompted, choose \"Install Ubuntu\".\n\n\n*Ensure that you meet all the installation prerequisites.  Ideally, connect to the internet at this time as well.\n\n\n*If you have wireless network hardware and there is an available network, you can (optionally) connect to it at this time.\n\n\n*Be certain to choose \"Install Ubuntu alongside Windows\" (or \"other operating systems\" or other similar wording, depending on your system configuration).  This is the important step that will ensure that Ubuntu and windows are both available after the installation.\n\n\n*Choose how much space to give to Ubuntu and Windows.  How much you give each one is up to you.\n\n\n*Complete the rest of the installation by setting your timezone and entering information about your computer and yourself.\n\n\n\n\n*Enjoy the informative slide show while the system installs.\n\n\n*Restart and enjoy Ubuntu!\n\n\n\n*\n\n*http://www.ubuntu.com/download/ubuntu/windows-installer\n\nA: Resize your Windows 7 partition by going to Start > My Computer > Right Click and select Manage > Disk Management > Right click your Windows Partition and Select Shrink Volume. Just shrink to whatever Windows suggests and leave it Unallocated.\nOn the Ubuntu install you select your Unallocated partition and click \"New\" and select the file system as a \"EXT3\" and select the mount point as \"/\" and click Okay (If you dont want swap)\nIf you do want swap type in the amount you want (in MB) select the file system as a \"Swap Partition\" and there is no mount point. Click Okay then you do the step in the paragraph above \nAfter Install, Windows will now be in your GRUB menu with Ubuntu as default but that can be fixed by editing your /boot/menu.lst\n\nA: Did you consider virtualization ?\nIf you just need an execution environment for command line unix tools (programming), virtualization is great !\nThe other advantage is that you have no more risk to wreck your Windows install.\nYou can use Virtualbox which is free, or vmware server, which is also free.\nAs for myself, I'm doing web development with ubuntu 10.4 LTS virtualized with vmware/Win7\n\nA: You can do it either with Wubi or you can install it in a separate partition.\nThese links may be useful:\n\n\n*\n\n*Wubi Guide\n\n*How to partition\n\nA: One way would be to do a Wubi install. That way you would basically install Ubuntu as an application that you run from within Windows. More information on that can be found here and here, as well as here.\nThe other way would be to resize your Windows partition to allow room for Ubuntu. There's a comphrehensive guide on that here.\n\nA: Install Ubuntu in an ext4 partition you created, and GRUB will do the rest for you.\n\nA: 1) You download the ISO of the desired Linux distro\n2) Use the free UNetbootin to write the ISO to a USB key\n3) boot from the USB key\n4) double click on install\n5) follow the straight-forward install instructions\n\nA: I went to ubuntu.com and downloaded the desired OS I wanted.More than likely if your computer is new then it has a 64bit system but check and make sure.  Windows 7 allowed me to put the OS onto a flash drive just as you would burn it to a cd.  I restarted the computer and the loader started and gave me a choice of installing along side of windows.  Choose that and you are good to go.  I did it on the day I bought my Acer laptop and both run smoothly.  It is easier than it sounds, just follow the prompts and you will not have any problems.  Good Luck\n\nA: Late by more than 8 years but I'll post my answer anyway, it may be helpful, tested it on  Winsows 10 (I don't know if it's working on 7 and 8.1)\nYou can partition you Hard drive without removing Windows, by following these steps:\n\n\n*\n\n*Press Windows Key + X and select Disk Management.\n\n*In the Disk Management window, right-click your C: partition and select Shrink Volume.\n\n*Enter the amount of desired space you want to shrink the partition in MB.\n\n\nNow You'll have free disk space where you can install Linux normally.\n", "Q: How to get Eclipse plugins working with Software Center based installation I installed Eclipse from the Software Center. Then I installed a \"Aptana\" plugin  by using:\nHelp -> Install -> New Software.\nThe plugin installed and Eclipse restarted, but I can't see any of the editors that I'd expect to see. If I try installing the plugin again, Eclipse insists that the plugin is already installed, and it is visible under: About Eclipse -> Installation Details -> Installed Software\nHow do I see my new editor windows?\n\nA: I would personally recommend not installing through the Software Centre for this very reason. Keeping things up to date for in-development plugins is a nightmare and there's always the chance that you want to stick with a known-working version but the repo version gets updated.\nIn short, I'd just download it from http://www.eclipse.org, stick it in my /home dir and live happily knowing I have some level of control over my development environment.\nThis of course comes at the cost of keeping it up to date but this is less of an issue as Eclipse can do this itself.\n\nA: It depends on which flavor of eclipse you downloaded from http://www.eclipse.org. You need to get the jee flavor to solve the gef problem(Eclipse IDE for Java EE Developers). Once you have got the jee flavor in your /home, you can install any plugin.\nYou can use the dropins directory found under eclipse to put any of your plugins if you want to skip installing when you change eclipse. Must create the following structure:\n\n\n*\n\n*/home//eclipse/dropins//eclipse/plugins\n\n*/home//eclipse/dropins//eclipse/features\n\n*/home//eclipse/dropins//eclipse/.eclipseextension\n\n\nMany of eclipse plugins comes with this structure. But the plugin aptana creates this structure when installed.\n", "Q: Can I use two USB gamepads to play games in FCE Ultra? I want to buy a couple USB game pads to use with NES emulator FCE Ultra. What I can't find out, is if I have two game pads connected, will FCEU differentiate between them? i.e. map each game pad to each player, or will both game pads button A generate the same key code?\nBTW I'm looking at the Genius MaxFire, Thanks!\n\nA: You can play using two gamepads, yes. There is a tab in GFCE UltraX (recommended over FCE Ultra) called \"Input\" where you can map the buttons to the buttons on the pad. A on one controller will not register as A on the other controller. GFCE UltraX (gfeux) can be installed in Ubuntu by running sudo apt-get install gfeux in a terminal, or simply clicking this link (doesn't work in Chrome).\nAs for the controller, I don't know if it works well in Ubuntu or not (most do), but it seems quite expensive for what it does. If you're open for suggestions, I'd recommend taking a look at a Saitek P380. It costs a fraction as much, has two analog sticks, an omnidirectional d-pad, 4 regular buttons + 4 shoulder buttons and start and select buttons. I have one and it works perfectly in Ubuntu.\n", "Q: What is the right way to connect to Reliance Netconnect+ and share the connection via Wireless? Thanks for this great initiative. I have a reliance netconnect datacard (in India) which I am trying to setup in Ubuntu 10.04 (Lucid).\nI have tried it with the Network manager to create a new Wireless Broadband connection. I have tried all the variations of the protocols etc, but no luck getting it to work. I then installed wvdial and gnome-ppp, using which I am able to connect to the internet quite reliably.\nI read on many forums that people have been able to connect to Reliance Netconnect using the Network Manager directly. If anyone has been able to do this, could you please let me know what setting you used etc? My modem is Huawei, Model EC168C.\nNow, my next problem/question: I want to share the internet connection using what is known as \"ad-hoc (computer-to-computer) connection\" in Windows. Does Ubuntu support a similar feature? Any tips to do this, and/or links to guides that work would be great! \nAlso, in order to make this work, do I need to have the connection working via \"Network Manager\" or would it work even if I connected using wvdial?\nThanks a lot for your answers and help !! Do let me know if any more info is needed.\nCheers,\nMaha\n\nA: Maha,\nI cannot help you with the Reliance problem, however I recently setup my laptop to share its internet connection via adhoc wireless.  You cannot share a wifi internet connection because you are already utilizing your wireless device but you can share a wired connection, aircard or usb tether connection.\n\n\n*\n\n*Confirm that dnsmasq-base is installed and install the dhcp3-server package.\n\n*Left click on network manager, select \"Create New Wireless Network\".  Give it a name, add your desired security.  Click Create.\n\n*Use network manager to connect to the newly created network and you are sharing your internet connection.\nGood luck!\nRay\n\nA: I have a Tata Indicom Photon+ with Huawei E1261. I had to install usb-modswitch and usb-modswitch-data to get the Network Manager to detect it. I am not sure it will work with Huawei EC168C, but you might want to check it out.\nHere is the link: http://digitizor.com/2010/06/28/how-to-use-tata-photon-plus-in-ubuntu-10-04-lucid-lynx/\n(Disclaimer: My blog)\n", "Q: How do I optimize the OS for SSDs? What steps should be taken before/during/after installation of Ubuntu on a Solid State Drive to optimize performance and ensure maximum durability of the drive?\n\nA: SSD Life\nGenerally I wouldn't bother - the worries about SSD life are overblown. You can read this detailed article about why you really shouldn't worry. In short the circuitry inside modern SSDs manages wear-levelling for you, and they know how to do it far better than you.\nIn the article is a calculation of the life of an SSD that is receiving writes at a continuous rate of 80M/s. The life is 51 years. That is based on 2007 technology - SSD life will be longer now. And you almost certainly don't write to your SSD at 80M/s 24 hours a day.\nSSD Performance\nHowever performance degradation over time can be a problem, and TRIM is the solution. There are two options\n\n*\n\n*automatic/online TRIM, aka discard\n\n*manual TRIM\n\nYou have to enable automatic TRIM yourself . (Basically you add the discard option to your mount options, provided you are using ext4.) I have found a blog post reporting that the discard option slows down your system when deleting files.\nYou can occasionally do it manually (or in a cron job) using fstrim. If you just have one partition then all you need to do is:\nsudo fstrim /\n\nNote that fstrim is only available in 11.10 and newer. For older systems you will need the wiper.sh script. I found the script at /usr/share/doc/hdparm/contrib/wiper.sh.gz on my system.\nIf you're wondering, the problem that TRIM solves, as described by Wikipedia, is:\n\nSSDs store data in flash memory cells that are grouped into pages, with the pages (typically 4 kB each) grouped together into blocks (typically 128 pages per block, totaling 512 kB). NAND flash memory cells can only be directly written to when they are empty. If they are considered to contain data, the contents first need to be erased before a write operation can be performed reliably. In SSDs, a write operation can be done on the page-level, but due to hardware limitations, erase commands always affect entire blocks. As a result, writing data to SSD media is very fast as long as empty pages can be used, but slows down considerably once previously written pages need to be overwritten. Since an erase of the cells in the page is needed before it can be written again, but only entire blocks can be erased, an overwrite will initiate a read-erase-modify-write cycle: the contents of the entire block have to be stored in cache before it is effectively erased on the flash medium, then the overwritten page is modified in the cache so the cached block is up to date, and only then is the entire block (with updated page) written to the flash medium. This phenomenon is known as write amplification.\n\n\nA: 4) enable automatic TRIM \nIf your SSD supports it, you should also enable automatic TRIM (as described here)\n\nA: UPS is required.In the /etc/sysctl.conf file\nvm.dirty_writeback_centisecs = 15000\nvm.swappiness = 10\n\nFind the configuration file daemon, usually /etc/syslog.conf или /etc/rsyslog.d/ and all the paths of the form /var/log/ change by writing a minus sign (\"-\") in front of ways.Before\nmail.err \n/var/log/mail.err\n\nAfter\nmail.err -/var/log/mail.err\nuse FS btrfs and use the -o ssd option \nMore http://vasilisc.com/speedup_ubuntu_eng#speedup_fs\n\nA: I would not add this line to your fstab, var/tmp folder is meant to survive reboots, and that could cause issues for you.\ntmpfs /var/tmp tmpfs defaults,noatime,mode=1777 0 0\n\nWhen I configure new system I leave all the tmp folder commented out this way if anything happens I can check the logs and stuff. Then once I have the main system setup I will un-comment them, but I never add the above line, here is what I use: \ntmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0\ntmpfs /var/log tmpfs defaults,noatime,mode=0755 0 0 \ntmpfs /var/log/apt tmpfs defaults,noatime 0 0\n\nAnd if I am having any issues with my system I comment those out to be able to check everything even after a reboot or forced reboot after a lockup.\nAlso you don't need nodiratime, noatime option takes care of both by itself.\nAs for TRIM, if your hw/sw support it, it's a must, I do not use discard in fstab. I create a daily cron, because my PC is always on, by doing this:\ngksu gedit /etc/cron.daily/trim\n\nThen add this to file and save (If you dont have a seperate /home partition on ssd, or have other parts that are on ssd you should get the idea how to modify this:\n#!/bin/sh\nLOG=/var/log/trim.log\necho \"*** $(date -R) ***\" >> $LOG\nfstrim -v / >> $LOG\nfstrim -v /home >> $LOG\n\nThen make the file executable by:\nsudo chmod +x /etc/cron.daily/trim\n\nI also edit my rc.local like so:\ngksu gedit /etc/rc.local\n\nAdd this above \"exit 0\" and below the last #:\n# Modification for SSD\n# you may want to add more folders to be checked/created to this list\nfor dir in apparmor apt ConsoleKit cups dist-upgrade fsck gdm installer news ntpstats samba speech-dispatcher unattended-upgrades; do\n  if [ ! -e /var/log/$dir ] ; then\n    mkdir /var/log/$dir\n  fi\ndone\n\nYou can copy and paste from here so there is no errors, to the layman it looks out of whack, it is not.\nI have also read that leaving 10% of your ssd drive unformatted can help extend life, that remains to be seen. I have not read that much into this so I can't vouch if it makes sense to do so.\nThis is the best all around guide, he did not skim around Google for a day and then come up with a guide, you should check it out HERE\n\nA: TRIM allows an operating system to inform an SSD which blocks of data are no longer considered in use and can be wiped internally. Trimming enables the SSD to handle garbage collection overhead, which would otherwise significantly slow down future write operations to the involved blocks, in advance.1 \nIn Ubuntu 14.04 a new feature has been added to the util-linux package that regularly trims SSDs automatically, but only Intel and Samsung SSDs have TRIM enabled by default, because some cheap SSDs can even brick themselves when running TRIM.2 The contents of /etc/cron.weekly/fstrim in Ubuntu 14.04:\n#!/bin/sh\n# call fstrim-all to trim all mounted file systems which support it\nset -e\n\n# This only runs on Intel and Samsung SSDs by default, as some SSDs with faulty\n# firmware may encounter data loss problems when running fstrim under high I/O\n# load (e. g.  https://launchpad.net/bugs/1259829). You can append the\n# --no-model-check option here to disable the vendor check and run fstrim on\n# all SSD drives.\nexec fstrim-all\n\n1https://en.wikipedia.org/wiki/Trim_%28computing%29\n2How is Trim enabled?\n\nA: There are several points:\nAlignment:\nWhat is often pointed out is the right alignment of the partition. This should be equal to the block size of the SSD. Play safe and make your partitions aligned to MiB boundaries. Note that you can't do this with the Ubuntu installer's partition tool (which uses MB not MiB), but you can boot the live CD, use Gparted (which uses MiB), then click Install to use the partitions you set up.\nThe right scheduler:\nA important point is the scheduler wich should be noop. You can set this scheduler via kernelparameter elevator=noop or via a entry echo noop > /sys/block/sda/queue/scheduler in you rc.local.\nMountflags:\nI would recommend noatime and discard\nTmpfs\nTo put tmp on  a ramdisk can increase the life time of the ssd.\nTo use this put the following line in you fstab: none            /tmp            tmpfs   defaults        0       0\nGenerally if you want to dive deeper into this topic I would recommend this excellent wiki-article.\n\nA: Ok \"long story short\":\n\n\n*\n\n*Yes. It is like a normal hdd. Here is a good overview.\n\n*Some special extras, that I will cover.\n\n*Quite good. I use it with a server.\n\n\nFormat as ext4 during install, and create a small swap ~1 GB. After install edit fstab with sudo gedit /etc/fstab and add the following line\ntmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0\n\nThis will create a ramdrive for your temp files, which will lower the ageing. Also add noatime,nodiratime,discard to your ext4 line after defaults. This will also lower wear, and enable TRIM function. Save and reboot.\n\nA: It is clear that /var/tmp should not be in tmpfs since by definition it's content needs to be preserved beyond reboots:\n\n\n*\n\n*Differences between TMP and VarTMP\n\nA: There are some good info How to tweak and optimize SSD for Ubuntu, Linux Mint from http://namhuy.net/1563/how-to-tweak-and-optimize-ssd-for-ubuntu-linux-mint.html you might be interested in\nUse preload\nTo install preload on Ubuntu, Linux Mint or debian based distributions\n# apt-get update && apt-get install preload\n\nTurn off your swap\nTo change swappiness setting:\n$ su -\n# nano /etc/sysctl.conf\n\nAnd add this line into sysctl.conf file.\nvm.swappiness = 10\n\n\nA: Fast tuning course for your SSD on Ubuntu:\nfilesystem\nArch wiki mentions few preferable options for SSD file system - one of them is unstable, others are ext* ones. I assume ext4 is one of the best picks.\nNote: In case of ext4 you may want to use discard mount option.\nfstab\n# <file system> <mount point> <type> <options>                                  <dump>  <pass>\nproc            /proc         proc   nodev,noexec,nosuid                        0       0\ntmpfs           /tmp          tmpfs  nodev,nosuid,noatime,mode=1777             0       0\n/dev/sda1       /             ext4   defaults,noatime,discard,errors=remount-ro 0       1\n/dev/sda2       /home         ext4   defaults,noatime,discard,user_xattr        0       2\n/dev/sda3       /windows      ntfs   defaults,noatime,discard,umask=007,gid=46  0       0\n\nFew important things here are:\n\n\n*\n\n*For systems with >=2 gigs of memory, locating /tmp in the RAM is desirable.\n\n*No swap partition. Nowadays it's needed only for hibernation, since modern machines has pretty big amount of RAM.\n\n*noatime and discard options. Info is here.\n\n\nscheduler\nConsider switching from the default scheduler, which under most Linux distro's is cfq (completely fair queuing), to the noop or deadline scheduler for an SSD. Using the noop scheduler, for example, simply processes requests in the order they are received, without giving any consideration to where the data physically resides on the disk. This option is thought to be advantageous for SSDs since seek times are identical for all sectors on the SSD.\nAdd following to /etc/rc.local:\n# SSD performance tuning\necho noop > /sys/block/sda/queue/scheduler\n\ninfo\none two\n\nA: I have successfully used several different techniques to improve the way Ubuntu uses the storage device, whether that be solid state or traditional drive.\nFor SSD's you are looking to minimise the number of times the drive is written too, as reads should not add wear to the drive.\n1) Manage the swap file\nIf you do not hibernate your computer and you have ample RAM memory to run all your applications, then in theory you do not need a swap partition.\nIf you have a mix of SSD and hard drives, place your swap partition on the hard drives only.\n2) No Writes for Read Timestamps (suitable for SSD's and hard drives)\nMounting your partitions with the options noatime and nodiratime will stop timestamp writes when you read files and folders.  These timestamp writes are not generally required unless you use a local mail server client such as mutt. The reason this is generally a bad idea, is because every read will produce a write when updating the timestamps. This decreases the life of the SSD.\nEdit your /etc/fstab configuration file (carefully - take a backup to be sure as breaking your fstab configuration can prevent you system from working):\ncp /etc/fstab ~/fstab-backup\ngksudo gedit /etc/fstab\n\nEdit the mounting options for your partitions by adding the text noatime and nodiratime to the lines defining your root (/) and other partitions if you have them (/home) - Note: if you have a /home partition, start with that just changing that partition if you are concerned about breaking something \n# / was on /dev/sda2 during installation\nUUID=587e0dc5-2db1-4cd9-9792-a5459a7bcfd2 /               ext4    noatime,nodiratime,errors=remount-ro 0       1\n\n# /home was on /dev/sda3 during installation\nUUID=2c919dc4-24de-474f-8da0-14c7e1240ab8 /home           ext4    noatime,nodiratime,defaults        0       2\n\nYou will need to reboot your machine before these changes take effect\n3) Minimising writes from the OS and applications\nAssuming that you are not running a mission critical product server, most people do not look at logs should something go wrong (especially as serious errors are rare for most Ubuntu users).  Therefore you can configure Ubuntu so all logs get written to RAM memory rather than the SSD.\nNote: only make the following changes when you have installed all software you are going to use (especially things like Apache web server), otherwise you may experience some issues with missing directories in /var/log\nFor background to this approach, see prolonging the life of your flash drive on ubuntu-eee.com \nOpen /etc/fstab with an editor (assuming you have backed up the /etc/fstab file)\ngksudo gedit /etc/fstab\n\nAdd the following lines at the end of the fstab file and save:\n# Uncomment these after all server based applications installed - eg. apache\n#tmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0\n#tmpfs /var/tmp tmpfs defaults,noatime,mode=1777 0 0\n#tmpfs /var/log tmpfs defaults,noatime,mode=0755 0 0 \n#tmpfs /var/log/apt tmpfs defaults,noatime 0 0\n# none /var/cache unionfs dirs=/tmp:/var/cache=ro 0 0\n\nYou will need to reboot your machine before these changes take effect\nSee also:\n\n\n*\n\n*How to enable TRIM?\n\nA: How to tweak and optimize SSD for Ubuntu, Linux Mint\nEnable TRIM\nTRIM (Trim command let an OS know which SSD blocks are not being used and can be cleared)\nBack up fstab first in case something wrong happen.\n# cp /etc/fstab ~/fstab.bk\n\nEdit fstab file\n# nano /etc/fstab\n\nAdd discard to your ssd drives or partitions, after ext4\nUUID=bef10b86-494d-41c6-aa46-af72cfba90fd / ext4 discard,errors=remount-ro 0 1\nAdding noatime and nodiratime\n\nnoatime and nodiratime are mount options in linux for linux file system. noatime disables atime updates on file system, and nodiratime will disables atime updates on directory system. By adding noatime and nodiratime will greatly reduce ssd load means performance gains.\nEdit fstab file\n# nano /etc/fstab\n\nAdd noatime,nodiratime to your ssd drives or partitions, after ext4\nUUID=bef10b86-494d-41c6-aa46-af72cfba90fd / ext4 discard,noatime,nodiratime,errors=remount-ro 0 1\n\n\nA: I suggest to place only those things which are read at boot time on the SSD any maybe applications which require much time to load.Data and logs and other uncritical things I would locate on a normal HDD.Also you could setup your ubuntu to only load a big initramfs from SSD at boot time and not write back changes to ssd.This has the benefit, that changes to this partition are not persistent which is sth like a protection for your boot system.Therefor you would need much more RAM of course.\nI would e.g. place the partitions\n/, /etc, /usr, /boot, /lib 32/64 on SSD while sth like\n/opt, /bin, /sbin, /root, /home and even swap (increase RAM!!!) on HDD\nWikipedia says:\n\nThe Linux kernel supports the TRIM function starting with version 2.6.33. The ext4 file system is supported when mounted using the \"discard\" parameter. The most recent disk utilities (and therefore installation software that make use of them) also apply proper partition alignment.\n\nFor backups there are many ways, simplest of which is (r)sync plus cron job.\n", "Q: How to create a permanent \"alias\"? If you create an alias for example: \nalias cls=\"clear\"\n\nIt exists untill you kill terminall session. When you start a new terminal window the alias doesn't exist any more. How to create \"permanent\" alias, one that exists in every terminal session?\n\nA: See http://www.joshstaiger.org/archives/2005/07/bash_profile_vs.html for the difference between ~/.bash_profile and ~/.bashrc\n~/.bashrc is run every time you open a new terminal, whereas ~/.bash_profile isn't. ~/.bashrc contains the following, which includes the ~/.bash_aliases file. This would be the most appropriate place to add your alias.\n# Alias definitions.\n# You may want to put all your additions into a separate file like\n# ~/.bash_aliases, instead of adding them here directly.\n# See /usr/share/doc/bash-doc/examples in the bash-doc package.\n\nif [ -f ~/.bash_aliases ]; then\n    . ~/.bash_aliases\nfi\n\n\nA: Stick that command in the last line of your ~/.bash_profile\n\nA: Add your line into ~/.bashrc or into ~/.profile / ~/.bash_profile for remote logins.\nIf you want the command being executed for all users, put it into /etc/bash.bashrc.\nEdit: In the latest versions of Ubuntu, ~/.bashrc automatically sources ~/.bash_aliases, so permanent aliases are best put into this file instead.\n\nA: You can put such aliases in the ~/.bash_aliases file.\nThat file is loaded by ~/.bashrc. On Ubuntu 10.04, the following lines need to be uncommented to enable the use of ~/.bash_aliases. On Ubuntu 11.04 and later, it's already enabled:\nif [ -f ~/.bash_aliases ]; then\n    . ~/.bash_aliases\nfi\n\nThe aliased command will be available on any new terminal. To have the aliased command on any existing terminal one need to source ~/.bashrc from that terminal as,\nsource ~/.bashrc\n\n\nA: You can add the function below to your .bashrc file.  \nfunction permalias () \n{ \n  alias \"$*\";\n  echo alias \"$*\" >> ~/.bash_aliases\n}\n\nThen open a new terminal or run source ~/.bashrc in your current terminal. You can now create permanent aliases by using the permalias command, for example permalias cls=clear.\n", "Q: How to start terminal with present working directory as \"Home\" instead of default \"Root\"? When I start my terminal the current working directory is always \"/\". I want it to start from \"/home/<username>\" i.e. my home. \nAny solution for this?\n\nA: When you open up a new terminal, the current working directory should be your home folder.\nnevon@loltop:~$ echo ${PWD}\n/home/nevon\n\nThat said, if this is not the case for you, I suppose you could append the following to the end of your .bashrc file:\ncd /home/username\n\n\nA: If the initial working directory for a terminal is not your home directory you are likely to have a serious configuration problem.\nCheck the following:\ngrep $USER /etc/passwd # Should show /home/youruser before the shell location\n\nCheck your home dir permissions/owner:\nls -ltrd $HOME # You must be the owner\n\nMake sure you are not doing a 'cd' on your shell startup scripts: \n~/.profile ~/.bashrc\n\n\nA: I would also check the configuration of the user account. Probably the home directory configuration of the user is set to \"/\" and not \"/home/<username>\".\n\nA: I added --working-directory=~/ to the command executed by my keyboard shortcut in order to fix this.\n", "Q: How to increase printers buffer while printing via command line? I have a Epson Stylus P50 usb printer and i need to print many copies (50~100) of some .prn files created via windows.\nI cannot alter/convert those files; They need to be printed exactly as they are.\nI installed the printer with cups and gutenprint drivers for epson R285 (there is not much difference between the 2 printer models).\nMy problem is that printing the prn with\nlp -d printer_name -n 100 /path/to/file.prn\n\nor\nlpr -P printer_name -# 100 /path/to/file.prn\n\ndoes not work as expected; Randomly the printer stops, in CUPS I got the error Unable to write 9640 bytes on printer_name and the jobs queue happens to be cleared automatically.\nSometimes, the printer prints 1~2 copies before stopping, but often it stops with the first copy.\nI guess the problem is that Ubuntu expects the printer buffer is bigger than it actually is... but I really do not know.\nSo, is there a way to increase the printer buffer, or to lower the buffer that Ubuntu expects the printer to have?\nEdit: the error happens even giving just 1 copy.\n\nA: That bug might be relevant to your case, unfortunately it does not provide a solution.\nIf you're affected by that bug you should mark the bug as affecting you (upper left side) and subscribe to the bug.\n", "Q: Seamless Citrix - full screen When I log into Citrix from my laptop with 10.04, and click on the windows RDP app to launch, and select full screen, it only fills in between the gnome panels, and adds scroll bars.  This does not work well at all.  And I'd love to get a fix (as a work around I tell citrix to use a full-screen session, not seamless, and this works as expected, but has it's own usability problems)\nLogging in on my desktop with Ubuntu 10.04, full screen works correctly. The only difference between the computers is the laptop has intel graphics and the desktop nvidia.\nThanks!\n\nA: Have you tried to use rdesktop directly?. It's the real program doing the talk to Citrix.\nYou can try it from the command line:\n$ rdesktop -f computer-name-or-ip\n\nWhere -f is the switch for full screen. If it works, then there are other frontends for rdesktop in the repos, you could try them to see if some one behaves correctly, just search for rdp in the Software Centre. If it doesn't maybe the nxClient from NoMachine could work, it's a free (as beer) but closed source product.\nI don't know any other implementation of rpd that works on linux. But maybe there is some nice java or flash client out there.\n\nA: How do you launch citrix? Do you launch through a ica file or through a web frontend? If it's the later you should be able to go into settings in the web ui and change the window settings.\nTry changing it to a percentage of the screen and put 99% or something.\nTry Ctrl+Alt+Break for changing between windowed and full screen. It's hotkeys for the windows version. I've never used em and can't test it right now, but it's worth a try.\n", "Q: How should Ubuntu be promoted? Sorry for being a bit subjective but how can we persuade other people we know to use Ubuntu...\n\nA: I've brought a number of people from Windows to Ubuntu.  There are several points that usually end up being the strongest sells:\n\n\n*\n\n*They want to have me as a technical resource when they have computer problems.  I tell them I will only support them if they run Ubuntu, since I don't really use Windows myself anymore myself.\n\n*They are suffering with spyware and viruses on Windows and want to escape that, but don't want to shell out for a new computer.  They like the idea that Ubuntu is immune to all this tends to resonate with them.\n\n*I try to always have a non-technical person like my wife with me, as they can speak more peer-to-peer and reassure them that you don't need to be a computer expert or anything.  They also tend to be able to explain things in a way that newbies can understand, when I'd be giving Too Much Information.\nI usually leave all the stuff about the free software ethos as secondary, just frosting for them.  Some people groove to that, but for most people it's not a selling point; if it were, they'd probably have tried out Ubuntu already.\nI also don't talk about the free cost of Ubuntu.  That can make them think, \"Hmm, must not be any good\".  Instead I'll say, \"You pay for a support contract - that's how they make money, and they're actually pretty good.  But that's optional, if you don't think you'll need it, you can use it without paying anything, on as many computers as you want.\"\n\nA: My advice is restricted, but persistent advocacy: tell your friends (or Facebook \"friends\") about all the good stuff, but don't be too pushy. Although Ubuntu has many virtues, so does MacOS X, and even Windows has its advantages - not to mention the other Linux distros. Don't forget that when praising your system of choice.\nActions speak louder than words. Show how much can be accomplished in Ubuntu, how elegantly it works. In my experience, showing the obvious advantages really makes an impression: the system is fast and reliable because it doesn't need a virus scanner; it comes with a full-featured word processor preinstalled; it has beautiful desktop-effects only a mouse click away; for the most part it works instantly, without any driver installation.\nTwo more things are really appealing and ought to be highlighted: the liberty of free software, with all its ethical and legal advantages, and the community of bright and helpful people - ubuntuforums.org, wikis, and now ubuntu.stackexchange.com. Starting with these, you won't persuade everyone, but you may convince some, and those may be the ones who contribute back to Ubuntu in the future.\n\nA: you can't: it's a matter of honor.\nif one believes that he is on top of the time with windows, you can't change their mind. nobody is pride to use a os for free even if he has no money for windows, they will rather use an old cracked XP... So while this also works they have at least the experience to work with the os of the biggest software producer.\nthat's just my 5 cents.\n\nA: That is like asking how you should promote your favorite ice cream... there are endless ways....\n\nA: How I Promote Ubuntu :\n\n\n*\n\n*Using It Myself: People who walk past me are curious and ask \"What is that ? Windows ? \" . Then I tell them it is \"Ubuntu\".\n\n*Bringing ISO's and CDs on-the-go: While some people do know what Ubuntu is ,they may  have in mind that \"Nah ,Windows is better \" . Offering them a CD or an ISO can let them try out Ubuntu and they may even install it.\n\n*I'm on a project (by myself) to offer free Ubuntu CDs to all the people who need them. Although CDs are redistributions , it is being shipped free of ANY charges to people (if they are in Malaysia).\nAnyways , I'm sure there are a lot more ways we can promote Ubuntu. You can check out this website if you want some Promotional Materials. The Spread Ubuntu website contains a variety materials such as brochures , posters , packaging and more.\n\nA: Use it everyday! That's the most effective way :)\n", "Q: Why does Ubuntu Download recommend 32-bit install? Update for 13.10: 64-bit version is now the default and 32-bit is labelled \"for machines with less than 2GB RAM\"\nThe Ubuntu desktop download screen has a pair of radio buttons you use to select whether you wish to download the 32-bit or 64-bit version.  The 64-bit version is labeled \"Not recommended for daily desktop usage.\"  If you have a 64-bit processor, why would you not want to use the 64-bit version of Ubuntu?\nUpdate for 10.10: They've removed the \"Not recommended\" label from the 64-bit version and added a \"Recommended\" label to the 32-bit version.\nUpdate for 11.04: Same as 10.10.\nUpdate for 12.04: Still says \"Recommended\" next to 32-bit version of desktop\nUpdate for 12.10: 32-bit version of desktop is still default, says \"recommended\"\nUpdate for 13.10: 64-bit version is now the default and 32-bit is labelled \"for machines with less than 2GB RAM\"\n\nA: As far as I know, 64-bit works fine, with the exception that some people have had problems with Adobe Flash.\nAlso, a 64-bit operating system will not work on a 32-bit PC but a 32-bit operating system will work on a 64-bit PC. This is probably the reason behind this warning (although it could be worded better).\nThe Ubuntu community wiki post on the subject recommends using 64-bit Ubuntu if you have a 64-bit pc and no specific reason not to use 64-bit. \nThere are limitations to 32-bit cannot access much more than 3GB of RAM (although this problem is addressed with the PAE kernels) but 64-bit has no problem here. If you have >3GB of RAM, consider using 64-bit.\n\nA: I assume that the main reason is this: the 32-bit version works on pretty much every single PC and Mac in circulation currently, so if you don't have any idea what 32-bit and 64-bit mean, you should just download the 32-bit version and install it, and it will just work. And if someone doesn't have any idea about the difference between the 32- and 64-bit versions, it;s unlikely that they're going to be doing anything where the difference has any observable effect.\nIn other words, for the 64-bit version, you have to figure out whether your system supports it. For the 32-bit version, you don't. It works on \"everything.\"\n\nA: I used to use 64bit Ubuntu on my desktop, and 32bit on my laptops.  For the most part I saw no differences, but there were some small niggles:\n\n\n*\n\n*As mentioned above, Flash historically hasn't been very well supported on 64bit.  I didn't think I'd care about this, but actually this was a fairly major annoyance for me.  I ended up using the 32bit version of flash, manually installed.  Recently Adobe has put out a 64-bit Flash, so possibly this is a thing of the past (I haven't tested it yet).\n\n*Java (and other software) on 64bit uses more memory, and this can have some performance impacts.  I don't use much java so haven't really experienced this issue but guess it's pretty well known.\n\n*It used to be that a lot more people ran 32bit than 64, so once and a while you'd run into a 64-bit specific problem that would tend to take a long time to get fixed.  This has gotten a LOT better in recent years though, but for someone that really wants everything to Just Work, you might prefer 32-bit.\n\n*64bit means that memory pointers can address higher amounts of memory.  If your system has 4gig or more of RAM memory, and you use apps that need lots of RAM, that can be a reason for using 64bit.  However, in recent years the PAE kernels for i386 have become standard, and these do permit addressing >4gig.\n\n*If you're a developer and you run 64-bit, you can build both 32-bit and 64-bit executables fairly easily (e.g. with pbuilder).  Building 64-bit binaries on 32-bit seems not possible (well, at least not without jumping through some hoops).\n[Update 12.04]\nJust recently I've reinstalled the amd64 version of 12.04, and find it a lot better than it was when I originally wrote the above.  I've not tested Java but Flash is definitely working as well as it had on 32bit.  Also, completely anecdotally but it seems like people are running 64-bit more often than 32-bit these days.\n\nA: I ran some tests to compare 32 vs 64 bit configurations on various applications on a couple of sample machines (small memory Atom based netbook) and a typical laptop.  I compared memory usage, power consumption for the following:\n\n\n*\n\n*32 bit kernel, 32 bit userspace\n\n*64 bit kernel, 32 bit userspace\n\n*64 bit kernel, 64 bit userspace\n\n\nData: http://kernel.ubuntu.com/~cking/x32/Quantal-x32-power-memory-comparisons.ods\nThe bottom line is that for small systems, 32 bit is a good fit, where as if you have enough memory and you have a modern 64 bit capable CPU, then 64 bit is suitable.  But there is more detail in the spreadsheet than than simple summary.\nI also ran some tests comparing 32 bit, 32 bit pae and 64 bit a while ago, here are the results:\nhttp://kernel.ubuntu.com/~cking/power-benchmarking/blueprint-foundations-p-64bit-by-default/hpmini-and-x220-tests/results-3/results.txt  - see the conclusions at the end for a overall summary.\n\nA: At same time Ubuntu Wiki says the opposite:\nUnless you have specific reasons to choose 32-bit, we recommend 64-bit to utilise the full capacity of your hardware.\nhttps://help.ubuntu.com/community/32bit_and_64bit\n\nA: 64 bit is only really useful if you have more than 4 gigs of RAM. If you use the 64 bit system, eventually you will run into a situation where a driver or even a program is not available in 32 bits. Adobe pulled its 64 bit Flash for a while. Canon printer drivers are only available in 32 bit (but can be force installed). I used both 64 and 32 bit systems, and found that 64 bit did not provide me any advantages (both ran at the same speed as far as I could tell).\n\nA: I wrote the last Launchpad Bug #585940 description myself a long time ago and the only thing I can say I have been unable to discover why is there so much misinformation around this topic.\nI think the most probable answer is the 64-bit edition is much more buggy than the 32-bit one, since this is what my own experience of only using Ubuntu in my daily life suggests. On the other hand this is only speculation since I have not performed a formal comparison between editions.\nAs far I'm able to work well enough using it I simply choose to use the 64-bit edition because is the one I want to be improved, since in time it will clearly be the best option and it will be here before we have noticed. By then I want us people being using a complete stable distribution.\n\nA: Use to, most computers where 32bit. Now most newer CPU's is 64bit. And 32bit is compatiable with both versions.\n\nA: One disadvantage to running the 32bit version non-PAE kernel is that your processes aren't protected with the CPUs non-executable (NX) bit, which can make it easier for attackers attempting to exploit flaws in software. See the Security Team's Features discussion on it for more details. In recent Ubuntu releases, there's an emulation mode, but it's of limited effectiveness.\nAlso, the randomization space available for things like Address Space Layout Randomization (ASLR) is much, much smaller when using 32 bits, potentially to the point of being brute forcible.\n\nA: This is actually just a mis-wording of sorts. According to LaunchPad Bug #585940 It's meant to convey that typical desktops are 32-bit whereas more recent desktops are 64-bit. Since the 32bit install will always work on both 32bit and 64bit machines it remains \"recommended.\"\n\nA: The reason is that there are still lots of 32-bit processors in production now, and most computer users do not know what 32-bit and 64-bit are.\nIf someone with 32-bit computer(s) downloads the 64-bit version, it is very certain that it will not run on his/her computer(s) because 32-bit processors cannot understand and handle 64-bit commands. However, if someone with 64-bit computer(s) downloads and uses the 32-bit version, it works because 64-bit arch is backwards-compatible to 32-bit.\nOne more issue is that 32-bit software demands less hardware power.\nUpdate: As of 13.10, Ubuntu Download page now recommends the 64-bit download and offers the 32-bit option \"for machines with less than 2GB RAM\". This is because most computing devices that could potentially have Ubuntu installed on today are 64-bit, and only devices with less than 2GB RAM may contain a 32-bit CPU.\n\nA: Any modern CPU is capable of running 64 bit.\nBoth Intel and AMD, even a older AMD sempron supports single core 64bit.\nIf You don't need memory hungry applications then there is no need to go 64bit.\nI have 16GB ram and sure 64 bit , 32bit would be a stupid move.\nCounts also for windows 7 en 8.\n", "Q: How to connect my printer to localhost? When I try to print, for some reason all the printers I previously had installed have disappeared.\nI pulled up the \"Printing\" dialog, and I see that localhost is \"Not connected,\" but when I try to connect, it fails. I have looked this up in various places, but the only two suggestions I've found have not worked. The first was to put apparmor into a less strict mode, and the second was to reset CUPS. I've done both of those things, and to no avail.\nI just want to print again!\n\nA: What do you think where 'localhost' aka 127.0.0.1 goes? Thats your network-card and if there is a printer connected it will have annother ip-address. So printing on 127.0.0.1 will not work.\nTry install a new printer in your printing dialog, if it will be identified thats ok, if not post some more information about your network.\n\nA: How funny! I just was looking for a permanent solution to this problem. \nHere is what will fix it when it happens. \nOpen Terminal: \ntype: sudo /etc/init.d/cups restart\nhit enter\nenter your password and the problem should be solved. \nMy issue is that it is not a permanent fix. I have to keep repeating it anytime my computer is restarted. This seems to be a new issue with 10.04. \nI would love to hear a permanent solution. \n\nA: /var/run/cups/cups.sock\ncheck this is the path to your cups server.\n11.10:\nClick ubuntu logo and then search printing. Hover near the top to get server and click this then click edit and check the path above is entered\nbefore unity:\nprinting preferences ( think it's system on the menu at the top ) basically the window with all your printers in. Click server and edit and then check the path at the top is entered.\nDon't forget to logout and log back in if you've changed the path. \n", "Q: I have problems installing Ubuntu 10.04 I tried to update Ubuntu 9.10 to 10.04LTS.  I have several issues and had to go back to Ubuntu 9.10.  First issue is the mouse has a drag time even when I click to speed it up. Second issue is sometimes the keyboard will freeze up and the last letter I type will repeat for about 20 times as if the key gets stuck  then the whole system freezes up and I have to reboot.  The third issue is I have DSL and the 10.04 doesn't seem to want me on the internet--In firefox I get server not found and finding software app just sits idle like it is searching for the internet.  Please help.  I love the 9.10.  I have an E-machine t5212 and 320 gb (replaced the  original 200gb after a virus shut down windows xp hard drive).  The  video card is Radeon Xpress 200.  Intel Pentium D processor and 1024mb DDR2.  I am new to Ubuntu but I have used it for about a year and love it.\n\nA: I always do a clean install... always!\nI have a few things for you though before clicking \"close\" or \"back\"\nThere may be a conflicting package on your system or something causing bloat, get rid of them by typing:\nsudo apt-get autoremove\n\nWhich will get rid of libs and packages which are not needed/conflicting/causing bloat.\n\nA: What about a test-drive with the Live-CD (without an installation) to check if the hardware is recognized and evey thing work well?\nHow did you change back to ubuntu 9.10 - i am just interested.\n", "Q: How can you monitor total internet data usage across reboots? Some broadband providers impose a monthly download limit, charging extra if you go over. It is also quite easy to exceed some of the lower limits just by installing/updating packages and 'normal' browsing (which to me includes streaming TV programs and movies).\nThis means that you need to limit the amount you use the internet, yet it is hard to know when.\nThe System Monitor helps a bit with this by giving a total received/total sent in the networking section of the Resources tab. However, this is reset every reboot. It would be good if there was a way to have a monthly total received so you can know how close you are to exceeding your limit and maybe even be given warnings if it looks like you are going to exceed the limits.\nDoes anyone know of a way to achieve this?\n\nA: vnStat - Light Weight Console-based Network Monitor\nvnStat is a console-based network traffic monitor for Linux and BSD that keeps a log of network traffic for the selected interface(s). It uses the network interface statistics provided by the kernel as information source. This means that vnStat won't actually be sniffing any traffic and also ensures light use of system resources.\nIn this tutorial we'll review:\n\n*\n\n*Features\n\n*Installation\n\n*Configuration\n\n*Start Systemd Service\n\n*Usage (from command line)\n\n*Conky example\n\nFeatures\n\n*\n\n*quick and simple to install and get running\n\n*gathered statistics persists through system reboots\n\n*can monitor multiple interfaces at the same time\n\n*several output options\n\n*summary, hourly, daily, monthly, weekly, top 10 days\n\n*optional png image output (using libgd)\n\n*months can be configured to follow billing period\n\n*light, minimal resource usage\n\n*same low cpu usage regardless of traffic\n\n*can be used without root permissions\n\n*online color configuration editor\n\nInstallation\nnvStat is in the official repositories so no need to link to a new ppa. To install create a Terminal instance using Ctrl+Alt+T and type at the prompt:\nsudo apt-get install vnstat\n\nAfter installation, keep your Terminal open for the following sections. There is no need to reboot.\nConfiguration\nPick a preferred network interface and edit the Interface variable in the  /etc/vnstat.conf accordingly. To the list all interfaces available to vnstat, use:\nvnstat --iflist\n\nTo start monitoring a particular interface you must initialize a database first. Each interface needs its own database. The command to initialize one for the eth0 interface is:\nsudo vnstat -u -i eth0 \n\nStart Systemd Service\nAfter introducing the interface(s) and checking the config file. You can start the monitoring process via systemd:\nsudo systemctl start vnstat.service\n\nTo make this service permanent use:\nsudo systemctl enable vnstat.service\n\nFrom now on, vnstat will be gathering network usage in the background using such a small percentage of CPU it doesn't show up on conky's (system monitor's) top 9 list of processes (on my machine).\nUsage (from Command Line)\nQuery the network traffic:\nvnstat -q\n\nViewing live network traffic usage:\nvnstat -l\n\nTo find more options, use:\nvnstat --help\n\nMonthly Totals\nTo see monthly totals, use:\nrick@dell:~$ vnstat -m\n\n eth0  /  monthly\n\n       month        rx      |     tx      |    total    |   avg. rate\n    ------------------------+-------------+-------------+---------------\n      Nov '16     76.31 MiB |    2.03 MiB |   78.35 MiB |   10.45 kbit/s\n    ------------------------+-------------+-------------+---------------\n    estimated      3.13 GiB |      84 MiB |    3.21 GiB |\n\nConky example\nConky is a popular light-weight System Monitor used across many Linux distributions. You can vnStat bandwidth totals to your conky display like this:\n\nNote when picture was taken Yesterday was Sunday which explains why the Weekly total is less.\nThe conky code to achieve this is:\n${color orange}${voffset 2}${hr 1}\n${color1}Network using vnStat \"-i\", \"-w\" and \"-m\"\n${color}${goto 5}Today ${goto 100}Yesterday ${goto 225}Week ${goto 325}Month ${color green}\n${execi 300 vnstat -i eth0 | grep \"today\" | awk '{print $8\" \"substr ($9, 1, 1)}'} ${goto 110}${execi 300 vnstat -i eth0 | grep \"yesterday\" | awk '{print $8\" \"substr ($9, 1, 1)}'} ${goto 220}${execi 300 vnstat -i eth0 -w | grep \"current week\" | awk '{print $9\" \"substr ($10, 1, 1)}'} ${goto 315}${execi 300 vnstat -i eth0 -m | grep \"`date +\"%b '%y\"`\" | awk '{print $9\" \"substr ($10, 1, 1)}'}\n${color orange}${voffset 2}${hr 1}\n\nTo save space on my narrow window, I used \"G\" instead of \"GiB\", \"M\" instead of \"MiB\", etc. If you have more screen real estate change substr ($10, 1, 1) to $10 and the same for $9.\nYou may have to change eth0 to wlan0 or eth1, etc. depending on your network name reported by ifconfig.\n\nA: Though not a \"ubuntu\" answer, I use the Tomato firmware on my WRT54G router for this. It gives me monthly up/down usage for the past couple of years, and the nice thing (in the context of your question) is that it is for the whole network, not just the one system it's running on (though this point is moot if the system in question is your router or directly connected).\n\nA: You can check out vnstat. It is command-line based and is available in the repository.\nYou can start it with sudo vnstat -u -i [interface]\nTo see the stats sudo vnstat -i [interface]\n\nA: I recommend the ntop utility which is available from the repositories, it runs as a service ands keeps traffic usage records. \nThe reports are available from am internal http server (port 3000). You can easily check them using a browser, http://localhost:300/\nCheck what you can get from ntop at the ntop website .\n\nA: Apart from any software solution I would suggest looking at your provider. Many of them have monitoring tools which send you a warning when you reach a certain limit or block your access temporarily. This has the advantage that you get some \"official\" number.\n\nA: Just to expand rickys anwer:\nWith ifconfig | cut -c 1-8 | sort | uniq -u you can list the interfaces:\nenp0s31f\nlo      \nwlp3s0\n\nFor one interface, you can then visualize the traffic like this:\nvnstati -vs -i wlp3s0 -o ~/summary.png\n\ngives a nice summary:\n\n\n\n*\n\n*rx is the received traffic\n\n*tx is the transferred traffic\n\n\nA: I found \"download monitor\" as very good and easy to use tool to show data stats. \nIt has GUI interface which makes it very easy to use.\nIt is available on Ubuntu Software Center.\n\n", "Q: How do I stream music to my AirTunes? I have used PulseAudio, but it sometimes works, sometimes it does not... Also my Rhythmbox doesn't play the songs sometimes and just hangs there paused.  Is there a more stable option to stream and listen to music on my AirTunes?\n\nA: PulseAudio\nWe can define an existing AirTunes device (e.g. Airport Express) as an output audio sink for Pulse Audio by installing paprefs and pulseaudio-module-raop and running Pulseaudio Preferences:\n\nIn the first tab Network Access tick \"Make discoverable Apple AirTunes sound devices available locally\".\nAs soon as the device is registered in the local network we can switch to this device from Sound Settings:\n\nChoose the name you have registered your AirTunes device (e.g. \"Wohnzimmer\" in this example). Note that we can not switch the output while a media player is streaming to our sound card. Pause or stop your player before changing output sinks. Streams will have a delay of about 3 to 4 seconds.\n\nVLC\nThe vlc media player claims to be able to stream audio via the RAOP protocol directly to an AirTunes device. However so far I was unable to achieve this with VLC 2.0 so I can't give you directions here.\n\nStream2ip\nAfter downloading and installing the DEBIAN package for stream2ip the application needs to be set up for streaming to the Air Tunes device by running Preferences from the man window:\n\nSelect the device Airport Express and type in the IP (the port is optional) of the device. By choosing Autoconnect and a time interval >0 seconds the application will listen for the AirTunes device on the given IP to connect as soon as the device is ready:\n\nThe advantages of stream2ip over simply using Pulseaudio Sound Settings are:\n\n*\n\n*Wait for a device to connect as soon as it is present.\n\n*Re-establish an interrupted connection.\n\n*No need to stop playback of a running media player to connect.\n\n*Restore previous output when the external device is turned off\n\n\nA: ps3mediaserver should be able to stream music to your AirTunes.\n\nA: I don't really think so if you are saying \"I want to listen to my mp3's\" because the plugin is closed-source so we cant control it. Sorry!\nAny other format should be fine.\n\nA: There is an alsa driver for raop_play (http://raop-play.sourceforge.net/alsa_raoppcm.html) but it isn't included in the deb package and it hasn't been updated for a while.  I've never had enough problems with PulseAudio to need it, but if you don't mind compiling from source you can give it a shot.\n\nA: gstreamer-faad is plugin for playing mp4 dont know if thqat wil work with AACs... check out this post on the ubuntu forums: http://ubuntuforums.org/showthread.php?t=14242\n\nA: More a comment than an answer, but I tried using Pulse Audio Preferences to stream to an Airtunes-capable Airport Express. The results were less than stellar. There's some buffering problems that caused it to not work as well as it should have worked, and I pretty much gave up on the idea for now. \n\nA: I've had the same problem with elementary 0.3.2. It looks like the cause of the problem is not the buffer size, but rather the network manager, which apparently intermittently has the WiFi device scan for networks. This seems to interrupt the stream, so independently of the buffer size there are little parts of the stream missing, which produces the stuttering effect.\nI was able to fix it by setting the BSSID of my WiFi connection. It's fairly easy, all you have to do is go to the settings of your connection. There's a pull-down menu named \"BSSID\" which is usually empty, but if you open it it offers you a string of characters. Pick that one, and it'll work fine.\nEnjoy your music and rock on!\n", "Q: How can I install a dual boot configuration with Ubuntu and Windows XP? First I want to install Ubuntu completely, and then I want to install Windows XP 64 bit as the 2nd boot OS.  How can I do this?  Currently I am using Windows XP as the main OS and 2nd boot is Ubuntu.\n\nA: I would recommend formating your computer to fresh windows XP 64 install. Then I would create two partitions. Install Ubuntu on to the partition that is not installed by windows. \nI feel that this is the best setup for maintaining to two systems on a dual boot machine have done it for years. \nHere is a tutorial on this process. Windows install first Linux installed first \n\nA: If you want to keep your XP follow this I posted to someone earlier:\nResize your Windows XP partition by going to Start > My Computer > Right Click and select Management > Disk Management > Right click your Windows Partition and Select Shrink Volume. Just shrink to whatever Windows suggests and leave it Unallocated.\nOn the Ubuntu install you select your Unallocated partition and click \"New\" and select the file system as a \"EXT3\" and select the mount point as \"/\" and click Okay (If you dont want swap)\nIf you do want swap type in the amount you want (in MB) select the file system as a \"Swap Partition\" and there is no mount point. Click Okay then you do the step in the paragraph above\nAfter Install, Windows will now be in your GRUB menu with Ubuntu as default but that can be fixed by editing your /boot/menu.lst\nNOTE: IT WAS FOR WIN 7 BUT I MADE THE NECESSARY CHANGES\n\nA: Do you just want Ubuntu to appear as the first option in the boot menu?\nIf so:\n\n\n*\n\n*Boot into Ubuntu\n\n*Install StartUp-Manager (you can search 'StartUp-Manager' in Ubuntu Software Centre)\n\n*Run System -> Administration -> StartUp-Manager\n\n*Change the default operating system to Ubuntu (choose the one with the highest Linux kernel version)\n\n*Reboot, Ubuntu should appear as the first option.\n\n\nNOTE: I am assuming you did a normal dual boot not a wubi install.\n", "Q: How can Huawei EC-1260 (Tata Photon) USB Internet Device be used to share Internet over a home wireless network? At home I have a Windows desktop - and one of the primary reasons I boot into it is to share my internet connection over the home wireless network. I have a setup of this kind:\n\nWindows Desktop <--------> Wireless Router <--------> Mac/Linux Laptop\n(plugged in USB\nInternet device)\n\nI have configured Windows to share its Internet connection over the network, using Windows Internet Connection Sharing. Instead of Windows I'd like to do the same in Ubuntu, but I\ngather that Linux does not share internet connections with other PCs like Windows does. What alternative do I have on Ubuntu?\n\nA: Ubuntu has all the packages to be a full-fledged router. You can run the primary computer as if it is a broadband router which will provide the Internet connection to all the other computers. \nhttps://help.ubuntu.com/community/Internet/ConnectionSharing has a lot of detailed information about how to configure such an Internet sharing configuration.\n\nA: *\n\n*Right click the Network Manager applet and click \"Edit Connections\" \n\n*Go to \"Wireless\" tab and click \"Add\"  \n\n*Enter \"ICS\" in the \"Connection name\" field  \n\n*Enter \"ICS\" in the SSID field  \n\n*Change the Mode to \"AdHoc\"\n\n*Go to \"IPv4 Settings\" and select Method \"Shared to other computers\"\n\n*Connect to the ICS wireless network\n\n\nThese steps are from memory and might be incomplete. WPA2 security seems not to work.\nSee http://www.ubuntugeek.com/creating-an-adhoc-host-with-ubuntu.html also.\n\nA: So, the desktop has the mobile modem and an ethernet connection to the wireless router?\nAnd you want to run Ubuntu on the desktop and share the 3G connection over ethernet and ultimately over wireless?\nDesktop\n\n\n*\n\n*Make sure the 3G connection is established in NetworkManager normally\n\n*Edit the Ethernet connection in NM and set IPv4 options to Shared to other computers.\nThis will setup a private local network, start a DHCP server (dnsmasq), \nand enable routing from the local network to the 3G connection.\nWireless Router\n\n\n*\n\n*Should be set to be a dumb Ethernet-WLAN bridge\n\n*Give it a static IP and connect the Ethernet cable from the desktop to its LAN port, if it has one. If it only has a WAN port enable DHCP on that instead of PPP, PPPoE or whatever.\n\n\nLaptop\n\n\n*\n\n*Just connect to the wireless network. You should receive an IP from the desktop by vitue of Shared with other computers being enabled. \n\n\nThat’s it.\n", "Q: Is there a preferable way of structuring partitions/mounts for /home/userX I change linux versions/distributions quite often on one of my computers but I would like to keep my home folder working (keep configuration and files), is there another better solution than making a separate partition for /home ?\n\nA: I tend to make /home it's own partition. Exactly how big depends on personal preference, but on a simple Ubuntu desktop probably doesn't need more than 20GB of root filesystem space (the desktop across the room from me is using a whopping 6.5GB!); the rest of the drive could become /home if you wanted.\nHowever...\nYou should remember that not everything pertaining to your user account(s) is stored in /home. There's lots of system-centric stuff in /etc that won't survive a reinstall. In particular /etc/passwd, /etc/shadow, /etc/group, and /etc/gshadow are important. If you reinstall and recreate your users and groups in the wrong order, the UID's and GID's won't match those recorded in your /home filesystem, and your file ownerships will be all messed up.\nThe solution to this extended problem is a little more complex, since the exact set of files in /etc that you'd need to preserve are likely to be very specific to your system and what you're doing. One option would be to make a protected directory under /home and make backup copies of /etc into it. At least that way you could get back the files that are missing after the reinstall. You might look at etckeeper (yes, it is packaged) as a way to make this more automated. You wouldn't want to restore /etc en-masse, of course: after a reinstall-upgrade there are likely to be major changes and you'll want to restore files from your archive or repository very carefully.\n\nA: Nope, I wouldnt say. Unless you want to copy home folder alot!\n\nA: If you have another computer which is connected to yours via network, you can share your home directory via NFS (or some other filesystem). This solution allows you to change your mount and without repartinioning.\nPutting your home directory on some USB stick and mount it from that stick could also be an option, depending from your preferences.\n", "Q: Can I use banshee from the command line? I love Banshee media player in general, and I already have an important library of music, which I've spent a lot of time organizing (labeling, correcting, etc). \nI also use the command line a lot, so I wonder if there is a way I can control banshee from the command line. As in:\n\n\n*\n\n*Next, Prev, Stop, Play, etc\n\n*In anyway query the Banshee database as if using the search box in the GUI\n\n\nI was akin to program it myself if there isn't, but that would be another question :)\n\nA: /usr/bin/banshee --next\n/usr/bin/banshee --previous\n/usr/bin/banshee --stop\n/usr/bin/banshee --play\n\nAll those above can be used in XFCE for shortcuts on your keyboard, respectively for:\nX86AudioNext\nX86AudioPrev\nX86AudioStop\nX86AudioPlay\n\n\nA: If you're looking to program an interface for Banshee (Other than just having the ability to send banshee --next or other control flag. Then you may be interested in the MPD - The Music Player Daemon which allows you to create your own interface or modify/use one of these Clients designed to work over MPD\n\nA: According to man banshee, it is possible to control playback. I'm not sure about searching though.\nHere are a few of the controls that you mentioned. Check the man page for many more.\n--next \n    Play the next track, optionally restarting if the 'restart' value is set\n\n--previous \n    Play the previous track, optionally restarting if the 'restart value is set\n\n--stop \n    Completely stop playback\n\n--play \n    Start playback\n\n\nA: There are quite a bit of commands you can use with banshee, it's been a ling time now, but here's a script I wrote because I could not find a way to play a smart playlist at login.\nIt was months ago, it was one of my first scripts and I did it for fun so it's pretty bad, I haven't tried it since but this should at least give you an example of how usable is banshee on the terminal :\n   #!/bin/bash\n    banshee --hide &\n    sleep 3;\n    banshee --play;\n\n    while true; do\n        pos=`banshee --query-position| sed s/position:\\ //| sed s/,.*//`;\n        dur=`banshee --query-duration| sed s/duration:\\ //| sed s/,.*//`;\n        left=\"$(expr $dur - $pos)\";\n\n        rating=`banshee --query-rating|sed s/rating:\\ //`;\n        isHumour=\"$(banshee --query-uri|sed s/.*Music//|grep /Humour)\";\n\n      if [[ $pos -lt \"3\" ]] && ([[ $rating -lt \"2\" ]] || [[ -n \"$isHumour\" ]]);\n      then\n        echo \"next\";\n        exec banshee --next &\n      else\n        echo \"sleep for\" $left;\n        sleep \"$left\";\n        pos=`banshee --query-position| sed s/position:\\ //| sed s/,.*//`;\n        dur=`banshee --query-duration| sed s/duration:\\ //| sed s/,.*//`;\n        left= expr $dur - $pos;\n        echo $left;\n    fi;\n    sleep 0.0001;\n    done;\n    exit 0;\n\nHope it helps, sorry if it confuses you...\n\nA: I don't think there is a command-line interface to Banshee at this point. And I haven't heard anything to indicate that they would be working on one.\n\nA: Here is what everyone has been looking for:\nsh -c \"sleep 1m; banshee --hide & sleep 20; banshee --play\"\n\nthe 1m stands for a timeout which you can change.\nYou need to put it in your start up applications\n", "Q: Which flavor of ubuntu? \n\nThis question has historical significance from the Ask Ubuntu Beta. It is not considered a \"constructive\" question, as per the FAQ.\n\n\nMy first question regarded a fresh install on my ubuntu box. Some great answers.\nMy housemate has a couple of Sun Ultra 20's that are unused. So I made the best box possible using the better components of each. It's sitting there just waiting to be loaded up with Ubuntu.\nThe new system may become my primary machine; or maybe not; and will probably be set up as a home server. Also, almost certain to install LAMP to use as a WordPress and Drupal testing platform.\nAt the moment I am undecided as to which version of Ubuntu I want to use. The choice is between Kubuntu, Ubuntu, Ubuntu Studio, or Ubuntu server (with desktop added).\n\n*Kubuntu - Basically just to try out and develop knowledge of kde.\n\n*Ubuntu Studio - Because I like the media tools for photography, video, etc. Not sure that this one is even necessary since I can add whatever pkgs I want to ubuntu\n\n*Ubuntu - Just because it's familiar.\n\n*Ubuntu Server - And add on a desktop since I'm more of an artist by nature.\nMy question is, What are the pros and cons of these options?\nThanks in advance. \n\nA: You are just talking about desktop environments here. Gnome is popular and so is KDE. I personally use XFCE. You can use different Desktop Environments in same ubuntu. SO just experience yourself and know\n\nA: If you just use Ubuntu, you can install packages from the different flavours. You can install KDE on Ubuntu and GNOME on Kubuntu, so it doesn't really matter. I advise you install plain Ubuntu as a starting point and add the packages you need from there.\n\nA: I agree with the answers to use plain ubuntu; you can start from that and then install any kde or media app you want.\nThat said, everyone's opinion on the different flavors/derivatives is different, so really if you are curious, I'd suggest downloading each in turn, trying them all out, and making up your own mind.\nI like using the plain stock ubuntu since I know that's what the majority of users use, so it's quite heavily tested.  But each of the derivatives has its strengths.\n\nA: The beauty of Ubuntu is work w/ what you know and add what you need.  So if as the last poster mentions you need the studio applications, then add them, or if you are a big fan of KDE or GNOME or specific apps to one DE or the other you can use them.\nStart w/ Ubuntu and then add the applications you want, you don't have to add the whole *ubuntu-desktop metapackage you can just install what you need\n\nA: Why limit yourself? Install one and add the others. You can select between them at login.\nI always install Kubuntu first because it has no Mono (not that I am hung up about it, but why install it, if you don't want it). Then I install ubuntu-desktop and search for mono-gac and remove it before I hit apply. I lose gbrainy and Tomboy in the bargain. Bonus! Then I add other desktop environments to top things up. You can't have too much of a good thing. Too bad you can't be in all of them at once. :)\nI do it just because I can. ;)\n\nA: I would recommend Mediabuntu and this is why:\nMy friend is a graphic designer and musician. So he has recording equipment he uses and a Tablet. The tablet worked out of the box with Mediabuntu (and was configured properly and worked well with Gimp, etc). His recording equipment was also well received (though that was mostly hardware related). It was easier for him to remove the 4-5 applications he didn't need then hunt down packages and software he wanted.\nHowever Mediabuntu does have some draw backs. Not being an \"official\" \"flavor\" it may lag behind in development from the upstream - but this is rarely ever a major issue.\n", "Q: How can I get the R backend for Cantor in Kubuntu? Kubuntu cannot build Cantor with its R backend because R is in the universe repository while Cantor (source pacakge: kdeedu) is in main, so cantor cannot depend on R.\nIs there any way to build my own Cantor package that include the R backend?\n\nA: This is a bug.\nAs a workaround, someone has created a ppa for kdeedu with R support.\nTry adding the ppa then installing Cantor.\n", "Q: How can I give the packages in my PPA an icon? When browsing the Software Center, I noticed that certain packages have icons - like Blender, the Gimp, etc.\nHow can I give the packages in my PPA an icon?\nAlso, when someone brings up the description of the package, it shows a screenshot. How can I do that too?\n\nA: Software Center gets it's metadata (including icons) from desktop files in /usr/share/app-install/.  The packages app-install-data and app-install-data-partner are installed by default and include desktop files for most of the items available in the software center.\nThe app-install-data package is automatically generated for each release, so packages available in the ubuntu repositories can just add an X-AppInstall-Package item to the .desktop file and wait for the next ubuntu release.\nThere's not really anything you can do for packages in PPAs.  There have been proposals to change this, but I don't think anything has come of them.  It's currently listed as an \"Unresolved Issue\" at https://wiki.ubuntu.com/SoftwareCenter\n\nA: You need to have your program in the official debian/ubuntu repositories, and then anyone can upload a screenshot to http://screenshots.debian.net. Unfortunately I don't think there is any way to have a screenshot for packages in PPAs.\n\nA: For the icon, you need to create a great one ;) and install it under /usr/share/icons/*. Then you'll need to give the path to the application icon somewhere[1] into the desktop menu for your app.\n[1] I don't know the actual way to do that in a package; you'll have to find the way.\n", "Q: Migrating, partitioning, and encrypting plan of attack Right now, I'm running Karmic with an unencrypted home folder sharing a partition with my system files. I'd like to change all that, but I have no idea where to start. Should I move my home folder to its own partition first, to easily perform a clean install? Should I back up my data, repartition my disk, then perform a fresh encrypted install? I'm stumped.\nIn what order should I transfer my home folder to its own partition, encrypt my data, and migrate to Ubuntu 10.04 to minimize my downtime and protect my data?\n\nA: From an information security perspective, the safest course of action is:\n\n\n*\n\n*Create an encrypted filesystem on a backup disk.\n\n*Back up your home folder to that encrypted filesystem.\n\n*Wipe the original disk with random data.\n\n*Perform a fresh, encrypted install.\n\n*Restore files from encrypted backup onto new encrypted filesystem.\n\n\nAll the while remembering that the weakest point in any crypto system is the human element. Choose a good passphrase, and use a different passphrase for each encrypted filesystem (this is not like \"use a different password for each website\", this is a serious infosec matter, identical keys on independent but related data sets is a serious cryptographic no-no and risks very real cryptanalytic attacks).\n\nA: 1) transfer you home folder to its home partition,\n2) fresh install and in manual partitioning set your data to /home,\n3) in the installer set your username to match your /home/username select encryption\nMy only concern is that the installer may have trouble encrypting an existing account's data, even possibly damage it. That's a slim chance, but if you go down that path make sure to backup your data to an external source just in case.\nThe other option, and one I've tried, is to backup your data, fresh install, and in the partitioner create /home and select encryption. After installation transfer your data into /home.\n", "Q: Where do I find system sounds? After installing gm-notify I see the option of hearing a sound every time a new e-mail arrives in my Gmail inbox, but I don't know where Ubuntu (10.4) stores the system sounds to assign one. Any ideas? Thanks.\n\nA: /usr/share/sounds/gnome/default/alerts\n\nwould be a good place to find sounds for this purpose.\n/usr/share/sounds/ubuntu\n\nis a sound theme. Sound themes can be chosen in sound preferences. 'ubuntu' is the only sound theme installed by default. I would advise against editing files in this folder directly. A better thing to do, if you wanted to edit the sounds in this folder, would be to copy it (perhaps to /usr/share/sounds/ubuntu-modified) and change the index.theme file to have a different name.\nsudo cp -R /usr/share/sounds/ubuntu /usr/share/sounds/ubuntu-modified\nsudo -H gedit /usr/share/sounds/ubuntu-modified/index.theme\n\nOnce this is done, you can safely edit the sounds in /usr/share/sounds/ubuntu-modified.\n\nA: /usr/share/sounds\n\nIf you remove/rename a sound, it should stop. Or you can replace it with an .ogg sound (.wav works too... I think...)\n\nA: You can find the bulk of the system sounds here: /usr/share/sounds/ with the majority of them being in /usr/share/sounds/ubuntu/stereo\n\nA: For some sillier sounds (which I sometimes like to use for system events), you can also check here: /usr/share/gnome-games/sounds\nYou can download more system sounds for Gnome at Gnome-look.org, too.\n\nA: You can also try\nSound > Sound Effects\nI have mine switched off since I find sound effects annoying \n", "Q: bashrc or bash_profile? I know the difference between the two bash login scripts:\n.bashrc is run only by \"non-login\" shells.\n.bash_profile (or .bash_login or .profile) is executed by \"login\" shells.\nDoes anyone have some good examples of what things that are a better fit for login-only execution, such that I'd only put them in .bash_profile, but they wouldn't really make sense in .bashrc?\n(I know most of us source .bashrc out of .bash_profile, so there doesn't seem to be much point in the opposite question...)\n\nA: Byobu is a great example of something you should never ever put in a .bashrc. \nOtherwise, it will recursively run itself in every single one of its 'virtual terminals' ;-)\nYou can try it though, it's sort of fun.\nThat why you put it in .profile, so byobu (which really is a just wrapper around screen) is only loaded, once, at login-time. And byobu itself can start new interactive bash sessions.\n\nA: Since a .bashrc is for non-login shells, I avoid any commands which echo to the screen. I've also run into experiences where echo statements in .bashrc will cause sftp and rsync commands to fail (and maybe scp commands as well).\n# Print some information as we log in\n# -s: OS Name -n: Node name -r: OS Release\nuname -snr\nuptime\n\nAlso, you generally won't run ssh-agent from a non-interactive shell. So I have this in .bash_profile.\nif [ -f ~/.ssh/ssh-agent ]; then . ~/.ssh/ssh-agent; fi\n\n", "Q: How can I highlight or annotate PDFs? Currently I need to highlight certain sections in PDFs, or add annotations (comments/notes). These modifications would need to be saved. \nWhat tools are out there to do this on Ubuntu?\n\nA: I was searching for exactly the same. For me, qpdfview works like a charm, is simple to use and lightweight. Its annotations and text highlighting is recognised in Adobe Reader (Linux version 9, Windows. iOS). Editing done on the aforementioned platforms are recognised by qpdfview as well. It allows you to delete annotations and highlighting too, and stores annotations in the PDF.\nIt is free, the source code can be found on launchpad. You find it in the Ubuntu Software Center and there is a ppa for a more recent version: ppa:b-eltzner/qpdfview\n\nA: Recently a new version of Foxit Reader is released for Linux. It has the highlighting and annotating support. It has more annotation options than Okular, including inline notes with transparent background, drawing of various shapes etc.\nHow to install Foxit Reader in Ubuntu is explained in this AskUbuntu answer:\n Install FoxitReader\n\nA: I have got a workaround to this problem, but it is too localized. Using okular for reading a pdf file and then annotate by pressing F6 to bring Highlighting toolbar.\nAfter annotating, you can save the file as document archive, which preserve the annotation. From File -> Export as -> Document Archive. \nNote This file can only be opened by Okular.\nInstalling Okular: To install okular, issue this command in terminal :\nsudo apt-get install okular\n\nA: Actually, none of these solutions work half as well as anything on Windows or Mac OS. \nMendeley only supports yellow highlighting and importing pdfs into Inkscape or OpenOffice is pretty inconvenient if you want to read a paper and simply make some annotations. \nFortunately, there are some free pdf viewers for Windows that work flawlessly with wine (If you find wine too complicated, use PlayOnLinux - a great front end for wine configuration). One of the best of those viewers is the PDF-XChange Viewer by Tracker Software. There is a free version that comes with a ton of annotation features, session saving etc. Grab it here:\nhttp://www.tracker-software.com/product/downloads\nAnd check out this screenshot:\n\nI really wish there was a working open source Linux alternative (xournal is good but too limited). But for the time being, I am happy with using wine.\n\nA: Jarnal is a good software that allows you to highlight\n\nA: I've tested PDF X-Change viewer and I experienced the same white space problem while scrolling. I'm currently using Foxit Reader 4.3 which works really flawlessly. Foxit 5 crashes with wine 1.3 but works fine with wine 1.4 and 1.5. The only minor bug is that when you add a text annotation, it will ask you if you want to download the dictionary. You simple click cancel and keep working. It will keep asking you just once every time you open Foxit. \nI managed to make Foxit reader 4 my default pdf viewer but can open files by double clicking a pdf file only if Foxit is not open. With Foxit 5 this issue is solved too. See this thread: How do I set a wine program (ex. Foxit Reader for Windows) as the default program?\nHope the pdf annotation feature in evince improves to avoid using wine.\n\nA: The latest version of Ubuntu's default PDF viewer Evince has a built-in highlighter. It is very efficient. And unlike other softwares, the highlighted text is also detected when we open it using other softwares like Adobe PDF Viewer. The version number is 3.17.4 and you can download it using the link below:\nhttps://github.com/GNOME/evince/releases\nPlease note that you have to first remove the old version of Evince before you install the new one. Also, the program crashed few times on my first day of install but it is totally fine for a month now. \n~Cheers~\n\nA: xournal is also some software which you use for this task.\nscreenshot of xournal from 2022:\n\n\nA: Future version of Evince will support PDF annotation and highlight.\nHere you can see a video of the first partial implementation, made by Carlos Garcia Campos \nIf you want to try I think you need to have at least evince 2.32 and recompile yourself latest version of Poppler cloning from the git repository:\ngit clone git://git.freedesktop.org/git/poppler/poppler\n\nHere the launchpad bug of this missing feature from evince (poppler packaged for Maverick isn't enough updated).\n21 april 2011 - Update\nEvince in Natty now support by default annotations (not highlighting).\nEvince in Natty is 2.32, poppler is 0.16.4.\n08 March 2017 Update Evince in Ubuntu 16.04 supports highlighting.\n\nA: The  evince package which is built-in in Ubuntu and is called Document Viewer can add annotations to PDFs.\nEvince 3.18.2 from the Ubuntu 16.04 default repositories has support for highlight annotations and moving annotation icons to a different position on the page.\nIf you do not have a visible side pane on the left side of the opened document's window, click View -> Side Pane or press F9 to make the side pane visible. At the top of this side pane, there is a dropdown menu with options like Thumbnails, Index and Annotations (some of which may be dimmed for some documents).\nTo create an annotation\n\n*\n\n*Select Annotations from the dropdown menu. You should now see List and Add tabs under the dropdown menu.\n\nIn Ubuntu 16.04 and later, click the toolbar icon that looks like a notepad. A new toolbar will appear under the toolbar with two icons for adding text annotations and  adding highlight annotations.\n\n\n\n*Select the Add tab.\n\n\n*Click on the icon to add an annotation.\n\nIn Ubuntu 16.04 and later, the icon for adding a text annotation looks like  piece of paper with a + in the upper right corner (marked by a diagonal yellow arrow in the below screenshot), and the icon for adding a highlight annotation looks like a piece of paper with three black blocks on it.\n\n\n\n*Click on the spot in the document window you would like to add the annotation to, preferably a blank spot where the annotation will not cover anything else in the document. Your annotation window will open.\n\n\n*Type your text into the annotation window. You can resize the note by clicking and holding the left mouse button on one of the bottom corners of the note, and moving it around.\n\n\n*Close the note by clicking on the x in the top corner of the note. You might need to hover over the x with the mouse to make it visible.\n\n\n*When you want to go an annotation click on the icon for it. If you can't see the annotation icons, then unfold the little black arrows to the left of the page numbers in the side pane to show them. The text annotation icon looks like a piece of paper with a pencil over it in Ubuntu 14.04 and it looks like a pencil in Ubuntu 16.04. The highlight annotation icon looks like a piece of paper in Ubuntu 16.04.\n\n\n*When you close the document you will be asked if you want to save the changes you made to it.\nTo create a highlight\nThe evince snap package makes the highlight text feature available to all currently supported versions of Ubuntu, otherwise the evince apt package in 18.04 and later also has the highlight text feature.\n\n*\n\n*Click the pencil icon in the upper left corner. In some versions of Evince there is a small notebook icon instead of a pencil icon in the upper left corner.\n\n\n*Click the Highlight text button in the upper left corner.\n\n\n*Select some text with the mouse and it will be highlighted.\n\n\n*When you close the document you will be asked if you want to save the changes you made to it.\nThe highlight feature of evince can also be obtained in Ubuntu 16.04 by installing the evince snap package:\nsudo snap install evince  \nsudo snap install gnome-3-28-1804  \nsudo snap connect evince:gnome-3-28-1804 gnome-3-28-1804\n\n\nA: I use an old version of Foxit Reader (the latest 4.x version from oldapps.com), and it works very well under Wine. \nAt the moment, there is no good native highlighting solution!\n\nA: PDF Studio is, probably, the best solution. It is not free, but you can install it using the Ubuntu Software Center.\n\nA: LibreOffice Draw works reasonably well for PDFs. It can not only annotate but do all the features of Draw such as drawing lines, shapes, etc. It saves as its own file format .odg but can export as PDF. \n\nA: I think that Xournal is the tool you're looking for.\nWhat you should do is exporting in PDF, and the changes will be saved in pdf.\n\nA: Maybe xournal (app to add annotations to pdf's files)\nClick to install xournal\nAnd okular save the hightlighting separetly then if you want to save the hightlighting you have to save the pdf like new file to save the hightlighting.\n\nA: I had the same question but unfortunately I didn't arrive to any satisfactory answer, being okular the closest one (but as you say, it does not save the changes in the same file, which is a problem). \nI finally decided to use \"PDF-Xchange Viewer\": that piece of program makes exactly what I wanted to do and does it well, but it has two problems: it is free but not opensource and there's no linux version, although it can be used in ubuntu via wine. I wish there were better ways to annotate PDFs and so on. \nMaybe you could open an issue at okular developers so hopefully they can implement that feature in the nearly future.\n\nA: You should also try PDF Buddy, an online PDF editor that supports highlighting, annotation, and other common editing features. It's a fast and easy solution that works in any modern browser.\n(Full disclosure: I'm a co-founder of PDF Buddy) \n\nA: -------------- EDIT March 2018 --------------\nHaving used multiple pdf viewers editors, and after 6 years (!) of asking this question, I settled in two different tools for different purposes:\n\n\n*\n\n*Mendeley Desktop is an excellent reference managers and it works flawlessly in most Ubuntu versions. It is ideal for papers and academic writing and supports notes and highlights synchronization. \n\n*Evince (or Document Viewer), the default pdf viewer as of Ubuntu 18.04 also supports highlighting and annotations. To show the annotations menu bar, you must click on the red circle (see below). The annotation options appear and you can annotate or highlight as seen in the blue circle in the image below. \n\n--------------------------------------------------------\nFor me the best solution was PDF X-Change Viewer. \n\nIt just installs and works flawlessly under Wine. (Source)\n\nThe only issue is that sometimes when you scroll fast it shows some white spaces over the text, that clear when you click or select a line in the document. \nThere is an option in the Edit menu under Preferences\\Performance\\Threads Usage:\n\"Use synchronous mode of page rendering\"\nwhich prevents those white spaces in mine.\n\nA: There is a package called pdfedit that can do this.\n\nA: Okular supports PDF annotations.\nTo save the highlighting/annotations directly in the PDF document, choose File > Save as... and create a new PDF which will contain your edits.\nHow to edit in Okular\nYou can choose Tools > Reviews to get other options like adding\n\n*\n\n*pop-up notes\n\n*inline notes\n\n*freehand line drawing\n\n*highlighter\n\n*stamp\n\n\nEdit: Inkscape supports PDF editing (one page at a time) and most people seem not to be aware of this so I'm adding it to the answer.\n\nA: The PDF viewer in Mendeley allows you to highlight and annotate PDFs. To save the modifications you need to File > Export PDF with Annotations.\nHowever Mendeley is not open-source, and it forces you to use an account... But otherwise the functionality is excellent.\nYou can download from here.\n\nA: Now you can actually export annotations to PDFs in Okular (this was not possible until recently): http://docs.kde.org/stable/en/kdegraphics/okular/annotations.html\nIt seems Okular has to be built with Poppler at least version 0.20. It works with Ubuntu 13.04.\n\nA: There's a plugin for OpenOffice.org that does this.\nhttp://extensions.services.openoffice.org/project/pdfimport\n\nA: Xournal++ has not been suggested yet. It allows to use a PDF document as a background to draw and put text objects and even LaTeXed formulas on top.\n\nXournal++ does not modify the background PDF document, but stores all drawings in a separate file. It is possible to export the combined result as a single PDF.\nXournal++ does not allow to select text or other objects in the background PDF, but it can be used in conjunction with Evince or Okular, where Evince or Okular is used to highlight or underline text in the underlying PDF, and Xournal++ is used to draw on top. However, the are issues with printing or \"flattening\" certain annotations created in Evince and in Okular.\n\nA: Master PDF Editor is a good software for annotating PDFs. There is a free version for non-commercial use.\nFeatures:\n\n\n*\n\n*Adding images to PDF \n\n*Adding/editing bookmarks\n\n*Opening PDFs in tabs\n\n*Adding sticky notes to PDFs\n\n*Adding Ellipse, Rectangle, Lines\n\n*Highlighting, striking out, underlining texts\n\n\nI think it works just like Foxit reader for windows.\nAdvantages over okular: \n\n\n*\n\n*In Master PDF Editor you can save PDF in a normal way without the need to saving PDF using \"save as\".\n\n*In okular as far as I know you can't add or edit bookmarks but in Master PDF Editor you can easily do that.\n\n*In okular you can't add images to pdf, But in Master PDF Editor you can.\n\n\nDisadvantage over okular: \nIt uses too much RAM.\n\nA: I got good results when annotating and editing PDFs online using PDFescape. There's a limitation on file size (10MB) and number of pages (100) though.\n", "Q: rkhunter warning about /etc/.java /etc/.udev /etc/.initramfs I am running Ubuntu 10.04.1 LTS . I am running rkhunter to check for rootkits.\nrkhunter is complaining about the following hidden files and directories. I think these files are not a real problem on my system, but how can I check to see if these files are legitimate files?\n[07:57:45]   Checking for hidden files and directories       [ Warning ]\n[07:57:45] Warning: Hidden directory found: /etc/.java\n[07:57:45] Warning: Hidden directory found: /dev/.udev\n[07:57:45] Warning: Hidden directory found: /dev/.initramfs\n\nUpdate\nTurns out that these directories are specifically mentioned in /etc/rkhunter.conf , which suggests that this is a frequently asked rkhunter question.  From rkhunter.conf :\n#\n# Allow the specified hidden directories.\n# One directory per line (use multiple ALLOWHIDDENDIR lines).\n#\n#ALLOWHIDDENDIR=/etc/.java\n#ALLOWHIDDENDIR=/dev/.udev\n#ALLOWHIDDENDIR=/dev/.udevdb\n#ALLOWHIDDENDIR=/dev/.udev.tdb\n#ALLOWHIDDENDIR=/dev/.static\n#ALLOWHIDDENDIR=/dev/.initramfs\n#ALLOWHIDDENDIR=/dev/.SRC-unix\n#ALLOWHIDDENDIR=/dev/.mdadm\n\n\nA: Basically ask Google, but those 3 are not dangerous! \n/etc/.java is created by sun-java (and possible also by OpenJDK)\n/dev/.udev is created by the udevd daemon\n/dev/.initramfs is if I remember correctly where the initial ram filesystem is mounted during the system boot process.\n", "Q: How can I find out if a process is CPU, Memory or Disk-bound? How can I find out if a process is bound to CPU, Memory or Disk?\n\nA: A tool that can be useful for real-time checking a number of process statistics (memory, cpu-usage, I/O, etc.) is htop.  It doesn't replace the more specialised tools named by Sudhanshu, but might be a good start.\n\nA: As well as the other tools mentioned, run ps l PID, inserting the relevant process id, or look at the STATE and WCHAN columns in top or htop.\nIf it's in D (for disk) state, then it's doing file IO. This could be because it's either reading a lot of files, or because it's using a lot of memory and swapping.  The WCHAN column will tell you what kernel function it's inside; googling for them or asking here may give you some indication what they mean.\nIf it's in R (run) state, it's using the CPU in user space, in other words it's CPU bound at that moment.\nIf it's in S (sleep) state, it's inside an interruptible system call, which may mean it's either actually sleeping, or it's doing something like waiting for network traffic or a lock.  Again, looking at the specific wchan will tell you more.\nSee also What is the \"Waiting Channel\" of a process?\n\nA: Run top and look at the cpu usage line.  A high user % indicates that it is cpu bound.  A high wait % indicates that it is IO bound.\n\nA: That requires some expert skills. It depends. Example:\n\n*\n\n*If there's enough of memory and disks don't seem too busy, it may be CPU-bound. Look at CPU usage and if its bordering at 100% it's CPU bound. If it's not there's an artificial bottleneck in the implementation. E.g. on a dual-core CPU a single threaded process will not go above 50% CPU usage.\n\n\n*If CPU and memory are available, but disks are very busy, or IO latency seems high, its likely that its IO bound. See if adding more disks (RAID?) helps.\n\n\n*None of the above? Check memory available.\n\n\n*Enough memory? There may be an artificial bottleneck in the process itself i.e. maybe someone forgot to remove a sleep(1)? Naah its not that easy usually. ;)\nThere's a reason why we have a whole lab for performance engineers in most companies dealing with performance sensitive products!\nUse tools like sar, vmstat, iostat, oprofile, lockstat, dtrace, product specific perf monitoring tools etc, to debug perf problems.\n\nA: check out iotop, can be useful\n\nA: I usually go:\nsudo apt install iotop htop   # Ubuntu/debian based systems\nor\nsudo yum install iotop htop   # Redhat/RPM based systems\nThen have a quick look at htop - is the system swapping (fully filled memory bar)? If so, you want to fix that first. Swapping is super expensive in terms of performance.\nIf the system is not swapping, check out the cpu bars. Are they near 100% most of the time? Well, then your CPU is busy :)\nNext, quit htop and start sudo iotop and check the top right numbers (total and actual disk write). How high are they?\nIf they about match the maximum reasonable throughput of your disk which is being read from / written too (and usually write operations are the bottleneck as disk write speeds are almost always lower then read speeds), then your IO is busy :)\nNote I am referring to the actual reasonable throughput on your disk (what you were to approximately get if you copied a set of files manually when the server was otherwise idle), NOT the \"label\" performance, which is often impossible to achieve to start with.\nThus, doing a few simple check, you worked out if your system is memory, cpu or disk bound. If you want more detailed numbers or analysis, checkout some of the other tools, but this gives you a basic idea, which is often sufficient to help you scale etc.\n", "Q: Is there any advantage to setting up a personal cloud instead of running a personal server without virtualization? I currently have my old PC sitting in my closet being a headless server (running Ubuntu Server). I use it as a file server, web server, and backup server. (The hostname is mneme, the Greek muse of memory.) Are there any major reasons for me to consider replacing this non-virtualized setup with a personal cloud running on the same or similar hardware?\nThe major reason I can think of would be separation of services. For example, my backup system and my apache web server have nothing to do with each other directly, so they could run in separate instances. If I want to experiment with some new service (e.g. set up a personal mail server), I could do it in a brand new instance and then later, after the inevitable miserable failure, I can just blow the whole mess away without affecting my other services. Is this something that I could do with one or two computers running a personal cloud? Are there other advantages to setting up a personal cloud?\n\nA: Firstly: \"cloud\" is marketing jargon for virtualisation but it tends to mean flexible virtualisation, where there's some elasticity and you can move things around. That the case, you'd require more than one host machine to do it and by the sounds of it, you don't want or need that.\nYour real comparison is between virtualisation and no virtualisation.\nWhy would somebody actually want to virtualise a machine?\n\n\n*\n\n*If they needed to run different versions or configurations of a platform\n\n*If the software needed the whole server to roam over and could damage other apps\n\n*If the virtual servers were being provisioned to separate users\n\n*They need to test various setups before deploying\n\n*Consolidation of multiple hardware servers into one beast.\n\n\nI don't see anything there that applies to you.\nYou talk about separating services but I don't see any benefit to you of doing that. You can take a normal machine and play around with it, install a mail server and if you don't like it you can just uninstall. There's no reason why this would effect another running service.\nThe only time it might is if you want to test a new configuration of an existing system without any downtime. In this case, you could provision a new VM, install and test, but you could easily do the same with a desktop and virtualbox. Vbox actually makes things a lot simpler.\nThere are benefits to virtualising but they only usually hit home when you're trying to turn a room full of slow, hot servers into a much leaner, efficient setup or if you have a lot of users who all need their own install space. For a single user with a single machine, you'll see more negatives than positives.\n\nA: I think you're not asking the right question...\nWhat we call \"the cloud\" is not \"vitualized environments\" but \"services that are hosted on the network\". Cloud services can be hosted on real hardware or virtual lmachines, it doesn't make difference. The reason why people tend to thing \"cloud\" means \"virtualized\" is because setting up cloud services is usually simplified by virtualization environments, and companies have pushed it through dedicated solutions (like Azure, EC2 and the like).\nAnyway, with this definition, you're somehow already having a cloud-like installation, with your file, web and backup services being accessible on the network (even if it's hosted on a \"real\" hardware).\nNow talking about virtualization: you are making a good summary of the advantages you could gain with it. The question is just: do you want to go through the hassle of reinstalling / reconfiguring everything in virtual machines, with the possible problems it may bring, or do you want to keep what you have and is working today ?\nI can't answer for you. My personal feeling on this kind of thing is usually \"if it ain't broken, don't fix it\", but then it is your choice. It may be a good learning opportunity :-)\n", "Q: What fonts are absolutely required? \n*\n\n*Is it possible, to wipe all fonts other than TrueType fonts? If so, how?\n\n*What fonts are absolutely needed/necessary in a working X environment?\n\n\nA: xfonts-base should be enough to start the X server..\nIf you intend to run a Desktop Environment you have to install some extra fonts.\n\nA: You should have at least one sans-serif, one serif and one monospace font (mainly for web browsing). You should be safe with only ttf-freefont and ttf-liberation. Note, all truetype font packages start with 'ttf-'. OpenType font packages begin with 'otf-'. To remove all OpenType fonts, remove all packages starting with 'otf-'.\n\nA: Many of the ttf-* packages are only for international script support and clutter the font listings on programs.\nThere is a fair amount of duplication. DejaVu, for instance, has Arabic characters in it, but there are separate arabic fonts installed. If you delete those you won’t see empty rectangles on websites containing arabic because DejaVu has those basically covered.\nJust one example.\n", "Q: How to change the color depth? I have Ubuntu 10.04 installed on a Dell C600 and the highest available resolution is 800x600. From my previous I remember 1024x768 would work after setting the colour depth to 16bit, but there is no xorg.conf in /etc/X11 anymore. So, how can the colour depth be changed on lucid lynx?\n\nA: You can create a new xorg.conf by switching into a virtual virtual console (Ctrl + Alt + (F1-F6)) and running sudo service gdm stop. \nThen run Xorg -configure (yes, it should be Xorg, not xorg).\nIf you had an old xorg.conf file in /etc/X11/ you'd first back that up by doing sudo cp /etc/X11/xorg.conf /etc/X11/xorg.conf.backup. \nThen move your newly created xorg.conf to /etc/X11/ by running sudo mv xorg.conf.new /etc/X11/xorg.conf and restart gdm by running sudo service gdm start.\nThen you can change the color depth in there by finding the appropriate section and changing/adding whatever's in there to DefaultDepth    16\n\nA: Try doing this step, but before you get to the sudo service xdm start part, change the screen section (within the xorg.conf file) to something like:\nSection \"Screen\"\nIdentifier    \"Default Screen\"\nMonitor        \"Configured Monitor\"\nDevice        \"Configured Video Device\"\nDefaultDepth    16\nModes        \"1024x768\"\nEndSection\n\n\nA: The following is verified on Ubuntu 13.04:\nTry doing this step: http://ubuntuforums.org/showthread.php?p=9362728#post9362728 , but before you get to the sudo service gdm start part, change (or add if there were none) the screen section (within the xorg.conf file) to something like:\n\nSection \"Screen\"\nIdentifier    \"Default Screen\"\nMonitor        \"Configured Monitor\"\nDevice        \"Configured Video Device\"\nDefaultDepth    24\nEndSection\n\nIn my case, depth used to be 32; I changed it to 24 to free some display memory so that I can plug a huge LCD display to it.\n", "Q: BigBen wireless gamepad does not connect The gamepad is more or less a clone of a xbox controller (IIRC it is even from the same manufacturer), labeled PCPADRFLX. lsusb lists the receiver as ID 1a34:0801.\ndmesg | grep input reads\n\n[6880.468415] input: ACRUX RF USB GAMEPAD 8206 as /devices/pci0000:00/0000:00:10.1/usb2/2-2/2-2.3/2-2.3:1.0/input/input17\n\nUnfortunately, while the receiver is recognized, the gamepad itself does not connect. Usually after pressing a button on it the LED would light up once to indicate it has connected, however it just blinks as it does when no receiver is connected at all.\nSo, how can I make the gamepad work?\n\nA: tips is a good treat to search google with the id of lsusb with this type of problem exam... 1a34:0801\nhttp://ubuntuforums.org/showthread.php?t=825464\n\nA: Have you seen this page?\nhttps://help.ubuntu.com/community/Xbox360Controller\nThey talk about drivers which may help you.\nEDIT: There is also a userspace driver: http://pingus.seul.org/~grumbel/xboxdrv/ if you don't want to use the kernel module for some reason.\n\nA: I once got the black BigBen Wireless gamepad working, but I forgot how to. I remember that I installed a lot of stuff (also the x360 driver for Linux) and suddenly it worked. I can't remember which version of ubuntu it was. It must have been 9.04 or 9.10. \nI remember I played Super Mayo Chronicles with it and it worked fine. So there is a way. If someone finds out how, a documentation would be great. Next time I try I will write down every single step I make.\n", "Q: How can the rules that determine valid user passwords be changed? Are there any particular rules on what a valid password is, speaking of length, upper- and lower and/or special characters, numbers, etc. and if so how they can be changed?\n\nA: Password strength rules are defined in the pam configuration in /etc/pam.d/, usually using the pam_cracklib module. However, the minimmum password length of 6 is hardcoded in the pam_unix module.\n\nA: I'm not entirely sure of your question, but it sounds like you're asking about passwords not being changed when you change the user account password - I'm assuming you mean external passwords in things like mysql?\nFrom what I understand, the user account password only changes the password used to login to Ubuntu (and the sudo password for your account).\n", "Q: Stopping desktopcouch and gwibber-service? powertop shows desktopcouch and gwibber-service are not-inconsiderable power-users. I don't use gwibber or Ubuntu One, so can I safely kill these processes? If so, how could I stop them starting up, especially if my laptop is on battery power?\n\nA: If you don't use them, you could uninstall them both. DesktopCouch isn't used for much yet. I just checked my database, and it's only really used for Gwibber and Evolution's contacts (and an experimental build of Caffeine). \n\nA: Open the System menu, go to Preferences and select Startup Applications. You can scroll through the list and deselect the two \"Ubuntu One\" entries. You might also want to turn off the Bluetooth service if you don't use that.\n\nA: To disable gwibber-service, instead of removing the package you could just disable the autostart service:\necho \"Hidden=true\" | sudo tee -a /etc/xdg/autostart/gwibber.desktop\n\nsource: http://geekvigarista.com/os/linux/ubuntu-linux/removendo-o-gwibber-e-desabilitando-o-gwibber-service-no-ubuntu\n\nA: I installed Ubuntu 10.04 on an x86-64 laptop and disabled Ubuntu One already from the \"Startup applications\". Yet I still have desktop couch processes running:\n\n1886 ?        S      0:00 /bin/sh -e /usr/bin/couchdb -n -a \\\"/etc/couchdb/default.ini\\\" -a \\\"/etc/xdg/desktop-couch/compulsory-auth.ini\\\" -a \\\"/home/wirawan/.config/desktop-co\n 1914 ?        S      0:00  \\_ /bin/sh -e /usr/bin/couchdb -n -a \\\"/etc/couchdb/default.ini\\\" -a \\\"/etc/xdg/desktop-couch/compulsory-auth.ini\\\" -a \\\"/home/wirawan/.config/deskto\n 1915 ?        Sl     6:38      \\_ /usr/lib/erlang/erts-5.7.4/bin/beam.smp -Bd -K true -- -root /usr/lib/erlang -progname erl -- -home /home/wirawan -- -noshell -noinput -smp au\n 1937 ?        Ss     0:01          \\_ heart -pid 1915 -ht 11\n 1790 ?        S      7:20 /usr/bin/python /usr/lib/desktopcouch/desktopcouch-service\n 1976 ?        SN     8:00  \\_ /usr/bin/python /usr/lib/desktopcouch/desktopcouch-service\n\nAnyone having idea to disable this completely without uninstalling desktop couch stuff?\n", "Q: Moving from bash to zsh I'm considering moving from bash to zsh as I often come across posts praising zsh. I'm an experienced command line user and I'm assuming the basics are pretty much the same, so I'm looking for advice to get the benefits of moving, and any gotchas to be aware of.\nPlease just give one bit of advice per answer. I'm looking for bite-size chunks where I can come back and integrate extra bits of info into my shell usage at a steady pace rather than trying to learn it all in one go.\n\nA: As you say, zsh is similar in many respects to bash. It has some features you won't find in bash, and it can be extended in powerful ways. Don't think of moving as a kind of revolution, but rather as a series of evolutionary steps that help you in your daily work. Here are some hints from my .zshrc. Although you say you prefer single pieces of advice, this post is a longish list. Still it is a good idea to go through the points one by one. Just add the interesting bits to your ~/.zshrc and reload with source ~/.zshrc. A final tip: learn the keystrokes of zsh's default (\"Emacs\") keyboard shortcuts: ^A ^E ^W Alt-F Alt-B Alt-P ^L ^R. You can replace Alt by two separate keystrokes: Alt-P is equivalent to ESC P.\n\nThis gives you more extensive tab completion.\nautoload -U compinit\ncompinit\n\nTab completion from both ends.\nsetopt completeinword\n\nTab completion should be case-insensitive.\nzstyle ':completion:*' matcher-list 'm:{a-zA-Z}={A-Za-z}'\n\nBetter completion for killall.\nzstyle ':completion:*:killall:*' command 'ps -u $USER -o cmd'\n\nChanges the definition of \"word\", e.g. with ^W.\nautoload select-word-style\nselect-word-style shell\n\nColors for ls.\nif [[ -x \"`whence -p dircolors`\" ]]; then\n  eval `dircolors`\n  alias ls='ls -F --color=auto'\nelse\n  alias ls='ls -F'\nfi\n\nShortcuts for ls.\nalias ll='ls -l'\nalias la='ls -a'\n\nOne history for all open shells; store 10,000 entries. This makes this into a useful memory aid to find the commands you used last time for ./configure etc. Use Alt-P (find command that starts like this) and ^R (search in history) liberally.\nHISTFILE=~/.zhistory\nHISTSIZE=SAVEHIST=10000\nsetopt sharehistory\nsetopt extendedhistory\n\nEnables all sorts of extended globbing, such as ls **/*.txt (find all text files), ls -d *(D) (show all files including those starting with \".\"). To find out more, go to man zshexpn, section \"FILENAME GENERATION\".\n# superglobs\nsetopt extendedglob\nunsetopt caseglob\n\nThis is useful to remember commands in your history without executing them.\nsetopt interactivecomments # pound sign in interactive prompt\n\nType \"..\" instead of \"cd ..\", \"/usr/include\" instead of \"cd /usr/include\".\nsetopt auto_cd\n\nNice prompt.\nPS1='[%T] %n@%m:%~# '\n\nDisplay CPU usage stats for commands taking more than 10 seconds\nREPORTTIME=10\n\nSome commands you use extensively in Ubuntu.\nalias 'a=sudo aptitude'\nalias 'ai=sudo aptitude install'\nalias 'ar=sudo aptitude remove'\nalias 'au=sudo aptitude update'\nalias 'ag=sudo aptitude safe-upgrade'\nalias 'as=apt-cache search'\nalias 'aw=apt-cache show'\n\nLists packages sorted by their size - useful when deciding which packages are taking up you disk space.\nfunction apt-list-packages {\n  dpkg-query -W --showformat='${Installed-Size} ${Package} ${Status}\\n' | grep -v deinstall | sort -n | awk '{print $1\" \"$2}'\n}\n\n\nA: Here is my .zshrc and that is the most importaint thing! zsh have a lot of options you can use, so look at some of all the examples around the net or read the documentation at the Zsh homepage.\nMy .zshrc doesn't contain any really cool things other than a timestamp in the righthand side of the command line.\nBtw, remember to try tab-compleation every where a few examples here:\nmplayer -a[tab]\n\nwill show somthing like this:\nmplayer -a\n -ac                 -- force usage of a specific audio codec\n -af                 -- activate audio filters\n -afm                -- force usage of a specific audio codec family\n -alang              -- select the DVD audio language\n -ao                 -- specify audio driver\n -aop                -- specify audio output filter\n\nAnd if you use passwordless ssh-keys or ssh-agent you might find it usefull to tabcomplete remote files:\nscp apollo:/home/user/[tab]\nDesktop/ Documents/ Downloads/ Music/ Pictures/ Public/ Templates/ Videos/\n\nAfter getting the list you can then press tab more times to cycle through the different possibilities.\nBut be warned, this shell will make you lazy and make you feel that a standard shell is stupid and annoying!\n\nA: A couple of specifically useful extended globs:\n\n\n*\n\n*rmdir *(/^F) - delete all non-empty directories under the current directory\n\n*grep traceback /srv/log/**/*(.m-2) - look for this regex in files modified in the last two days\n\n*chmod g+w **/*(U^I) - make any files owned by me and not group-writable be group-writable\nYes, of course you can write this with find but this is easier to dash off.  It does have two drawbacks, to be fair, both to do with them all being expanded onto the command line: if it matches many thousands of files the command line will get too long and this will fail, and secondly all of the files are found before the file starts to run.\n(You'll need setopt extendedglob if that's not already on)\n\nA: I dont know that much about bash, so I can't compate. Some snippets from my zsh config file.\nSome config\nHISTFILE=~/.zsh_history\nHISTSIZE=1000\nSAVEHIST=1000\nREPORTTIME=10 # print elapsed time when more than 10 seconds\nsetopt NO_HUP\nsetopt NO_LIST_BEEP\nsetopt LOCAL_OPTIONS # allow functions to have local options\nsetopt LOCAL_TRAPS # allow functions to have local traps\nsetopt HIST_VERIFY\nsetopt SHARE_HISTORY # share history between sessions ???\nsetopt EXTENDED_HISTORY # add timestamps to history\nsetopt PROMPT_SUBST\nsetopt CORRECT\nsetopt COMPLETE_IN_WORD\nsetopt IGNORE_EOF\n\nsetopt APPEND_HISTORY # adds history\nsetopt INC_APPEND_HISTORY SHARE_HISTORY  # adds history incrementally and share it across sessions\nsetopt HIST_IGNORE_ALL_DUPS  # don't record dupes in history\nsetopt HIST_REDUCE_BLANKS\n# Leave some chars out of the out of WORDCHARS so ^W acts more nicely \nWORDCHARS='*?_-[]~\\!#$%^(){}<>|`@#$%^*()+:?'\n\nGit in the prompt\nif [[ -n $SSH_CONNECTION ]]; then\n  export PS1='%m:%3~$(git_info_for_prompt)%# '\nelse\n  export PS1='%3~$(git_info_for_prompt)%# '\nfi\n\nSome hotkeys, insert at the beginning of the line some text. \ninsert_sudo     () { zle beginning-of-line; zle -U \"sudo \"         }\ninsert_apt      () { zle beginning-of-line; zle -U \"sudo apt-get \" }\ninsert_gem      () { zle beginning-of-line; zle -U \"sudo gem \"     }\ninsert_install  () { zle -U \"install \"     }\n\nzle -N insert-sudo      insert_sudo\nzle -N insert-apt       insert_apt\nzle -N insert-gem       insert_gem\nzle -N insert-install   insert_install\n\nbindkey \"^B\" insert-gem\nbindkey \"^N\" insert-install\nbindkey \"^k\" insert-sudo\nbindkey \"^a\" insert-apt\n\nThe functions, I store then in ~/.zsh/functions\nThe git_info_for_prompt\nlocal g=\"$(git rev-parse --git-dir 2>/dev/null)\"\nif [ -n \"$g\" ]; then\n  local r\n  local b\n  if [ -d \"$g/../.dotest\" ]\n  then\n    if test -f \"$g/../.dotest/rebasing\"\n    then\n      r=\"|REBASE\"\n    elif test -f \"$g/../.dotest/applying\"\n    then\n      r=\"|AM\"\n    else\n      r=\"|AM/REBASE\"\n    fi\n    b=\"$(git symbolic-ref HEAD 2>/dev/null)\"\n  elif [ -f \"$g/.dotest-merge/interactive\" ]\n  then\n    r=\"|REBASE-i\"\n    b=\"$(cat \"$g/.dotest-merge/head-name\")\"\n  elif [ -d \"$g/.dotest-merge\" ]\n  then\n    r=\"|REBASE-m\"\n    b=\"$(cat \"$g/.dotest-merge/head-name\")\"\n  elif [ -f \"$g/MERGE_HEAD\" ]\n  then\n    r=\"|MERGING\"\n    b=\"$(git symbolic-ref HEAD 2>/dev/null)\"\n  else\n    if [ -f \"$g/BISECT_LOG\" ]\n    then\n      r=\"|BISECTING\"\n    fi\n    if ! b=\"$(git symbolic-ref HEAD 2>/dev/null)\"\n    then\n      if ! b=\"tag: $(git describe --exact-match HEAD 2>/dev/null)\"\n      then\n        b=\"$(cut -c1-7 \"$g/HEAD\")...\"\n      fi\n    fi\n  fi\n\n  if [ -n \"$1\" ]; then\n    printf \"$1\" \"${b##refs/heads/}$r\"\n  else\n    printf \"[%s]\" \"${b##refs/heads/}$r\"\n  fi\nfi\n\nSome github options \n#compdef github\n\n_github() {\n  if (( CURRENT > 2 )); then\n    # shift words so _arguments doesn't have to be concerned with second command\n    (( CURRENT-- ))\n    shift words\n    # use _call_function here in case it doesn't exist\n    _call_function 1 _github_${words[1]}\n  else\n    _values \"github command\" \\\n     \"fetch[Fetch from a remote to a local branch.]\" \\\n     \"ignore[Ignore a SHA (from 'github network commits')]\" \\\n     \"fetch_all[Fetch all refs from a user]\" \\\n     \"info[Info about this project.]\" \\\n     \"browse[Open this repo in a web browser.]\" \\\n     \"home[Open this repo's master branch in a web browser.]\" \\\n     \"clone[Clone a repo.]\" \\\n     \"pull-request[Generate the text for a pull request.]\" \\\n     \"network[Project network tools.]\" \\\n     \"pull[Pull from a remote.]\" \\\n     \"track[Track another user's repository.]\"\n  fi\n}\n\n_github_pull() {\n  _arguments \\\n    \"--merge[Automatically merge remote's changes into your master.]\"\n}\n_github_clone() {\n  _arguments \\\n    \"--ssh[Clone using the git@github.com style url.]\"\n}\n\n_github_track() {\n  _arguments \\\n    \"--private[Use git@github.com: instead of git://github.com/.]\" \\\n    \"--ssh[Equivalent to --private.]\"\n}\n\n_github_network() {\n  if (( CURRENT > 2 )); then\n    # shift words so _arguments doesn't have to be concerned with second command\n    (( CURRENT-- ))\n    shift words\n    # use _call_function here in case it doesn't exist\n    _call_function 1 _github_network_${words[1]}\n  else\n    _values \"github network command\" \\\n     \"web[Open network in a web browser.]\" \\\n     \"list[List networked repositories.]\" \\\n     \"fetch[Fetched commits for a given networked repository.]\" \\\n     \"commits[List networked commits not pulled into this repo.]\"\n  fi\n}\n\n_github_network_commits() {\n  _arguments \\\n    \"--project[Filter commits on a certain project.]\" \\\n    \"--author[Filter commits on a email address of author.]\" \\\n    \"--common[Show common branch point.]\" \\\n    \"--nocache[Do not use the cached network data.]\" \\\n    \"--sort[How to sort : date(*), branch, author.]\" \\\n    \"--thisbranch[Look at branches that match the current one]\" \\\n    \"--applies[Filter commits to patches that apply cleanly.]\" \\\n    \"--limit[Only look through the first X heads - useful for really large projects]\" \\\n    \"--before[Only show commits before a certain date.]\" \\\n    \"--after[Only show commits after a certain date.]\" \\\n    \"--shas[Only show shas.]\" \\\n    \"--cache[Use the network data even if it's expired.]\" \\\n    \"--noapply[Filter commits to patches that do not apply cleanly.]\"\n}\n\n\nA: I'm in the same trip :)\nSo far I've found that the thing is to have a good configuration file (.zshrc).\nTake this one as example http://matt.blissett.me.uk/linux/zsh/zshrc, look at the comments and hack your way around. Stackoverflow and severphault and good places to search too.\nI have yet to dive into http://dotfiles.org/.zshrc, but I don't have that much time to loose :)\n\nA: Learn about the extended globbing and recursive globs in zsh.\nLearn a little about zstyle and how various things (especially completion) let you tune their configuration using zstyle.\nLook into the associative arrays.  Also the standard arrays (beware the differences from bash, for the better!)\nIf you use regular expressions, look into =~ (which bash also has) and consider: setopt rematch_pcre\nAvoid writing scripts which depend on more than a little of zsh's magic, because while it's fantastic to use, zsh can tend towards being write-only.  If you're using too much more, think about when to switch to a language such as Python.\nZsh is seductive.  It is the dark side.  Welcome.\n\nA: Big benefit – excellent tab completion with pre-packaged completion scripts for many commands. Here's an example showing the output of apt-get<TAB>:\napt-get\naction\nautoclean        build-dep        clean            dselect-upgrade  install          remove           update           \nautoremove       check            dist-upgrade     help             purge            source           upgrade          \n\n\nA: I would recommend the book From bash to Z Shell. It has all the advice you need for switching your shell. It explains the differences of both shells and makes it easy for a new zsher.\n\nA: I've give a coupe of talks and converted several people over to zsh. I keep a github repo of my (what are the advantages) notes along with both a starter and a copy of my own zsh config in github here. \nhttp://github.com/mitechie/zshrc\n\nA: Another great ressource is the zsh lovers page (comes from grml zsh site).\n", "Q: Technically speaking, what is different about Ubuntu compared to other Linux distributions? This is a question that's puzzled me for quite a while (and refers to the differences between all distributions).\nIn my mind, a distribution is: a pre-configured OS, with some pre-installed packages, some created by the distribution's community that are unique to that distribution (e.g. apt-get).\nI'm not sure my definition is right as I feel there's something else. I'm really interested in setting up my own ArchLinux distro (which starts as a very minimal barebones system that you expand yourself) but feel I need to understand this first.\n\nA: The biggest difference between different Linux distributions is the package management system used. Ubuntu is very similar to Debian and uses the Debian package management system (.debs, apt-get etc.). However, there is a much bigger difference between Ubuntu and Fedora and Red Hat which use the Red Hat package management system (.rpms, yum etc.). ArchLinux uses the Pacman package manager. Other distributions, such as Gentoo, require everything to be built from source.\nDistributions with a package management system often have a different set of packages available in their repositories.\nThe most visible differences are the default application selection and the default themes and settings. These seem to be the decisions that cause the most controversy but they are the easiest to change; all distributions are extremely customisable.\nAlso, the different distributions have limited binary compatibility, which means that the source code for packages has to be compiled separately for each distribution to create native binaries.\nYou can read about binary compatability her: https://wiki.ubuntu.com/MarkShuttleworth\n", "Q: Nasty CPU spikes that aren't connected to any visible processes Really strange issue here. I intermittently keep getting really unpleasant CPU spikes, where the CPU gets to 80-90% busy across all cores for about 5 minutes. When I look at conky, in htop or system monitor, and sort by % CPU, I can't see any process that accounts for this much CPU usage.\nThe only things I've changed since this started are:\n\n\n*\n\n*I moved to kernel version 2.6.35 (home compiled, up from 2.6.24-1)\n\n*I installed the Nvidia driver 256.44 (up from 256.34)\n\n\nNow, I am willing to downgrade either/both of those to find the problem but I'd prefer to do this as scientifically as possible and find out what is causing the CPU explosion before I downgrade.\nEdit: My precise issue looks like a nvidia regression in their latest driver. Other people are getting similar spikes. \n\nA: \"the CPU gets to 80-90% busy across all cores for about 5 minutes\"\nThat much usage would possibly enable you to pinpoint the culprit by using pidstat available in the sysstat package.  \nSimply run pidstat -u | sort -nr -k 7,7 | head -10 and the process that used the most CPU should be the top line.  \n\nA: I would try to find the cause for the problem with some shell script:\n#!/bin/sh\nMAXLOAD=100\nCURRLOAD=`uptime | sed 's@.*load average: \\([^,]*\\).*@\\1@' | sed 's@0\\?.0\\?@@'`\n\nif [ $CURRLOAD -gt $MAXLOAD ]; then                                             \n  ps -eo tid,pcpu,comm | sort -n -k 2 | tail -n 5 | \\\n    mail -s \"High load\" -e your@addre.ss\nfi\n\nThe script has two variables MAXLOAD and CURRLOAD. The first one should be a high load multiplied by 100. So if you encounter a spike and see the system load going up to 2 or 3, than you should set MAXLOAD to some value around 200. $CURRLOAD takes the output of uptime, looks for the load and removes the dot as well as leading zeros.\nIf the load at some point is to high it prints out the five processes with the most CPU utilisation and send them to your@addre.ss.\nThis script should help you to find the reason for a spike and if you know it you maybe can resolve your issue.\n\nA: It might be a kernel thread, those are hidden by default in most performance monitors.  In htop you can hide/show kernel threads with \"K\" (shift+k).\n\nA: To get output from top that you can save: top -b -n1\nStick this in a cronjob and you can look at the minutely processlist even after the problem went away. Example crontab entry:\n* * * * * top -b -n1 > /tmp/top_output_$(date +%Y-%m-%d_%H:%M:%S)\n\nThis will save it in one file per minute in /tmp\n\nA: There are some recently fixed bugs which might correct this issue. If you are running Ubuntu I'd suggest sticking with the Ubuntu kernel to pick up the patches through regular updates.\nI'd recommend installing Lucid for the support and stability. You can go with Maverick if there are features that you are aware of that are not in Lucid that you need.\n\nA: I think this is a kernel issue.  I would revert to an officially tested version.\n", "Q: YAMMM equivalent I've long used YAMMM for pulling metadata and thumbnails of my films/rips now i'm in trouble since switching as i can't seem to find any equivalent, The XBMC scrapers have been a disaster (e.g. I ripped toy story 2, put it in a folder \"Toy story 2 (2000) and it pulled everything for toystory 3) \nSo what apps can you recommend?\n\nA: When I was using MythTV it seemed to do a reasonably solid job of pulling metadata and thumbnails, even for my Korean soap opera. However I don't really know enough to tell you which sub-package does the actual scraping.\n", "Q: WINE users configuration I'm rebuilding an Ubuntu system and this is a problem that I had on my original installation.\nThe issue is this: In my home account I installed apps into Wine and all is good. However, I have a second account that I use for work purposes. So, I open Wine in the second account and it turns out that my home account Wine apps are not installed. So, basically I had to install the apps into the second user account as well. This is really inefficient since it's about 600MB worth of apps. (At the time I was new to linux and didn't have time to do this properly.)\nAnyway, since I'm essentially starting over, what I'd like to do is have Wine apps installed and available to multi users. \nThe question: How do I make Wine apps available to multiple users?\nThanks.\n\nA: Wine does not properly support multiple users in the Linux sense.  \"Bad things\" happen if two different users attempt to use the same Wine Prefix (a wine installation such as ~/.wine) at the same time.\nHowever, if this isn't something you need to worry about then you will want to create a folder with permissions accessible by both users, and then create a symlink to it as ~/.wine.\n\nA: I did find:\nhttp://ubuntuforums.org/showpost.php?p=3205534\nAll that you would have to do is follow the steps and make the 2 accounts part of the existing group plugdev by going to System > Administration > Users and Groups and editing the \"Group\" property to \"plugdev\"\nUpdate: Wine implemented an extra security check to prevent using wine as root ( http://wine.1045685.n5.nabble.com/Bug-30647-New-WINEPREFIX-quot-not-owned-by-you-quot-unnecessarily-restrictive-td5703178.html ), as such this solution to share the whole .wine folder among multiple users no longer works.  In case you receive the error \".wine is not owned by you\", instead of sharing the whole .wine folder to /home/wine, only do it for the .wine/drive_c folder.  \n", "Q: Fixing USB drive auto-notify Yesterday I was copying files from SD cards, but at some point they stopped auto-mounting. Didn't notice any errors. I can still mount by right-clicking the appropriate file in /dev in Konqueror.\nUPDATE: Slight correction. The drives never automounted, but I've stopped getting the notification that a drive is plugged in.\nWhat processes should I be checking? Something in Device Actions?\nI'm using Kubuntu 10.04\n\nA: Check out system setting's removable devices section and see if auto-mounting is enabled, I think the default is NOT to automount removable media - access/actions are done through the Device Notifier normally. You can edit various settings and devices from there\n\nA: To enable automount:\nRight click the Device Notifier plasmoid and go to Device Notifier Settings.  Click \"Automounting\" in the pane on the left, and then hit the checkbox to enable it.\nTo check that new devices are recognised:\ntail -f /var/log/dmesg\n\nDid you by any chance upgrade to KDE SC 4.5?\nEDIT:\nOh, in that case, right click on the tray and go to System Tray Settings, then check the box that tells the Device Notifier to be present in it.\n\nA: You can enable mount your pen drive/ pen drive is detecting automatically by ubuntu 11.10. just go to disk utility and format it.\nrestart your system. You will get your pen drive option in HOME folder.\n\nA: Automounting is done by udev (/sbin/udevd), so that would be the first thing I'd check.\n\nA: I go to Favorites, System Settings, Removable Drives (near the bottom under Hardware) to check the box for that device. It is easier for a GUI user than typing commands and hoping that you typed correctly.\n", "Q: How to fix unreadable tooltips in Eclipse Helios? This is what a function tooltip looks like for Eclipse CDT in Ubuntu 10.04 with the default theme:\n!\nThere's nothing in Eclipse's General > Appearance > Colors And Fonts preferences settings. Is there an easy fix for these unreadable context sensitive help boxes?\n\nA: This can be solve by changing the background colour in Ubuntu. I’ve tried changing the background colour in Eclipse but it doesn’t seems to works. To change the background colour in Ubuntu, go to\nSystem > Preferences > Appearance\n\n“Appearance Preferences” panel shows up, click on “Customize…”.\n\n“Customize Theme” shows up, go to “Colors” and select a lighter color for “Tooltips” Background, a darker color for “Tooltips” Text.\n\nStart or restart Eclipse, you will see the the lighter colors you selected when the code-assist appears.\nThis solution is copied from: http://tipstank.com/2010/05/23/solve-eclipse-black-pop-up-code-assist-box-in-ubuntu-10-4-lucid/\n\nA: For CDT do the following:\nWindow>Preferences>C/C++>Editor: Appearance Color Options>Source Hover Background\n\nUnfortunately there doesn't seem to be an application-wide setting. Kind of ridiculous.\n\nA: I've solved using this tip: http://wiki.eclipse.org/IRC_FAQ#Black_background_color_for_tooltips_on_Linux.2FUbuntu.2FGTK \nBut I also changed the selected_fg_color to black. So I did change as follows:\ntooltip_fg_color:#000000\nselected_bg_color:#f07746\nselected_fg_color:#000000\n\nSo just\nsudo gedit /usr/share/themes/Radiance/gtk-2.0/gtkrc \n\nand insert in place of the first line:\ngtk-color-scheme = \"base_color:#ffffff\\nfg_color:#4c4c4c\\ntooltip_fg_color:#000000\\nselected_bg_color:#f07746\\nselected_fg_color:#000000\\ntext_color:#3C3C3C\\nbg_color:#E6E6FA\\ntooltip_bg_color:#C0C0C0\\nlink_color:#DD4814\"\n\n\nA: My solution: Set the tooltip background to a gray variety. Works for both white and black text!\n\nA: An easy workaround to fix this is to install gnome-color-chooser.\nOpen it, go to Specific -> Tooltips and put black foreground over pale yellow background.\n\nA: i think, the tool you want to install is Gnome Color Chooser\ni have the screenshot here: \ntype this to install Gnome Color Chooser:\nsudo apt-get install gnome-color-chooser\n\nopen it, and go to Spesific -> Tooltip - Background\nchoose your desired color, and apply it.\ndoes not need to restart your eclipse, the tooltip background color is immediately changing.\n\nA: Go to Window -> Preferences -> C/C++ -> Editor\nUnder \"Appereance color options\" edit your \"Source hover background\"\n\nA: Eclipse seems to take the tooltip backgroud color from the system theme.\nI wasn't able to change the tooltip color without changing the system theme. I'm using the tropical theme with ambiance window decorations, currently, and it's working great! Give it a try!\n\nA: Try to customize the used Ubuntu theme System > Preferences > Appearance > Customize\nIn the tab Colors change the background and text colors of Tooltips\n\nA: I had the same problem with Zend Studio, it seems that the only fix at the moment is to adjust the tooltip colors in the appearance settings for ubuntu.\n", "Q: Rhythmbox keeps changing track to a different album I'm not sure whats happened but when i try and listen to a song in an album just after the song has finished and should go onto the next track it starts to play stereophonics (the same album) rather than the next track, has anyone else had this problem!? \n\nA: Check your \"play queue\". It probably has the offending music queued. \n\nA: Make sure you have only the one genre/artist/album selected and you have shuffle/repeat turned off.\n\nA: Do you have repeat on? Control > Repeat\n", "Q: How can I run Dwarf Fortress in text mode (ncurses) on my Linux VPS? I installed Dwarf Fortress on my Linux VPS to use with dfterm. It's running Ubuntu 10.04 Server x86-32. I'm fairly certain I have all the dependencies:\nI've installed:\n\n\n*\n\n*ncurses\n\n*ncursesw\n\n*libsdl\n\n*libsdl-image\n\n*libgtk\n\n*libglu\n\n*libopenal1\n\n\nI had to turn sound off or it will instantly segfault, and I set the display mode to text. I've made no other changes to the config.\nHowever, even before I go near dfterm, it won't run properly. It just displays a blank screen. What could be causing this? Is there a dependency I missed? Is there something else I should have changed in the config?\nGiven that it is a server, there is a good chance that if there is a missing dependency, it's something that the devs went \"Sure, everyone has that\" and didn't bother to list.\nOther ncurses applications (vim, irssi use it, I think?) work fine.\n\nA: I was able to recreate the segfaulting by running df on a regular Ubuntu install with X turned off.\n...\n(Dwarf_Fortress:5346): Gdk-CRITICAL **: gdk_window_new: assertion `GDK_IS_WINDOW (parent)' failed\nSegmentation fault\n\nI suspect the problem is that this game expects to have a functioning GL driver available.  And for that you need X running.  But a VPS doesn't have X!\nInstead, use Xvfb, which is a \"fake\" virtual X.  You'll need to install xvfb and whatever dependencies it wants (probably xorg-server-core and a bunch of other stuff that may not be installed on Ubuntu Server).\nStart the fake xserver up like this:\n $ Xvfb :1 -screen 0 1024x768x16 &\n\nThen make sure your DISPLAY variable is pointed to it:\n$ export DISPLAY=:1\n$ ./df\n\nI also needed to disable sound and run in TEXT mode, but it worked this way, with no X running.  I hope it works for you.\n\nA: You could try to use ldd to see if there is a shared object missing.\nFor example, something like:\nldd /usr/local/bin/df\n\nEverything that ldd lists as \"not found\" is missing.\nYou should also try to look at all the *.so files (with ldd) if any in the game folder. You can find the *.so files by using this command:  find . -iname '*.so' -type f\n\nA: Have you seen this DFTerm article on the DF Wiki?  It lists some dependencies that you don't seem to have listed above....\n\nA: You need to edit your init.txt.  Look for a setting for [PRINT_MODE:2D] and change it to [PRINT_MODE:TEXT]\nYou probably want to change to [SOUND:NO] as well. \nYou'll only run at 80x24 unless you run inside of screen or tmux though.\n", "Q: Occasional excessive IOWait freezes computer - how to diagnose? I have a very slow SSD on an eeepc900A, and it occasionally freezes the OS (even the mouse pointer) with system monitor showing excessive IOWait.  How can I diagnose what is causing this and should the system allow it?\nThanks.\n\nA: You could install the package iotop\nsudo apt-get install iotop\n\nand run the program to see what has high io demands at those moments.\n\nA: There's a good ServerFault answere here\n", "Q: Good filesystem for /tmp? I'm thinking of having /tmp on its own partition... what would be a good filesystem to format it with?\nThe reason I ask is because the data being stored in /tmp is not permanent, so I don't need journaling, a fancy index, or anything.\n\nA: If you don't want it possibly eating RAM, I'd just run it as ext2. No reason to eat the small performance hit of journaling for a filesystem whose data you don't (shouldn't) care about across reboots.\nActually, scratch that, you should probably use ext4 and disable its journal, it should be faster than ext2. Format it ext4, and stick it in fstab with the mount option data=writeback.\n\nA: Using tmpfs should be fine for your needs, provided that you have adequate RAM installed.\nThat being said...something that should be considered with regard to using a ramdisk for /tmp (this taken from an older post elsewhere):\n\n\n*\n\n*Should /tmp be on a real disk area or allowed to be implemented basically on the SWAP area (or tmpfs)?\n\n\nWhen it's heavily used, this is a temptation - \"we'll put /tmp into a RAM disk, it'll speed up access, and when the system reboots/shuts down, there's nothing to clean up\". However, if you are thinking of implementing temp space as a RAM disk that will be swapped, then I would consider the ramifications of your system's swap space usage by other programs. If swap is there as a form of \"emergency overflow\" for when the system is in dire straights and needs it, the last thing you need is to have swap space consumed by a runaway process filling /tmp, consuming memory, causing pressure on the VM subsystem to swap to disk. Between swap activity, and the additional I/O streaming into the RAM disk (which in turn may cause additional page-ins to satisfy a seek() ) your system will quickly become I/O bound.\n\nA: Using ext4 with specific mount options should be fine. Use the following mount options:\nbarrier=0 : Significantly improves file write operations in some scenarios\nnoatime : Don't update file last access time, you don't need this on /tmp files and it should help with write operations performance.\n\n\nA: I sometimes find moving /tmp to ram (tmpfs) is the best solution (Especially on my setups which use a lot of disk intensive IO stuff - MySQL, etc) if you have enough RAM to feed it.\n\nA: I'm happy with ext4. You can play with some mount options if you like to tweak it or use tmpfs if you have a lot of ram.\n\nA: There are several good choices here:\n\n\n*\n\n*tmpfs: is a filesystem which stores its files in RAM. This doesn't mean that the filesystem will eat all your RAM. Instead it takes only the amount it really needs. Usually only some MB are needed. If you'll use it, add a line like: none /tmp tmpfs size=64M,mode=1777 0 0 to your /etc/fstab. You can change the size to a value you like. If you think at some point that it is too little, you can use mount to increase the size: mount -t tmpfs tmpfs /tmp -o size=128M,mode=1777,remount. The size will be increased in place without deleting existing files.\n\n*ext2/3: You said in your question that you don't need any fancy features. However I would advise using a journal. Because if you use ext2 and you have a quite large /tmp, checking it will take some time. ext3 boots faster in many cases. Therefore I would suggest the use of journalling.\n\n*ext4, reiserfs etc.: Some software uses /tmp for storing large amounts of small files. So in some cases there are no more free blocks and the filesystem is full. ext4 and also reiserfs store files in a different way. So it could be a good choice to use those for your /tmp.\n\n\nIf your computer runs for a long time, it is a good idea to delete unused files in /tmp. tmpreaper is one solution which does that for you.\nHowever my first choice would be using tmpfs.\n\nA: In response to those asking about why you would want a separate /tmp partition, I'm sure there are many reasons, as some have already stated, but one that I find particularly relavant today is that if you are running / on an SSD, you want to minimize the writes to that drive, therefore moving /tmp is a good idea since it is an area of the filesystem that tends to change a lot.\n\nA: I think tmpfs might be a bad option because usually /tmp is world writable so anyone can fill it up and if it fills up it will take all you memory and your server will slow to a crawl\n", "Q: Mounting a USB disk in a permanent location I have a USB hard disk that I want to mount on boot and in a specific location. How can I make that drive mount and stay available (say for local backups, etc.) even though no one's logged in?\nIt seems that udev or something similar grabs hold of the disk. If I put an entry in /etc/fstab that tries to specifically mount this disk (by UUID), then that mount process and the udev mount process seem to end up in a battle with each other and the disk doesn't get mounted.\n\nA: Mount the disk using udev. Place the rules from this wiki into /etc/udev/user.rules and reboot (or reconnect the USB HDD) . There are several favors of rules in the wiki (that's why I didn't list them here), choose the one that best suits your needs (e.g. you need a specific normal user to be able to unmount it).\nPerusing /lib/udev/rules.d/80-udisks.rules will help you understand what's udev doing to your hard disk.\nBesides the udev rules I mentioned above I think there's another approach you can take: instruct udisks (through udev) to leave your disk alone and then mount it through fstab.\nThis code works on my system\nACTION!=\"add|change\", GOTO=\"my_udisks_end\"\nSUBSYSTEM!=\"block\", GOTO=\"my_udisks_end\"\n\nENV{ID_TYPE}!=\"disk\", GOTO=\"my_udisks_end\"\nENV{ID_BUS}!=\"ata\", GOTO=\"my_udisks_end\"\nENV{DEVTYPE}!=\"partition\", GOTO=\"my_udisks_end\"\n\nKERNEL==\"sd*|hd*\", ENV{UDISKS_PRESENTATION_NOPOLICY}=\"1\"\n\nLABEL=\"my_udisks_end\"\n\nbut is generic and includes all partitions. To be able to target your particular hdd/partition use udevadm info --query=all -n /dev/sdX and then match on some of those particular atributes in the udev rules.  \nA good resource to help you in this is Writing udev rules. Unfortunately it contains some outdated info (udevinfo was replaced by udevadm indo). I assure you, though, it's a worthwhile read -- udev is a central piece of architecture nowadays and you can accomplish a lot by using it. It's also pretty flexible.  \nIt's also easy to make mistakes in udev rules :). Use udevadm test $(udevadm info -q path -n /dev/sdX) to take a 'peek' at what's udev doing.\n\nA: You could try referencing it by /dev/... instead of by UUID. It is most likely /dev/sdb*, you can check this by going to System -> Administration -> System Monitor and clicking on the 'File Systems' tab. You will need to have inserted the USB drive first and let it be automatically mounted. Replace 'UUID=uuid' with the '/dev/sdb*' in /etc/fstab. It's always a good idea to back up fstab before editing it.\n", "Q: Support for various features in gedit I'm trying to use gedit as my main editor, and am looking for help with some tricky features. For each of the following, can people help me out with how to install and configure the feature?\n\n\n*\n\n*code folding\n\n*pylint support\n\n*splitview support\n\n*spell check\n\n*whitespace deletion\n\n*regex-powered find and replace\n\n*any other features I should know about?\n\n\nTags: Plugins, IDE\n\nA: Geany has all of the features you want except inbuilt pylint support (although there is inbuilt syntax checking and you could run pylint using the integrated terminal). Split view and spell checking are available through plugins (packages: geany-plugin*). Geany is lightweight and simple to use - perfect if you are looking for something more advanced than gedit but don't want/need the complexities of a full-blown IDE. \nI would suggest installing geany and the extra plugins.\nVia the terminal with sudo apt-get install geany\nOr install using the Software Center:\n\n\nA: See http://live.gnome.org/Gedit/Plugins\nYou install them by downloading the plugin's files and copying them to ~/.gnome2/gedit/plugins.\n\nA: *\n\n*Code Folding\nThe plugin throws an error on the\ncommand line when you try to fold.\nBut it may be something a good Python\nprogrammer could fix in five minutes.\nApparently code folding is slated to\nbe supported by gedit natively\neventually.\n\n*Pylint\nThe one reference to a plugin I found\npointed to a bzr branch that no\nlonger exists.\n\n*Splitview\nI don't use it much, but it does a\ngood enough job for me.\n\n*Spell Check\nThe plugin should be enabled by\ndefault. Use Tools > Autocheck\nSpelling to turn it on.\n\n*Whitespace Removal\nRemoves unnecessary whitespace on\nsaving a file.\n\n*Regex Search and Replace:\nExtract to your plugins directory,\nenable, and use Tools > Regex Search\n& Replace.\n\n*Others:\nThe gedit-plugins package comes with\nsome handy plugins. You should check\nthat out.\n\nA: Even though gedit is good for basic file editing I wouldn't use for more than I would use notepad.exe on Windows. You might want to use a IDE (Integrated Development Environment). Depending a bit on what code you write these might be worth a lookover:\n\n\n*\n\n*NetBeans\n\n*\n\n*Java\n\n*PHP\n\n*C/C++\n\n*Python\n\n\n*Eclipse\n\n*\n\n*Java\n\n*PHP\n\n*C/C++\n\n*Python\n\n\n*Cream\n\n*\n\n*Seems to be a cross of gedit and notepad++ but I haven't used it.\n\n\n*Editra\n\n*\n\n*Much like Cream. (not really an IDE)\n\n\n*VIM\n\n*\n\n*Designed as a cli tool, got GUI extension but lacks a bit in usability if you don't read the manual!\n\n*A lot of languages!\n\n\n*GNU emacs\n\n*\n\n*Designed as a cli tool, got GUI extension but lacks a bit in usability if you don't read the manual!\n\n*A lot of languages!\n\n\n\nBout VIM and Emacs are a bit hard to learn to use, VIM in my opinion being the simpler one.\n\nA: Geany with plugins installed from http://getdeb.net or its ppa repository is fantastic text editor.\n\nA: *\n\n*Pylint (kinda)\n\n\nI use a python checker that is part of the gedit-developer-plugins package in the repos. It doesn't seen to use pylint, but it does a nice work checking syntax and style. It's called GDP Format in the plugin lists, not a very descriptive name.\n\nA: I've been searching for a decent TextMate clone for Linux and finally I managed to pimp my gEdit and abandoned all the other IDEs (NetBeans, Komodo... you name it):\nThis is the way to do it:\nsudo apt-get install gedit gedit-plugins\ncd ~/Downloads\ngit clone http://github.com/gmate/gmate.git\ncd gmate\nsh ./install.sh\n\nNext time you launch your gEdit you'll be surprised how powerful it is. Don't forget to check the plugins as well to beef up the editor even more.\n", "Q: Lightroom alternative? What is the best alternative to Adobe Lightroom on Linux/Ubuntu?\n\nA: I use Darktable too. If your camera is supported RawTherapee will be an option as well.\n\nA: I have been quite happy with using Bibble 5.\nWhile it is a commercial program, I find it outstrips all open-source solutions in both usability and speed - at least for my uses. And they have quite good Linux support, including .deb-packages and simultaneous releases on all platforms.\n\nA: the best I like is digiKam but there are also UFRAW, RawTherapee and Shotwell(RAW support in development).\nThere are also Lightzone and Bibble if you are looking for commercial products.\n\nA: Darktable all the way.  Extremely versatile and well-thought-out RAW workflow tool.  It's a new-ish project, but you'd never know it from the features and stability.  There's an official release, as well as PPAs available for those of us who like the latest and greatest (and don't mind the odd hiccup, though those have been rare for me).\nBe sure to watch the tutorial videos on their Sourceforge page... many features and functions are not immediately obvious to first-time users.\nI've also used RawTherapee to great effect, but at the moment, Darktable beats it hands-down.\n-Mark\n\nA: I'm shooting sports 3-5 times per week(400-1000 shots per event) and I use Darktable for my needs.\nAlso I download and organize my photos with Rapid Photo Downloader.\n\nA: I quite like F-Spot + UFRAW for organising photos and processing them but I also use Darktable for when I get bored of UFRAW.\n", "Q: Nautilus automatically browses as root I used gksudo nautilus (not through the terminal but through the 'Open With' command) for some copy & paste stuff that requires root access.\nBut now whenever I open the file browser (Nautilus) to access my local folder, it doesn't open normally, but opens with root access as if I had used gksudo nautilus again.\nOnly Trash is able be to opened normally without any root access.\nHow can I get back the normal, unprivileged behavior for nautilus?\n\nA: In general it might be a good idea to install nautilus-gksu. This package allows you to switch to root. It adds a menu entry where you can choose to work with root access.\n\nA: Go to the /home/user/.local/share/applications/ directory, in there is you users custom mime settings. One or more files will be called userapp-SOMETHING.desktop just delete the one causing problems - you can examine which one you need to delete by opening them with gedit.\nYou might have to re-login for changes to take affect but I don't think so.\n", "Q: The best way to compile a kernel for an i7 processor? I have compiled my own kernels for a while now. I started when I got my i7 processor and wanted its turbo boost to work properly. I've since bought an SSD so continue to benefit from a more recent kernel than the repo version.\nWith my most recent builds, I've started getting weird CPU spikes. While it could be a number of different things causing this, I'd like to focus on getting the kernel \"right\" and if possible, more optimised than ever.\nI follow the \"Old-Fashioned Debian\" on the Kernel/Compile wiki. I do this because I'm building from a direct download from kernel.org. First questions: Should I get my source from somewhere else and should I use a different build method?\nThe guide suggests getting the current .config like so:\ncp -vi /boot/config-`uname -r` .config\n\nThis is all well and good if your current configuration works well but I'm concerned mine contains a problem... Second question: Is there a good Ubuntu-friendly, i7-friendly default .config file I can download from somewhere?\nThere are a lot of kernel patches floating around at the moment. Some promise a more responsive system through patching IO bugs, some give \"better\" schedulers (BFS, et al) but it's hard to find decent benchmarks to see if these are worthwhile features of if they're just unstable junk. Third: Are there any patches you would apply to 2.6.35 to make it more compatible with Lucid?\nI fear it's make menuconfig where I screw things up. I try to turn off drivers I don't need and select options that look like they'll optimise things but, truth be told, I'm not a kernel developer; I don't know for certain if an option will break everything or even help at all. Fourth: How would you optimise the .config/build-process for an i7 and SSD?\n\nA: From my point of view kernel.org is the right place to get a kernel. Usually I clone the git repository from mainline. Maybe you could also use a recent vanilla kernel and apply the patches from Ubuntu. You'll find the diff at the linux-image package page. Be aware that there could be some conflicts which you have to resolve. So the first version is probably better.\nI guess you wouldn't find any good .config in the wild. What I find helpful is make localmodconfig in the kernel source. First you copy your old config to /usr/src/linux-2.6 (or the place where your kernel sources are) and then you execute this command. It will disable all module which are not loaded. So you gain more customization in the first place. \nI'm not aware of any patches which are good for Lucid. \nI'm a member of a local LUG. We make from time to time kernel workshops. Here all members meet. We configure a kernel and talk about our knowledge of different entries. In the end all profit from it and this helps to build better kernels. So if I look for optimisation I would ask our members. If that is not an option, reading the Linux Kernel mailing list could also help to find a solution. You'll find often some discussion which are helpful. \n\nA: There is a mainline kernel PPA:\nhttps://wiki.ubuntu.com/Kernel/MainlineBuilds\nUnless you are trying to resolve a specific problem (that you experience with an Ubuntu stock ekernel) ou you are trying to use a specific feature/option not available on Ubuntu's kernel you will probably just be wasting your time.\nIf you do have a problem with your current kernel please file a bug report at launchpad.\n\nA: You don't mention which kernel version you are building. Because you've asked about patches to Lucid I'm going to assume that's what you are trying to tweak.\nMy suggestion is to not waste your time. The Ubuntu Kernel team applies all the patches that are released by the upstream stable release team to Lucid (and other releases as well). You might be able to get a little more performance from the kernel by hand tweaking configuration parameters but you'd have to spend a lot more time trying to measure the improvement if there really is one. You'd be much better off staying on a stock kernel and picking up the patched kernels from Ubuntu. These patches can contain performance improvements as bugs are found and fixed.\nThe reason you may be seeing CPU spikes may be due to some kernel bugs that have been recently been fixed upstream and the patches are working their way into Lucid right now.\nOnce you start building your own kernel, you are now assuming the responsibility for keeping it patched and rebuilt. That's what Canonical pays people to do so you don't have to. Your really do have better things to do with your time.\n", "Q: How do I dual-boot with Debian? I want to install Debian Unstable alongside Maverick but I don't want to lose my data.\nAlso my CD drive is Broken.\n\nA: Installing Debian without a CD drive\nIf you have the partition space to install Debian along side Ubuntu as a dual boot setup (as mentioned in previous answers), then as you have a broken CD drive you can install Debian (and other Linux distributions) from a USB memory stick.\nUsing the System > Administration Startup Disk Creator you can create a USB memory stick from any of the Ubuntu CD images, the .iso files.  You may be also able to use debian .iso files with the same startup disk creator.\nAlternatively, you can use unetbootin which will create live and install USB sticks from a wide range of distributions (it will even download the the .iso files for you for some distributions).\nInstallation from a USB memory stick is exactly the same as from a CD, however for some PC hardware when first switching on the PC you may need to press the escape key when you see the manufacturers logo to bring up a boot menu allowing you to select the USB memory stick as the boot device.\n\nA: The normal process would be to reparition your HD (if you don't have another one), install Debian into the new free space, don't install a new grub, edit Ubuntu's grub to boot to Debian and you're done.\nHowever, I've just found Lubi which gets its name from Wubi. It basically allow you to install a linux to a file in your existing filesystem and then just loopback-mount it and chainload into it from Grub. I've made it sound more complicated than it is... But it looks like it should work.\nIt certainly seems a lot less destructive than repartitioning could be.\n\nA: If you have an existing Ubuntu installation and a decent network on your side, you can use debootstrap. So first you have to repartition your drive and in the new gained free space you can install Debian. Helpful ressources are:\n\n\n*\n\n*Installing Ubuntu from a Linux system: This describes how to install Ubuntu from another Linux. You just have to change some settings, because you want to install Debian from an Ubuntu.\n\n*Explanation of debootstrap in Debian wiki: This is a description from the Debian wiki. It has some good links to other ressources.\n\n", "Q: Best way to set up and record DVB-C PAL and share recorded streams with DNLA on Ubuntu? I have an EyeTV Hybrid DVB-C USB (plus a few Pinnacle DVB-T ones) receiver which works well under OS X, but I would like to have recording under Ubuntu instead - preferrably with EPG -and share with DNLA to my tv set.\nWhat would be the best way to do so in terms of programs etc?\n\nA: MythTV. Big and bulky but it supports most hardware and has a built-in UPnP server.\n", "Q: Whither hybrid suspend? So what ever happened to hybrid suspend, where it would suspend to both RAM and disk? It was kind of hot a few years ago, but it seems it was dropped. Is there any way to set this up in recent Ubuntu versions?\n\nA: You can enable hybrid suspend by following the answer to this question:\n\n\n*\n\n*How do I use pm-suspend-hybrid by default instead of pm-suspend?\n\nA: There is a program called pm-is-supported that can be used to check for the suspend capabilities of the system.\nOn my system here are the results (0 means supported, 1 means unsupported):\n$ pm-is-supported --suspend ; echo $?  \n0  \n$ pm-is-supported --hibernate ; echo $?\n0\n$ pm-is-supported --suspend-hybrid ; echo $?\n1\n\nThe manpage of pm-is-supported suggests that s2both supports hybrid suspend. I've installed s2both, available in the uswsusp package but it still reports that hybrid suspend is not supported. I have a hunch that it needs a reboot because it updated the initrd image. I'm gonna reboot and report back. Wish me luck.\nUpdate: Running sudo s2both wrote the snapshot to disk and suspended to RAM correctly, however when I pressed a key to resume the system rebooted (and didn't restore the snapshot from disk).\nI think there's something wrong with the uswsusp package in ubuntu. The splashy package (which is used by uswsusp) has a file conflict with lsb-base which has been left unfixed since Jaunty ( https://bugs.launchpad.net/ubuntu/+source/splashy/+bug/328089 )\nTry running sudo s2both or sudo pm-suspend-hybrid, see if it works on your system.\n\nA: This question comes up frequently enough in Google that I think it's worth bumping. Li explains hybrid suspend perfectly. However, s2both requires uswsusp (thus not using in-kernel suspend), and pm-hsuspend-hybrid does the wrong thing because it is unmaintained[1]. \nHere's how to enable the hybrid suspend seamlessly: \n\n\n*\n\n*Override \"suspend\" call to do a \"hybrid_suspend\" in pm-utils.\n\n\n\n    % cat /etc/pm/config.d/00-use-suspend-hybrid\n    # Always use suspend_hybrid instead of suspend\n    if [ \"$METHOD\" = \"suspend\" ]; then\n        METHOD=suspend_hybrid\n    fi\n\n\n\n*\n\n*Make a backup of /usr/lib/pm-utils/pm-functions\n\n*Get the patch from here: https://bugs.freedesktop.org/attachment.cgi?id=68712\n\n*\n\n*This patch enables hybrid suspend if available (i.e. on kernels 3.6+)\n\n\n*Either apply it using 'patch -p0' or manually merge it if that fails\n\n\nThis method works for me on my Sony Vaio SVS. \nPS: Reproducing the patch here in case the file is deleted in the future:\n\ndiff --git a/pm/pm-functions.in b/pm/pm-functions.in\n--- a/pm/pm-functions.in\n+++ b/pm/pm-functions.in\n@@ -316,8 +316,28 @@ if [ -z \"$HIBERNATE_MODULE\" ] && \\\n    {\n        [ -n \"${HIBERNATE_MODE}\" ] && \\\n        grep -qw \"${HIBERNATE_MODE}\" /sys/power/disk && \\\n+       HIBERNATE_MODE_SAVE=$(cat /sys/power/disk) && \\\n+       HIBERNATE_MODE_SAVE=\"${HIBERNATE_MODE_SAVE##*[}\" && \\\n+       HIBERNATE_MODE_SAVE=\"${HIBERNATE_MODE_SAVE%%]*}\" && \\\n        echo -n \"${HIBERNATE_MODE}\" > /sys/power/disk\n        echo -n \"disk\" > /sys/power/state\n+       RET=$?\n+       echo -n \"$HIBERNATE_MODE_SAVE\" > /sys/power/disk\n+       return \"$RET\"\n+   }\n+fi\n+\n+# for kernels that support suspend to both (i.e. hybrid suspend)\n+# since kernel 3.6\n+if [ -z \"$SUSPEND_HYBRID_MODULE\" ] && \\\n+   [ -f /sys/power/disk ] && \\\n+   grep -q disk /sys/power/state && \\\n+   grep -q suspend /sys/power/disk; then\n+   SUSPEND_HYBRID_MODULE=\"kernel\"\n+   do_suspend_hybrid()\n+   {\n+       HIBERNATE_MODE=\"suspend\"\n+       do_hibernate\n    }\n fi\n\nSources:\n\n\n*\n\n*https://bugzilla.redhat.com/show_bug.cgi?id=843657\n\n*https://bugs.freedesktop.org/show_bug.cgi?id=52572\n[1]: pm-utils predates in-kernel hybrid suspend available in kernels 3.6+. What pm-suspend-hybrid actually does is put your machine in sleep mode for 15mins by default, and then hibernate. \n", "Q: How well does Microsoft Office Excel work in Wine? Some interest in Excel 2003, but primarily in Excel 2007. Wondering if advanced features, such as macros can be made to work flawlessly. Or if there are any major issues I should know about.\nUsing an alternative open source native program is unfortunately out of the question due to complex macro/VBA heavy spreadsheets.\n\nA: MS Office 2007 works well in Ubuntu 12.10, with following inconveniences:\n- when any *office app is started, another launcher opens in Unity bar with default WINE icon... :( (I have managed to get proper launchers through Drag/drop from Dashboard, however after the Launcher is clicked it opens under new launcher with WINE icon.)\nAfter some upgrade I can't associate extensions to MS Office apps. as well, apart from that it is working fairly good.\nI haven't tested macros abilities, as they are not-essential in my work environment, hence not used.\n\nA: Excel 2007 should work well with some adjustments.\nExcel 2003 is unlikely to work properly.\nAlways look on the wine application database to find out how well a program can be run in wine.\n\nA: if you use playonlinux then both will work pretty well.\n\nA: Just installed latest PlayOnLinux on Ubuntu 11.10 desktop, Macros did not work at all under Excel 2007. Everytime I try to run the macro, even the simplest one-liners, it crashes.\n", "Q: Is there an easy way to edit gtk-recordMyDesktop videos? gtk-recordMyDesktop outputs .ogv files that seem perfectly fine - they work well in Totem and VLC. However, if I try to edit them in openshot or kdenlive, the editor either crashes (kdenlive) or won't show the video properly (openshot). PiTiVi appears to work but then locks up when it tries to render the video.\nUsing video conversion tools, such as ffmpeg outputs a video that is a jumble of colours; although it is just about possible to make out some movement.\n\nThe only way I've managed to edit the videos is to use DeVeDe to create a DVD .iso, mount the ISO and then edit the .VOB file(s).\nThis is a bit of a faff; does anyone know of a better way around this?\n\nA: You need to convert them first... they never worked without converting (at least for me):\nmencoder -idx out.ogv -o out.avi -oac mp3lame -ovc lavc\n\nThen you can edit them in your favourite video editor (I for one prefer Avidemux).\n\nA: I see you had trouble with ffmpeg, but I have had a lot of good luck converting just about anything using it. If you don't specify a bitrate or quality setting in ffmpeg, it can use some really low quality settings. This may be why your conversions look so crummy. The video editors are picky about what kinds of videos they work well with, so I always convert to MP4 with MPEG4 video and FAAC audio. The command I use is:\nffmpeg -i in.ogv -vcodec mpeg4 -acodec libfaac -sameq out.mp4\nThe -sameq option tells ffmpeg to try to make the resulting video approximately as good looking as the original.\nOnce you have it in MP4, I recommend you use OpenShot to edit it.\n\nA: Try lives, LiVES is a Video Editing System, it's available from the repositories.\n\nA: You can try mobile media converter (.deb download)\nIts a great tool to convert videos in good/high qualities then you can edit the video easily using any editor.\n", "Q: Is it possible to import DV video using Firewire? I know there are several video editing programs: PiTiVi, Openshot, etc\nHowever I am unsure if I can transfer video footage from a DV tape to my computer. In other operating systems (with the correct software) I can connect my firewire camcorder or tape deck to a pc, and record the video to file in realtime.\nIs this possible in Ubuntu and if so which software is needed?\n\nA: I use the command line program dvgrab to pull from my minidv camcorder over firewire.\nThe command I use is: \nsudo dvgrab -a -format raw -rewind -t prefix-\n\nThe permissions are messed up, which is why you need sudo. Afterwards, just do:\nsudo chown username:username prefix-*.dv\n\nThe rewind command rewinds the tape, so leave it off if you don't want to rewind.\nThe prefix- gets appended to the file name to help you identify it. The files are automatically split when dvgrab finds a time gap or every 2GB.\nManpage for the dvgrab command  has a few more useful options.\n\nA: In short, it's possible but thanks to regression upon regression, it's a pain in the rear.\nIn Lucid it involves telling udev to keep its paws off the firewire device and let it be a raw interface:\necho 'KERNEL==\"raw1394\", GROUP=\"video\", MODE=\"0664\"' |\nsudo tee /etc/udev/rules.d/50-raw1394.rules\n&& sudo restart udev\n\nYou then plug you camera in, hit play on the camera then use something like kino that interfaces with the dvgrab package to record the video to disk. As I mentioned: PITA.\nhttps://help.ubuntu.com/community/Firewire\n", "Q: Watch QuickTime videos in the browser? It's rather frustrating to me that I can't watch any of the videos on Apple's site. Is there a QuickTime plugin for Chrome or Firefox, and if not, why?\n\nA: The Quicktime codec, like most other non-free formats, is provided as part of the w32codecs package (or its 64-bit equivalent, w64codecs) by Medibuntu. The community documentation includes instructions for installing.\nOnce the codecs are installed the standard media plugins for your browser should detect and handle them.\n\nA: I've discovered that sometimes Apple actually detects which browser/OS you're using when it embeds videos on its site, and that can prevent QuickTime videos from playing even if you have the proper codecs and plugins installed. You can circumvent this in Firefox by changing your user agent string.\nYou'll need the User Agent Switcher extension:\nhttps://addons.mozilla.org/en-US/firefox/addon/user-agent-switcher/\nAnd a user agent string that specifies a browser on Mac or Windows. There's a rather nice list of user agents here:\nhttp://techpatterns.com/forums/about304.html\n\nA: Odd... Works for me!\nI'm using the totem plugin which I thought shipped with Ubuntu. Have a look at about:plugins in the browser and see if you can see \"QuickTime Plug-in 7.something\"\nIf you don't, check totem-mozilla is installed. Might be worth installing the ubuntu-restricted-extras package to make sure you've got the right codecs.\nJust searching synaptic, I also have libquicktime1 installed. It's a dependency of quicktime-utils so it might be worth installing that. It might just be something used for encoding to quicktime.\nEdit: you might also need gstreamer-plugins-bad for AAC audio.\n\nA: All you need is to run the following from a Terminal window:\nsudo apt-get install gnome-mplayer gecko-mediaplayer\n\n", "Q: How can I debug/monitor Emacs to find out why it's using so much memory? I'm using GNU Emacs 23.1.50.1 (x86_64-pc-linux-gnu, GTK+ Version 2.18.0) and start my Emacs session inside GNU screen. \nSince I upgraded to Ubuntu 10.04 and the version of emacs-snapshot there I encounter some problems. Sometimes Emacs hogs all RAM plus the same amount of swap space (2+2GB) and also eats all CPU time. When I send the process a SIGTERM the process stops eating CPU time, but the huge allocated amount of memory stays. Emacs itself doesn't take any key sequences. So usually I send the process a SIGKILL and it dies.\nNow I want to find out where the bug (if there is one) is located and want to do some debugging. I can see no special reason for this behavior. Sometimes it starts after Emacs is freshly started, sometimes I can work a whole day without problems, sometimes it happens in between. So I'm looking for a kind of debugging or monitoring the process. \nI tried strace, but this generates too much output. Strace output of an editing session could easily fill my whole hard drive. Running Emacs inside gdb would also not work, because if I remember correctly Ubuntu builds the software without debugging symbols. So do you have any advice on how I can find the (possible) bug? What would you suggest?\n\nA: Perhaps the package emacs-snapshot-dbg might be of interest?\n\"This package contains the debugging symbols useful for debugging Emacs.\"\n\nA: I found the answer to this by accident. The problem was not emacs, but a malfunctioning GNOME keyring. When I start Emacs without the keyring daemon all is fine. So disabling it resolved my issue here.\n\nA: At the moment I'm trying to save all content of Messages-buffer to a file and hope to find something useful:\n(with-current-buffer \"*Messages*\" (auto-save-mode t))\n\n", "Q: What is the \"keyring\" or \"keychain\"? Can someone please explain what Ubuntu's keychain or keyring is, as well as use cases for it?\n\nA: If you mean the package/command named keychain:\n\nkeychain is a manager for ssh-agent, typically run from ~/.bash_profile.  It allows your shells and cron jobs to easily share a single ssh-agent process.  By default, the ssh-agent started by keychain is long-running and will continue to run, even after you have logged out from the system.\n\nSo in short, it's a tool to make ssh-agent easier to use.\n\nA: A keyring basically stores all your various passwords and allows you to access them with one master password. So instead of having to enter passwords for my wireless, email and ubuntu one accounts separately I just enter one master password to unlock my keyring. Then I have access to all the accounts stored in that keyring.\nIf you set your keyring password to the same as your login password the keyring will be unlocked when you sign in at boot up.\n\nA: The Gnome Keyring is used by Gnome-ish apps to store secrets on your behalf. The secrets are stuff like SSH keys, keys to wifi networks, et cetera. \nIf you want to poke at your keyring, go to the Accessories menu and run the app called \"Passwords and Encryption Keys.\" It will show your a number of folders on the Password tab - each one of those is called a keyring. Each entry under a folder is a password. Double click on them to see their contents. \nThe reason a keyring is provided is that applications have to store secrets somewhere. It's easy for programmers to make a mistake and leave secrets around for anyone to read. In theory, the Gnome Keyring should store passwords for everything and do it right. \n(You should always exercise a minimum of security - add a password to keyrings that you care about, keep your computer physically safe, etc)\n\nA: Which keychain do you mean?\n\n\n*\n\n*There's the apt keyring, that is used for verifying downloaded packages. This helps to prevent malicious software from being installed via apt.\n\n*There's your user keyring where good apps store passwords (such as mail passwords, wifi passwords)\n\n\nAnd then there's this. Guess what that is good for :)\n", "Q: How to enable anisotropic filtering and anti-aliasing with mupen64plus 1.99.3 OS: Ubuntu 10.04 64-bit\nI have searched alll over for how to enable these with the mupen emulator. Thought I might check and see if anyone here has knowledge on this.\nhttp://code.google.com/p/mupen64plus/\nI'm really hoping I don't have to go back to Windows to use Project 64 to get these. And before anyone says \"Project 64 rocks with wine\" well I'm sure it does, but no Anti-Aliasing in wine...\nThanks in advance! ^^\n\nA: I think I figured out how to configure mupen to use AA & AF. Problem is you have to configure config.cpp in the Rice Video plugin by hand. The option for multi-sampling and anisotropic filtering was already there, but set to 0. Using this guide I downloaded the HG and built it with the config altered and unaltered, but both ways I get an error running mupen64plus.\n    ethan@ethans-mac:~/Emulators/N64/mupenHG/test$ ./mupen64plus --resolution 1920x1080 --windowed --verbose /home/ethan/Emulators/ROMs_ISOs_IMGs/N64/Zelda\\:\\ OOT/Legend\\ of\\ Zelda\\,\\ The\\ -\\ Ocarina\\ of\\ Time\\ \\(USA\\).n64\n __  __                         __   _  _   ____  _             \n|  \\/  |_   _ _ __   ___ _ __  / /_ | || | |  _ \\| |_   _ ___ \n| |\\/| | | | | '_ \\ / _ \\ '_ \\| '_ \\| || |_| |_) | | | | / __|  \n| |  | | |_| | |_) |  __/ | | | (_) |__   _|  __/| | |_| \\__ \\  \n|_|  |_|\\__,_| .__/ \\___|_| |_|\\___/   |_| |_|   |_|\\__,_|___/  \n             |_|         http://code.google.com/p/mupen64plus/  \nMupen64Plus Console User-Interface Version 1.99.3\n\nUI-console: attached to core library 'Mupen64Plus Core' version 1.99.3\n            Includes support for Dynamic Recompiler.\nCore: Goodname: Legend of Zelda, The - Ocarina of Time (U) (V1.0) [!]\nCore: Name: THE LEGEND OF ZELDA\nCore: MD5: 5BD1FE107BF8106B2AB6650ABECD54D6\nCore: CRC: ec7011b7 7616d72b\nCore: Imagetype: .v64 (byteswapped)\nCore: Rom size: 33554432 bytes (or 32 Mb or 256 Megabits)\nCore: ClockRate = f\nCore: Version: 1449\nCore: Manufacturer: 43000000\nCore: Cartridge_ID: 4c5a\nCore: Country: USA\nCore: PC = 80000400\nCore: EEPROM type: 0\nUI-Console: Cheat codes disabled.\nUI-console: using Video plugin: 'Mupen64Plus OpenGL Video Plugin by Rice' v1.99.3\nUI-console: Video plugin library: ./mupen64plus-video-rice.so\nUI-console: using Audio plugin: 'Mupen64Plus SDL Audio Plugin' v1.99.3\nUI-console: Audio plugin library: ./mupen64plus-audio-sdl.so\nUI-console: using Input plugin: 'Mupen64Plus SDL Input Plugin' v1.99.3\nUI-console: Input plugin library: ./mupen64plus-input-sdl.so\nUI-console: using RSP plugin: 'Hacktarux/Azimer High-Level Emulation RSP Plugin' v1.99.3\nUI-console: RSP plugin library: ./mupen64plus-rsp-hle.so\nCore Error: broken Video plugin; function(s) not found.\nUI-Console: error from core while attaching Video plugin.\nCore Status: Rom closed.\n\nThoughts or solutions? Thanks.\nLinks used to figure this out: http://code.google.com/p/mupen64plus/wiki/CompilingFromHg?colspec=ID%20Type%20Component%20Status%20Priority%20Stars%20Milestone%20Owner%20Summary&sort=-id\n\nA: If you use Nvidia you can override the Antialiasing and Anisotropic Filtering settings globally using the nvidia-settings application.\nhttp://img208.imageshack.us/img208/6316/70292226.jpg\nThere might be a similar control panel for ATI?\n", "Q: Turning off the backlight on the console I'm using an IBM Thinkpad X21 as a 3G router.  It's running a server install of lucid.  The laptop has the lid up most of the time. There is no X, just a plain console.  The colsole blanks itself, but the LCD backlight is always on.  \nThe graphics chip is ATI Technologies Inc Rage Mobility P/M AGP 2x (rev 64).\nThe following modules related to the framebuffer are now loaded:\n$ lsmod | grep fb\nfbcon                  35102  71 \ntileblit                2031  1 fbcon\nfont                    7557  1 fbcon\nbitblit                 4707  1 fbcon\nvga16fb                11385  1 \nvgastate                8961  1 vga16fb\n\nCan I make the LCD backlight turn off when the colsole is unused and have it turn on automatically when needed?\n\nA: You should be able to use setterm to do this:\n# turn power save on, blank after 10 mins, powerdown after 20mins\nsetterm -powersave on -blank 10 -powerdown 20\n\n\nA: vbetool works for me. I have used it on a dell inspiron 8100. Old computer, but it is supposed to be a general tool, I believe.\nIt was not installed by default on my computer: Ubuntu server 9.04.\nI installed it using apt-get:\nsudo apt-get install vbetool\n\nThen, I can execute it:\nsudo vbetool dpms off\nsudo vbetool dpms on\n\nFor me this turns the laptop monitor completely off (including the backlight) and then on.\nDoesn't seem to be exactly what you want, but maybe it is close enough. \nHope this helps\n\nA: Not quite as automatically as you might like, still issuing the following ought to turn the brightness all the way down. Further poking around in the /sys tree might reveal other complementary steps to improve on it:\nsudo su -c 'echo \"0\" > /sys/devices/virtual/backlight/acpi_video0/brightness';\n\nThen use the power buttons on the keyboard to get the brightness back up. Be sure to verify the correctness of this line w.r.t. how your /sys tree looks.\n", "Q: How can I create a select menu in a shell script? I'm creating a simple bash script and I want to create a select menu in it, like this:\n$./script\n\necho \"Choose your option:\"\n\n1) Option 1  \n2) Option 2  \n3) Option 3  \n4) Quit  \n\nAnd according to user's choice, I want different actions to be executed. I'm a bash shell scripting noob, I've searched the web for some answers, but got nothing really concrete.\n\nA: Bash fancy menu\nTry it out first, then visit my page for detailed description.\nNo need for external libraries or programs like dialog or zenity.\n#/bin/bash\n# by oToGamez\n# www.pro-toolz.net\n\n      E='echo -e';e='echo -en';trap \"R;exit\" 2\n    ESC=$( $e \"\\e\")\n   TPUT(){ $e \"\\e[${1};${2}H\";}\n  CLEAR(){ $e \"\\ec\";}\n  CIVIS(){ $e \"\\e[?25l\";}\n   DRAW(){ $e \"\\e%@\\e(0\";}\n  WRITE(){ $e \"\\e(B\";}\n   MARK(){ $e \"\\e[7m\";}\n UNMARK(){ $e \"\\e[27m\";}\n      R(){ CLEAR ;stty sane;$e \"\\ec\\e[37;44m\\e[J\";};\n   HEAD(){ DRAW\n           for each in $(seq 1 13);do\n           $E \"   x                                          x\"\n           done\n           WRITE;MARK;TPUT 1 5\n           $E \"BASH SELECTION MENU                       \";UNMARK;}\n           i=0; CLEAR; CIVIS;NULL=/dev/null\n   FOOT(){ MARK;TPUT 13 5\n           printf \"ENTER - SELECT,NEXT                       \";UNMARK;}\n  ARROW(){ read -s -n3 key 2>/dev/null >&2\n           if [[ $key = $ESC[A ]];then echo up;fi\n           if [[ $key = $ESC[B ]];then echo dn;fi;}\n     M0(){ TPUT  4 20; $e \"Login info\";}\n     M1(){ TPUT  5 20; $e \"Network\";}\n     M2(){ TPUT  6 20; $e \"Disk\";}\n     M3(){ TPUT  7 20; $e \"Routing\";}\n     M4(){ TPUT  8 20; $e \"Time\";}\n     M5(){ TPUT  9 20; $e \"ABOUT  \";}\n     M6(){ TPUT 10 20; $e \"EXIT   \";}\n      LM=6\n   MENU(){ for each in $(seq 0 $LM);do M${each};done;}\n    POS(){ if [[ $cur == up ]];then ((i--));fi\n           if [[ $cur == dn ]];then ((i++));fi\n           if [[ $i -lt 0   ]];then i=$LM;fi\n           if [[ $i -gt $LM ]];then i=0;fi;}\nREFRESH(){ after=$((i+1)); before=$((i-1))\n           if [[ $before -lt 0  ]];then before=$LM;fi\n           if [[ $after -gt $LM ]];then after=0;fi\n           if [[ $j -lt $i      ]];then UNMARK;M$before;else UNMARK;M$after;fi\n           if [[ $after -eq 0 ]] || [ $before -eq $LM ];then\n           UNMARK; M$before; M$after;fi;j=$i;UNMARK;M$before;M$after;}\n   INIT(){ R;HEAD;FOOT;MENU;}\n     SC(){ REFRESH;MARK;$S;$b;cur=`ARROW`;}\n     ES(){ MARK;$e \"ENTER = main menu \";$b;read;INIT;};INIT\n  while [[ \"$O\" != \" \" ]]; do case $i in\n        0) S=M0;SC;if [[ $cur == \"\" ]];then R;$e \"\\n$(w        )\\n\";ES;fi;;\n        1) S=M1;SC;if [[ $cur == \"\" ]];then R;$e \"\\n$(ifconfig )\\n\";ES;fi;;\n        2) S=M2;SC;if [[ $cur == \"\" ]];then R;$e \"\\n$(df -h    )\\n\";ES;fi;;\n        3) S=M3;SC;if [[ $cur == \"\" ]];then R;$e \"\\n$(route -n )\\n\";ES;fi;;\n        4) S=M4;SC;if [[ $cur == \"\" ]];then R;$e \"\\n$(date     )\\n\";ES;fi;;\n        5) S=M5;SC;if [[ $cur == \"\" ]];then R;$e \"\\n$($e by oTo)\\n\";ES;fi;;\n        6) S=M6;SC;if [[ $cur == \"\" ]];then R;exit 0;fi;;\n  esac;POS;done\n\n\nA: Not a new answer per se, but since there's no accepted answer yet, here are a few coding tips and tricks, for both select and zenity:\ntitle=\"Select example\"\nprompt=\"Pick an option:\"\noptions=(\"A\" \"B\" \"C\")\n\necho \"$title\"\nPS3=\"$prompt \"\nselect opt in \"${options[@]}\" \"Quit\"; do \n    case \"$REPLY\" in\n    1) echo \"You picked $opt which is option 1\";;\n    2) echo \"You picked $opt which is option 2\";;\n    3) echo \"You picked $opt which is option 3\";;\n    $((${#options[@]}+1))) echo \"Goodbye!\"; break;;\n    *) echo \"Invalid option. Try another one.\";continue;;\n    esac\ndone\n\nwhile opt=$(zenity --title=\"$title\" --text=\"$prompt\" --list \\\n                   --column=\"Options\" \"${options[@]}\")\ndo\n    case \"$opt\" in\n    \"${options[0]}\") zenity --info --text=\"You picked $opt, option 1\";;\n    \"${options[1]}\") zenity --info --text=\"You picked $opt, option 2\";;\n    \"${options[2]}\") zenity --info --text=\"You picked $opt, option 3\";;\n    *) zenity --error --text=\"Invalid option. Try another one.\";;\n    esac\ndone\n\nWorth mentioning:\n\n*\n\n*Both will loop until the user explicitly chooses Quit (or Cancel for zenity). This is a good approach for interactive script menus: after a choice is selected and action performed, menu is presented again for another choice. If choice is meant to be one-time only, just use break after esac (the zenity approach could be further reduced also)\n\n\n*Both case are index-based, rather than value-based. I think this is easier to code and maintain\n\n\n*Array is also used for zenity approach.\n\n\n*\"Quit\" option is not among the initial, original options. It is \"added\" when needed, so your array stay clean. Afterall, \"Quit\" is not needed for zenity anyway, user can just click \"Cancel\" (or close the window) to exit. Notice how both uses the same, untouched array of options.\n\n\n*PS3 and REPLY vars can not be renamed. select is hardcoded to use those. All other variables in script (opt, options, prompt, title) can have any names you want, provided you do the adjustments\n\nA: Since this is targeted at Ubuntu you should use whatever backend debconf is configured to use. You can find out the debconf backend with:\nsudo -s \"echo get debconf/frontend | debconf-communicate\"\n\nIf it says \"dialog\" then it likely uses whiptail or dialog. On Lucid it's whiptail.\nIf that fails, use bash \"select\" as explained by Dennis Williamson.\n\nA: I have used Zenity, which seems always there in Ubuntu, works very well and has many capabilities. This is a sketch of a possible menu:\n#! /bin/bash\n\nselection=$(zenity --list \"Option 1\" \"Option 2\" \"Option 3\" --column=\"\" --text=\"Text above column(s)\" --title=\"My menu\")\n\ncase \"$selection\" in\n\"Option 1\")zenity --info --text=\"Do something here for No1\";;\n\"Option 2\")zenity --info --text=\"Do something here for No2\";;\n\"Option 3\")zenity --info --text=\"Do something here for No3\";;\nesac\n\n\nA: If you only want a very simple menu that shows \"in place\" and you can continue typing after that - without any fancy external dialog program, then you can use ANSI escape sequences and a simple loop to render the list and allow a cursor to be moved on top of it.\nThe answer here by user360154 already has everything you need, but it is also super fancy, does much more than needed and while the code is also formatted to look fancy - it isn't easy to read and understand.\nHere's the same approach as user360154's but much simpler:\nfunction choose_from_menu() {\n    local prompt=\"$1\" outvar=\"$2\"\n    shift\n    shift\n    local options=(\"$@\") cur=0 count=${#options[@]} index=0\n    local esc=$(echo -en \"\\e\") # cache ESC as test doesn't allow esc codes\n    printf \"$prompt\\n\"\n    while true\n    do\n        # list all options (option list is zero-based)\n        index=0 \n        for o in \"${options[@]}\"\n        do\n            if [ \"$index\" == \"$cur\" ]\n            then echo -e \" >\\e[7m$o\\e[0m\" # mark & highlight the current option\n            else echo \"  $o\"\n            fi\n            index=$(( $index + 1 ))\n        done\n        read -s -n3 key # wait for user to key in arrows or ENTER\n        if [[ $key == $esc[A ]] # up arrow\n        then cur=$(( $cur - 1 ))\n            [ \"$cur\" -lt 0 ] && cur=0\n        elif [[ $key == $esc[B ]] # down arrow\n        then cur=$(( $cur + 1 ))\n            [ \"$cur\" -ge $count ] && cur=$(( $count - 1 ))\n        elif [[ $key == \"\" ]] # nothing, i.e the read delimiter - ENTER\n        then break\n        fi\n        echo -en \"\\e[${count}A\" # go up to the beginning to re-render\n    done\n    # export the selection to the requested output variable\n    printf -v $outvar \"${options[$cur]}\"\n}\n\nHere is an example usage:\n\nselections=(\n\"Selection A\"\n\"Selection B\"\n\"Selection C\"\n)\n\nchoose_from_menu \"Please make a choice:\" selected_choice \"${selections[@]}\"\necho \"Selected choice: $selected_choice\"\n\nWhich should look like this: \n\n\nA: There is already the same question in serverfault answered. The solution there uses whiptail.\n\nA: #!/bin/bash\n# Bash Menu Script Example\n\nPS3='Please enter your choice: '\noptions=(\"Option 1\" \"Option 2\" \"Option 3\" \"Quit\")\nselect opt in \"${options[@]}\"\ndo\n    case $opt in\n        \"Option 1\")\n            echo \"you chose choice 1\"\n            ;;\n        \"Option 2\")\n            echo \"you chose choice 2\"\n            ;;\n        \"Option 3\")\n            echo \"you chose choice $REPLY which is $opt\"\n            ;;\n        \"Quit\")\n            break\n            ;;\n        *) echo \"invalid option $REPLY\";;\n    esac\ndone\n\nAdd break statements wherever you need the select loop to exit. If a break is not performed, the select statement loops and the menu is re-displayed.\nIn the third option, I included variables that are set by the select statement to demonstrate that you have access to those values. If you choose it, it will output:\nyou chose choice 3 which is Option 3\n\nYou can see that $REPLY contains the string you entered at the prompt. It is used as an index into the array ${options[@]} as if the array were 1 based. The variable $opt contains the string from that index in the array.\nNote that the choices could be a simple list directly in the select statement like this:\nselect opt in foo bar baz 'multi word choice'\n\nbut you can't put such a list in a scalar variable because of the spaces in one of the choices.\nYou can also use file globbing if you are choosing among files:\nselect file in *.tar.gz\n\n\nA: You can use this simple script for creating options #!/bin/bash\necho \"select the operation ************\"\necho \"  1)operation 1\"\necho \"  2)operation 2\"\necho \"  3)operation 3\"\necho \"  4)operation 4\" \nread n\ncase $n in\n  1) echo \"You chose Option 1\";;\n  2) echo \"You chose Option 2\";;\n  3) echo \"You chose Option 3\";;\n  4) echo \"You chose Option 4\";;\n  *) echo \"invalid option\";;\nesac\n\n\nA: I have one more option that is a mixture of these answers but what makes it nice is that you only need to press one key and then the script continues thanks to the -n option of read. In this example, we are prompting to shutdown, reboot, or simply exit the script using ANS as our variable and the user only has to press E, R, or S. I also set the default to exit so if enter is pressed then the script will exit.\n#!/bin/bash\nread -n 1 -p \"Would you like to exit, reboot, or shutdown? (E/r/s) \" ans;\n\ncase $ans in\n    r|R)\n        sudo reboot;;\n    s|S)\n        sudo poweroff;;\n    *)\n        exit;;\nesac\n\n\nA: Using dialog, the command would look like this:\ndialog --clear --backtitle \"Backtitle here\" --title \"Title here\" --menu \"Choose one of the following options:\" 15 40 4 \\\n1 \"Option 1\" \\\n2 \"Option 2\" \\\n3 \"Option 3\"\n\n\nPutting it in a script:\n#!/bin/bash\n\nHEIGHT=15\nWIDTH=40\nCHOICE_HEIGHT=4\nBACKTITLE=\"Backtitle here\"\nTITLE=\"Title here\"\nMENU=\"Choose one of the following options:\"\n\nOPTIONS=(1 \"Option 1\"\n         2 \"Option 2\"\n         3 \"Option 3\")\n\nCHOICE=$(dialog --clear \\\n                --backtitle \"$BACKTITLE\" \\\n                --title \"$TITLE\" \\\n                --menu \"$MENU\" \\\n                $HEIGHT $WIDTH $CHOICE_HEIGHT \\\n                \"${OPTIONS[@]}\" \\\n                2>&1 >/dev/tty)\n\nclear\ncase $CHOICE in\n        1)\n            echo \"You chose Option 1\"\n            ;;\n        2)\n            echo \"You chose Option 2\"\n            ;;\n        3)\n            echo \"You chose Option 3\"\n            ;;\nesac\n\n\nA: #!/bin/sh\nshow_menu(){\n    normal=`echo \"\\033[m\"`\n    menu=`echo \"\\033[36m\"` #Blue\n    number=`echo \"\\033[33m\"` #yellow\n    bgred=`echo \"\\033[41m\"`\n    fgred=`echo \"\\033[31m\"`\n    printf \"\\n${menu}*********************************************${normal}\\n\"\n    printf \"${menu}**${number} 1)${menu} Mount dropbox ${normal}\\n\"\n    printf \"${menu}**${number} 2)${menu} Mount USB 500 Gig Drive ${normal}\\n\"\n    printf \"${menu}**${number} 3)${menu} Restart Apache ${normal}\\n\"\n    printf \"${menu}**${number} 4)${menu} ssh Frost TomCat Server ${normal}\\n\"\n    printf \"${menu}**${number} 5)${menu} Some other commands${normal}\\n\"\n    printf \"${menu}*********************************************${normal}\\n\"\n    printf \"Please enter a menu option and enter or ${fgred}x to exit. ${normal}\"\n    read opt\n}\n\noption_picked(){\n    msgcolor=`echo \"\\033[01;31m\"` # bold red\n    normal=`echo \"\\033[00;00m\"` # normal white\n    message=${@:-\"${normal}Error: No message passed\"}\n    printf \"${msgcolor}${message}${normal}\\n\"\n}\n\nclear\nshow_menu\nwhile [ $opt != '' ]\n    do\n    if [ $opt = '' ]; then\n      exit;\n    else\n      case $opt in\n        1) clear;\n            option_picked \"Option 1 Picked\";\n            printf \"sudo mount /dev/sdh1 /mnt/DropBox/; #The 3 terabyte\";\n            show_menu;\n        ;;\n        2) clear;\n            option_picked \"Option 2 Picked\";\n            printf \"sudo mount /dev/sdi1 /mnt/usbDrive; #The 500 gig drive\";\n            show_menu;\n        ;;\n        3) clear;\n            option_picked \"Option 3 Picked\";\n            printf \"sudo service apache2 restart\";\n            show_menu;\n        ;;\n        4) clear;\n            option_picked \"Option 4 Picked\";\n            printf \"ssh lmesser@ -p 2010\";\n            show_menu;\n        ;;\n        x)exit;\n        ;;\n        \\n)exit;\n        ;;\n        *)clear;\n            option_picked \"Pick an option from the menu\";\n            show_menu;\n        ;;\n      esac\n    fi\ndone\n", "Q: UNE takes about 30 minutes to start up (installed through WUBI) For some reason my Ubuntu UNE installed using wubi takes about 30 minutes to start up.\nAll I see is\n-\n\nwith barely any harddrive activity\n\n*\n\n*This has happened since the first install (this behaviour is not observed on the live usb)\n\n*The only thing installed previously was Windows 7 server edition\n\n*I seem to have grub 2, then windows boot up manager, then grub 1\n\nGoing into grub and manually loading the kernel, It gets stuck at:\n[0.797171] kernel)thread_helper+0x6/0x10]\n\nI'm assuming it's either this task or the task after it that is blocking.\nI also get the following error:\nVFS: open route device \"(null)\" ... please append a correct \"root=\" boot\nkernel panic not syncing vfs unable to mount root fs on unknown-block(8,1)\nPID 1, comm: swapper not trained \ncall trace:\n- ?printk\n- panic\n- mount_block_root\n- ?sys_mknod\n- mount_root\n- prepare_namespace\n- ? sys_access\n- kernel_init\n- ?kernel_init\n- kernel_thread_helper\n\n\nA: Your best bet is to back up your files and re-install.\nI'm not sure what's causing the problem, but the 3 separate boot loaders sounds definitely wrong to me.\nI would also advise doing a full dual boot instead of a wubi install because:\n\nWhat is the performance?\nThe performance is identical to a standard installation, except for hard-disk access which is slightly slower than an installation to a dedicated partition. If your hard disk is very fragmented the performance will degenerate.\nAny gotcha?\nHibernation is not supported under Wubi, moreover Wubi filesystem is more vulnerable to hard-reboots (turning off the power) and power outages than a normal filesystem, so try to avoid unplugging the power. An Ubuntu installation to a dedicated partition provides a filesystem that is more robust and can better tolerate such events.\n\n(from the wubi FAQ)\nIf you store the wubi image (normally:  c:/ubuntu/disks/root.disk) somewhere safe then you can mount it from a normal Ubuntu install and access your files.\n\nA: Maybe you need to defragment your windows ntfs system. If the Ubuntu partition created by wubi as a file in windows' ntfs filesystem is very fragmented (it is a quite large file), then it would take a lot of movements by the disk head and hence slow down the boot time.\nAnother issue to look for are timeouts that block other things. Networking used to be such a problem. If you don't have a DHCP server but you network connection expects one, there is quite a long time out. However, since this is now handled by upstart, it should have less an impact than it used to have. You an look this up in the logs in the /var/logs directory. dmesg gives you a lot of the hardware device messages, messages gives you a lot of the software log messages.\n\nA: I would suspect that the NTFS-filesystem in which the loopback file is located is dirty or outright broken.  Boot in Windows and repair it.\nIf that doesn't help, you need to go spelunking in /var/log to see if there is anything in a logfile (e.g. messages) that indicates that something is strange.\n\nA: Check whether you have \"ntfs-3g\" or not. If its not installed, install this.\n", "Q: Why would the aptitude binary be missing if its package is installed? Yesterday I upgraded a laptop from Kubuntu 9.04 (Lucid) to 9.10 (Karmic). Then afterwards I tried to install some software\n$ sudo aptitude install dont-remember-what-it-was\n\nand I get\nsudo: aptitude: command not found\n\nWait, what? How can aptitude be missing? And it's not just that - apt-get and dpkg also somehow mysteriously vanished from the system. I've manually checked in /usr/bin and all the other directories in $PATH and verified that the files actually do not exist.\n$ ls /usr/bin/aptitude\nls: cannot access /usr/bin/aptitude: No such file or directory\n\nThankfully I have two graphical package managers available, Adept Installer and KPackageKit. Both of them report that the aptitude package is installed. I tried uninstalling and reinstalling it through the GUI, just to be safe, and the uninstall/reinstall seemed to go off without a hitch. But the actual program binaries are still missing.\nIs this something normal? If not, has anyone ever heard of it happening? Is it likely that the missing programs will magically reappear if I upgrade to 10.04?\nEDIT: I have no idea what was going on, but after leaving the computer off overnight and a couple of reboots, the problem seems to have fixed itself. All the right files seem to be there.\n\nA: That is definitely not normal!\nTo get dpkg and apt-get back you can do the following:\nDownload dpkg_1.15.8.2ubuntu3_i386.deb and apt_0.7.25.3ubuntu9.1_i386.deb\nar x dpkg_1.15.8.2ubuntu3_i386.deb\nsudo tar -C / -xzf data.tar.gz\nar x apt_0.7.25.3ubuntu9.1_i386.deb\nsudo tar -C / -xzf data.tar.gz\n\nNote that some packages at internally compressed with lzma instead of gzip, so one would have to use \nsudo tar --lzma -xf data.tar.lzma\n\nAfterwards you should be able to do apt-get update and then install aptitude with\napt-get install --reinstall aptitude\n\nWarning!\nI really cant recommend that people install packages like this! Be sure to look at the configuration of the specific package, and if any dependency is missing! And if possible reinstall the packages through apt or dpkg afterwards.\n\nA: This is definitely not normal. I suggest you do a filesystemcheck and also check installed files with md5sum like this:\nmd5sum -c /var/lib/dpkg/info/*.md5sums 2>/dev/null | grep -v OK$\n\nAnd then maybe reinstall the affected packages with:\nsudo apt-get install --reinstall aptitude\n\n\nA: When you upgraded, Aptitude was uninstalled for some unknown reason. Most likely, it was a bug in the upgrade. Or, Aptitude was incompatible with the new software.\n", "Q: How do I reset X My computer seems to have issues suspending and resuming properly. Most recently, it resumed from hibernate, was working fine until I started logging in, and then X froze completely. I can log in via SSH (and it works flawlessly when I do), and I'd love to reset it without restarting the whole computer, and preferably without crashing all my open applications.\nIs this doable? If I have to crash the open apps, that's OK too, I suppose, but not preferred.\n\nA: I know hibernation still has a lot of issues with a wide variety of hardware in Ubuntu. You can restart X I believe with service gdm restart (or /etc/init.d/gdm restart) you should be able to get X reset. If you use Kubuntu or KDE you'll want to use service kdm restart (or /etc/init.d/kdm restart)\n\nA: Since the computer is not locked up, Alt+SysRq+k should kill/restart your X server. Type it on the X VT not on a console VT.\n\nA: If you need to restart X frequently you can do it with the Key combo Control + Alt + Backspace. It used to be enabled by default on Ubuntu but they have disabled it since 9.04 version I guess.\nTo re-enable it:\n\n\n*\n\n*Select “System”->”Preferences”->”Keyboard”\n\n*Select the “Layouts” tab and click on the “Options” button.\n\n*Select “Key sequence to kill the X server” and enable Control + Alt + Backspace.\n\n\nI suggest you keep looking to find the root of your problem since this is just a paliative, but should help you for now.\n\nA: Technically, with these kinds of \"X freeze\" issues, it's actually not that X itself froze up, but rather that the GPU on the video card locked up for some reason, and thus X could no longer update graphics on it.\nSo because of that, resetting X generally isn't going to solve the problem.  Like the prior two commenters mentioned, several easy ways exist to restart X such as restarting gdm or kdm, or turning on ctrl-alt-backspace and using that key combo.  But next time \"X freezes\", go ahead and try them, and I'll bet it has no effect.\nThe problem really is deeper down in the stack, at the kernel level.  Possibly if you closed X, unloaded and reloaded all the kernel graphics drivers, then restarted X it'd come up.  But in restarting X you lose all your apps.  So other than an interesting test, it's probably faster and safer to just do a full reboot.\nYou didn't mention which video driver you're using, but with for instance the Intel video driver, the GPU is handled by code in the Linux kernel itself.  Some developers have been experimenting with adding a \"GPU reset\" feature in the kernel that will automatically clear the GPU's memory and re-initialize it when it seems to no longer be responding to graphics commands.  This reset functionality is new and doesn't always work in all cases for various reasons, and isn't (yet) available for the nouveau or ati open source video drivers.  Hopefully it'll be coming soon.\nIf you're using a proprietary driver like nvidia or fglrx, well all bets are off.  Check the forums for those drivers for tips.\n\nA: Btw, you said \"X froze completely\" which if true my previous answer applies.  However, a common failure mode I've seen is a problem where when the lid closes the screen goes blank and doesn't come back, however X is not frozen in this case - all the GUI apps still run and produce noise and so on.  You just don't see anything on the screen.\nIn this case, it's a very different problem - the graphics card is able to send graphics to several different \"outputs\" (E.g. LVDS, DVI, VGA, TV-out) but only two \"pipes\" at one time.  Sometimes it chooses the wrong output to send data to.  So initially graphics is sent to the laptop panel (LVDS), you close the lid, reopen it, and now graphics are being sent to the TV-out output, even if you don't actually have a physical TV-out port in the laptop itself!\nThe fix in this case is generally to force-off the wayward output.  It used to be you could just put something in your xorg.conf to do this, but now with kernel mode-setting it's not so easy.  In any case, I've documented both methods at https://wiki.ubuntu.com/X/Quirks if you want to know the gritty details of how to do it.\n", "Q: I have a catch 22 here! No internet unless I update I have a usb internet tether, but it will not work in Ubuntu, unless I download something in the terminal, but I also can not get internet until I get this device working. I am able to use my Windows side on the internet, that's how I am doing this, but not with Ubuntu side. \nIs there any way, that allows me to download a packet (that i have directions for) while using Windows side, in the command-line? \nThis is the fix I found for my usb device, that I can't do without internet.\nTo get it working, make sure your iPhone is not plugged in. Then open up terminal and add the following repository:\nsudo add-apt-repository ppa:pmcenery/ppa\nsudo apt-get update\nsudo apt-get install libimobiledevice-dev libimobiledevice-utils ipheth-utils gvfs\n\nAfter this is done, turn MyWi application back on and plug it in. It will not seem to work if you have it plugged in, and then turn it on.\n\nA: You might be interested in that I recently stumbled upon by another user here Keryx which will allow you to use an internet capable machine to put the updates onto a USB drive then apply those updates to your computer via USB\n\nA: What about manually downloading all the packages from the ppa and installing them in your computer?.\nIf you click on the view package detail in the ppa web page, you should be able to download the debs one by one. Please check that you download the Lucid packages if you are using 10.04, and Karmic if you are using 9.10.\n\nA: If your router has a wired connection you can just use that (assuming your laptop also has a wired ethernet socket, if not you can get USB to wired ethernet adaptors for £10-£20 these days, the apple one works out of the box with ubuntu)\n", "Q: Basic Ubuntu FTP Server I would like to setup a basic FTP server on my Ubuntu Server install.  I have been playing with VSFTPD, but am having issues getting the server to allow me to create directories and copy files.  I have set the system to allow local users, but it appears that doesn't mean I get access to create directories.  This may be an instance where I need to be better grounded in Ubuntu server setup in order to configure this FTP server adequately.  The end goal is to be able to move files from my local dev folder into my www folder for deployment.  Directories need to be able to move as well.  Any help would be greatly appreciated.\n\nA: I would strongly recommend using vsftpd. It is one of the most secure FTP daemons in Linux. Many others had weaknesses in the past and it seems the FTP is hard to implement in a secure way.\nvsftpd starts right after you install it. Ubuntu enables local users to log in. So start your FTP client and log in as normal user with your system password (My example uses lftp):\n> lftp 127.0.0.1 ftp\nlftp 127.0.0.1:~> user qbi\nPassword: #typing my password which I also use to log in via GDM\nlftp qbi@127.0.0.1:~> ls\ndrwxr-xr-x 10 1000 1000   4096 2008-07-28 16:32 Desktop\n... many more\n\nNow I'm using some kind of file manager (Nautilus, Shell etc.) to create a new directory foo and go back to my FTP client:\nftp qbi@127.0.0.1:~> ls -l\n...\ndrwxr-xr-x 2 1000 1000   4096 2010-08-09 13:32 foo\n\nDirectory is there and I'm able to cd into it and use it. This is also the same if you have special users. There you can also create directories and they are immediately accessible. Here it is important to look for access rights.\n\nA: I humbly recommend an FTP server I wrote myself from scratch: JetFTP. It is extremely simple to install and use.\n\nInstallation:\n\n*\n\n*Add my PPA to your software sources and update:\n  sudo apt-add-repository ppa:george-edison55/george-edison\n\n\n\n*Run the following command:\n  sudo apt-get install jetftp\n\n\n\n*That's it!\n\nUsing JetFTP is simple - just connect to port 8021 using a login name and password on the computer JetFTP is running on.\n\nA: I'm going to recommend PureFTPD because it's been the simplest and easiest to use in my opinion. You'll need to install it first: sudo apt-get install pure-ftpd once it's installed it'll start itself up. By default it uses PAM Authentications - meaning it uses the accounts which already exist on the system for it's auth. All you'll need to do is create a user account with the home directory being your www path and set the password for that account. You should then be able to connect with that user/pass combination to upload/download files.\nSomething like this:\nsudo adduser ftpman --home /var/www/ --ingroup www-data\nWhich will create the ftpman user and put him in the www-data group which Apache uses and will walk you through the rest of the setup script. Once that's defined make sure to chmod the WWW folder if you get errors about it already existing to the user/group combination you created.\nLastly if you want to lock down SSH access for that account run: sudo chsh -s /bin/false ftpman which will change that users shell to false. (Replace ftpman with your ftp user)\n\nA: Do not use ftp, it is an inherently insecure protocol because it sends the username and password in the clear to the server. Implementing sftp is just as easy and you gain a huge advantage in the security of your connection.\n\nA: In my opinion SFTP is a better way to go. Hey, it's got the word \"secure\" in the name, it must be better :)\nSFTP uses ssh to do file transfers (as distinct from FTPS, which is FTP + TLS, basically). What that means is that if you can ssh to the target machine, you can almost always SFTP to it, as it uses the same auth mechanisms, so no having to install and configure different server daemons at all (i.e. no pureftpd or vsftpd). As long as your permissions are set correctly for /var/www - which is probably a matter of sudo chmod g+w /var/www; sudo usermod -g $USER -G www-data $USER - you should be able to use SFTP immediately.\nMost client software nowadays will do SFTP pretty happily, and you can also use scp from a shell on the dev server to copy stuff across (scp -R will copy entire folders across, and is very handy). You can even go another step and automate logins with public keys, meaning no more typing passwords :)\n\nA: There are three different ways to set up an ftp server:\n(1)  Anonymous FTP :\nPeople can access the server only with the anonymous account and without a password. Of course, the server administrator will set a limit for uploads to prevent users from putting illegal files like pirated music/films/games.\n(2)  FTP with both anonymous access and users with a passworded account:\nThis method lets both anonymous and passworded account users to enter the server. They will only have access to a specified directory, except for the user root who can view/modify/delete all files and/or folders.\n(3) FTP with mysql support for virtual users authentication :\nThis method allows access to the server only for some user groups that haven't got a virtual users authentication shell account on the system. It uses an external mysql server that stores user information.\nFirst Option : Anonymous FTP\nBefore starting the creation of an anonymous ftp server, you have to add a user called ftp into your system, with a home directory too. This step is really easy, just follow these commands:\nuseradd -d /home/ftp/ftp -s /bin/false ftp\n\nmkdir -p /home/ftp/upload\n\nDoing this permits only this account to write in this folder. You can use more variables to specify what the ftp server will do. Here are some examples:\n-e Allow access to the server only by anonymous users\n-B Start the server with background demon\n-i Anonymous users can't upload files\n-M Let anonymous users create folders\n-s ftp user files cannot be downloaded\n\nSecond Option : '''Both anonymous and passworded account users'''\nTo make it possible to have both anonymous and passworded account users in the same server, follow this small guide :\n-B ,-i ,M, -r, -s same of before\n-u <uid> Enable users with a specified user id (uid) to access the server \n-V <Ip address> Only specified IPs will be able to access the server in non-anonymous mode \n\nThird Option : '''Virtual Users with Mysql'''\nTo create a server with mysql support follow this steps :\nDownload and install User Manager for PureFTPd which you can find here \nhttp://machiel.generaal.net/index.php?subject=user_manager_pureftpd\nDecompress it and upload all its contents into your web server www directory and then write on your browser this link link http://localhost/ftp/install.php\nFollow all the steps that the installer asks to you\nCopy and save rge pureftpd-mysql.conf into pureftpd user manager directory\nDone. Access to the administration panel using this link http://localhost/ftp \nMore options to add before launch the server process\n-c <num> Max client that can connect to the server\n-C <num> Max connections for a IP\n-T <bandwitdh> Max bandwitdh disponible for each connection\n-n <MBytes> Max MB that a user can have into its home folder\n-m <Cpu Loading> Stops the anonymous uploads if the cpu loading exceed from this value \n\nAnd see this for some ftp server application: \nhttps://help.ubuntu.com/6.06/ubuntu/serverguide/C/ftp-server.html\n\nA: The default install of VSFTPD doesn't allow any create/modify changes by default.  You need to edit /etc/vsftpd.conf and uncomment the following line...\nwrite_enable=YES\nAnd secondly you need to configure the appropriate file-system permissions on the respective files and folders.\n", "Q: Can I run Android apps on Ubuntu? Is it possible to run Android apps on Ubuntu? And I don't mean inside an emulator, but natively, as you would with any other application installed using the Ubuntu Software Center.\n\nA: Seems there are more and more developers entering this domain.\nhttp://www.shashlik.io/, \nWhat is Shashlik\n\nThe goal of Shashlik is to provide a way to run Android applications on a standard Linux desktop as easily and simply as possible.\n\ncan run android apps, on Ubuntu. It's not stable, and not all apps work, but it seems promising.\nP.S. I had to sudo apt-get install libgl1-mesa-dev and sudo apt-get install kde-baseapps-bin\n\nA: No, you can't (other than through an emulator as mentioned by Oli.) However, it looks like the Ubuntu people are working on this, so you might be able to do it in the future. My proof: http://arstechnica.com/open-source/news/2009/05/canonical-developers-aim-to-make-android-apps-run-on-ubuntu.ars\n\nA: It possible to run Android apps on Ubuntu?\nYes\nNatively, as you would with any other application installed using the Ubuntu Software Center?\nYes, but through a lot of tinkering:\n\n\n*\n\n*Using chrome (Beta level tools);\n\n*Anbox (Alpha level software);\n\n\n\n\n\n*\n\n*Google Chrome can run Android apps as chrome apps but first, you must convert them using by using Arc Welder or the ARChon Custom Runtime.\n\n*Anbox  is not an emulator but a compatibility layer. It aims to run Android applications on any GNU/Linux operating system by putting the Android operating system into a container, abstracting hardware access and integrating core system services into a GNU/Linux system, so Android applications can be integrated with your operating system like any other native application.\n\nA: YOU CAN\nAnd have several options to do it. \n\n\n*\n\n*Special emulator like those that come with Android SDK. Don't use ARM-based as they are sloooow. \n\n*Generic virtual machine like VirtualBox with Android x86 installed. My recommend.\n\n*Chrome. Recent versions of Google Chrome can run Android apps inside itself (never tried that, but people rate it high).\n\n*Connect android device by USB or Wi-Fi network, and use some sort of Remote Desktop. \n\n\nA: You can now under Chrome run APKs, using this extension (bearing in mind it is in development for use by developers for testing apps). Here are some steps I did to get it to work\n\n\n*\n\n*Install from here -  click 'Add to Chrome'\nThis will take a while as it seems to download a crx installer weighing in at 113Mb, and another one at around 9Mb, so be patient:\n\nN.B. on my Fedora 21 build of Chromium 40 I got the error 'Manifest file is invalid' when trying install the extension, even after clearing data and reloading the extension. I also had issues with Ubuntu 14.04's build of Chromium 41, so I installed Google Chrome :( and that worked.\n\n*Get a APK of the application you want to use - no, it does not seem like you can install from Google Play, you need a APK file of the app, so this is the tricky bit. Most closed source devlopers don't want their stuff freely distributed, so for most apps on Google Play at least you either need to use:\n\n\n*\n\n*Use a APK for a open-source app - for testing this I tried using the x86 APK for VLC Media PLayer, which resulted in a error screen - I then tried the armv7 arc version and that worked at first and then crashed.\n\n*Get a APK from a Android device - this easily easily be done on some rooted Android devices, on normal devices I think you can copy system app's apks from /system/apps or somewhere - again not recommended due to legal stuff.\n\n*Use a third-party service/repository of APKs - e.g. this article suggest this one, but the issue here is that you may be downloading modified or infected programs/files. Probably should be considered a last resort.\n\n* Use a third-party extension - e.g. this one that pretends to be a device and downloads (not a good idea if you like legal stuff, plus google tracks your every move (mainly when signed in) so may be found out pretty quick...  Dead as out of date on both browser and likely android support. It isn't recommend to install extensions not in browser's extension store anyway!\n\n\n*Install it\nNow we get to the more fun bit of trying it out. Go to the Apps thing in chrome (or type chrome://apps in the URL bar) and launch Arc Welder. Then choose the directory the APK is in and then the APK, then choose 'Launch App' in the window.\nIf the window shows the app icon as one that looks like this:the app probably won't work so their may not be much point in continuing. This seemed to happen alot with apps for Android 4.4+...\n\n*Use it\nI managed to get QuickOffice to run and mostly work under the extension, though I couldn't save any documents as it was not happy about choosing the place to save the file (showing a folder selection box, not a file selection box for saving :P )\n\nAfter you press 'Launch App', the extension automatically adds a entry to the apps page on Chrome - this you can make into a standalone application launcher to launch the app directly from your app menu/dash/launcher - this is possibly the best feature of this extension as integrates with the desktop and you don't need to launch a emulator etc first.\n\nOverall this is brilliant, considering this probably is still in development and not designed for this it works quite well.\nSources:\n\n\n*\n\n*Getting Started with ARC\n\n*Android apps to run on Windows, Macs and Linux\n\n*Test Android apps in Chrome OS, Windows, OS X, or Linux using ARC Welder Chrome app\n\nAlternatively you can use a emulator as suggested in other answers - I did have some success using Genymotion (there were some handy instructions here, but this answer may help). Android Emulator can be got as part of the Android Studio SDK, however since Android Nougat apps should be signed.\n\nA: The straight answer is no you can't. Although Android apps are developed in Java and thus should work, the environment is completely different:\n\n\n*\n\n*Screen size is limited, the concept of a \"Windowing System\" does not exist in a mobile\n\n*Some of the hardware simply isn't there, SIM card, GPS, etc\n\n\nThere's an emulator that fools the apps by giving them those extra bits they need. But it uses the native OpenJDK on your machine so they will run well. Think of it like a test environment and not an emulator.\nAnyway if you idea is running Layar in your laptop, forget it, it doesn't make any sense at all.\n\nA: A more recently available option is Anbox. Unlike most other solutions, it is container based rather than being an emulator. This means that it runs on the host kernel. It also attempts to integrate into your host OS so that apps appear to be native. It is currently alpha but looks promising.\n\nA: The closest you'll get is through an emulator. This answer might not be for you (you might already know all this) but if other people drop into this thread, they might be interested in knowing.\nYou can run things through the Android emulator, part of the Android SDK (software development kit).\nThis provides a virtual device which does allow you to run quite a lot of Android applications though it may struggle with some of the more hardware-dependent things (3D, Phone calls, GPS, SMS, etc)\nHere's a guide on getting it set up:\nHow to Run Android Applications on Ubuntu - Softpedia\n\nA: Ubuntu Web\nUbuntu Web is an Ubuntu remix that is designed to be an open source desktop Linux replacement for Chrome OS.\n/e/OS is an open-source mobile operating system paired with carefully selected applications. They form a privacy-enabled internal system for your smartphone. And it's not just claims: open-source means auditable privacy. Logging into the /e/ account makes it possible for you to take advantage of a rather nifty trick Ubuntu Web has up its sleeve. This trick is WayDroid, a port of Anbox which allows users to install Android apps from the /e/ store.  source\nVisit /e/ Application Checker to check if your favorite Android apps are available in the /e/ store, for example there's YouTube and Instagram which make it possible to view these two apps on your tablet in full screen portrait mode.\n\n", "Q: What reason could prevent console output from \"virsh -c qemu:///system console guest1\"? I'm running KVM on a Ubuntu 10.04 host. The guest OS is also Ubuntu 10.04 .\nI am attempting to connect to the guest using the 'console' command. It appears I can establish a connection, but I get no output.\n$ sudo virsh -c qemu:///system console guest1\nConnected to domain guest1\nEscape character is ^]\n(NOTHING HERE)\n^]\n$\n\nI don't have a 'serial' device configured, but I do have these 'console' devices.\n<console type='pty' tty='/dev/pts/2'>\n  <source path='/dev/pts/2'/>\n  <target port='0'/>\n</console>\n<console type='pty' tty='/dev/pts/2'>\n  <source path='/dev/pts/2'/>\n  <target port='0'/>\n</console>\n\nAre these sufficient for a console, or do I need a serial device as well?\nWhat do I need to do in order to get the KVM console to work?\n\nA: I'm fairly sure you do need to configure the guest to use a serial console.  You need three things for this to work:\n\n\n*\n\n*give the guest a virtual serial device of type pty (for example by adding one in the virt-manager vm info page)\n\n*tell the kernel to use that for its output, by adding boot parameters like serial=tty0 console=ttyS0,115200n8 into GRUB_CMDLINE_LINUX in /etc/default/grub; then run sudo update-grub\n\n*(optional) put a getty on ttyS0 so that you get a login prompt\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=507650 for more.\n\nA: One possibility is that your virtual machine does not have a serial console configured. \nvirsh dumpxml guest1\n\nwill show if there is a serial console configured or not. There should be something similar as \n<serial type='pty'>\n<target port='0'/>\n</serial>\n\n\nA: Here it is very well explained:\nSerial console for Ubuntu server 10.04 KVM guests\n\nA: I just ran into this. \nHere is what I have inthe XML config on the host (running KVM):\n<serial type='pty'>\n  <source path='/dev/pts/0'/>\n  <target port='0'/>\n</serial>\n<console type='pty' tty='/dev/pts/0'>\n  <source path='/dev/pts/0'/>\n  <target port='0'/>\n</console>\n\nI also had to add the following in /etc/default/grub.conf in the VM (append to the \"kernel\" command):\nkernel ..... serial=tty0 console=ttyS0,115200n8\n\nFinally I secured the ttyS0 by adding \"/etc/securetty\" to enable root login from here\nvi /etc/securetty\nttyS0\n\nYou might need to muck with your getty settings (as described by the other answer) as well\nHope this helps\n", "Q: Sync notes between Android phone and Ubuntu? I want a note taking app on my Ubuntu running laptop and an app on my Android phone which can sync with each other, through online means or manually syncing. So far the only thing I've seen is the Evernote app for android and the beta quality third party app Nevernote.\nIdeally, I'd like an app that syncs with Tomboy, but the only thing I've found is Tomdroid which is buggy and only lets you view notes.\nDoes anyone have any suggestions? Or will I have to stick to Android apps which only sync with web sites?\n\nA: I just use text files in a Dropbox folder, in conjunction with Dropbox clients on \"real\" computers and the Android Dropbox App on my phone. Simple, but it works really well. And if you need something more sophisticated, using .doc files and .xls files with OpenOffice (on the PCs) and DocumentsToGo (on the phone) also works very well (DocumentsToGo is the only Android app I've paid money for, but there's nothing free to compare with it).\n\nA: There is an app for Android called Tomdroid which had experimental support for web syncing and seems to be close to making a new release. See this thread on the tomdroid mailing list.\n\nA: There is an Ubuntu One client for Android. It seems like you should be able to sync any files from your phone to your desktop.\nIf Ubuntu One can't do it, DropBox can.\n\nA: It's web-based, but 'GooMemo' will sync with a Google Docs account, which in turn could be accessed from or potentially sync'd with Ubuntu.  That's what I'm using at the moment.\nThat said, all of my notes on my ubuntu machine are in a hierarchical tree managed by 'pytombo' (since before I had an android phone).  Unfortunately I've not found an equivalent on android to allow me to browse/change these files other than a simple file manager.\nHope that helps and I'll read the other answers with interest!\n\nA: YES, it's possible without any CLouds.\nEven in 2020 it's a \"problem\" to sync Android notes, adresses, dates etc with Ubuntu without using any clouds, especially US-american data gathering clouds.\nHere's what I did (basement is UBUNTU 18.04 and Samsung S7):\nInstall CompanionLink on Android cellphone (free)\nInstall CompanionLink via WINE (because it's Windows Software) on Ubuntu \n  (you need to pay a little fee for the Windows version of CompanionLink)\nInstall an old MS-Office Pro 2007 also via WINE on Ubuntu\nCreate the same User  (like your mailbox on Android) in MS-Office\n fill it with at least one contact, date, note, task.\nStart CompanionLink and adjust the type sync-method you prefer\n(wifi, usb or companion-cloud) \nHint: I onyl use direct way via WIFI because I never use anykind of clouds to keep my data private.\nFirst sync should be ANDROID to Outlook no deletions at all!!!!\nWhen this is done, you may create new items in each of them.\nAccording to your subsequent adjustments how to sync, it will sync all latest updates visversa. (simply learn all options CompanioLink provides)\nSo, be happy or die in the linux-jungle  ;o))\njust see\n\nA: I don't exactly use notes. I use task with notes attached.\nI use RememberTheMilk, a web based task manager (you can attach any number of notes to a task). There are at least two apps that sync to it in Android (the official one only works with premium accounts). You can use Tasque to sync with it in ubuntu.\nThere are lots of other ways to sync or read RtM. I even used a Google Desktop Widget to put my task on a sidebar (it wasn't really practical).\nI know this is not a exactly what you asked, but as you haven't accepted any answer it could be a interesting workaround.\n\nA: I use Nitro for my notes, You can find it in the Ubuntu Software Centre. Set it up to sync via Ubuntu One or Dropbox, it is easy and works great. When I am on windows (work, ect) I use it in portable Chrome/Chromium from the web store, then set up my sync and I am good to go. For your android devices you can install NitroDroid from the Play store. It works great and now I have my notes with me wherever I am. It is easy and pain free, I highly suggest you try out Nitro on all three platforms it works great.\n\nA: I think Evernote is the best option if you want the best support on the go.\nIt has a full featured web version accessible from anywhere pretty much as well as the localised clients for all the popular phone OS, Nevernote support for Linux and Desktop Windows/Mac support.\nSo if you don't want to be withyour notes anywhere, I'd go with Evernote.\nIt is what I use and I've never had a problem with it so far.\n\nA: i am using fiinote and jotterpadx on android to make notes on android  and to sync the notes i further use dropsync in android which syncs selected folder to dropbox. by dropsync i am sharing the notes saved in the respective folder of jotterpadx and fiinote . however we need to export the notes made in fiinote in pdf or txt in order to be able to open in ubuntu desktop\n\n\n*\n\n*fiinote : https://play.google.com/store/apps/details?id=com.fiistudio.fiinote\n\n*jotterpadx : https://play.google.com/store/apps/details?id=com.jotterpad.x\n\n*dropsync : https://play.google.com/store/apps/details?id=com.ttxapps.dropsync\n", "Q: Is aptitude still considered superior to apt-get? When I first started with Ubuntu using aptitude was the 'in-thing', with some stated improvements over apt-get. Am I correct in saying that apt-get has now 'caught up' with aptitude, and it makes little difference which is used (although it is preferable to choose one or the other, and stick with it)?\nMoreover, with aptitude set to be removed from a default Ubuntu install, should everyone revert to apt-get, especially when guiding new users interested in the CLI?\n\nA: In addition to the other answers, it's also worth noting that apt-get often falls on its face for simple operations, and it has no ability to handle dependency version mismatches or broken packages (although it claims that broken packages can be fixed with apt-get install -f, I've literally never seen that work in my entire life). \nFor some reason, I still use apt-get by default, but when it encounters problems, I usually end up resolving them with aptitude, which never seems to encounter apt-get's numerous problems.\n\nA: I would say that in my personal experience aptitude and apt-get have very similar functionality. \nThe main difference that come to mind that might effect a users choices are, that aptitude offers an ncurses interface and that it offers options for safe-upgrade and full-upgrade that can come in handy. \nPersonally I always use apt-get and recommend that new users use apt-get as well. With aptitude set to be removed from Ubuntu by default as you said, this still seems to be the best recommendation. \nAs if they did want to use aptitude they will need to know how to use apt-get to install aptitude if they want it :)\n\nA: I guess it's a matter of personal choice by now. I find typing aptitude search makes more sense to me than apt-cache search, and I like that it tells me which packages I have installed right there in the search output, instead of having to run dpkg -l.\n\nA: On a server I prefer Atitude because it comes with a pretty good interface to check package changelogs, selective upgrades and that kinds of stuff. apt-get is more quick though and I always use that if I just want to update everything without too much hassle.\n\nA: As far as I can see, in 10.04, the main differences between aptitude\nand apt-get are: \n\n\n*\n\n*aptitude adds explicit per-package flags, indicating whether a\npackage was automatically installed to satisfy a dependency: you\ncan manipulate those flags (aptitude markauto or aptitude unmarkauto) to change the way aptitude treats the package.\napt-get keeps track of the same information, but will not show it\nexplicitly. apt-mark can be used for manipulating the flags.\n\n*aptitude will offer to remove unused packages each time you\nremove an installed package, whereas apt-get will only do that if\nexplicitly asked to with apt-get autoremove or specify --auto-remove.\n\n*aptitude acts as a single command-line front-end to most of the\nfunctionalities in both apt-get and apt-cache. Note: As of 16.04, there is an apt command that includes the most commonly used commands from apt-get and apt-cache and a few extra features.\n\n*In contrast to apt-cache's \"search\", aptitude's \"search\" output\nalso shows the installed/removed/purged status of a package (plus\naptitude's own status flags).  Also, the \"install\" output marks\nwhich packages are being installed to satisfy a dependency, and\nwhich are being removed because unused.\n\n*aptitude has a (text-only) interactive UI.\nI personally use only aptitude for my command-line package\nmanagement (and I never use the text UI); I find its output more\nreadable than apt-get/apt-cache.  \nHowever, if aptitude will be no longer standard on Ubuntu, there's\nno other choice than use apt-get in instructions and how-to\ndocuments.\n(Personally, I'm rather disappointed to see it go away in 10.10;\nespecially since the improvements of aptitude over apt-get are\nmostly on the usability side.  I guess they deemed that those\nconversant with the command-line know how to get aptitude back, and\nthose who don't use the command-line will not care...)\n\nA: Earlier apt-get would not manage dependencies properly and therefore cause orphaned dependencies to remain in a system even after the package that was using them was uninstalled - this is not longer the case, to remove orphaned dependencies use\nsudo apt-get autoremove\n\naptitude always did this right and tracks dependencies better, but now both package managers do the job.\nOn ubuntu it is better to use apt-get because its supported and endorsed by the company, on debian I would use aptitude\n", "Q: Network Preferences Occasionally Defaulted upon Login Sometimes (but not all the time, oddly enough), when I log into my system, Networking will be disabled by default. Is this a common issue, or is there some workaround I missed to set 'On' as the PERMANENT default (!?).\n\nA: This question looks very similar. Ressu's accepted answer runs something like this:\nRight-click the Network Manager applet and choose Edit Connections. Edit the connection you want to be used on login and check the \"Connect automatically\" and \"Available to all users\" checkboxes.\n", "Q: Recover EXT4 partition I was trying to resize my EXT4 partition and something went wrong. I lost it. The space in once consumed is now being represented as Unallocated. How do I recover the partition? \n\nA: Well provided you haven't overwritten it, it's possible.\nsudo apt-get install testdisk\nsudo testdisk\n\nHere's a full thread showing how somebody restored their EXT4 partition (including some complications): http://ubuntuforums.org/showthread.php?t=1376383\n", "Q: What DLNA server to choose? What DLNA server program should I choose and how do I set it up?\nIt is an absolute requirement that it doesn't take a lot of resources since it will be running on a 500 MHz machine.\nThere seems to be quite a few server programs and I don't have any experience with these userfriendly auto-detecet protocols/services.\nBtw, the server doesn't have a GUI...\n\nA: I'm a fan of ushare myself: GeeXboX uShare UPnP A/V Media Server HomePage\n\nA: I'm pretty pleased with PS3MediaServer on Ubuntu 11.10. Ubuntu has a help page for it at Ubuntu Documentation - Ps3MediaServer. Installation is easy, adding files is easy and it works great. Don't let the name fool you, you don't have to have a PS3 to enjoy this. And best of all, it's all handled through a graphical GUI.\n\nA: I've switched from MediaTomb (which has been crashing all over the place) to MiniDLNA.\nIt's lighter, no interface at all and hasn't crashed on me yet. Scans fast too.\n\n\nA: MediaTomb? \nQuite popular and only a web interface to speak of. It also does on-the-fly transcoding but you may need to disable that or your little 500mhz server might explode.\n\nEdit\nMediaTomb is unsupported since 2017-04-03.\nThey direct users to Gerbera, which is built upon MediaTomb. \n\nA: Plex recently appeared in the Ubuntu Software Center. I have used their server for two years and recommend it.\n\nA: Go for Rygel. It is easy to use and does transcoding on the fly (read you can play your videos on your TV if your TV can decode them).\n\nA: A few more alternatives can be found in my answer to minidlna and samsung tv file format doesn't support, e.g. Rygel (in the repos), Mediatomb, Serviio, PS3Mediaserver...\n", "Q: How can I resolve the disabled Bluetooth on resume/power issue on Lenovo laptops? After you install Ubuntu on a Lenovo laptop the Bluetooth will be disabled after reboot or resume. \nThe only workaround for this issue is to load factory default from the BIOS but this is not something you want to do each time you reboot Ubuntu on a dual-boot machine.\nThe problem was reported several times over time on Lenovo support forum but nobody from them bothered to take a look on this. Examples:\n\n\n*\n\n*http://forums.lenovo.com/t5/IdeaPad-Y-U-B-and-Z-series/How-to-turn-on-bluetooth-on-ubuntu-08-10/m-p/99839\n\n*http://forums.lenovo.com/t5/T400-T500-and-newer-T-series/T400-bluetooth-doesn-t-turn-on-after-wake-up-from-standby-mode/m-p/197984\n\nA: I have a Lenovo T410 with Ubuntu 10.10.  I just tested it and my bluetooth starts successfully on a reboot and on resuming from standby.  For reference, here's what my bluetooth adapter is called in the lsusb output:\n0a5c:217f Broadcom Corp. Bluetooth Controller\n", "Q: How to install php-gtk? I can't find it in the repositories.I am using Maverick.\n\nA: Phoronix have a deb available. It's for Lucid but they claim it works with Maverick.\nOtherwise, there are a few other debs floating around the internet.. And then there's compiling it yourself.\n\nA: There's a comprehensive guide I wrote here. The main culprit for most issues is the necessary dependencies and a libtool.m4 problem -- but it's all detailed in that thread. Works fine with Ubuntu 12.04.\n\nA: Maybe nobody has packaged it so far. It seems you have to compile it for yourself. There is some documentation how to install it on Linux. \n", "Q: Native, FOSS GUI prototyping tools? As part of my job as a web developer, I spend an amount of time doing UI prototypes to show the client. It's a pain in the behind but sometimes it has to be done.\nI've seen Shuttleworth (and the design team) pump out images like this:\n\nThat's made by something called Balsamiq Mockups... Something that balances on top of Adobe Air (yack!) and costs $79.\nI've tried it but it kept falling over. I think it had something to do with Air not the app itself. My point is if I'm paying out for something, I want it to be native.\n\nA: I also recommend use of Inkscape for mockups.  You can get a few stock widgets from www.openclipart.org (someone should upload more!).\nWhere I find it very handy is for marking up an existing UI...  Take a screenshot of the app, insert into Inkscape and put it on a locked layer, then do your drawing on a layer on top of that to show whatever changes you need to show.\n\nA: For reasons I don't begin to understand, its authors have written it as a Firefox plugin, but Pencil is a great FOSS prototyping tool. Like Balsamiq Mockups, it comes with a massive number of prefabricated components that allow you to quickly throw together a demo screen.  Also like Balsamiq, you can have multiple pages in a sketch, and link between them, allowing your programmers and designers to \"click\" certain buttons, and get a feel for what should happen when that occurs.\nUnlike Balsamiq, its default mock widget set looks like real widgets, which I get concerned causes programmers to slavishly imitate the mockup they see on screen. Thankfully, a sketch widget template has been distributed with Pencil for awhile now. Also unlike Balsamiq—and hopefully not surprising for a Firefox add-on—Pencil exports its sketches to HTML, not Flash/Flex.\nI know Pencil looks weird because it's a Firefox extension, but it actually works very well, and is easy-to-use. I am not ideologically attached to FOSS and don't mind spending $80 for great software, so I'll be honest and say that I use Balsamiq over Pencil. I find Balsamiq's general workflow and ease-of-use superior to Pencil. But Pencil's still a great tool. If you're looking for a FOSS prototyper, I think you'd have a hard time doing better. Launch Firefox and go check it out.\n\nA: Personally I like doing web-ui prototyping in Inkscape (vector graphic drawing program), it is fairly simple to use and you can reuse most of the mockup when you are going to make the final product.\n\nA: Try Glade Interface Designer, a GTK/Gnome interface designer, usually used for real applications, but could equally be used for prototypes.\n\nA: I've used Mockingbird before for a very small project.  http://gomockingbird.com  It's a web-based client that allows collaboration.  It apparently is going to leave beta and stop being free in a few days though.  \n", "Q: Lost LXDE menus after replacing /home I am trying Lubuntu on an old laptop.  I have before and after the install I had two partitions (+swap) mounting on / and on /home.  When I did the Lubuntu install I told it to ignore the /home partition.  After the Lubuntu install I logged in and everything appeared OK.\nI mounted the /home partition as /hold.old.  Then I copied all the files from /home to /home.old.  Then for each user I chown'ed the stuff in /home.old.  Then I edited /etc/fstab to mount the /home partition.  Then I renamed /home.  Then I rebooted.\nAll my old files are where I expected them in the /home filesystem.  But my LXDE menu system is messed up.  Instead of the full menu system I only have terminal and logout.  I thought that most of the menu system lived in /usr/share.  But, apparently LXDE has some menu stuff in /home that I did not get copied over correctly.\nIs there a quick way to restore the default LXDE menu system?\nCan you point some documentation that would be good for learning the sysadmin level workings of LXDE?\n\nA: Just show all the hidden files using CTRL+H and then copy EVERYTHING. The configuration will be in /home somewhere. In a hidden file there could be alot of configurations. Especially in .config .\n", "Q: How to access a Windows shared drive/folder from Ubuntu? Specifically, what are the login credentials I need to provide?\nDetails: The machine I want to access is running Windows 7, and I'm sure the folder sharing is working as other Windows machines can access it. In Ubuntu, I can go to Places -> Network and i see the machine there and open it, when I try to view the shared folder it will prompt me for Username/Domain/Password.\nAre these credentials supposed to be my login details on the other machine? My account there does not have a password though, should I leave it blank? I'm also not clear what \"Domain\" needs to be.\n\nA: Your login should indeed be your login on the remote machine.\nThere is no way to allow general access to your home folder over the network without a password.  If you want full access to your home folder, you must give your account a password. You can leave automatic login turned on if you simply don't want to type a password at startup.\nYou can, however, allow access to the Public directory in your home directory without requiring login. To do that, go to Network and Sharing Center⟶Change advanced sharing settings, turn on Public folder sharing, and turn off Password protected sharing (located under the Advanced Sharing Options section near the bottom).\nThe domain, if this isn't on an ActiveDirectory domain (which seems likely, since your account has no password), should be either blank or the word WORKGROUP in all caps.\n\nA: Type\nsudo smbpasswd -a \"username\"\n\nwhere \"username\" is the login username,\nex:\nsudo smbpasswd -a abc\n\nyou will be asked for a password.\nThis will create the login id and the password that you need inorder to open the file on the network.\n\nA: Wild guess... but have you tried the user guest, invitado or whatever is the name of the windows guest user in your language?.\n", "Q: How do I mount an ISO? I was hoping to know if Ubuntu comes with a standard way of mounting ISOs. I looked around online and found a bunch of scripts that can do it. \nThis to me seems like core functionality, is it offered by default in Ubuntu. If not where is the best and simplest mounter for ISOs.\n\nA: I always used Gmount-iso to mount ISO files.\napt-get install -y gmountiso\n\nA: An alternative for quickly grabbing files off of an iso to DreadPirateJeff's solution of loopback mounting isos is the bsdtar(1) package .\nsudo apt-get install bsdtar\n\nFor example, to grab the specific build information off of the Ubuntu 10.10 i386 livecd, which is contained in the /.disk/info file on the iso and dump it to STDOUT, you'd do\nbsdtar -x -O -f ubuntu-10.10-desktop-i386.iso  .disk/info\nwhich would return\nUbuntu 10.10 \"Maverick Meerkat\" - Release i386 (20101007)\nGiven that it's a variant tar utility, you can of course extract multiple files to disk. The advantage is that you can do all the above without root privileges, unlike loopback mounts.\n(Another alternative is the isoinfo(1) utility from the genisoimage package ; however, it's slightly less straightforward to use than bsdtar.)\n\nA: Old question, but im amazed no one mentioned the easiest method:\nOpen Nautilus and... double-click the .ISO file!\nNo need of terminal, or installing any app or script. Its default Ubuntu behaviour since (at least) 10.04 Lucid.\n\nWorks only with \"regular\" ISO images (single track, no multi-data, no sub channels), but those are the vast majority of images. For the special cases, I use AcetoneISO (already mentioned in another answer)\nThe local mount point nautilus uses for such mounts is located under ~/.gvfs, a hidden directory under your Home folder (you may have to hit Ctrl+H to find it when browsing in Nautilus or using Open/Save File dialogs). In the above example, the mount point is\n/home/rodrigo/.gvfs/MB SUPPORT CD.ISO/\n\nand it's thus accessible by any program, terminal, script, etc.\n\nA: An alternative to archive-mounter is Furius ISO Mount which not only mounts ISOs but can \n\n\n*\n\n*check checksums, \n\n*create checksums \n\n*call nautilus for file browsing \n\n*call brassero to burn to CD.\n\n\napt:furiusisomount\n\nA: I think the easiest tool for mounting ISOs is AcetoneISO, it is very similar to DaemonTools for Windows. Give it a try :)\n\nA: If you prefer to keep it old school, in a terminal:\nsudo mount /path/to/iso /path/to/mountpoint -o loop\n\nThis, of course, will not allow you to edit the ISO as the other mentioned tools will, but if you just need to quickly get into one and pull a few files from it, works like a charm :-)\n\nA: Brasero which comes with Ubuntu is able to create and open (to manipulate) ISOs. If you're looking for a way to mount an ISO so it's contents are available like a \"drive\" you may want to use simply Right Click the ISO and choose \"Open With Archive Mounter\" which will mount the ISO as a drive and you should see it listed under the Places menu.\nThis all assumes you are using 10.04\n", "Q: Printer sharing and Ubuntu I have a printer plugged it into my Ubuntu desktop machine. I want to access it from Windows 7 on my laptop. Is this possible? If yes, how can I do this?\n\nA: Yup. Quite simple too. IMO this is quicker than using cups' web gui.\n\n\n*\n\n*Make cups accept connections from other computers. \nsudo nano /etc/cups/cupsd.conf\n\nAnd then replace Listen localhost:631 with Listen *:631. Save and exit (control+x, y, return). \nNote: If this computer ever goes out into the wild, where it's not hidden behind a router, it might be worth specifying an IP address instead of wildcarding. If it sits behind a protected router all the time, you don't need to worry about it.\nNote 2: If you have a firewall running on your computer (eg ufw, firestarter) be sure to allow connections on port 631 through.\n\n*Restart cups:\nsudo /etc/init.d/cupsys restart\n\n\n*From the Windows computer, start the Add a printer wizard (in Control Panel > Printers), select network printer and when you finally get around to the part where you enter an address, stick something like this in:\nhttp://your_ubuntu_ip:631/printers/whatever_your_printer_is_called\n\nYou then just install the Windows drivers for it and bish, bash, bong your're done.\nIf you don't know the name (to replace whatever_your_printer_is_called), take a look at cups http://localhost:631 and see what the name is for the printer.\n\nA: Yes, It is possible.\nPlease look at Network Printing With Ubuntu.\n", "Q: How can I install Steam? How can I install and run Steam on Ubuntu?\n\nA: The easiest way to run Steam on Ubuntu is definitely Crossover Games. CX Games supports a lot of games like Starcraft II, Civilization V, Left4Dead and so on. Furthermore there is professional support you can contact if you run into problems. Try the trial version!\n\nA: Steam is now released for Ubuntu and there's no need to run Wine or any other thing to get it to work. \nRun\nsudo apt-get install steam\n\nOr Install it with this button:  \n\nThis offers the easiest method for installing Steam. After clicking the orange button you may not have Ubuntu Software Centre configured to install .apk's. To get Ubuntu Software Centre to show Steam from this link browse to software-centre which is located at /usr/bin/software-centre when prompted after clicking on the orange button.\nWhen installing the \"buy\" button is not asking for payment to be able to install the Steam for Linux client as it is only indicating you need to buy games in order to use the client for playing games or using apps once the client is installed.\nWhich means if you have already Steam Play or Linux games in your Steam library there is no cost at all in order to be able to use the Steam for Linux client to play games as it possible to sign in to Linux client with the same account details as with Windows client; just not both at same time.\nAlso consider upgrading you video drivers as shown in this article step-by-step, doing so will allow you to get the best performance on your graphics card. The article covers the drivers installation for the NVIDIA, AMD/ATI and Intel graphics cards.\n\n\n*\n\n*Steam Client now available in Ubuntu Software Center\n\n*store.steampowered.com: browse Linux games\n\nA: I just install Steam on 10.10 this morning with wine and it was super easy. That said the actual games are another story. Just download the .msi file from steam and use the terminal to install it.\n\nA: A few hours ago the Steam Beta client for Linux has arrived. It can be found here. Everyone can install it, but only beta access users can use it at te moment.\nEdit\nA workaround to use Steam without beta access has been found. \nsteam steam://open/friends\n\nEDIT\nSteam is now in open beta.\nEDIT\nSteam is now in the Ubuntu Software Centre.\n\nA: In addition to Marco's great answer, I think it is relevant to argue that the best method to run Steam on Ubuntu might be by running it as a standalone session. Depending on your preferences, it may not be as convenient as running Steam for Linux from a logged on Unity session, but it will probably spare you valuable resources so you can have a smoother gaming experience.\npopey and Jorge Castro adress the issue here, but the gist of it is that this standalone session is achievable through a third-party app called steam-login, which can be easily installed running the following in a terminal:\nsudo add-apt-repository ppa:thor27-gmail/steam-desktop \nsudo apt-get update \nsudo apt-get install steam-login\n\n\nA: I recommend you to use plain Wine without PlayOnLinux. Winetricks is helpful, however.\nSteam Games on Linux website has detailed information about which games can be played successfully, and what you have to do for that.\n\n\n*\n\n*First of all, make sure you have installed proprietary graphics drivers if they are available.\n\n*Install the latest Wine.  \n\n*Configure Wine (look at STEAM + WINE CONFIGURATION section)  \n\n*Go to Winetricks and follow these steps:\n\n*\n\n*Select the default wineprefix OK\n\n*Install a Windows DLL or component OK\n\n*It is important to mark d3dx9 here. Optional packages that may be needed for some games: d3dx10, vb6run, vcrun2005, vcrun2008, vcrun2010, physx. OK\n\n*Install a font OK\n\n*Mark corefonts and tahoma. OK\n\n\n*Next, download Steam and go through the installer.  \n\n*When you create an account or just log in, you should have no trouble downloading your games through Steam as usual and playing them.  \n\n*Make sure to change video settings in the game to low ASAP (don't miss the \"advanced\" video settings for Valve's games). Windowed mode is mostly better. It is good to restart the game after this.\n\n\nA: An easy way to install Steam is to use PlayOnLinux. The advantage of using this approach (as opposed to using plain Wine or the native Linux version) is that it allows you to download and install Windows games---which otherwise wouldn't work natively on Linux---that are already linked to your Steam account. PlayOnLinux also allows you to easily customize your \"Windows\" installation, such as installing required dependencies or tweaking the registry.\n\nA: steam-native-runtime\nTry installing by using the steam-native-runtime package available from an Arch repository ('i686' & 'x86_64'). This package includes needed libraries that the official [steam_latest.deb][2] archive does not. For further reading, check the steam-native-runtime wiki, Steam/Troubleshooting.\n\nsteam_latest.deb (official archive)\n⇝ 1] Download[↴] the steam_latest.deb archive from Steam.\n⇝ 2] Open Terminal & enter these commands:\ncd ~/Downloads\nsudo apt-get install python-apt\nsudo dpkg -i steam_latest.deb\n\n⇝ 3] Now, open the newly added Steam launcher, or enter command steam.  You'll need to accept the Terms & Conditions the first time you launch it.\n", "Q: What is the difference between Network Manager and 'ifconfig' 'ifup', etc? Ubuntu seems to provide at least two network \"toolsets\" (for lack of a better term). I'm running into conflicts between these two.\n\n\n*\n\n*Network Manager\n\n*Something which is more like the traditional network tools (e.g. ifconfig, 'ifup', /etc/network/interfaces\nI am often running into conflicts between these different sets of tools. For example, I'm running Ubuntu Desktop at home and I'm using software like KVM/libvirt which recommends that I disable Network Manager, but disabling Network Manager causes other things to break.\nWhat is the difference between Network Manager and the traditional network tools? Can these two suites run side-by-side or must I stick with one or the other? Is there a document which summarizes the difference between these different tools? I have been unable to find one.\n(Forgive the vagueness of this question. I've searched and searched for an answer, but I have only found many vague answers which don't seem relevant to Ubuntu 10.04/Lucid, and I may not fully understand the purpose of NetworkManager. However, this seems to be a frequently asked question. If you have advice for clarifying this question, please post a comment.)\n\nA: On a typical Debian-based distribution you have two command-line utilities used to configure network interfaces: the deprecated ifconfig from net-tools and the newer ip from iproute2.\nHowever these two utilities directly configure the kernel and do not persist your config, if you reboot your machine you will need to reconfigure your interfaces again.\nYou have three major packages available for that purpose:\n\n*\n\n*ifupdown\n\n*NetworkManager\n\n*systemd and its daemon systemd-networkd\nIn general, you should choose one and stick to it, even if ifupdown works well with NetworkManager it can still creates unexpected configuration issues.\nifupdown\nQuite deprecated but reliable, you might encounter it on many older systems. The config is stored in /etc/network/interfaces and managed by the networking.service daemon which is a wrapper around the ifup and ifdown commands which are also wrappers themselves around ifconfig (or ip for ifupdown2).\nRead the man at ifupdown.\nNetworkManager\nUsually included with desktop distributions since many graphical front-ends are available, the config is stored in /etc/NetworkManager and managed by the NetworkManager.service daemon.\nYou can manage the config with the included nmcli or nmtui utilities.\nRead the man at NetworkManager.\nsystemd-networkd\nUsually used on server distributions and the official successor to ifupdown as it is included within systemd, the config is stored in /etc/systemd/network and managed by the systemd-networkd.service daemon.\nRead the man at systemd-networkd.\ndhclient\nAlthough not a daemon, dhclient from isc-dhcp-client is nonetheless a very important package and often required on desktop distributions as you often need to obtain a IPv4 from a DHCP server.\nHopefully, as IPv6 (which uses SLAAC) is slowly being adopted, this will probably change in a near or distant future.\n\nA: NetworkManager and ifconfig are not (by default) compatible (NetworkManager won't configure interfaces listed in /etc/network/interfaces). NetworkManager is a sort of settings daemon that makes sure that multiple users can edit network connections, this is very smart in a desktop environment (especially on laptops that might move around between different wireless networks). Basically NetworkManager is a frontend to iproute, dhclient, wpa_supplicant and ppp.\nifconfig is a general tool for configuring network interfaces, you can for example do like this:\nifconfig eth1 10.0.0.1 netmask 255.0.0.0 hw ether 10:10:10:10:10:10\nifconfig eth1 down\n\nto set your IP, netmask and MAC address of eth1, and then down (disable/turn off) your interface. ifconfig doesn't read any config files and does only exactly what it is told.\nifup and ifdown are helper programs that use ifconfig to configure a network interface in accordance to /etc/network/interfaces this will make sure that if there are any up, down, pre-up, pre-down, post-up, post-down scripts that need to be run they will be.\nOk, then there is wpa_supplicant and dhclient. dhclient is a DHCP client - ifup will use this if a network interface is configured for DHCP, as will NetworkManager. wpa_supplicant is a tool for configuring encryption on wireless networks.\nMost of these tools have man pages, for instance the interfaces-file have it's own manpage that describe the format of that config file.\nman interfaces\nman ifconfig\nman ifup\n\nSo that being said i would recommend that you remove (or disable) NetworkManager, I don't think that any thing will break from removing NetworkManager except the gui tools for setting up network. If you want to configure wireless without NetworkManager you might want to look at this.\n\nA: These toolsets are complementary, not mutually exclussive.  \nFWIW, ifconfig is just a tool among other *config tools which are used to configure network interfaces.\nThe ifup(8) and ifdown(8) tools are one layer above the *config tools. You can think of them as helper tools.\nLikewise, NetworkManager is a level above the ifup(8) and ifdown(8) tools. For lack of a better term, NetworkManager is able to orchestrate the tools(ets) from the levels below in order to acomplish higher level tasks like Internet Connection Sharing with additional ease compared to just using the tools from the levels below.\n\nA: Network Manager is a GUI program used when dealing with Ubuntu as a workstation OS installed on your desktop/laptop. \nThe ifconfig-type utilities are command-line based and are used when dealing with Ubuntu as a server OS, when you don't have a graphical interface available to you (for example, when you boot up an Amazon EC2 instance based on Ubuntu). They are typically used over an ssh connection.\n\nA: If you remove network manager I assume you need to configure /etc/network/interface to make interfaces work.\n", "Q: Login fail with low graphics then crash? I was using Transmission to download some stuff, when I got a notification that there was only 800 MB of free space left. \nI soon rebooted, only to find out, that i could not login again. I would get an error stating, that the default configuration had changed for \"gnome-power-manager\" and to contact my system-administrator, though i am the sysadmin.  Every time i tried to login it would fail and the whole thing was in low graphics mode.  \nSo my question is if there is a way to fix this?\n\nA: Sounds like your HD is too full for its own good. You can break in through recovery mode and delete a few things in a few simple steps:\n\n\n*\n\n*Hold the left shift key when your\nBIOS screen shows up. Keep holding\nit until you're given a GRUB menu\nscreen.\n\n*Select the first recovery mode option.\n\n*When given the choice, select the root console option.\n\n*You're now in single user text mode. You can move around and (provided your user files aren't encrypted) you can delete, add/remove packages, etc. This should give you enough time to delete a few non-essential things (I'd free up a couple of gigabytes to be sure). \nYou can also always move them off to a USB disk but I'm not sure if they auto-mount in single user mode so you might have to do it yourself.\n\nA: Once logged into a terminal, as per qbi's post, you can clear out your package cache to free up some space:\nsudo apt-get clean\nWhen apt downloads packages it caches copies of them in /var/cache/apt/, this command will clean out the package cache.\nYou can use du -h /var/cache/apt before and after clearing the cache, to see how much space you have left before and after.\nYou can also run df -h to see how much space you have on all mounted devices, ie your hard drives.\n\nA: From your question it looks like your hard drive has no (or too less) free space. Usually this leads to some strange behavior in some software. You can try to go a virtual terminal. Press Ctrl+Alt+F1 and enter your username and password. Now it should open a shell. If you are familiar with it, you can browse around, look for large files and move them away or delete them.\nIf it doesn't work or you're unfamiliar with a shell, you can also use some live CD. I would suggest Knoppix. You download the image, burn it on CD and start the CD. It starts some Linux environment with a graphical mode. There you can browse your hard drive and also move away/delete unneeded files. If there is more free space your problems will probably go away.\n", "Q: Why do some packages disappear from the repositories? I needed to install a program (GSAS & EXPGUI) that depends on the libg2c0 library. This library was in the repositories up to Ubuntu Jaunty (9.04), and then it was removed. \nThe solution is to download the Jaunty package, and then sudo dpkg --force-depends -i libg2c0_3.4.6-8ubuntu2_amd64.deb. If found this solution not to be in the spirit of Ubuntu (is there a word for that, like Pythonic is to Python?)\nIn general, what are the reasons for removing a given package from newer versions?\nIs there a better way to manage dependencies to no longer supported packages?\n\nA: Packages are removed from the repository in newer releases for different reasons. \nOften package names have a reference to its version. In this case, a newer version might exist. In this case the dependency for your package might need to be updated. However, this is rather a replacement than a pure dropping of packages.\nPackages are often dropped when there is no active development anymore, and they are not in a state than is valuable. It makes no sense to keep packages with critical bugs which are not fixed.\nAnother reason might be that no maintainer works on the package anymore. This might even be the case in Debian, since a lot of Ubuntu's packages are synced from Debian. This is a matter of interest. If the current maintainer has no time or passion anymore, the package is put on a list of orphaned packages. This allows the community to look if someone else will step up. If not, it will be dropped after some time since it is assumed that nobody has interest in the package anymore. \nIn your particular case, the GNU Fortran 77 was replaced by the GNU Fortran 95 compiler. Hence the runtime libraries have been dropped too. I am not sure if that helps you, but your package should be made to run on the new Fortran compiler (which should be possible if it is open source). Then it will use the new library which is available.\n", "Q: How to use pressure sensitive drawing in a Linux-based browser? Wacom provides a web browser plugin that allows pressure sensitive drawing with their and other PenAPI compatible tablets in a browser. Unfortunately their plugin only supports Windows and Mac OS X. Is there a way to get this functionality under Ubuntu Linux?\nCurrently, I can already use pressure-sensitive drawing in some Linux applications like GIMP and Inkscape, just not in a web browser.\nA browser based application that would benefit from pressure sensitive drawing is for example DeviantArt's Muro, a HTML5 based drawing application. Under Windows and Mac OS X, Muro supports pressure sensitivity when the Wacom-supplied browser plugin is installed.\n\nA: Short answer is no.\nIn order to provide pressure sensitivity, the browser (or a plugin) would have to hook into the same code (XInput) that drawing applications like Inkscape or the GIMP use. Browsers, like most desktop applications, generally leave input details to the operating system so they only see mouse or keyboard events.\nI see that the Muro plugin is a proprietary Wacom application, so I wouldn't expect to see it ported any time soon. However you could open bugs requesting pressure sensitivity in conjunction with HTML5 canvas for the various browsers. As multitouch screens are becoming more important it is increasingly likely someone has been working on at least a plugin that might provide such information.\n\nA: Hello from the future world of 2022!\nThe PointerEvent.pressure property is supported in major browsers, and allows web applications to utilize pressure-sensitive input devices.\nIn my experience (on an Ubuntu 20.04-derived distro) this worked out-of-the-box with Chromium; that is, Google Chrome, less the proprietary Google bits. I used the Flatpak version; your mileage may vary with the Snap or .deb package.\nWith Firefox, I found I had to set MOZ_USE_XINPUT2=1 in the environment in order to get pressure sensitivity. I think this is a regression; follow this bug for details. There is also an about:config setting called dom.w3c_pointer_events.dispatch_by_pointer_messages that might come into play; see here for details.\nYou can test if this works for you at https://tldraw.com or https://pressurejs.com.\n\nA: It's 2015 now and two plugins that enable pressure-sensitive input in Linux browsers have become available meanwhile:\n\n*\n\n*WacomWebPlugin. Works in both Firefox and Chrome, but has to be compiled. (I could not find pre-compiled Ubuntu packages.) Did not test this one, but it seems the more advanced one, and source code is available.\n\n\n*Mikro's plugin. There is also a discussion thread for it. Source offered, but not available for download. Development seems to have stopped. But it works: I just tested it on Firefox 35.0 64bit, using Muro.\nFor installing plugins manually in recent versions of Firefox under Ubuntu, refer to this answer.\n\nA: openCanvas pressure sensitivity works under Wine, so you may try installing firefox under wine and trying it that way.\nI think they've fixed the problem with the Y-axis being inverted, so that may be a way to get it working.\nGood luck!\n(also, for other drawing applications you may want to try mypaint (my fave) and drawpile)\n", "Q: How can I suspend/hibernate from command line? How can I suspend or hibernate my laptop using command line, without installing additional software?\n\nA: Adam Paetznick's dbus-send answer didn't work as purported for me on lucid; the machine woke up unlocked, even though the gnome-power-manager is set to lock the screen on wake-up.\nI want the screen to be locked at wake-up, and found that the following does that:\n$ gnome-screensaver-command --lock && pmi action hibernate\n\nI imagine this does not depend on the gnome configuration, but I haven't tested that.\n\nA: English\nIf you want your computer to suspend in one hour because you want to go to bed listening to your favorite radio station, open terminal and type:\nsudo bash -c \"sleep 1h; pm-suspend\"\n\nand your computer will fall asleep in 1 hour. When you awake, it will have kept your open images and all your stuff.\nYou can replace 1h by what you want: h for hours, m for minutes, s for seconds, d for days.\nGood night!\nFrançais\nSi vous voulez juste que votre ordinateur se mette en veille dans une heure parce que vous voulez vous endormir en ecoutant votre radio préférée, ouvrez Terminal et tapez :\nsudo bash -c \"sleep 1h; pm-suspend\"\n\net votre ordinateur s'endormira dans une heure. Quand vous vous réveillerez, il aura conservé en mémoire vos applications ouvertes.\nVous pouvez remplacer 1h par ce que vous voulez: h pour les heures, m pour les minutes, s pour les secondes, d pour les jours.\nBonne nuit!\nEspañol\nSi quieres suspender tu computadora en una hora porque quieres ir a dormir escuchando tu estación de radio favorita, tan solo abre el terminal y escribe:\nsudo bash -c \"sleep 1h; pm-suspend\"\n\ny tu computadora se quedará dormida en 1 hora. Cuando despiertes, allí habrán quedado abiertas tus imágenes y todas tus cosas.\nPuedes reemplazar 1h por lo que desees: h para horas, m para minutos, s para segundos, d para días.\n¡Buenas noches!\n\nA: Traditionally ubuntu supported a fairly blunt method of suspend and hibernate. Neither would integrate well with other apps and sometimes not even work on some machines. This new method doesn't require root and notifies all applications listening for power events.\nSystemd Method\nStarting with Ubuntu 16.04, systemctl call must be used (See Suspend command in Ubuntu 16.04)\nsystemctl suspend\n\nand\nsystemctl hibernate\n\nNew Method (obsolete)\nObsolete circa Ubuntu 16.04; use systemctl instead, as above.\nSee the answer here on this page from Adam Paetznick regarding the use of dbus. Ideally you would create a ~/bin/suspend shortcut/script that makes the use of this action easy.\nFor use over ssh, you should modify policykit rules as outlined by Peter V. Mørch\nOld Method\nAccording to the Ubuntu Forum you can use the following commands:\npmi action suspend\n\nand\npmi action hibernate\n\nThis requires that you install the powermanagement-interface package (not tested).\nsudo apt-get install powermanagement-interface\nI have also found the commands sudo pm-suspend and sudo pm-hibernate to work on my netbook.\n\nA: New interface\n…which works in 15.10 Wily, and possibly Utopic and Vivid.\ndbus-send --print-reply --system                         \\\n    --dest=org.freedesktop.login1                        \\\n    /org/freedesktop/login1                              \\\n    org.freedesktop.login1.Manager.Suspend boolean:true\n\nHelpfully this doesn't require sudo, unlike the pm-suspend command.\n\nA: To get Hibernation:\nsudo pm-hibernate\n\nTo get Suspend:\nsudo pm-suspend\n\n\nA: You can use the file /sys/power/state to do this. First find out what states are supported:\nuser@linux:_> cat /sys/power/state\nstandby mem disk\n\nroot@linux:~> echo -n mem > /sys/power/state  # suspend to ram\nroot@linux:~> echo -n disk > /sys/power/state  # suspend to disk\n\nor via dbus:\n\n    # Suspend\n    dbus-send --session --dest=org.gnome.PowerManager \\\n      --type=method_call --print-reply --reply-timeout=2000 \\ \n      /org/gnome/PowerManager org.gnome.PowerManager.Suspend\n\n    #Hibernate\n    dbus-send --session --dest=org.gnome.PowerManager \\\n      --type=method_call --print-reply --reply-timeout=2000 \\ \n      /org/gnome/PowerManager org.gnome.PowerManager.Hibernate\n\nAccording to this entry in launchpad the above interface was removed. So it would not work anymore in Ubuntu.\n\nA: The gnome-friendly way is to use dbus.\ndbus-send --system --print-reply \\\n    --dest=\"org.freedesktop.UPower\" \\\n    /org/freedesktop/UPower \\\n    org.freedesktop.UPower.Suspend\n\nThere are two advantages to this command over pm-suspend.\n\n\n*\n\n*It will lock your screen (upon resume) if you have that option selected in gnome.\n\n*It does not require root privilege, so it is easy to add it as a keyboard shortcut, for example.\nAs mentioned in the comments exchanging the Suspend in the last line to Hibernate creates a hibernate command:\ndbus-send --system --print-reply \\\n    --dest=\"org.freedesktop.UPower\" \\\n    /org/freedesktop/UPower \\\n    org.freedesktop.UPower.Hibernate\n\nIf the hibernation throws Error org.freedesktop.UPower.GeneralError: not authorized your user might not be allowed to hibernate. Edit or create /etc/polkit-1/localauthority/50-local.d/com.ubuntu.enable-hibernate.pkla so it contains the following section: (source)\n[Re-enable hibernate by default]\nIdentity=unix-user:*\nAction=org.freedesktop.upower.hibernate\nResultActive=yes\n\nThis was tested on UbuntuGnome 14.04.\nNote: This is basically the same as qbi's answer, but updated to work for newer versions of Ubuntu as well as including hibernate.\n\nA: since 15.04 systemD is the standard init system so there is a new command to be used:\nsystemctl suspend\n\n\nA: To suspend a system (14.04) from the command line (or keyboard shortcut) use:\ndbus-send --system --print-reply --dest=\"org.freedesktop.login1\" /org/freedesktop/login1 org.freedesktop.login1.Manager.Suspend boolean:true\n\nI found this out by playing around with gdbus which can list the interfaces available:\nTo list the services available on the bus:\ndbus-send --system --dest=org.freedesktop.DBus --type=method_call --print-reply /org/freedesktop/DBus org.freedesktop.DBus.ListNames\n\nTo find the methods:\ngdbus introspect --system --dest org.freedesktop.login1 --object-path /org/freedesktop/login1 --recurse\n\n\nA: Here's how to put a remote machine in standby over ssh:\n\nssh -t 192.168.1.4 'sudo nohup &>/dev/null bash -c \"(sleep 1; echo -n mem >/sys/power/state) &\"'\nx@192.168.1.4's password: \n[sudo] password for x: \nConnection to 192.168.1.4 closed.\n\n/sys/power/state works in Ubuntu 13.10. pmi gives Dbus error.\n\nA: Personally, I've been experimenting with the pmi method. However, when I tried this, I got an error message: Error org.freedesktop.DBus.Error.Spawn.ChildExited: Launch helper exited with unknown return code 1. However, there is a workaround in the 3rd comment of this bug report, which seems to have worked for me (I'm using Ubuntu 13.03).\n\nA: Update for those who, like me, still work on KDE/Ubuntu 14.04 systems. To lock use qdbus, and to suspend use dbus. Full command:\nqdbus org.freedesktop.ScreenSaver /ScreenSaver Lock && dbus-send --system --print-reply --dest=\"org.freedesktop.UPower\" /org/freedesktop/UPower org.freedesktop.UPower.Suspend\n\nTo hibernate, i.e. suspend to harddisk instead of RAM, replace 'Suspend' at the end of the command by 'Hibernate'.\nTo just lock the screen without suspending, xscreensaver-command -lock will work, IF you type only 1 hyphen for the '-lock' option, and only if the screensaver is running. Actually not a very useful command. Using i3lock is easier, but then you will not get a neat login dialog to get back to work, as you will when using qdbus.\n\nA: The following works for me on 16.04 (with Gnome desktop):\n\ngnome-screensaver-command --lock && compsleep\n\nI have also installed it as a custom keyboard shortcut via the Gnome settings panel as keys \"Shift-Super-X\".\n", "Q: What are the must-have apps to customize Ubuntu Look and Feel? Seeing that this is a big Ubuntu community, I have never looked at someone's Ubuntu desktop and thought \"that looks cool, I wish I had X. How did you do that?\"\nWhat are the must have add-ons for look and feel?\ne.g conky, tilda,  album art, emerald, docky etc... \n\nA: Ubuntu Tweak is bound to help you a bit. It makes basic tweaking REALLY easy.\n\nA: One trick is to look at the gconf settings for apps, such as the screensaver, nautilus, panels, etc.  Often there are tweakables in there that aren't exposed in the app's preferences settings.\nRun gconf-editor for a GUI interface to examine config settings, or if you prefer command-line tools use gconftool-2.\nFor instance, I make a script to customize a new Ubuntu install (I'm frequently installing/reinstalling and like to have the look and feel customized to my preferences automatically).  I use gconftool-2 to do all these customizations.  For example:\ngconftool-2 --set /desktop/gnome/session/idle_delay \\\n    --type int 30\ngconftool-2 --set /apps/gnome-screensaver/lock_enabled \\\n    --type Boolean FALSE\n\n\nA: Compiz\n\nA: For the latest Ubuntu 17.10, the GNOME Tweak Tool is a very helpful appllication to customize the desktop.\n", "Q: Why no ooVoo on ubuntu? The only reason I ever boot into Windows (7) is to use the popular video chat software ooVoo (website). It's useless under Wine and there seems to be no way to run it in Ubuntu except for some proprietary tools. Does anyone have any information on some alternatives to running it with Wine?\n\nA: Ekiga - free(gratis), free(libre)\nQuteCom - free(gratis), free(libre)\nSkype - free(gratis), non-free(libre)\nTo find this I searched 'voip', 'video chat' and 'softphone' (seperately) in the Ubuntu Software Centre (I already knew about Skype)\n\nA: After some Google Searching and some unsuccessful fiddling around with Wine  I decided to search for an alternative. That is When I found Tokbox! Tokbox is A FREE Cloud based alternative to ooVoo for Ubuntu Linux user has just been released. \nNo need for wine or a Virtual Box and thier is nothing to Download. Tokbox is a website that brings video conferencing into the cloud. What does than mean for you? It will work on any computer that has a web browser and Adobe Flash installed. That means that literally everyone out know can use it and the best part it works INSTANTLY. \nJust send them a link through facebook, twitter, Aim, Google Talk or even an email and they can connect this you in a matter of seconds. Take that ooVoo and their is no need for the recipient for the invitation to sign up either. Simply click the link and you are inside a live video conference. I will be installing a Web App using Google Chrome today on all the computers in the Internet cafe today and their will be a big shinny icon on everyones desktop pointing to the TokBox App on everyones home screen. For more information Visit http://www.tokbox.com/ Enjoy. \n\nA: I use Google hangouts... It's rock solid and stable (never crashes. Even if your internet stops working and then starts working again, you can re-enter the video conference call! Really cool) It's free, up to ten people in the same video call (I think it's ten) It's backed up by the bigegst company in the world... So why not give it a try. I am happy with it... Oh BTW... It has its own mobile app too! \n\nA: Empathy does video calls for some of the protocols it support, and maybe aMSN (install) Messenger® video chat, but it's not good to depend on a proprietary protocol that may change without warning.\n\nA: Pidgin now supports video calls over Jabber (XMPP)\n", "Q: how can I fix the (broken) icons in the notification area upon login? The icons in the notification area are sometimes broken upon login. This is always fixed if I close the session and login again.\nSee in this screenshot, the usual \"power\" button is replaced by a part of my user name. The whole username should be \"agustin\".\nThe problem is not just visual, if you click where the power button should be you get no functionality. Interestingly, if you click on the other button, and you move the cursor qith the arrow keys, you get the menu.\nI believe this problem is related to the nvidia propietary drivers, but I am not sure. Any ideas? Anyone had this problem like me?\n--\nAgustín\n\nA: Try\nkillall gnome-panel\nThe panel will disappear, but don't panic... it will reappear in a few seconds with all your icons in place.\n\nA: I just found this http://www.ubuntuupdates.org/ppas/27 \nI added the repository with sudo add-apt-repository ppa:ubuntu-x-swat/x-updates, updated aptitude and then got some new updates in update manager, mainly about nvida and the new driver.\nThis new driver solved my problems, I'm not sure on how stable or experimental these packages are, but they seem pretty good to me.\n--\nAgustín\n", "Q: How can I strip down Ubuntu? I'm trying to fix what I consider a bloated install of Ubuntu. When I install Ubuntu on a machine, I get things that I don't want - web browsers, office applications, media players, accessibility utilities, Ubuntu One, and so on. My goal is to create a way that I can have an install of Ubuntu that contains only the most minimal packages - the administrative tools and package manager, a GUI (my preference would be GNOME), a text editor, core drivers (video cards, network cards - wired and wireless, input devices), and anything else that I have to have to run a stable distribution. From there, I would like to pick and choose which packages I install to create my own customized system.\nAfter playing around with other distros like Arch and Slackware, like how they provide a barebones install by default. However, I get trapped in a \"configuration hell\" - right now, I tried moving away from Ubuntu and to Arch, but after spending 6 hours with it, I still don't have a usable system. It's half configured and I don't have any usable software packages to enable me to work.\nIs anything that can help me available? Either something like the OpenSUSE builder that lets you choose applications and packages for the CD, an advanced installation mode where I can choose the packages to install and which to ignore, or a guide on how to strip Ubuntu down to its bare bones?\nAnd I suppose a natural follow up to this is once I have a stripped down Ubuntu, will this affect updating at all? When Canonical releases the next version of Ubuntu, I don't want any bloatware reinstalled. And yes, most of the applications that come with Ubuntu, I simply don't use. Ever.\n\nA: Ubuntu has a mini.iso which is a totally stripped down version of ubuntu that you can use to build up yourself. It's about 28MB or so.\nAs of this reply the latest version is 12.04 Precise, so you can just replace the distro release name in the url to get the mini.iso for that release.\nFor 64bit: http://archive.ubuntu.com/ubuntu/dists/precise/main/installer-i386/current/images/netboot/mini.iso\nFor 32bit: http://archive.ubuntu.com/ubuntu/dists/precise/main/installer-i386/current/images/netboot/\nYou can then install your GUI/Desktop environment of choice using apt-get and so on with whatever packages you wish to install.\n\nA: Rather than stripping down, why not instead 'build up'?\nAs well as downloading Ubuntu JeOS (Just Enough OS), you can also find netboot images from the repository folders.\nhttp://archive.ubuntu.com/ubuntu/dists/lucid/main/installer-i386/current/images/netboot/\nUsing mini.iso is probably recommended, as you use uNetbootin to copy it onto a pendrive.\n\nA: Start from Ubuntu Server and build up. It uses the same repos as the desktop distribution and you can install various desktop configurations. \nI just suggest you stay away from the big metapackages like ubuntu-desktop or you'll end up will the full blown distro.\nIf you only want to strip down (rather than building up) you're going to have to remove ubuntu-desktop (which depends on loads of things) and convert all the automatically met dependencies to manually installed. If you don't aptitude will nuke them as it (amongst other tools) will automatically clean up \"obsolete\" packages -- those are packages that fulfil no dependency or user choice.\n\nA: *\n\n*Do a \"minimal\" install as many people suggested\n\n*Install your required packages with:\nsudo apt-get install --no-install-recommends package-name, where package-name is the package you want to install\n\n\nThe configuration requirements depends on which packages you select to install, keeping a minimal install depends on knowning \"minimal\" tools or rely on manual configuration.\nThe more user friendly configuration tools which make Ubuntu great for most people usually have an high number of dependencies.\n\nA: Install the Ubuntu Server and ssh in.  That is as stripped as it can possibly get.\n\nA: Here's what I did to remove unwanted default packages from a normal desktop install:\n\n\n*\n\n*Remove the ubuntu-desktop package. This doesn't actually remove any programs - it's just a meta-package that depends on the default packages. If you don't remove it you'll wind up with broken dependency errors.\n\n*Check out its dependencies in a package manager (I like to use aptitude). Uninstall the ones you don't want.\n\n\nI'm not sure how extensively you want to trim, but that should do it for the default GNOME apps. Upgrading has worked fine for me. If the new release includes new default packages you may need to install them manually if you want them - otherwise it seems to work okay.\n\nA: Use the Ubuntu Server media, and choose the option to build the minimal installation. People call this \"JeOS\", although I think the term \"JeOS\" may have been deprecated. The Ubuntu Server Guide says:\nWhile installing from the Server Edition ISO (pressing F4 on the first screen will allow you to pick \"Minimal installation\", which is the package selection equivalent to JeOS).\n\nA: I'm not sure exactly what you mean when you say \"bloatware\", but it sounds like you might be interested in Xubuntu - it is also a GTK-based distro, but designed to be very lightweight.  You can then install any apps or pieces you'd like on top of it as you would with the regular Ubuntu distro.\n\nA: Install Synaptic Package Manager ( sudo apt-get install synaptic ) and go through the 'Installed' list and remove what you dont want, the descriptions are at the side and that way you can really streamline your setup without having to build it up from scratch...\nAs always just be careful what you remove, although first thing I always get rid of is 'mono-runtime' and it's dependencies as well as 'thunderbird' since my e-mail is mainly web-based...\n\nA: You could use \napt-get remove \"package\"\n\nuntil all of the packages that you don't want are gone, then use remastersys to create a livecd\n", "Q: Is GParted a good tool for resizing an NTFS partition? I have a dual-boot setup with Ubuntu and Windows Vista. I need to shrink the partition that Vista is installed on. (It's an NTFS partition.) I tried using Vista's own disk manager, but it didn't work.\nI heard that GParted can resize NTFS partitions - is this true? Is it a safe tool for resizing partitions? Are there any potential issues I should be aware of if I use it?\n\nA: GParted works great for that. I used it to resize my Windows 7 partition without any problems at all. However, in order to avoid problems, you will want to uncheck the \"round to cylinders\" option when you resize the partition. That can cause booting problems for Windows 7 or Vista.\n\nA: I can only speak from personal experience, but I have used gparted on NTFS partions several times and never encountered a problem.\n\nA: Indeed - my first introduction to Linux systems was using a GParted 'image' to boot from and resize the my VMware Fusion virtual PC's hard drive. I've since used it maybe a dozen times for doing this, on different VMs, for XP and Win2k3 (both NTFS). No problems at all. \nIf you haven't done it before, just take your time and carefully read all the pop-up dialogs and messages before pressing 'Yes'. :-)\n\nA: gparted is a great partitioning tool - I have used it to resize FAT, NTFS, EXT[2..4] and haven't run into any issues as of yet. However - with all disk operations there is always the possibility of failure and that should always be weighed during resizing.\nMake sure you have nothing mounted to the drives you're attempting to resize, ensure that you have ample CPU and RAM to perform the operations. If you're on a Laptop make sure it's plugged in and that it won't suspend or hibernate while performing these operations. Lastly this can be time intensive - my last tip is, while gparted is running it may appear unresponsive or frozen. Just let it finish.\n", "Q: How to get more people involved in improving X.org for Ubuntu? In Ubuntu, X is one of the more critical pieces in the stack.  As such, we get a TON of questions and bug reports about it, probably about 100 times as many as we have manpower to handle.\nCanonical is hiring additional engineers to work on X which will help, but still there are many things that are outside the scope of what Canonical can do, so I feel it is really important to have a strong community involved in improving X in Ubuntu, particularly around getting all these massive amounts of bug reports answered, triaged, and (hopefully) solved.\nHowever, it's tough to find people to work on X or to convince people that it is worthwhile for them to invest their time in it.  How would you suggest going about encouraging people to get involved, who might not otherwise be thinking of working on X?\n\nA: Well like everything a lot of it is making it easy and accessible for people to find out about it. So from what I remember with bug triage originally there wasn't a lot of help coming from the community. Then when some wiki pages explaining the regular processes in triaging bugs and some bug days got a lot more community members involved. Also if you can start a regular activity for the community to do and offer help to those that try it you will get some interest.\nIf you need help with the activity you can email me and ill help with organizing it.\nSo my answer is making a wiki page with questions and commands for getting good bug triage info to get people involved in that. \nFor development its a big problem. Xorg and Kernel stuff require low level programming skills for most bug fixing and implementing features. So you have to target a specific group of programmers and get them interested. I dont have any suggestions here except ask around a bit and see who hangs out in #ubuntu-x and ask them if they can help. \n\nA: To complement what jbowtie said, I would add that, as a bug triager, I find X bugs very challenging to deal with, simply because X is a very complex beast. This is reflected in the complexity of the troubleshooting wiki page. What would definitely help is a sort of mentorship program for BugSquad members to learn how to deal with X bugs better. Maybe do a bug hug day around it? Or a hands-on training session in #ubuntu-classroom?\n\nA: The reason X doesn't get alot of work is that it requires an enormous amount of knowledge about how GPU's, memory etc.. work as well as familiarity with the X.org code base and to some extent kernel programming. It's not a trivial thing to get into and from a community perspective those who are interested in working on X or X drivers are probably already doing so. There is currently no motivation for a developer for developer to work on Xorg aside from personal interest. \nThe thing that the community has which X.org developers don't necessarily have, is access to a wide variety of hardware. Having people who are willing to spend the time to write 'good' bug reports and test drivers and parts of the Xorg stack before a release is probably going to help the engineers more than anything. \nCurrently there is an Xorg edgers repo which I use to test drivers on my stable system. It's pretty easy to roll back a single package after i'm done testing. However the only other way we can test is to either build X yourself or to install the edgers repository which builds from upstream. This does a wholesale X replacement as far as i can tell. This means it's an all or nothing approach to testing X. \nHaving a way to have 2 versions of X ( and fairly easily choose) which one you want to use would allow testers to not only test X , but subsequently get back to a working Xorg so they can submit the bug report. \n\nA: Speaking as a developer who is casually interested in X, here are my issues:\n\n\n*\n\n*I only have access to a handful of graphics cards and I suspect most people only have access to one. Thus I can't do much for the vast majority of bugs, which will always be on \"some other card\".\n\n*Unlike most packages, I can't trivially create a test environment for a new driver version; virtual machines have their own X drivers.\n\n*I can't easily update to the latest driver, test it out, then revert. This discourages experimentation (because if something goes wrong I might as well be bricked); it also hinders regression testing.\n\n*Last time I looked, successfully applying a patch, compiling and running X was difficult to do, stepped all over the package manager, required kernel modules to be patched as well, and was pretty much an irreversible step.\n\n*Nowadays, X drivers split their code between kernel, Mesa, udev (for settings and defaults), and userland drivers. Which means patches get split as well...\nSo I guess the answer is to make applying and reverting changes something that is handled by the package manager and easy to recover from when it breaks your system.\nAlso, a system like DKMS should be looked at for X drivers; if I could easily patch/compile/test/uninstall, say, the input driver for my touchscreen without having to rebuild the whole monolithic contraption (with its threat of making X completely unusable), you'd get more casual contribution and motivate me to look at triaging bugs and testing patches relating to that bit of hardware.\n\nA: It's difficult to improve X.org when many users use proprietary drivers that replace portions of the graphics stack and then look to the X.org team when a kernel upgrade / X.org upgrade breaks their driver install.\nA lot of the talk about \"I don't have all the cards available\"  is also valid.\nGraphics programming is fairly hard if you're not a good programmer. Debugging can be a real pain, especially if you can't see what's going on.\n", "Q: Can I use NetworkManager without a tray/dock/bar? I would like to use NetworkManager, but prefer a keyboard driven window manager that provides as much space on the screen as possible for my code.  I just hate that little strip of real estate \"trays\" take up on my screen.  I have tried running nm-* from the command line, but they seam to never work without a tray.\n\nA: According to http://live.gnome.org/NetworkManager/ReleaseProcess, version 0.8.1 provides a command line interface.\nYou can get it from https://launchpad.net/~network-manager/+archive/trunk, please note that I don't use it. I have no idea about it's stability.\nIn case of problems you can use the ppa-purge utility to get back to the official package.\n\nA: If you're willing to consider other network management applications besides Network Manager, you can install wicd, which has both an ncurses console interface as well as a regular graphical window interface (not a tray icon).\nBefore you install it, though, make sure you know how to revert to Network Manager (or manual networking), because installing wicd will remove Network Manager and vice versa.\n\nA: If you're running on Ubuntu Maverick (and thus have network-manager 0.8.1), try the nmcli tool:\n$ nmcli\n\nUsage: nmcli [OPTIONS] OBJECT { COMMAND | help }\n\nOPTIONS\n  -t[erse]                                   terse output\n  -p[retty]                                  pretty output\n  -m[ode] tabular|multiline                  output mode\n  -f[ields] <field1,field2,...>|all|common   specify fields to output\n  -e[scape] yes|no                           escape columns separators in values\n  -v[ersion]                                 show program version\n  -h[elp]                                    print this help\n\nOBJECT\n  nm          NetworkManager status\n  con         NetworkManager connections\n  dev         devices managed by NetworkManager\n\nAs above, it's just one file, and comes with NM 0.8.1.\n\nA: From wikipedia...\n\nNetworkManager has two components:\n\n*\n\n*a service which manages connections and reports network changes\n\n\n*a graphical desktop applet which allows the user to manipulate network connections. The\nnmcli applet provides similar functionality on the command line.\n\nIn fact, there are multiple tools available for replacing those nasty GUI dependent applets.  The two I am aware of are cnetworkmanager and network-manager-cli.\nNeither of them are currently packaged in Ubuntu, nore are they perticularly stable.  network-manager-cli looks more mature, but neither has seen any development for a while.\nnetwork-manager-cli has the added advantage of being single-file.  Just plop it in your bin and you're off to the races.\nAccording to joao-pinto's answer, NetworkManager 8.01 includes command line interfacec.  As of this moment, 8.01 doesn't ship with Ubuntu, so you'll have to grab it from Trunk.  Of course, soon enough, this whole woe will be deprecated and nobody will be complaining about anything.\n\nA: You can try  cnetworkmanager. It is easy to use. However, you should terminate nm-applet beforehand. On the other hand, network-manager-cli has no downloadable files in the projects site.\n\nA: If the issue is screen real estate rather than keyboard access, you can configure the tray to be a normal window instead of a screen hog. This requires cooperation from your window manager, but if it's \"keyboard driven\" it probably gives you enough control.\n", "Q: How can I add a separator to the Place sidebar in nautilus? I'd like to drag a few more folders to the places sidebar in nautilus, but want to group these new ones separately to the default folders (like Dropbox, Downloads and Documents). Is there a way to add a new separator to the list?\n\nA: This is not ideal but as far as I can see the only option you have short of filing a bug and chasing it through or writing and applying a patch.\n\n\n*\n\n*Open Nautilus\n\n*Browse to a directory that you don't want to bookmark, for example /bin\n\n*From the Bookmarks menu click on \"Add Bookmark\"\n\n*Then Right click on the bookmark for /bin and choose \"Rename...\"\n\n*Rename the bookmark to \"----------\"\n\n*Close Nautilus and open it again\n\n*you now have something that looks vaguely but not very much like a separator.\n\n\nEDIT: Looks like there is already a bug filed for this. Add your own point of view here.\n\nA: Hack on the code. \nAFAIK there's no gconf (or other) way to alter the places that aren't bookmarks.\n", "Q: Will plymouth allow for a nice boot experience with proprietary graphics drivers in future? The new graphical bootloader introduced in 10.04 (plymouth) looks amazing until I enable proprietary drivers for my video card. I then get a horrible flashy monster of a boot experience, which I can cope with if I have to, but I'm sure would be offputting for newer users.\nMy understanding is that plymouth depends on features that currently aren't available in the proprietary drivers. My question is, is this likely to change, or should I just get used to 'one or the other' (i.e. a nice boot experience or a nice desktop experience, but not both)? Can we expect to see plymouth playing nice with proprietary graphics drivers in future, or is this solely reliant on work from the proprietary manufacturers?\n\nA: You're asking a question that can only really be answered by the developers and decision makers at the companies making the hardware and the drivers.\nUltimately, it can be done but it requires some give on both sides of the fence. Nvidia, for example, claim they could do it but require some relaxation on the licensing of certain libraries.\nFrom AaronP (nvidia staff):\n\nThe last time I talked to the\n  developers working on it, they told me\n  that the hooks necessary to implement\n  kernel modesetting were exported to\n  GPL modules only, and therefore are\n  not usable by the NVIDIA driver. On\n  the other hand, that was a while ago\n  and I haven't looked at it since. If\n  the kernel developers are willing to\n  work with us to make kernel\n  modesetting possible for NVIDIA GPUs,\n  then we'll look into it.\n\nAnd again here:\n\nWell, let me rephrase that... it was\n  specifically designed to be\n  incompatible with non-GPL drivers, at\n  least according to Dave Airlie when I\n  asked him about it a couple of months\n  ago. I haven't actually looked at the\n  code, myself.\n\nThat was two years ago... So no, this hasn't been moving along particularly fast. I fear there's probably more luck in getting X loaded up faster and just using XSplash.\nBut when you look at it from Nvidia's point of view, what does this feature really add for their users? Would they benefit more from 400 man-hours going into Xorg development or 400 hours going into making the boot sequence more pretty?\n\nA: There is a fix for this:\n\n\n*\n\n*Edit /etc/default/grub (Press Alt-F2 and enter gksudo gedit /etc/default/grub)\n\n*Find the line that looks something like #GRUB_GFXMODE=640×480\n\n*Remove the '#' and change the resolution to your screen resolution (eg. GRUB_GFXMODE=1280x800)\n\n*Save and close the file.\n\n*Edit /etc/grub.d/00_header (Press Alt-F2 and enter gksudo gedit /etc/grub.d/00_header)\n\n*Find the line gfxmode=${GRUB_GFXMODE}\n\n*Add this line underneath: set gfxpayload=keep\n\n*Save and close the file.\n\n*Run Applications -> Accessories -> Terminal\n\n*Enter sudo update-grub, enter your password if necessary and wait for it to finish.\n\n\nReboot and it should now look better, although boot speed may be slightly decreased.\n\nA: Nouveau is picking up 3d acceleration with Gallium3D as well as proper power management right now.  Even if the GPL-only-symbols thing doesn't get fixed, nVidia proprietary drivers will not be alone in providing a 'nice desktop experience' for much longer.\nhttp://nouveau.freedesktop.org/wiki/FeatureMatrix\nHaving Nouveau at this level of functionality will mean 3d acceleration working on LiveCDs, faster boot times, better security, driver-installation-free ubuntu installs, and so on.  Gaming performance will probably take longer.  --but for Compiz, I'd say depending on your nVidia gpu, you're looking at 11.04.\n\nA: I had the same problem after installing the Nvidia drivers. This is a known problem and there's a bug report for this: Bug #540801\nComment #2 on this bug report describes a workaround for this which worked for me:\n\nThe problem here is the graphics drivers; on your system they're taking longer to load than it takes to check and mount the filesystem - so there's no reason to start the splash screen, since we can already start X.\nOn HDD-based systems this is worse because we do the ureadahead phase before loading drivers; thus it can take a long time for a splash to appear.\nOne \"solution\" is to use the initramfs and start plymouth as a critical step:\necho FRAMEBUFFER=y > /etc/initramfs-tools/conf.d/splash\nupdate-initramfs -u\nBut that introduces a significant delay into boot just to get the splash screen up for the rest of it.\n\nIf you run the above two commands from the command-line (as root) and restart your system, you should have your nice Plymouth boot screen back. The downside however, is a that your system takes a little longer to load, but in my opinion that's a small price to pay. My system still boots quite fast.\nIn the case of a low Plymouth resolution; there's a way to fix that as well: Changing Bootup Resolution (Plymouth)\n\nA: I know this has been answered already, but I came across this the other day and it applies rather well: http://www.webupd8.org/2010/10/script-to-fix-ubuntu-plymouth-for.html\nThis worked with no problems for me. It was super easy as well.\n", "Q: Is it possible to install Ubuntu on a Mac using Bootcamp? I want a native Ubuntu installation, not an VM.  Do I have options on my Mac (that don't involve destroying the 'Mac' portion of it) or should I just switch to a standard PC?  If I do have options, it would be nice to know what they are :-p\n\nA: You have options! There are help pages for installing on Macs that show the hardware support and installation alongside OSX.\nHere is the page where you select which hardware you have:\nhttps://wiki.ubuntu.com/MactelSupportTeam/CommunityHelpPages\nJust click through, select the version of Ubuntu and you'll get some installation instructions. Be sure to check the hardware compatibility too because you might not want to install if certain things aren't going to work.\n\nA: No, Bootcamp only supports ISO files for Windows 10 or later.  This was tested on MacOS Catalina 10.15 Beta.\nPopup that appears if you try to attach an Ubuntu ISO file in Bootcamp\nThis link outlines a way to install Ubuntu as a dual-boot system on a Mac.\n\nA: The instructions for non-destructive, dual boot Mac/Ubuntu setup can be found on Ubuntu Community pages. I've have followed that instruction and installed Ubuntu 11.04 on MacBook Pro side by side with OSX. Both systems work fine. \n\nA: I think it is possible to install Ubuntu on Macs (without destroying OS X) using Bootcamp. Bootcamp is made for Mac users to install Windows alongside OS X.\n\nA: easier way after burning the ubuntu cd restart your mac when the white screen comes up press quickly alt the you should insert the ubuntu cd dont go into efi but go to windows \nthen you can install it . before all of this be careful dont partiton you hard disk  \n", "Q: Problems mounting an SMB share in my fstab I have a valid, reachable SMB share on my Windows box, which I can mount with \nsudo mount -t cifs //192.168.0.9/C /mnt/WinC -o username=foo,password=bar\n\nbut isn't mountable from my fstab.  The fstab entry reads\n//192.168.0.9    /mnt/WinC    credentials=/root/.smbcredentials,iocharset=utf8,file_mode=0777,dir_mode=0777    0    0\n\nand the credentials file (which has 777 permissions while I get this working) contains\nusername=foo\npassword=bar\n\nbut sudo mount -a results in an error, which from a dmesg | tail, shows\n[225040.991705]  CIFS VFS: No username specified\n[225050.991721]  CIFS VFS: cifs_mount failed w/return code = -22\n\nAnyone else seen this issue and managed to resolve it?\n\nA: I went mad on 14.04. the credential= option was not mounting the share in fstab although I could mount it \"by hand\" in the cli. Issue was that the \"cifs-utils\" package was not installed...\nsudo apt-get install cifs-utils\n\nand everything was fine...\n\nA: Install smbfs. \nSounds silly that a package could fix this but when you use credentials files, the kernel diverts to the mount.cifs command rather than doing the mount itself. This package provides mount.cifs so should get you on the road to victory!\nEdit: As Klaus points out in the comments, for 13.04 and later, you need cifs-utils.\n", "Q: Is there a keyboard-centric desktop/WM available? I know of the awesome window manager, which after some customization may suit my desires, but I was wondering if there is a keyboard-centric desktop environment that doesn't require too much tweaking to make it really useful. Of course gnome and I'm sure KDE have nice shortcuts, and the ability to set them up how you want, but that becomes a problem because in a lot of cases the keyboard ends out conflicting with built-in program behavior.\nAny suggestions?\n\nA: There are plenty! (However, all the ones that I know of are also tiling window managers.)\n\n\n*\n\n*XMonad is likely the one with the largest user\ncommunity.  It has extensive documentation and works well with\nGNOME/EWMH extensions (albeit you have to activate them in the\nconfiguration file).  The configuration file has Haskell syntax, but\nit's certainly possible to edit it without knowing much about\nHaskell, by just copying+pasting examples from the documentation.\nDefault keybindings are vim-inspired, though they can all be\nremapped (including using chained keybindings like Emacs' C-a C-b\nC-c). It's available in Ubuntu as package xmonad.\n\n*Bluetile is an offspring of XMonad: it\nsupports a simplified configuration file, and integrates well with\nthe GNOME desktop by default.  Unfortunately, it's not available in\nUbuntu 10.04, so you have to install from source.\n\n*DWM is the \"inspiring father\" of XMonad\nand Awesome.  It's very lean and fast, and available as package\ndwm in Ubuntu 10.04. However, by design, to change the\nconfiguration you have to edit a header file in the sources and\nrecompile; most documentation about the available options is only\navailable as mailing list posts.  It does not support GNOME/EWMH by\ndefault, you will have to patch it; the Echinus fork of DWM\nstarted this way. Most dwm users will frown upon a \"desktop\nenvironment\" so it's probably not the right choice if you like GNOME\ngimmicks.  Default key bindings are vim-like; they can be remapped,\nbut there's no option for chained key-combos.\n\n*Awesome started off as a fork of DWM.\n\n*Ion is a tiling window manager fully\nprogrammable in Lua: also the \"configuration file\" is a Lua script,\nso you can map any key to any action (provided you know enough Lua\nfor the task).  No support for GNOME or EWMH extensions, as far as I\nknow. Available in Ubuntu 10.04 as package ion3.\n\n*wmii is the predecessor of DWM (same\nauthor).  It can be fully controlled by the keyboard, but has a\nsmaller selection of layouts, and the configuration format is\nbased on a \"virtual filesystem\", which makes very complex things\npossible but (IMHO) also simple things rather complicated.\nAvailable in Ubuntu 10.04 as package wmii.\n\n*larswm can configure a key binding for\nall the operations it supports.  Documentation comes in the form of\na man page, clear and complete.  The user community is now very\nsmall, and the mailing list used to be silent for months.  No\nsupport for EWMH/desktop extensions. Available as package larswm.\n\n*ratpoison, as the name says,\nforces you not to use the mouse.  Every action is accomplished by\na key stroke.  Default keybindings are inspired by GNU screen and\nEmacs; they can be rebound, subject to the constraint that there is\nalways a global \"prefix key\" to initiate the action.\nStumpWM is a rewrite of\nratpoison in Common Lisp, which adds the nice option to hack the\nWM while you're running it.  No support for EWMH/desktop extensions\n(by design, I'd say). Both are available in Ubuntu 10.04 (packages\nratpoison and stumpwm).\n\nA: Use Meta or Ctrl-Alt modifiers for desktop shortcuts.\nMost programs use Ctrl or Alt modifiers for their shortcuts (or use  the function keys with no modifiers).\nMost programs don't use Ctrl-Alt shortcuts and almost never use Meta shortcuts, so you should be safe using these without conflict.\n\nA: You might want to check out the keyboard shortcut community wiki on here for more information on default keyboard shortcuts :) \n\nA: Apart from awesome, other choices are DWM & WMii. I don't know much about WMii but DWM is extremely simple and slick and has all customization contained in the source code itself. However, this means it requires you to recompile it everytime you change a shortcut. This is what gives dwm its power and performance.\nMy choice would be awesome - it can be easily installed from official ubuntu repositories. \nsudo apt-get install awesome awesome-extras\n\nHOWTO: Setup AwesomeWM - Ignore the build from src instructions if u use above install command\n\nA: I would argue that Emacs has crossed the boundary of being a text editor and is now a full blown OS, and at least for me, is my prefered keyboard centric user interface. I mean the above statement as a compliment and a strong recommendation of the program rather than the tired joke some people imply with the same statement.\nI  usually invoke it in a terminal window with:\nemacs -nw\n\nOf course install it with:\nsudo apt install emacs\n\nI am still surprised that Ubuntu and Canonical choose not to install it by default.\nIt does have a somewhat steep learning curve, but will reward you with a rich working environment and editor. Start your exploration by using it's built in tutorial, which you can invoke with:\nctrl-h t\n\n", "Q: How can Wolfenstein Enemy Teritory with dependency on libgtk1.2 be installed on Ubuntu? Hey,\nIm trying to install Wolfenstein E.T however it comes up with this error message when running, Saying its missing Libgtk-1.2. In the repos there is only libgtk2.0 any ideas how i can get around this problem?\n\nA: Either download and compile libgtk-1.2 or update and recompile the game (don't think this is a real possibility, but in theory it works.)\nYou can google for instructions on how to compile it.\n\nA: The enemy-territory package which is available from http://www.playdeb.net does not depend on libgtk1.2 .\n", "Q: Is there a tablet-centric desktop available for Ubuntu? I have a Lenovo x61 tablet PC running Ubuntu 10.04. I've got Karol Krizka's auto-rotate daemon working, along with a variety of other applications like cellwriter, though for some reason even when it's working properly, it needed a fix for me. There's a host of other applications I use such as\n\n\n*\n\n*xournal, for general notetaking\n\n*mypaint, for drawing\n\n*easystroke, for gesture recognition\n\n\nprobably others that I forget at the moment...\nBut I was wondering if there are any good tablet-oriented desktop environments for Ubuntu?\n\nA: There really isn't any out there currently - but what you may want to install is the new UNE (Ubuntu Netbox Edition) which provides the new launcher application on the destkop itself. Should make using a tablet a lot more effective.\nTo get this to work you'll need to add this [ppa]: ppa:netbook-remix-team/ppa to your system and install the relavant packages. It took me quite some time to hunt down this repository for some reason. I believe you'll then want to execute sudo apt-get install unity ubuntu-netbook-unity-default-settings and any other packages listed.\n\nA: gnome-shell looks like it's going to be a serious contender for tablet interfaces. Other than that, I'd try out the various netbook-orientated environments like Ubuntu Netbook Edition.\nTo test out gnome-shell I recommend not using the repo version which is a very long way behind the current development version and instead use a PPA like so:\nsudo add-apt-repository ppa:ricotz/testing\nsudo apt-get update\nsudo apt-get install gnome-shell\n\nTo use it just fire off:\ngnome-shell --replace\n\nTo turn it off:\nmetacity --replace\n\nTo remove it:\nsudo apt-get install ppa-purge\nsudo ppa-purge -p testing ricotz\n\n\nA: For a touch interface, you could use LXDE + lxlauncher or the GNOME + netbook-launcher (the launcher from the current (10.04) netbook edition).\nTo add to your applications list you could use fennec, a touch oriented browser.\nAlso look here for a list of applications bundled with  a touch oriented OS (most, but not all, will be available for Ubuntu).\n\nA: The new ubuntu touch ui is well supported on the tablet . But it is not completed yet\n", "Q: Why isn't my monitor's native resolution appearing as an option? I'm on a clean install of Ubuntu 10.04 LTS.  My monitor's native resolution is 1280x1024.  However, in the Monitor Preferences application, I am only presented with 640x480 and 800x600 as options.  My video card is an on board Matrox G200eW.  I tried installing the proprietary driver from Matrox's website, but the installer immediately throws four errors.  I also tried using xrandr to set my resolution, but it simply pops back saying \"Size 1280x1024 not found in available modes.\"  How can I get 1280x1024 added to my available sizes to that I can switch to it?\n\nA: Installing the proprietary driver might help!\nYou can also put new screen modes in the configuration file called /etc/X11/xorg.conf but there is no default since everything is probed every time X starts. So to get a good default you can have Xorg write the probed config to file. This is done by shutting down X and the restarting, telling X on the commandline that it only has to write a config file.\nSo firstly print or write down these instructions ;)\nThen press Ctrl + Alt + F1 to go to a console. There you will have to login. Just login as your normal privileged user.\nTo stop X use this command:\nsudo service gdm stop\n\nand then to have X generate a new configfile\nsudo Xorg -configure\n\nThe Xorg command will tell you where it have saved the config and you can now choose to return to X if you are more comfortable with a GUI.\nRestart X by using this command\nsudo service gdm start\n\nNow edit you new xorg.conf and save it as /etc/X11/xorg.conf find the section that looks like the one below and add the videomodes you want (the Modes line properly isn't there, but just add it after Depth like I have done below.\n\nSection \"Screen\"\n    Identifier    \"Default Screen\"\n    Device        \"NVIDIA Corporation NV34 [GeForce FX 5200]\"\n    Monitor        \"CM752ET\"\n    DefaultDepth    16\n    SubSection \"Display\"\n        Depth        24\n        Modes      \"1024x768\" \"800x600\"\n    EndSubSection\nEndSection\n\n\nA: If your driver supports xrandr this should work:\n\n\n*\n\n*Use this command:\ncvt width height\n\n\n*I will give an output like this:\n1280x1000 59.93 Hz (CVT) hsync: 62.21 kHz; pclk: 105.50 MHz\nModeline \"1280x1000_60.00\"  105.50  1280 1360 1488 1696  1000 1003 1013 1038 -hsync +vsync\n\n\n*Copy the numbers after 105.5\n\n*Then use these commands:\nxrandr --newmode name 105.50  1280 1360 1488 1696  1000 1003 1013 1038 -hsync +vsync  \nxrandr --addmode name\n\n\n*The first command will create a new mode with name, the second will add that mode to the available list.\nNow you should be able to select your desired resolution from the drop-box in the usual menu.\n\nA:  (II) MGA(0): Not using default mode \"1280x1024\" (hsync out of range)\n\nYou need to define a monitor section in xorg.conf with a sufficiently broad hsync range.  \nSomething like:\nSection \"Monitor\"\n     Identifier \"MyMonitor\"\n     HorizSync  xx-yy\nEndSection\n\nIt would be best if you put the exact hsync range for your monitor.\nI believe this is happening because the video driver is unable to get correct EDID information from the monitor. You might also need to experiment with your driver's settings to tell it to ignore the EDID information it's getting from the monitor.\n\nA: I would recommend, correctly installing your drivers. Then i am sure if your graphic card is capable of displaying the resolution 1280x1024  it will.\n:)\n\nA: This answer suggests setting the refresh and sync rates for the monitor. Use your monitor's specification to find its values, then put them like this:\n  Section \"Monitor\"\n   Identifier \"Monitor0\"\n   VendorName \"Unknown\"\n   ModelName \"CRT-0\"\n   HorizSync 31.0 - 81.0\n   VertRefresh 56.0 - 76.0\n  EndSection\n\n\nA: A common cause of this problem is the monitor sending bad (or no) resolution information to the driver.  The driver then restricts itself to common defaults (e.g. 640x480 or 800x600, or sometimes 1024x768).  Sometimes a bad cable is at fault.\nSo first verify if your monitor info is getting through properly, and if not react:\n\n\n*\n\n*Run sudo get-edid to verify the extended display data.  For example I get:\n\n\n\n\n\n*Download Phoenix EDID Designer and run it with wine Phoenix.exe.  In a few clicks you can set the native resolution of your monitor, invent a manufacturer ID and serial number, and be on your way.  Save this as a \"raw\" file.  To keep things simple enter only the native resolution of your monitor.\n\n*Back up xorg.conf and add a CustomEDID option:\nSection \"Device\"\n    VendorName     \"NVIDIA Corporation\"\n    BoardName      \"GeForce GT 430\"\n    ...\n    Option      \"CustomEDID\" \"DFP-0:/home/bnesbitt/XP-17-EDID.raw\"\nEndSection\n\n*Restart the X server or (if you're brave) reboot.\nFor clarity that error message was 'The EDID data should not be trusted as the VBE call failed. EDID claims 255 more blocks left EDID blocks left is wrong. Your EDID is probably invalid.'.\n", "Q: Where can I find the gnome applets scripts that I can look at them? How can I see the code of gnome panels? for example view the code is executed When I click on shutdown button in the panel.\n\nA: As far as I see it the relevant code is in panel-action-button.c. This code handles the shutdown and other things. You find the complete code at git repository of gnome-panel.\n", "Q: Themes mess up any time I install anything in wine Every time I remove or install anything to do with Microsoft, either it be fonts or dependencies for wine. \nI constantly find my theme messing up. Does anyone know why this happens?\nPlease and thank you.\n\nA: Wine should not do anything to the Ubuntu theme. I think you should file a bug report with Wine. http://bugs.winehq.org/\n\nA: Perhaps you're replacing an Ubuntu font with a Windows font with the same name? Please, see this note, which is in the package ttf-mscorefonts-installer:\n\nNOTE: the package ttf-liberation\n  contains free variants of the Times,\n  Arial and Courier fonts. It's better\n  to use those instead unless you\n  specifically need one of the other\n  fonts from this package.\n\nBest regards.\n", "Q: How can I safely shutdown/reboot/logout KDE from the command line? I am not talking about shutdown and reboot commands. I want to initiate the same routine from command line that would be performed if I would press the logout/reboot/shutdown button inside the KDE desktop.\n\nA: So I tried the answer presented by Gilles, but that only works for KDE4.\nAfter a system-update with my graphics, I could no longer log out, reboot, or shutdown. Eventually found this command worked:\nqdbus org.kde.ksmserver /KSMServer logout 0 0 0\n\nMy source is from here, where they discuss it a bit more. I'm not sure about he other optoins. Forum topic discussion KDE5 shutdown options. The above command seems to have shutdown my system gracefully. All my programs came back that were expected, in the right layout order, and I did not seem to be missing anything. If this doesn't work, please comment and I will adjust my answer but so far this is all that has worked for a graceful KDE5 shutdown when my is locked. (I obviously could have used the shutdown command or called init, but those aren't graceful.)\n\nA: For KDE 5+:\nqdbus org.kde.Shutdown /Shutdown logout\nqdbus org.kde.Shutdown /Shutdown logoutAndReboot\nqdbus org.kde.Shutdown /Shutdown logoutAndShutdown\n\nThe last option specifies which method gets called. It seems the options for KDE4 mentioned below are partially supported(reboot didnt work so I ended up using these newer methods).\nRef: Reddit\nFor KDE 4:\nNote that this answer was written in 2010 for KDE 4. It may not apply to modern systems.\nqdbus org.kde.ksmserver /KSMServer org.kde.KSMServerInterface.logout -1 -1 -1\n\nThe three integer parameters are the confirm, sdtype and sdmode arguments to KWorkSpace::requestShutDown. Their values are explained at the top of the page. Since the page has disappeared, here are the values (still present in a cache).\nenum ShutdownConfirm {\n  ShutdownConfirmDefault = -1,\n  ShutdownConfirmNo = 0,\n  ShutdownConfirmYes = 1\n}\n\n\n\n*\n\n*ShutdownConfirmDefault:\nObey the user's confirmation setting.\n\n*ShutdownConfirmNo:\nDon't confirm, shutdown without asking.\n\n*ShutdownConfirmYes:\nAlways confirm, ask even if the user turned it off.\n\n\nenum ShutdownMode {\n  ShutdownModeDefault = -1,\n  ShutdownModeSchedule = 0,\n  ShutdownModeTryNow = 1,\n  ShutdownModeForceNow = 2,\n  ShutdownModeInteractive = 3\n}\n\n\n\n*\n\n*ShutdownModeDefault:\nSelect previous mode or the default if it's the first time.\n\n*ShutdownModeSchedule:\nSchedule a shutdown (halt or reboot) for the time all active sessions have exited.\n\n*ShutdownModeTryNow:\nShut down, if no sessions are active.\nOtherwise do nothing.\n\n*ShutdownModeForceNow:\nForce shutdown.\nKill any possibly active sessions.\n\n*ShutdownModeInteractive:\nPop up a dialog asking the user what to do if sessions are still active.\n\n\nenum ShutdownType {\n  ShutdownTypeDefault = -1,\n  ShutdownTypeNone = 0,\n  ShutdownTypeReboot = 1,\n  ShutdownTypeHalt = 2,\n  ShutdownTypeLogout = 3\n}\n\n\n\n*\n\n*ShutdownTypeDefault:\nSelect previous action or the default if it's the first time.\n\n*ShutdownTypeNone:\nOnly log out.\n\n*ShutdownTypeReboot:\nLog out and reboot the machine.\n\n*ShutdownTypeHalt:\nLog out and halt the machine.\n\n*ShutdownTypeLogout:\nTemporary brain damage.\nDon't use. Same as ShutdownTypeNone\n\n\n\nA: For any version of KDE (maybe also GNOME and others):\nIn KDE Control Center (KDE3.5/trinity) you can set a keyboard shortcut for \"halt without confirmation\" (should be a complicated one to avoid tragedy, like Ctrl+Shift+Alt+Delete) and then run xvkbd (virtual keyboard):\nxvkbd -text '\\C\\S\\A\\d'\n\nYou can create an alias for this (e.g. kdehalt);\nMy favourite one: sleep 1h 20m && kdehalt or wget \"http://something\" ; kdehalt.\n", "Q: Are there any good books for new Ubuntu users? I recently installed Ubuntu in my uncle's laptop. He seems to like it and he is asking me for some good Ubuntu books for beginners. I was thinking about The Official Ubuntu Book. Any other suggestions would be very much appreciated.\nHe comes from a Windows background if that would help.\n\nA: I've read lots of good books about Ubuntu and Linux in the past few months. This is the first great book.\n— Arsgeek.com review of Beginning Ubuntu Linux, Second Edition\nKeir Thomas walks you through the whole Ubuntu experience from beginning to end, comforting you with a calm voice when you might be feeling a bit lost ... He has done a great and thorough job.\n— Free Software Magazine review of Beginning Ubuntu Linux, Second Edition\nWinner of a Linux Journal Editor's Choice 2006 award (first edition)!\nBeginning Ubuntu Linux, Second Edition updates the best-selling and award-winning first edition. It's the perfect guide for those switching to the world's favorite Linux. The new edition has been thoroughly updated to cover technology introduced in the 6.10 release.\nIn the 680+ fully illustrated pages, you'll learn how to install Linux, set up your hardware and software, customize the desktop experience, browse the Web and send/receive e-mail, play back audio and video, edit digital images, use the OpenOffice.org office suite, and more.\nAdditionally, you'll discover how to perform vital maintenance tasks, such as securing your computer against hackers, updating online, optimizing your system, installing and managing software, backing up, accessing your computer remotely, scheduling tasks, and more.\nA whole third of the book is dedicated to Linux internals, including managing system processes and working at the command line. Two appendixes pre a glossary of Linux terms and an index of commands that can be used to control Ubuntu.\nBeginning Ubuntu Linux, Second Edition is a complete, comprehensive, and unbiased guide to getting the most from Ubuntu.\nDVD-ROM\nBeginning Ubuntu Linux, Second Edition features a unique DVD-ROM companion disk containing the full Ubuntu installation that you can install on your computer. A full installation guide is pred in the book. Also included on the DVD-ROM are the Ubuntu sister projects, such as Kubuntu, Xubuntu, Edubuntu, and others. Both the long-term support and recent 6.10 releases of all projects are pred.\nIn Detail Part 1: Introducing the World of Linux\nOpening the book are several chapters pring a brief but complete history of Linux. You'll learn about the key figures in the Linux movement and discover why the politics behind free software are so important.\nPart 2: Installing Ubuntu\nHere you'll find a fully illustrated guide to both installing Ubuntu on your computer and initially preparing the computer for Ubuntu. Detailed screenshots guide you through every step. In addition, there's a problem-solving chapter pring solutions for the most common issues.\nPart 3: The No-Nonsense Getting Started Guide\nThe six chapters of Part 3 take you from zero to hero in as little time as possible. You'll learn what's what on the Ubuntu desktop and how to customize Ubuntu to suit your workflow. You'll be introduced to Linux replacements for your favorite Windows programs, and you'll be introduced to the Linux file system, so you can start working straightaway.\nPart 4: The Shell and Beyond\nThe five chapters in Part 4 introduce the heart of Linux: the command line. You'll be introduced to the BASH shell, and a full rundown of the Linux filesystem is pred. You'll learn how to work with text files. The closing chapters of this section teach pro-level tricks you can use at the command line to work more efficiently.\nPart 5: Multimedia\nHere you'll learn how to set up Ubuntu to work with common audio and video files that you might have used under Windows or Macintosh. Then you'll be introduced to Ubuntu's audio and video playback software. Additionally, a complete guide to image editing and digital image management is pred.\nPart 6: Office Tasks\nThe seven chapters in this section pre a comprehensive guide to the OpenOffice.org office suite. You'll learn how to undertake common tasks using the word processor, spreadsheet, presentations package, and database applications. Additionally, a complete guide to using Ubuntu's e-mail and personal information manager is pred.\nPart 7: Keeping your System Running\nThe six chapters in this part of the book pick up from Part 4 and expand on various system management/command-line skills. You'll learn how to perform vital maintenance tasks, such as managing users, or installing and removing software. It's in this part of the book that you'll really learn your Linux stripes!\n\nA: A good start is the recently published ubuntu manual \"Getting Started with Ubuntu 10.04\", made by the community: http://ubuntu-manual.org/\nIt is available for free as a PDF, but you can also order a printed version for less than 10$ at Lulu.com: http://www.lulu.com/product/paperback/getting-started-with-ubuntu-1004/10793559\n\nA: You certainly took a good step and joining here. Asking question would be beneficial to both you and people who come after you.\nI have found this book to be especially useful, bit outdated but still extremely useful. By Neal Krawetz\n\nA: Ubuntu Kung Fu :\n\nUbuntu builds on a solid base of\n  Debian Linux to create an\n  award-winning operating system that's\n  light-years ahead of its competitors.\n  Ubuntu consistently tops lists of the\n  most popular Linuxes amongst\n  professionals and enthusiasts; Dell\n  recently embraced Ubuntu in its\n  product lines after a user survey\n  indicated overwhelming public support.\nUbuntu Kung Fu pres hints, hacks,\n  tweaks and tricks for every level of\n  user. Guaranteed to be free of the\n  usual dross that fills tips books,\n  Ubuntu Kung Fu is written to be\n  entertaining and, above all, readable.\n  Its 300+ concise tips utilize and\n  exploit hidden or lesser-known\n  features to boost day-to-day\n  productivity. You'll also find tips on\n  tweaking Ubuntu, wrangling the system\n  into shape, optimizing, enhancing\n  security, and lots more. Learn what\n  extraordinary things can be done with\n  Ubuntu.\nWritten with the migrating Windows or\n  Mac OS X user in mind, Ubuntu Kung Fu\n  avoids the usual Linux/Unix folklore\n  that can send most of us to sleep. The\n  tips have one aim--to produce results\n  as quickly as possible, in an\n  environment where the reader can\n  polish their skills as they read. This\n  is the Linux book for the rest of us.\n\n\nA: You can also find some great free Ubuntu books here: List of free Ubuntu books\n\nA: The Ubuntu Pocket Guide\nAvailable in print or for free in PDF form. Written for Ubuntu Intrepid, it is still very relevant for Lucid Lynx (at time of posting) and most likely for the next few releases too.\n\"Written for anybody switching to Ubuntu, particularly former Windows users, Ubuntu Pocket Guide and Reference assumes zero Linux knowledge. It provides the wisdom of the expert user and concisely conveys core competencies.\"\nhttp://www.ubuntupocketguide.com\n\nA: A PDF download \"A Complete Beginner’s Manual for Ubuntu 10.04 (Lucid Lynx)\" is available at:\nhttp://www.ubuntugeek.com/download-free-ubuntu-10-04-lucid-lynx-pdf-guide.html\n", "Q: What is the easiest way to resolve apt-get BADSIG GPG errors? I frequently cross this issue, and always have to google for an answer. Does anyone have a permanent fix for BADSIG errors from apt-get?\n\nW: GPG error:\n  http://download.virtualbox.org lucid\n  Release: The following signatures were\n  invalid: BADSIG 54422A4B98AB5139\n  Oracle Corporation (VirtualBox archive\n  signing key) \n\n\nA: The important part of your error message is the following in bold:\n\nW: GPG error: http://download.virtualbox.org lucid Release: The following signatures were invalid: BADSIG 54422A4B98AB5139 Oracle Corporation (VirtualBox archive signing key) \n\nCopy the stuff in bold and then open a terminal and type:\nsudo apt-key adv --recv-keys --keyserver keyserver.ubuntu.com 54422A4B98AB5139\n\ni.e. paste using SHIFT + INS the number you have copied - 54422A4B98AB5139\nYou'll have to enter your password, the key will be downloaded and integrated.\n\nA: Try deleting the key\nsudo apt-key del 16126D3A3E5C1192\n\nthen updating the repository\nsudo apt-get update\n\nYou should get a NO_PUBKEY error instead of a BADSIG error and\nsudo apt-key finger\n\nshould not find the key (called \"Ubuntu Extras Archive Automatic Signing Key\")\nNow add the key\nsudo apt-key adv --recv-keys --keyserver keyserver.ubuntu.com 16126D3A3E5C1192\n\nThe result of apt-key finger should have\npub   1024D/3E5C1192 2010-09-20\n      Key fingerprint = C474 15DF F48C 0964 5B78  6094 1612 6D3A 3E5C 1192\nuid                  Ubuntu Extras Archive Automatic Signing Key <ftpmaster@ubuntu.com>\n\n\nIf that does not work, try\napt-get clean            # Remove cached packages\ncd /var/lib/apt\nmv lists lists.old       # Backup mirror info\nmkdir -p lists/partial   # Recreate directory structure\napt-get clean\napt-get update           # Fetch mirror info\n\nSource: this ubuntu forums thread\n\nA: If you still have this error after adding the key try:\n\n\n*\n\n*goto your apt-cacher-ng cache directory, and delete the virtualbox entry:\ncd /var/cache/apt-cacher-ng\nsudo rm -rf download.virtualbox.org\n\n\nA: Found another server that we could use:\ngpg --keyserver hkp://subkeys.pgp.net --recv-keys [YOURKEYINQUESTION]\ngpg --armor --export [YOURKEYINQUESTION] | sudo apt-key add -\n\n\nA: Here's the (easiest) solution:\nType the following commands in the Terminal:\n$ sudo -i\n# apt-get clean\n# cd /var/lib/apt\n# mv lists lists.old\n# mkdir -p lists/partial\n# apt-get clean\n# apt-get update\n\nCredits: ubuntugeek.com\nEdit:\nIf the error occurs again (maybe after a few days/months), open Nautilus as root > navigate to var/lib/apt > delete the \"lists.old\" folder > then open the \"lists\" folder and delete the \"partial\" folder. Now, execute the aforementioned commands again.\n\nA: Another easier way to resolve BADSIG GPG errors is via a software called Y PPA manager \n\nsudo add-apt-repository ppa:webupd8team/y-ppa-manager\n  sudo apt-get update\n  sudo apt-get install y-ppa-manager  \n\nClick on Advanced\n \nAnd then select Fix all GPG Badsig errors\n\n", "Q: What are some CD Ripping Programs you can use on Ubuntu? What are some CD ripping programs for Ubuntu? Can you list the Pros? What are the Cons? For each program there should be a screenshot, sources to install, and instructions to install and use.\n\nA: A lot of time has passed since this Q&A was updated, but it is still the best (only?) \"CD Ripper\" thread in AskUbuntu (I think).\nAs of this contribution, the developer for Ruby Ripper writes: \"The best current way to rip audio is Morituri, which is available in Precise and beyond.\"\nNOT mentioned to date in this Q&A, Morituri \"is a CD ripper aiming for accuracy over speed. Its features are modeled to compare with Exact Audio Copy on Windows.\" At the moment the README on Github notes as a \"Known Issue\": \"no GUI yet\".\nDevelopment on Grip, \"a GTK-based CD-player and CD-ripper / MP3 encoder\", was mentioned above as having slowed down, and so it seems to be, but that hasn't stopped it from being well used.\nAnd maybe it's worth noting Flacon as well in this thread: \"Flacon extracts individual tracks from one big audio file containing the entire album of music and saves them as separate audio files.\" On 2015-09-10 WebUpd8 posted some information about it (including installation instructions) with the Flacon 1.2.0 release.\n\nA: I use ABCDE that is a very good ripper :\nabcde -a cddb,read,encode,tag,move,playlist,clean -d /dev/cdrom -o m4a -V -x\n\n\nA: I had the same question.  I wanted a programme that would create FLAC and MP3.  After researching it a bit I came across Asunder CD Ripper.  Seems to do everything I need of a ripping programme.\nFrom the Description:\nAsunder is a graphical Audio CD ripper and encoder. It can be used to save tracks from Audio CDs. Main features are:\n    Supports WAV, MP3, Ogg Vorbis, FLAC, and Wavpack audio files\n    Uses CDDB to name and tag each track\n    Can encode to multiple formats in one session\n    Creates M3U playlists\n    Allows for each track to be by a different artist\n    Does not require a specific desktop environment (just GTK+)\n\nA: Ubuntu Default CD Ripping Software : \nTo rip a CD, you will require a suitable CD-ripping application. One is installed by default on Ubuntu, and there are others available through Ubuntu's software channels, as reported in the Ubuntu Documentation.\nSound Juicer\nSound Juicer is Ubuntu's default CD-ripping application, and also has the ability to play your CDs and download track data from the Internet.\n\nTo rip a CD using Sound Juicer, simply insert an audio CD; Sound Juicer should start automatically. Alternatively, you can select Sound Juicer from Applications -> Sound & Video -> Audio CD Extractor. By default, the CD will be encoded into the OggVorbis format, a Free Format. If you wish to rip a CD to a non-free format such as MP3 or AAC, you will need to install some additional software. \nKubuntu Default CD Ripping Software :\nThere are two methods of ripping an Audio CD in a default installation of Kubuntu. One is using Konqueror's audiocd:/ KIO-slave and the other is KaudioCreator (KMenu->Multimedia->KaudioCreator). On inserting the Audio CD, you should be presented with the KDE Audio CD Daemon asking you what you wish to do. To use the KIO-slave method (which is relatively easier), select the 'Open in a new Window' option. Or, if you prefer using KAudioCreator, select the Extract and Encode Audio tracks option.\nUsing audiocd:/ to rip a CD\nIn Konqueror's location bar, type audiocd:/ and press enter. You should now see the tracks in the CD along with folders named Ogg Vorbis, FLAC, MP3 etc. Click on the folder which corresponds to the format in which you wish to encode, eg. Ogg Vorbis.\nNow, copy the tracks that you need from that folder and paste it in the desired location (/home/kubuntu in the example). The tracks are automagically ripped, encoded and copied to the location you specified!\nNote: Copying speeds might not be as fast as those achieved when copying a file directly from the CD as the files are also being ripped and encoded. If you wish to modify some of the settings (like editing the tagging sytax or modifying the encoding settings), you can access it either through System Settings (KMenu->System Settings->Sound and Multimedia->Audio CD) or through KDE Control Center (kcontrol).\nUsing KAudioCreator\nLaunch KaudioCreator (Kmenu->Multimedia->KaudioCreator). It should automatically display the tracks in the disc. You can modify the settings to suit your needs (Settings->Configure KaudioCreator), and also choose an encoder. Click on the Rip Selection icon to start the Ripping and encoding process. \nOther CD Ripping Software :\nIn alphabetical order.\nABCDE\nThose who want a no-nosense, fast, customizable ripping solution should try ABCDE.\nAnd example conversion from CD to AAC/MP4:\nabcde -a cddb,read,encode,tag,move,playlist,clean -d /dev/cdrom -o m4a -V -x\n\nAsunder\nAsunder is an easy-to-use, plain CD ripper that converts into MP3, OGG, FLAC, WAV, and the new open codec WavPack. Asunder is in the Ubuntu repository and can be installed with Synaptic or Software Center.\nGrip\nI have been using Grip until Edgy. It's very easy to use but still very configurable.\nNote: Grip is no longer supported by its developers, or by Debian or Ubuntu. It has been removed from the repositories in Ubuntu 9.10.\nRipper X\nTo install:\nsudo apt-get install ripperx\n\nRubyRipper\nRubyRipper has been recommended in many forum threads and seems to be one of Linux's best ripping solutions. Also, many feel the closest to EAC in quality of rips.\nRubyRipper is not included in the default Ubuntu install and is not included in any of the repositories. Fortunately there is a DEB package available.\nTo install:\n1.Install dependencies by typing in the terminal:\nsudo apt-get install cd-discid cdparanoia flac lame mp3gain normalize-audio ruby-gnome2 ruby vorbisgain\n\n2.Download the DEB package from here and follow the instructions. \nAlternate install:\nOpen a terminal window and type: \nsudo add-apt-repository ppa:aheck/ppa\nsudo apt-get update\nsudo apt-get install rubyripper\nsudo apt-get install rubyripper-gtk\n\n\nA: If you want quality rips, then I recommend EAC running inside of Wine.\n\nA: I know I'm rather late to the party, but I love using ripit on the command-line. This perl script is available in the repositories and relies on several programs such as cdparanoia, but you need to have the encoders such as flac or vorbis installed if you want to encode in those formats. \nThe great thing about it is that it gets all the audio CD information from CDDB or Musicbrainz so the tracks are labeled correctly. The tracks can be tagged with ID3 tags and a playlist can be created.\nAfter the rip, a properly labeled folder containing correctly labeled tracks will be found in the location specified.\nThere is a choice of encoders; choose -coder 1 for oggenc, -coder 2 for flac and so on; and choose the quality with -q and specify a value between 1 and 10; -q 8 will encode in 256 KBit/s. For more information see man ripit or see the Ubuntu manpage online. \nA sample burn command that I use regularly is:\nripit -eject -d /dev/sr1 -coder 1 -q 8 -o ~/Music\n\nExplanation: -d /dev/sr1 specifies the optical drive with your cd in (you can find out what it yours is with sudo lshw -c disk and install lshw if necessary); -coder 1 -q 8 is the ogg encoder with quality level 8; -o ~/Music means save the output to /home/mike/Music.\nNote: if there is any hidden data on the cd inserted, you will need to note the response from ripit and then simply add 1-10 (if there are ten tracks) after /dev/sr1.\n\nA: Well, rhythmbox itself is able to rip CDs and get album data from the MusicBrainz database. \nIf you insert a CD, a CD icon appears in the Rhythmbox's side bar at the left. Right click it and choose \"Extract to library\". Make sure to have the format set to the one you want (probably MP3): Edit -> Preferences -> Music -> Preferred Format.\nIn the current version, 3.3 (on Ubuntu 16.10), rather than right-clicking the CD icon, you click the \"Extract\" button in the main window.\n\nA: The current CD rippers in Ubuntu are terrible. The least worst CD Ripper for Linux is the venerable k3b\nWhy it is the best:\n\n\n*\n\n*you can set a high paranoia level to correct scratch errors reading your CD. Set to 3 for the best correction (as good as Exact Audio Copy)\n\n*it queries MusicBrainz and FreeDB and CDTEXT \n\n*you have the most sophisticated options of path and filename configurationn\n\n*You can easily configure a variable bitrate and it will obey what you configured (I'm looking at you SoundJuicer and RhythmBox)\n\n*Accents are correctly saved in file names and metadata (Take that RubyRipper!)\n\n\nWhy it is not good:\n\n\n*\n\n*If your CD isn't in MusicBrainz or FreeDB, there's no easy way to submit it. SoundJuicer is better in this point.\n\n*it won't record the track number in your MP3 metadata, so won't be able to listen the CD as the artist intended. You must go to \"MP3 (lame)\" configuration and add --tn %n option. Since you are there, also add the option --tv TPE2=%r to get Album Artist metadata recorded. \n\n*you can't freely write in the genre field, you are subjected to FreeDB limited and American centric selection\n\n*It is inefficient to edit track and artists names, you have to go to the field and click F2 to edit each field\n\n*every time you start to rip you must remember to click \"load saved configurations\", or you will have your ripped files in an undesired format.  K3b has a weird config option. In Misc → Default action dialog setting, you must select \"saved setting\". It doesn't display the last one used by default. \n\n*no cover art (Clementine usually takes care of that)\n\n\nRemember that you'll need to install KDE libs to use it. \n\nA: Sound Juicer works well for me. Take a look at the community docs, or project website for more info. \n\nA: I use Banshee as my audio player and it does ripping pretty damned well too. Insert the CD, it'll pull down the album contents, click copy and it rips it to the library, tags set and everything.\nThe format settings are a little less configurable than a dedicated ripper but I just default to FLAC and that's fine for me.\n\nA: I love Rubyripper but this issue has me using the CLI version on 10.04. I can't post more than one link here, but there is a good overview of Rubyripper's features at the hydrogenaudio.org Knowledgebase\n\nA: Audex   is an easy to use audio CD ripping application\n\nA: I had a real bad time trying to do this on Ubuntu 18.04 using various popular apps such as Audacity, Rhythmbox, and Sound-juicer.  One common problem seemed to be the interface to MusicBrainz, which refused to populate my data even though it had an accurate \"stub\" entry for the CD I was using.  There was something else that affected more than one of these apps that made it nearly impossible to even enter the track data manually -- basically the keyboard interface was bizarrely half-broken.\nFinally, ripperx got the job done.  Maybe the magic was that it uses \"CDDB\" instead of MusicBrainz.  Sometimes, older is better.\nsudo apt install ripperx\n\nThe only difficulty I had was that the CD source wasn't configurable in the application and I needed to use the command line to sudo ln -sf sr1 cdrom to specify the correct device.\n\nBonus note: Test playback of an MP3 using the ancient madplay from the command-line using Bash Process Substitution to modernize the output piping:\nmadplay temp.mp3 -o wave:>(aplay)\n\nBTW: “MP3 is dead” missed the real, much better story\nSomething else that may come in handy: accessing CD tracks from the file system\n\nA: Be wary, and check online before you waste your time on downloads that are junk. Sound Juicer is great if you only want OGG files, currently there is no access to preferences, you may be able to get that menu item back by fiddling with crap and searching on the internet - I've been at it for an hour and have given up - just want to rip to my iPod Sound Juicer is just junk for me.\n\nA: A good graphical option is xfca, which stands for \"X Convert File Audio\". The official website is here (in French though).\nTo install, run:\nsudo apt-get install xfca cdparanoia cd-discid\n\nThe latter two are needed if one wants to download CD metadata. \nThe interface is very straightforward, as you can see below:\n\nIt also includes a command line option, xcfa_cli, which complete manual can be accessed from man xcfa_cli.\nAlso, this program integrates with gmusicbrowser, in case you use that music player.\n", "Q: Kernel > 2.6.32-20 doesn't boot (root file system does not exist) One of my notebooks is a Compaq nc4200 (Mobile Intel 915GM Express). All Ubuntu kernels > 2.6.32-20 don't boot on that machine. Instead I get an error message:\nerror: unexpectedly disconnected from boot status daemon\nBegin: Waiting for root file system ...\n\nAfter some googling I found Bug #574755 in Debians BTS. In this case plymouth had some bug. So I tried to add i915 modeset=1 to /etc/initramfs-tools/modules. This made the boot screen complete lack. I saw no output anymore. Second I tried to remove the plymouth-package. After purging it I got the same message again.\nI dug a bit further. From my point of view this must be some kind of file system thing. Output from boot:\nBegin: Running /scripts/init-premount ... done.\nBegin: Mounting root file system ... Begin: Running /scripts/local-top ... done.\nBegin: Waiting for root file system ...`\n\nAfter some time there is a timeout and a BusyBox shell appears:\nGave up waiting for root device. Common problems:\n - Boot args (cat /proc/cmdline)\n   - Check rootdelay= (did the system wait long enough?)\n   - Check root= (did the system wait for the right device?)\n - Missing modules (cat /proc/modules; ls /dev)\nALERT! r/dev/disk/by-uuid/(UUID-of-my-sda1) does not exist. Dropping to a shell!\n\nBusyBox v1.19.3 (Ubuntu 1:1.10.3-7ubuntu1.1) built-in shell (ash)\nEnter 'help' for a lost of built-in commands.\n(initramfs)\n\nNow I'm out of ideas. What can be the cause of it? How I resolve this issue?\n\nA: If you are still having this problem:\n  1. Go to launchpad and file a bug. A new bug. Don't add a \"me too\" to an existing bug.\n  2. Go to #ubuntu-kernel on freenode (this is an irc channel on an irc server). The Ubuntu kernel team hangs out there almost 24 hours per day, Monday through Friday. Please, don't pop in, ask a question and if you don't get an answer right away, disconnect. If you are patient, you can get someones attention and they will try to help. Really, they are not scary people :-)\n\nA: Have you tried to use the old notation /dev/sdxn instead of using UUID?.\n\nA: It's possible that your drive is not coming online fast enough and the kernel is giving up on it before it is ready.  There's a way to test this to work around it.\nThe instructions below assume you are running Ubuntu 9.10 or later.  If you are running an earlier release, you can see https://help.ubuntu.com/community/GrubHowto for instructions on performing the edits below.\nWhen rebooting your system, select the kernel to boot (you may need to hold shift while the system is booting to see the GRUB bootloader menu, depending on your setup).  Then press 'E' to edit the boot options.\nScroll to the line that starts with \"kernel\" and move the cursor to the end of the line.  At the end of that line, add a space and \"rootdelay=60\".  This will tell the kernel to wait up to 60 seconds for your drive to become ready.  Then press Control-X to boot.\nIf all goes well, your system will boot.  If this is the case, you can make the changes permanent by adding them to the default boot options.  To do this, open a terminal (Applications - Accessories - Terminal) and type:\nsudo gedit /etc/default/grub\n\nFind the line that looks like:\nGRUB_CMDLINE_LINUX=\"\"\n\nand change it to\nGRUB_CMDLINE_LINUX=\"rootdelay=60\"\n\nFinally, run\nsudo update-grub\nto make sure your changes are properly picked up.\nFor more information about the options available in the bootloader, you can see https://help.ubuntu.com/community/Grub2 .  (There is a bug report about this delay for specific hardware at https://bugs.launchpad.net/ubuntu/+source/linux/+bug/482327 .)\n", "Q: Conexant modem in Ubuntu Previously linuxant release driver for conexant modem (HCF or HSF), now for newer kernel this site doesn't release for newer kernel version (after 2.6.31-17 version). how to use conexant modem in Ubuntu with newer Kernel than 2.6.31-17 (... , 10.4 , ...)?\nLinuxant Ubuntu driver : \nhttp://www.linuxant.com/drivers/hsf/full/downloads-ubuntu-x86.php\n\nA: There is a compile-it-yourself option. See here.\nDownload the tar and then follow METHOD C on the installation instructions.\nFollowing your comment, I decided to try building it. It went fine. Here's what I did:\n\n\n*\n\n*Download and extract the tar for the right arch.\n\n*cd into the new directory and then\nsudo make debprecomp\n\n\n*Assuming everything worked, there should be a .deb file sitting in the directory above the current working dir. Just double-click it and it should install.\nAfter that just follow the rest of the installation instructions.\n\nA: Also Dell provide this driver.\nI have used it long time ago.\nTry this page or looking for similar items on dell support.\n", "Q: How should I synchronize configurations and data across computers? Imagine I have three Ubuntu computers home, laptop, beach-house. They all have the same version of Ubuntu, 10.04 installed, and are kept up to date from the repositories.\nI use f-spot, thunderbird, and google-chrome on all of the computers. Is there a way to keep the data and configuration in sync across them, without requiring constant connectivity for normal (non-synchronous) usage? \nFor example, they should be usable without network connectivity, so something like NFS won't work. \nAn ideal solution would not require manual action to start the syncing process. \n\nA: Apps like f-spot, thunderbird, and google-chrome all use some form of binary database to store their data. Trying to sync things like this where there's the possibility of the same app accessing/modifying the file at the same time could get really messy.\nInstead you want to look for application-specific solutions.\n\n\n*\n\n*With thunderbird, I would say use IMAP. If you don't have it, GMail supports it. You could have thunderbird upload all your email there, or better yet, have GMail pull in email from your other accounts. You also gain pretty decent webmail and a great spam filter for free. \n\n*Firefox has (amongst other things) Firefox Sync.\n\n*Chrome has a sync feature built in, documented here.\n\n*F-Spot is tougher. Perhaps consider something to sync the files but not the database. This would mean you'd need to scan for new files all the time but only if you needed to use F-Spot on every computer. \nYou could limit yourself to using F-Spot on one computer and just accessing the files on the others. Of the three, the F-Spot database is the most fragile so be careful if you do share the database file.\n\nA: To synchronize data, such as documents, use UbuntuOne or DropBox. I can really recommend the latter. This assumes that you don't mind storing your data in a company's data center or cloud. I'm not sure about sharing your music collection through the internet. My network connection is not fast enough to allow this, so I'd go with manual copying or using rsync regularly.\nFor configuration, there are two different cases: applications that use regular text files as configurations, and those that use a gconf, a database or something nonstandard. For the former, you can store the dotfiles (for instance ~/.vim/, ~/.zshrc) in a subfolder of your Dropbox (or UbuntuOne) folder, and then symlink the files back to your $HOME directory. This works well.\nAs to the applications you mention, it seems that none of them use simple text files as configuration. That means, in essence, that you can't effectively synchronize them. The reason is that, if there is a conflict, you won't be able to resolve it. Furthermore, some parts of the configuration directory, such as cache files, are bound to be system-specific or otherwise inappropriate for synchronization. In these cases, I say don't bother with synchronization, and just copy over the config directory once. There's an exception, however: applications that natively support sharing a configuration across multiple computers. Firefox can do this, and recent versions of Google Chrome can store at least some parts of the configuration in your Google profile (check your preferences). I'm not sure sharing plugins/extensions is supported, but it's a feature that is being worked on.\n\nA: For google chrome enabling sync will sync your bookmarks. In newer versions it allows you to sync autofill, bookmarks, extensions, preferences, and themes.\n\nA: XMarks can sync your bookmarks, passwords, and open tabs between Firefox and Chrome (and a few others) on different computers.\nDropBox for F-Spot.\n\nA: You could use a startup script that syncs (with rsync) the necessary files if the network is up. Hence you could use upstart to trigger the script and base it on the network ready event.\nAlternatively, maybe it would be possible to use Ubuntu-one for the synchronization of the files in question.\n\nA: Jorge Castro says \"in newer versions\" Chrome will let you sync history.  I have the latest; I don't see it as an option.  Since this is a feature dear to my heart, please let me know where you saw this information.  \nOr did you mean \"future versions\"?\n\nA: Are you regularly on all three systems simultaneously, doing lots of data changing on all of them?  If not, is there any reason an rsync on login and another on logout wouldn't do?  Perhaps not the perfect solution, but adequate...\nOn login:\nrsync -avz -e ssh remote1:~/.thunderbird/ ~/.thunderbird/\nrsync -avz -e ssh remote2:~/.thunderbird/ ~/.thunderbird/\n\nOn logout:\nrsync -avz -e ssh ~/.thunderbird/ remote1:~/.thunderbird/\nrsync -avz -e ssh ~/.thunderbird/ remote2:~/.thunderbird/\n\nwhere remote1 and remote2 are whichever two systems you're not sitting at?\n", "Q: No wireless and display issues on Dell Inspiron 1210 (Mini 12) I recently upgraded a friend's Dell Mini 12 (Inspiron 1210) from Ubuntu 8.10 to 10.04 netbook edition. After installing, and performing the available updates, I'm unable to detect any wireless networks (it knows it has a wireless card, but won't list any active networks). \nThere also seems to be an issue with the display drivers: when scrolling, resizing, or drawing any windows there is a noticeable lag as I watch the screen redraw. As if there are no compatible display drivers installed.\nAll these problems go away the moment I boot up a version of 8.10. But I'd like to keep 10.04 if possible.\nAre these common problems? Everything I've read suggest this is laptop should be compatible. Any suggestions? Thanks.\n\nA: According to the Ubuntu wiki page on netbooks the display driver issue is well known. For Lucid the recommended fix is to install updated graphics drivers from a PPA.\nPer that page execute the following commands in the Terminal:\nsudo add-apt-repository ppa:gma500/ppa && sudo apt-get update\nsudo apt-get install poulsbo-driver-2d poulsbo-driver-3d poulsbo-config\n\nthen reboot to enable the newly installed drivers.\nWith wireless, the solution is less well-documented, but it looks like many netbooks have success using the Broadcom STA drivers. These can be enabled by the \"Hardware Drivers\" application (under the \"Administration\" menu).\n", "Q: After entering password in keyring box the desktop freezes I'm new to Ubuntu and I'm afraid I've done something really stupid.\nAfter booting, When prompted to enter a password to unlock my login keyring, I tried to enter my password, but it won't let me.\nI can move my cursor but everything else is frozen.\nI tried to access the terminal by using Ctrl + Alt + F2, I entered my login and password from there and it worked, I just don't know what to do afterwards.\nDon't know what other information I can provide other than the fact that I am using Ubuntu 10.04\n\nA: Switch to X (the graphical interface that is frozen) usually by typing Alt+7 and then type Alt+SysRq+k .\nThis will kill X and it will restart. This is kind of a \"nasty\" solution but without additional details and debugging is the best I can offer.\n-- or --\nlogged in on a virtual console (or remotely) type sudo service gdm restart\n\nA: Have you tried just pressing Escape?\nSeems silly but I used to have something like this happen to me. Gnome would load up and a keyring unlock prompt would show. If I entered within a minute, fine. If I took too long the system would focus on something else (that I couldn't see) and the mouse or keyboard wouldn't let me move back to unlock it.\nOne day I mashed the keyboard in frustration, hit Escape by accident and the keyring box reloaded, allowing me to type its password.\nI've since found that the reason the login pops up is because of network-manager. I've changed all my connections so that \"Available to all users\" is checked and now I don't get any annoying popups. I'm told removing the password from the keyring is another solution but it's less secure.\n", "Q: How can I access system mail in /var/mail/ via thunderbird? I've got cron jobs sending mail to my user at /var/mail. I know how to access that at the command line with the mail command. But, while a big command line fan, I do not like reading mail (even system mail) that way.\nMy mail client of choice is Thunderbird. Can I read /var/mail messages in Thunderbird? How?\nI'm running Ubuntu 9.04 and Thunderbird 2.0.0.24 (though I'm soon to upgraded to 10.04).\n\nA: In Ubuntu 10.04, with Thunderbird 3, the option is accomplished by:\n\n\n*\n\n*Select Edit,   Account Settings \n\n\n*Choose Account Actions,   Add other account\n\n\n*Select Unix Spool (Movemail).\n\nThe UI to access this menu is slightly different in Thunderbird 2, but I didn't have it handy. \nIn Thunderbird 2, do the following, adapted from the Gmail FAQ:\n\n\n*\n\n*Click the Tools menu, and select Account Settings..\n\n*Click the Add Account... button to launch Account Wizard.\n\n*Select Movemail from the list. \n\n", "Q: How do I troubleshoot booting into black screen? \nPossible Duplicate:\nMy computer boots to a black screen, what options do I have to fix it? \n\nI installed Lucid Lynx over PXE onto this dell server seemingly successfully, but booting from the HD results in a black, unpowered screen.  There appears to be no network connectivity to the box either.  It may have landed at a textual busybox type prompt, but I can't see it.  Ctrl-Alt-Delete seems to reboot.\nOn my last attempt I held shift and the grub menu came up, but recovery mode produced the same results.\nShould I drop into the grub prompt and give the kernel a magical boot option?  Should I boot from a rescue cd and munge some bits on the HD?  Give up and install windows?\n\nA: Here are a couple of \"magical boot options\" to try:\n\n\n*\n\n*nomodeset\n\n*i915.modeset=0 xforcevesa\nI'd remove quiet splash when trying these and only one at a time, not together as they'll likely conflict.\n\nEdit: for an explanation of how to use these:\n\n\n*\n\n*When booting, hold left-Shift\n\n*Highlight the first option and press e\n\n*Go down to the line that looks like:\n/boot/vmlinuz-3.0.blah-generic root=UUID=blah ro quiet splash\n\n\n*Replace quite splash with your boot option of choice.\nIf that works out well, you can make the changes to /etc/default/grub by editing the GRUB_CMDLINE_LINUX_DEFAULT value. After saving, run sudo update-grub.\n\nA: It is likely to be related to plymouth/mountall check the following blog entry for some tips:\nhttp://handypenguin.blogspot.com/2010/04/when-recovery-mode-fails-to-boot.html\n", "Q: How can I disable Ctrl+Q for all applications (system wide)? A lot of applications like Firefox, Chrome etc, get closed when I accidentally press Ctrl+Q instead of Ctrl+W because of the proximity of the Q and W keys on the keyboard. Is there a way this shortcut can be removed or reset on a system wide basis?\n\nA: The best way is to disable the keyboard setting in your specific application. For Firefox there is an extension keyconfig. This allows you to change keyboard settings.\nIf you want to disable Ctrl+Q for your whole system, I would suggest to make a new setting:\n\n\n*\n\n*Go to System -> Preferences -> Keyboard settings\n\n*Click Add\n\n*Give it a name like fake setting and enter /bin/false as command. Apply your changes.\n\n*Click on 'Disabled' and press Ctrl+Q.\n\n\nNow you should have a new entry with your applied name and your keyboard setting. Every time you press Ctrl+Q your system will run the command /bin/false which basically does nothing. So this is a workaround to disable the setting.\n\nA: Probably inserting the shortcut under System -> Preferences -> Keyboard Shortcuts and \"disabling\" it should do the trick.\n\nA: You can go to System → Preferences → Keyboard Shortcuts and assign this combo to an unused action. For example I assigned Ctrl+Q to switch to workspace 12 (no, I don't have 12 workspaces).\nAs a result this system wide setting overrides application one and Ctrl+Q no longer closes Firefox (likely the combo never reaches Firefox). It just does nothing.\n\nA: For newer Firefox versions, you can disable it as follows:\n\n*\n\n*Go to about:config.\n\n*Set browser.quitShortcut.disabled to true.\n\n*Restart the browser.\n\nFor other applications, the steps will differ. Chrome no longer closes on Ctrl+Q, so there is no need to change anything there. Note that in many other applications, Ctrl+Q is a useful shortcut, so disabling it system wide would break that functionality.\n\nA: If Ctrl + Q closes the keyboard settings window, like it did for me, youi can do the following:\n\n*\n\n*Set the shortcut to another value.\n\n*Close the window and wait until the updated shortcut appears somewhere in ~/.gconf/desktop/gnome/keybindings/*.\n\n*Open that file and edit the stringvalue of that command to read &lt;Primary&gt;q.\n\n*Reboot the PC.\n\nThis worked for me as opposed to the accepted answer.\n\nA: Here is a command-line version of the already-supplied GUI version. On some systems Ctrl+Q will close the accelerator input window without setting the shortcut, so this can be needed:\ngconftool-2 --type string --set /desktop/gnome/keybindings/inhibit_ctrl_Q/name \"Inhibit Ctrl+Q\"\ngconftool-2 --type string --set /desktop/gnome/keybindings/inhibit_ctrl_Q/action /bin/false\ngconftool-2 --type string --set /desktop/gnome/keybindings/inhibit_ctrl_Q/binding \"<Primary>q\"\n\nNote that this solution is for GNOME 2/Unity. A similar solution should be possible with gsettings for GNOME 3.\n\nA: My current workaround is to create a new shortcut in System Settings → Keyboard → Shortcuts. If the shortcut is accidentally pressed, we receive an informative message.\n\n*\n\n*Title: Quit Prevention\n\n*Command: notify-send 'Dear idiot' \"Don't press ctrl-Q\"\n\n*Shortcut: Ctrl+Q\nThis disables the command system-wide, however, which might be an acceptable tradeoff depending on your use case.\nThe above is Tested in Ubuntu 16.04.\n\nA: On Linux with Firefox Quantum, there is currently a bug that prevents extensions and explicit configuration from changing a built-in shortcut such as Ctrl+Q.\nA workaround is to block it at the system level by e.g. installing the script from https://github.com/sasawat/firefox-ctrl-q-workaround and assigning it as the action of Ctrl+Q as a global shortcut.\n\nA: For me, disabling the Ctrl+Q shortcut system-wide is not the perfect solution, because it prevents applications other than Firefox, Chrome etc., to be notified when you use that shortcut. For example, IntelliJ IDEA uses Ctrl+Q as a default binding to show quick documentation pop-up.\nIf you are looking for a Firefox-only solution, I highly recommend Disable Ctrl-Q Shortcut plugin. In my opinion it's a better option than keyconfig mentioned by @qbi because its source is available on GitHub, while keyconfig is available only as a binary.\n\nA: My way is going to System → Preferences → Keyboard Shortcuts (yeah I know it's not there). Here you add one more shortcut with the Name \"Do nothing\", with a random Command with the Shortcut Ctrl+Q. Then the deadly combo should not bother you anymore anywhere.\n\n", "Q: How can the font size in empathy be configured? Empathy uses a very small font size. I'd like to have some larger font. But the system setting has no entry for fonts. How can I use another/larger font in empathy?\n\nA: This bug has been reported. However, if you are using the adium theme there is a workaround here.\n", "Q: How long till a package shows up in the repository? A package was recently added to Ubuntu. (It was synced from Debian.)\nI searched for it on http://packages.ubuntu.com, but it isn't showing up.\nHow long does it take?\n\nA: The packages.ubuntu.com website for maverick is not working (yet), i.e. you can use it only to search for packages in releases <= 10.04. If you install the devscripts package you can use the command rmadison:\nrmadison stackapplet\n\nwill show you all versions in the repositories:\nstackapplet |    1.2.0-1 | maverick/universe | source, all\n\nApparently it's there now.\n\nA: It's in there now. At least it's on the main server.\nI added the maverick universe repo to my Lucid install and this is what I saw:\noli@bert:~$ apt-cache policy stackapplet\nstackapplet:\n  Installed: (none)\n  Candidate: 1.2.0-1\n  Version table:\n     1.2.0-1 0\n        500 http://gb.archive.ubuntu.com/ubuntu/ maverick/universe Packages\n\nI suspect http://packages.ubuntu.com -- like any ubuntu machine -- only updates every so often so will often lag behind.\nIf you can't see the package, your local repo might be behind the rest. Try changing to the main repo which should be the first to update.\n\nA: packages.ubuntu.com for maverick is broken due to a bug which is still in the process of being fixed.  It should take only some time to get into Ubuntu.  Meanwhile, you can also look at launchpad.net/ubuntu/+source/package-name for example https://launchpad.net/ubuntu/+source/stackapplet\nrmadison is another great tool which can help you know the status of a package.\n", "Q: What Ubuntu / Linux podcasts are most helpful? Which podcasts in either the Ubuntu or general Linux categories are the most helpful or most enjoyable.  \nOne podcast per answer which could be voted independently would be useful and possibly mentioning if it is highly technical, generally informative, or just fun.\n\nA: Full Circle Podcast by the Full Circle Magazine.\n\nA: I like FLOSS Weekly which is about Free Libre Open Source Software. This is hosted by Leo Laporte and Randal Schwartz along with a guest host (sometimes). It is not exclusively on Linux, but they are a great introduction to a lot of the Open Source software thats available out there.\n\nA: The Tuxradar Podcast by some editors of Linux Format Magzine is a show recorded every two weeks which includes some news about the Linux and Free Software world, a lot of commenting and discussing and a lot of fun (jokes, challenges) too. The guys don't take themselves too seriously and you shouldn't do either.\n\nA: I also want to add a plug for the Ubuntu UK podcast. Produced by the UK loco team, more family friendly, but less controversial. \n\nA: Not exclusively Ubuntu but Dan and Fab at Linux Outlaws have a great podcast. Recorded live usually on a Monday evening (UK time) \n\nA: The Linux Action Show is a lot of fun.\n\nA: While no longer in production, the Linux Reality podcast is an excellent way to improve your understanding of Linux and the concepts surrounding it. The full show is 100 episodes long, and each covers a different part of Linux.\n", "Q: How can Evolution connect to Exchange via the OWA connector? I have been trying for a while to get Evolution to connect to my Exchange account. I think the complication is the that the OWA url is https://owa[...]. \nI am able to connect with Android phones, iPhones, etc., but I can't do it with Evolution.\nIs there a way to make this work?\n\nA: You'll need to use the evolution-mapi plugin - It took me a good long while to get it setup properly with my machine at work. I was able to get calendar and mail to sync properly. Some interesting things I had to do:\n\n\n*\n\n*For server I had to use the IP address of the Exchange server\n\n*I had to use the Exchange MAPI as server type, if you're using Exchange 2003 or lower the Microsoft Exchange plugin will work fine.\n\n\nA: I've also failed to configure Evolution with an Exchange server (2007, I think). \nDavMail came ot the rescue! http://davmail.sourceforge.net/\nDavMail is a gateway that interfaces with an Exchange server and provides Evolutions with standard IMAP, Pop, CalDav etc interfaces. \nHope it helps\n/N\n\nA: You should normally access your 2003 Exchange through the OWA, but beware, Evolution in Maverick is critically bugged regarding the Exchange connexion. There's an open bug on the Launchpad about it : https://bugs.launchpad.net/ubuntu/+source/evolution-exchange/+bug/606822\n", "Q: \"Ubuntu is an ancient african word, meaning 'I can't configure Debian.'\" in Urban Dictionary In Urban Dictionary, Ubuntu is defined as\n\nUbuntu is an ancient african word, meaning \"I can't configure Debian\".\n\nI'm confused about the meaning. How true is this sentence? Are really Ubuntu and Debian so close to each other?\n\nA: The joke is that, back then, GNU/Linux was \"for uber-geeks only\", and Ubuntu pushed to become the \"newbie-friendly\" distro. Nowadays, while you still shouldn't suggest Knoppix or Gentoo to your grandma, most distros have become much friendlier than before.\n\nA: No, this is a joke.\nUbuntu (the word) \"is an ethic or humanist philosophy focusing on people's allegiances and relations with each other\". It is often translated directly as \"humanity towards others. The word has its origin in the Bantu languages of southern Africa\".\nUbuntu (The OS) is built on the foundation of Debian. It is a fork of the Debian project. Ubuntu shares many of the packages and components of Debian.\nUbuntu's goal is to be a user friendly Linux distributions for those unfamiliar with Linux in general. \"Ubuntu has a strong focus on usability and ease of installation\" whereas \"Debian is known for relatively strict adherence to the Unix and free software philosophies\" and will sacrifice user friendliness in favour of those ideals.\nHence the formulation of the joke. If you are new to Linux and are unable to configure Debian, you may instead choose Ubuntu. They have taken a inconsequential fact about the Ubuntu distro (it's naming based on an African word) and altered it to poke fun at the project goals, just like advanced users often ridicule beginners (or newbies) in many areas of proficiency.\nUrbanDicionary.com - In their own words \"A website with a brilliant concept that could have become great if it hadn't been overrun by a mob of losers, who spend their days trying to feel important and popular by insulting everything else on God's green earth.\"\n\nA: The term Ubuntu has been explained in this question What does “Ubuntu” mean?\nYes. Ubuntu is based on Debian. The packages used are to a high extend identical. Ubuntu has in contrast to Debian a regular release schedule, and is more focused on stability and the needs of end users. Debian has more freedom for experimental packages and is a very good distribution for developers.\n\nA: Not true at all.\nActually Ubuntu means (from the site): \n\nUbuntu is an ancient African word meaning 'humanity to others'. It also means 'I am what I am because of who we all are'. The Ubuntu operating system brings the spirit of Ubuntu to the world of computers.\n\nAnd also from ubuntu site: \n\nDebian is 'the rock upon which Ubuntu is built'.\n\nSo, Ubuntu is a Linux Distribuition derived from Debian.\n\nA: Urban Dictionary isn't really a source for correct definitions - while \"humorous\", that's not really what it means.\nWhat Ubuntu means has been well covered here: What does \"Ubuntu\" mean? - Ubuntu was once considered a flavor of Debian and that's where it's roots are. Debian, in my opinion - back when Ubuntu came about - was more of a start towards desktop Linux and still had it's roots very much in Servers.\nUbuntu project took what Debian had going for it (Package Management, Philosophy, etc) and spearheaded on the \"Linux for Humans\" and not for servers campaign, and here we are today.\n\nA: Thought I would throw in this short clip of Nelson Mandela's definition of Ubuntu. \n", "Q: Are there any packages in Ubuntu that allow routing on application layer level? I would like to route packages received by a VM host to different VM guest, on basis of application layer, in particular domains given in urls. It is impossible to route on network layer level, since IP address limitations (to the outside) do not allow this.\n\nA: You mention URLs so forgive me if I make an assumption that this is web traffic. Could you put an apache + mod_proxy on the domU / VM host and direct the traffic based on URL that way?\n\nA: nginx is a light-weight proxy that can do this with web and e-mail traffic.\n", "Q: How can I prevent or diminish Nautilus freezing problems? After upgrading the Ubuntu to 10.04 my Nautilus file manager gives lot of problem. Nautilus freezes after few minutes of start. I tried with Thunar, but I did not like that. Now I have Dolphin too, when Nautilus goes problem, then I start work with Dolphin. I do not like this. I want to work on Nautilus or equivalent one.\nI work with lot of images using GIMP and Inkscape. I tried many things including reinstalled the OS for 6 time in 4 months. I cannot leave Ubuntu, but I am limbing. Some body help me to fix it.\nThanks in Advance.\n\nA: You need to first diagnose your problem.\nTry launching Nautilus from a Terminal by typing nautilus and pressing enter.\nAny errors or warnings will be displayed in the terminal and this may help you to find the issue. \nYour issue may already have been reported as a bug.\nSee Launchpad for a list of bugs in nautilus.\nOnce a solution is found for one of these bugs, they will be fixed, but it may take a long time for the bug fixes to appear in Ubuntu. Often, however, people will post temporary solutions in the comments of a particular bug.\nAlso, PCManFM is another option for an alternative file manager. It is similar visually to nautilus, fast, but with a few less features.\n\nA: You might want to disable preview for images or other multi-media things. Such previews need memory as well as cpu power, which can lead to freezing when either the cpu is overloaded, or a lot of swapping occurs.\n", "Q: How can multiple private keys be used with ssh? I was able to setup ssh to use private/public key authentication.  Now I am able to do\nssh user@server1\n\nAnd it logs on with the private key. Now I want to connect to another server and use a different key.  How do set it up so\nssh user@server1\n\nuses privatekey1\nssh user@server2\n\nand uses privatekey2\n\nA: You can set this up in your ~/.ssh/config file. You would have something like this:\nHost server1\nIdentityFile ~/.ssh/key_file1\n\nHost server2\nIdentityFile ~/.ssh/key_file2\n\nman ssh_config is a reference\n\nA: There are a few options.\n\n\n*\n\n*Load both keys into your ssh agent using ssh-add. Then both keys will be available when connecting to both servers\n\n*Create your $HOME/.ssh/config file and create a Host section for server1 and another for server2. In each Host section, add an IdentityFile option pointing to the appropriate private key file\n\nA: Besides the (preferable) option of adding both keys in $HOME/.ssh/config (note that this requires appropriately setting attributes of $HOME/.ssh and $HOME/.ssh/config), you can use\n$ ssh -i privatekey1 user@server1\n\ne.g.\nI learned this by way of solving this more complex situation:\nMultiple ssh access types from a given user1/client to the same user2/server\n", "Q: Is there any simple way to install tarballs? Most Linux software is packaged in tarballs. All of them require but a few commands to compile and install them. \nMy question is; we have gdebi for standalone debian packages, so why not an app to install tarballs the same way? Why is such an apparently simple process not automated? Why must we continue to intimidate and drive away new users with ideas of compiling software?\n\nA: Instead of spending time making installation of tarballs easier, it would be more beneficial overall to spend it packaging the software for Debian/Ubuntu. Not only will this enhance the offerings of Debian based distributions such as Ubuntu, it will also correctly install dependencies\n\nA: tarballs are usually highly customizable. even though with 90% of them you just go ./configure && make install, some others require custom parameters or in the worst case they use different steps to buid the application.\nimho as a normal user you should not have to deal with tarballs. you might be better off checking if it's in someone's repository first.\nthe problem with tarballs (as an install method for endusers) is that:\n- if something goes wrong you quickly need to be very tech savy to fix it\n- doesn't necessarily adhere to the folder structure of your disto\n- not always possible to easily uninstall software again.\nto your second question: yes, this process is automated with debian-source packages or rpm-source packages. but those aren't problematic and i think they can just be opened in gdebi. i am not sure you know, but a tarball is the easiest way a developer can get their code out into the world. no matter what mess they have in their project, just zip up the source and upload it--- that's the only requirment i know for a tarball: it must contain the source of some app and eventually provide a build script. \nso even though its not going to work to use those tarballs directly, i think you're touching on a very important issue here: linux packaging is a mess. its a lot of work even for a single distro and it's practically impossible for a small project to maintain packages for a variety of distros. \nthere were (and still are) a bunch of projects that tried to unify packaging across distros, but afaik this never went anywhere really. at least nothing that is as common as an msi package for windows or a dmg on the mac. \ni know this answer must be frustratring, but if i haven't missed a revolution recently than that's what we're stuck with for now.     \n\nA: Checkinstall can generate debs from source. (It can also generate RPM's and slackeware packages)\nYou run ./configure then\ncheckinstall -D \n\nto create a debian package.\nI think the tool is mainly meant to allow you to cleanly upgrade and remove software on your own machine and not for creating distributions for others - but if you don't have complex dependancies, it should do what you want.\n\nA: You could write a little bash script if you're doing this a lot...\n#!/bin/bash\nFILE=$1\nDIR=\"${FILE%.tar.gz}\"\ntar -xzf $1\ncd $DIR\n./configure\nmake\nsudo make install\n\nCall it tarinstall (or something), put it in your path and then just do:  \ntarinstall thisnewpackage.tar.gz\n\nAlthough I do agree that it's much better to be using a packaging system like .debs or .rpms.\n\nA: Those processes are automated.  You get them in .deb or .rpm packages mostly.  The only difference (at the level you're thinking) between a tarball and a .deb is the compilation.  Tarball's generally contain source code and make files, not pre-compiled binaries (though they DO sometimes contain those too).  .debs are pre-compiled across multiple architectures.\nHere's an analogy for you:\na .deb is a truck carrying a whole car.\nA tarball is a truck carrying a box of car parts and a manual telling you how to assemble the parts to get the car.\nSo, when you install something from a .deb (or a .rpm on those \"other\" distros) you're installing the same stuff that you'll get in that tarball, just with the work already done for you.\nThough I disagree with txwikinger about progression/regression.  There's nothing wrong at all with tarballs and I use them frequently to wrap up code or screenshots, log files, or what have you to send to people for various reasons.  I also download source tarballs to read the source code for a program so I can see what's going on if I run into a problem.  \n\nA: Different apps are written by different developers with different standards.  It would prove to be a very difficult task to have one application to install all tarballs.  Instead we have debs which are precomplied.   Tarballs also provide a problem of dependency which debian and derivatives have fixed with apt and aptitude that would be next to impossible to achive with only a tarball.\n\nA: As a normal user you probably don't want to go around installing tarballs.  The Debian and Ubuntu teams spend a lot of time customizing and verifying upstream packages before they put them into the repository.  Making a package is a big hairy mess of dependencies and distribution specific install scripts. There's just no simple way to automate the process.\nHowever if you're a programmer or you are trying to contribute to an upstream project, you'll need to install official tarballs eventually.  Although not automatic, there are a few tools that help make the process easier.\nIf you just want to patch some bug in a program you've installed, you can get the source code with apt-get source packagename and hack away.  If you want to send that patch upstream though it's better if you start with an upstream tarball.\nMost projects out there are using autotools which automates a fair amount of compile-time decisions.  You can usually tell if a project uses autotools because there is a configure script in the folder.  If there is you can build and install the package using one line ./configure && make && make install.  Unless you've built the package before though, it will probably fail because you are missing some compile-time dependencies.\nIf the package you are trying to install is already in the Ubuntu repositories you can get APT to automatically install all the libraries you need to compile the tarball with apt-get build-dep packagename.  If there are no new dependencies this is usually all you need to do before you can compile the program.  If it's not in the Ubuntu repositories you are on your own, check the documentation of the project to find out what it needs.\nOne problem with the ./configure && make && make install procedure is that there's not usually a make uninstall.  There's a program called checkinstall that will run make install for you and register the package in APT so that you can uninstall it later.  checkinstall doesn't always work though, and depending on how important the package you are installing is to the system, it could be very dangerous.\n\nA: .deb packages are tarballs with the necessary information to do proper package management added to them.\nIf you just install a tarball, how do you make sure that all dependencies are met? All the necessary libraries are installed?\nHow do you want to remove a package that is installed by only the tarball? \nYou lose all the safeguards that the debian based package management gives and that in particular makes it so easy to install software by new users. To make it easier for them to install tarballs as they are would be a step backwards, not progress.\nThis aside, how can \n./configure && make && sudo make install\n\nbe further simplified? (If you consider a user that needs to be able to deal with the issues raised above)\n\nA: As in the above posts checkinstall will help you to install and un-install source application in an efficient way. Since it creates native packages (rpm for redhat flavours and deb for debian flavours including ubuntu) it is very easy to manage these packages with native package manager such as software center. Check this article for more info: findasolution.in checkinstall package managment made easy in linux . It is originally return for Centos but will also work in ubuntu. \n", "Q: How can I add the Network Manager Applet to the panel after removing? In rearranging the panel, I removed the Network Manager Applet. I tried to add it back, but it doesn't show up in the list (Add To Panel). I can start it up and see it as a running process (nm-applet), and I'm still connected to the internets, but I don't know how to get the panel icon back.\n\nA: System -> Preferences -> Startup Applications\n\nCheck \"Network Manager\"\nIf it's not in the list then add nm-applet --sm-disable\n\nA: You have to add the Notification Area applet to the panel. The network manager will show up there.\n", "Q: alternate look for the GNOME main menu On my desktop computer, the GNOME main menu on the panel has a different look: it's just one \"Ubuntu logo\" icon; clicking on it displays the \"Applications\" menu on top, with \"Resources\" and \"System\" being two sub-menus (last two entries). \nI actually like this alternate style more than the default one, and would like to have it on my laptop as well.  What should I set/alter to have the alternate look on another computer?\n(The desktop has always been this way -- I guess it's because it was a Debian machine before, and I installed Ubuntu without reformatting /home.)\n\nA: *\n\n*Right click on the panel. \n\n*Click 'Add to Panel...'. \n\n*Select 'Main Menu' (not 'Menu Bar', this is the default menu applet). \n\n*Click 'Add'.\n\n\nYou can remove the old menu by right clicking it and clicking 'Remove from Panel'.\n", "Q: How can I set up an authenticated encrypted SMTP server? I'd like to set up authenticated, encrypted SMTP on my remote Ubuntu server, how do I do that? \nIt's just a personal server, so I'd like a cheap option, i.e. not buying SSL certs - self-signed will do for now at least.\nUpdate: I'm a little tied to exim as I've got some other stuff configured in that.\n\nA: I would suggest Postfix. This is a mail server which is very easy to set up (in my opinion). You'll find some useful documents:\n\n\n*\n\n*Postfix SMTP AUTH (and TLS) HOWTO\n\n*Postfix TLS Readme\n\n*Postfix-Wiki\n\n*Postfix documentation site\nThose documents cover the basic setup of Postfix. If you encounter problems you should come back (or better, ask Superuser).\n\nA: You can do that by using postfix and dovecot packages. There are lots of detailed instructions available. Just to mention a few:\nhttp://johnny.chadda.se/article/mail-server-howto-postfix-and-dovecot-with-mysql-and-tlsssl-postgrey-and-dspam/\nhttp://www.debianadmin.com/debian-mail-server-setup-with-postfix-dovecot-sasl-squirrel-mail.html\nhttp://rimuhosting.com/support/settingupemail.jsp?mta=postfix\nhttp://www.linuxmail.info/\n\nA: Install dovecot-postfix package and you are done.\n\nA: One place to get started with encrypted authentication for exim is here:\nhttp://www.debian-administration.org/article/280/HowTo_Setup_Basic_SMTP_AUTH_in_Exim4\n\nA: Install the exim4-daemon-light package. Debconf will ask you some questions about the setup of the server.  The installation should auto-generate some self-signed certificates, if it doesn't use the /usr/share/doc/exim4-base/examples/exim-gencert script to generate one, or do it by hand.\nInstall sasl2-bin to get a saslauth daemon. Then read /usr/share/doc/exim4-config/README.Debian.gz, in particular the 2.2.2. and 2.3. sections.\nThis will explain the rest, but briefly, edit /etc/exim4/exim4.conf.localmacros to include\nMAIN_TLS_ENABLE = true\n\n", "Q: Disable password access through SSH? I'm setting up a server for backing up my desktop box remotely. I want to prevent remote password access to the server, permitting only users with private keys (AKA my desktop box) to access it. How can I block remote password access while allowing physical password access to the server?\n\nA: Just insert the following to the sshd config on the server (/etc/ssh/sshd_config)\nPasswordAuthentication no\n\nYou might need to reload the ssh service\nsudo service ssh reload\n\nThat should do the trick ;)\nFor more options type man sshd_config in to your terminal.\n\nA: Just a note about SSH access to servers - you may also want to disable the root user from ssh, this way at least hackers will have to guess the username as well.\nPermitRootLogin no\n\n", "Q: Looking for CAPS LOCK/NUM LOCK and HDD activity indicators I've purchased a Dell Inspiron 1545 for my wife. Due to some really bad judgement from the design team, the only indicator you have is the power one.\nWhat do you guys recommend in terms of having some nice indicators for CAPS/NUM Lock and HDD activity? I just feel so lost without some quick visual clue on those items.\n\nA: There is an applet you can add to the panel to do this.\nLook for the \"lock-keys-applet\" package.  You can find this in the Software Center (Applications - Ubuntu Software Center) by searching for \"lock keys\" or just clicking on that link.\nOnce you have installed it, right-click on a panel at the top or bottom of the screen and select \"Add to Panel...\" and selecting it.  (Again you can search for \"lock keys\" to show it quickly.)\nThis will show the status of caps lock, num lock, and scroll lock on the panel.\n\nA: For the caps lock and num lock you can use the Indicator-keylock package. It looks like this:\n\nAnd instructions for installing are available at: http://www.webupd8.org/2010/07/indicator-keylock-displays-keyboard.html\nFor the hdd activity monitor you can use the system monitor applet available in the gnome-applets package. Go to preferences and choose to display disk activity.\n\nA: Not really an answer, but I'd just add a system monitor to the panel.  Showing it in the leds would be kind of cool: and it's technically possible, I just don't know of pre-canned code to do it.  You can script it using xset -led.\n", "Q: Stuck at boot time in the splash screen prior to gui login dialog This is an issue I've been facing for a long time. However I am still able to use my ubuntu via recovery mode, where I log-in to the shell, where I type startx. Sometimes when i restart, it goes in clean. But most of the time I get hung up with the splash screen.\nWondering if this is an issue with mount: heard that ubuntu will check the hdd once after every 30 mounts. I seem to notice it has not being doing that for a while.\n\nA: Boot in recovery mode\nTry pressing Esc right after you BIOS screen to access the grub menu, there you choose \"Recovery mode\" this will give you more debug messages. When the recovery menu appears you can \"Drop to root shell prompt\" and then look at the logfiles in /var/log folder, especially dmesg.0 (Kernel debug messages from last boot) this might point you in the right direction.\n\nA: Although this is not a technically a 'solution', try booting in from a different Kernel if you have any. I also have this issue but been able to boot from a different Kernel. (Primary Kernel: 2.6.32-25-generic, Secondary: 2.6.32-21-generic -- Secondary Works!)\n\nA: Glad to know I'm not the only one.  I have gotten this problem a number of times too. No amount of hitting ESC key or any other key combination works. The only way is to do a hard reboot. I've always wondered about it but haven't bothered so much since it still works after the forced reboot. \n", "Q: How do I remove an application? How do I remove an app (Tonido) in Ubuntu?\n\nA: If you had installed the app through the normal means, I mean the Software Centre, synaptic or a .deb file, etc... you need to search for the app in the Software Centre and click uninstall.\nYou can also uninstall it from the command line using\n$ sudo apt-get remove appname\n\nThere are a couple of advanced options, like purging (removing config files) and removing dependencies. You will need to use synaptic or the command line to use them.\nIf you used some other method of installation, you will need to tell us about how you installed it to be able to help you.\n\nA: Ubuntu offers several ways to remove an application. For all further explanations I assume that you installed some Ubuntu package. So the explanation is not valid if you installed software via ./configure && make && make install or used some kind of app specific setup wizard.\nSoftware-Center\nUbuntus Software-Center (Applications --> Software-Center) lists software which is currently installed on your computer. You can use the search box to look for a specific application. Click on the application you wish to remove and click on the Remove-button.\nSynaptic\nAnother way to remove software is by using Synaptic. Click on System -> Administration -> Synaptic. A new window open and you can enter some search term into the box. So you will narrow down the list of software. After you found the software to remove right-click on the package and select Mark for Removal. Then apply the changes. Synaptic will show you a window with the changes it wants to make and if you apply the software will be removed.\nAptitude\nAptitude is a text-mode software. You will need to open a terminal and enter sudo aptitude. Aptitude shows you a textual interface. You can search for your software by typing a slash (/) and entering some part of the name. If the software doesn't show the software in the first place (some packages have similar names) click n. If you find the package you want to remove enter -. After you found all your software enter g. Aptitude will show you all software it wants to remove. If all is correct enter g again and the software will be removed.\nAptitude can also be used via commandline. If you know the exact name of the software type:\naptitude remove packagename\n\nYou can also use aptitude purge packagename. Aptitude will then remove anything which is related to the software (config files, database files etc.)\napt-get\napt-get is a full command line program. If you want to remove software enter:\napt-get remove packagename\n\nYou can also use purge as in aptitude.\n\nA: sudo apt-get remove tonido\n\n", "Q: What spam filter should I use with Evolution: Bogofilter or SpamAssasin? The Ubuntu standard mail client Evolution provides two plugins for spam filtering:\n\n\n*\n\n*Bogofilter\n\n*SpamAsassin\n\n\nWhat is the difference? Are there any advantages / disadvantages (speed / accuracy / ...)? \nNote: I'm mainly interested in \"out-of-the-box\" performance, not in advanced configuration of either of the spam filters.\n\nA: Well in a perfect world, you'd probably run emails through both before emails got anywhere near a client machine... But that's a discussion for another time.\nSimply put SpamAssassin is a safer choice. It might not catch as much spam, (it probably will) but you're probably less likely to get false positives. That for me is a very important part of performance. \nBut both systems need to be told things to sort the ham from the spam. You can't really expect to just start using something like this and get 100% accuracy. Pull in things like spamhaus to help. Train it by marking files properly.\nIf you can spare any time to configuration, use this generator to quickly set some ground rules.\n\nA: I use Bogofilter as my client filter plugin and Spamassasin at the server. So I have best of both worlds ;).\nAnyway I believe that Spamassasin works better without training, that's why I put it on the server. It just a feeling, totally subjective, based just on personal experiences, so feel free to ignore.\n", "Q: How can I troubleshoot the lack of detection of the D-Link DWM-152 (HSDPA USB modem)? I just installed Ubuntu 10.04 LTS.\nHowever, my D-Link DWM-152 (HSDPA USB modem) is not able to be detected.\nI am having exactly same result as c_siswan\nhttp://ubuntuforums.org/showthread.php?t=1476983\nCan anyone suggest me a solution?\n\nA: Give sakis3g a try. If it works than we know the modem works on Ubuntu and it's just a matter of including it in usb_modeswitch data or toggling it manually and we can work towards that.\n\nA: Go to www.dlink.com, support+download and then search for DWM-152 and update your firmware. Have a look at this Blogpost saylinux.wordpress.com/2010/07/20/using-d-link-3g-usb-dwm-152-with-ubuntu-10-04/\nMaybe it works with network-manager if you try the newest developer version from here: https://launchpad.net/~network-manager/+archive/trunk\n", "Q: Are there anywhere instructions explaining how to troubleshoot sound problems on the Ubuntu desktops? I would like to have a general list of steps I can do to troubleshoot problems with sound.\n\nA: Yes, there are: https://wiki.ubuntu.com/DebuggingSoundProblems\nThe first step on a current (10.04) distribution should be to run:\nubuntu-bug audio\n\nin a terminal or after pressing Alt+F2.\n", "Q: How can I hide directories or files without changing their names? The OCD in me wants directories I do not like the name of to be hidden since I do not interact with them directly.\nHow can I hide directories without using the dot notation?\n\nA: Assuming you only care about hiding the files from showing up in nautilus, there is a bug on the GNOME Bugzilla about this. However, currently, that bug has not been resolved.\nThere is another way to hide files from appearing in nautilus. If you create a file called .hidden inside of a directory, any filename listed in the file will not be displayed.\nFor example, below is a .hidden file that I created. This file will hide any files or folders named b or e located in the same directory as the .hidden file.\n\nBelow is a screenshot of the folder that contains the .hidden file. Note that you only see three files: a, c, and f. You do not see the .hidden file due to the '.' at the beginning of its name.\n\nThe screenshot below is of the same folder as before. However, this time, I hit Ctrl+H to cause nautilus to display hidden files and folders. Notice how there are several additional files that show up. You now see several files that were previously hidden due to having names that began with a '.'. There are also now files called 'b' and 'e', which although not having names beginning with a '.', were hidden due to being listed in the .hidden file.\n\nFiles mentioned in the .hidden file will only be hidden in nautilus. Tools like ls will still display them. The .hidden file is also not recursive. It only affects files in the same directory as the .hidden file is in.\nSome people on the forum have gone ahead and created scripts for nautilus that make it easier to add files to the .hidden file. The first script includes a nice explanation about how to install and use the scripts, but the second script is a bit cleaner and shorter. Feel free to use either script to make your life a bit easier.\n\nA: From the command line you could try something like this in your .bash_aliases file:\nlsh() {\n    [ -s .hidden ] && echo \"lsh: hiding $(wc -l .hidden) patterns\" && ls $@ | grep -v -F \"$(cat .hidden)\";\n    [ ! -f .hidden ] && ls $@\n}\n\nThis adds a new command lsh that behaves like ls, but hides files listed in a .hidden directory. (It also is missing some of its features like  colorized output and column listings.)\n\nA: If you want to hide files, you are only left with renaming them with a preceding ., as is *NIX convention. Sorry, but that's it.\nHowever, if you would like to hide the content of the files/directories, you can do so with file permissions.\nSo say you have a bunch of files in a folder called secret_stash, you could change it so that only you (the owner) have r-x (read, execute) and everyone else has nothing --- (no access). Since r-x is the minimum perms needed to view a directory (read to access its contents and execute to be able to see them), anything inside of that folder is effectively hidden from everyone but root. \nNOTE: I'm running this demo as root, and trying to access the folder as myuser\nTo do this you run chmod 700 dirname (700 means rwx------):\n% mkdir secret_stash\n% chmod 700 secret_stash\n\nAnd here it is:\n% whoami\nroot\n% ls -ld secret_stash\ndrwx------ 2 root root 4.0K 2010-08-12 07:59 secret_stash/\n% ls secret_stash  \n./  ../  secret.txt\n% cat secret_stash/secret.txt \nTOP SECRET DATA\n\nNow and if I try to access it from myuser, attempts to access the folder or its contents fail:\n% whoami\nmyuser\n% ls -ld secret_stash\ndrwx------ 2 root root 4.0K 2010-08-12 07:59 secret_stash/\n% ls secret_stash \nls: cannot open directory secret_stash: Permission denied\n% cat secret_stash/secret.txt\ncat: secret_stash/secret.txt: Permission denied\n\nAnd now I've said the word \"secret\" so many times it's lost all meaning!!\n\nA: 1st off: if you want to hide a file from anyone: install a linux intrusion detection system. (Snort is an example) You can even hide a file from \"root\" but \"root\" will also be able to revert those setting. \n\nBut it might be easier to just set the permissions of the directory that holds the file to \"root\". Example:\n $ sudo su\n # mkdir tmp/\n # touch tmp/1\n # chown root:root tmp\n # chmod 000 tmp  \n # ls -l\ntotal 4\nd--------- 2 root root 4096 2015-08-07 06:36 tmp  \n # exit\nexit\n $ ls\ntmp\n $ cd tmp/\nbash: cd: tmp/: Permission denied\n\nAnd the file 1 is effectively hidden from view.\nDirectory will be visible; file will not be visible. \nMind though: \"root\" will ALWAYS have access to any file.\n\nTogether with the chattr you can even make the file immutable. \nsudo su    \nchattr + i {file}\n\nand even \"root\" can not alter the file -unless- the chattr is reverted (and yes \"root\" can do that). \n\nAny Keyboard Shortcut for that?\n\nNo, this is something you need to do manually.\n\nA: Unix and Linux only supports hiding folders that being with a .. \nIf you really want to get them out of the way, but want them to not have .s, put them all in a .hidden in the same directory as the file or folder you want to hide. .hidden will not be exposed by the file manager, and your files will not have a name change. \n\nA: There's also an extension for Nautilus called nautilus-hide that will allow you to hide any file or folder with a simple right-click on them.\nTo install this extension :\nsudo apt-get install nautilus-hide in a terminal,\nor search for \"nautilus hide\" in the Ubuntu Software Center.\nDon't forget to quit Nautilus after installation : Alt+F2 and type nautilus -q.\n", "Q: How can I make non-kde/non-qt application started with root privileges look integrated into my KDE desktop? I have a desktop that has both Gnome and KDE installed.\nWhen I start non-KDE applications under my user account running KDE, the application widgets obtain the same window decoration, style etc as my KDE applications.\nHowever, when I have to start an application with root privileges (i.e. via kdesudo), the style is like Gnome, not like KDE.\nWhat do I need to do to change this?\n\nA: Perhaps try copying: \n~/.kde/share/config/gtkrc\n~/.kde/share/config/gtkrc-2.0\n~/.kde/share/config/colors/\n~/.kde/share/config/kwinrc\n\nto /root/.kde/share/config/.\n\nA: It's in the docs ... \nKDE Configuration ... \nHowever, you cannot give sudo access before a user is logged in ... \nSince kdm must run before any user is logged in, it is not associated with any particular user. Therefore, it is not possible to have user-specific configuration files; all users share the common kdmrc. It follows from this that the configuration of kdm can only be altered by those users that have write access to $KDEDIR/share/config/kdm/kdmrc (normally restricted to system administrators logged in as root).\nEdit: I apologize. The answer above does not address the problem ... for clarification I believe this is a possible workaround ...\nI tried this and it seems to work ...\nsu - \n[password]\ncd ~/.kde/share/apps\nln -s /home/[user]/.kde/share/apps/color-schemes ./color-schemes\nln -s /home/[user]/.kde/share/apps/QtCurve ./QtCurve\n\n\nA: This might work. It's a bit manual and you might even need to install it if it doesn't come with the core gnome stuff but there you go.\nsudo gnome-theme-manager\n\nMy basis for this is gnome stores its theme settings in the user's home. KDE (or Kubuntu) sets you a theme close to your KDE theme but doesn't set one for the root account. By running this, you should be able to pick (or install then pick) a theme that closer matches your current KDE theme.\nEdit: Multiple other sites suggest doing this for Gnome users wanting to sync the root theme:\nsudo ln -s ~/.themes /root/.themes\nsudo ln -s ~/.icons /root/.icons\nsudo ln -s ~/.fonts /root/.fonts\n\nI'm not sure if this will work for you but it might be worth a shot as it should be automatic.\n\nA: have you tried to change the appearance in system settings with the root account?\ntry to open it login as root\n$ sudo su\n# systemsettings\n\nthen change the appearance as you like, in this case using the same settings of your account\n", "Q: Backup Software Sources In Ubuntu 10.04, when I goto System > Administration > Software Sources and goto the Authentication tab, I can view all of my keys allowing me to download from third party sources.\nHow would I back this up to copy all of my sources and keys to a new system?\n\nA: The method to backup your sources list has already been described by garbagecollector (also note the additional directory as explained by Javier Rivera). \nTo backup the trusted keys added to your system you can use the apt-key command line program. I don't know if there is a way to do this from the GUI.\nFrom a terminal you can run something like this:\nsudo apt-key exportall > ~/repositories.key\n\nThen on your other system you should be able to import that key file from Software Sources or you can use apt-key again:\nsudo apt-key add /path/to/repositories.key\n\nI only have one Ubuntu desktop system so I haven't tested this out, but I think it should work.\n\nA: From 10.04 the source list can be in different places, the file /etc/apt/sources.list as said before and all the files inside /etc/apt/sources.list.d/.\nThe keys are stored in a similar fashion, the file /etc/apt/trusted.gpg and the files inside /etc/apt/trusted.gpg.d/\nFinally you will need the info in trustdb.gpg to be able to decrypt the keys.\nYou will need to copy all these files and dirs.\nEdit: The best way to copy the keys is explained in another answer. So please copy only sources.list and all the files inside sources.list.d. I keep the info about the files placement in the case it proves useful to another person.\n\nA: I believe this would help backing up your sources.\nsudo cp /etc/apt/sources.list /etc/apt/sources.list.backup\n\nThen do the reverse when you are your new system.\nMaybe also try this software. Although I haven't used it myself.\n", "Q: How to determine where biggest files/directories on my system are stored? I was wondering how do you know where the largest files in my system are stored.\nFor example---\nDisk Space Used: 1GB\nJava: 500MB\nJava Percentage: 50% maybe represented in a pie chart. Maybe?\nI know this maybe a feature overkill. I sometimes forget having stored things and wonder why my disk is so full. \nSo basically a command that will allow me to run on the file system and provide me with information on disk space used.\nPlease and thank you.\n\nA: A useful command to that helps in cases you need to determine that for specific directories from the command line:\ndu --max-depth=1 -x -h\n\nIt gives you a list of the first depth directories and their sizes \n-x limits the analysis to one file system\n-h shows human readable k/M/Gbytes (this prevents you from sorting the output though)\n\nA: The Disk Usage Analyzer is available under Ubuntu > Accessories > Disk Usage Analyzer. It provides you with a snazzy pie graph showing what files and folders take up the most space:\n\nThe documentation on it is a little sparse, but you can find more information on the Ubuntu wiki, and the project page.\nIf you're interested in using the command line, there's du which is described here.\n\nA: Unless it changed recently, baobab only shows directories; check out kdirstat for an alternative that actually shows files, coloured by type.\nA commandline alternative is\ndu -a | sort -nr | head\n\n\nA: The other excellent pie-graph disk usage tool is Filelight. It's a KDE app, and it's available in the repositories.\n\nA: The solution that @UncleZeiv proposed is not working when there is really no more space left, since sort is using the /tmp folder when there are multiple lines to sort.\ndu -a | sort -nr | head\nsort: write failed: /tmp/sortuCYq8E: No space left on device\n\nAn alternative is a combination of the answer from @UncleZeiv and @Yoav Weiss, plus adding another path for the temporary location:\nsudo du -a | sort -nr -T /media/usb-key\n\nFinally, my preferred solution will be a human-readable one that doesn't depend on temp folder and list root directory (/):\nsudo du -ah --max-depth=1  / | sort -hr\n\n\nA: Use the Disk Usage Analyser (Applications -> Accessories -> Disk Usage Analyser):\n(The command is baobab).\nClick Analyser -> Scan Filesystem\n\nA: Another tool for this is jDiskReport (a Java app)\n", "Q: What is the difference between running VMs and a Ubuntu EC2 cloud? Does it make sense to run a cloud on only one server? If so what are the benefits?\nAre there any nice tools managing my VMs (apart from virt-manager) even if I do not use the EC2 cloud?\n\nA: As I said in another thread, when you're dealing with a single computer, can't really do \"cloud\" computing because at its core, cloud computing relies on scaling in some direction, be that more CPU power, more memory, disk, bandwidth, user capacity and to do that, you need multiple hardware units to be able to provision things...\nIn the case of the other thread, there isn't much point breaking up a server into VMs just for multiple services if they're all yours, there's just no benefit.\nBut to answer the question:\n\nWhat is the difference between running VMs and a Ubuntu EC2 cloud?\n\nElastic provisioning is probably the biggest difference. Amazon have tons of hardware that you can bind your \"instance\" to, including hot-provisioning CPU time, RAM (IIRC) with an almost infinitely scalable disk platform (S3) behind it. Traditional VMs tend to come with fixed things that can be upgraded but require a VM restart.\nA side effect of that, especially with Amazon's EC2 is you pay for what you use. This isn't always good as you can usually find a better value VPS if your machine is doing a lot of work.\n\nA: I run several kvm virtual machines on a couple of the servers that I'm responsible for at one of my places of work. I chose to set them up this way for a couple of reasons. \nThe configuration of each guest server is focused on the task assigned to it. I've set up one for internal websites, another for handling Samba shares, etc.) This also means I can make changes with one set of services without affecting the others.\nIn theory, I can move the virtual machine from one physical system to another without making a lot of changes. (I haven't ended up doing this much because the servers I have aren't currently running the same architecture.)\nAnd, it is really easy to setup new virtual machines for trying out new configurations using the Virtual Machine Builder.\nI don't know much about other tools for managing the virtual machines because I only use the vmbuilder and virsh command line tools which work well for my admittedly basic requirements.\nUpdate: I might have misunderstood the question. My setup is just kvm virtual machines on individual servers, there is no \"cloud\" in the Ubuntu Enterprise Cloud or Amazon EC2 sense.\n", "Q: 'Installing' Applications, where to put folders? I've just bought a game (Machinarium) which does not come with a deb file neither is it a ./configure, make etc type of application. I can just run it. Where is the best place to put it so i can create a launcher and keep it out of my home directory? \ni.e. I'm basically asking where are applications are installed and should i put this game there.\nThanks!\n\nA: Based on the fact that you have paid money for it, might be a good idea keeping it close to other documents that you will definitely take care of, that is, in the home directory.\n~/bin is not widely known location but it is added in the PATH by bash so it looks pretty standard to me.\n\nA: Usually you would select /opt or /usr/local as installation path.\nYou need to use sudo if you want to copy anything into those directories.\n", "Q: Why won't xfs_check run? I'm running a fully updated Ubuntu 9.04 \"Jaunty\" i686 server. I have an single XFS volume in an LVM group called /dev/mapper/vg0-bigthree.\nIf I boot to single user mode and ensure that the volume is unmounted, I still get the following every time I try to run xfs_check:\n$ sudo xfs_check /dev/mapper/vg0-bigthree \nxfs_check: /dev/mapper/vg0-bigthree contains a mounted and writable filesystem\n\nfatal error -- couldn't initialize XFS library\n\nJust to be thorough, I started by trying to run\n$ sudo fsck.xfs /dev/mapper/vg0-bigthree \nIf you wish to check the consistency of an XFS filesystem or\nrepair a damaged filesystem, see xfs_check(8) and xfs_repair(8).\n\nbefore turning to xfs_check.\n\nA: Clearly the fs is un-mounted. It appears as though either autofs or nfs is still holding onto the file system and once they are stopped the check will run.\n`service autofs stop`\n`service nfs stop`\n\nxfs_check is looking at stale information in /etc/mtab rather than up-to-date information in /proc/mounts.\n\nA: Make sure the filesystem isn't listed in /etc/mtab or /proc/mounts as mounted.  (I'm not certain which xfs_check looks for).  I've seen this occur in cases where a device wasn't cleanly unmounted.\n", "Q: How can I install different icons? \nPossible Duplicate:\nHow do I get and install more themes, icons, and pointers? \n\nI often find myself seeing new icons but I am unable to install them. \nHow do you install icons on Ubuntu? Can someone break down the process for me?\n\nA: Drag and drop the theme package in the Appearance Preferences window\n (System->Preferences->Appearance) Theme tab.\n\n\n\nA: To add a new icon theme, copy them into the hidden directory (control+h in nautilus to show hidden files) .icons in your home directory.\nYou should then be able to select them from Appearance Preferences.\nIf you don't have a ~/.icons directory, just create one.\n\nA: If you just want to change an individual icon you should do the following:\n\n\n*\n\n*Download a .png image\n\n*Right click the icon you want to change\n\n*Go to Preferences and then click on the little image window on the upper left.  \nIt will open a dialog where you can select the icon you wish to substitute for the old one.\n", "Q: Creating a launcher (for Mechinarium) I'm trying to make a launcher for Mechinarium, Its a flash game with a launcher that runs flash files in separate folders in its directory as far as im aware. \nI've tried to make a launcher which points towards this executable which runs fine when i click on it. When i try and run it from the launcher the player comes up (black screen) and i can right click and get the flash options however the game does not load.\nAny ideas? \nThanks.\nEDIT - ANSWER:\nhttp://machinarium.net/forum/index.php/topic,467.0.html\n\nA: I've had a few issues like this with various things. I find the best way to fix these is to write a little shell script and stick it in ~/bin.\nHere's what I did for Nexuiz (which had some path issues):\n#!/bin/bash\ncd ~/Nexuiz\n./nexuiz-linux-x86_64-sdl\n\nYou obviously don't want that path or that executable but basically cd to the right place and then run it. \nDon't forget to chmod +x the script. And then just have your launcher call the script.\nYour script should look like this:\n#!/bin/bash\ncd /home/will/Machinarium\n./Machinarium\n\n\nA: You can create a launch script and put it into /usr/local/bin.\nFurthermore, you can create a menu entry that points to the script to be able to launch it from your menus. In KDE you can use kmenuedit for this, Gnome has a similar menu editor too.\n", "Q: How to only perform LTS upgrades? I know I've seen this documented somewhere before, but what's the option to keep update-manager from prompting for updates except for LTS-to-LTS releases?\n\nA: If you go to Ubuntu > System > Administration > Update Manager, you'll see a Settings... button at the bottom left of the dialog. In the dialog, switch to the Updates tab and uncheck the updates checkboxes and set Release Upgrade to \"Long Term Support Releases Only\". \nIt should look something like:\n\nSee the community docs for more information. \n\nA: Posting as an answer what @flickerfly said in a comment: the way to do it without a GUI is to change the value of Prompt in /etc/update-manager/release-upgrades.\n[DEFAULT]\nPrompt=lts\n\nThe possible values are (copied from the file itself):\n\n\n*\n\n*never: Never check for a new release.\n\n*normal: Check to see if a new release is available.  If more than one new\nrelease is found, the release upgrader will attempt to upgrade to\nthe release that immediately succeeds the currently-running\nrelease.\n\n*lts: Check to see if a new LTS release is available.  The upgrader\nwill attempt to upgrade to the first LTS release available after\nthe currently-running one.  Note that this option should not be\nused if the currently-running release is not itself an LTS\nrelease, since in that case the upgrader won't be able to\ndetermine if a newer release is available.\n\n", "Q: How to force panel not to be on top? I am trying to present a full screen slideshow using OOo Impress, but the top panel stays on top of the slideshow. I went to Slideshow->Slideshow Settings... and made sure Always on top was checked.\nHow can I fix this?\n\nA: Unfortunately this is a bug in Ubuntu and there is no fix available yet.\nThe bug is tracked here but unfortunately most of the workarounds didn't work for me. Feel free to try them on your system:\n\nAs funnylife_ma mentioned, you could\n  either disable compiz (not ideal) or\n  you could just disable the Place\n  Windows plugin. Simply trying to\n  untick Place Windows didn't work as\n  after a few seconds it would be\n  re-enabled (I assume another plugin\n  required it). To do this I had to go\n  into CCSM > Preferences > Plugin List,\n  un-tick Automatic Plugin Sorting (and\n  acknowledge the warning saying I know\n  what I'm doing) then disable Place.\n  Not ideal but a lot better than\n  auto-hide panels or no compiz.\n\n--or--\n\nGo to System - Preferences - Conmpiz\n  Config Settings Manager\nIn this screen click on utilities on\n  the left, click on workarounds on the\n  right. Put a checkmark for the enable\n  legacy full screen support\n\n--or--\nInstall OOo from openoffice.org like this\nThe workaround that works is to disable Compiz by setting Visual Efects to None in System → Preferences → Appearance.\n\nA: Try to set Visual Effects to None in Appearance Preferences.\n\nA: There are two things you can do:\n\n\n*\n\n*F11 that puppy before you full screen. I hopefully that will help with the panel.\n\n*If not I believe this thread has a possible solution to your problem. \nKeep me posted, let me know if they works with you.\n", "Q: Dropbox reconnect on network connection established I am running UNR (but using the regular gnome launcher) and have DropBox installed. Since I use my laptop on the train, there is no network connectivity. However once I reconnect to a network, dropbox seems to be completely unresponsive to the fact that there is a network connection and has to be restarted (which means lots of hard drive scanning, battery usage, slowdowns, etc). Is there a way to get dropbox to reconnect automatically, or gota wait for a patch?\nEdit:\nNothing special about my network configuration, pretty much out-of-the-box. Note that most of the time I connect to wifi not cable. But the problem does not change in either case.\nAnd I forgot to mention, I usually put my computer to sleep/hibernate in between leaving home and using it on the train so it \"loses\" or \"gains\" connection on waking up.\nMore Edit:\nI just had the problem happening again. Basically it has a network cable plugged in. Goes to sleep. On wakeup (cable still plugged in) dropbox is stuck at \"connecting\".\n\nA: Does it still happen if you just disconnect your network cable then reconnect without suspending?  If not, you may have a timing problem like the dropbox process already being suspended when the network goes down.  You could try putting a script into /etc/pm/sleep.d that explicitly takes down the network interface before suspending, maybe with a short sleep to give dropbox time to process the event.  \nIf worse comes to worst you could always put a script in there to restart dropbox.  At least then you wouldn't have to do it manually every time.\n\nA: Due to lack of response I am going to assume that this is a problem with Dropbox itself and not Ubuntu.\n\nA: Ubuntu One, for the record, does not suffer from this issue and disconnects/reconnects depending on the network status autimatically.\n", "Q: Firefox Slow Performance I have to say, firefox on ubuntu's performance is attrocious. Very quickly it gets into 100% cpu use (thank god I have multiple cores) and hundreds of megs of ram. Even closing tabs does not help the issue (unless google.com uses supreme amounts of javascript).\nOn the same machine chromium browser runs lightning smooth. I tried swiftfox, nothing useful there. Is this a common problem? Only recent (past 3.6) versions have even been able to scroll rather smoothly vs choppy performance when using the scroll bar on pages. The performance is getting close to running firefox on a windows xp virtual box vm.\nEdit:\nOS:\nKubuntu 9.10. Installed Gnome packages for Ubuntu and use those. Upgraded to 10.04.\n64bit\nNvidia Proprietary Video Drivers using the Restricted Driver tool.\nHardware:\nCore 2 Quad\n4gb DDR2 667 ram\n7200rpm hdd\nNvidia GeForce 8800\nAlso note for everyone responding:\nThe default settings work damn well in windows on the same machine. The performance in Linux is what sucks.\n\nA: There's a possibility that the sqlite database that Firefox uses becomes too fragmented and reading that could grind the hard drive for a minute or two (especially if you like me have hundreds of bookmarks and never delete history)\nThe solution to this is the Vacuum Places Improved addon (link text). It defragments your sqlite database, and the startup performance is markedly improved (at least for me it did). Maybe that will work for you.\n\nA: I can't replicate the issues you're detailing - this seems very odd to me (and I'm speaking on the level of testing on multiple machines. This likely may be something particular with your setup.\nHere are a few things that can contribute to poorer performance on a machine:\n\n\n*\n\n*Clean Install v Multiple Upgrades: I had a similar issue on a workstation that had been upgraded through the years from 5.10 to 9.04 the desktop would randomly restart at odd intervals with no warning - and no log entries. I ended up doing a clean install and the issue went away. Not the best scenario where Troubleshooting triumphed but an example of how older configurations can cause weird issues.\n\n*Hardware: Far less likely - but it may just be an issue with that Firefox release and your setup (drivers, configuration, etc) might be conflicting - which would explain why Swiftfox (a Firefox derivative aimed at increasing performance of the Mozilla tool for Linux) is also responding poorly.\n\n\nI would search for people exhibiting similar issues with Firefox on setups similar to yours ( You didn't provide anything so I can't really help you further ) but it may be a configuration, compilation issue.\n\nA: Some possible steps to increase performance:\n\n\n*\n\n*Make sure you only have the extensions installed that you absolutely need\n\n*clear your history, cache, cookies etc.\n\n*Set it so that Firefox doesn't remember history.\n\n*Disable flash and java plugins if you don't use them.\n\n\nOther browsers you could use when you don't need firefox:\n\n\n*\n\n*chromium/chrome (package: chromium-browser)\n\n*midori (package: midori)\n\n*epiphany (package: epiphany-browser)\n\n\nA: When Firefox starts eating CPU, I find that most of the time there are pages with Flash animations being the culprit.\nTry installing the Flashblock addon and see if that helps. This addon prohibits embedded Flash animations/videos from running until you click on them.\n", "Q: What's the difference between \"Service\" and \"/etc/init.d/\"? I've been managing server installations both on and off Ubuntu flavor for some time - I've become quite adjusted to /etc/init.d/ for restarting servcies. Now I get this message:\nroot@tatooine:~# /etc/init.d/mysql status\nRather than invoking init scripts through /etc/init.d, use the service(8)\nutility, e.g. service mysql status\n\nSince the script you are attempting to invoke has been converted to an\nUpstart job, you may also use the status(8) utility, e.g. status mysql\nmysql start/running, process 14048\n\nThis seems to have been brought about in the latest LTS of Ubuntu - why? What's so bad about /etc/init.d/ and what/is there a difference between service and /etc/init.d/?\n\nA: Also check the man page for the service command: man service\nservice runs a script in a predictable environment (working directory is / and only 2 environment variables are set: LANG and TERM).  It also adds the ability to do --full-restart.  So to sum up:\n\n\n*\n\n*service may run scripts from either /etc/init or /etc/init.d (upstart or System V)\n\n*service runs scripts in a predictable environment.\n\n\nThe \"predictable environment\" aspect can cause you problems if your script depends on an environment variable for some reason.  There is probably a way to get around that, but I don't know what it is, and that's beyond the scope of this question :)\n\nA: /etc/init.d scripts are the old way of doing things. They come from the System V standard. However, those scripts are fired only in a particular sequence, so no real dependencies can be established.\nTherefore, upstart has been developed with the intent to substitute all the /etc/init.d scripts with upstart scripts (in /etc/init). \nservice allows the smooth transition from /etc/init.d scripts to upstart scripts. In the future, when more and more scripts are transferred to upstart, service will still work because it finds both possibilities. \n\n\n*\n\n*How to enable or disable services?\n", "Q: What is the best way to convert or copy an VM image into an lvm? I have a couple of VMs running on images instead of lvms. I am not concerned about downtime but just about convenience of the process.\n\nA: There is a short discussion at serverfault, hope it helps :-)\n", "Q: Unable to switch between windows I recently upgraded to 10.04.  Before the upgrade, I was using multiple windows, and I was able to drag applications across the windows.  But, now the windows are locked.  Further, the icon of the maximized window is not showing.  Just a generic window icon.\n\nA: You need to be running compiz to drag windows across your virtual desktops.\nMetacity doesn't have this behaviour (by default anyway), although you can change what workspace a window is on by right clicking the title bar.\nTo enable compiz:\n\n\n*\n\n*Go to System -> Administration -> Hardware Drivers and make sure you have graphics drivers (if available) installed and enabled.\n\n*Right Click on the desktop and click 'change desktop background' or go to System -> Preferences Appearance\n\n*Click the 'Visual Effects' tab, select custom and click 'Preferences'\n\n*Edit your compiz preferences. You can choose Edge behaviour in the 'Edge' tab. Also enabling the Desktop Cube in the 'Desktop' tab allows you to drag windows between desktops.\n\n\nA: If you meant monitors. \nSystem > Preferences > Monitors\nMake sure they are on and same Image on monitors is checked off. \nIf you meant workspace you can move any application by right clicking on the task bar and assigning it to the desired workspace. \nHope it works :)\n\nA: Sounds like you window manager has died. This happend on a few machines for me when upgrading from 9.10 to 10.04.\nYou can fix this by opening a terminal (application-accessories-terminal) and typing:\nmetcity --replace\n\nor if your graphic card supports 3D acceleration then tyrp:\ncompiz --replace\n\nthen close all open windows and go to system-settings-start up programs-settings and press the button labled \"Remember currently running programs\".\n\nA: I understand it like if you are using multiple workspaces\nDrag windows over workspaces:\nNote: In order to drag windows across workspaces you do not need 3d enabled.\n\n\n*\n\n*Install ccsm in software center. (Advanced desktop effects settings)\n\n*List item\n\n*Goto System -> preferences -> compizcompiz settings manager\n\n*Then choose: Desktop wall -> Edge flipping \n\n*The functionality you are looking for is called \"edge flip move\" so toggle that\n\n\nResetting the desktop switcher in the panel: \n\n\n*\n\n*Right click it and select remove from desktop\n\n*Riht click the panel and select \"add to panel\"\n\n*Then add the workspace switcher move it position and lock it to the panel.\n\n\nIf your having multiple issues after upgrade to 10.04 i recommend doing a backup and reinstalling a fresh version of it. If it's only this you should be fine.\n", "Q: How to install GUI desktop on a server? After installing Ubuntu server how do I install the desktop environment? \n\nA: If you just need to run virtual GUI (GUI exsists but you dont need to see it) on the computer for testing or other purposes.\nsudo apt-get install xvnc4viewer\nIs a setup I have.\n:)\n\nA: Depending on which desktop you wish to install, you install the the meta-package that installs all the necessary packages. You can use apt-get or aptitude to do this.\nsudo apt-get install ubuntu-desktop\n\ninstalls the Unity desktop\nsudo aptitude install kubuntu-desktop\n\nwould install the KDE desktop\nOther desktop meta-packages are xubuntu-desktop, ubuntu-gnome-desktop, lubuntu-desktop, and edubuntu-desktop .\n\nA: If you wan to install a graphical desktop manager without some of the desktop addons like Evolution and OpenOffice, but continue to use the server flavor kernel use the following command\nsudo aptitude install --without-recommends ubuntu-desktop\n\n\nA: From Ubuntu 20.04, we could use sudo apt install ubuntu-desktop-minimal to minimal install ubuntu-desktop, it removes around 80 packages (and related cruft) from the default install, including Thunderbird, LibreOffice and so on.\nThe command could replace the old command sudo apt-get install --no-install-recommends ubuntu-desktop or sudo aptitude install --without-recommends ubuntu-desktop.\n\nA: sudo apt-get install ubuntu-desktop\n\n", "Q: Is it worth to tune Ext4 with noatime? With previous versions of Ubuntu (using Ext3 filesystem) I used to tune it for better performance with noticeable results by setting the noatime parameter in /etc/fstab.\nIs it still worth it to do that with the Ext4 filesystem, which is now default in Ubuntu?\nIf so, does the procedure changed in some way?\nAn example of this tuning can be found here. \n\nA: On Ubuntu 10.04, relatime is part of the default mount options, unless overridden in /etc/fstab. The previous few releases had relatime explicitly in /etc/fstab. relatime gives the same speed (and flash write cycle conservation) benefits as noatime, without causing trouble to old-fashioned mail notifiers.\nThe article you cite recommends data=writeback. Ubuntu defaults to data=ordered. Ubuntu's setting is slower in case of heavy disk load, but carries significantly less risk of data loss in case of a crash or power failure. So I would not recommend changing from the Ubuntu default.\nChanging commit=5 to commit=100 increases the time window during which data will be lost in case of a crash, for little benefit in most circumstances.\nSummary: leave the settings as they are, they were chosen for a reason.\n\nADDED: There are other things beyond mount options than can make a difference. Switching from ext3 to ext4 is itself often a visible improvement. Here are a few more tips for laptop users.\n\n*\n\n*If you have a slow SSD, check out this thread at SU. The important tips are to use tmpfs for /tmp and for the browser cache (and perhaps history).\n\n\n*If you have a hard disk and you want it to stop spinning for extended lengths of time, then install noflushd, which allows the disk to spin down by delaying all writes until the RAM is full. (Of course, reads can cause the disk to spin up; you'll want to get into the habit of running cat /files/I/m/likely/to/need >/dev/null before the disk spins down.) In order for noflushd to be effective, turn off all swap and mount your filesystems with something like commit=3600.\nUsing noflushd effectively means that your data can remain unwritten to disk for an extended length of time. This is a risk, to be weighed against the benefit of not having any noise or heat coming from the disk for a while. Don't use noflushd if you're not comfortable with that risk.\n\nA: Yes, it still may make sense to use noatime as of Ubuntu 12.10\nrelatime is a default mount option. And relatime is much better than atime. The former requires a write for the first read after a write, the latter requires a write for every read. But with noatime each read is free of a write.\nThis basically means that the number of writes to a disk for relatime mount is close to double relative to a noatime mount other thing being equal. It is a serious concern for partitions on flash memory devices.\nThe detailed discussion by linux kernel community is at http://kerneltrap.org/node/14148\n", "Q: Installation:Troubleshooting webmin dependencies I am having a dependency problem dpkg installing webmin 1.510 (deb) package on Ubuntu 10.04.\nI do not know where to look to find info about what dependencies are needed.\n\nA: The answer for dependencies is actually listed here: http://www.webmin.com/deb.html\n\nIf Debian complains about missing\n  dependencies, you can install them\n  with the command :\napt-get install perl libnet-ssleay-perl openssl libauthen-pam-perl libpam-runtime libio-pty-perl\nIf you are installing on Ubuntu and\n  the apt-get command reports that some\n  of the packages cannot be found, edit\n  /etc/apt/sources.list and make sure\n  the lines ending with universe are not\n  commented out.\n\nI followed the instructions and uncommented  \"universe\" lines in /etc/apt/sources.list which were indeed commented out as the instructions suggested (the file contains more info if you read it). Note: Only two universe lines were commented out in my file but others were not. I made sure all universe lines were uncommented in the entire file and then saved it.\nAfter following the above instructions dpkg still failed to install webmin, with same message,  then I used the following apt-get force command with no package name. It pushed everything through that didn't go through prior, including the webmin:\nsudo apt-get -f install\n\nSuccess! :)\n\nNote: I found this only minutes after posting the question.\nTurns out I was looking for Ubuntu help on the web site menu, but needed to choose Debian help since I'm using the Debian installer.\n", "Q: Finding the file system explorer application in a default desktop install? I'm new to Ubuntu in general (using 10.04) and from the default Ubuntu desktop after a default Ubuntu desktop install, cannot find the file system explorer program in the top application menu.  \nUPDATE: I want to see the complete  file system, not just My Documents, My Pics, etc.\nI know it's gotta' be there, but maybe I don't recognize the name (because I come from the Windows world) .. so I think this is going to be a race to first post :)\n\nA: Usually you would want to access the items in the Places menu located to the right of Applications in the top left corner of the screen. \nThe \"Computer\" option will give you a view of the removable storage devices on your computer (CD drive, USB drives, etc.) as well as the file system. To get a view of the complete file system go to Places > Computer > File System. This should open a window titles \"/ - File Browser\" with the full contents of your main file system, which is generally the contents of your hard drive.\nFor your personal documents and other user files, you can open the \"Home Folder\" bookmark (usually right at the top of the Places menu) or one of the other bookmarks in that first section.\nAll of the icons in the first two sections of the Places menu will open the file system explorer in Ubuntu which is called Nautilus although the window will likely be titled \"File Browser\".\n\nA: The filesystem browser in Gnome is called Nautilus.\n", "Q: Where's the best place to share files from? I've got Samba installed on Ubuntu 10.04 and am about to configure it using webmin, but I just realized I don't know the best place to create a file share on a Linux system.  \nI want to use best practice as to not accidentally create a security risk or put a share in an unconventional place where an experienced Linux user would have a hard time finding it.\nBasically I want to transfer some general files (pics, docs, etc) back and forth between a Ubuntu file share (placement TBD) and a Windows machine. \n\nA: Often configurations are done that allow every user to have a public folder in their home directory. This way every user has control over their public files and no system files will ever be accessible there.\n\nA: If you want to provide a central server, I would store the Samba shares within /srv. Have a look here: https://secure.wikimedia.org/wikipedia/en/wiki/Filesystem_Hierarchy_Standard#Directory_structure\n", "Q: What's lost+found and where did it come from? I reformatted a hard drive to ext4, planning to use it as a backup drive. After mounting the freshly-formatted drive, I discovered a single empty directory inside it: lost+found. What's the purpose of this mysterious directory?\n\nA: lost+found is the directory in which fsck (filesystem check) will put files it restores from orphaned blocks. This can happen when something corrupts filesystem meta-blocks (also called i-nodes) in which the references of the blocks are stored which contain the data of a file.\nLook also at http://tldp.org/LDP/Linux-Filesystem-Hierarchy/html/lostfound.html http://ubuntuforums.org/archive/index.php/t-229143.html\n", "Q: How to install an RPM using a GUI tool in Ubuntu Desktop? I've been given some RPM files on CD and want to install them in Ubuntu (10.04) Desktop using a GUI app. Is there a way for me to do this without resorting to the command line? \nI'd like to know what GUI app to use, and also how to install an RPM with it.\n\nA: Ubuntu is Debian based and therefore uses.deb packages to install. If you want to install .rpm packages, you first should convert them into .deb packages with a conversion software such as alien. Then you can use gdebi or dpkg to install them.\nHowever, caution must be applied by doing that. Even such conversion software does not always create the correct dependencies to other packages. Therefore, the software installer might refuse to install your package because of missing dependencies, or the software might not work very well because not all dependencies have been created and maybe some libraries are missing.\nUsually, it is better to find a .deb package if at all possible.\n\nA: There is no popular stable GUI for installing .rpm on Debian or Ubuntu. \nAlien can be used to convert rpm packages to deb and install them in Ubuntu. To install an rpm-package from the console:\nsudo alien -i --scripts your_package.rpm\n\n-i means \"install\" and --scripts \"include scripts in package\"\n\nA: You can't install RPMs directly on an Ubuntu system because Ubuntu uses the DEB package format.\nYou can convert the RPMs to DEBs using a gui like PackageConverter which is a front-end for alien. Here's how it looks like:\n\nConverting the RPMs to DEBs is, however, no guarantee that they will install correctly on your  .deb based system much less work as they should.\nAfter you've converted them to DEBs you can double click them in nautilus which will launch the gdebi GUI to help you install them as normal debian packages.\n", "Q: Why does the mount point keeps changing, and how can I prevent it? When I plug in an external USB drive, it automatically mounts and it's accesible in /media/disk/\nHowever after a while, this is how my /media directory looks like:\ncesar@minas-tirith:~$ ls /media/\n0BC7-569E  0BC7-569E_  disk  disk_  disk__  disk___\n\nAs you can see, the disk entry is repeated with additional _ appended at the end. I don't know why this happens, but I can imagine that under some circumstances, the system can't mount the disk in /media/disk/ and creates disk_, then it can't mount it in /media/disk_ and creates disk__ and so forth. The other entry 0BC7-569E I think it's from a SD media card so it's not only for USB drives.\nI would like to know what is causing this? Is this expected behavior? or how can I prevent this from happening?\n\nA: For a long-term fix, you could add the drive to /etc/fstab with a designated mountpoint. I recommend using the UUID to identify the drive.\nBonus tip:\nIf you want the icon to be displayed when the drive is mounted, set the mountpoint somewhere within /media/. If you don't, set the mountpoint somewhere else, such as /mnt/.\n\nA: You can work around this, by unplugging the USB drive, and the going to a terminal (e.g. Application->Accessories->Terminal) and entering:\nsudo rmdir /media/disk\nsudo rmdir /media/disk_\nsudo rmdir /media/disk__\nsudo rmdir /media/disk___\netc\n\nWhen you replug the disk in it should remount at /media/disk/\n(Do the same for your /media/0BC7-569E)\n\nA: This is not  a complete answer, but rather a comment to help understand the issue better (I don't have enough reps yet to comment).\nYou can check diagnostic messages generated while usb / sdio devices are mounted and unmounted by running following command or by selecting (clicking on) the \"dmesg\" item in the left hand side of System -> Administrator -> Log File Viewer\ndmesg | tail -20\n\nThe tail command prints only the most recent 20 msgs. While inserting or removing the card, run this several times or change the number at the end to see more/ less messages. This would give you an idea of what is going wrong.\n\nA: Make sure you always unmount USB devices before you  un-plug them.\n", "Q: Change web browser shown in the Ubuntu Desktop application launcher? I'd like to change the web browser shown on the application launcher, from Firefox to Chrome. \nThis setting obviously differs from the default web browser known to the system because I already set Chrome as the default and it launches links instead of Firefox.\n\nA: Locate Chrome In Applications → Internet, right click on it and select Add launcher to panel.\n", "Q: What is Utnubu? Not Ubuntu,I heard it on Planet Ubuntu but google doesn't tell me anything.\nIt is something related to Debian.\n\nA: Utnubu - Ubuntu spelled backwards - is an effort to package Ubuntu-specific packages for Debian. While historically most applications have been packaged by Debian developers and imported into Ubuntu, there are a growing number of applications that have been packaged directly by Ubuntu developers and which could easily be imported into Debian.\nYou can find out more on the Debian wiki page. There is also a mailing list, and, as maco pointed out, an IRC channel.\n\nA: Do you mean this?\n\nOne of Ubuntu's activities is frequently redistributing packages originally from Debian to Ubuntu's users. Well, Utnubu is about the reverse, copying packages from Ubuntu to Debian.\n\nI've never heard of this before. I assume it's real. =)\n\nA: It's the effort to work together with Debian.  Check out the #debian-ubuntu channel on OFTC\n", "Q: What are some commercial apps for Ubuntu? Anything including games and obscure software\n\nA: The Humble Indie Bundle is a commercial collection of games that was sold as \"pay what you want\". The games are available for puchase independently now.\n\nA: there are not some, but A LOT of commercial apps for linux, check http://lin-app.com/ :)\n\nA: Now, I'm assuming that by \"commercial\" you mean \"for-pay\" with no implications regarding Free/Non-Free.\nThe Canonical Store sells Parallels and PowerDVD.  There are Linux versions of Quake and Doom as well. \n\nA: If you do mean \"For Purchase\" software, there is a section for such applications in the Ubuntu Software Center.\n\nCurrently, it only contains 'Fluendo DVD Player', which is being sold for US$ 24.95.\n\nOther applications will probably be added in the future. This is still a new feature.\n", "Q: Is there a way to turn gvim into fullscreen mode? Is there a way to turn gvim into fullscreen mode? I know that this is possible on OS X through MacVim, but wasn't able to find a way to do it on Ubuntu.\n\nA: With gnome you can set a shortucut to the \"fullscreen\" action. Use gnome-keybinding-properties, select Window Managaer and choose Change to Fullscreen, then select a shorcut (F11 for example). This shortcut will set the current Gnome Window in fullscreen mode.\nThis doesn't work unless the Enable Extra WM Actions plugin is checked in the Compiz Settings Manager\n\nA: For XFCE Users:\nAlt+F11 works out of the box\n\nA: The system settings do not work for me on Ubuntu 12.04 (as happens to miloshadzic) because gvim catches the F11 key and does not pass it on to the system. \nThere is a solution though, that I found in this blog\nmake sure you have wmctrl installed. If you have that, then add the following to your vimrc:\nmap <silent> <F11>\n\\    :call system(\"wmctrl -ir \" . v:windowid . \" -b toggle,fullscreen\")<CR>\n\nAnd on save of the .vimrc and restart of gvim F11 now has the desired effect.\n\nA: You can also switch into fullscreen mode by changing the lines and columns settings. Try to put this into your vimrc:\nif has('gui_running')\n    set lines=999 columns=999\nendif\n\n\nA: Maximised window instead of fullscreen\nIf you have a right-side XFCE launcher panel, the fullscreen option of wmctrl causes gvim to overlap.\nBelow variant with maximized_vert,maximized_horz resolves this issue and enables F11 for maximised window toggling:\ncommand! Maximised :call system(\"wmctrl -ir \" . v:windowid . \" -b toggle,maximized_vert,maximized_horz\")\nnoremap  <silent> <F11> :Maximised<CR>\nvnoremap <silent> <F11> <C-C>:Maximised<CR>\ninoremap <silent> <F11> <C-O>:Maximised<CR>\n\n\nAutomated, upon starting gvim\nPlace the following line in gvimrc, for a foolproof fullscreen at gvim startup:\nautocmd GUIEnter * call system(\"wmctrl -ir \" . v:windowid . \" -b add,maximized_vert,maximized_horz\")\n\n\nA: On Ubuntu cinnamon go to Keyboard -> Shortcuts -> Windows -> Toggle fullscreen state. Set as F11 for example.\n", "Q: How can I boot from a 16 Gb pendrive with some old BIOS? I need to boot Ubuntu in a computer (computer A) with no CD. I have a 16 Gb pendrive with a live Ubuntu version. The pendrive works in at least two newer computers. Computer A boots from a 2Gb pendrive right. So it's likely a BIOS issue.\nBut it's quite inconvenient to always carry two pendrives, how can I made the older computer boot from the bigger drive?.\nNotes:\n\n\n*\n\n*Repartitioning the drive doesn't seen to work.\n\n*I noticed than the 16 Gb pendrive is seen like a external zip drive by the BIOS, while the smaller one is seen as a Hard Disk. Likely related.\n\n\nA: Very often you can run in to problems with high-capacity usb-sticks and old hardware, most of the time the it is only BIOS that seems to be the problem. So if the BIOS can be upgraded then try that.\nThe only other solution (afaik) is to kickstart usb-booting from a floppy-disk, and that is not really an alternative to carrying two sticks.\nIf you are interested in the floppy method you should look at the grub documentation, and this brief guide on how to dd the precompiled image for pendrivelinux, after writing the disk you might have to edit the grub-config file on there.\n\nA: A lot of BIOSes, even quite recent ones, can't boot from a USB device that has partitions. In Linux terms, the filesystem must be directly on /dev/sd?; the mere existence of a partition table makes the BIOS give up.\nIf this is an older BIOS, then in addition the bootloader may need to live entirely near the beginning of the disk (typical limits are 512MB, 2GB or 8GB).\n\nA: *\n\n*If you haven't tried it already, try\nsticking the 16 GB stick in Ubuntu\nand shrinking the partition down to\n2 GB using gparted. I know you said, \"Repartitioning the drive\ndoesn't seen to work\", but you didn't go into details. If this works, you can format the remainder of the drive to something like ext3 and windows will never know that space is there.\n\n*You could get a Compact Flash to IDE converter (both laptop and desktop IDE plugs are available), and a flash card and put your OS on that. Of course, instead of two pen drives you have to open every case and hope for a spare PATA socket, so I don't see how that helps\n\nA: In 2007 I installed Xubuntu on a 20GB hard drive on an older computer. When I booted up, I got GRUB error 18.\nReading about GRUB error 18, I learned that it meant my Ubuntu partition was too large for the BIOS to handle.\nThe solution was to create a 100MB EXT3 partition and set it to be mount as /boot.\nHow to do the same with a flash drive, I'm not sure.\n\nA: With http://www.plop.at/en/bootmanager.html you can create a cd that will allow you to boot the usb. You would have to carry both the cd and stick with you though. \n\nA: Try Unetbootin it is better for booting older computer from USB stick.\nI first used Yumi boot it worked fine for newer computers but not old.\nThen I installed Unetbutin and the old computer boots ok.\nIf you favor a Linux computer it is also possible to make a startup on a USB with an ISO file with Ubuntu startup program.\n\nA: The best way to create a USB multiOS bootable is with Yumi and has to be on FAT 32.\nFirstable add the unlisted ISOs , and secondary the main ISOs example Ubuntu 11.04 x86, Ubuntu 11.04 x64.\n", "Q: Is it possible to find out which files are deleted during a filesystem recovery check? Some files/inodes are deleted during filesystem check if corrupted in a way after a system crash. fsck only reports \"some inodes were deleted\". Is it possible to know exactly what files were deleted and how to recover them?\n\nA: Check in your /var/log/fsck/ directory the file checkfs. It is the logfile of fsck.\n\nA: Check http://tldp.org/LDP/Linux-Filesystem-Hierarchy/html/lostfound.html .\n\nA: It should also create a odd looking file name in the lost+found directory at the base of the filesystem that contained the deleted files.\nYou can look through those files and try to guess which was which, and possibly recover some information from them.\n", "Q: Accessing a specific URL with firefox 3.6 on Ubuntu 10.4 crashed the OS, how should I debug this? The system is a spare Dell 2400 I wiped clean, with Ubuntu 10.4 installed. Update manager has everything current, and I haven't been mucking with drivers or tricky system settings. In fact, it has been a stable and friendly system to install and use.\nSo imagine my surprise when browsing to http://element-14.com/ (an otherwise useful community site for electronic engineering types) followed a redirect or two, then black screen, then the I'm starting up tune with the pink hazy smoke and nothing further works. The keyboard is crashed hard, and the Alt-SysRq key combos do nothing.\nMore than just firefox and the X server are crashing. I repeated the crash with an SSH session open, and not only did the connection get taken down, but it no longer responded to attempts to get a fresh connection.\nI tried enabling Apport, in hopes that it would notice something and help identify the culprit, but it seems to be oblivious to the crash.\nEach time, I've had to lean on the power button to reboot.\nGoogle searches hint that there are issues with the particular intel chipset providing the VGA on its motherboard.\nI'm looking for advice about how to proceed with debugging this kind of crash. Any ideas?\nUpdate: I tried following advice to try setting up the netconsole kernel module and a matching netcat instance to receive the log. I set up netcat on my XP box, used Alt-SysRq-S to verify it could receive kernel messages, then browsed to the site. Only two printk()s were logged:\n\n[251728.009794] i915: Unknown parameter `modset'\n[251728.051420] i915: Unknown parameter `modset'\n\nHmm. Perhaps my video driver is misconfigured? Especially since I see these same messages in the output of dmesg just after booting.\nAt least this time I explicitly synced my disks before deliberately crashing the system.\nFor the record, lspci -nn | grep VGA says:\n\n00:02.0 VGA compatible controller [0300]: Intel Corporation 82845G/GL[Brookdale-G]/GE Chipset Integrated Graphics Device [8086:2562] (rev 01)\n\nUpdate: Solved!!!\nThe hint to use netconsole led to an epiphany. Googling around the phrase \"i915 unknown parameter modset\" suddenly led me to trip over the root cause.\nThe name of the option to the i915 driver is modeset not modset.\nI changed /etc/modprobe.d/i915.conf to have the correct spelling, rebooted, and now I can access element-14 (and presumably other sites that do whatever it is that element-14 does that triggers the bug in the video driver) without an unpleasant forced reboot.\nThis leaves behind the (apparently well known) issue that the i915 driver lacks quality, especially on older chipsets. Apparently the Kernel Mode Setting feature is particularly deficient. Without the option spelled correctly, it defaulted to KMS enabled, and also crashed. With it spelled correctly, KMS is disabled, and the driver survives whatever content was triggering the crash.\nAlso, there are a number of bug pages at launchpad and other community sites that have the wrong spelling of the option name. I strongly suspect that is where I got the spelling I used.\nEdit: I've copied the relevant solution to an actual answer, and improved my description of it here.\n\nA: Assuming it's a kernel crash you need to capture the kernel dump info, you can try using a kernel net console: https://wiki.ubuntu.com/Kernel/Netconsole\n\nA: Almost assuredly a graphics chip driver or chip bug as there is little else that has crushed a system like that in my experience. If you want to really muck about inside drivers that don't get much attention, do enjoy.\nThere are app-notes, device documentation, and code at Intel. Personally, I'd drop US$30-40 on the best damn PCI graphics card money can buy (yes, you do pay a premium for legacy hardware) and be done with it. Ask around and you may find someone with a similar vintage machine with such a card for free. I just recycled such a machine for a friend the other week.\n\nA: The hint about netconsole from João Pinto led to an epiphany. Googling around the phrase \"i915 unknown parameter modset\" suddenly led me to trip over the root cause.\nThe name of the option to the i915 driver is spelled \"modeset\" not \"modset\".\nI changed /etc/modprobe.d/i915.conf to have the correct spelling, rebooted, and now I can access element-14 without a reboot.\n", "Q: Is there a Evernote client? Evernote is a cool site for capturing note, tagging it and retrieving it from everywhere. The Web application is nice but I was wondering if anyone knows about a standalone version such as for Windows, Android,... but for Ubuntu ?\nThanks !\n\nA: I believe they don't have Linux support but here is a cool article on various alternatives.\n\nA: On Linux, you can use NixNote (previously Nevernote), an unofficial Evernote client written in Java but if you want something lightweight, you should try Everpad, a new Evernote client that integrates nicely with Unity.\nIt supports online sync, notes, tags, notebooks, file attachments (remember there's a 60 MB monthly limit) and places.\n\n\nInstallation:\nTo install Everpad all you need to do is run the following commands in terminal:\nsudo add-apt-repository ppa:nvbn-rm/ppa\nsudo apt-get update && sudo apt-get install everpad\n\nOnce installed all you need to do is search for ‘Everpad’ in the Unity Dash and then run the Everpad application. You will then see the app indicator appear on your panel. Once it does, click on it and select “Settings & Management” then “Authorise” to configure Everpad with your Evernote account.\nTo create a new note, simply click on the Everpad app indicator and select “Create Note” or click on an existing note to edit it.\n\nTroubleshooting:\nHaving a issue? Report them @Github\n\nSources: Omg Ubuntu!\n\nA: I don't think there's a native client :-(\nSo, your best bet might be to run it in wine. e.g.: http://abbysays.wordpress.com/2008/05/24/how-to-install-evernote-30-on-ubuntu/\n\nA: Not really, no. You might consider running the web app in Prism, which is quite a nice bit of kit that allows you to run a web app in a standalone window/browser. Or you can use Wine, which works fairly well with Evernote.\n\nA: As of March 2021 there WAS a beta version of an official Evernote client for Linux (a deb package) available. If you agreed to provide Evernote with feedback via a single email survey, you could download it from the Early Access Evernote homepage as deb-package. The deb-package can be installed with the Software Center, other tools or via the command line as usual.\nMore infos you can find on It is FOSS.\nBut very soon this page was deleted.\nHopefully there will be soon an official version without the beta-status.\nMaybe you can still get this beta version through the Early Access program, see a blog article about this.\n\nA: Not an official one, but I've had success with the unofficial client NeverNote\n\nA: +1 for Tomboy/Dropbox.\nAdd Gnome-do and it's extremely useful.\n\nA: I've just installed Evernote app for Android as Chrome's extension on Ubuntu using this tutorial. It looks like separate app: can be found in Ubuntu's search and can be locked to sidebar. For now it seems to be working: I've signed into account, synchronized, can see notes, tags and other things, that I can see on my Android tablet. Also I've tried to create note, add tag to it and sync. Found this note on tablet. Nice!\nI can't say, that functionality of this client is enough for me, because I did not test it for a long time, but it's very good alternative for native linux Evernote not official clients.\n\nA: You can try a combination of Dropbox for folder sync in multiple computers, and Tomboy for note-taking.\nSetup Dropbox first, then setup Tomboy's folder within Dropbox's folder.\nDo this in every computer you use.\nAlso, both can be used in multiple platforms.\n\nA: Tomboy and UbuntuOne has worked well for me.\n\nA: There is also emacs-evernote-mode, that let's you edit and create notes in Emacs using either XHTML or TEXT mode. The cool part is that you can post a region from any Buffer as a note with a single command M-x evernote-post-region. I realize this is probably appealing only for Emacs users (such as myself).  \n\nA: There's a new client called ForeverNote \nhttps://github.com/milan102/ForeverNote\n\nA: As the official beta deb-package is not available anymore, alternatives are welcome:\n\n*\n\n*Tusk - Refined Evernote desktop app, there are several possibilities how to install it, see the release page on Github.\n\n*Nixnote2 - A clone of Evernote for Linux, available from the official repositories or a PPA.\n\n*Running Evernote in Firefox: Since its latest updates (2021) it runs very smoothly, it’s pretty quick and can be closed simply by closing the tab\n\n", "Q: Gnome-terminal shortcut open multiple ssh connections in tabs I was wondering does anyone know a way to make some kind of shortcut under Ubuntu that when I click on it, it will open up multiple SSH sessions (or execute other actions) in a tabbed gnome-terminal?\n\nA: Use the following format: \ngnome-terminal --tab -e \"cat /dev/urandom\" --tab -e \"top\"\n\nA: I think I have just about worked this out now.\ngnome-terminal --tab -t htop -e htop --tab -t top -e top --maximize\nWill open up a new tabbed gnome terminal with htop running in the first window and top in the second for this example. \nTo create the shortcut I just made a simple bash program to run the command.\n#!/bin/bash\ngnome-terminal --tab -t htop -e htop --tab -t top -e top --maximize\n\nMarking it as executable. Then it works by double clicking it. The only annoying thing about this is that it asks\nDo you want to run \"Terminal Session\", or display its contents?\nIs there someway to disable this?\n", "Q: Configuring GPG in Kmail Having done a fresh install I need to set this up again. We could do with an up to date guide. This might encourage more people to use encryption and signing.\nI already have a keyring, but others need to know how to do that. That should probably be a separate question. I use KGPG to manage my keys.\nIn Kmail I know you need to set the default signing and encryption keys on your Identity.\nWhen I try to sign an email it complains that signing failed without asking for my pass-phrase. What am I missing? How should I configure cryptography in Kmail?\n\nA: You need to put \nuse-agent\n\nin your ~/.gnupg/gpg.conf\nI know because Seahorse used to put a blank file there and break things for people using GNOME & KDE together.  I wrote the patch that made it properly copy the skeleton file, but that wasn't until 2009.\n", "Q: Child-proofing an account I'd like to make an account for my daughter in which:\n\n\n*\n\n*Only the Applications menu is shown.  Maybe Places.  Definitely no System.\n\n*The Applications menu only shows the applications I choose for her (games, education, etc.)\n\n*There's no internet connection\n\n\nA: To add the new user, go into System -> Administration -> Users and Groups.\nYou can add a new account from here which you should definitely give limited permissions. I would set the account type to 'Desktop User'.\nYou can then click on 'Advanced Settings', click the 'User Privileges' tab and untick the following:\n\n\n*\n\n*'Connect to the internet using a modem'\n\n*'Connect to wireless and ethernet networks'\n\n\nThis should disable the internet.\nI don't think there is an easy way to not show the whole 'System' menu but you can disable menu items using alacarte by right clicking on the menu bar and clicking edit menus. As long as the new user account doesn't have administration privileges, they can't do any harm to the system through these menus anyway. She won't be able to do anything with the System -> Administration programs for instance. The worst thing she can do is completely mess up her theme and delete all her personal files but this will not affect the system as a whole.\nAlternatively, if there is only a small number of programs you want her able to access, you could delete the menu applet from the top panel and add shortcuts to the desktop of the programs you want her to access.\nSee this question for other parental control options.\nYou may be interested in a program called GNOME Nanny although it is still under development and there are no stable releases.\n\nA: I think your answer is pessulus or Sabayon - so called Lock-down editors. See http://library.gnome.org/misc/release-notes/2.14/ (scroll down to the heading \"2. What's New For Administrators\")\nIf I understand correctly, what you need is a kiosk mode where only your selected apps are allowed to be run by the user and nothing more. You can check out this post to know more about this.\n", "Q: Nano syntax highlighting for C# and/or ASP.Net Has anyone got (or can point in the direction of) a nanorc file that contains syntax highlighting for C# and/or ASP.Net?\n\nA: Replicating my answer.\nUsing the Java example from http://wiki.linuxhelp.net/index.php/Nano_Syntax_Highlighting, you can try to add something like the following into your ~/.nanorc:\nsyntax \"C# source\" \"\\.cs$\"\ncolor green \"\\<(bool|byte|sbyte|char|decimal|double|float|int|uint|long|ulong|new|object|short|ushort|string|base|this|void)\\>\"\ncolor red \"\\<(as|break|case|catch|checked|continue|default|do|else|finally|fixed|for|foreach|goto|if|is|lock|return|switch|throw|try|unchecked|while)\\>\"\ncolor cyan \"\\<(abstract|class|const|delegate|enum|event|explicit|extern|implicit|in|internal|interface|namespace|operator|out|override|params|private|protected|public|readonly|ref|sealed|sizeof|static|struct|typeof|using|virtual|volatile)\\>\"\ncolor red \"\"[^\\\"]*\"\"\ncolor yellow \"\\<(true|false|null)\\>\"\ncolor blue \"//.*\"\ncolor blue start=\"/\\*\" end=\"\\*/\"\ncolor brightblue start=\"/\\*\\*\" end=\"\\*/\"\ncolor brightgreen,green \" +$\"\n\n\nA: I don't know of an existing highlight for C# in Nano but you could write your own. The syntax for syntax highlighting is pretty simple. Here's the one for Java (which will be very similar to a C# syntax - mainly just different keywords):\n## Here is an example for Java.\n##\nsyntax \"java\" \"\\.java$\"\ncolor green \"\\<(boolean|byte|char|double|float|int|long|new|short|this|transient|void)\\>\"\ncolor red \"\\<(break|case|catch|continue|default|do|else|finally|for|if|return|switch|throw|try|while)\\>\"\ncolor cyan \"\\<(abstract|class|extends|final|implements|import|instanceof|interface|native|package|private|protected|public|static|strictfp|super|synchronized|throws|volatile)\\>\"\ncolor red \"\"[^\"]*\"\"\ncolor yellow \"\\<(true|false|null)\\>\"\ncolor blue \"//.*\"\ncolor blue start=\"/\\*\" end=\"\\*/\"\ncolor brightblue start=\"/\\*\\*\" end=\"\\*/\"\ncolor ,green \"[[:space:]]+$\"\n\nThat's sitting in /usr/share/nano/java.nanorc. If you write your own you'll need to link to it from /etc/nanorc. There may be a user-local version of both too but I don't know it.\nEdit: for ASP.NET you could just clone the HTML one and alter the syntax slightly to handle ASP.NET tags. It won't be perfect (it won't handle <script runat=\"server\">...</script> contents for example) but it should be better than a poke in the eye with a sharp stick.\n\nA: This works for me:\nsyntax \"cs\" \"\\.cs$\"\nmagic \"Cs \"\ncomment \"//\"\n\ncolor green \"\\<(bool|byte|sbyte|char|decimal|double|float|int|uint|long|ulong|new|object|short|ushort|string|base|this|void)\\>\"\ncolor red \"\\<(as|break|case|catch|checked|continue|default|do|else|finally|fixed|for|foreach|goto|if|is|lock|return|switch|throw|try|unchecked|while)\\>\"\ncolor cyan \"\\<(abstract|class|const|delegate|enum|event|explicit|extern|implicit|in|internal|interface|namespace|operator|out|override|params|private|protected|public|readonly|ref|sealed|size$\ncolor red \"\"[^\\\"]*\"\"\ncolor yellow \"\\<(true|false|null)\\>\"\ncolor blue \"//.*\"\ncolor blue start=\"/\\*\" end=\"\\*/\"\ncolor brightblue start=\"/\\*\\*\" end=\"\\*/\"\ncolor brightgreen,green \" +$\"\n\n", "Q: How to build application without sudo privileges? What do I need to setup on a Ubuntu 9.10 server so that a user can build applications of there choice (i.e. ./configure , make && make install) with out the need for sudo/admin privileges.\nI just feel its a bit of a security risk having to give a user access to parts of the system they might not need in order to build a app.\n\nA: Users can build applications without sudo rights. The only time you need sudo rights is when you want to install something into the system directories.\n./configure and make work always without sudo rights. make install usually needs sudo rights because it will install the application to /usr/local or /usr (sometimes /opt).\nHowever, if you change the prefix for the installation path (i.e. ./configure --prefix=~/usr/local) in a way that the installation will be perform inside the user's home directory tree, no sudo rights are needed for make install.\n\nA: If your users use \n./configure --prefix=/home/user/opt/\n\nOr for cmake projects\ncmake -D CMAKE_INSTALL_PREFIX:PATH=/home/user/opt/ ../source/\n\nThis will install the program in that prefix (instead of the default /usr/local/) and your users should then be able to run the program like this:\n/home/user/opt/bin/program\n\nIf you want them to be able to run the programs by simply using the name (without full path) you need add /home/user/opt/bin to the path environment variable, edit the users .profile and add the following line:\nexport PATH=/home/user/opt/bin:$PATH\n\nNote that programs installed in this way will be private to the specific user, but it's a way to do it\n\nA: Adding to what txwikinger has said, you might want to check also fakeroot, which gives an opportunity for building .deb packages with dpkg without needing elevated privileges. Of course, installing those will generally need sudo access.\n", "Q: How do I use ext3cow? A while ago I looked at the ext3cow file system. I am interested in getting it running under lucid. I was wondering whether anyone had successfully set it up on their system and could offer any tips? I have had a quick google around but not found any mentions of getting it working under Ubuntu.\nhttp://www.ext3cow.com/\n\nA: I too looked at ext3cow a while ago and spent some time in setting things up and testing.\nWhat I found and what I suspect you will find, is that what you really require is distributed VCS such as bzr.\nHaving the file system history is very useful and ext3cow takes care of this for you automatically without the hassle of having to commit. But in reality having the option to commit, add log details, revert easily and graphically view the history makes the committing a small overhead to manage.   \n\nA: As there website says: \n• It is totally modular, requiring no changes to kernel or VFS interfaces\nIt hasn't been in development for a couple of years. I am doubtful but hopeful give it a try.\nOr maybe look at some alternatives.\n\nA: In the path of alternatives, there are other copy-on-write filesystems, like btrfs and copyfs.\n", "Q: How can I disable the auto-play feature when MTP device is connected? Currently whenever I connect an MTP device (my creative zen, or blackberry) rythmbox automatically tries to mount it as a music device and opens up. I just want to be able to connect my device to the usb for charging without having windows popup every time I do.\nHow can I disable this \"autoplay\" feature?\n\nA: This is probably a better solution (and more likely to work):\n\n\n*\n\n*Open up the file manager (nautilus)\n\n*Click Edit -> Preferences\n\n*Click the 'Media' Tab\n\n*Next to 'Music Player', select 'Do Nothing' from the drop down list.\n\n\nThe media player should still automount and be available from the 'Places' menu. You will still be able to use Rhythmbox to play/manage the device but you will have to open it up manually.\n\nA: For Ubuntu and specifically the Zorin Ubuntu derivative: Go to system settings>details, click on details, then click on \"removable media\", then click the check box \"never prompt or start programs on media insertion\". This is the easiest way to suppress auto-play via the gui. I suppose there is a way to do this via terminal as well, but my post is for those like me that are more comfortable using the gnome gui instead of terminal.  \n\nA: For Zune HD, I found \"Do Nothing\" for \"Music Player\" (in Preferences for nautilus) was insufficient.  I unchecked \"Browse media when inserted\" and that seemed to solve the problem, allowing me to charge my Zune HD via my Ubuntu laptop USB port without having the thing freeze up, reboot, etc.  (Before that, I had tried \"Do Nothing\" for \"Photos\" and \"Software\", but those didn't solve the problem.)\nWith this solution, I assume it'll be necessary to manually mount CDs and the like when I insert/connect them.\n\nA: One possible solution:\n\n\n*\n\n*In Rhythmbox, go to Edit -> Plugins.\n\n*Untick 'Portable Players - MTP'.\nI'm not sure if this will work and it will probably mean that you have to manually enable the plugin if you want to listen to the device.\n", "Q: Replace grep command with grep -n --colour? Because I'm lazy.... any time I want to use grep, I want it to be grep -n --colour. Is there a way to permanantly map this?\n\nA: In your $HOME/.bashrc file, add:\nexport GREP_OPTIONS=\"-n --color\"\n\nThis will work with egrep too and in aliases that use grep.\nUpdate: GREP_OPTIONS is deprecated from grep 2.21 on and if you use this solution you will see the following warning:\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\n\nThe best solution is to therefore follow maco's advice in his answer. Or switch to using ag, which outputs in color by default.\n\nA: Edit ~/.bash_aliases\nAdd a line that says:\nalias grep='grep -n --color'\n\n~/.bash_aliases is automatically included by ~/.bashrc if it exists\n\nA: you can modify the file .bashrc located in your home directory defining an alias, which will override any default setting:\nalias grep='grep -n --color'\nafter the change close and open the terminal again because the file is read only when you open the terminal.\nIf you take a look on the file .bashrc you will found more default aliases like:\nalias ll='ls -l'\nalias la='ls -A'\nalias l='ls -CF'\n\nA: Create a script in addition to an alias mentioned in the other answers. An alias by itself won't always work, and a script layer is fast enough for human readable output anyways.\nChoose a short name, like cgrep:\n#!/bin/sh\ngrep --color -n \"$@\"\n\nPlace it in your path, say ~/bin (if you read UPE this is in your path :). Then stuff like this will work:\nfind /usr/share -name '*.txt' | xargs cgrep testing\n\nI'm still not so happy, I too wanted grep to always color when stdout to a terminal without selectively typing cgrep.\n", "Q: How can I make gnome-terminal not transparent? When I use gnome-terminal the background is annoyingly slightly-transparent. Here you can read the ubuntu.stackexchange.com site through the background.\n\nThese are the background options I have, which are set to \"not transparent\".\n\nI have the desktop visual effects set to \"Normal\". Changing them to None removes the problem, but obviously I lose out on visual effects like window previews, drop shadows, nicer transitions, etc. Any ideas how to make this background truly solid while keeping normal visual effects?\n\nA: The workaround for this is to set it to transparent and pull the bar to maximum. \nThat should fix your issue. :)\nLike so. \n\n\nA: I think this is a bug. Many other people have experienced it too. You can read more about it and find workarounds at https://bugs.launchpad.net/ubuntu/+source/gnome-terminal/+bug/561370\n\nA: I'm assuming you encountered this problem with one of the Ubuntu themes. GNOME Terminal will use the background from the theme, and some of the Ubuntu themes (e.g. Ambiance) specify a transparent background for the terminal. You can change this but you need to change a gconf setting which means using gconf-editor (a GUI program) or gconftool (a command line program).\nUsing gconf-editor, go to /apps/gnome-terminal/profiles/Default/use_theme_background and set it to false.\nAlternatively, in a terminal window, type:\ngconftool -s /apps/gnome-terminal/profiles/Default/use_theme_background -t bool false\n\nThe transparency should disappear.\n", "Q: Customize software sources for Ubuntu Desktop updater to manage? I love the software updater in Ubuntu Desktop and want to configure underlying package managers  with other sources of software.  Sometimes I run into a new software project that isn't delivered through the updater. I install the software outside the updater but I know there's some way to tell the updater to monitor it for updates. \nLooking for leads on where to find the best info (for a newbie) to customize the sources of software updating in Ubuntu Desktop.\n\nA: If the outside sources are PPAs, you can simply add them in the Third Party tab.  If you're compiling from source or downloading random .deb files from the Internet (not from a PPA page or Debuntu or Medibuntu, which do have full repos), then the Update Manager can't handle those.\n\nA: Basically the updater program (update-manager) needs an APT source url, which can be an ftp-server or http-server. But the files on the server needs to be structured in a special way for the updater to work and you can't just add anything to it. These servers are often referred to as repositories (or repos).\nA lot of 3rd party applications are available in their own repositories, often you will encounter instructions to add some lines to /etc/apt/sources.list but you can instead add them through the GUI by going to System > Administration > Software Sources and in the Other Software tab clicking Add... These lines will always start with deb and can look like this one for Oracle VirtualBox\ndeb http://download.virtualbox.org/virtualbox/debian lucid non-free\n\nPPA's (Personal Package Archives) is a shortcut (of sorts) to doing this for some programs, but only the ones that are hosted at launchpad.net there is a bit of information on PPA's on this page. Afaik the only way to add PPA's is through the command line (terminal) with this command:\nsudo add-apt-repository ppa:launchpad-user-name/name-of-repos\n\nlaunchpad-user-name and name-of-repos will be differnt in the real world!\nYou will find the names of the different PPA's on launchpad or you might find people that refers to them on 3rd party sites.\nAfter adding a new source the programs from the new source will appear in the software management tools like Ubuntu Software Centre (or what it's called, I use aptitude on a command line ;)\n", "Q: Using Ubuntu with a two-screen setup I have to install Ubuntu on a two-screen setup. How should I do that and what are some specific things that I should keep in mind while doing it. Will it break anything?\nI use an ATI graphics card\n\nA: System -> Preferences -> Monitors gives you a useful graphical interface to easily set this up. This works very well for me using the open source ATI drivers. I doubt you will encounter any great problems (using a fairly mainstream graphics card). If you're using proprietary drivers you may need to use the vender's own tool, e.g. the Nvidia config utility.\nIt shouldn't 'break' anything, the worst case scenario is you end up with the same thing on both screens.\n\n\nA: Depends on your video drivers. For nvidia you need to use the nivida configure tool. However to make it premenent, you need to run it from command line sudo nvidia-settings and save to x-config after you set it up.\nI didn't notice the ATI comment. I am unfamiliar with ATI's flags, I tend to avoid ATI cards because of their shitty linux drivers, I fought with them enough for a lifetime.\n\nA: I had difficulty getting my ATI card to work in anything other than mirror mode until I settled on the steps at https://askubuntu.com/a/104265/19802\nApart from that - things to keep in mind\n\n\n*\n\n*drivers may not install first time (never have for me with ATI)\n\n*get familiar with gui recovery; one attempt had it doing something horrible after I tried extending the desktop (either not starting the gui, or black screens; perhaps it crashed after I hit ok into a corrupt xorg state). Best to have a second computer handy with your favourite search engine ;)\n\n*Will it break anything? Quite possibly. The variations are far and wide. \n\n\nOne useful item I just discovered was Alt+Ctrl+F2 to get to a terminal screen and then unity &disown to relaunch the desktop (without closing applications - yay!) Alt+Ctrl+F7 will get you back to the new desktop - complete with shortcut keys (like Alt+Tab). Ok, so I was clicking on everything in compiz to test out my new speed,but still...\n", "Q: Preventing Video Playing lag in Flash \nPossible Duplicate:\nWhy are Flash applications so sluggish in Ubuntu? \n\nI have just installed Ubuntu for a friend. He uses 32 bit. When he views YouTube videos full-screen there is a kind of lag. He is using an ATI 1 GB graphics card. This doesn't happen when he is not in full screen mode. Is there any workaround to prevent this?\n\nA: A better video card might help.\n", "Q: Player for internet radio I used mplayer -options url://to/radiostation to listen to internet radio for some time. However I'd like to use another software for this. What do you use and what do you consider the advantages of this software?\n\nA: Try \"Radio Tray\"!\nIt's quite new and active developed. And really small.. http://radiotray.sourceforge.net/\nDevelopment Blog: http://linuxsoftware.blogsome.com/category/radio-tray/\n\nA: Personally I like to use VLC for most media playing. Since it can play just about anything.\nIt does internet radio and playing other media streams such as RTP and UDP.\nhttp://wiki.videolan.org/What_can_vlc_do%3F#Listen_to_online_radio\nhttp://www.engadget.com/2005/11/29/how-to-stream-almost-anything-using-vlc/\n\nA: I use streamtuner  a lot to listen to radio stations.\n\n\n*\n\n*Browse the SHOUTcast, Live365 directory, Xiph.org (icecast.org/Oddsock) directory and basic.ch DJ mixes\n\n*Manage your local music collection, with full support for ID3 and Vorbis metadata editing\n\n*Listen to streams, browse their web page, or record them using programs such as  streamripper \n\n*Implement new directory handlers as tiny Python scripts or as dynamically loadable modules written in C\n\n*Retain your favourite streams by bookmarking them\n\n*Manually add streams to your collection\n\n\n\n\n\nA: Any player can play a radio stream, the idea is to find the radios that you want.\nAfter trying different ways of listening to internet radio, I think the best way is to create your own playlists of radio stations and then play them in your favorite music player and benefit from all the player's enhanced features, instead of using already compiled lists provided by a  limited \"radio player\", while many radio stations are usually full of pub or plainly stupid, and the big number does not help finding the best ones. Better find them and save the ones you want in a playlist.\nIn order to find radios, there are a lot of ways, the internet is full of them. A radio player can be an initial way to find some radios, but searching the internet is a good way to refining criteria. One can go to a dedicated site like shoutcast, jazzradio.fr or very comprehensive, like listenlive.eu and others, or search by different criteria (like high bitrate, and get something like search for \"radios high bitrate\").\nMany radio stations provide a pls or similar file that can be opened, saved or added into a larger playlist. The way the stream location is provided may vary. \n\n\n\n\nOr the stream link may be visible:\n\nAnd open URL/Location in an audio player.\nDoing this for the best radios you find may lead to a long playlist that you can save and share. (Here are my present best radio playlists for jazz and classical music.)\nTo play such playlists better use a light and good audio player that would load/buffer instantly like Deadbeef or Audacious. VLC will do fine. I prefer DeaDBeeF (easy manipulation of playlists is important here).\nI find this method very comfortable, for it gives easy access to what you most like and to change between stations. \n\n\nA: Personally, I enjoy Amarok, and usually play streams in it. http://amarok.kde.org Many streams can be added via the script engine (Cool Streams and such), and individual streams can be added from the menus: Playlist > Add Stream. If you want to reuse that stream, save the playlist with the disk icon on the bottom of the playlist, then right-click to rename with an appropriate stream name if you want.\nValorie\n\nA: My brother uses audacious. Personally i use mplayer in a ssh+screen session to my media/nas-server..\nBut if there is anything mplayer can't handle i use cvlc (vlc commandline)\n\nA: VLC 1.1.x doesn't come with the huge online radio list it used to so I definitely recommend Tunapie which you can use with any audio player, including VLC.\n\nA: I like Rythmbox, as I listen to some podcast like Linuxoutlaws PaulDotCom ... I like to keep it all together.\nalso you can access Last.fm and manage your record tracks.\nFeatures:\n\n\n*\n\n*Music playback\n\n*Gapless playback\n\n*Music importing\n\n*Audio CD burning\n\n*Album cover display\n\n*Song lyrics display\n\n*Last.fm support\n\n*Jamendo support\n\n\nA: Try Exaile. It's lightweight, has plugins for Shoutcast radio and is very influenced by Amarok but is built for GTK. I enjoy it thoroughly!\n", "Q: How do I add a user to the \"sudo\" group? In /etc/sudoers I see this:\n# Allow members of group sudo to execute any command after they have\n# provided their password\n# (Note that later entries override this, so you might need to move\n# it further down)\n%sudo ALL=(ALL) ALL\n\nSo how do I add a user to that sudo group?\n\nA: You can either use the user management GUI for it (same place where you create users), or use sudo adduser <username> sudo in the command line.\n\nA: sudo gpasswd -a $USER sudo\n\nA: sudo usermod -aG sudo <username>\n\nThe a is very important. Without it they'll be removed from all other groups. You will need to either restart your shell/terminal or log out and back in for this to take effect. \nSee also: \n\n\n*\n\n*How can I add a new user as sudoer using the command line?\n\nA: I am late to the party, but this answer might help someone that uses Ubuntu inside a Docker container.\nI recently created a Docker container based on Ubuntu 16.04.1.\nBy default, the Docker Ubuntu image is a stripped down version of Ubuntu, which does not have a vast majority of common tools including sudo.\nBesides, by default, the user is logged in to the Docker container as root.\nTherefore, I started the container with the docker run command, and installed the 'sudo' package:\nroot@default:/# apt-get install sudo\n\nRunning the command adduser myuser sudo reported error adduser: The user 'myuser' does not exist..\nAfter reading this answer, I first ran the command to create the user:\nroot@default:/# adduser myuser\n\nThen ran the following command:\nroot@default:/# adduser myuser sudo\nAdding user `myuser' to group `sudo' ...\nAdding user myuser to group sudo\nDone.\n\nThe user myuser was successfully added to the sudo group.\n\nA: Here's how I setup a non-root user with the base image of ubuntu:18.04:\nRUN \\\n    groupadd -g 999 foo && useradd -u 999 -g foo -G sudo -m -s /bin/bash foo && \\\n    sed -i /etc/sudoers -re 's/^%sudo.*/%sudo ALL=(ALL:ALL) NOPASSWD: ALL/g' && \\\n    sed -i /etc/sudoers -re 's/^root.*/root ALL=(ALL:ALL) NOPASSWD: ALL/g' && \\\n    sed -i /etc/sudoers -re 's/^#includedir.*/## **Removed the include directive** ##\"/g' && \\\n    echo \"foo ALL=(ALL) NOPASSWD: ALL\" >> /etc/sudoers && \\\n    echo \"Customized the sudoers file for passwordless access to the foo user!\" && \\\n    echo \"foo user:\";  su - foo -c id\n\nWhat happens with the above code:\n\n\n*\n\n*The user and group foo is created.\n\n*The user foo is added to the both the foo and sudo group.\n\n*The uid and gid is set to the value of 999.\n\n*The home directory is set to /home/foo. \n\n*The shell is set to /bin/bash.\n\n*The sed command does inline updates to the /etc/sudoers file to allow foo and root users passwordless access to the sudo group.\n\n*The sed command disables the #includedir directive that would allow any files in subdirectories to override these inline updates. \n\n\nA: You can also use a graphical interface. Click on the gear on the top right of the panel, then select \"System Settings\" and then \"User Accounts\"\nYou need to click the little unlock button to be able to edit things in this window. Then click on the person's account and select the proper dropdown for \"Account Type\"\n\n\nA: Its really simple if you are using Unity as your desktop environment.\nIf you have created a user already then you can simply change it from Standard to Administrator, else make sure that you selected Administrator when creating a new one.\nDon't forget to unlock before trying to change it\n\n\nA: Use usermod. Add the sudo permission with the following command:\nusermod -aG sudo <your username>\n\nPlease note that you'll have to use the root account to do this or use another account that has sudo permissions. If you don't have access to another account for some reason and you don't know the root password, you'll need an Ubuntu (or another Linux distro) live CD and then you'll need to chroot into your Ubuntu filesystem and run the above command from inside the chroot.\n", "Q: Can't launch Eclipse I've been using Eclipse for quite a while. I just switched from OpenJDK to SunJDK. I went back to using Eclipse, it opened just fine. I added some libraries to my build path of a project, but the error checker was still saying I didn't have it. So I decided to restart Eclipse. After than I can't start eclipse. It doesn't give any errors or anything. If I launch it from the command line, it doesn't do anything:\njoel@joel-laptop:~$ eclipse\njoel@joel-laptop:~$ \n\nIt never pops up the choose workbench dialog or anything.\nHas anyone heard of this? I'm using the latest version from the Ubuntu repos.\nI've tried restarting my machine and reinstalling Eclipse. Nothing.\n\nA: I used apt-get purge eclipse and then apt-get install eclipse and it still did the same thing. I ended up purging Sun JDK and reinstalling Eclipse and it installed OpenJDK. All works again.\nHowever, I'm a little disappointed that it wasn't working with Sun JDK. Oh well. Whatever.\n\nA: UNless you have good reason to, I have found that the best way to run Eclipse is to download it from eclipse.org, and not install the one in the Ubuntu repositories.  Uninstall the repository version, and download one manually and run it.\n\nA: there is a log in workspace/.metadata/.plugins/org.eclipse.ui.workbench/log that you can check although I don't think that's going to work in your case. Also what do you mean you reinstalled eclipse? are you using synaptic or just unzipping into a directory? try which eclipse in case you have many installed to see which is being executed.\ncheck if setting up the JRE manually using the -vm parameter in eclipse.ini changes thing.\n", "Q: What exactly is in ubuntu-desktop? I'm also interested in its variants, like kubuntu-desktop. It appears to include GNOME (or KDE) and a bunch of other things. But it's quite large - is there a breakdown of what is included in ubuntu-desktop and exactly what those items are/do?\n\nA: Too much to list here!\nYou can click through each package for a detailed description. Note these dependant packages have their own dependencies and some of those have even more.\n\nA: The ubuntu-desktop (and similar) packages are metapackages. That is, they contain no data (besides a small documentation file in the case of the *-desktop packages). But they depend on dozens of other packages that make up each of the Ubuntu flavors.\nYou can see a complete listing of each package's dependencies on packages.ubuntu.com. A quick search lists these metapackages.\n\n\n*\n\n*ubuntu-desktop\n\n*kubuntu-desktop\n\n*xubuntu-desktop\n\n*lubuntu-desktop\n\n*edubuntu-desktop\n\n*edubuntu-desktop-kde\nA more detailed explanation of metapackages and a list of some more useful metapackages can be found here.\n", "Q: How to make hibernate/sleep work on laptops where default setup isn't working? I have an Asus r1f laptop. For some reason, hibernate/sleep isn't working properly at all. Are there any other packages I can use or tweaks I can implement to get this working?\nI've googled around and this appears to be an issue with some laptops and their need for proprietary drivers. Is this true? Is there anything I can do?\n\nA: You can try to put the name of your proprietary module (nvidia or fglrx (for ATI) are most likely) in the quotes in MODULE=\"\" in the /etc/default/acpi-support file and reboot.\nsudo nano /etc/default/acpi-support\n\nThis'll make that module unload before suspend and reload after suspend.  It sometimes works, but it's also possible that you have just plain buggy drivers somewhere and need to file a kernel bug.\nEDIT:\nIt's also very possible that you've just plain found a bug. If you think that's the case, please file it:  ubuntu-bug linux\n\nA: You should try µswsusp. From the Wikipedia article:\n\nuswsusp (userspace software suspend)\n  is a suspend-to-ram and\n  suspend-to-disk implementation for the\n  Linux operating system, compatible\n  with kernels 2.6.17 and onwards. It\n  supports both s2ram (\"standby\") and\n  s2disk (\"hibernate\"), as well as a\n  mode called \"s2both\", which saves\n  state to disk and RAM. S2both is\n  intended for use in low-battery\n  situations where restoring from ram is\n  desired but can't be relied on as the\n  battery may fail causing a restore\n  from disk to be necessary.\n\nThe package is available in the Ubuntu Software Center.\n\nA: Are you install your ubuntu with regular installation or use wubi installer?\nCompared with a regular installation, a Wubi installation faces some limitations. Hibernation is not supported and the filesystem is more vulnerable to hard reboots.\n", "Q: Icons on menus have disappeared When i right click to bring up a menu, for example on the desktop, i have 'open terminal here' which i know should have a terminal icon next to this however it doesn't. Any ideas? I had a poke around in gconf-editor but didn't have much luck (though i didn't try very hard ;)\nThanks\n\nA: In gconf-editor go to desktop -> gnome -> interface and check the checkbox for menus_have_icons. There's also a buttons_have_icons which you may want to enable.\nThis was a delibrate 'feature' in Gnome 2.28, from which Ubuntu 10.04 for built.\nThese two options can also be changed through the \"Gnome settings\" panel of Ubuntu Tweak, see screenshot below. (Ubuntu Tweak can be installed through a PPA)\n\n\nA: fluteflute's answer is excellent, but in case anyone wanted to change this setting without using Ubuntu Tweak, you can do this by changing the following two gconf settings to true using gconf-editor (a GUI program) or gconftool (a command line program):\ngconftool --set /desktop/gnome/interface/menus_has_icons --type bool true\ngconftool --set /desktop/gnome/interface/buttons_have_icons --type bool true\n\n", "Q: How can I start my own Repository I'm an avid developer but I never actually gotten around to setting up my own PPA - how would someone go about this? Common issues encountered? How do I get my source code to be compiled into packages on the PPA?\n\nA: There are some tools to help you upload you source tarballs + debian control-files to your PPA on launchpad. And this will tell you how. But uploading the package is a very small part of it all...\nSetting up a build environment and a debian package (.deb) infrastructure in not a simple thing! It requires a good understanding of the package structure and how different types of scripts work (in particular Make and Shell scripts).\nI have found these two guides to be very usefull when i'we been packing .deb's\nUbuntu packaging guide\nDebian new maintainers guide\nBe careful to read all of the Ubuntu packaging guide thoroughly and you should be on your way to victory!\n\nA: Register on Launchpad like txwikinger said, then you need to generate a GPG key\ngpg --gen-key\n\nand upload it to Ubuntu's keyserver\ngpg --keyserver keyserver.ubuntu.com --publish-keys $KEYID\n\nReplacing $KEYID with the number after the slash on the \"sec\" line of:\ngpg -K --fingerprint\n\nClick the green + next to the GPG key part of your profile, and give it the key fingerprint from the earlier command.  You'll receive an encrypted email.  Decrypt it (setup your GPG key in your mail client to make this easier), then click the link inside to verify that you own the key.\nClick on your launchpad.net page to create a new PPA\nFollow the packaging guides Source Lab linked, but unlike what Txwikinger said, you will not upload a deb.  That's because a deb is a binary package, and PPAs take source packages.  After you've got the 4 necessary files (/debian/rules /debian/changelog /debian/control and /debian/copyright) in your source directory and an original tarball of the source outside it, run\ndebuild -S -sa\n\nA source package will be generated consisting of a .debian.tar.gz (if using source format 3.0) or .diff.tar.gz along with a .dsc and a .changes file.  The .dsc and .changes will need to be signed, so you will need to enter your GPG passphrase twice.  The -sa is only needed the first time you upload that package to the PPA.  Later revisions, you can live it off.\nThen you will run:\ndput ppa:youruser/ppa *.changes\n\nObviously filling in your own username, and if you chose a custom name for the PPA, put that after the slash.  The PPA's page on Launchpad will tell you the exact ppa: syntax.\n\nA: You register for an account in https://launchpad.net on your home page you can start your own ppa. The ppa is hosted on launchpad.\nYou compile your sources by creating a .deb package and upload it to your ppa with the dput command. The package will then automatically compiled by launchpad's compile farm and is available on a number of platforms.\nMore information about packaging can be found in the wiki about packaging.\n", "Q: CCleaner equivalent? I frequently use ccleaner to (cover my tracks), clean up unused data stored on my computer from web traffic and hotfixes on my windows system.\nI was wondering if there is a piece of software that does the same thing for ubuntu that ccleaner does for windows?\nPlease and thank you.\n\nA: You could use the user switcher applet to open a Guest Session.\nDo whatever it is you need to do and then log out. \nThe history is not associated with your account and in any case and is lost when the guest session ends.\n\nA: I practice various methods to auto clean my disk which I'm mentioning here. Hope this helps.\n1.Use Disk Usage Analyzer by going to Applications->Accessories->Disk Usage Analyzer and click on the Scan Filesystem at the top to get it to analyze your disk usage pattern.\nNow u can easily analyze which files are waste and its time to trash them.\n2.Clean up your package installation using the following commands.\nclearing up of the partial packages: sudo apt-get autoclean\nclearing up of the apt-cache :sudo apt-get clean\ncleaning up of any unused dependencies: sudo apt-get autoremove\nA good practice to avoid any left behind is to use the autoremove command whenever you want to uninstall an application.\nsudo apt-get autoremove application-name\n\n3.Use Computer Janitor by going in Administration->Computer Janitor. It automatically scan and displays all the unused packages which can easily be deleted. But be careful it also shows the .deb packages installed manually(i.e. not using apt-get).\nAnd I'd suggest u to check out this page for more advanced techniques.. \nHope that was useful.\n\nA: BleachBit (Available in the software center)\n\nBleachBit quickly frees disk space and tirelessly guards your privacy. Free cache, delete cookies, clear Internet history, shred temporary files, delete logs, and discard junk you didn't know was there. Designed for Linux and Windows systems, it wipes clean 90 applications including Firefox, Internet Explorer, Adobe Flash, Google Chrome, Opera, Safari,and more. Beyond simply deleting files, BleachBit includes advanced features such as shredding files to prevent recovery, wiping free disk space to hide traces of files deleted by other applications, and vacuuming Firefox to make it faster. Better than free, BleachBit is open source.\n\nUbuntu Tweak\n\nUbuntu Tweak is an application to\nconfig Ubuntu easier for everyone.\nIt provides many useful desktop and\nsystem options that the default\ndesktop environment doesn't provide.\nWith its help, you will enjoy with the\nexperience of Ubuntu!\n\n\nA: Computer Janitor can clean up old kernels and a bunch of other stuff.  For history/cookies/etc, I like to just set Firefox to delete all that every time I close the browser.\n\nA: I am going to support BleachBit here as it does more than things like Janitor, like tracking down .DS_Store files (I have a Mac on my LAN) and thumbs.db and other trash files.  I also like Ubuntu Tweak for easy, safe kernal cleanup.\n", "Q: Wake from hibernate on ssh request Is there a feature (or aptitude package) in Ubuntu 10.04 that will wake my computer up from standby when it gets an ssh (or other webrequest).\nI've been trying to put my computer in hibernate/standby when I'm not running code in an effort to \"go green\" at my university.  However, I often need to ssh into my computer over the weekend to do work.  However, it does not seem to \"wake-up\" to hear this request.  I remember on my old windows machine there was a \"Wake-on-LAN\" option to the hibernate command.  So if I needed to remote-desktop in while it was asleep it would wake up.\nCan anyone request a good way to replicate this feature?\nThanks,\nWill \n\nA: You need some device on your local network which can send the WOL package needed. It must be the local network because the package isn't forwarded by routers to other network segments.\nThe perfect device to do this, would be your router.  Unfortunately very few routers support this, but if you get one which use OpenWRT or similar you can install software which can generate the necessary WOL packet waking up the machine you actually want to talk to.\n\nA: The Ubuntu Forums has an excellent Guide. You will need to wake the machine with a WOL packet before you ssh in though.\n\nA: I believe here it the link that would help you out :) \nThere are clear instructions for setting up to WOL (wake on lan)\n\nA: Wake On LAN is something you can enable in the BIOS.\n\nA: If you use an OpenWRT/Tomato based router, a shell script I wrote that runs on the router and wakes up any PC that's receiving an incoming SSH connection, might be of use to you.\n", "Q: Automatic logoff I had a problem with my Ubuntu 10.04 that automatically log off while working,Even i working with Excel its automatically log off and returned to login screen,i checked it all the power settings and updated all it to never.Also i disabled screen saver.In some forums they are telling that keystroke is enabled in your keyboard thats why your facing this,but i don't know where it is....\nI think the problem will be small,but i don't know where the problem is.........\nAnybody help me to solve this problem,Awaiting for answer............\n\nA: A Windows machine with the same symptoms turned out to have a bad memory module. If you have a Ubuntu live CD, use it to run a memory check.\n\nA: You've had an X crash.  Usually when this happens a 'backtrace' will be printed to the end of your /var/log/Xorg.0.log or /var/log/Xorg.0.log.old.  Look in those files for a backtrace.\nMore information about troubleshooting X crashes is available at http://wiki.ubuntu.com/X/Backtracing/.\n", "Q: How to update mod_wsgi to latest version on Ubuntu 10.04? My Ubuntu server has this version installed:\n# dpkg -l | grep wsgi\nii  libapache2-mod-wsgi  2.8-2ubuntu1  Python WSGI adapter module for Apache\n\nHow can I get the latest Version 3.3?\n\nA: Download and compile it. There is a pretty good README in their source package. But you can start by installing build-essential the basic system for compiling, then just follow the README\n\nA: sudo apt-get build-dep libapache2-mod-wsgi\nAnd then you can build from source reading the readme\n\nA: Debian has libapache2-mod-wsgi, but this won't work on Ubuntu 10.04 because it depends on libpython2.7 for which there's no package for 10.04.\nI downloaded the source from here:\n$ wget http://modwsgi.googlecode.com/files/mod_wsgi-3.3.tar.gz\n\nThen just\n./configure\nmake\nsudo make install\n\n\nA: What worked for me was running this :\nsudo aptitude install libapache2-mod-wsgi\n\n\nA: I had mod_wsgi installed for python 2.7. I ran the below command to uninstall 2.7 and install 3.6 (my python version).\nsudo apt-get install libapache2-mod-wsgi\n\n", "Q: view or convert MDI file I have some insurance files that I need to be able to view, but they are in the MDI format I can't get them to work at all in Ubuntu. \nI've searched the entire forum and I've even installed Microsoft office 2003 & 2007 through Wine, but it still doesn't work correctly. \nThe only solutions posted in the forum have suggested getting an MDI to pdf converter or installing MS office.  I haven't gotten any of this to work.\nHow can I view or convert MDI files?\n\nA: File format descriptions of this say something like: \"\"\"The MDI is a a high resolution, tag-based graphics format. MDI files are only supported by the Microsoft Office 2003 version (NOT supported in Office 2007) of Microsoft Office Document Imaging. If you are going to share files with people who are using Office Document Imaging 2002, or another document imaging program, save your files in TIFF format for compatibility.\"\"\"\nSo apparently even Microsoft doesn't support this format anymore...  Maybe you can tell the insurance company that you don't have that antique MS Office version (anymore)?  (And in the mean time, use Document Viewer as \"moberley\" suggests.)\n\nA: I didn't have access to any Microsoft Document Imaging (MDI) files to test out on my system, but I figured I'd see if I could get the Bugysoft MDI2PDF converter (a Windows program) to run with Wine. I got some errors from the installer and was not able to get the program to start up.\nHowever, MDI2PDF did include a example single page MDI file which I was able to open in the Gnome Document Viewer (on Ubuntu 10.04). I did have to manually select the Document Viewer application to open the file because Ubuntu did not associate the .mdi extension.\n\nA: I've seen a lot of poor reviews for Bugysoft MDI2PDF.\nA lot of people seem to recommend PrimoPDF which doesn't explicitly advertise MDI conversion but its users do. It also does more than MDI2PDF. But does it work on Wine? Well I'll leave that to you to find out.\n", "Q: Keyboard/Mouse not recognised during installation I have a Logitech MX5000 keyboard/mouse combo. I'm using the Logitech Bluetooth dongle, and I use it in USB emulation mode (not native Bluetooth).\nI tried to install Ubuntu 10.04 using WUBI. After the Ubuntu setup started natively, the keyboard and mouse refuse to work.\nI have no other keyboards or mice around. I tried unplugging and re-plugging the USB dongle to make sure it's in USB mode and not Bluetooth, but when I do that the keyboard refuses to re-pair with the dongle (using the connect buttons). Rebooting into Windows 7 and the keyboard/mouse instantly come back.\nAny ideas how I can get Ubuntu 10.04 installed?\n\nA: Unfortunately, I don't know what the problem is but I did come across this program called HIDpoint which is a configuration program for a variety of Logitech input devices (and a couple of others). I can't say if it will help with your issue, but I thought it might be worth investigating if nothing else is working.\nHIDpoint's supported devices page lists a Logitech MX5000 keyboard but I don't see an MX5000 mouse there. The download page says that it supports Ubuntu 10.04 and Ubuntu 10.04 64bit.\n\nA: I had the same problem with this desktop around Ubuntu 8.10. The workaround was to uninstall bluez-utils (I think, or bluetooth completely). This made it work, but I eventually put it on ebay and bought a mx1000 with a standard keyboard.\n", "Q: How are administrators supposed to read root's mail? What is the Ubuntu way for system administrators to receive system notifications, which typically take the form of e-mail sent to the root account?\nExamples of such notifications are the output of cron jobs, or degraded RAID notifications.\nOn a pretty much default Ubuntu 10.04 installation, I can't find any way that anything happens to root's mail other than being deposited in /var/mail/root. How are users supposed to 1. discover it and 2. read it as it arrives?\nI observe that on a warty, the installer added root: myusername to /etc/aliases. So back then the user who installed the system if (s)he read the local mail. So there seems to have been a regression somewhere along the way. Still this was not a complete solution, because Ubuntu users can't be expected to be aware that they have local mail and should set up their mail client to read it.\nADDED: given current replies, a server user should be able to cope, provided he's aware of the issue. Fair enough. But consider J. Random Desktop User, who doesn't know how to use a command line, and only knows how to click the mailbox icon to read his mail. How can he be notified that his system wants to tell him something? (Allow a one-time intervention by a more competent user if that's unavoidable.)\n\nA: Encouraged in the comments by Gilles, I have adapted and expanded another answer:\n\n\n*\n\n*How do I read local email in thunderbird?\n(I am running Ubuntu 12.04.1 LTS, but the general setup process should apply to previous and future Ubuntus)\n\nThe first thing to do is to install a Mail Transfer Agent (MTA) so the mail can be relayed to a mail User Agent (MUA) such as Thunderbird. This is only necessary because we are dealing with local mail and want to be able to send and receive it; with normal remote gmail type accounts, only a user agent such as Thunderbird is necessary.\nI use postfix, which itself is an alternative to sendmail, of which there are commercial and open source versions. More information about postfix's capabilities is at the official site and users may find that the mailing lists contain useful information if any issues arise. \nSo, to install the program, run\nsudo apt-get install postfix\n\nYou can either configure it when it is installed, or decline the offer and later run \nsudo dpkg-reconfigure postfix\n\nto create the important config file (/etc/postfix/main.cfg). If you ever manually edit this file, which is not necessarily recommended, you must run sudo newaliases and sudo service postfix restart afterwards to apply the changes.\nPostfix is pretty straightforward to setup, although you may have some particular settings that you wish to apply. In the first screen you see below, you must choose the local option for your mail:\n\nThen on the next screen choose your 'mail name'; it is usually the same as /etc/hostname. You can accept the defaults for most of the following screens. \n\nWhen it mentions /etc/aliases and the Root and Postmaster recipient (as above), you can fill in your user name, but make sure you check your aliases file is as it should be by reading the next section of this tutorial. \nFirst, as also recommended in this discussion, your /etc/aliases should be like this if it is setup correctly:  \npostmaster:    root\nroot:   mike \n\nIf not, edit it with sudo nano /etc/aliases, and then run sudo newaliases and sudo service postfix restart so that the configuration is updated. Postfix's aliases feature allows mail to be redirected, so the setup is very important for the rest of this tutorial.\nAs also noted in the above link, you need to create a .forward file containing your username and localhost: e.g. mike@localhost so that root's mail will be forwarded to you. To do this, enter these commands:\nsudo touch /root/.forward\n\nand then run    \nsudo nano /root/.forward\n\nto place your user: e.g. mike@localhost in the file and save it.\nIn addition, I found it was necessary to add your user to the mail group so that Thunderbird could access the mail files:\nsudo adduser $USER mail\n\nand then logout and login for the changes to take effect. There is no need to chown or chmod any files, as some articles might suggest, and adding your user to the mail group is much better practice and avoids any direct changing of the permissions on the root filesystem.\n\nNow for the Thunderbird configuration. Go to edit > account settings > account actions > add other account > select Unix spoolmail and in the next screen put your username in the first box and place yourusername@localhost in the second box.\n\n\nNow, go to your new account in account settings and select server settings and select the local directory as /var/mail or /var/mail/username (if setup), as in the screenshot below.\n\nAs per the instructions in this article you will need to configure the smtp server if you want to test the account by sending a mail to root@localhost and then clicking get mail in Thunderbird to receive it, as root's mail is being redirected to youruser@localhost. \nGo to account settings > outgoing server and choose to add a new one. The settings should be as in the screenshot below:\n\nNow, finally test your account by composing a mail to root@localhost and then a few seconds later clicking get mail on your account. You should see an email like this:\n\nSome programs or logs will need to be configured so that they send mail to root, but that can be decided as you find the need. This article should hopefully be useful as it is not always straightforward to set up Thunderbird to receive local mail.\n\nA: Currently there is no notification to the user that a root local mailbox even exists, because user != root If you needed to check the mailbox you could type the following: sudo mail to launch the mail application under root.\nYou could also log in as root on that server. To unlock the root password simply type: sudo passwd and enter a new password for root.\n\nA: If this is a server I would strongly suggest you alias root to a real email address so you get your email delivered to your administrators\nIt is as easy as adding \n# Person who should get root's mail\nroot:   all_administrators@mydomain.com\n\nto the end of /etc/aliases \nAlternatively you can configure mail to be aliased to your local username and then when you log in you will get the message \"You have mail\", which you can check using the mail command or by installing pine / mutt /alpine or something similar on that server..\n\nA: Using any mail compatible client (like Thunderbird) in your session\nYou can easily expose your local mail using POP3 / IMAP protocol\n\n*\n\n*Redirect root mail to your user\nsudo echo \"root: $USER\" > /etc/aliases # $USER is myuser\n\n\n\n*Expose your local mail as POP3 or IMAP with mailutils\nsudo apt install mailutils-pop3d  # POP3\n\nor\nsudo apt install mailutils-imap4d # IMAP\n\n\n\n*Restart your system\n\n\n*Add it to your mail client\nIn Thunderbird you just have to input user@localhost and your user's login password\n\nA: I am personaly using a mailer agent called nullmailer. It acts as a mail proxy, and transfers all mails sent to root to a mail address of your choice.\nYou need to set its settings in conf files under /etc/nullmailer. Basically : give it your mail porvider address and credentials, and the adress you want to receive the root emails on.\nYou can install it with\nsudo apt-get install nullmailer\n\nYou can get more information on its setup here : \nhttp://jviz.research.iat.sfu.ca/wiki/index.php?title=HOWTO_Setup_Nullmailer\n\nA: An alternative -\nI archive all root mail to some files, and then delete the original mail.\nI cron a script (here is the key part) -\n#!/bin/bash\nif `/usr/bin/mail -e`; then\n   /usr/bin/mail --print 2>&1 > /tmp/email_${date +\"%Y-%m-%d_%H.%M\").log\n   echo ‘d *’ | /usr/bin/mail -N > /dev/null\nfi\nexit 0\n\nThis keeps things tidy and I can keep an eye on it.\nI could email a daily mail file out to an external email id, etc...\n", "Q: How to set up an Ubuntu 10.04 machine to accept ssh requests only from within the local network? I am about to install 10.04 (from bare metal to replace 9.04) and I want to set it up so that I can shh into the machine, but only from other machines on my local network. (I.e., I want to reject all ssh attempts from other than 192.168.1 set of IPs.) How do I do that correctly on 10.04?\n\nA: In addition to using hosts.allow and hosts.deny, you can use firewalls. \"ufw\" is installed by default in Ubuntu. You enable it with\n\nsudo ufw enable\n\nand then limit the ssh connectivity with `\n\nsudo ufw allow from 192.168.1.0/24 to\n  any app OpenSSH\n\nThat should do it. I believe the FireStarter application will allow a GUI configuration of ufw as well.\n\nA: You have to edit the two configuration files /etc/hosts.allow and /etc/hosts.deny (you can get a detailed explanation of the format with man hosts_access):\netc/hosts.allow:\nsshd: 192.168.1.\n\netc/hosts.deny:\nsshd: ALL\n\nIn both cases you could replace sshd with ALL, then these rules would not only apply to the ssh server but to all other daemons that might be running.\n", "Q: How to harden an SSH server? What measures can/should I take to make sure that security around my SSH server is absolutely impermeable?\nThis will be community wiki from the start, so lets see what people do to secure their servers.\n\nA: There is a Debian Administration article on this topic. It covers basic SSH server configuration and also firewall rules. This could be of interest also to hardened an SSH server.\nSee there article: Keeping SSH access secure.\n\nA: I would suggest:\n\n\n*\n\n*Using fail2ban to prevent brute force login attempts.\n\n*Disabling logging in as root via SSH. This means an attacker had to figure out both the username and the password making an attack more difficult. \nAdd PermitRootLogin no to your /etc/ssh/sshd_config.\n\n*Limiting the users that can SSH to the server. Either by group or just specific users. \nAdd AllowGroups group1 group2 or AllowUsers user1 user2 to limit who can SSH to the server.\n\nA: My approach to SSH hardening is... complex.  The following items are in terms of how I do it, from the edge-most border of my network(s) to the servers themselves.\n\n\n*\n\n*Border-level filtering of traffic through IDS/IPS with known service scanners and signatures in the blocklist.  I achieve this with Snort via my border firewall (this is my approach, a pfSense appliance).  Sometimes, I can't do this though, such as with my VPSes.\n\n*Firewall/Network filtering of the SSH port(s).  I explicitly only allow certain systems to reach into my SSH servers.  This is either done via a pfSense firewall at the border of my network, or the firewalls on each server explicitly being configured.  There are cases where I can't do this, though (which is almost never the case, except in private pen-testing or security testing lab environments where firewalls won't help test things).\n\n*In conjunction with my pfSense, or a border firewall NAT-ing the internal network and separating from the Internet and the systems, VPN-Only Access to Servers.  Gotta VPN into my networks to get to the servers, because there's no Internet-facing ports as such.  This definitely doesn't work for all my VPSes, but in conjunction with #2, I can have one VPS be the 'gateway' by VPNing into that server, and then permit it's IPs to the other boxes.  That way, I know exactly what can or cannot SSH in - my one box that is the VPN.  (Or, in my home network behind pfSense, my VPN connection, and I'm the only one with VPN access).\n\n*Where #3 is not doable, fail2ban, configured to block after 4 failed attempts and block the IPs for an hour or more is a decent protection against people constantly attacking with bruteforcing - just block em at the firewall automatically with fail2ban, and meh.  Configuring fail2ban is a pain though...\n\n*Port obfuscation by changing the SSH port.  However, this is NOT a good idea to do without any additional security measures as well - the mantra of \"Security through Obscurity\" has already been refuted and disputed in many many cases.  I have done this in conjunction with IDS/IPS and network filtering, but it's still a VERY poor thing to do on its own.\n\n*MANDATORY Two-Factor Authentication, via Duo Security's Two-Factor Authentication solutions.  Every single one of my SSH servers has Duo configured on it, such that in order to even get in, 2FA prompts happen, and I have to confirm each access.  (This is the ultimate helpful feature - because even if someone has my passphrase or breaks in, they can't get past the Duo PAM plugins).  This is one of the biggest protections on my SSH servers from unauthorized access - each user login MUST tie back to a configured user in Duo, and since I have a restrictive set, no new users can be registered in the system.\nMy two-cents to securing SSH.  Or, at least, my thoughts on approach.\n\nA: Other answers provide security, but there is one thing you can do which will make your logs quieter, and make it less likely that you'll be locked out of your account:\nMove the server from port 22 to another one. Either at your gateway, or on the server.\nIt doesn't increase the security, but does mean all the random internet scanners won't clutter up you log files.\n\nA: Enable two factor authentication with HOTP or TOTP. This is available from 13.10 onwards.\nThis includes using public key authentication over password authentication as in another answer here, but also requires the user prove he holds his second-factor-device in addition to his private key.\nSummary:\n\n\n*\n\n*sudo apt-get install libpam-google-authenticator\n\n*Have each user run the google-authenticator command, which generates ~/.google-authenticator and helps them configure their two factor devices (eg. the Google Authenticator Android app).\n\n*Edit /etc/ssh/sshd_config and set:\nChallengeResponseAuthentication yes\nPasswordAuthentication no\nAuthenticationMethods publickey,keyboard-interactive\n\n\n*Run sudo service ssh reload to pick up your changes to /etc/ssh/sshd_config.\n\n*Edit /etc/pam.d/sshd and replace the line:\n@include common-auth\n\nwith:\nauth required pam_google_authenticator.so\n\nMore details on different configuration options are my blog post from last year: Better two factor ssh authentication on Ubuntu.\n\nA: Make the sshd block client IP's that have failed to supply correct login information \"DenyHØsts\" can do this job quite effectively. I have this installed on all my Linux boxes that are in some way reachable from the great outside.\nThis will make sure that force-attacks on the SSHD won't be effective, but remember (!) this way you can end up locking yourself out if you forget you password. This can be a problem on a remote server that you don't have access to.\n\nA: Here's one easy thing to do: install ufw (the \"uncomplicated firewall\") and use it to rate limit incoming connections. \nFrom a command prompt, type:\n$ sudo ufw limit OpenSSH \n\nIf ufw is not installed, do this and try again:\n$ sudo aptitude install ufw \n\nMany attackers will try to use your SSH server to brute-force passwords. This will only allow 6 connections every 30 seconds from the same IP address. \n\nA: If I want to have some additional security or need to access SSH servers deep inside some corporate network I setup a hidden service by using the anonymisation software Tor.\n\n\n*\n\n*Install Tor and setup the SSH server itself.\n\n*Make sure sshd only listens at localhost.\n\n*Open /etc/tor/torrc. Set HiddenServiceDir /var/lib/tor/ssh and HiddenServicePort 22 127.0.0.1:22.\n\n*Look at var/lib/tor/ssh/hostname. There is a name like d6frsudqtx123vxf.onion. This is the address of the hidden service.\n\n*Open $HOME/.ssh/config and add some lines:\nHost myhost\nHostName d6frsudqtx123vxf.onion\nProxyCommand socat STDIO SOCKS4A:127.0.0.1:%h:%p,socksport=9050\n\nFurthermore I need Tor on my local host. If it is installed I can enter ssh myhost and SSH opens a connection via Tor. The SSH server on the other side opens its port only on localhost. So nobody can connect it via \"normal internet\". \n\nA: Use public/private key pairs for authentication instead of passwords. \n\n\n*\n\n*Generate a passphrase-protected SSH key for every computer that needs to access the server:\nssh-keygen\n\n*Permit public-key SSH access from the allowed computers: \nCopy the contents of ~/.ssh/id_rsa.pub from each computer into individual lines of ~/.ssh/authorized_keys on the server, or run ssh-copy-id [server IP address] on every computer to which you are granting access (you'll have to enter the server password at the prompt).\n\n*Disable password SSH access:\nOpen /etc/ssh/sshd_config, find the line that says #PasswordAuthentication yes, and change it to PasswordAuthentication no. Restart the SSH server daemon to apply the change (sudo service ssh restart).\nNow, the only possible way to SSH into the server is to use a key that matches a line in ~/.ssh/authorized_keys. Using this method, I don't care about brute force attacks because even if they guess my password, it will be rejected. Brute-forcing a public/private key pair is impossible with today's technology.\n\nA: You might want to checkout the FreeOTP app from RedHat instead of using Google Authenticator. Sometimes when updating the app, they lock you out! ;-)\nIf you want to use other hardware tokens like a Yubikey or an eToken PASS or NG or if you have many users or many servers, you might want to use an opensource two factor authentication backend.\nLately I wrote a howto about this.\n\nA: For large numbers of users/certificates consider LDAP integration. Large organizations use LDAP as a repository for user credentials and certificates stored on badges or fobs, whether the certificates are used for authentication or signing emails.  Examples include openLDAP, openDJ, Active Directory, Oracle Universal Directory, IBM Directory Server, snareWorks...\nComputers and groups can also be managed in LDAP giving central credential management. That way help desks can have a one stop shop to deal with large populations.\nHere's a link to centOS integration: http://itdavid.blogspot.com/2013/11/howto-configure-openssh-to-fetch-public.html \n\nA: I wrote a small tutorial on doing this recently. Basically, you need to be using PKI and my tutorial also shows how to use Two-Factor Authentication for even more security.  Even if you use none of those things, there's also some tidbits about securing the server by removing weak cipher suites and other basics. https://joscor.com/blog/hardening-openssh-server-ubuntu-14-04/ \n\nA: You can also block based on country of origin using the geoIP database. \nBasically if you live in the US then there is no reason for somebody in Russia to connect to your SSH so they will be automatically blocked. \nThe script can be found here: https://www.axllent.org/docs/view/ssh-geoip/\nYou can also add iptables commands to it (I did for my droplets) to auto drop all traffic to/from those IPs.\n", "Q: How to setup a machine to host my websites to the world - with my own url? I have been playing around with my blog, alot. I have couple of old computers laying around i want to put to use. \nI was wondering if there is a way to setup a server, then will be linked to a url that i buy and server pages and maybe even install wordpress.\nAny information on setting that up on Ubuntu 10.04 Desktop would be amazing. \nPlease and thank you.\n\nA: Setting up a webserver on Ubuntu is very easy to do you can either use apt-get and install Apache, PHP and MySQL manuall or use tasksel to install the LAMP stack.\nsudo tasksel install lamp-server\nhttps://help.ubuntu.com/community/ApacheMySQLPHP\nOnce that's done you'll be able to setup your blog on the local machine and get it running. \nYou can follow the guide here for how to install wordpress under Ubuntu or follow this one for a generic guide on how to get installed. \n--\nNext steps\n\n\n*\n\n*Buy the domain (I get mine from 123-reg.co.uk)\n\n*Point domain to your IP address\n\n*\n\n*If you have a static IP simply point the domain to that IP.\n\n*If you don't have a static IP you'll need to use a service like dyndns to update the DNS records as your IP changes. \n\n\n*Depending on your network setup you will then either need to use port forwarding to forward port 80 to your machine running apache or use NAT on your router to connect your public IP address to the IP of your machine. \n\n\n-- \nSome other points\n\n\n*\n\n*You would be better using Ubuntu Server if possible on the machine as its more designed for the task and there is no need for a GUI on a web box.\n\n*If your website / blog becomes popular you may find your internet connection is not capable of handling the load as most home internet connections do not have very good upload speed. \n\n\nA: Wordpress is in the universe repository.  You can install via apt-get or synaptic and all the dependencies will get pulled in.  More documentation here.\nTo host a server, you need an ISP that gives you an external static IP address, which most do, but you usually have to ask for a static IP.  Then it's a matter of getting a domain pointed to that address and opening a hole in your firewall.\n\nA: If you are doing this for the experience or fun of it, rock on.\nIf you are doing this because you want to have a reliable website, don't bother. Homes make lousy datacenters for the same reason that website hosting costs money: ensuring the power stays up, the net stays up, the server and the applications are up is capital and labor intensive which is most efficiently amortized across a server farm.\nSome routers support a \"roaming\" DNS server like http://www.dyndns.com/ which allows you to maintain a static name even though your ISP may shuttle your IP address around dynamically, but the caveat of \"this may irritate your ISP\" does apply.\n(disclosure: I have a free DynDNS account for no really good reason, it works on the odd times I've tried it, I don't use it for anything important, my ISP is very liberal and I have no connection to DynDNS aside from that.)\n", "Q: Conky Guides (links) I want to take a stab at creating my own layouts for conky, but I'm having trouble finding any recent guides. \nIf you know of any, I would be grateful if you could post some links. \n\nA: I started with this lifehacker article to set me up which led me to this ubuntu forums thread with lots of config files to help customize everything.\nThis Google search helps to find some more scripts ready.\n\nA: you also might want to hit up gnome-look they have an active community of moders. \nsuper beginners can look here\n", "Q: Can I set the power indicator to show battery percentage instead of time remaining? It's great that the indicator applet tells me I have 2 hours and 12 minutes of battery left, or that it will be charged in 1 hour 8 minutes, but I might well change my pattern of usage during that time and am frankly not confused by percentages.\nHow do I make the applet show a percentage charged or discharged instead?\n\nA: You can install the Battery-Stats applet, which will replace the Power-Managers's applet with more information and some power-management options as a bonus.\nsudo apt-get install battery-stats\nbattery-stats-collector\n\nThen see /var/log/battery-stats for sample information.\n\nA: I don't think the indicator shows that information yet.\nYou can click on the menu entry which says \"X hours YY minutes left to (dis)charge\" and it will open the battery profile dialog. That one has percentages under \"Laptop Battery -> Details (scroll to bottom)\"\n\nA: Matthew Paul Thomas, an interface designer for Canonical's Ubuntu team, in his blog comments this April wrote \"I think the only point in showing a percentage charge is so that a human can get an idea of how much time is left. But we have computers to do those sort of calculations now. If a battery’s estimated time remaining is wrong, its percentage will be even less informative.\"\nThere is also a comment on the Ubuntu wiki that says \"This coloring is deliberately time-based, not percentage-based; how much time you have left is more important than how long the battery can theoretically last.\"\n\n\nA: The percentage was intentionally removed by the power house that is the Canonical design team.\nSee the comments by MPT here: http://design.canonical.com/2010/04/battery/\n\nA: I had this problem, as far as i search there is not any way to solve this problem in unity panel but i solved it buy installing cairo-dock. It has some theme that can show percentages over its image.\nYou can install cairo-dock from repository \nsudo apt-get install cairo-dock\n\nthen after running it:\n\n\n*\n\n*in cairo-dock configuration go to add-ons tab.\n\n*tick \"Power Manager\" applet and click apply button.\n\n*in the dock right click on \"Power Manager\" applet and from \"power manager\" menu click on edit button.\n\n*in shown dialogue goto \"Configuration\" tab.\n\n*from first combo bos (\"choose the style of disply\") select \"Gauge\".\n\n*open Gauge section and from \"choose one of the available theme\" select a theme that show percentages in its image (theme like, \"Battery-Mono\" , \"Battery:MeeGo theme\" , \"Battery:Oxygen theme\" ,...)\n\n\nA: I just wrote a new applet for the sole task of showing the battery percentage in the panel. It comes as a python script. For more information and to download visit the github repo for the project.\n\nA: Right click applet, choose Configure, select Show percentage.\n\nA: Add this as a \"command\" somewhere in your notification area: \nupower -d | grep percentage: | awk '{print $2} ' | head -1\n\n", "Q: Can't get HP Officejet 6500 card reader to work This network (wired) printer works great using the latest HPLIP drivers. However when I plug in an SD card, it just blinks and never shows up mounted anywhere. Has anyone come up with a way to mount these? I'm using Lucid, 10.04.\nre: version, hp-info says \nxxxxx@lucid:~$ hp-info\n\nHP Linux Imaging and Printing System (ver. 3.10.5)\nDevice Information Utility ver. 5.2\n\nCopyright (c) 2001-9 Hewlett-Packard Development Company, LP\nThis software comes with ABSOLUTELY NO WARRANTY.\nThis is free software, and you are welcome to distribute it\nunder certain conditions. See COPYING file for more details.\n\nUsing device: hp:/net/Officejet_6500_E709a?zc=HP05857E\n\n\nA: No go on this I'm afraid. You have to access the card reader over USB.\n\nWe have removed support for the hp-unload (the card reader). To access the card please use the built in USB mounting system.\n\nEdit: I say that but the hplip package still seems to ship hp-unload. Try this:\nhp-unload hp:/net/Officejet_6500_E709a?zc=HP05857E -i\n\n", "Q: How to fix a Package Manager Error in notification area after upgrading a fresh install of lucid with a '/home' from Jaunty? I just installed 10.04, and used manual partitioning to preserve my '/home' from a 9.04 install. (To be clear: I did not upgraded 9.04 to 10.04, but installed 10.04 off a of CD, keeping only my '/home'.) After the sucessful 10.04 install, I used synaptic to apply all updates, rebooted, removed some packages (mostly tomboy and bluetooth), rebooted, and then used synaptic to install tonnes of packages, mostly from lucid/main and lucid-updates/main, though I also did install a number from lucid/universe and lucid-updates/universe.\nA minute or so after the mass installation of new packages, a red circular icon with a white bar running horizontally through it appeared in my notification area. (The icon is quite like the \"Do not enter this road\" sign pictured here.) On hovering my mouse over the icon, I get the following message:\n\nAn error occurred, please run Package Manager from the right-click menu or apt-get in a terminal to see what is wrong. The error message was: 'Unknown Error: '' (E:Opening configuration file /etc/apt/apt.conf.d/99synaptic - ifstream::ifstream (13: Permission denied))' This usually means that your installed packages have unmet dependencies\n\n(Since there was no way to copy the text, I transcribed it; it isn't impossible that it is not a completely faithful transcription.)\nI then ran the following commands:\n\n\n*\n\n*sudo apt-get check\n\n*sudo apt-get clean\n\n*sudo apt-get autoclean\n\n*sudo apt-get autoremove\nand then ran those same commands (in that order) but also with the -f flag. I then rebooted. This hasn't removed the warning icon from the notification area. So, I am at a loss for how to proceed.\n[Snip a lot of detail about what packages I'd installed and removed that turned out not to be relevant at all.]\n\nA: This should fix the permission problem (from this thread):\nsudo chmod o+r /etc/apt/apt.conf.d/99synaptic\n\nBut usually if you have broken dependencies you'd look in synaptic, aptitude or fire off:\nsudo dpkg --configure -a\n\n", "Q: Simple Twitter client to post all text entry This is a bit of a weird question, and I don't even know if it belongs here or not.\nI want to set up a Ubuntu box with a keyboard and a twitter program, so that everything that is typed into the keyboard is posted on twitter. So what I am looking for is a simple twitter client that will force all input via keyboard into a tweet and post to twitter after 140 chars, after the enter key, and/or a time period. \nBasically what I am planning is a little experiment to leave a keyboard somewhere it can be typed on and played with, and post all text entry through to twitter automatically.\nThe alternative is to simply save all entered text to a file, but I would prefer the twitter approach.\nDoes anyone have any ideas if there is a program/script out there that will do this for me?\nI am mainly looking for a command line script, as GUI programs are easier to exit or lose focus than a command line.\n\nA: I am sure all of this can be done through a simple python script. Interesting idea. I am sure you have some use for it. \nI would recommend taking a look at the twitter-python API -- simple and straightforward and it would be easy integrate your recording keystroke requirement as well. \nIf you need help making things work or have questions. stackoverflow.com is an amazing resource.\n\nA: There are some command-line twitter clients (either hand rolled, or purpose built), but it sounds like you have a pretty specific set of features in mind. \nI think you'll have to add a bunch of scripts around an existing client. \nGood luck. =)\n", "Q: VLC - scroll wheel doesn't change volume level I'm having trouble with vlc, when i try and adjust the volume with my scroll wheel it doesn't change the volume, in settings x-axis control is set to volume control so i can't understand why it wont work\nAny ideas?\nCheers\n\nA: This happened to me! Ctrl+H also would not turn VLC into minimal view as it should.\nI was using the VLC in the Ubuntu repository, so I uninstalled that. \nThen I added the Getdeb.net repository (this is where VLC puts all of the new releases) and installed it from there and now it works perfect.\nI don't know if this will work for you but it's worth a shot.\n\nA: Using the 1.1.2 version of VLC and it does work. Give it a try. :)\n\nA: If that doesn't work i believe ctrl + up/down arrows will increase and decrease the volume as well.\n\nA: I'm using VLC 2.0.1, I'm not sure but I think it might be available now in the 12.04 Software Center. For me it has not had any sound issues with the scroll wheel.\nHowever, if you need the PPA that is directly from VideoLAN (VLC) then use these commands in your terminal (ctrl + alt + t) to add the newest VLC to your repository:\n1) sudo add-apt-repository ppa:videolan/stable-daily,\n2) sudo apt-get update,\n3) sudo apt-get install vlc\nHope you get everything figured out and that everything works out for you.\nLive long and prosper!\n", "Q: Guest Resizing Ubuntu 10.04 64-bit in VMware Player not working Background\nI'm running Ubuntu as a guest OS in a VM. Originally the VM was created with Ubuntu 9.10 64-bit and with vmware-tools installed, when I resized or maximized the VMware Player, the guest OS was correctly and automatically resized. Once I upgraded to Ubuntu 10.04 (not reinstalled), automatic resizing no longer works. However, the mouse and network drivers do continue to operate properly.\nWhen installing vmware-tools in 10.04, I notice a lot of LSB warnings for upstart jobs that were not thrown when installing it in 9.10. \nEnvironment\n\n\n*\n\n*Distro: Ubuntu 10.04 64-bit\n\n*Kernel: Linux nitrogen 2.6.32-24-generic #39-Ubuntu SMP Wed Jul 28 05:14:15 UTC 2010 x86_64 GNU/Linux\n\n*VMware Player: 3.0.1 build-227600\n\n*Host OS: Windows 7 Home 64-bit\n\n\nWhat I've already tried:\n\n\n*\n\n*Reinstalling vmware-tools\n\n*Updating to the latest patch level of VMware player 3.0.1\n\n*Updating all installed Ubuntu packages, including kernel (and then re-install vmware-tools)\n\n*Manually creating entries in xorg.conf for the host's fullscreen resolution\n\n\nProblem\nWhen I resize or maximize the VMware Player window, the guest OS size stays fixed.\nQuestion\nHow do you configure vmware-tools for VMware Player 3.0.1 in Ubuntu 10.04 64-bit to enable automatic guest resizing?\nUpdate\nI don't know exactly WHY this fixed my issue, but on Aug 28th, 2010 a set of package updates came out that (see below), after installation, magically resolved this issue. I'm Guessing it has something to do with the xorg packages.\nStart-Date: 2010-08-28  08:05:49\nInstall: ttf-dejavu-extra (2.30-2)\nUpgrade: libsmbclient (3.4.7~dfsg-1ubuntu3, 3.4.7~dfsg-1ubuntu3.1), language-pack-gnome-en-base (10.04+20100422, 10.04+20100714), libkpathsea5 (2009-5ubuntu0.1, 2009-5ubuntu0.2), smbclient (3.4.7~dfsg-1ubuntu3, 3.4.7~dfsg-1ubuntu3.1), linux-image-2.6.32-24-generic (2.6.32-24.39, 2.6.32-24.41), ubufox (0.9~rc2-0ubuntu2, 0.9~rc2-0ubuntu2.1), language-pack-gnome-en (10.04+20100422, 10.04+20100714), xserver-xorg-core (1.7.6-2ubuntu7.2, 1.7.6-2ubuntu7.3), ghostscript-cups (8.71.dfsg.1-0ubuntu5.2, 8.71.dfsg.1-0ubuntu5.3), xserver-common (1.7.6-2ubuntu7.2, 1.7.6-2ubuntu7.3), libwbclient0 (3.4.7~dfsg-1ubuntu3, 3.4.7~dfsg-1ubuntu3.1), icedtea-6-jre-cacao (6b18-1.8-4ubuntu3, 6b18-1.8.1-0ubuntu1), linux-headers-2.6.32-24-generic (2.6.32-24.39, 2.6.32-24.41), openjdk-6-jre-lib (6b18-1.8-4ubuntu3, 6b18-1.8.1-0ubuntu1), libfreetype6 (2.3.11-1ubuntu2.1, 2.3.11-1ubuntu2.2), openjdk-6-jre-headless (6b18-1.8-4ubuntu3, 6b18-1.8.1-0ubuntu1), samba-common (3.4.7~dfsg-1ubuntu3, 3.4.7~dfsg-1ubuntu3.1), linux-headers-2.6.32-24 (2.6.32-24.39, 2.6.32-24.41), ifupdown (0.6.8ubuntu29, 0.6.8ubuntu29.1), tzdata-java (2010k-0ubuntu0.10.04, 2010l-0ubuntu0.10.04), libdjvulibre21 (3.5.22-1ubuntu4, 3.5.22-1ubuntu4.1), ghostscript-x (8.71.dfsg.1-0ubuntu5.2, 8.71.dfsg.1-0ubuntu5.3), libservlet2.5-java (6.0.24-2ubuntu1.2, 6.0.24-2ubuntu1.3), libgs8 (8.71.dfsg.1-0ubuntu5.2, 8.71.dfsg.1-0ubuntu5.3), tzdata (2010k-0ubuntu0.10.04, 2010l-0ubuntu0.10.04), ghostscript (8.71.dfsg.1-0ubuntu5.2, 8.71.dfsg.1-0ubuntu5.3), google-chrome-beta (6.0.472.33-r55501, 6.0.472.51-r57639), linux-libc-dev (2.6.32-24.39, 2.6.32-24.41), samba-common-bin (3.4.7~dfsg-1ubuntu3, 3.4.7~dfsg-1ubuntu3.1), upstart (0.6.5-6, 0.6.5-7), libdjvulibre-text (3.5.22-1ubuntu4, 3.5.22-1ubuntu4.1), language-pack-en-base (10.04+20100422, 10.04+20100714), binutils (2.20.1-3ubuntu6, 2.20.1-3ubuntu7), openjdk-6-jre (6b18-1.8-4ubuntu3, 6b18-1.8.1-0ubuntu1), language-pack-en (10.04+20100422, 10.04+20100714)\n\nEnd-Date: 2010-08-28  08:09:25\n\nA: I don't know the solution to this problem, but I'm also running Ubuntu 10.04 as VMware guest and thought some observations might be helpful. I normally use VMware Workstation (7.1.0 build-261024), but I did load this VM with the Player to verify that it behaved in the same fashion.\nMy VM was originally a fresh install, rather than an upgrade. The resizing appears to be working as intended. I don't know if it's relevant but the Ubuntu guest doesn't have the feature where the mouse moves seamlessly between host and guest, but I don't think I've ever used that with an Ubuntu guest on VMware.\nIn the virtual machine settings on my machine, the display setting is set to \"Use host settings for monitors\".\nYou mentioned that you manually created some configuration in xorg.conf, but I notice that my VM doesn't have an xorg.conf file but does have a whole bunch of available modes in the display settings control panel. I think it may be worth investigating if something changed with the X server configuration in the upgrade that could be resolved by reinstalling it with the default settings.\n\nA: i dont know about vmware, but with virtual box, they there is a setting that says adjust with windows size, which you can enable and you can run smooth. I believe porting your guest system in vmware to vbox is straightforward and simple. Link here plus its free, as well as creating guest OSes as well.\n:)\n", "Q: How can I map a character to a key combination? I'm a bit of a fan of the interrobang (‽), but it obviously is not on my keyboard. How can I map that character to a key combination?\n\nA: In GNOME you can enter unicode characters by type Ctrl+Shift+u+unicode point, followed Space or Enter.\nSo, type an interrobang, you'd enter Ctrl+Shift+u+2032d+Space.\nHow cool is that‽ Actually, I think it's a bit clumsy, but it does the job.\n\nA: Another, low-level option to try, especially if you can't get xkb to work is to use xmodmap directly.\nThe first thing to do would be to get a sense of your current keyboard layout. Open a terminal and type:\nxmodmap -pke\nThis will give you a list of numbered positions on your keyboard and what they are mapped to. E.g., you might see an entry like:\nkeycode 14 = 5 percent 5 percent\nThis means that a certain key is mapped to 5 when pressed normally, the percent sign % when pressed with a shift. (And the next two values are for when Mode_shift is active; but let's not get into that right now.\nIf I wanted to change this key I could type in:\nxmodmap -e \"keycode 14 = 5 U203D 5 UD203D\"\nNow, instead of getting a percent sign % when I type shift-5, I get ‽. \nThat's just an example; probably you don't want to remap % to ‽. But maybe there's some other key you don't use a lot. For example, one nice option might be to remap the shift-Menu instead. So I see from xmodmap -pke that I have:\nxmodmap -e \"keycode 135 = Menu Menu Menu Menu\"\nI might make it instead:\nxmodmap -e \"keycode 135 = Menu U203D Menu U203D\"\nIf I want to make that permanent, just throw it inside some init script that runs automatically, like .profile, .bashrc or .xinitrc, or create your own that Lubuntu loads automatically.\nHowever, it's very important to run xmodmap -pke first to see what your initial set up looks like. Your keycode numbers may well be different from mine. And it's also the best way to see what else is available.\nAnyway, that's a very low-level option. If you want a high-level option, look at something like autokey  or xdotool  instead.\n\nA: Another option is to make use of the 'compose' key. Using Ubuntu, choose one in the Keyboard → Layouts → Option configuration (I choose Right Alt). For Kubuntu, go to System Settings → Input Devices → Keyboard → Advanced, check \"Configure keyboard options\", and then select your chosen key under \"Compose key position\". \nTo use the compose key, type Compose + ? + !. \nThere are lots of useful looking characters you can generate in this way: http://www.hermit.org/Linux/ComposeKeys.html\n\nA: Here's something that works okay:\n\n\n*\n\n*Install xdotool  (brilliant piece of software by the way)\n\n*go to System → Preferences →\nKeyboard Shortcuts\n\n*Add a new shortcut, as the command\nchoose xdotool key ctrl+shift+u\ntype \"203d \"\nThis is based on Matt's answer, but it will type the keys for you every time you hit the keyboard shortcut (albeit a bit slowly, about 150ms).\nTo add any other character, go to the gnome character map and search for it; In the status bar you should see the hexadecimal index of the glyph - i.e. \"U+203d\".\nI now have the interrobang mapped to Ctrl+?, see‽ :-)\n", "Q: ureadahead seems to block the system on boot I had a look at my bootcharts and something seems to be wrong with them. The ureadahead process does what it's supposed to do (disk utilisation is 100% most of the time), but it also blocks any other action.\nSince I've got a slow, laptop harddrive, ureadahead itself takes ~50s of the boot time. Then, the rest of the visible boot sequence takes another 100s to complete, using a lot of CPU, but not maxing it out and lots of IO (again, 100% almost all the time).\nThis seems just strange to me. Is my ureadahead misconfigured? Why does it block tasks like bringing up the network which seems to be taking lots of cpu? Should it take ~50% of the bootchart time in general?\nEdit: here is the example bootchart: http://img191.imageshack.us/img191/1049/localhostkarmic20100815.png (or this if the direct one didn't work: http://yfrog.com/f/5blocalhostkarmic20100815p/ )\n\nA: Blocking the boot is by design.  The point of ureadahead is to preload all the data your boot will require ahead of time.  The reason to do this is that the primary reason for disc slowness is seek times - even slow hard drives should be able to push out >50 MB/sec reads, but if you need to seek around - at tens of milliseconds per seek - that decreases dramatically.  By running ahead of time, ureadahead should be able to minimise the seeks and hence minimise the time needed to read all the data your boot will need.\nSo, the ideal bootchart looks like ureadahead at 100% I/O utilisation, followed by everything else starting up and using no (disc) I/O.  This boot isn't practically achievable, not least because many of the services we're starting up write to the disc, but that's the idea.\nLooking at your bootchart it seems that ureadahead is having a hard time actually pulling data off your disc - there's lots of time where it's at a very low throughput.  Even so, it looks like it's doing some of its job - after ureadahead starts your boot is mostly CPU bound, rather than I/O bound, and it looks like the large patches of I/O-bound boot are associated with preload firing up.  \nYou might want to try removing preload, or to reprofile your boot¹, or it might be that some of your files are very fragmented, or it might be a bug in ureadahead.\n1: Removing the pack files from /var/lib/ureadahead will cause ureadahead to reprofile on your next boot.\n\nA: Everything looks okay with the bootchart, it does show that the cpu is waiting on input/output and the hard drive is almost always 100% so if you wanted a faster boot you should try installing boot up manager (bum) and disable unnecessary services, also remove preload as RAOF said because it slows down boot and only really works with things like open office which take forever to load. If you still wish to have a faster boot then do a fresh install of Ubuntu 10.04, maybe even on a separate partition incase your not sure of how it would work out. Good luck\n", "Q: Can I use Ubuntu PPAs in Sidux? I want to test Sidux in Dual-Boot! Cause it is Debianoid a question popped up: Is ist possible to use PPAs in Sidux, too?\n\nA: Technically yes. The PPAs use the same format as normal apt respositories so you'd be fine in that respect.\nThe problem comes with dependencies. If packages have different names, you're not going to be able to fulfil some deps without pulling more and more Ubuntu packages in.\nAs Sidux is debian-based, not Ubuntu-based, there's a good chance you'll run into a problem. Add the repo and load up aptitude and see what the deal is. As long as you don't try installing anything, you won't break anything by doing this.\n\nA: No. Some packages may work, however there is a good probability that a package may not work on sidux (or more specifically Debian sid).\nThis is not just because of dependency issues. Dependency issues are easily resolved by creating dummy packages and installing the correct packages yourself. Further, a great deal of the packages are Debian packages recompiled unmodified on Ubuntu -- all packages with version numbers that don't end in -0ubuntu1 or more generally -XubuntuY. IIRC, greater than 75% of packages in Ubuntu are unmodified. Clearly dependencies aren't such a huge issue.\nBinary compatibility is something you should be more afraid of. Ubuntu is not always binary compatible with Debian. It maybe at times, it may not at other times. Packages on Launchpad PPAs are complied in a clean root Ubuntu environment not Debian. Should it be that at the given time the two are not binary compatible, the package will break on your computer.\nSo, here's the best way to do this (although not the quickest). Install pbuilder. Add the PPA's source repository to your software sources. Download the source package using apt-get source foobar and then run sudo pbuilder build foobar-1.2.3-0ubuntu4ppa5.dsc. (Please save yourself some time and use tab auto-completion, don't try to remember which version was downloaded). This will build the package from source and give you a binary compatible (since you compiled it on your own machine) .deb that you can install available in /var/cache/pbuilder/result/.\n\nA: Hey i have made an automated script to add ppa's to debian system's\nhttp://blog.anantshri.info/howto-add-ppa-in-debian/\ndo check and suggest any corrections if required.\n", "Q: How do I troubleshoot sporadic HDMI failures? I'm running HDMI video and audio from the on-board ATI graphics output of a GIGABYTE GA-MA78GM-S2HP motherboard to an Philips TV. It works fine, but every once in a while the screen will go blank and I can't seem to get it back without reseting the computer. The screen saver and power modes don't seem to cause it and I tried disabling them to no avail.\nDoes anyone have any tips on how I could (a) reset the video output without a hard CPU reset, (b) gather more data to troubleshoot the problem and/or better yet (c) know what could be causing this issue?\n\nI have replaced the 19\" TV with a 24\" HDMI monitor and have not had a reoccurrence of this problem since that time.\n\nA: a) \nHave you tried to restart X?. You can do it from the terminal (switch using CTRL+ALt+F1) and writing:\n/etc/init.d/gdm restart\n\nor\nservice gdm restart\n\nIf this doesn't work you could try to unload/load the graphic card module from the kernel, but this can a little tricky as usually there are a couple of modules depending one on another. You can start typing lsmod in a terminal to see what modules you have loaded. You can force modules to unload using rmmod as root and load them again with modprobe.\nb)\nHave you looked at the system and X.org logs?. You can check them on System->Administration->System Logs or in /var/log/. The needed info is likely shown at the bottom of a dmesg command right after the problems happen.\n", "Q: How to start GNOME session from chainroot? I have used cowbuilder to set-up a chainroot with ubuntu+1 (essentially minimal ubuntu installation in a sub-folder, which you can \"change\" into, for example for building packages in a clean environment).\nHow can I start gnome-session from there? Ideally I want it to appear on a new VT. I hope to achieve poor-man's virtualisation ;-) \n\nA: You should be able to do this with a combination of startx and /etc/X11/Xsession, as long as you've got the necessary trees bind-mounted (I'd guess that you'll need /dev, /sys, and /proc)\nChroot into your… chroot and run\nsudo startx bash\n\nwhich should give you an X term with a shell.  To start a GNOME session you can simply run\n/etc/X11/Xsession\n\nfrom that shell.\nYou should be able to get this on the VT of your choice; check out the man page for startx for this, and other potentially interesting options.\nNote that this doesn't make for a secure chroot - since /proc and /sys and /dev are mounted in the chroot a sufficiently advanced malicious user break out of the chroot with ease.\n\nA: I have used such a setup a long a time ago.\nI believe it was just as simple as starting X from the chroot specyfing a different display name:   \nstartx -- :1\n\nSwitch to it with: CTRL-ALT-F9\n", "Q: Thinkpad T60 flickering screen I'm running Ubuntu 10.04 LTS (Lucid Lynx) on my Lenovo Thinkpad T60.  I randomly get screen flickerings on my screen.  Once it happens, it doesn't go away (unless I reboot my computer).  I would describe the flickering as horizontal color lines appearing throughout the screen where the text is difficult to read everywhere.\nI ran the following to see what video card is installed:\n$ lspci | grep VGA\n01:00.0 VGA compatible controller: ATI Technologies Inc Radeon Mobility X1400\n\nMy question is: what's wrong and how do I fix it?\n\nA: Based on your description, sounds like Bug #541501 which is still open.\nI have a similar problem on a Thinkpad T60 with ATI Radeon Mobility X1300. None of the workarounds suggested in the comments of the linked bug entry (modeset=0 and/or new_pll=0 parameters to the radeon module, a newer mainline kernel) seem to completely make the problem go away for me – however, some of them seem to help a bit though.\n\nA: I'm now running Ubuntu 11.04 on my Thinkpad T60, and the screen flickering issue doesn't exist anymore.\n", "Q: Installing drivers for internet connectivity I'm having problems installing the drivers for internet connectivity from service provider. My computer recognizes the files when I insert the stick but does not want to install the drivers when I click on the .exe  files.\n\nA: I am not sure that you necessarily need to do this, it depends on what network interface you are trying to install. \nHowever assuming it is a wireless card and that you really do require the windows drivers you may find what you need to know on the ndiswrapper page of the Community Ubuntu Documentation.\n\nA: To connect with my mobile as a 3G modem (via usb cable) I had to use the wvdial package to get it to work...\ntry:\nsudo aptitude install wvdial\n\nand then:\nsudo wvdialconf\n\nElsewhere you need to tell us some more detail on what modem you are trying to get to work...\n\nA: I installed a 3G USB modem...did the following: There was a problem the USB modem (which the service provider replaced)...downloaded \"flip flop USB\" from Ubuntu software centre for network recognition...installed \"mobile partner\"(may have a different name with other providers) for Linux for USB(internet) login...if necessary, make sure that proxy settings are set to \"no proxy\"...thanks everyone taking the time to read and post answers...hope my experience will be of some value as well \n\nA: When you see the windows drivers on the modem it is in USB-drive state. You need to install usb-modeswitch to toggel it in to modem mode.\nThis is also what namkid is refereing to as \"flip flop USB\". You can install this tool from the software center.\n\nA: Is not necessary install other software,the NetworkManager recognizes the USB modem,only connect the modem and wait...\n", "Q: How do I get the Kubuntu upgrade notification icon back? When Kubuntu needs to be upgraded between versions (e.g. 9.10 to 10.04), there's a notifier icon that shows up in the system tray,\n\n(Source)\nBut if I click on it to start the upgrade and it fails for some reason (in my case, not enough space on the /boot partition), the icon disappears. How can I either get it back, or run the upgrade manually, without having to log out and log back in?\n\nA: Open up KPackageKit in Kickoff (under the Computer tab), and it should offer to install updates.\nIf KPK can't do it:\nsudo do-release-upgrade\n\n\nA: The program that places the icon in the tray is a python script, update-notifier-kde, and it can be run from the terminal as\npython /usr/bin/update-notifier-kde\n\n(sudo not required, it will prompt for the password graphically)\n", "Q: How to get rid of odd error line when ALT+TAB'ing away from an emacs launched in terminal I have a very fresh install of Lucid 10.04 64bit, fully upgraded, and with a raft of additional packages added. Amongst them is emacs (23.1+1-4ubuntu7). I habitually launch emacs from a terminal. \nI just observed that when I have the GUI emacs (i.e., the result of running emacs not emacs --nw) and I Alt+Tab away from it, each press of Alt+Tab results in the line\n** (emacs:7690): CRITICAL **: murrine_style_draw_box: assertion `height >= -1' failed\n\nbeing output to my terminal window (I assume it's from the stderr of the emacs process).\nThis didn't happen on Jaunty 9.04, for which I had the default Jaunty emacs package installed. \nHow to fix?\n\nA: The bug is\nknown,\nand there is a work-around in this comment on\nit.\nI effected the change there suggested; once I closed and reopened emacs, the problem was solved.\n\nA: This is not a solution, but an easy workaround to this problem is to simply change the theme. The default theme:\nSystem -> Preferences -> Appearance -> Theme\n\nis set at Ambiance. Changing it to Clearlooks solves the problem (and one could simply customize so that it \"looks\" like any other theme you like).\n", "Q: Anyone get DOOM 3 audio working properly with Ubuntu 10.04? The audio configuration must have changed from 9.10 to 10.04, because audio no longer seems to work with DOOM 3. This was the suggested way to run DOOM 3 before, and it worked fine:\ndoom3 +set s_alsa_pcm plughw:0\n\nHowever, DOOM 3 is completely silent after I upgraded to Ubuntu 10.04. Has anyone gotten the audio for DOOM 3 to work in Lucid Lynx?\nEdit: Here's some potentially useful console output:\n------------------------------------\ndlopen(libasound.so.2)\nasoundlib version: 1.0.22\nAlsa is available\n------ Alsa Sound Initialization -----\nsnd_pcm_open SND_PCM_STREAM_PLAYBACK 'plughw:0' failed: Device or resource busy\ndlclose\nWARNING: sound subsystem disabled\n\nEdit2: Well, it seems that DOOM 3 is unable to share, like other applications, so closing\nRhythmbox and Chrome and anything else that shows up in Sound Preferences under the\nApplications tab worked. I would like to get it to play nice like everything else, but\nthat may be too much to ask. If someone can come up with a solution that causes DOOM 3 to\ncoexists peacefully with other applications would constitute an accepted answer. It sucks\nto have to close everything else first.\n\nA: Try change the driver to OSS, perhaps like this (sorry I can't verify this command atm):\ndoom3 +set s_driver oss\n\nAlso check that nothing else is using the sound card, like a music player?\n\nA: Have a look here: PulseAudio - Perfect Setup #Quake3\n\nA: Try installing the libsdl1.2debian-alsa package.\n\nA: To get sound working in quake4 (same engine as doom3), I had to combine the 2 suggestions above:\nsudo apt-get install libsdl1.2debian-alsa\n\ndoom3 +set s_driver oss\n\n", "Q: Where to file bugs/wishlist for Unity? I guess the question explains it all...\n\nA: https://bugs.edge.launchpad.net/unity/+filebug\nThe link answers it all.... =)\n\nA: This really depends on the type of bug or wishlist item you with to report. There are two aspects to unity. There is the upstream source and the Ubuntu package.\nThe upstream source is basically what you can find at https://launchpad.net/unity. It is the unity application itself. This does not include any Ubuntu-specific changes that we might ship or the deb package.\n\nThe Ubuntu package is the deb version of the upstream source that you can install from the Ubuntu repositories. This can be found at https://launchpad.net/ubuntu/+source/unity. The package takes care of installing dependencies, installing all of the files from the upstream source into the correct locations, and making any Ubuntu-specific changes that need to be made (among other things).\n\nIf your bug or feature request has to do with the application itself (i.e. some feature does not work properly, a request for new functionality, etc.) you should file it against the upstream application here. \nIf your bug is an issue with the Ubuntu package (fails to install from repositories, missing dependencies, Ubuntu-specific features not working, etc) you should file it against the Ubuntu package. This guide will guide you through the process of using ubuntu-bug to report the bug (which will attach some additional debug information).\nSince unity is not currently synced from Debian, you do not need to worry about reporting the bug there.\n", "Q: Is there a SubEthaEdit-like text editor? Is there a network-synchronized multi-user IDE available in the Ubuntu repositories?\nIf so, how did you find out about it?  This is not the sort of thing that has an easy-to-search-for name...\n\nA: I don't know about a real IDE (programming environment) but there are several applications that allow you to work together on \"something\".  Some that I know about:\n\n\n*\n\n*The *obby family of applications (Gobby, etc.) are text editors, but not really usable as a full IDE in my opinion (although it could be possible to write an IDE based on its library?).  Gobby is used at the Ubuntu Developer Summits to take notes.\n\n*AbiWord is a word processor that has a collaboration plugin\n\n*Coccinella (not in the Ubuntu archive) is a combination of a chat client and a shared whiteboard\n\n\nAnd of course there are also several on-line web-applications for collaborative editing.)\n\nA: I haven't used either, but I believe Gobby is similar\n\nA: You're probably better off using a version control system (like svn or bzr) and just use a  normal editor/IDE for your programming.\nEveryone can then make their own changes in a separate branch that can be merged later into the main development version ('trunk').  \n\nA: I searched for \"collaborative editing\" back when I was trying to find alternatives.\nI think the best you're going to get is something like http://etherpad.com/. I've tried Gobby, but found it way limited and unstable to recommend, YMMV. \nI prefer emacs, and there have been attempts at working collab.editing into emacs, including using the obby protocol, I never got this to really work though (see http://www.emacswiki.org/emacs/CollaborativeEditing for some discussion). There's also emacs multi-tty, which is a great feature in general, but not completely suited for collaborative editing (unless you're on the same network and prepared to give others full access to your machine, the same goes for shared screen sessions, which are even more insecure).\nAbiCollab ( http://msevior.livejournal.com/27859.html ) seems really cool, but mainly useful for writers, not programmers.\nI'm still using git, pastebins and IRC :/\nEDIT: I've started using this setup: http://www.emacswiki.org/emacs/tmux_for_collaborative_editing The trick is just to make a shell account where you only keep stuff that you don't mind sharing. Let that be the host, and you've got full collaborative editing with all the power of emacs.\n", "Q: kqemu ppa for 10.04 Where is a good (working, no dependency issues) PPA for qemu-kqemu and the kqemu module builder for Ubuntu 10.04?\nA good PPA from which to obtain kqemu for 10.04 from would be one that has a working package with dependencies set to be handled correctly and that one can install without having to hold packages or override to keep qemu and kqemu at the PPA version. Since upstream support is gone, updates are unlikely.\nPlease don't suggest alternatives unless you can show they are faster than kqemu at disk I/O and networking on a VT-free machine.  I am quite aware that kqemu development has been discontinued and that Canonical has discontinued KQEMU support, leaving VT-free users who need fast virtualization in the cold.\n\nA: Try this ppa:\ndeb http://ppa.launchpad.net/dnjl/virtualization/ubuntu lucid main\ndeb-src http://ppa.launchpad.net/dnjl/virtualization/ubuntu lucid main\n\n", "Q: VNC remote doesn't work with Ubuntu? I was wondering if anyone has a workaround for VNC remote not working with Ubuntu running compiz. From what I can tell it works if I disable compiz effects, but who's not a fan of eye candy? Anyway, it's not a huge deal if there's no work around anyone knows because I've been using nx server instead to remote connect to my desktop. I was just wondering if there's a way to get VNC working because I have an app on my ipod touch that can VNC, but there's no NX client for the itouch.\n\nA: I have the same issue. I don't know how to fix it, but I came up with a decent work-around. I added a launcher on the top panel to switch to the Metacity window manager.\n\n\n*\n\n*Right click on the panel and click \"Add to Panel...\"\n\n*Choose \"Custom Application Launcher\" and click \"Add\"\n\n*Type whatever you want for the name. I called it \"Metacity\"\n\n*Type \"metacity --replace\" (without the quotes) for the command\n\n*Optionally fill in the comment box and choose an icon (I used vinagre.png since I run it from VNC)\n\n\nWhen I log in remotely, the first thing I do is click the Metacity launcher, and the screen starts updating correctly.\nI have fusion-icon installed, so I use it to switch back instead of making a launcher for Compiz. If you want to use a launcher to switch back to Compiz, follow the same steps for Metacity, but use the command \"compiz --replace\".\n\nA: If you use x11vnc, you can add \"noxdamage\" flags to its command line to start up a VNC server which will give you all the pretty compiz effects over VNC (which is probably bad, but there you go).\nTo install :\n\nsudo apt-get install x11vnc\n\nThen run it in a terminal (one time only, just to set the password)\n\nx11vnc -usepw\n\nThen finally stick this command into /etc/rc.local : \n\nx11vnc -usepw -forever -noxdamage -scale 4/5 -avahi -timeout 60 -nolookup -q\n\n-forever will keep the server going after you disconnect.  Otherwise, when the first client disconnects, the server will stop running.\n-avahi will mean that the server will advertise itself using avahi (multicast dns).  Clients like Reminna and Vinagre will search for and show these.  Also useful if your client is on a Macintosh, since \"bonjour\" is really just a made-up Apple brand for zeroconf, of which avahi is the open-source version of.\n-scale 4/5 will mean that a 1900x1200 screen will fit on a 1280x1024 screen.  Yes, most clients will allow a local-side scale, but this option means that less data is sent by the server in the first place, which may be useful for slower, or internet-based connections.\n-nolookup means that the server won't try to lookup the client. No long pauses on connect.\n-timeout just specifies how long the server will wait for a client to connect before sleeping again.\nThe advantage to this method is that there's a host of other options available if you care to take a look (man x11vnc).  Very flexible, but sadly no pretty GUI available.\np.s. If you haven't yet tried Reminna as an alternative to Vinagre, I'd suggest you give it a go.  It's a superb VNC client which just happens to feature RDP support too.\n", "Q: What's the friendliest virtualization solution? I want to experiment with virtualization in Ubuntu 10.04 and have found the following list of hopefully relevant names:\nXen, OpenVZ, KVM, Vservers, EC2 and Solaris Zones, although this is just a sample list and the question is not exclusive to these.\nFrom the community's experience, what virtualization solution should I use on Ubuntu to learn with? \nFactors are ease of setup, ease of use. Stability is also important. Secondary are memory usage and performance issues. \nWhat do I want to virtualize? Well, pretty much anything the chosen software will allow, under the banner of experimentation.\n\nA: VirtualBox is probably the most friendly if you only need to run 1 or 2 VMs at a time.\nIf you need to simultaneously run many different Linux environments (10 or more per host) then OpenVZ is the way to go. It's like chroot but provides completely isolated Linux environments (containers) with the ability to control resources, do check-pointing, and live migration. I'm using it for already more then 2 years for many different sysadmin tasks at work (a 400 user Bioinformatics center at a large university).\nOpenVZ has almost no overhead. It's the only one of it's kind (operating system level virtualization). It handles well Linux applications of any proportion from a web reverse-proxy to an I/O intensive backup system processing 30TB a day. Having 30 or more containers per server is normal. Another big advantage is that from the hardware node (equivalent to Dom0 in Xen) you have all the file systems of the Linux containers mounted directly - no NFS required. Also, you can see all the processes of your Linux containers from the head node with the ability to strace, kill, etc...\nYou can safely delegate containers with ssh access to your friends and let them be root.\nYou would need to be comfortable with Linux and the command-line. Being able to edit start-up scripts would be helpful (quickly give you a lot of control). For more advanced setups, may need to learn some networking.\n\nA: Apart from Virtualbox, KVM along with virt-manager as front end is a pretty good virtualization solution in my experience.\n\nA: I'd recommend VirtualBox, if you're just getting started. (apt-get install virtualbox-ose) It's intended for running a virtual machine on a desktop (or laptop) computer, so that you can use both the virtual (guest) computer and the real (host) computer together. It gives you a nice GUI that you can use to create virtual machines and alter their settings. You can start and stop the virtual machine, so that if you need extra processing power for some task you're running on the host, the guest doesn't have to get in the way.\nThe names you gave in your question are more high-level, I think. They're the kinds of things I hear about in connection with virtual private server (VPS) companies, which are web hosting companies that use virtualization to provide several people with servers using one physical computer. They're probably somewhat more complicated to set up and maintain, and typically when you use something like Xen, the host computer isn't intended to do much besides serving as a \"base\" for the VPS's.\n\nA: If you intend to use the host (computer that you install the VM-software on) for any thing other than to be at VM-host then you should keep to VirtualBot and qemu (or vmware if you like burning monies liberties).\nI can recommend taking a look at qemu (install), it is a bit hard to setup (afaik no of the gui-tools really works well) since it is a commandline tool. But one of the main features of qemu is that you can emulate other CPU targets that the one your on. I often use it to boot a test-root-image of for my phone (Which in effect is a 500MHz ARM computer running Maemo Linux.)\nWhen qemu runs on a x86-64 it can use KVM for x86-64, when on ia32 it can use KVM on ia32, when on PPC 440 it can use KVM for PPC 440 ect..\n\nA: I have had very good experience with VMWare Player.  It does two things well - running virtual images, and automatically integrating itself with the host environment.\n\nA: I have both VirtualBox and VMware workstation installed on my HP EliteBook 8530.  I experience occasional freezes with VirtualBox, but not VMware workstation.  I've tried to tell myself that its some obscure bug, but its happened with both 10.04 and 10.10, so I'm not sure that it is... I've tried to collect info, but to no avail.  \nThat said, I'd stick with VMware Workstation if you can float the coin to buy it.  If you can't, just be prepared for some odd behavior from VB.\n-C\n", "Q: Fix laptop hard drive load cycles / kerchunking in desktop and laptop Ubuntu 10.04 machines How does one prevent the power-save load-cycling of a laptop hard drive in 10.04 in desktop and laptop machines?  These desktop and laptop machines with laptop hard drives have thousands of load cycles, already according to smartctl, and we don't want them to die of kerchunking.\nLaptop-mode-tools is, or was, somehow involved. The files have moved around and been refactored a good bit since I fixed this on 9.04, and I can't seem to find the setting now.\n\nA: sudo hdparm -B254 /dev/yourdisk\n\nA: AFAIK you must be able to set it in /etc/hdparm.conf . If it doesn't work you can always add nohdparm to your boot line on grub.\nNote that /etc/apm/event.d/20-hdparm will change APMD_SPINDOWN, maybe upping it value there can be a more conservative approach.\n", "Q: Conveniently switch between Apple and PC keyboard (swap Windows and Alt keys) I alternate between a Unicomp clicky keyboard by day, and the Apple bluetooth keyboard by night.\nThe Apple keyboard physically swaps the Alt and Windows keys. How do I counteract this?\nAlso, how can I streamline the process since I switch keyboards twice per day.\n\nA: This is on Ubuntu 10.04.\nManually swapping the Windows and Alt keys\n\n\n*\n\n*System -> Preferences -> Keyboard\n\n*Layouts tab\n\n*Click \"Options...\"\n\n*Expand \"Alt/Win key behavior\"\n\n*Choose between:\n\n*\n\n*Default (when using the PC keyboard)\n\n*\"LeftAlt is swapped with Left Win\" (when using the Apple keyboard)\n\n\n\nSemi-automated swapping\nI have added this to my .bashrc:\n# Output the gconf settings for enabled or disabled keyboard swapping based on whether the argument is \"apple\"\nsetting_for_alt_key () {\n  gconftool --get /desktop/gnome/peripherals/keyboard/kbd/options \\\n  | ruby -e 'set = {}; STDIN.gets.strip.gsub(/\\]|\\[/, \"\").split(\",\").each{|x| set[x]=1}; set[\"altwin\\taltwin:swap_lalt_lwin\"]=1; STDOUT.write \"[\" + set.keys.select{|x| ARGV[0] == \"apple\" || x !~ /swap_lalt/ }.join(\",\") + \"]\"' \\\n    \"$1\"\n}\n\nkmac () { gconftool --set --type=list --list-type=string /desktop/gnome/peripherals/keyboard/kbd/options \"$(setting_for_alt_key apple)\"; }\nkpc  () { gconftool --set --type=list --list-type=string /desktop/gnome/peripherals/keyboard/kbd/options \"$(setting_for_alt_key)\"; }\n\nThen when I activate the Apple keyboard, I type kmac at the terminal. When I deactivate it, I type kpc. So far I have not been able to justify auto-detection.\n(Also, if somebody has a better way to work with Gconf, either with gconftool-2 or perhaps language bindings, I'd love to hear it.)\n\nA: Go to System>Preferences>Keyboard and add the appropriate keyboard layouts you want to use. Then in the layouts tab click the \"Options...\" button and find \"Keys to change layout\" and find a keyboard short cut that you will like.\n", "Q: How do I manage users in ProFTPD? How do i add a new user to my FTP server running ProFTPD. \nI have the server running, i added a system user but i get  Login incorrect.\nThank you for your help in advance.\n\nA: If normal system users are used, you simply use the system utilities: adduser, usermod, useradd, userdem, deluser, etc\nIf virtual users are enabled the users are managed in the file defined by the AuthUserFile directive and the groups in AuthGroupFile. The format is similar to the system passwd file and group file. You can learn more at http://www.proftpd.org/docs/howto/VirtualUsers.html\n", "Q: How do I set up a Cron job? I want to schedule a task to run on a regular basis and have heard that Cron is the way to do this.\nHow do I add Cron jobs in Ubuntu?\n\nA: Put a shell script in one of these folders: /etc/cron.daily, /etc/cron.hourly, /etc/cron.monthly or /etc/cron.weekly. \nIf these are not enough for you, you can add more specific tasks e.g. twice a month or every 5 minutes. Go to the terminal and type:\ncrontab -e\n\nThis will open your personal crontab (cron configuration file). The first line in that file explains it all! In every line you can define one command to run and its schedule, and the format is quite simple when you get the hang of it. The structure is:\nminute hour day-of-month month day-of-week command\n\nFor all the numbers you can use lists, e.g. 5,34,55 in the minutes field will mean run at 5 past, 34 past, and 55 past whatever hour is defined.\nYou can also use intervals. They are defined like this: */20. This example means every 20th, so in the minutes column it is equivalent to 0,20,40.\nSo to run a command every Monday at 5:30 in the afternoon:\n30 17 * * 1 /path/to/command\n\nor every 15 minutes\n*/15 * * * * /path/to/command\n\nNote that the day-of-week goes from 0-6 where 0 is Sunday.\nYou can read more here.\n\nA: Example of running script test_cron.sh by cron every minute on Ubuntu 18.04 using symbolic link:\ntest_cron.sh file:\n#!/bin/bash\necho \"System backuped\" >> /media/myname/data/backup/backup_tmp.log\n\nIf you want to use environment variables in your script like $USER in paths it is better to type precise path, bash will not know your variables at execution time. \nmyname is user name (part of root group, I am not sure that root privileges are necessary).\nAllow users to set cron jobs, file will be created if necessary:\nsudo nano /etc/cron.allow\n\nroot\nmyname\n\nThe path to script is /home/myname/shell/test_cron.sh\nI changed the owner and made it executable:\nsudo chown myname /home/myname/shell/test_cron.sh\nchmod +x /home/myname/shell/test_cron.sh\n\nI added symbolic link:\nsudo ln -s /home/myname/shell/test_cron.sh /usr/bin/test_cron\n\nLogged as myname I added new task to execute test_cron every minute.\ncrontab -e\n\n*/1 * * * * test_cron\n\nTo check if the command in the list:\ncrontab -l\n\n*/1 * * * * test_cron\n\nTo check execution \ngrep -i cron /var/log/syslog\n\nNov 17 12:28:01 myname-ubuntu CRON[13947]: (myname) CMD (system-backup)\n\n\nA: If you prefer to do it using a GUI, you can go to the Software Center and install Scheduled tasks (or run sudo apt-get install gnome-schedule). It will provide a powerful GUI to add cron tasks.\nNote that if you use this method, tasks by default will be executed as your own user, not as root. This is usually a good thing.\n\nA: I recommend KDE's Task Scheduler (kde-config-cron) . Access it from the System Settings in the Task Scheduler module there.\nIt manages both personal and system Crontabs, and the ease of creating the time boundaries greatly surprised me (see the screenshot below). I think this part is really underrated.\n\n\nA: I wanted to set a Cron job to run through a bash script, so executing the script would add a cron job.\nI realised that when you make use of:\ncrontab -e \n\nThen it creates the file:\n/var/spool/cron/crontabs/root \nWhere root is the name of the user running running the crontab command. So based on this and in 14.04 at least, we can execute the following bash commands to create a new Cron job:\necho \"30 17 * * 1 /path/to/command\" > /var/spool/cron/crontabs/root\n\nWe also need to set the correct ownership for the file:\nchown root:root /var/spool/cron/crontabs/root\n\nAnd set the correct permissions:\nchmod 600 /var/spool/cron/crontabs/root\n\nIf when you run crontab -e there are already Cron jobs in the list, then you are able append to the list using the following command:\necho \"30 17 * * 1 /path/to/command\" >> /var/spool/cron/crontabs/root\n\n\nA: KDE Task Scheduler will not work in regular Ubuntu. It works only in KDE Systems like KUbuntu. For non KDE system you will prefer to use gnome-schedule\n$ sudo apt-get install gnome-schedule\n\nThe app is Scheduled tasks in the Dash.\n\nA: If the job you want to run can be run with the same privileges as your user I recommend using a user crontab which you can edit by running EDITOR=\"gedit\" crontab -e (which will use gedit to edit the crontab file) or simply crontab -e (which will use the default editor) in a terminal.\nIf you want to run something every 10 minutes, for example, you add a line like this\n*/10 * * * * /usr/bin/somedirectory/somecommand\n\nand save the file.\nYou can see the contents of the user crontab with crontab -l.\nTo add a cron job that runs as root, you can edit root's crontab by running sudo crontab -e.\nThe most flexible way is to use the system crontab /etc/crontab which you can edit only with root privileges. In this file, the user each command is to be run as is specified, so you can run your commands as root (in case you need that level of privilege) or any other user on the system.\nFor example, if you want to run something every 10 minutes as root, you'd add a line like this\n*/10 * * * * root /usr/bin/somedirectory/somecommand\n\n(notice the addition of the user to the line)\nYou can see the contents of the system crontab file with cat /etc/crontab.\nMore details at: https://help.ubuntu.com/community/CronHowto\n\nA: Considering you have multiple cron jobs with particular user and they don't share same schedule. You can just simple create file under /etc/cron.d/\nLets say file name is myjobs then just write all your schedulers in that file and then run following command.\ncrontab -u <username> /etc/cron.d/myjobs\n", "Q: How can I optimise a server for a Low Latency application I have an application that is latency sensitive. Although I care about throughput, extreme low latency is more important to me.\nPlease suggest how I can optimise my server to achieve the lowest possible latency - that is, the lowest possible response time from a request being received on a network interface (or inifiniband card) and the response being published.\nInitial thoughts are\n\n\n*\n\n*Pin all operating system activity to a set of cores and dedicate others to my (don't know the best way to do this)\n\n*Setting overcommit_memory to don't overcommit\n\n\nThe article Optimizing Servers and Processes for Speed seems to be a good start but other pointers are welcome.\nAny other suggestions welcome\n\nA: First and foremost, I think you should install and use the linux-rt kernel. This kernel is patched and allows nearly all of the kernel to be preempted, with the exception of a few very small regions of code (\"raw_spinlock critical regions\"). This is done by replacing most kernel spinlocks with mutexes that support priority inheritance, as well as moving all interrupt and software interrupts to kernel threads.\n\nPreemption is the act of temporarily\n  interrupting a task being carried out\n  by a computer system, without\n  requiring its cooperation, and with\n  the intention of resuming the task at\n  a later time.\n\nRead A realtime preemption overview. This will allow you to understand how things work, something that will enable you to fine tune the kernel for your particular application.\nThere's also RTLinuxFree developed by Wind River Systems which also has a commercial counterpart if you have money laying around.\nFor linux-rt I recommend reading the RT Wiki\nMaybe your application supports RTAI?\n\nA: Perhaps twiddling with the hardware clock frequency could be of importance? That might affect switching ACPI power states, for example, if your machine is expected to be in idle state for periods of time, and has to respond quickly to network requests. Or if you need (extremely) accurate timing and logging, say.\nSee link text for some more discussion. I'm not sure how recent is, but the hardware clock option was still there last time I checked (some 6 months ago).\n", "Q: How to speed up SSH login? From outside of my house, whenever I login to my Ubuntu server using SSH, it takes about 6 seconds for me to get the prompt for password, however when I login to my web hosting server it takes about 1 second. What can I do to speed this up?\n$ cat /etc/lsb-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=8.04\nDISTRIB_CODENAME=hardy\nDISTRIB_DESCRIPTION=\"Ubuntu 8.04.1\"\n$ ssh -v\nOpenSSH_4.7p1 Debian-8ubuntu1.2, OpenSSL 0.9.8g 19 Oct 2007\n$ cat /proc/cpuinfo\nmodel name      : Dual-Core AMD Opteron(tm) Processor 1210\ncpu MHz         : 1000.000\ncache size      : 1024 KB\n$ cat /proc/meminfo\nMemTotal:      2074528 kB\n\n\nA: For me, the reason number 2 (after the server-side UseDNS option) for long SSH session logins are client side attempts to connect using IPv6 (which, obviously, isn't set up correctly on my network - or almost any other network, for that matter).\nSee HOWTO: Speed up SSH login on Ubuntu forums.\nThe \"solution\" is to enable IPv4 only:\n1) either for the given SSH client invocation:\nssh -4 login@hostname\n\n2) or globally in ssh client conffiguration in /etc/ssh/ssh_config:\nHost *\n   AddressFamily inet\n\nOf course, it would be more correct to set up IPv6 on your network properly, but who has the time for that :)\n\nA: The number one reason I've seen for this is a configuration option in SSHD UseDNS this option (enabled by default) causes the server to perform DNS resolution on the incoming requests. A time consuming operation. I've seen logins go from one minute plus waiting for password prompt to under a few seconds. If you edit /etc/ssh/sshd_config on the server and add (if it's not there) at the bottom UseDNS no then restart the SSH daemon with service ssh restart you should see an improvement next time you connect.\n\nA: Try adding the next option with your ssh command:\n-o \"PreferredAuthentications=password\"\n\n(this prevents ssh from negotiating any other authentication method, and speeds up the password promtp!)\n\nA: Additionally, type this on the remote machine (as the user you would log in as) to suppress any MOTD messages:\ntouch ~/.hushlogin\n\nDoesn't make as much a difference as turning off UseDNS but it might help on slower connections.\n\nA: As you are using a rather old Ubuntu version, it might well be this bug: https://bugs.launchpad.net/ubuntu/+source/openssh/+bug/300151\nRestarting dbus (/etc/init.d/dbus restart) might help.\n", "Q: Why tilda take long time to appear on my laptop? Im using tilda on 2 computer, a desktop and a notebook, both with ubuntu LL 10.04 and Compiz.\nThe notebook has 6Gb RAM, 4 Cpu's (Core i3 330M) @ 2,13GHz, and an ATI Radeon HD 5650 (with ati closed drivers).. its a new notebook.\nThe Desktop has 2 Cpu, 4Gb ram and an Intel graphic card.. its 5 years old.\nI dont know why, but when i show/hide tilda (i use it in fullscreen mode with opacity), in the desktop show up instantly, instead in the notebook take 2~3 seconds.\nWhy the notebook is slower, even if it is more powerfull?\nCan be a matter of drivers/graphic card type, or there is some configuration i can check?\nOn both I did install tilda from ubuntu software sources.\nEDIT:\nI just noticed that it happens when i try to maximize every window (a terminal, google chrome, gedit, etc..), if i press F11 to maximize it: in the notebook it takes few seconds, in the desktop is instantly.\nCould it be a compiz setting?\n\nA: It was a driver problem.\nI solved installing the latest version of ATI drivers, adding two repositories:\ndeb http://ppa.launchpad.net/ubuntu-x-swat/x-updates/ubuntu lucid main \ndeb-src http://ppa.launchpad.net/ubuntu-x-swat/x-updates/ubuntu lucid main\nkey: http://keyserver.ubuntu.com:11371/pks/lookup?op=get&search=0x3B22AB97AF1CDFA9\n\nand then sudo apt-get update\n\nA: I would try re-installing; also maybe checking to see if the key binding you use launches another process in the background that you may be unaware of. \nOpen top and then run tilda, maybe that will help you troubleshoot better.\n\nA: Maybe you can try Guake ;)\nJust an idea..\n", "Q: Re-mapping keyboard keys I am using a keyboard with the Fn key. This is on a laptop.\nSo my Fn + Up/Down/Left/Right keys are mapped to brightness/volume. I would much rather them be mounted to Page Up/Page Down and Home/End. And map the other 4 keys to these 2. The page Page Up/Page Down has Fn + them for Home/End. Its a shitty keyboard layout but I want to make it work.\nAnyone knows how to figure out what the keycodes are and how to remap them?\nVersion: 10.04  x32\nSo here are some experiments:\nUsing xmodmap -pke I discovered that keycodes 122 = vol down, 123 = vol up. And I got all the info for Home/End/Page Up (next), Page Down (prior).\nNow when using the vol up keys, there are no events being fired that xev can detect.\nI can remap the volume keys to XF86AudioLowerVolume or XF86AudioRaiseVolume, but once I map those two to Home/End (respectively) they don't do anything. xev still does not pick up these events after a remap.\nRemap: xmodmap -e \"keycode 122 = Home\"\n\nA: Some laptop Fn key combinations are multimedia keys (appearing to the OS as ordinary keys with nonstandard codes), while others trigger ACPI events that eventually reach the OS, and some are just handled by the BIOS and never seen by the OS. The information paths are explained on the Hotkeys/Architecture page on the Ubuntu wiki, complete with diagrams.\nThe KeyTouch program should handle anything that is seen by the OS, and has a friendly GUI for describing your model and configuring what the keys should do (install the keytouch-editor package as well as keytouch).\nIf the OS can't see anything when you press the brightness keys, it could be because they're handled directly by the BIOS. The battle is not completely lost — it is in principle possible to hack the BIOS — but the difficulty level is considerably raised.\n\nA: There is a program called xev that does what you require. I liked the tutorial on setting it up.\n\nA: The Fn key combinations is not defined in software and can therefor not be redefined, so you need a soldering iron and some electronics knowhow!\n", "Q: How to turn off calling help on F1? I am playing ADOM right now and under F1 button there is very aggressive tactic, which is extremaly useful when you are fighting on distance. Right now I can't use it, because help dialog pops up. How can I turn it off?\n\nA: *\n\n*Launch System → Preferences → Keyboard Shortcuts\n\n*Locate the line that says \"Launch help browser\"\n\n*Click where it says \"F1\"\n\n*Hit the Backspace key.\n\n*It should now say \"Disabled\"\n\n\nA: Easiest solution: http://ubuntuforums.org/showthread.php?t=1317325\n", "Q: Has anyone got graphics working properly on 10.04 on a Sony Vaio P series? A fresh install gives me full native resolution but it's still pretty unusable. Scrolling a browser or page of text is so slow it's forced me back to windows (!). Youtube video is out of the question.\nI've also tried netbook edition but same problems (unsurprisingly).\nSpecifically, I have the Sony VGN-P11Z.\nCheers,\nMatt\n\nA: It's a known problem with the intel GMA 500 that your computer uses. The fix is avaliable in a ppa. To sum up, type in your teminal:\nsudo add-apt-repository ppa:gma500/ppa\nsudo apt-get update\nsudo apt-get install poulsbo-driver-2d poulsbo-driver-3d poulsbo-config\n\nand reboot.\n\nA: Javier is right above, but there's some additional fixes, too (especially for 10.10 at least)\nTry the end of this thread for 10.10 on Vaio P\nhttp://ubuntuforums.org/showthread.php?p=10027642\n(I'm also trying to keep this up to date, too, for my personal experience with setting it up at  dumbbunny.org/2010/10/24/sony-p-series-running-10-10-meerkat-ubuntu/  )\n", "Q: Nautilus doesn't show my desktop until I kill it Something's wrong with nautilus. When I boot my computer and it logs in, Gnome shows, things are running, I can run programs and everything, but my desktop has no icons. I have to open a terminal and run killall nautilus and then suddenly everything works fine.\nHow can I diagnose and fix this? Or, as a last resort, how might I create a script that runs at startup to automatically kill and restart nautilus?\n\nA: #!/bin/bash\nkillall nautilus\n\nWould be your script. make sure you make it executable\nchmod +x nameofscript.sh\n\nall you would have to do is place the script in the start up sequence using. \nSystems > Preferences > Startup Applications.\nI would first wait on your next restart maybe it just take a bit longer.\n\nA: This is a known bug in GNOME affecting many distributions.\nSee this bug report for details and workarounds.\n", "Q: Where do I even start if hibernate / un-hibernate is slow? I've been using Ubuntu for about 8 months now, and the time it takes to un-hibernate seems to vary by minutes sometimes. I haven't been able to see a correlation between what's open when it's hibernated and how long it takes. I'm wondering how to go about diagnosing this?\nI spun off the question about timing the wakeup to a separate question.\n\nA: The official hibernate troubleshooting page is Debugging Kernel Hibernate\nHowever, this forums article looks like it might be more useful (start at comment #4).\n\nA: I think the time taken to (un)hibernate will depend mainly on the RAM and swap usage. When you hibernate, the data in RAM is basically saved into swap and when you unhibernate it is loaded from disk. This will be slower when there is more RAM to move. When some swap is used it will most likely take even longer.\nIt may help with speed if you close the programs which you don't need to sustain their current state before hibernating. I always shut down completely if possible.\nI don't think there is an internal way to time (un)hibernation.\nhttp://en.wikipedia.org/wiki/Hibernation_(computing)\n\nA: Not only open applications, but also devices plugged in can affect hibernate time as they often have to be shut down and then brought up in just the right order and have timeouts and such applied to them.  Maybe it takes longer when you've got a USB hub or printer plugged in?  or when you've been using the audio device a lot?\n\nA: Yes I've noticed this myself. I'm using Linux Mint 19.1, and hibernation takes some about 5 minutes but some other times it will be quick even that nothing changed! Wake up from hibernation is fast enough but the issue is the computer will remain slow for about 5 minutes or more with constant disk access which I fail to know which service is causing. I feel the whole hibernation speed depends on the following:\n\n\n*\n\n*The size of consumed data in the memory which to be saved on SWAP partition.\n\n*Hard drive speed\n\n*Type of opened applications, I've noticed if virtual machine is running it will  slow hibernation process.\n\n\nAnyways I feel that hibernation/standby processes needs a lot of improvement in Linux, Windows is vastly superior in this area.\n", "Q: How do I find out which process is eating up my bandwidth? I think I'm being the victim of a bug here. Sometimes while I'm working (I still don't know why), my network traffic goes up to 200 KB/s and stays that way, even tough I'm not doing anything internet-related. \nThis sometimes happens to me with the CPU usage. When it does, I just run a top command to find out which process is responsible and then kill it. Problem is: I have no way of knowing which process is responsible for my high network usage. Both the resource monitor and the top command only tell me my total network usage, neither of them tells me process specific network info.\nI've found questions here about monitoring total bandwidth usage, but, as I mentioned, that's not what I need. Is there another command I can use to find out which process is getting out of hand?\nThe command iftop gives results that disagree entirely with the information reported by System Monitor. While the latter claims there's high network traffic, the former claims there's barely 1 KB/s.\nI've already tried killing all the obvious ones (Firefox, update-manager, Pidgin, etc) with no luck. So far, restarting the machine is the only way I found of getting rid of the issue.\n\nA: Another alternative is iptraf. It won't show you the PID of the process, but will tell you which connection uses how much bandwidth.\n\nA: Use iftop to locate the TCP port on your machine that is receiving the most traffic.\nThen use sudo netstat -tup to locate the process \"owning\" that port.  \nThat's the process you're looking for.\nPS: Should work for UDP too.\n\nA: Late answer, but I had the same problem. Turned out to be Ubuntuone. Found that by running tcpdump. I went through the same learning curve on process identification. \nFrom my notes:\n\nUbuntu box connection information\nStarted up my Ubuntu 10.04 desktop this morning to find that after a few minutes the Internet connection is crawling. I've seen this on Windows boxes before, and 99% of the time it's spyware. So, I needed to investigate...command line style.\ntcpdump. Shows Ubuntuone going crazy.\nSystem>Preferences>Ubuntu One. Turn all synchronization off. That did it.\nSo, I'm thinking I'd like to see all network connections and what they're doing. I can\nnetstat -cW (list network connections continuously in wide format so foreign addresses aren't truncated)\nlsof -i |grep -v 'localhost' (list open files matching an Internet address of any, grep to remove any open files associated with localhost -- my thought here being that I don't want to see local services as they likely will not affect network utilization).\nSome things to take away:\n  \n  \n*\n  \n*Need to learn about Ubuntu logs for troubleshooting.\n  \n*Need to learn more about tcpdump, so I'll start with this tutorial by Daniel Miessler.  \n  \n\n\nEditor's note: This answer was referring to tinker's blogspot article which is meant for invited users only. Since this answer has appreciable upvotes, so it is valuable. I found a copy of article on Wayback Machine. And included that here.\n\nA: I've had a lot of success with nethogs. It has to run as root but there are different ways you can sort the statistics (like KB/s or total bandwidth monitored since nethogs started).\nAlso, if you use wireless you need to pass the device to it.\nInstall it with command: sudo apt-get install nethogs\nJust run\nsudo nethogs\n\nIf you want to check the total cumulative sum of bandwidth consumed since you open nethogs, do (it's useful to see which programs consume more bandwidth over the long run)\nsudo nethogs -v 3\n\n\nA: You might want to look into ntop - which should monitor network activity on a process level. You can find ntop in the Software Center or with sudo apt-get install ntop\nFor installation instruction, follow their page http://packages.ntop.org/\n\nA: Here's one I like, it tells you what's reading from the network the most, anyway (doesn't seem to work for which one is \"writing to\" the network, so...you get half).\n$ sudo apt install dstat\nthen\n$ dstat --net --top-io-adv\n-net/total- -------most-expensive-i/o-process-------\n recv  send|process              pid  read write cpu\n   0     0 |chrome               1885   19k  17k0.4%\n 504B  734B|chrome               1923    0   66k0.2%\n 651k   18k|chrome               1923  597k 593k2.0%\n  19k   26k|gnome-terminal-      25834 429B  59k0.8%\n\n\n", "Q: Switching between graphics cards I've just bought an Asus laptop which is equipped with two graphics cards; one integrated in the intel i3 CPU and a Radeon Mobility HD5145.\nWill Ubuntu switch between the cards to balance power/performance? i.e. only use the Radeon when the demands placed on the integrated card are too great?\n\nA: No, Ubuntu will not switch between the cards.  This is known as a hybrid graphics system.\nIf you look in your /var/log/Xorg.0.log you can see which driver is loaded (page down a few screenfuls and look for RADEON(0) or intel(0).\nThe only way I know of to force which card to use is to specify the PCI Bus ID of the graphics card.  You get the Bus ID from lspci.  It's also usually shown near the top of your /var/log/Xorg.0.log.  Then, set up your xorg.conf with a device section and put\nBusID \"PCI:0:0:1\"\n\nor whatever bus id you want.  You don't need to specify the video driver as well (but it can't hurt).\nDavid Airlie has worked on making hybrid graphics work better. His blog has some interesting info about it...  \nSearching for 'linux hybrid graphics' may turn up other useful examples and details about it.\n\nA: Right now you can use the GUI provided by Ubuntu Control Center to switch between GPUs, but it only works with the opensource drivers.\nhttp://code.google.com/p/ucc/\nhttp://www.omgubuntu.co.uk/2010/08/ubuntu-control-centre-0-5-brings-gpu-switching-to-linux/ \n\nA: Your model has an AMD discrete graphics card, so you have two options:\n\n\n*\n\n*try the latest closed-source Catalyst Driver for login/logout card switching, or\n\n*try vga_switcheroo and open-source graphics drivers with the graphical vga switching already installed. See this YouTube video.\n\n\nA: That sounds like special software or configuration needed. I wonder if tools like http://www.grano.la take that into account.\n", "Q: connecting and copying files with scp -- ubuntu 10.04 I have a work computer. I have a home computer. I want to be able to share files between with scp, both our computers are behind routers, which assign a local ip. 198.168.0.*\nAs well as knowing their outside IP, I would like to know how to browse and share files and log in to one another with ssh, public keys as well please. \nPlease and thank you.\n\nA: If you want to connect to either computer, you will need to expose the computer through your router's NAT. Set up port forwarding to port 22 on both systems. Ideally, you will want to use keypair authentication and disable password access in /etc/ssh/sshd_config.\nAlternatively, if you have SSH access to a third system that can be exposed to the Internet, you can use SSH's built-in forwarding feature (man ssh, look up the -R and -L options and optionally -n) to open a port remotely that forwards back to your system. (For example: Computer A connects to the server with -R 2222:127.0.0.1:22, and computer B connects to the server on port 2222 to gain access to computer A.) There is some overhead involved, however minor.\nAs a variation on the above port forwarding: You'll likely only be able to open ports on your home computer - this will probably be enough. But if you need to be able to access your work computer from home, you will need to set up your work computer to connect to your home computer with an -R option as above. Then, you will be able to connect (ssh user@localhost:2222) without difficulty.\n\nA: You can forward port 22 on your home router (See the router manual for a howto on that) to the computer where the SSH-server is running, that way you can connect to your home ip-addres (external IP) from work. If you don't know that IP-address you can look here from your home computer.\nThe other way around is the same if you have access to the router at your work, but if you don't you might want to take a look at this or you can from your work computer do\nssh -R 8022:127.0.0.1:22 ip.of.home.comp\n\nThis will open a connection to your computer and make a TCP-tunnel from you local machine back to your work computer. When you come home you are then able to do:\nssh -o Port=8022 127.0.0.1\n\n", "Q: How do I enable the Ubuntu One tray applet? I am running 10.04 and I am unable to get a tray applet to appear for Ubuntu One. I am sure there was an applet in 9.04 (Jaunty) and 9.10 (Karmic).\nI have the package ubuntuone-client-gnome installed which Synaptic tells me \n\n\"This package contains the tray applet and Nautilus extension, providing integration with the GNOME desktop.\"\n\nThe applet is not on the \"Add to panel...\" list and there doesn't appear to be anything in the menus.\nSo how do I make the applet appear?\n\nA: Those of you wanting to know more about what the syncdaemon is doing may be interested in magicicada. It's a desktop app that talks to syncdaemon over dbus. It's already in Maverick, and you can get it off the PPA for Lucid: ppa:chicharreros/ppa.\n\"A tool for engineers by engineers\" would aptly describe it.\n\nA: As far as I know, the Ubuntu One applet has been integrated into the 'me menu'. At the bottom of the me menu you should see something like:\nChat Accounts...\nBroadcast Accounts...\nUbuntu One...\n\nClick on 'Ubuntu One...' to edit Ubuntu One preferences. Other actions are done in nautilus. You can right click on a file/folder (in your home folder) and click 'Synchronise on Ubuntu One' for example. \n\nA: Richard - At Ubuntu 10.04 LTS, we removed the applet that was there in Ubuntu 9.10. Hopefully, there will be some updates to the network indicatory menu in Ubuntu 11.04 that we will be able to take advantage of to show Ubuntu One sync status. Until then, you can use Jorge's technique of running u1sdtool from the Terminal.\nu1sdtool --help returns a list of the arguments you can use to tell what's happening with sync. Some ones that I use frequently are \n\n\n*\n\n*u1sdtool -c\n\n*u1sdtool -s \n\n*u1sdtool --waiting-content\n\n*u1sdtool --current-transfers\nThanks!\n\nA: If you are still interested in it have a look at: ubuntuone-indicator\n", "Q: Create a Hamachi like NAT based VPN tool Is there a tool like Hamachi which works on Ubuntu? Bonus points if it can be paired with something running on Windows/Mac.\n\nA: OpenVPN is the server and client side program that does the communication, and there are a number of GUI tools for configuring OpenVPN to do pretty much everything that Hamachi2 does:\nHere's a good list:\ncclint@ubuntu:~$ apt-cache search openvpn configuration\ncollectd-core - statistics collection and monitoring daemon (core system)\ngadmin-openvpn-client - GTK+ configuration tool for openvpn (client)\ngadmin-openvpn-client-dbg - GTK+ configuration tool for openvpn (debug for client)\ngadmin-openvpn-server - GTK+ configuration tool for openvpn (server)\ngadmin-openvpn-server-dbg - GTK+ configuration tool for openvpn (debug for server)\nopenvpn-auth-ldap - OpenVPN LDAP authentication module\ntunneldigger - Configures OpenVPN tunnel networks\n\nI don't use any of them, but they all should be safe to try out for sure.\n\nA: How to install Hamachi on Ubuntu?\nThis is Haguichi\nThis is Hamachi-GUI\n\n\nA: Wippien\n", "Q: Copying to two locations at the same time I'm not very fluent with bash... what I'd like to do is copy the content of a DVD-R to two different hard drives in the fastest possible way.\n(UI-based solutions are welcome too)\nThanks!\n\nA: The bottleneck is likely to be reading from the DVD drive, so we must ensure to either read it only once, or read it twice but at sufficiently close intervals that the data will still be in the cache. The latter sounds difficult, so let's go for the first.\nWe need to get a duplicator in there somewhere. If we restrict to basic shell commands, the only choice is tee. So we need to convert the input (a tree of files) into a stream, feed the stream to tee, and convert each output stream back to a tree of files. The tool to do that is an archiver. Compression on something that'll remain in memory is a waste, so let's just use tar.\nPipes (command0 | command1) allow us to feed the output of a command into one other commands. We need to feed the output of tee into two other commands, so another bash construct comes in handy: command1 >(command2) creates a pipe that is passed to command1 as its first command rather than becoming the standard output of command2. (Look up process substitution in the bash manual.)\nHere's the command (untested):\nmkdir /media/disk0/copy_of_dvd /media/disk1/copy_of_dvd\ncd /media/cdrom\ntar cf - . | tee >(tar xf - -C /media/disk0/copy_of_dvd) | tar xf - -C /media/disk1/copy_of_dvd\n\n\nA: One shell based solution is to open a terminal and type:\ncp -r /location/of/DVD /hard/drive/a &\ncp -r /location/of/DVD /hard/drive/b\n\nThe command cp is for copy files and the -r switch copies all files recursively. You have to enter the directory where your DVD is located (usually /media/dvd or similar) and second the place in the harddrive where you want the files (i.e. /home/diego/mydvd). The & sends the first process to the background and you can immediately enter and execute a second command.\n\nA: As mentioned in Li Lo's comment to qbi's answer, optical drives (CD, DVD, etc.) are the slowest kind of drive, so you want to minimize the amount of reading that you do from the DVD drive. The obvious solution would be to copy the data from the DVD to one location on the hard drive and then copy it from that location to the other hard drive.\ncp -r /media/cdrom /location1\ncp -r /location1 /location2\n\n", "Q: How can I create a application launcher for a .sh file? I have this run.sh file, and I've create a symbolic link into my desktop. \nWhen I double-click on it the file the following dialog appearsr\n\nAnd I have to click on \"run\" each time. How can I create a link that runs by default?\n\nA: Why not just configure Nautilus to execute by default?\nUnder Nautilus goto Edit->Preferences->Behavior and click:\n\"Run executable text files when they are opened\"\n\nA: Richard's solution does not work for the Unity Desktop which recent Ubuntu versions use by default. To easily create shortcuts in unity you can use the \"Main Menu\" aka alacarte application which lets you edit programs. Just click the appropriate category and then \"Create Item\".\n\nA: Instead of linking directly to the .sh file create an application launcher as follows:\n\n\n*\n\n*Right click on your desktop\n\n*Choose \"Create Launcher...\"\n\n*Change \"Application\" to \"Application in Terminal\" in the drop down box.\n\n*Give it a name like \"Idea\"\n\n*Enter the command like this /path/to/script/idea.sh\n\n*Add a comment if you like, it will show up when you mouse hover over it if you move the launcher to a menu bar.\n\n\nThen when you click the launcher a terminal window will open and the command will run in there. \nIf you don't want to open a terminal to see any output, just use \"Application\" instead of \"Application in Terminal\".\nYou may have to edit the desktop file with something like gedit to add the \"Path\" of the script. Like This:\n#!/usr/bin/env xdg-open\n\n[Desktop Entry]\nVersion=1.0\nType=Application\nTerminal=false\nIcon[en_US]=/home/kurt/Games/dontstarve/dontstarve.xpm\nExec=/usr/games/dontstarve/bin/dontstarve.sh\nPath=/usr/games/dontstarve/bin\nName[en_US]=Dont Starve\nName=Dont Starve\nIcon=gnome-panel-launcher\n\n\nA: I Wanted to make it easier to launch \"Dont Starve\" for my kids. I started the program with /usr/games/dontstarve/bin/dontstarve.sh in a terminal, but wanted it in the applications menu. \nI added a menu item with Alacarte but it would not work because it was a .sh file.\nAfter many searches, I figured I needed to specify the path for the script.\nAdd path as explained in Desktop Variables\nI located the launcher alacarte-made-51cc077a-58af-11e3-a764-00252267190b.desktop in \n~/.local/share/applications/ and modified it by adding the path line.\nNow Launcher file looks like this:\n#!/usr/bin/env xdg-open\n\n[Desktop Entry]\nVersion=1.0\nType=Application\nTerminal=false\nIcon[en_US]=/home/kurt/Games/dontstarve/dontstarve.xpm\nExec=/usr/games/dontstarve/bin/dontstarve.sh\nPath=/usr/games/dontstarve/bin\nName[en_US]=Dont Starve\nName=Dont Starve\nIcon=gnome-panel-launcher\n\nWorks like a champ. I Hope this helps someone else. \n( I actually run Mint 15 Olivia based on Ubuntu Raring )\n", "Q: How to Schedule a Ruby Script I have a ruby script I'd like to execute every 5 minutes or so.  I have seen mention of cron tasks, but not in the context of executing Ruby.  I would like to know the steps necessary to execute the ruby script on a scheduled basis.\n\nA: Scripts are scripts whether they be python, bash or ruby. Just make sure they are executable.\nThey are the same as steps listed here. \n", "Q: Disabling auto-open How do I keep CD/USB automounting (works fine) BUT without auto-opening in Nautilus?\n\nA: From inside Nautilus: Edit > Preferences > Media\nHere you can change behavior for recognized media types (CD, Music Player, Photos, etc.) and unrecognized (\"Browse media when inserted\" option).\n\n\nA: System->Preferences->Removable Drives (only in Ubuntu version 9.04 and below)\nThere should be setting there to chose what happens when removable media is inserted.\n", "Q: Trouble with UFW blocking stuff from NAT machine to inside of NAT I've got a NAT box (Ubu 10.04) running ufw with the following sudo ufw status verbose:\nStatus: active\nLogging: on (low)\nDefault: deny (incoming), allow (outgoing)\nNew profiles: skip\n\nTo                         Action      From\n--                         ------      ----\n22480/tcp                  LIMIT IN    Anywhere\n\nWhen I nmap -PN -p 22 192.168.0.0/24 to find all the SSHes running on my NATed (working fine) inside network, I get the following: \nStarting Nmap 5.00 ( http://nmap.org ) at 2010-08-16 23:06 EDT\n0 ports scanned on 192.168.0.0\n\nInteresting ports on 192.168.0.1:\nPORT   STATE  SERVICE\n22/tcp closed ssh\n\nInteresting ports on 192.168.0.2:\nPORT   STATE    SERVICE\n22/tcp filtered ssh\n\nInteresting ports on 192.168.0.3:\nPORT   STATE    SERVICE\n22/tcp filtered ssh\n\nInteresting ports on 192.168.0.4:\nPORT   STATE    SERVICE\n22/tcp filtered ssh\n\n... Continuing for all 254 IPs ...\n\nNote that there are not machines at those other IPs (2, 3, 4, ...).\nWhy is this UFW rule causing this??  Why should a UFW input rule mess with the ability to nmap out from the router into the internal network?  That's not an input, and ufw is set to the default config (except as above) of blocking input ports and not blocking output to  ports.\nAlso, how can I get it to stop logging all the crap that isn't important that it receives?  I do want it to log stuff destined to my IP, but not broadcast traffic from Windows machines on the outside (routable) network.  The logging of this stuff is really making the logs huge.\n\nA: I don't know anything about ufw. But nmap always returns filtered if you test a machine that doesn't exist without discovering it first.\nIf the machine doesn't answer, nmap can't really know if it is because it doesn't exists or just because it's ignoring the packages. As you are disabling ping (-PN) Nmap doesn't try to discover hosts so it's assumes that it exists and is filtering the packets.\n\nA: For the ufw logging, ufw has several different log levels. You can adjust them like so:\n$ sudo ufw logging low\nIf you want some logging, but not all, you can set the loglevel and then insert a deny rule at the beginning of your chain. Eg:\n$ sudo ufw insert 1 deny to 192.168.1.255\n", "Q: What eBook readers are available? Can anyone suggest a nice eBook reader in Ubuntu? \nPreferably something lightweight.\n\nA: I've not been happy with Calibre due to the translation functions outputting corrupt RTF's as well as the developer's aggressive lack of interest in providing packages.  I usually just use OpenOffice to translate stuff to PDF (using Gentium Book Basic) and then use Evince which seems to work fine for me.\n\nA: There is an amazing piece of software called Calibre. I linked an article talking about its features it nice and useful! To install it click the icon: calibre \nAlternatively you can install Adobe Reader with eBook extension. \n\nA: FBReader \n\nA: If you use Firefox and have it running most of the time you can read the .epub format e-books from within the browser with this extension http://www.epubread.com/en/\n\nA: I use Calibre because the integration with my Android phone is amazing. Calibre + Wordplayer FTW!\n\nA: My suggestion would be Cool Reader 3.  It's a simple install, and a very lightweight program (nothing so bulky as Calibre, which is nice software IF you have eBook hardware like e.g. a Kindle or a Sony, but overpowered for just a ePub viewer).\nYou can get Cool Reader by:\nsudo add-apt-repository ppa:vovansrnd/coolreader\nsudo apt-get update\nsudo apt-get install cr3\n\nCheers!\n\nA: This software has been discontinued.\nEasy-Ebook-Viewer\nI used to love fbreader but in ubuntu 17.04 it got problem while installing.\nSo after a little googling I found Easy-Ebook-Viewer\nInstallation:\nsudo apt install git gir1.2-webkit-3.0 libwebkitgtk-3.0-0 gir1.2-gtk-3.0 python3-gi\ngit clone https://github.com/michaldaniel/Ebook-Viewer.git\ncd Ebook-Viewer\nsudo make install\n\n", "Q: Ufw causing trouble with DHCP or WPA? It appears that enabling UFW is causing my network connection to drop periodically on a WPA-Enterprise network, according to the network-manager GUI app (and the lack of a server response to web browsing for a minute or so while it is out).  Is this because UFW is preventing something needed for WPA or DHCP when configured with the defaults?\n\nA: I'm running 10.04 on a Dell X300 (old) laptop with ufw enabled (through GUFW gui tool : sudo apt-get install gufw, then configure from system/administration/firewall configuration).\nWe use a non-hidden SSID configured with WPA2 and PEAP authentication.  No issues.\nUFW is configured as default - deny all incoming, allow all outgoing.\nAs a result, DHCP should be unaffected since technically it's outbound traffic (a network broadcast to the local subnet), to which the DHCP server responds appropriately.\nLike the commenters above, I presume that everything works if you disable UFW (sudo ufw disable)?  If so, further investigation required - perhaps a look at /var/log/messages or similar.\n", "Q: What IM do you use to login into Microsoft Office Communicator? I've used Pidgin, but it hasn't worked 100%, so maybe you know about something better...\n\nA: I used to use pidgin-sipe in Pidgin. The same plugin apparently works through empathy too.\nI say \"used to\" because I'm not longer in an environment where I need it, not because I found anything better. As far as I know, it's the only plugin to tackle the problem.\nIn short, I think you're left trying get your problems fixed (report a bug), rather than jumping boat to another project... Which is probably healthier for both of you.\n\nA: pidgin-sipe works very well, make sure your office communicator server and proxy server (if necessary) is set correctly.\n\nA: As it was said, you can use either Empathy (installed by default on UBuntu) or Pidgin (available in the Software Centre), as long as you install the following plug-in which works for both: pidgin-sipe.\nThere is a detailed explanation of the steps on this forum thread: http://ubuntuforums.org/showthread.php?t=1291311\nLook for Huygens' (myself) posts.\n", "Q: How to make \"suspend\" option work? In the power management, I selected the option called \"suspend when I close the lid\". If I close the lid, the computer is not suspending. It keep itself on. How can I solve this problem?\n\nA: This usually happens when some process stops the system from being suspended.\nDo\ndmesg -T|grep Freez -A4\n\nand look for these entries:\n--\n[sun mar  3 15:19:48 2013] Freezing user space processes ... \n[sun mar  3 15:20:08 2013] Freezing of tasks failed after 20.01 seconds (3 tasks refusing to freeze, wq_busy=0):\n[sun mar  3 15:20:08 2013] mount.nfs       D e8631aa0     0  5518   5517 0x00800004\n[sun mar  3 15:20:08 2013]  e8631b10 00000086 f7bc0e00 e8631aa0 c1053cb4 c1809020 c192ee00 c192ee00\n--\n\nCheck the time stamps to see which of the reported problems relate to your try to suspend. In this case, it is mount.nfs that is causeing the problems.\nNow, put a script in /etc/pm/sleep.d/, scripts there will be run at suspend and resume. The file name should start with an ordering number, 00-49 for user scripts (for more details, see man pm-suspend).\nThe script could look like this\n#!/bin/sh\n(killall -1 mount.nfs; exit 0)\n\nwith correpsonding entries for other processes that caused problems, if any.\nParenthesis and exit 0 is a trick: if the process isn't found, killall will exit with exit code 1, which will cancel the entire suspend. The above will run killall in a sub-shell that will exit with 0.\nIf you're having problems, check /var/log/pm-suspend.log that will log the attempt to suspend and to run your script.\n\nA: Does the computer suspend when you choose the suspend option instead of closing the lid?\nCheck the suspend logs at /var/log/pm-suspend.log\nthat might tell you why it's not suspending. \n", "Q: Quotation marks in Ubuntu Terminal I'm using Ubuntu 9.04 as a guest in VMWare. When I am using quotations marks in terminal, the first pressing of the key produces nothing, while the second one produces a double quotation mark looking like the ones from the keyboard, but different from the ones I already have in some text documents. What should I do?\n\nA: This probably has to do with \"Dead keys\".\nGo to Menu>System>Preferences>Keyboard click the tab labeled \"layout\" and try to add a different keybord layout (I have no clue if this helps for a Romanian keybord layout).\nAlternatively, try to press space afterwards (instead of pressing the key twice).\n\nA: It sounds like the terminal might be using start and end quotes instead of just quotation marks... Which is odd. And wrong. Why it's doing this, is beyond me, and I can't think of a solution other than copying and pasting.\n", "Q: How much space will the Ubuntu 10.04 netbook take after installation......is it compatible with the Archos 9? I wanted to install Ubuntu on my Archos 9, which currently has Windows 7 starter. Is it possible to get onscreen keyboard with d default key on archos??\nHow much space does Ubuntu take up after installation?\n\nA: Had a quick look around this seems to be quite a comprehensive guide on how to do it\nhttp://www.ossramblings.com/installing-ubuntu-archos-9-tablet\nIn that guide they use a netbook install of Ubuntu not sure how much space that takes up normally but I know the system requirement for the desktop version is 5Gb so would think the netbook version would be a bit less.\n", "Q: Why won't Blizzard make Starcraft 2 compatible with Ubuntu? Will this chicken-VS-egg problem of not having new top games for linux ever get solved?\n\nA: \nWill this chicken-VS-egg problem of\n  not having new top games for linux\n  ever get solved?\n\nProbably. As Linux distributions continue to get better for more and more scenarios and increase their desktop share, companies will notice Linux and push out clients.\nYou have to understand, porting a game is not a cheap or simple process:\n\n\n*\n\n*Any libraries that are single-platform have to be swapped out (DirectX)\n\n*Any non-portable code has to be swapped out\n\n*(The biggest): Testing.\n\n\nIt basically means keeping devs working for a lot longer, hiring more testers to test on umpteen different distributions with umpteen different configurations on umpteen different hardware variants and then distributing and maintaining it.\nIt'll happen when these companies know they'll get a return on their investment and that's probably going to need one big company to take a risk on us and prove (or disprove) that we're a viable market for games. \nAt the moment, Valve looks like our best bet but even if they released Steam with all their Source Engine games today, it would be years before the likes of EA took serious notice.\nIn the meanwhile, Wine is getting pretty good at getting current AAA games working within a few months.\n\nA: Two words: Market share.\nUbuntu's market share is at about 1%.  Microsoft Windows is at about 92%.  While Mac OS X is at about 5%.\nIt just wouldn't be worth their time to develop and support software (Starcraft 2) to run on Ubuntu or any other flavor of Linux.  \nSimply put, Ubuntu isn't popular enough.\nSource for statistics: Ars Technica: Windows 7 growing faster than Vista, overtakes Mac OS X\n\nA: It depends on what you mean by 'compatible'. If you mean a native version, it is unlikely that one will be created due to the market share arguments made by @sunpech.\nYou'd be better off asking how to run Starcraft 2 on Ubuntu.\nFrom the wine application database:\nhttp://appdb.winehq.org/objectManager.php?sClass=version&iId=20882\nit looks like it can be run quite well in wine. You should try running it in wine.\n", "Q: Is it possible to extend the disk space available to a wubi install? I installed ubuntu 10.04 using wubi. I now wish to allocate more disk space to my ubuntu install. Is this possible?\n\nA: From the WubiGuide:\n\nHow do I resize the virtual disks?\nYou can use LVPM, at\nhttp://lubi.sourceforge.net/lvpm.html\nAs an alternative, you can use the\nfollowing script to move /home to a\ndedicated virtual disk.\nDownload wubi-add-virtual-disk, open a\nterminal and run:\nsudo sh wubi-add-virtual-disk /home 15000\n\nWhere the first argument is the\ndirectory to move to a new dedicated\ndisk, and the second argument is the\nsize in MB.\nYou should now reboot. If you are\nhappy with the result, you can now\nremove /home.backup. To undo the\nchanges remove /home, copy rename\n/home.backup to /home and remove the\n/home line in /etc/fstab.\nNote that contrary to previous\ninformation, this script is not\nsuitable for moving /usr - experienced\nusers may be able to do this manually,\nat own risk, following a process\nsimilar to that outlined in the file.\n(Do not rename /usr until the very\nlast moment, as rsync is installed\nthere.)\n\n\nA: There are a few options to resize. Source the Wubi Guide.\nYou can resize by making a duplicate, larger root.disk. The downside is that it doesn't help if you're short on space and it takes a little longer. On the plus side, you have a backup to make sure everything worked and you run it right from the Wubi install.\nThe other method is to dynamically resize the root.disk in place. The downside is you have to do it from a Live CD/USB, you don't automatically get a backup, and there's no helper script. The plus side is it's blazingly fast and you can increase by a couple of GB rather than find space to duplicate++.\nBoth methods are documented in the Ubuntu community Wiki.\nIt's also possible to create a separate virtual disk for your /home directory. This is not discussed here, but can be found in the Wubi Guide.\nResize and Duplicate the root.disk\nFirst download the script wubi-resize-1.6.tar.gz from https://help.ubuntu.com/community/ResizeandDuplicateWubiDisk to your Downloads directory, right-click and choose \"Extract here\". The rest of the resize is run from the Terminal. \nFor usage instructions:\ncd ~/Downloads/wubi-resize-1.6\nbash wubi-resize.sh --help\n\nTo create a new 10GB virtual disk:\nsudo bash wubi-resize.sh 10\n\nSee the Wiki documentation for more information, including how to verify the integrity of the script. Also, note that there's a built-in maximum for the new disk (32GB), but this can be overridden with the --override-max option. (I don't recommend making the root.disk too large because many Wubi installs suffer from corruption and sometimes the data is not recoverable`. It's better in this case to use shared data partitions or to migrate to a normal dual boot.\nIn-place resize of the root.disk\nIf you don't have enough space to do a full duplicate, you can do an in-place resize instead. For this you have to boot from a live CD/USB as it won't work while running Wubi. Although not required, it's a good idea to backup the root.disk or the data on it. (This is a good idea for any Wubi install as it's not as reliable as a normal install).\nMount the NTFS partition that your root.disk is on (this example assumes it's /dev/sda1 and the mountpoint is /media/win - adjust accordingly in the following instructions):\nsudo mkdir -p /media/win\nsudo mount /dev/sda1 /media/win\n\nCheck the size of the root.disk (not required):\ndu -h --apparent-size /media/win/ubuntu/disks/root.disk\n\nRun fsck on the root.disk:\nfsck -f /media/win/ubuntu/disks/root.disk\n\nResize - specify the desired final size (this example resizes to 10 GiB):\nresize2fs /media/win/ubuntu/disks/root.disk 10G\n\nReboot back into Wubi Ubuntu. See https://help.ubuntu.com/community/ResizeWubiDisk for more information.\n", "Q: Clock stops ticking when inactive, causing drift The clock applet drifts in time.\nClock is set to \"synchronize with internet ...\" so it is correct at startup, but then if I stay inactive for some time, may be 5 min as well as 1 hour, the clock stops ticking.\nIf I start to be active again, then the clock applet moves again, but the time is now late.\nAnd it is not only the applet that is wrong, but the whole system date, because when I run date in a terminal, the time is also wrong.\nClarification : \nSorry, may be my question was not clear. Here is my bug report to ubuntu :\nExpected Behaviour :\nClock-applet displays the correct time,\nObserved Behaviour :\nDisplayed time is drifting\nHow to reproduce :\nIf I get away from my computer for some times, the time displayed by the clock applet drifts. But the date command also show the wrong time. Moreover, sleep interval also get wrong. To debug this, I tested the following script :\n#!/bin/bash\nwhile [[ true ]]\ndo\n    date >> clocktest.log\n    hwclock >> clocktest.log\n    sleep 300\ndone\n\nMust be run as root because of hwclock.\nIl launched it : \n./clocktest.sh &\n\nand got away from my computer\nHere is the output log :\n1 mardi 17 août 2010, 12:42:12 (UTC+0200)\n2 mar. 17 août 2010 12:42:13 CEST -0.346882 secondes\n3 mardi 17 août 2010, 12:47:13 (UTC+0200)\n4 mar. 17 août 2010 12:57:13 CEST -0.080965 secondes\n5 mardi 17 août 2010, 12:52:13 (UTC+0200)\n6 mar. 17 août 2010 13:02:14 CEST -1.002776 secondes\n7 mardi 17 août 2010, 12:57:18 (UTC+0200)\n8 mar. 17 août 2010 13:07:18 CEST -0.063633 secondes\n9 mardi 17 août 2010, 13:02:18 (UTC+0200)\n10 mar. 17 août 2010 13:12:19 CEST -0.361501 secondes\n11 mardi 17 août 2010, 13:07:19 (UTC+0200)\n12 mar. 17 août 2010 13:17:20 CEST -0.987434 secondes\n\nLine 1 and 2 show the first time through the loop.\nLine 3 and 4 show the bug : while date (and sleep) thinks 5 minutes have elapsed, hwclock shows that 15 minutes have elapsed.\nLine 5 to 12 shows normal behaviour, except now date is late by 10 minutes.\nBehaviour is normal because I was back at my desk using the computer.\nHaving clock applet displaying the wrong time is one thing, but having the whole system time wrong (since sleep gets confused too) is a major bug.\nHardware : \nIt is a fujitsu siemens amilo xi 2550 notebook.\nIt was working fine with ubuntu 8.04\n\nA: Your CMOS battery seems to be dying.  Open the computer, and there's a little thing that looks like a large watch-battery on the motherboard.  Replace that.\n", "Q: How to hide users from the GDM login screen? I have recently added several new users, that I need for qmail. Now they appear in the box in the login screen and clutter it, and I have to scroll to find my user. How can I hide those users from the login box?\n\nA: For newer GDM 3.X, old answers don't work, except for this one\nThe greeter setting in custom.conf is obsolete, i.e. it won't work anymore. One easy workaround if you want to avoid changing the uid of the user:\n\n\n*\n\n*Open the terminal, and enter (replace user with the username you want to hide from the login screen):\nsudo nano /var/lib/AccountsService/users/user\n\n\n*Add the following to the file:\n[User]  \nLanguage=   \nXSession=gnome  \nSystemAccount=true  \n\n\n*Switch user or log out to test if user is not listed anymore.\n\nA: Edit the file /etc/gdm/gdm.schema find the section that currently looks like this:\n  <schema>\n    <key>greeter/Exclude</key>\n    <signature>s</signature>\n    <default>bin,root,daemon,adm,lp,sync,shutdown,halt,mail,news,uucp,operator,nobody,nobody4,noaccess,postgres,pvm,rpm,nfsnobody,pcap</default>\n  </schema>\n\nAnd to exclude a user called qmail for example add qmail to the default list so the section looks like this.\n  <schema>\n    <key>greeter/Exclude</key>\n    <signature>s</signature>\n    <default>qmail, bin,root,daemon,adm,lp,sync,shutdown,halt,mail,news,uucp,operator,nobody,nobody4,noaccess,postgres,pvm,rpm,nfsnobody,pcap</default>\n  </schema>\n\nThat will stop user qmail appearing in the gdm greeter.\nThere used to be a nice GUI tool to do this but is has not been in Ubuntu for the last few releases.\nThe other alternative is to set the UID of the user to under 1000. Those are considered to be system accounts which are excluded in the GDM greeter too.\n\nA: I wrote a script (gdm-greeter) this weekend. It works well on CentOS 6.2, I wonder if it will be useful for Ubuntu?\n#!/bin/bash\n#\n# $LastChangedDate: 2012-02-17 09:13:10 +0100 (Fri, 17 Feb 2012) $\n# $Revision: 1627 $\n#\n\n# Get the default exlude list\nDefaultExclude=`sed 's,</schema>,#,' /etc/gdm/gdm.schemas | \\\n                tr '\\n#' '#\\n' | \\\n                grep '>greeter/Exclude<' | tr '\\n#' '#\\n' | \\\n                grep '<default>' | \\\n                sed -e 's,.*<default>,,' -e 's,</default>.*,,'`\n\n# Get the Exclude list from the config\neval `grep '^Exclude=' /etc/gdm/custom.conf 2> /dev/null`\n\n# If empty copy the default\nif [ \"$Exclude\" = \"\" ]\nthen\n   Exclude=$DefaultExclude\nfi\n\n# Collect all user accounts with a shell\nUsers=\"`grep 'sh$' /etc/passwd | awk -F: '{print $1}' | \\\n        sort | tr '\\n' ',' | sed 's/,$//'`\"\n\n\n#------------------------------------------------------------------------------\n\n# The functions area\n\nPlaceExclude() # $1 new exclude string\n{\n   # Create a .bak file\n   if [ ! -f /etc/gdm/custom.conf.bak ]\n   then\n      cp /etc/gdm/custom.conf /etc/gdm/custom.conf.bak\n   fi\n\n   # Create a tmp file without the Exclude string\n   cat /etc/gdm/custom.conf | tr '[\\n' '\\n[' | \\\n   sed -e 's/^\\(greeter[]].*\\)[[]Exclude=[^[]*\\([[].*\\)/\\1\\2/' | \\\n   tr '[\\n' '\\n[' > /tmp/custom.conf.$$\n\n   # If the tmp file is there and we have non default Exclude\n   if [ -f /tmp/custom.conf.$$ ]\n   then\n      if [ \"$1\" = \"$DefaultExclude\" ]\n      then\n         cat /tmp/custom.conf.$$ > /etc/gdm/custom.conf\n      else\n         # Place the new Exclude string\n         cat /tmp/custom.conf.$$ | tr '[\\n' '\\n[' | \\\n         sed -e \"s/^greeter[]][[][[]/greeter][Exclude=$1[[/\" | \\\n         tr '[\\n' '\\n[' > /etc/gdm/custom.conf\n      fi\n   fi\n   rm -f cat /tmp/custom.conf.$$\n}\n\n#------------------------------------------------------------------------------\n#------------------------------------------------------------------------------\n\n# Command area\n\nadd() # Cmd (Add a user to the greeter {<user>\n{\n   UserFilter=`echo $Users | sed 's/,/|/g'`\n   if ! echo $1 | egrep -w $UserFilter &> /dev/null\n   then\n      echo \"Error: user $1 unknown\"\n      echo\n      return 1\n   fi\n\n   # Only work with the users not in the default exclude list\n   Filter=`echo $DefaultExclude | sed 's/,/|/g'`\n   Hidden=`echo $Exclude | tr ',' '\\n' | egrep -vw \"$Filter\" | tr '\\n' ','`\n\n   # Check if we need to do something\n   if ! echo $Hidden | tr ',' '\\n' | grep -w $1 &> /dev/null\n   then\n      echo\n      echo \"User $1 is not hidden\"\n      echo\n   else\n      # Remove the user from the exclude\n      PlaceExclude \"`echo $Exclude | tr ',' '\\n' | grep -vw $1 | \\\n                     tr '\\n' ',' | sed 's/,$//'`\"\n\n      # Tell the action\n      echo \"User $1 added to the greeter\"\n      echo\n   fi\n}\n\ndel() # Cmd (Delete/hide a user from the greeter {<user>\n{\n   UserFilter=`echo $Users | sed 's/,/|/g'`\n   if ! echo $1 | egrep -w $UserFilter &> /dev/null\n   then\n      echo \"Error: user $1 unknown\"\n      echo\n      return 1\n   fi\n\n   # Check if we need to do something\n   if echo $Exclude | tr ',' '\\n' | grep -w $1 &> /dev/null\n   then\n      echo\n      echo \"User $1 is already excluded from the greeter\"\n      echo\n   else\n      # Exclude the user\n      PlaceExclude \"$1,$Exclude\"\n\n      # Tell the action\n      echo \"User $1 hidden from the greeter\"\n      echo\n   fi\n}\n\nhide() # CMD (Delete/hide a user from the greeter {<user>\n{\n   del $1\n}\n\nhidden() # Cmd (List the hidden users {\n{\n   Filter=`echo $DefaultExclude | sed 's/,/|/g'`\n   Hidden=`echo $Exclude | tr ',' '\\n' | egrep -vw \"$Filter\" | tr '\\n' ','`\n\n   if [ ${#Hidden} -eq 0 ]\n   then\n      echo \"No hidden users\"\n      echo\n   else\n      echo\n      echo \"Users hidden from the greeter:\"\n      echo\n      echo $Hidden | tr ',' '\\n' | sed 's/^/   /'\n   fi\n}\n\nusers() # Cmd (List the users in the greeter {\n{\n   Filter=`echo $Exclude | sed 's/,/|/g'`\n   Greeters=`echo $Users | tr ',' '\\n' | egrep -vw \"$Filter\" | tr '\\n' ','`\n\n   if [ ${#Greeters} -eq 0 ]\n   then\n      echo \"No users in the greeter\"\n      echo\n   else\n      echo\n      echo \"Users in the greeter:\"\n      echo\n      echo $Greeters | tr ',' '\\n' | sed 's/^/   /'\n   fi\n}\n\nlist() # CMD (List the users in the greeter {\n{\n   users\n}\n#------------------------------------------------------------------------------\n#------------------------------------------------------------------------------\n\n# Framework area\n\nhelp() # Cmd (Command help {[command]\n{\n   if [ \"$1\" = \"\" ]\n   then\n      CMD=help\n   else\n      CMD=$1\n   fi\n\n   if ! grep \\^${CMD}*\\(\\).*#.*Cmd $0 > /dev/null 2>&1\n   then\n   (\n      echo\n      echo \"Error: unknown cmd\"\n      echo\n   ) >&2\n   else\n   (\n      echo\n      echo \"Usage: `basename $0` $CMD `grep \\^${CMD}*\\(\\).*#.*Cmd $0 | \\\n                    sed 's/.* {//g'`\"\n      echo\n   ) >&2\n   fi\n}\n\n#\n# Main\n#\n\nif [ \"$1\" != \"\" ] && grep -i $1\\(\\).*#.*Cmd $0 > /dev/null 2>&1\nthen\n   $*\nelse\n   echo\n   echo \"Usage: `basename $0` command [parm1] [parm2] [..]\"\n   echo\n   echo \"  Available Commands:\"\n   echo\n   grep \\^[0-9a-z_A-Z]*\\(\\).*#.*Cmd $0  | \\\n   awk -F\\( '{printf \"%-16s %s\\n\",$1,$3}' | sed 's/ {.*//g' | sort\n   echo\nfi\n\n\nA: I'd have to agree that the most accepted answer here is close, but not dead on.\nI just licked this problem myself, and the answer for me was to alter the following gdm.schema entry:\n(original)\n<schema>\n      <key>greeter/IncludeAll</key>\n      <signature>b</signature>\n      <default>true</default>\n    </schema>\n\n(after my edit)\n<schema>\n      <key>greeter/IncludeAll</key>\n      <signature>b</signature>\n      <default>false</default>\n    </schema>\n\nThe effect of this is that all user-listing is disabled, which if I'm interpreting the original question correctly, is actually what the OP (gruszczy) was intending to do.  This eliminates the need to craft a long line of excludes, as all userIDs regardless of UID number are excluded regardless once this setting is altered.  I've personally applied this setting to 3 separate CentOS 6.2 servers at work that are occasionally accessed via XDMCP (using xrdp > vnc-server > xinetd > gdm > gnome) over RDP, which allows some of our less experienced Linux admins work on these systems with minimal training.\nAll of that said,  while I do agree that an inexperienced sysadmin should learn from the beginning to work from a personal account (maybe with sudo access) rather than as root, if you have the experience to work with that account properly, there's no harm in doing so.  Just make sure you know what you're doing before hand.  In the case of my other sysadmins, I've added CentrifyDC for Active Directory support to all of these systems and configured the systems so that the AD-UserIDs can be used for desktop sessions while maintaining the user's AD Security Group rights.  But personally, since I engineered all of these servers and have used Linux for over 15 years now, I think nothing of using root to speed things along.  In fact, I tend to enable root on systems where it's been disabled just so that I can use that account and cut to the chase with getting things done.  The main thing there, really, is just to make a habit of creating a backup copy of any file before you alter it.  That will safe guard against most mishaps and allow you to recover the system should you perform an edit that would otherwise cause the system to become inaccessible (just boot to a live CD and fix up what needs to be fixed up).  \nIMHO, I believe that the mantra of 'never login as root' is really just there to protect the n00bie sysadmins from themselves.  But if you reach a level of competence with Linux to the point where you can engineer a system from any Linux OS in a very short amount of time and it work every time, then there's no reason to live by the 'never login as root' mantra because by that point you're ready to handle the responsibility that comes along with using that account.  This is especially true in environments that use CentrifyDC for AD support, because 'root' becomes the local sysadmin account and is (usually) enabled automatically.  So, I find it best to cut to the chase and make the setting of the root account's password as one of the very first tasks I do on any deployment nowadays.  Sure, I could do the whole 'login as my own ID, then sudo up', but I personally don't feel the need to do things that way.  Your own mileage may vary...\n\nA: Hacky but you can modify the user's id so they don't show in the list:\nsudo usermod -u 999 <username>\n\nThis works because users with id under 1000 are considered to be \"system\" users (i.e. not humans).\nThe only other way I know is to hide the list completely:\nsudo -u gdm gconftool-2 --type bool --set /apps/gdm/simple-greeter/disable_user_list 'true'\n\n\nA: Elaborating on Gilles's comment to the accepted answer, here's what I believe is the current \"best practices\" (Gnome-safe) way to do this.   This change will also be reflected in the Gnome \"Indicator Applet Session\".\nThis method is that one suggested in the docs at the GDM website, and though both the site and Gilles show the addition of \"nobody\" to the exclude, I wanted to make sure that it was clear this is actually necessary (despite what the manpages or online docs explicitly offer).  I've tested this on a couple of 10.10 systems to verify repeatability.    \nAll we need to do is to make on one-line edit to /etc/gdm/custom.conf.  Most other methods (making changes to default.conf, gdm.conf, etc.) are deprecated.\nIf you have an existing /etc/gdm/custom.conf, edit that file. \nOtherwise, copy over the example file :  \nsudo cp /usr/share/doc/gdm/examples/custom.conf /etc/gdm/custom.conf\n\nIn the [Greeter] section of /etc/gdm/custom.conf , add:  \nExclude=user1,user2,nobody\n\nWhere \"user1\" and \"user2\" are the usernames or passwd file entries (e.g., qmail, squid, etc.) that you do not wish to show on the GDM \"face browser\". \nNote : Under my version of Gnome/GDM (2.30), if you do not have \"nobody\" listed in the Exclude entry, then you will have a bogus login user nobody show up instead of user1 or user2.  \nN.B.#2 : The non-display of accounts with UID's below 1000 is a configurable parameter.  By default, the MinimalUID value is set to 1000.  If and only if the default setting IncludeAll=true is left in place and the Include directive is not changed to a non-empty value, does the GDM greeter scan the passwd file for entries with UID's greater than MinimalUID.  Users with UID's above MinimalUID that are not in the Exclude list are then displayed.\nI haven't tested whether the reverse setting, namely, that setting an Include=user1,user2 entry in custom.conf will work as presented.   It should override any IncludeAll setting, and display only the users explicitly listed. \n\nA: Change the user login shell to an empty string in /etc/passwd\nFor Example, change:\n# Change\nexample:x:2001:2001:Example User,,,:/home/example:/bin/bash\n\n# To\nexample:x:2001:2001:Example User,,,:/home/example:\n\nI restarted my display manager and observed this taking effect.\nsudo service lightdm restart\n# (or gdm, mdm, ...)\n\n\nIt took me weeks to identify this as the reason why users were hidden in the display manager login greeter. It is apparent that /var/lib/AccountService/users is being ignored by MDM, and assumedly GDM as well. I didn't go as far as to add an Exclude=user1,user2 or an Include=user3 under [greeter] in /etc/mdm/mdm.conf, or create an /etc/mdm/custom.conf, as a another box was hiding users added via useradd just fine, while users added with adduser were shown. Setting the login shell to /bin/false denies all login to that user, which I still wish to su as. But that also hides the user in the login screen if you want that user to be plain inaccessible.\n\nA: This worked for me on Zorin 16 - gdm3\nUncomment the line which says disable-user-list=true in /etc/gdm3/greeter.dconf-defaults\nnano /etc/gdm3/greeter.dconf-defaults\n\n# - Disable user list\ndisable-user-list=true\n\nThen\n/etc/gdm3/greeter.dconf-defaults\n\n", "Q: How can I troubleshoot keryx 'UnicodeEncodeError' error? As I'd seen it recommended in How can I install software or packages without Internet (offline)? tried to install Keryx but I am not able to open it. When I run it in a terminal it prints these warnings:\n(keryx:4127): Gtk-WARNING **: GModule (/usr/lib/gtk-2.0/2.10.0/i486-pc-linux-gnu/engines/libmurrine.so) initialization check failed: Gtk+ version too old (micro mismatch)\n\nFontconfig warning: \"/etc/fonts/conf.d/11-lcd-filter-lcddefault.conf\", line 9: invalid constant used : lcddefault\nFontconfig warning: \"/etc/fonts/conf.d/53-monospace-lcd-filter.conf\", line 17: invalid constant used : lcdlegacy\nTraceback (most recent call last):\n  File \"<string>\", line 132, in <module>\n  File \"keryx/build/pyi.linux2/keryx/outPYZ1.pyz/lib.wxkeryx\", line 49, in Start\n  File \"keryx/build/pyi.linux2/keryx/outPYZ1.pyz/wx._core\", line 7912, in __init__\n  File \"keryx/build/pyi.linux2/keryx/outPYZ1.pyz/wx._core\", line 7487, in _BootstrapApp\n  File \"keryx/build/pyi.linux2/keryx/outPYZ1.pyz/lib.wxkeryx\", line 27, in OnInit\n  File \"keryx/build/pyi.linux2/keryx/outPYZ1.pyz/lib.log\", line 46, in info\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-8: ordinal not in range(128)\n\nHow can I solve this problem?\n\nA: Not knowing Keryx, from looking at the source it seems that the error occurs here, in an innocuous print statement.\nAFAIK the _() function is used in localization to retrieve the translation of a given string based on you current locale. So the problem is most likely related to your non-English language environment. Try running\nLANG=C ./keryx\n\nfrom the terminal window. This runs the program in English. If this is indeed the problem, send a bug report to the developer.\n\nA: The GTK library that you have is too old for the keryx software that you to installed. Check on the keryx website what the requirements for libraries are and see if you can find a .deb in either the Ubuntu archives or a PPA that meets this requirement.\n\nA: It is trying to interpret non-ASCII data as ASCII. This happens in the log function, so I'm guessing it is trying to log user-supplied data. The LANG=C trick is definitely worthwhile to try. What are you doing to make it crash? How do you start the application?\n", "Q: What does examples.desktop do? What's the point of the examples.desktop file?\n\nA: It is a location launcher. A desktop shortcut to a location.\nThe contents looks something like this:\n[Desktop Entry]\nVersion=1.0\nType=Link\nName=Examples\nName[es]=Ejemplos\nName[fi]=Esimerkkejä\nName[fr]=Exemples\nComment=Example content for Ubuntu\nComment[es]=Contenido del ejemplo para Ubuntu\nComment[fi]=Esimerkkisisältöjä Ubuntulle\nComment[fr]=Contenu d'exemple pour Ubuntu\nURL=file:///usr/share/example-content/\nX-Ubuntu-Gettext-Domain=example-content\n\nIt just opens nautilus at /usr/share/example-content/\nThe example content directory is a show case of open source and free culture.\nYou can read more about example content here.\nYou can learn more about .desktop files here.\n\nA: It is a shortcut to a folder called examples.It contains Ubuntu Free Culture Showcase and Case Studies.\n\nA: It shows up as a shortcut to a folder in the Files manager (circled in red).\nI find it annoying as well. It's just an example, you can delete it. You can also delete it from /etc/skel to prevent it from appearing for newly created users too:\nsudo rm /etc/skel/examples.desktop\n\n\n", "Q: apt-get or aptitude equivalent to yum whatprovides Is there an equivalent to the yum \"whatprovides\" option in apt-get? \nFor example on CentOS\nyum whatprovides /usr/share/gdm/themes/TreeFlower/background.png\n\nTells me \nredhat-logos-4.9.99-11.el5.centos.noarch : CentOS-related icons and pictures.\nRepo        : base\nMatched from:\nFilename    : /usr/share/gdm/themes/TreeFlower/background.png\n\nCan I get similar functionality on the command line in Ubuntu?\n\nA: This depends on whether the package containing the file is already installed. If so, use dpkg -S filename.\nIf your intention is to find out which package to install to get a certain file, one option is to use the online packages.ubuntu.com: scroll down to \"Search the contents of packages\". Make sure that the right distribution is selected. If you're looking for a files irrespective of the path, check the appropriate option.\nThere is also apt-file. Because this method required updating the files database, however, I prefer the other, instant option.\n\nA: You want the 'apt-file' command.\napt-file search /usr/share/gdm/themes/TreeFlower/background.png\n\nBefore using it, you may need to create or update its database by running:\napt-file update\n\n\nA: wajig whichpkg /usr/share/gdm/themes/TreeFlower/background.png\nYou'll have to install wajig, which is a frontend to a bunch of utilities related to apt. If you use wajig, you can use all of those tools without having to memorize their names.\n\nA: Isn't this the same question as this How do I find the package that provides a file?\nI prefer the dpkg -S <filepath> command\n", "Q: How can I get Firefox to use Dolphin instead of Nautilus? I am using dolphin as my file manager and when I download something via firefox, I right click the download dialog and choose \"open folder\", I always get nautilus. \nWhy doesn't firefox open the folder with dolphin?\nThanks\nNote: I tried adding the tag \"dolphin\" but because of my low rep I can't create new tags :(\n\nA: sudo apt-get install kmozillahelper\n\nis not more available. \nHow to use dolphin to open folder in firefox\nWhen I installed KDE and Firefox this feature actually worked – I downloaded a file, clicked on “open containing folder”, and Dolphin would happily pop with the respective folder open.\nHowever, when I installed a few more apps,  Firefox started calling Gwent or other app to “open the folder”.\nSolution:\nIn the file /usr/share/applications/mimeinfo.cache, find inode/directory and make kde4-dolphin.desktop on first such as:\ninode/directory=kde4-dolphin.desktop;kde4-gwenview.desktop;kde4-kfmclient_dir.desktop;\n\n\nA: As user162413 stated, kmozillahelper is no longer avaliable. His solution however did not work for me.\nInstead, one from dragly did the trick:\nOpen up /usr/share/applications/defaults.list and change line \ninode/directory=nautilus.desktop\n\nto\ninode/directory=kde4/dolphin.desktop\n\nWorks without need to restart Firefox.\n\nA: To get Dolphin in the file-picker dialog, install the package \"kmozillahelper\" from the standard repositories. \nsudo apt-get install kmozillahelper\n\nSet the filepicker-variable in in Firefox by visiting the URL about:config.\nMore information here\n\nA: After installing Firefox in Kubuntu there was not default file manager associated with the browser. \n\n\n*\n\n*Pressing the grey/green \"Display the progress of ongoing downloads\" arrow, just next to the search engine box in the head (right hand/top) of the browser (my Firefox version is 25.0.1), \"Show All Downloads\" menu was displayed. \n\n*When I pressed it \"Library\" window opened and I pressed on \"Open Containing Folder\" button. \n\n*Then \"Launch Application\" dialogue pops up with \"Choose an Application\" suggestion. \n\n*Pressing \"Choose...\" I selected /usr/bin/ as folder and chose dolphin as the program.  Dolphin can be selected as default application using the check box.\nBy the way - trying to install kmozillahelper in Kubuntu I got \"E: Unable to locate package kmozillahelper\". That's right - it's not available any more.\n\nA: For those still having this issue, I found a slightly easier way:\n\n\n*\n\n*Open the Default Applications control module (KDE menu -> search for Default)\n\n*Select the File Manager list\n\n*Ensure that Dolphin is selected\n\n\n*\n\n*if it is already selected, reselect by clicking on another option then back to Dolphin\n\n\n*click Apply\n\n*test\n\n\nThis worked for me.  YMMV, but this would be a much better solution rather than editing the MIME configuration manually.\n\nA: A workaround that worked for me was to set MOZ_USE_XINPUT2=1 when launching Firefox.\n\nA: I had a similar problem. Installing KDE for Ubuntu and Firefox not using Dolphin. The only thing that worked for me was uninstalling Nautilus and everything GNOME related completely.\n", "Q: How to seamlessly connect two LAN's? I'm going to connecting two LAN's in some way, I imagine some form of VPN tunnel between the gateway/router on each side. Both routers have Ubuntu-server 10.04 installed, but the only vpn-like experience I have is setting on-demand TCP-port forwarding with ssh, but I want this to work for windows clients as well.\nThe two networks are only connected through an Internet connection, and I don't want my private traffic exposed (traffic like samba).\nSo how can I do this?\n\nA: While we have VPNs at work we usually use cisco tech to build them (although we use linux machines to do some advanced routing before it hits the real routers). So I have no experience using OpenVPN, but a quick google search gives some quite straight forward tutorials. I liked this one.\n\nA: A VPN is a virtual private network. By definition that makes you traffic protected. It works by encrypting the packets when they are sent over the public network between the gateways. \nTherefore, you don't need to be concerned about your traffic. It is protected when going through the tunnel.\nIf you want to prevent certain traffic to even cross over the tunnel, you can do this by setting up a firewall (or setting the iptables in the appropriate way) such that this particular traffic will not be routed through the vpn interface.\nYou can set this up by using openvpn as provided in the Ubuntu repositories.\nI am still not sure if this is what you are looking for, but this is the best I can answer this question as it is at this time.\n", "Q: Where can I get themes and eye-candy for my desktop? Apart from those themes in the repository and Gnome-look.org, are there other places to get themes for my Ubuntu Desktop?\nAlso, are there any 3rd party repositories of themes and other eye-candy?\n\nA: Here you'll find some Ubuntu related art:\nhttp://browse.deviantart.com/?q=gallery%3Aubuntu-artists%2F24290476\nAnd here, Ubuntu awareness material (and release countdown buttons) :\nhttp://spreadubuntu.neomenlo.org/\nRegards!\n\nA: Here are some themes PPAs:\n\n\n*\n\n*https://launchpad.net/~tiheum/+archive/equinox  \n\n*https://launchpad.net/~elementaryart/+archive/ppa\n\n*https://launchpad.net/~elegant-gnome/+archive/ppa\nAll of those are amazing themes. The first PPA comes with the updated Ubuntu Light Themes backported from Ubuntu 10.10 to Ubuntu 10.04.\n\nA: This weblog does alot of customization tutorials and various other ubuntu thematics related topics. \nPlus its in England\n\nA: GNOME-LOOK.ORG\nI have been using this for so many years, their collection is just unmatched in terms of volume and quality. \n\nA: Reddit pics (http://www.reddit.com/r/pics/) is sometimes a good source for artistic, odd, funny, or bueautiful images that make good desktop backgrounds. Here are a few I've found (I especially like landscapes):\nhttp://i.stack.imgur.com/SPY3v.jpg\nhttp://i.stack.imgur.com/UBl94l.jpg\nhttp://science.nationalgeographic.com/wallpaper/science/photos/canyons-gallery/canyon-de-chelly/\n\nA: Web Upd8 is where I got a lot of nice themes and tips for customization. Plus they maintain a PPA with modding/utility apps.They also have a PPA ppa:webupd8team/themes (How to add PPAs) specifically for themes.\n\nA: And the \"Granddaddy\" of them all is gnomelook.org---not a PPA, but when you can just take a .tar & drop it on Appearance--why a PPA?\n\nA: You might want to look at this eye-candy project from France, it's amazing:\nhttp://www.bisigi-project.org/?page_id=8&lang=en\nIt works great, I didn't have any problems with the themes and they are complete, meaning that you have their icons not only on your desktop but also in nautilus file browser.\nI apologize in case an answer from above has already mentioned it.\n", "Q: Is there a WINE version of Flash as a plugin to Firefox or Chrome? I've seen complaints about flash performance. Would it be possible to use WINE as a plugin to firefox in order to get better performance out of flash? (Hopefully WINE would utilize some sort of hardware optimizations) Would using WINE even give better performance?\n\nA: No. \nAt best you could get this to work by running the whole browser in wine but that would be sure to decrease performance not increase performance.\nThe best way to overcome poor flash performance is to download videos instead of streaming them using tools such as abby (also: clive, cclive, youtube-dl). All of these are available from the Ubuntu Software Centre.\n\nA: The best performance change I've made for Flash is to install a flash blocking extension (e.g. Chrome, Opera (builtin at opera:config#UserPrefs|EnableOnDemandPlugin), Firefox).\nWhen I have 150 or more tabs open (not so uncommon for me) – or even just 20 :) – this really helps, yet I can still click to run any Flash applet I must use.\n\nA: It won't help. The main problem with flash is that it can't use xv output and Wine won't help you with that. Pulseaudio also seems to help with bad flash performance, so you could try a different sound server. I wasn't successful with that on Lucid tho.\nFor YouTube, Vimeo and Blip.tv you could use my FlashVideoReplacer extension, which replaces the embedded video with available mp4 in order to play it with other plugins. CPU usage is reduced a lot.\nhttps://addons.mozilla.org/en-US/firefox/addon/161869/\nAlso see my tutorial on flash optimization for other alternatives:\nhttp://firefox-tutorials.blogspot.com/2010/05/flash-optimization.html\n\nA: Pipelight! It's running flash, shockwave, silverlight and unity player through wine http://fds-team.de/cms/pipelight-installation.html\n\nA: Go for  \"lovinglinux\" tutorial , i tried FlashVideoReplacer extension and it worked like a charm . thank you \"lovinglinux\" =)\n\nA: Lets just cross our fingers that html5 will be the standard soon! For now use Chrome, Opera or Firefox4 beta and activate html5 on youtube. Works pretty well...\n", "Q: convert flv for playback on ipad I like to watch flv videos during downtimes using my ipad.  Whats a good tool for converting video files and then tossing them onto the ipad.  Primarily I've grabbed a few flv tutorials off you tube.   I know ffmpeg can do the transform, but it's got one of those \"needs a phd in video\" to sort out...\n\nA: Try:\n\n*\n\n*Arista Transcoder (Seems to be specially for devices like ipods/phones etc.)\n\n*WinFF (GUI for FFMPEG)\n\n*OggConvert (Converts to free formats)\n\nThese can all be found in the Ubuntu Software Centre.\nEDIT: Arista is probably the best of these as it has a preset for the ipad.\n\nA: I find that MediaCoder works quite well for video transcoding. It has presets for iPod/iPad and runs just fine under Wine.\n\nA: Hands down best video encoder. Handbrake. \nHandbrake is not available from the repositories. You can install it from a ppa though:\n< \n\nA: Once you have the codecs installed, you just need to learn one ffmpeg command to re-encode your videos:\nffmpeg -i in.flv -vcodec libx264 -acodec libfaac -sameq out.mp4\n\nFor help with codecs, I recommend this useful page at Ubuntu help.\n", "Q: How to log-in via TTY by instead of GDM? I want my Ubuntu box to boot directly into a tty login screen and after it does that I want it to automatically run startx how would I go about doing this?\n\nA: What txwikinger said, but then to make it automatically run startx when you login, edit ~/.bash_profile  -- that file is only executed on login shells, not in normal terminal emulators that you open on your desktop.\nEDIT:\n~/.profile if you don't use bash\n\nA: You can disable the automatic start of the X-server by disabling the start on lines in gdm.conf and/or kdm.conf. This way upstart will not automatically start the X-server.\nAfter logging in into the tty, you can just start the appropriate login session via sudo start gdm or sudo start kdm. Or if you rather want the traditional x, you could run startx, if it is configured such that you can do the things you want to do from that. \n\nA: Turns out from the grub boot menu you can press e over any entry to edit its configuration.  If you do this over the ubuntu entry there is a line that starts with the word linux and ends with something like ttyhandoff=7.  Changing this to ttyhandoff=1 does what you would expect.\nApparently you could also append text to the end of this line.\n", "Q: Google Talk Video Chat There are no video chat plugins supplied by Google for Ubuntu. They are availabe just for PC and Mac. Are there any alternatives?\nUPDATE:\nGoogle has launched official video chat plugin for Linux \nhttp://www.google.com/chat/video\nhttp://gmailblog.blogspot.com/2010/08/use-linux-now-you-can-video-chat-too.html\n\nA: Another popular IM application, pidgin, supports Google Talk voice/video. \nIt is available from the Ubuntu Software Centre.\n\nA: The default IM application in Ubuntu, Empathy, supports Google Talk voice and video out of the box.\nIn order to use it, right click on the contact and select either \"Audio Call\" or \"Video Call\". \nUsers that have audio capability will have a microphone next to their name in the contact list, and a little webcam if they have video support.\nGoogle also now supports Linux officially in their client, which you can download from here.\n\nA: Google video can now be used in Linux. gmailblog\nYou can download it here.\n\nA: I use pidgin for voice chat. You have to enable voice/video plugin of pidgin. The official google voice chat is now available for linux as well\n\nA: A painless way to install it\nIn a terminal\nwget http://dl.google.com/linux/direct/google-talkplugin_current_i386.deb && sudo dpkg -i google-talkplugin_current_i386.deb\n\n\nA: My suggestion would be to use gtalk made for chrome os. It can be used in any linux supporting google chrome using this tutorial.\nhttp://tutafuta.com/2011/05/25/how-to-use-gtalk-on-linux-or-mac/\nyou can use this handy trick to do all you can do with google talk, audio/video chatting \n", "Q: Aliases: difference between .bash_rc, .bash_aliases and /usr/local/bin Playing around with Terminal, I noticed that there are many ways to create permanent aliases.\nI'm a Linux newbie, and from what I know, doing:\n\n\n*\n\n*sudo ln -s /path/to/executable /usr/local/bin/desired_alias\n\n*adding desired_alias = '/path/to/executable' to ~/.bashrc\n\n*uncommenting those lines in ~/.bashrc:\nif [ -f ~/.bash_aliases ]; then\n    . ~/.bash_aliases\nfi\n\nand putting desired_alias = '/path/to/executable' into the ~/.bash_aliases \nall have the same effect.\nWhat is the difference between the first and second methods?\n\nA: With the first method you are not creating an alias, you are creating a symlink. Symlinks are short for symbolic links:\n\nSymbolic  links  are files that act as\n  pointers to other files. [...] A \n  symbolic link is a special type of\n  file whose contents are a string that\n  is the pathname another file, the file\n  to which the link refers.  In other\n  words, a symbolic link is a pointer to\n  another name, and not to an underlying\n  object.\n\nRead more about symlinks here and here.\nOnly with the second method you are, in fact, creating an alias.\n\nAliases  allow  a  string  to be\n  substituted for a word when it is used\n  as the first word of a simple command.\n  The shell maintains a list of aliases\n  that may be set and unset with the\n  alias and unalias builtin commands\n  (see SHELL BUILTIN COMMANDS  below).\n  The  first  word of each simple\n  command, if unquoted, is checked to\n  see if it has an alias. If so, that\n  word is replaced by the text of the\n  alias.\n\nYou can define an alias anywhere where you can type a command and have the shell (bash in this case) interpret it, however in order for the alias to be available in other shells it needs to be defined in a file that's interpreted by the shell on startup (shell startup, not computer startup). \nFor bash these are /etc/bash.bashrc (system wide) and ~/.bashrc. These files are interpreted when the shell starts in interactive mode (like when using Terminal). I'm not going to mention the profile files because they serve a different purpose.\nSo, you want to add your aliases to ~/.bashrc to have them available in every interactive shell.\nThe .bash_aliases method accomplishes exactly the same thing as putting the aliases in ~/.bashrc but has the added benefit of being easier to be parsed and manipulated by programs.\nThe . ~/.bash_aliases means source (load) _~/.bash_aliases_ in the context of the currently running shell.\n", "Q: My Toshiba's fans do not work automatically My Toshiba Satellite m505-s4940's fans do not turn on automatically, so it was overheating before I learned how to do it manually by using this keyboard-shortcut:fn+F3 \nI have to do this every time I use my computer!\nI really like the performance of Ubuntu, and I just began to use and love it, but I would like to solve this problem.\nHopefully someone can help me, and sorry about my English. It is not my native language : )\n\nA: This has been reported here and here and here (kernel).\nThere appears to be one workaround: \n\n\n*\n\n*Boot up\n\n*Suspend\n\n*Wake it up\n\n*ACPI should work (fans should work, the lid should sleep it, etc)\n\n\nIf this doesn't work, I recommend you don't run Ubuntu until it's fixed as letting it overheat is very dangerous to the hardware.\nOf course if you can help the kernel devs find a fix for this, the faster you get the fix.\n\nA: You can use the toshiba utils Certain Toshiba's laptops to control fan speed.\nhttp://www.buzzard.me.uk/toshiba/index.html\n\nA: got the same problem, this fix solved it completelty\nhttp://tuxtweaks.com/2008/08/how-to-control-fan-speeds-in-ubuntu/\n", "Q: How to automate starting terminal instances for specific tasks I'm going through some programming tutorials and for every session, I have to start up at least 3 terminal windows (one for a log file tail, one for testing output, one for running various shell commands in, etc.)\nRight now I start them all up manually: click the Terminal icon, cd to the right folder, type in the commands, and change the window title to something meaningful.\nIs there a way to write up a script or something that would automate that for me? And if so, how?\n(I'm cool with not getting a complete script as an answer. A pointer where to start reading would work too.)\n\nA: Since you're clicking the Terminal icon, I assume you're using gnome-terminal.\nI got a list of options by using gnome-terminal --help at the command line and reading from there.\nBuilding on maco's answer, I might suggest something like this:\ngnome-terminal --window --title=Log -e \"tail -f /var/log/syslog\" --window --title=Output --working-directory=output --window --active --title=Dev --working-directory=dev/project\n\nThis example starts three windows (though you could pass --tab for tabs) and sets the working directories (relative to home) and titles for each, starts the tail command in one and makes the third window active.\nOf course you may prefer to use separate lines to launch each window, particularly if you have many arguments.\nAnother useful thing to do, once you have your windows arranged to your liking, is to use \ngnome-terminal --save-config=FILE\n\nThis creates a configuration file with information on all open terminal windows and tabs (including the titles, working directories, and so forth). Launching gnome-terminal with the --load-config option will then recreate your layout.\nA lot of developers who work with multiple terminals like to use Terminator as it adds features such as a grid layout and keyboard shortcuts.\n\nA: Whatever terminal emulator you're using should be able to accept a command as an argument.  For example:\ngnome-terminal -e \"tail -f /var/log/syslog\"\n\nJust add such commands to your autostart in System -> Preferences -> Sessions (Ubuntu) or System Settings -> Autostart (Kubuntu)\n\nA: You could also automate that using a script. I recommend reading the Advanced Bash Scripting Guide or the Bash Programming HOWTO, along with the man page for whichever terminal you're using.\nHere's a simple example:\n$ vi your-script\n#!/bin/bash\ngnome-terminal -e \"tail -f /var/log/syslog\"\ngnome-terminal --working-directory=/foo/bar\ngnome-terminal --whatever-else\n\nThen just make it executable:\n$ chmod +x your-script\n\n", "Q: Access Windows 7 Media Streaming I wish to be able to see and stream music to my Ubuntu 10.04 installation through Rhythmbox. I have enabled media streaming in Windows 7 and I can see Rhythmbox as an allowed device.\nI have installed the Coherence plugin for Rhythmbox. I can see my Windows 7 PC under the Shared folder in Rhythmbox, but I do not see any of my music.\nIs there a step along the way that I missed or something else that I have to enable?\n\nA: I've installed the coherence plugin as well, and at first I had the exact same behaviour as yours. After a little while, my library had shown up (I use a NAS with Twonky installed). \nThe one thing that comes to my mind, after enabling media sharing in Windows 7, is that you also have to disable \"password protect sharing\" in the \"sharing\" configuration pane for DLNA devices to be able to access Windows Media Player library. \n\nA: I suggest that you install the Firefly Mediaserver. ( http://www.fireflymediaserver.org/ ) It's a streaming server that is open-source and can stream towards Rhythmbox. \nI'm not really familiar with the software, so I suggest that you also take a look the following answer: Music player that can access/catalog music on network drive.\nI hope I could help,\nMartijn.\n", "Q: Where is the Flash in Chrome? I installed Google Chrome. This is the first thing I did after installing Ubuntu. I went into firefox, and went to chrome.google.com, and hit the button. I don't like package managers, and avoid the command line like the pox.\nThen, I started using Google Chrome. I went to Kongregate, and clicked on a game. It told me I didn't have flash. A few different websites told me the same. I assumed that they must have been wrong. I hit the link to Adobe, to install Flash, and it reassured me; of course, Google Chrome includes Flash. I checked my version - Chrome 5.0.375.126. Of course, I just downloaded it.\nI scoured the internet for solutions. None worked. Many seemed to involve re-enabling Flash, or something like that. But insofar as I can tell, there is no Flash anywhere in my Chrome. I feel like I bought a Reese's cup, and found solid chocolate. I checked in the Chrome plugin manager, and everything. A few solutions told me to copy some garbage into my command line and hit enter (as almost all solutions to problems on linux entail). I did it, reluctantly, and it did nothing.\nI thought Flash was supposed to come with Chrome. But it didn't. Sooooo... What gives?\nGoogle Chrome version:\nGoogle Chrome 5.0.375.126 (Official Build 53802)\nWebKit 533.4\nV8 2.1.10.15\nUser Agent Mozilla/5.0 (X11; U; Linux x86_64; en-US) AppleWebKit/533.4 (KHTML, like Gecko) Chrome/5.0.375.126 Safari/533.4\nCommand Line  /opt/google/chrome/google-chrome\nOperating System: Ubuntu 10.4 64 bit.\n\nA: *\n\n*Download\nWhat I usually do is download the Flash player from Adobe's site (since I use a 64-bit system, I download the 64-bit plugin).\n\n*Extract package\nThen, in a terminal, run gksudo nautilus.\nExtract the package by right-clicking on the downloaded package and selecting \"Extract Here\".\nEnter the folder and you will find a file named libflashplayer.so.\n\n*Copy the file libflashplayer.so into either:\n\n\n*\n\n*/usr/lib/firefox-addons/plugins (for Firefox)\n\n*/usr/lib/chromium-browser/plugins (for Chromium)\n\n\n\nThat is it!\n\nA: Chrome now includes Flash built in by default, there is no need to do anything else. \n\nA: I noticed that chrome does get some plugins out of the firefox plugin directories. If a working Flash plugin is installed in firefox it is likely to work in Chrome. The flashplugin-installer package basically installs Flash for firefox.\n\nA: sudo apt-get install ubuntu-restricted-extras - solve this problem\n\nA: I've just found a solution for those who has flash working on firefox but not on chromium. It's based on the fact that every browser has it's own plugins directory:\n\n\n*\n\n*/usr/lib/firefox-addons/plugins (for Firefox)\n\n*/usr/lib/chromium-browser/plugins (for Chromium)\n\n\nSo, the only thing you've to do is to unificate them, aka, making one the link to the other. Probably, all plugins are on Firefox plugins directory, but it isn't worth to ensure that:\nls -l /usr/lib/{mozilla,chromium-browser}/plugins\n\nIf Firefox is the one where all plugins are, do the next. If not, do the opposite:\nsudo rmdir /usr/lib/chromium-browser/plugins\nsudo ln -s /usr/lib/mozilla/plugins /usr/lib/chromium-browser/\n\nFinally, restart Chromium so changes take effect.\nProbably, it wouldn't be a bad idea to create a bug report on chromium/firefox package mantainers to alert about the bug and the simple solution.\nSee you!!\n\nA: The location of the plugin for Google Chrome is: /opt/google/chrome/libgcflashplayer.so\n\nA: If you are using Chrome 19.\n\n\n*\n\n*Go to about:plugins\n\n*Click Details button in top right.\n\n*Flash plugin consists of two libs. Disable /opt/google/chrome/PepperFlash/libpepflashplayer.so\nFlash is back.\n", "Q: Is it possible to view PDFs right in Chrome without downloading them first? When I click a link to a PDF in Chrome instead of displaying the PDF in the browser I see a blank page with \"Missing plugin\" written over it. Is it possible to get this plugin somewhere or am I condemned to downloading the PDF first and then displaying it using standard PDF viewing software?\n\nA: Google have recently released this feature for Chrome, however there are currently several bugs associated with it, especially on Linux. This feature will come, but may take time (anything from days to months, though Chrome is usually quite good at fixing such problems).\nAlternatively you could use the official Docs PDF/PowerPoint Viewer to automatically view PDF files in Google Documents.\n\n\nA: You might be seeing this bug, which should be fixed in a newer release of Chrome. I use the Docs PDF/PowerPoint Viewer which sends the PDF directly to google docs to view.\n", "Q: Is Live Video Chat with MSN/Windows possible? Is this currently possible in either Lucid or Maverick?\n\nA: telepathy-butterfly  which is a backend to the default Ubuntu IM client Empathy has just received support for the p2pv2 protocol, which will be the only voice/video protocol used by future version versions of the official Windows client. (see bug report and OMG! Ubuntu)\nWhilst these fixes are in the source code, it will take time for a new version of telepathy-butterfly to be released, packaged and put in Ubuntu. We are also dependant on the uptake of future versions of the official Windows client (we will be compatible with all future versions, currently in Beta testing). I imagine this will be working in a mainstream way by Ubuntu release 11.04\n\nA: you can use aMSN. Its a MSN messenger clone for linux.\n\nA: Not with a native client but you can through Meebo (uses Flash).\n\nA: Emesene might possibly work?\n\nA: emesene is a great msn chatting program and YES it has a video support till now but it makes the program crash most of the time :D .. i read lots of comments that complain about microsoft denying access to its chat servers for other apps than microsoft's messenger\n", "Q: Thinkpad middle button scrolling I'm running Ubuntu on my Thinkpad T60.  Is there a way to get the middle button to act like a scroll like it would when it runs Windows?\nI'd like to be able to hold the middle button down and scroll down a webpage using the red button.\n\nA: ThinkWiki has instructions on how to do this. Specifically, how to use xinput(1) to configure the TrackPoint. \n(All in all, ThinkWiki is a great resource. It's pretty much the go-to place for just about anything on running Linux on Thinkpads.)\n\nA: http://www.eastwoodzhao.com/thinkpad-middle-button-scroll-ubuntu-linux-10-04-lucid-lynx/\nIn short, run this: gksu gedit /usr/lib/X11/xorg.conf.d/20-thinkpad.conf and put this in the file:\nSection \"InputClass\"\nIdentifier \"Trackpoint Wheel Emulation\"\nMatchProduct \"TPPS/2 IBM TrackPoint|DualPoint Stick|Synaptics Inc. Composite TouchPad / TrackPoint\"\nMatchDevicePath \"/dev/input/event*\"\nOption \"EmulateWheel\" \"true\"\nOption \"EmulateWheelButton\" \"2\"\nOption \"Emulate3Buttons\" \"false\"\nOption \"XAxisMapping\" \"6 7\"\nOption \"YAxisMapping\" \"4 5\"\nEndSection\n\nSave and restart.\n\nA: Install package \"gpointing-device-settings\"\nSet options as follows:\ncheck \"Use middle button emulation\"\ncheck \"Use wheel emulation\"\nselect button \"2\"\ncheck \"Enable vertical scroll\"\n\n\n\nA: I use the following in my AwesomeWM autostart file:\n# make the mouse work right on my thinkpad in lucid\nxinput set-prop 'TPPS/2 IBM TrackPoint' \"Evdev Wheel Emulation\" 1\nxinput set-prop 'TPPS/2 IBM TrackPoint' \"Evdev Wheel Emulation Button\" 2\nxinput set-prop 'TPPS/2 IBM TrackPoint' \"Evdev Wheel Emulation Timeout\" 200\n\nIn the default Gnome install you could write a script that runs on boot or perhaps check out if the .xinitrc or .Xresources is used. (I can't recall which is used any more)\n\nA: Gpointing is a graphical application  for the gnome desktop to achieve the same result ;)\nWith Ubuntu install it in a terminal\nsudo apt-get install gpointing-device-settings\n\nor via software center \"gpointing-device-settings\"\n\nA: In Ubuntu 14.04, these settings are in /usr/share/X11/xorg.conf.d/11-evdev-trackpoint.conf. It looks like this:\n # trackpoint users want wheel emulation\n\nSection \"InputClass\"\n    Identifier  \"trackpoint catchall\"\n    MatchIsPointer  \"true\"\n    MatchProduct    \"TrackPoint|DualPoint Stick\"\n    MatchDevicePath \"/dev/input/event*\"\n    Option  \"Emulate3Buttons\"   \"true\"\n    Option  \"EmulateWheel\"  \"true\"\n    Option  \"EmulateWheelButton\"    \"2\"\n    Option  \"XAxisMapping\"  \"6 7\"\n    Option  \"YAxisMapping\"  \"4 5\"\nEndSection\n\nTo get \"natural scrolling\", that is, scrolling in the direction of the pointer, you can swap the YAxisMapping values to be \"5 4\" instead. I restarted after I swapped mine and it worked fine.\n", "Q: How do I restore a linux boot partition? First of all, I'm a linux noob (I've been using linux for a about four-five years, but only fixed problems as I got them though usually I just reinstalled everything).\nI have recently installed kubuntu 9.04, then upgraded to the latest Kubuntu (10.4). Everything went smooth and I have used it OK for about two weeks.\nAfter the latest security/bugfixes update, the bootloader got corrupted.\nMy questions:\nCan I restore it from the 9.04 boot CD/DVD, or do I need a special rescue system?\nShould I get a new live DVD for 10.4 and fix it from there?\nAlso, what do I need to actually fix? What utilities do I need? (What should my steps be?)\nThanks :)\n\nA: (K)ubuntu 10.04 uses Grub2 and the good news is that you can restore the boot loader configuration and the MBR by booting up from the live CD. See instructions here - even though the title sounds like it is related to only recovering from windows installation, the steps there allow you to re-install the respective bootloader back on your system. \nOn a side-note, I think since you have upgraded from Kubuntu 9.04 your system will probably still use legacy grub boot-loader. Please check here for how to upgrade to grub2. This is strictly optional - there is a note there about why the normal upgrade process didn't change the boot-loader when you moved from 9.04 to 10.04.\nPlease comment if you need more info.\n\nA: More often than not, the process of restoring GRUB (in recent releases of Ubuntu, that means Grub2) is described in a convoluted way. In fact it's pretty straightforward.  In a nutshell, the boot process may be broken because of one (or both) of these reasons:\n\n\n*\n\n*Grub isn't installed to the boot sector of your drive (\"Master Boot Record\" or MBR) or has been corrupted (this may be caused by a number of things, including eminently installing Windows).\nN.B.: Grub can be installed to the MBR of your boot disk or to the \"volume boot record\" of a partition.  In most cases, you'll want it to be installed in the MBR.\n\n*Your grub configuration (grub.cfg) is wrong or has been corrupted. On Ubuntu this file is generated for you (see below), so you don't need to touch it yourself, but you can manually re-create it by using update-grub.\n\n\nI recommend following these instructions in the section \"Recover Grub2 via Live CD\". The procedure described there takes care of both sources of problems. These are the tasks you'll perform:\n\n\n*\n\n*Start from a working Linux system, preferably a recent Ubuntu installation disc which is at the same time a Live CD. You do not need to use the Live CD of the variant or version of Ubuntu you're using. An older version is fine. The Live CD is only used to get access to your hard drive.\n\n*Find out the name of the partition that holds your boot directory, e.g. `/dev/sda1. In almost all cases, that's just the Linux partition where you've installed Ubuntu.\n\n*Mount that partition to /mnt and chroot into the mount point. Note that this means that you get a shell that looks and behaves as if you had booted the system normally. You can do many things you can do on your regular system, like installing packages and editing configuration.\nYou might be fine without chrooting, using the update-grub provided by the Live CD along with the switch --root-directory. But knowing how to chroot into a system partition is a useful skill, and the procedure is more robust.\n\n*Check /etc/default/grub to see if something's wrong there (normally this should be fine).\n\n*Regenerate grub.cfg by running update-grub.\n\n*Install grub to the hard disk by running grub-install. This is the crucial step.\n\n\nThen you can reboot and the system should start again. For the details, see the link. Finally, note that the step preceded by \"If you have /boot on a separate partition\" is not needed in normal circumstances, though the three commands doing the \"bind\"-mounts which follow are required. \n\nA: Depending on the exact error you're getting, you may also have to disable some windows tools (Dell DataSafe Local Backup, etc) that may be causing the corruption to keep it from happening again.  Here's a relevant bug report:\nhttps://bugs.launchpad.net/ubuntu/+source/grub2/+bug/482757\n", "Q: Can I use my computer as an A2DP receiver / bluetooth speaker? First, the problem: I'm using a Cowon MP3 player as my main music player with basic earplugs.\nIt offers A2DP & I'd like to have my netbook (running UNE 10.04) act as receiver. \nSome resources on the web about a2dp, but most are out of date:\n\n\n*\n\n*http://fosswire.com/post/2008/10/better-bluetooth-audio/\n\n*http://jprvita.wordpress.com/2009/12/15/1-2-3-4-a2dp-stream/\n\n*http://dpillay.wordpress.com/2010/09/27/ubuntu-10-04-a2dp-awesome-headset-music/\n\nA: It's really simple now in Ubuntu 12.04  \nConnect your bluetooth device  \nSearch for your bluetooth device and take note of it's source number:  \npactl list sources \n\nMake a loopback for the bluetooth device:\npactl load-module module-loopback source=$SOURCE_NUMBER  \n\nWhere $SOURCE_NUMBER is the number you previously took note of.  \nFor example, I entered the following to get audio playback to work:\n$ pactl load-module module-loopback source=3  \n\nThat's it! I found the solution in the top answer to be a bit complicated, so I simplified it this way (much less typing and copy/pasting). Though my solution will probably break if you remove any audio devices listed before the bluetooth device by pactl list sources. \nAlso, don't forget to remove the loopback module before disconnecting the bluetooth device:\nTake note of the module number of the loopback device you created:\npactl list short modules\n\nRemove the loopback device:\npactl unload-module $MODULE_NUMBER\n\nThe previous answers were written prior to 12.04's release, so I'm sure there were some changes. For example, I didn't have to manually enable using bluetooth devices as an audio source (it was enabled by default). However, I do sometimes have to toggle the \"Media Audio\" profile in my bluetooth settings on my phone (Samsung Captivate running CyanogenMod 9.1.0).\nThere's probably a way to leverage dbus-monitor by using a shell script to watch for bluetooth A2DP device connections and automatically load a loopback module for it, but that's a bit over my head.\nHopefully we won't need to do this manually any more in Ubuntu 12.10.\n\nA: To use your Ubuntu machine as an a2dp Bluetooth device, you must first configure it to register as an \"a2dp sink\" endpoint.\nThe bluez package in Ubuntu (10.04 and above) includes a utility called sdptool that can be used to check whether a Bluetooth device is configured as an a2dp sink or not.  Here is the output from sdptool run against my Bluetooth headset (the address is taking from the \"Bluetooth settings\" dialog in the gnome-control-center):\n$ sdptool search --bdaddr 00:18:16:3A:3B:D4 a2snk\nSearching for a2snk on 00:18:16:3A:3B:D4 ...\nService RecHandle: 0x10002\nService Class ID List:\n  \"Audio Sink\" (0x110b)\nProtocol Descriptor List:\n  \"L2CAP\" (0x0100)\n    PSM: 25\n  \"AVDTP\" (0x0019)\n    uint16: 0x102\nProfile Descriptor List:\n  \"Advanced Audio\" (0x110d)\n    Version: 0x0102\n\n$\n\nand here is the output when run against my local Ubuntu machine:\n$ sdptool search --bdaddr local a2snk\nSearching for a2snk on FF:FF:FF:00:00:00 ...\n$\n\nThis shows that the Ubuntu machine is not advertising itself as an a2dp sink.  It is advertising itself as an a2dp source however:\n$ sdptool search --bdaddr local a2src\nSearching for a2src on FF:FF:FF:00:00:00 ...\nService Name: Audio Source\nService RecHandle: 0x10003\nService Class ID List:\n  \"Audio Source\" (0x110a)\nProtocol Descriptor List:\n  \"L2CAP\" (0x0100)\n    PSM: 25\n  \"AVDTP\" (0x0019)\n    uint16: 0x102\nProfile Descriptor List:\n  \"Advanced Audio\" (0x110d)\n    Version: 0x0102\n\nThis enables the Ubuntu machine to pair correctly with the headset as an audio source, but it does not enable using the Ubuntu machine as an output (sink) for Bluetooth audio.\nIf you edit /etc/bluetooth/audio.conf, you can enable a2dp sink support by adding this line underneath the [General] section:\n  Enable=Source\n\nThis is both counterintuitively named--since what we're adding here is Bluetooth sink support, not source support--and in contradiction with the comment in this file that claims all implemented services are enabled by default. :(\nAfter making this change, you will need to restart bluetoothd by running sudo service bluetooth restart.\nIf you have previously paired your Android device and Ubuntu computer while trying to get this work, you will need to delete the pairing on both sides and re-pair them in order to get Android to recognize Ubuntu as an available audio device.\nOnce you've done this, the Android device should show up as an input device under PulseAudio. If PulseAudio does not detect the new Bluetooth audio source, you may need to install and load the Bluetooth module, from the command line:\n sudo apt-get install pulseaudio-module-bluetooth\n pactl load-module module-bluetooth-discover\n\nThen you need to tell PulseAudio to route this audio input to your output/sink (such as your speakers, or a Bluetooth headset) using a loopback connection (a straight line from a source to a sink).\nLater versions of PulseAudio may have module-bluetooth-policy included and it may already have set up a loopback device for you, but this does not seem to be the most common case.\nA semi-automatic way to set up the loopback connection - if you also have the pavucontrol GUI program installed - is to simply load the loopback module and configure it using pavucontrol, since PulseAudio will remember the settings. Loading the module is done from the command using pactl:\n pactl load-module module-loopback\n\nDon't fear if you don't hear anything yet, or if you get strange feedback effects, we need to tell the newly created device which source to get input from and which sink to send the output to first.\nOpen pavucontrol and open its Configuration tab. Make sure your Bluetooth device shows up here (after pairing with it using blueman-manager or another Bluetooth tool) and the profile is set to A2DP. Switch to the Input devices tab and make sure your device shows up here as well and is not muted. Now switch to the Recording tab and make the newly created loopback connection use your device as a source with the select box next to the mute button. Switch to the Playback tab to select the sink the loopback connection should use in the same way. If the loopback device does not show in the tabs, make sure all streams are displayed using the selectbox at the bottom of each tab.\nYou should now hear the audio from your device, if it's playing, in your speakers, or whichever output sink you selected. When your device is disconnected the loopback device will fallback to an available sink and source, which may not be desirable, so make sure you mute the loopback device until you need it. The loopback connection will restore the same sink/source the next time the same Bluetooth device is connected thanks to the module-*-restore modules.\nIf that doesn't work, or you don't have pavucontrol installed, you may instead set up the loopback using the following method:\n pactl load-module module-loopback source_dont_move=yes source=$BTSOURCE sink=$SINK\n\n(Replace $BTSOURCE with the source name for your Bluetooth device as seen by PulseAudio, e.g. bluez_source.14_DA_E9_2A_D7_57; and replace $SINK with the name of the PulseAudio output you want to send the audio stream to, e.g: alsa_output.pci-0000_00_1b.0.analog-stereo. You may leave out the sink argument entirely and have it fallback to an active sink, and change it later via pavucontrol.)\n\n\n*\n\n*You can find $SINK with pactl list sinks, it's shown after Name:\n\n*Similarly you can see the $BTSOURCE with pactl list sources\n\n*The source_dont_move argument prevents the loopback connection from falling back to another audio source when the Bluetooth device is disconnected. It is instead removed and you'll have to set it up again next time.\n\n\nHere's what an example one would look like (Remember to replace the : with _ in the Bluetooth address!):\npactl load-module module-loopback source_dont_move=yes source=bluez_source.14_DA_E9_2A_D7_57 sink=alsa_output.pci-0000_00_14.2.analog-stereo\n\nIf loading the fallback module fails, try removing the source_dont_move=yes argument, it was made available first in version 1.0.\nThen be careful however to remove this loopback connection before you drop this audio, or if for instance your laptop microphone is unmuted, you may get some very bad feedback.  To drop this loopback connection manually when you're done, run:\npactl unload-module $(pactl list short modules | grep \"loopback.*$BTSOURCE\" | cut -f1)\n\nAgain, replace $BTSOURCE with the name for the PulseAudio source that refers to your Bluetooth device. You may also unload the module using the id returned by the load-module command:\n$ pactl load-module module-loopback source_dont_move=yes source=bluez_source.14_DA_E9_2A_D7_57 sink=alsa_output.pci-0000_00_14.2.analog-stereo\n15\n$ pactl unload-module 15\n\nReferences:\n\n\n*\n\n*Blog post outlining some of the details on how this is being fixed in Ubuntu.\n\n\nA: For 13.04, pair your source device with the ubuntu laptop and it just works!   Very cool to find that it was that easy now.\n\nA: In Ubuntu 16.04 this works out-of-the-box.\n\nA: I use blueman, installed from Ubuntu software center.\nRight-clicking on the blueman icon*-> \"local services\" -> audio-> Check \"advanced audio reception\" is tipped. Btw I use it to listen in my Ubuntu 11.10 laptop what I play on my android phone.\n*The blueman icon is showed in bottom-right corner in gnome shell + ubuntu 11.10, that is my case.\nI hope this is useful in some way for you. \n\nA: Even easier solution than the answer.\nYou can simply go\nsudo apt-get install pulseaudio*\n\nThen reboot. After reboot, connect to your Bluetooth and simply play the music on your phone.  Everything will be transmitted to your computer and play out on the computer's speakers.\nAnd yes! you're welcome.\n", "Q: How to stop acpid restarting /etc/acpi/lid.sh restart unnecessarily? On my Acer Aspire One netbook, I have noticed that acpid starts /etc/acpi/lid.sh multiple times a minute. This script should only be started when the lid is closed or opened. How can I stop theses unnecessary starts from happening without switching off acpi or disabling the lid event?\n\nA: Is this the same issue as this bug\nIf so there is a description of the cause here and the solution is here\nLike the man says\n\n[this] involves recompiling the\n  kernel. Don't do this unless you're\n  familiar with the process. Back up\n  your machine beforehand. Follow this\n  guide at your own risk. Etc, etc\n\n", "Q: Netbook Remix goes to low graphics mode after booting up from hibernate I am using an Asus 1005P netbook. What happens is when I wake up the machine from hibernate state, a while later x crashes and goes to low graphics mode.\nI stumbled on solutions in ubuntuforums but none of them seem to work:\nhttp://ubuntuforums.org/showthread.php?t=1498447\nDoes anyone have another solution for this?\n\nA: This most likely is a bug. If you want to debug and collect information that could explain why it doesn't work on your laptop, take a look at The Ubuntu wiki page on debugging low power states.\n", "Q: Can I log how long resume (un-hibernate) takes? This question has been spun off from my question about hibernate being slow.\nI know I can run a script when I resume the computer by putting it in /etc/acpi/resume.d, but that will only run it once. What I was hoping for was a \"starting wakeup\" script and a \"finished wakeup\" script, so each one would log it's time somewhere and I could see how long resume works.\nI figure this is a long shot, since the \"starting wakeup\" script would have to run really early, so even if it was possible, there might not be a disk to write to.\n\nA: You can look in /var/log/syslog for a general system log, it will contain messages from the kernel about the hibernate process. \nThe delta from when processes start being frozen to when there are no more kernel log messages (until it starts at 0.0000000 on reboot) is the time your computer took to hibernate. \n", "Q: Can't seem to get my login screen back after installing slim At one point I switched from GDM to slim and now I can't seem to get past the splash screen. After pressing Esc I can see that it is stuck on Starting X Display Manager: Slim. I need to get back to GDM or just figure out what it is doing.\nThoughts?\n\nA: Assuming GDM is still installed:\nsudo dpkg-reconfigure gdm\n\nwill let you select what your default display manager is.  If it's not installed...well, install it.\nIt'll go into effect on reboot.\n\nA: I would drop into a command prompt - You can switch at any time by pressing Ctrl+Alt+F2 and login. Then you can sudo apt-get remove slim. Once you've done so - if you already have GDM installed then just sudo dpkg-reconfigure gdm otherwise run sudo apt-get install gdm\n", "Q: Keeping multiple terminal windows in focus I write code. I use terminal a lot. I ofter use many terminal windows. I hate how tabs look.\nAre there any applications that allow me to keep multiple terminal windows in focus to streamline my development?\n\nA: Yakuake is like Guake + Terminator: you get multiple tabs and split screen terminals, all in a quake drop-down. But it's a KDE application so if you're using Gnome, I would say Guake.\n\nA: Try Terminator. It allows you to split the terminal window (You can also have tabs and separate windows).\n\nYou can install terminator from your current terminal with this command:\nsudo apt-get install terminator\n\nOr you can search 'terminator' in Ubuntu Software Centre (or Synaptic).\n\nA: I also (in addition to terminator) use Guake sudo apt-get install guake. It is a quake-like console tool which is basically a tabbed terminal except it pops out when you press F12 and closes when you lose focus (if you configure it that way). I love it.\n\nA: I don't see what the problem is. I just opened 5 terminal windows at the same time, no problem, by hitting ctrl+shift+n with the terminal open, or going to File > Open Terminal. I haven't done anything that would affect the terminal... This is pretty much right out of the box. Are you using 10.4?\n\nA: Both screen and byobu (which is just screen with some neat extras) allow you to use multiple windows within one session.  For me they're must-have applications when I'm connecting via SSH. \nSee https://help.ubuntu.com/community/Screen for more information on how to use screen.\n\nA: Just some alternatives out there:\nTry a different terminal. I use urxvt-unicode (package name) and it has a much better tab layout/look imo. \nHere's a page with a sample screenshot of the tabs in the upper corner:\nhttp://battlemidget.blogspot.com/2007/10/urxvt-fvwm.html\nSecondly, you might consider a tiling window manager at some point. I'm a huge fan. You don't have to worry about laying out all those different terminals and just add/remove as you need them. I'm using AwesomeWM, but Xmodad is another really good one. \nQuick youtube of someone using it:\nhttp://www.youtube.com/watch?v=6FUkmMeU3bU&feature=related\n\nA: If what you want is to have many ssh/telnet connections to some machines, please, ty PAC (http://sourceforge.net/projects/pacmanager/)  link text\n\nA: Mutiplexing the terminal?\n\n\n*\n\n*sudo apt-get install guake\n\n*sudo apt-get install tmux\n\n*Open guake by pressing F12.\n\n*Right click on the dropping window and then select Preferences.\n\n*Select usr/bin/tmux in the only one select box.\n\n*In my case, I have to close and re-open guake.\n\n\nSo now you have guake with multiple window display and several other tools. \nCtrl+B and then % for vertical splitting. \nCtrl+B and then \" for horizontal splitting.\n", "Q: Is there a way to check hardware integrity? I know how to check hard disk integrity, and how to check RAM integrity (with live cd), but is there a way to check if others hardware is working well or is broken?\nFor example graphic card, audio card, etc.. ?\nI'm not trying to check in an hardware works well with ubuntu (aka driver question), i need to check if an hardware is broken or not\n\nA: In System->Administration->System Testing there are a set of tests that check your system. They might not cover every piece of hardware but they do a decent job of getting the basics, network, sound, etc.\n\n\nA: You can test your sound stuff like this:\nspeaker-test\n\nCompletely contingent upon having working drivers though.\n\nA: You can check the health of your hard drive with System > Administration > Disk Utility\n", "Q: Comparison of backup tools \nThis question exists because it has historical significance, but it is not considered a good, on-topic question for this site, so please do not use it as evidence that you can ask similar questions here.  While you are encouraged to help maintain its answers, please understand that \"big list\" questions are not generally allowed on Ask Ubuntu and will be closed per the help center.\n\nBackup is incredibly important. Obviously there's no best backup tool, but a comparison of the options would be very interesting.\n\n\n*\n\n*Graphical Interface? Command line?\n\n*Incremental backups?\n\n*Automatic backups?\n\n*Install method: In standard repositories? PPA?\n\n\nA: I run a custom Python script which uses rsync to save my home folder (less trash etc) onto a folder labelled \"current\" on a separate backup HDD (connected by USB) and then the copy (cp) command to copy everything from \"current\" onto a date-time stamped folder also on the same HDD. The beautiful thing is that each snapshot has every file in your home folder as it was at that time and yet the HDD doesn't just fill up unnecessarily. Because most files never change, there is only ever one actual copy of those files on the HDD. Every other reference to it is a link. And if a newer version of a file is added to \"current\", then all the snapshots pointing to the older version are now automatically pointing to a single version of the original. Modern HDD file systems takes care of that by themselves. Although there are all sorts of refinements in the script, the main commands are simple. Here are a few of the key ingredients:\nexclusion_path = \"/home/.../exclusions.txt\" # don't back up trash etc\nmedia_path = \"/media/... # a long path with the HDD details and the \"current\" folder\nrsync -avv --progress --delete --exclude-from=exclusion_path /home/username/ media_path\ncurrent = \"...\" # the \"current\" folder on the HDD\ndest = \"...\" # the timestamped folder on the HDD\ncp -alv current dest\n\nI had some custom needs as well.  Because I have multiple massive (e.g. 60GB) VirtualBox disk images, I only ever wish to have one copy of those, not snapshot versions.  Even a 1 or 2 TB HDD has limits.\nHere are the contents of my exclusions file. The file is very sensitive to missing terminal slashes etc:\n/.local/share/Trash/\n/.thumbnails/\n/.cache/\n/Examples/\n\n\nA: rsnapshot vs. rdiff-backup\nI often refer to this comparison of rsnapshot and rdiff-backup:\nSimilarities:\n\n*\n\n*both use an rsync-like algorithm to transfer data (rsnapshot actually uses rsync; rdiff-backup uses the python librsync library)\n\n*both can be used over ssh (though rsnapshot cannot push over ssh without some extra scripting)\n\n*both use a simple copy of the source for the current backup\n\nDifferences in disk usage:\n\n*\n\n*rsnapshot uses actual files and hardlinks to save space. For small files, storage size is similar.\n\n*rdiff-backup stores previous versions as compressed deltas to the current version similar to a version control system. For large files that change often, such as logfiles, databases, etc., rdiff-backup requires significantly less space for a given number of versions.\n\nDifferences in speed:\n\n*\n\n*rdiff-backup is slower than rsnapshot because of its need to calculate delta files. There are ways to speed it up, though, like the --no-fsync and --no-compression options.\n\nDifferences in metadata storage:\n\n*\n\n*rdiff-backup stores file metadata, such as ownership, permissions, and dates, separately.\n\nDifferences in file transparency:\n\n*\n\n*For rsnapshot, all versions of the backup are accessible as plain files.\n\n*For rdiff-backup, only the current backup is accessible as plain files. Previous versions are stored as rdiff deltas.\n\nDifferences in backup levels made:\n\n*\n\n*rsnapshot supports multiple levels of backup such as monthly, weekly, and daily.\n\n*rdiff-backup can only delete snapshots earlier than a given date; it cannot delete snapshots in between two dates.\n\nDifferences in support community:\n\n*\n\n*rdiff-backup has seen a lot of recent development and bugfixing activity. From December 2019 till spring 2020, rdiff-backup was re-worked into version 2, which supports Python 3.\n\nSupported file systems:\n\n*\n\n*rdiff-backup supports all unixoid file systems. FAT32, NTFS and HFS+ are supported too. As of today (July 2020), there are still problems with exFAT.\n\n\nA: rsync \nIf you're familiar with command-line tools, you can use rsync to create (incremental) backups automatically. It can mirror your directories to other machines. There are lot of scripts available on the net how to do it. Set it up as recurring task in your crontab. There is also a GUI frontend for rsync called Grsync that makes manual backups easier.\nOne very useful example is:\nrsync -vahP --delete --backup-dir ../$(date --iso-8601=minutes) <source directory> <destination directory>\n\nAmong -vahP, the -a flag is important, as this preserves file permissions and recurses into subdirectories. --backup-dir stores changed and deleted files in the specified backup directory, which is conveniently named after the current date and time.\nThe idea below stores changed/deleted files with a suffix, which carries the current time/date:\nrsync -vahP --delete --backup-dir ../backup --suffix .$(date --iso-8601=minutes) <source directory> <destination directory>\n\nThough rsync is very fast and very versatile, only the last backup can be easily restored in an obvious way.\nAnother way to preserve deleted files would be using hard links.\nSee:\n\n*\n\n*http://www.sanitarium.net/golug/rsync_backups_2010\n\nA: Dirvish\nNote: As of 2021-01 the last release was in 2005.\nA nice command line snapshot backup tool which uses hardlinks to reduce diskspace. It has a sophisticated way to purge expired backups.\n\nA: Duplicati\nAn open source, gratis backup application running on Linux, with gui that \"securely stores encrypted, incremental, compressed backups on cloud storage services and remote file servers. It works with Amazon S3, Windows Live SkyDrive, Google Drive (Google Docs), Rackspace Cloud Files or WebDAV, SSH, FTP (and many more)\".\nVersion 1.0 is considered stable; there is a version 2 in development with considerable internal changes that is currently working (though I wouldn't use it for production). There are standard or custom filter rules to select files to backup.\nI have been using it for years partly (not connected to anyone there but have considered looking at the API to add a backend, speaking as a developer) although infrequently, on both a Windows laptop and my Ubuntu 14.04 install.\nA fork of duplicity.\n\nA: BorgBackup is a CLI tool and with Vorta as its GUI does everything you need and more.  There is even a PPA for BorgBackup itself.\nThe main difference between BorgBackup and any other backup solution is that it's a deduplicating backup solution:\nE.G. if you have multiple copies of one single file, that file will take up space only once.\n\n\n*\n\n*Install BorgBackup:\nsudo add-apt-repository ppa:costamagnagianfranco/borgbackup\nsudo apt update\nsudo apt install borgbackup\n\n\n*Install Vorta:\npip install vorta\n\n\n*Make your initial backup:\nborg init --encryption=repokey-blake2 /media/ExternalHDD/{user}\n\n\n*click the Vorta icon to go to the GUI and configure it.\n\nA: Duplicity \nDuplicity is a feature-rich command line backup tool.\nDuplicity backs up directories by producing encrypted tar-format volumes and uploading them to a remote or local. It uses librsync to record incremental changes to files; gzip to compress them; and gpg to encrypt them.\nDuplicity's command line can be intimidating, but there are many frontends to duplicity, from command line (duply), to GNOME (deja-dup), to KDE (time-drive).\n\nA: TimeVault\nWarning: unmaintained\nTimeVault a is tool to make snapshots of folders and comes with nautilus integration. Snapshots are protected from accidental deletion or modification since they are read-only by default.\nCan be downloaded from Launchpad.\n\nA: PING is a no-nonsense free backup tool that will let you make backups of entire partitions. It is a standalone utility that should be burnt on CD. \nWhat I like about this program is that it copies the entire partition.\nImagine this: while modifying your Ubuntu as a superuser, you changed a vital part and Ubuntu won't start up anymore.\nYou could format the hard disk and reinstall Ubuntu. While backup solutions as Dropbox, Ubuntu One etc. might be useful for retrieving the important files , it won't restore your wallpaper, Unity icons and other stuff that made your Ubuntu the way you liked it. \nAnother option is to ask for help on the internet. But why not just restore the whole system to the way it was a few days ago? PING will do exactly this for you.\nPro's:\n\n\n*\n\n*Will not only backup documents, but system files as well\n\n*It's easy to use\n\n*It is possible to backup other (non-Linux) partitions as well\n\n*It will compress the backup in gzip or bzip2 format, saving disk space\n\n\nCons:\n\n\n*\n\n*The PC will have to be restarted before being able to backup\n\n*PING will make a backup of an entire partition, even when only few files have been modified\n\n*You'll need an external hard drive or some free space on your PC to put your backups\n\n\nAn excellent Dutch manual can be found here.\n\nA: s3ql is a more recent option for using Amazon s3, Google Storage or OpenStack Storage as a file system.  It works on a variety of Linux distros as well as MacOS X.\nUsing it with rsync, you can get very efficient incremental offsite backups since it provides storage and bandwidth efficiency via block-level deduplication and compression.  It also supports privacy via client-side encryption, and some other fancy things like copy-on-write, immutable trees and snapshotting.\nSee Comparison of S3QL and other S3 file systems for comparisons with PersistentFS,  S3FS,   S3FSLite,   SubCloud,   S3Backer and    ElasticDrive.\nI've been using it for a few days, starting from s3_backup.sh, (which uses rsync) and am quite happy.  It is very well documented and seems like a solid project.\n\nA: Dropbox\nA cross-platform (proprietary) cloud sync for Windows, Mac, and Linux. 2GB of online storage is free, with paid options.  Advertised as a way to \"store, sync, and, share files online\" but could be used for backup purposes too. \nNote that even on paid accounts revision history is limited to one year and on free accounts it is only one month.\nNote also that restoring large amount of files may be very time-consuming as Dropbox was not built as a backup tool.\n\n\nA: luckyBackup \nIt's not been mentioned before, so I'll pitch in that \"LuckyBackup\" is a superb GUI front end on rsync and makes taking simple or complex backups and clones a total breeze.\nNote that this tool is no longer developed.\nThe all important screenshots are found here on their website with one shown below:\n\nNote: As of 2021-01, the last release of luckyBackup was on 2018-11\n\nA: inosync\nA Python script that offers a more-or-less real-time backup capability.\nMote that this software is not maintained anymore.\n\"I came across a reference to the “inotify” feature that is present in recent Linux kernels. Inotify monitors disk activity and, in particular, flags when files are written to disk or deleted. A little more searching located a package that combines inotify's file event monitoring with the rsync file synchronization utility in order to provide the real-time file backup capability that I was seeking. The software, named inosync, is actually a Python script, effectively provided as open-source code, by the author, Benedikt Böhm from Germany (http://bb.xnull.de/).\"\nhttp://www.opcug.ca/public/Reviews/linux_part16.htm\n\nA: Obnam\nWarning: Software is no longer maintained, authors recommend not using it\n'Obnam is an easy, secure backup program. Backups can be stored on local hard disks, or online via the SSH SFTP protocol. The backup server, if used, does not require any special software, on top of SSH.\nSome features that may interest you:\n\n\n*\n\n*Snapshot backups. Every generation looks like a complete snapshot, so you don't need to care about full versus incremental backups, or rotate real or virtual tapes.\n\n*Data de-duplication, across files, and backup generations. If the backup repository already contains a particular chunk of data, it will be re-used, even if it was in another file in an older backup generation. This way, you don't need to worry about moving around large files, or modifying them.\n\n*Encrypted backups, using GnuPG.'\n\n\nAn old version can be found in the Ubuntu software sources, for the newest version refer to Chris Cormacks PPA or Obnams website.\n\nA: BackupPC\nIf you want to back up your entire home network, I would recommend BackupPC running on an always-on server in your basement/closet/laundry room. From the backup server, it can connect via ssh, rsync, SMB, and other methods to any other computer (not just Linux computers), and back up all of them to the server. It implements incremental storage by merging identical files via hard links, even if the identical files were backed up from separate computers.\nBackupPC runs a web interface that you can use to customize it, including adding new computers to be backed up, initiating immediate backups, and most importantly, restoring single files or entire folders. If the BackupPC server has write permissions to the computer that you are restoring to, it can restore the files directly to where they were, which is really nice.\n\n\nA: bup\nA \"highly efficient file backup system based on the git packfile format. Capable of doing fast incremental backups of virtual machine images.\"\nHighlights:\n\n\n*\n\n*It uses a rolling checksum algorithm (similar to rsync) to split large\nfiles into chunks.  The most useful result of this is you can backup huge\nvirtual machine (VM) disk images, databases, and XML files incrementally,\neven though they're typically all in one huge file, and not use tons of\ndisk space for multiple versions.\n\n\n\n\n*\n\n*Data is \"automagically\" shared between incremental backups without having\nto know which backup is based on which other one - even if the backups\nare made from two different computers that don't even know about each\nother.  You just tell bup to back stuff up, and it saves only the minimum\namount of data needed.\n\n\n\n\n*\n\n*Bup can use \"par2\" redundancy to recover corrupted backups even if your\ndisk has undetected bad sectors.\n\n\n\n\n*\n\n*You can mount your bup repository as a FUSE filesystem and access the\ncontent that way, and even export it over Samba.\n\n\n\n\n*\n\n*A KDE-based front-end (GUI) for bup is available, namely Kup Backup System.\n\n\n\nA: CrashPlan\nCrashPlan is a company providing business backup, without plan for individual users.\nFeatures\n\n*\n\n*10$/month/device fee\n\n*Triple destination data storage and protection\n\n*Silent and continuous\n\n*Generous retention and versioning\n\n*Deleted file protection\n\nI had considered a bunch of options and configurations (using rdiff-backup, duplicity, backup-ninja, amazon s3, remote server). What it finally came down to was simplicity.\nCrashPlan is cross platform, but not open source.\nIt's also worth noting that with a (paid) CrashPlan Central 'family' plan you can backup all the computers you own.\n\nA: Bacula\nI used Bacula a long time ago. Although you would have to learn its architecture, it's a very powerful solution. It lets you do backups over a network and it's multi-platform. You can read here about all the cool things it has, and here about the GUI programs that you can use for it. I deployed it at my university. When I was looking for backup solutions I also came across Amanda.\nOne good thing about Bacula is that it uses its own implementation for the files it creates. This makes it independent from a native utility's particular implementation (e.g. tar, dump...).\nWhen I used it there weren't any GUIs yet. Therefore, I can't say if the available ones are complete and easy to use.\nBacula is very modular at it's core. It consists of 3 configurable, stand-alone daemons:\n\n\n*\n\n*file daemon (takes care of actually collecting files and their metadata cross-platform way)\n\n*storage daemon (take care of storing the data - let it be HDD, DVDs, tapes, etc.)\n\n*director daemon (takes care of scheduling backups and central configuration)\n\n\nThere is also SQL database involved for storing metadata about bacula and backups (support for Postgres, MySQL and sqlite.\nbconsole binary is shipped with bacula and provides CLI interface for bacula administration.\n\nA: Simple Backup \nNote: As of  2021-01 the last release was on 2013.\nSimple Backup is another tool to backup your file and keep a revision history. It is quite efficient (with full and incremental backups) and does not take up too much disk space for redundant data. So you can have historical revision of files à-la Time Machine (a feature Back in time - mentioned earlier - is also offering).\nFeatures:\n\n*\n\n*easy to set-up with already pre-defined backup strategies\n\n*external hard disk backup support\n\n*remote backup via SSH or FTP\n\n*revision history\n\n*clever auto-purging\n\n*easy sheduling\n\n*user- and/or system-level backups\n\n\nAs you can see the feature set is similar to the one offered by Back in time.\nSimple Backup fits well in the Gnome and Ubuntu Desktop environment.\n\nA: tar\ntar, a simple and reliable tool for archiving files, can also be used for backups. But today, we have better and faster backup tools with more useful features. Depending on your needs, tar can still be useful.\nCreate a full backup of your home directory:\ncd to the directory where you want to store the backup file, and then:\ntar --create --verbose --file backup.tar <path to the home directory>\n\nFor subsequent backups, we want to avoid a full backup - because it takes too much time. So we simply update the files in backup.tar:\nAgain, cd to the directory where the backup file is, and then use --update:\ntar --update --verbose --file backup.tar <path to the home directory>\n\nAll files that are either new or have been modified will be saved in backup.tar. Deleted files will be kept. To restore the most recent backup, right-click on the file and choose \"Extract to...\". To retrieve older versions of your files, you have to open backup.tar, and find the files (and versions) you want to restore.\nNote: You cannot use --update on a compressed tar file (e.g. .tar.gz).\n\nA: Déjà Dup \nDéjà Dup is (from Ubuntu 11.10) installed by default. It is a GNOME tool intended for the casual Desktop user that aims to be a \"simple backup tool that hides the complexity of doing backups the Right Way\". \nIt is a front end to duplicity that performs incremental backups, where only changes since the prior backup was made are stored. It has options for encrypted and automated backups. It can backup to local folders, Amazon S3, or any server to which Nautilus can connect.\nIntegration with Nautilus is superb, allowing for the restoration of files deleted from a directory and for the restoration of an old version of an individual file.\n\n\nNote that as of February 2016 this project appears to be almost completely ignoring bug reports with only minor triage activity and the last bugfix dates back to 2014, though there are new releases with minor changes.\n\nA: DAR \nDAR - the Disk ARchive program - is a powerful command line backup tool supporting incremental backups and restores. If you want to backup a lot of files then it may be considerable faster than rsync (rolling checksum) like solutions.\n\nA: Attic Backup / Borg Backup\nNote: As of 2021-01 the last release was on 2015.\n\nAttic is a deduplicating backup program written in Python. The main goal of Attic is to provide an efficient and secure way to backup\ndata. The data deduplication technique used makes Attic suitable for\ndaily backups since only the changes are stored.\n\nMain Features:\n\n\n*\n\n*Easy to use\n\n*Space efficient storage: Variable block size deduplication is used to reduce the number of bytes stored by detecting redundant data.\n\n*Optional data encryption: All data can be protected using 256-bit AES encryption and data integrity and authenticity is verified\nusing HMAC-SHA256.\n\n*Off-site backups: Attic can store data on any remote host accessible over SSH\n\n*Backups mountable as filesystems: Backup archives are mountable as userspace filesystems for easy backup verification and restores.\n\n\nRequirements:\nAttic requires Python >=3.2. Besides Python, Attic also requires msgpack-python and OpenSSL (>= 1.0.0). In order to mount archives as filesystems, llfuse is required.\nNote:\nThere is also now a fork of Attic called Borg.\n\nA: Spideroak\nA dropbox like backup/syncing service with comparable features.\n\n*\n\n*Access all your data in one de-duplicated location\n\n*Configurable multi-platform synchronization\n\n*Preserve all historical versions & deleted files\n\n*Share folders instantly in web\n\n*ShareRooms w / RSS\n\n*Retrieve files from any internet-connected device\n\n*Comprehensive 'zero-knowledge' data encryption\n\nListed supported systems:  Debian Lenny, OpenSUSE, RPM-Based (Fedora, etc.), CentOS/RHEL, Ubuntu Lucid Lynx, Ubuntu Gutsy Gibbon, Ubuntu Karmic Koala, Ubuntu Maverick Meerkat, Ubuntu Intrepid Ibex, Debian Etch, Ubuntu Hardy Heron, Slackware 12.1, Ubuntu Jaunty Jackalope\nMore info at https://spideroak.com\n\nA: Back in Time\nI have been using Back in Time for some time, and I'm very satisfied with it.\nAll you have to do is configure:\n\n*\n\n*Where to save snapshot\n\n*What directories to backup\n\n*When backup should be done (manual, every hour, every day, every week, every month)\n\nand forget about it.\nTo install Back in Time on Ubuntu 14.04-18.04:\nsudo apt install backintime-gnome\n\nTo install Back in Time on Ubuntu 20.04 and later:\nsudo apt install backintime-qt\n\nThe program GUI can be opened via Ubuntu search for \"backintime\".\n\nThe project is active as of August 2019.\n\nA: FlyBack\nWarning: Unmaintained, last update in 2010.\nSimilar to Back in Time\n\nApple's Time Machine is a great\n  feature in their OS, and Linux has\n  almost all of the required technology\n  already built in to recreate it. This\n  is a simple GUI to make it easy to\n  use.\n\n\n\nA: Areca Backup\nWarning: Unmaintained, last release in 2015.\nis also a very decent GPL program to make backups easily.\nFeatures\n\n\n*\n\n*Archives compression (Zip & Zip64\nformat)\n\n*Archives encryption (AES128 & AES256\nencryption algorithms)\n\n*Storage on local hard drive, network\ndrive, USB key, FTP / FTPs server\n(with implicit and explicit SSL /\nTLS)\n\n*Source file filters (by extension,\nsubdirectory, regular expression,\nsize, date, status, with AND/OR/NOT\nlogical operators)\n\n*Incremental, differential and full\nbackup support\n\n*Support for delta backup (store only\nmodified parts of your files)\n\n*Archives merges : You can merge\ncontiguous archives into one single\narchive to save storage space.\n\n*As of date recovery : Areca allows\nyou to recover your archives (or\nsingle files) as of a specific date.\n\n*Transaction mechanism : All critical\nprocesses (such as backups or merges)\nare transactional. This guarantees\nyour backups' integrity.\n\n*Backup reports : Areca generates\nbackup reports that can be stored on\nyour disk or sent by email.\n\n*Post backup scripts : Areca can\nlaunch shell scripts after backup.\n\n*Files permissions, symbolic links and\nnamed pipes can be stored and\nrecovered. (Linux only)\n\n\nA: Jungledisk \nIs a winner as far as I'm concerned. It backs up remotely to an optionally-encrypted Amazon S3 bucket, it's customisable, it can run in the background (there are various guides available for setting that up). There's a decent UI or you can hack an XML file if you're feeling so inclined.\nI backup all of my home machines with the same account, no problem. I also can remotely access my backed-up data via myjungledisk.com .\nIt's not free, but in US terms it's certainly cheap enough (I pay around $8 a month). I feel that's more than acceptable for an offsite backup where someone else deals with hardware and (physical) security etc issues.\nI can't recommend it enough.\n\nA: saybackup and saypurge\nThere is a nice script called saybackup which allows you to do simple incremental backups using hardlinks. From the man page:\n\nThis script creates full or reverse incremental backups using the\n  rsync(1) command. Backup directory names contain the date and time\n  of each backup run to allow sorting and selective pruning.   At the\n  end of each successful backup run, a symlink '*-current' is   updated\n  to always point at the latest backup. To reduce remote file\n  transfers, the '-L' option can be used (possibly multiple times) to\n  specify existing local file trees from which files will be\n  hard-linked into the backup.\n\nThe corresponding script saypurge provides a clever way to purge old backups. From the home page of the tool:\n\nSayepurge parses the timestamps from the names of this set of backup\n  directories, computes the time deltas, and determines good deletion\n  candidates so that backups are spaced out over time most evenly. The\n  exact behavior can be tuned by specifying the number of recent files\n  to guard against deletion (-g), the number of historic backups to keep\n  around (-k) and the maximum number of deletions for any given run\n  (-d). In the above set of files, the two backups from 2011-07-07 are\n  only 6h apart, so they make good purging candidates...\n\n\nA: backup2l\nWarning: unmaintained, last commit on 2017-02-14\nFrom the homepage: \n\nbackup2l is a lightweight command line tool for generating,\n  maintaining and restoring backups on a mountable file system (e. g.\n  hard disk). The main design goals are are low maintenance effort,\n  efficiency, transparency and robustness. In a default installation,\n  backups are created autonomously by a cron script.\nbackup2l supports hierarchical differential backups with a\n  user-specified number of levels and backups per level. With this\n  scheme, the total number of archives that have to be stored only\n  increases logarithmically with the number of differential backups\n  since the last full backup. Hence, small incremental backups can be\n  generated at short intervals while time- and space-consuming full\n  backups are only sparsely needed.\nThe restore function allows to easily restore the state of the file\n  system or arbitrary directories/files of previous points in time. The\n  ownership and permission attributes of files and directories are\n  correctly restored.\nAn integrated split-and-collect function allows to comfortably\n  transfer all or selected archives to a set of CDs or other removable\n  media.\nAll control files are stored together with the archives on the backup\n  device, and their contents are mostly self-explaining. Hence, in the\n  case of an emergency, a user does not only have to rely on the restore\n  functionality of backup2l, but can - if necessary - browse the files\n  and extract archives manually.\nFor deciding whether a file is new or modified, backup2l looks at its\n  name, modification time, size, ownership and permissions. Unlike other\n  backup tools, the i-node is not considered in order to avoid problems\n  with non-Unix file systems like FAT32.\n\n\nA: I recommend Timeshift for Ubuntu users who want to backup an entire partition.\nTimeshift is a system restore utility which takes snapshots of the system at regular intervals. These snapshots can be restored at a later date to undo system changes. Timeshift creates incremental snapshots using rsync or BTRFS snapshots using BTRFS tools.\nTimeshift can be installed from the default Ubuntu repositories in Ubuntu 20.04 and later with the following command.\nsudo apt install timeshift\n\nIn Ubuntu 18.04 Timeshift is available from ppa:teejee2008/timeshift.\nTo get started using Timeshift read this tutorial: How to Use Timeshift to Backup and Restore Ubuntu Linux.\nIf you get this bug All snap apps doesn't launch after Timeshift system restore delete all traces of snapd with sudo apt autoremove --purge snapd and reinstall the snaps that couldn't launch previously. In this scenario typically 2 or 3 snap packages might need to be reinstalled.\n\nA: faubackup\nAnother small tool which lets you do incremental backups with hardlinks was Faubackup.\nFrom the homepage:\n\nThis Program uses a filesystem on a hard drive for incremental and\n  full backups. All Backups can easily be accessed by standard\n  filesystem tools (ls, find, grep, cp, ...)\nLater Backups to the same filesystem will automatically be\n  incremental, as unchanged files are only hard-linked with the existing\n  version of the file.\n\nIt allows to create different levels of backups. From the man page:\n\nFauBackup may be configured to keep certain backups for a long time\n  and remove others. Have a look at traditional backup systems. You have\n  tapes for daily, weekly, monthly and yearly backups, and store them\n  according to your local backup policy. FauBackup can do this for you\n  on harddisks, too. That is, it can keep some yearly, weekly, etc.\n  backups for you and automatically remove other obsoleted backups.\nFour different backup-types are recognized: daily, weekly, monthly and\n  yearly. The first existing backup in such an interval will be\n  considered belonging to the coresponding type. Thus, the first backup\n  in a month (eg. 2000−12−01@06:30:00) will be a monthly backup; the\n  first backup in 2001 will be of all four types, as January 1st, 2001\n  is a Monday.\nThe number of backups kept for each type is configureable (See\n  faubackup.conf(5) ). If a backup doesn’t belong to such a type (eg.\n  second backup in a day), or is too old for that type, it will be\n  removed on faubackup --\n\n\nA: boxbackup\nFrom the homepage: \n\nBox Backup is an open source, completely automatic, on-line backup\n  system. It has the following key features:\n  \n  \n*\n  \n*All backed up data is stored on the server in files on a filesystem - no tape, archive or other special devices are required.\n  -The server is trusted only to make files available when they are required - all data is encrypted and can be decoded only by the\n  original client. This makes it ideal for backing up over an untrusted\n  network (such as the Internet), or where the server is in an\n  uncontrolled environment.\n  -A backup daemon runs on systems to be backed up, and copies encrypted data to the server when it notices changes - so backups are continuous\n  and up-to-date (although traditional snapshot backups are possible\n  too). \n  \n*Only changes within files are sent to the server, just like rsync, minimising the bandwidth used between clients and server. This makes\n  it particularly suitable for backing up between distant locations, or\n  over the Internet. \n  \n*It behaves like tape - old file versions and deleted files are available. \n  \n*Old versions of files on the server are stored as changes from the current version, minimising the storage space required on the server.\n  Files are the server are also compressed to minimise their size. \n  \n*Choice of backup behaviour - it can be optimised for document or server backup. \n  \n*It is designed to be easy and cheap to run a server. It has a portable implementation, and optional RAID implemented in userland for\n  reliability without complex server setup or expensive hardware.\n  http://www.boxbackup.org/\n\n\nA: zpaq\nzpaq is a file archiver that grew out of the PAQ series of file compression tools. It can be used for incremental backups, and you can revert to any previous file version. By default, the add options only adds files with a newer date, or with a changed file size. By default, zpaq cuts files into blocks that are about 64 kilobytes big, and it stores only the blocks the have not yet been encountered by the program.\nAs a backup software, zpaq has a disadvantage - it does not allow you to delete old backups. On the other hand, once the initial backup has been done, incremental backups only need very little memory, and are very fast.\nThe -key option encrypts the backup with AES-256.\nBackup\nzpaq add backup.zpaq <path to the directory you want to back up>\n\nUsing the most extreme (and slowest) compression (default is 1):\nzpaq add backup.zpaq <path to the directory you want to back up> -method 5\n\nUsing -method 0 does not compress any data. For backups, -method 1 is recommended, although -method 2 is nearly as fast.\nList the files in your most recent backup\nzpaq list backup.zpaq\n\nList contents of second backup\nzpaq list backup.zpaq -until 2\n\nList all versions of all files\nzpaq list backup.zpaq -all\n\nThe version is indicated by a four-digit number, starting with 0001. (Additional digits are added as needed.)\nExtract the most recent backup\nzpaq extract backup.zpaq <destination>\n\nExtract the second version of your backup\nzpaq extract backup.zpaq <destination> -until 2\n\nExtract all versions of all files that have \"diary\" in their names\nzpaq extract backup.zpaq -only \"*diary*\" -all\n\nThe file versions will be saved in different folders - 0001 for the first version, 0002 for the second, et cetera.\n\nA: A new one is : https://github.com/kopia/kopia\nKopia is a simple, cross-platform tool for managing encrypted backups in the cloud or locally. It provides fast, incremental backups, secure, client-side end-to-end encryption, compression and data deduplication.\nand can do automatic backups\nhttps://kopia.io\nafter comparing kopia to restic, duplicati, duplicacy, duplicity, bup, borg ... and others, I decided to use kopia primarily , but I'm using in the same time restic, duplicati and bup , so I have 4 types of backup , if one fail then I still have 3. \nInstall method:\nGUI: linux (portable AppImage) . windows (install exe)\ncommand line: a simple self contained  portable go exe\n\n\n\nA: fwbackups\ninstallation:\nDownload\nsudo apt install sudo apt-get install gettext autotools-dev intltool python-crypto python-paramiko python-gtk2 python-glade2 python-notify cron\n\ntar xfj fwbackups-VERSION.tar.bz2\ncd fwbackups-VERSION\n./configure --prefix=/usr\nmake\nsu -c \"make install\"\n\n\nA: For the people that don't know, MEGA is a Dropbox alternative, with 50GB of free storage, available for Mac, Windows and Linux, created by Kim Dotcom.\nInstall\nDownload the Mega Sync Client for Linux. Open the terminal in the directory you downloaded the deb files, then Copy/Paste the following code: sudo dpkg -i megasync-xUbuntu_14.04_amd64.deb. After that start mega from the Dash, from there one it will start up at login. Also note that the deb file also adds a ppa in your sources list. Meaning future updates, you will get via your Software Updater. \nsudo add-apt-repository ppa:otto-kesselgulasch/mega\nsudo apt-get update\nsudo apt-get install megasync\n\nFeatures\nHere are some features that are touted by Mega:\n\n\n*\n\n*Secure:\n\n\n*\n\n*Your data is encrypted end to end. Nobody can intercept it while in storage or in transit.\n\n\n*Flexible:\n\n\n*\n\n*Sync any folder from your PC to any folder in the cloud. Sync any number of folders in parallel.\n\n\n*Fast:\n\n\n*\n\n*Take advantage of MEGA's high-powered infrastructure and multi-connection transfers.\n\n\n*Generous:\n\n\n*\n\n*Store up to 50 GB for free!\n\n\n\n\nSource: \nexcerpt from:\n\n\n*\n\n*Mega Sync Client For Linux - EuroBytes\nWhich I am the author of.\nAs stated in other file-sharing-service answers, synchronisation is not backup (tldr: risk of synchronising corrupted/deleted files, particularly if no file-versioning available). The key to decrypt the encrypted data at Mega is secured and accessed by your account credentials (kept remotely but encrypted also), so as long as you still have login access/a user you shared the files to can login, the files won't be lost unless synchronised versions are overwritten by bad data.\n\nA: rbackup\nrbackup tries to combine the advantages of rdiff-backup and rsnapshot. \n", "Q: No menu when trying to run Codeblocks I installed codeblocks but the gui is not displaying well. There is no File, Edit, View, Search, Project etc but everything else is there. I am running 9.10.\n\nA: What version of CodeBlocks are you using ? The one in the Ubuntu repositories, or the latest release (CodeBlocks 10.05) ?\nIf you're using the 10.05, you need to install the corresponding wxWidget libraries (see the CodeBlocks site), because the wxWidgets in the Ubuntu repositories are not up to date for the latest CodeBlocks.\n\nA: Sounds like your config file is messed up and the menu is being hidden.\nTry removing ~/.codeblocks/default.conf\n", "Q: gnome-mplayer to play on second screen with option xineramascreen I am trying to make gnome-mplayer play a video in fullscreen on my second screen. I am using a Nvidia card with xineramascreen. Below is my ~/.mplayer/config file.\n[default]\nxineramascreen=1\n\n[gnome-mplayer]\nao=alsa:device=hw=1.0\nmsglevel=all=5\nalang=English,eng,en\nslang=English,eng,en\nxineramascreen=1\n\nThe options have no affect, it plays on my primary screen as usual.\nRunning mplayer -xineramascreen 1 works perfectly, I just want gnome-mplayer to work since it's nicer to use with GUI and Nautilus integration etc.\n\nA: When starting gnome-mplayer, you can try exporting the display: export DISPLAY=0.0; gnome-mplayer (change 0.0 to the desired display).\n", "Q: Installing by using Wubi on Windows Vista 64 After Reboot no Windows Partition is found and installation cannot start. How can we solve this, in order to try Ubuntu ?\nIt says I only have free space available, but that isn't true. I'm on the demo now. \nIf I try to install from the demo, I do get:\n\"The following partitions cannot be unmounted /isodevice\"\n\n\nA: I believe there is a know bug with wubi and windows vista. \nHere is a forum link that might help\n\nA: You seem to have damaged or altered your partition table, wubi doesn't manipulate it so it sounds strange that it should be the cause of this. You could use a tool like PhotoRec to recover files you didn't backup.\nAnother tool called TestDisk might even be able to recover your partition but if you installed filled over its position, it is likely to be damaged beyond a meaningful \nreparation.\nLastly if you have a wubi installation (and it is working) then you can access your Windows partition from the /host/ folder.\n", "Q: byobu and ssh-agent byobu cannot connect to ssh-agent socket well. actually I can make just one connection via ssh-agent but if I try to establish another ssh connection using the agent, it doesn't work.\nI've tried \nsetenv SSH_AUTH_SOCK `echo $SSH_AUTH_SOCK`\n\nin ~/.byobu/profile but it didn't work as well.\n\nA: I'm not sure why people attempt to solve this at the terminal multiplexer configuration level. That's not a place for it, unless you want to have to do it again because you've switched to tmux, screen, etc.\nEvery time you open another window, your shell gets executed and reads its configuration files.\nSourcing this from your shell configuration file solves the problem for any shell that I use:\n#!/bin/bash\nSSH_AGENT_TYPE=\"ssh\"\nSSH_AGENT_INFO=\"${HOME}/.ssh-agent\"\n\nsource_agent_info() {\n  export SSH_AUTH_SOCK=''\n  export SSH_AGENT_PID=''\n\n  if [[ -f ${SSH_AGENT_INFO} ]]; then\n    source ${SSH_AGENT_INFO}\n  fi\n}\n\nagent_running() {\n  source_agent_info\n  proc_file=\"/proc/${SSH_AGENT_PID}/cmdline\"\n  if [[ \"${SSH_AGENT_PID}\" =~ ^[0-9]+$ ]] && \\\n     stat \"${proc_file}\" &> /dev/null && \\\n     grep ssh-agent \"${proc_file}\" &> /dev/null; then\n    return 0\n  else\n    return 1\n  fi\n}\n\nrun_ssh_agent() {\n  ssh-agent 2>&1 | grep -v echo > \"${SSH_AGENT_INFO}\"\n  source_agent_info\n}\n\nif ! agent_running; then\n  run_ssh_agent\nfi\n\n\nA: This issue is detailed in Bug #664059, and solved for byobu versions 3.7 and above.\nBasically, there is an incorrect assumption that /var/run/screen/S-$USER/ will exist and be writable at the point at which the SSH socket needs to be set.  So I moved the symlink to the SSH socket to $HOME/.byobu/.ssh-agent.\n\nA: There is a bug report #616899 which sounds similar to your problem. They suggest to download byobu v3.1 and manually install it. \n\nA: I've been doing ssh-agent byobu all the environment variables gets passed easily.\n", "Q: How to improve wireless network speed? I am running 10.04 LTS on a desktop PC with a Belkin G-Plus MIMO Wireless network card.\nEver since running Ubuntu on the machine I have noticed fairly slow network speeds (about half the speed I get when running the same card through Windows)  I did some research I found out that by and large wireless network cards aren't that well supported on most Linux distros.\nI was wondering though if there is anything I could be tweaking on the system that could help squeeze a little more out of the card?\nHere is some more information\n\n*-network:1\n   description: Wireless interface\n   physical id: 2\n   logical name: wlan0\n   serial: 00:1c:df:24:5e:54\n   capabilities: ethernet physical wireless\n   configuration: broadcast=yes ip=192.168.1.5 multicast=yes wireless=IEEE 802.11bg\n\n\n\nA: You didn't mention what kernel driver you're using for the card, but often tunables can be found in /sys/module/[driver]/.  For example, my iwlagn driver shows this:\nbryce@lynmouth:/sys/module/iwlagn$ ls\ndrivers/  holders/  initstate  notes/  parameters/  refcnt  sections/  srcversion  version\nbryce@lynmouth:/sys/module/iwlagn$ ls parameters/\n11n_disable    amsdu_size_8K    antenna          fw_restart4965  queues_num    swcrypto\n11n_disable50  amsdu_size_8K50  disable_hw_scan  fw_restart50    queues_num50  swcrypto50\nTo find out some more info about what the parameters mean, look at the output of modinfo <driver>.\nTo change values of a parameter, just do \"echo [number] > /sys/module/[driver]/parameters/[parameter]\".  Some parameters are read-only, so do a \"cat .../[parameter]\" to check that your new value was set.\n\nA: This isn't ideal but can you try a different wifi card? Wifi can be really hit and miss. At least this way you can determine if a different card makes any noticeable bandwidth differences.\n\nA: You can try enabling Jumbo Frames. \n\nA: Try running this command in a Terminal window (Ctrl+Alt+T):\nsudo iwconfig wlan0 rate 54M\n\n", "Q: Change partition sizes after windows removal? Let's say we install ubuntu side by side with a windows installation.\nAt that time, we will NOT have much space to play with so:\n/ - 5gb\n/swap - 1gb\n/home - 5gb\nAfter that, we decide to remove windows. And we have much more space to play with.\nQuestion:\nWhat program can we use, in order to easily change all partition sizes after windows removal?\nThanks in advance,\nMEM\n\nA: I can really recommend gparted, at their homepage you can download a live-cd or live-usb image that can do it all in a nice easy to use gui tool. You have to boot from some live disk since you cant resize a partition that is already mounted.\nThere is some generel documentation/guide to gparted here\n\nA: If you think you're going to end up in this situation, I'd recommend installing from an Alternate CD to start with so that you can use LVM.  LVM will let you add & resize logical volumes later, even while running (except for / which can only be resized from a live cd).\nIf you're already installed and in this situation, boot from a live cd and use GParted, which I think is included on the live cd.\n\nA: QTParted should do the trick for you.\nhttp://qtparted.sourceforge.net/\n", "Q: Blank screen, blinking cursor on boot Occasionally my Ubuntu 10.04 PC won't boot properly.  It gets past Grub and then stops at a blank screen and blinking cursor.  From what I've read, this blinking cursor screen is presented by Ubuntu itself and not Grub, so I assume the boot process gets halted for some reason.  Has anyone any guidance on how to diagnose this issue or what the cause is likely to be?  Normally I need to press the reset button to reboot the PC and often it will reboot fine.  The fact that it is intermittent is what confuses me.\nAny pointers on diagnosing the problem would be much appreciated.\n\nIt's been a while, mainly because my server has been up for a long time.  It looks like I've captured a recurrence of this issue, I copied the messages file and the dmesg file and had a look where processing seems to have stopped and found the messages below.   I'm going to do some research on Google etc. but figured I'd put it up here in case anyone can help and wants to earn themselves some points.  I should mention that the ondemand governor failed message happens on successful boots but the other two don't appear to.\nOct 11 23:17:21 linux kernel: [   98.905370] ondemand governor failed, too long transition latency of HW, fallback to performance governor  \nOct 11 23:21:48 linux kernel: Kernel logging (proc) stopped.  \nOct 11 23:21:48 linux rsyslogd: [origin software=\"rsyslogd\" swVersion=\"4.2.0\" x-pid=\"697\" x-info=\"http://www.rsyslog.com\"] exiting on signal 15. \n\nI found a few vague references to rolling over of logfiles at boot time being the cause.\n\nA: In my case, the blinking cursor was all I would ever get. No boot. It was upon installing a fresh Ubuntu Minimal. I figured out that during the GRUB installation step, it was installing GRUB onto the wrong drive, the \"first\" drive (/dev/sda).\nMy system has 3 drives. Two 500GB drives in RAID, that I didn't want to touch during installation, and a 120GB SSD that I use for the OS. For whatever reason, the \"first drive\" (/dev/sda) is one of my 500GB drives. /dev/sdb is my 120GB drive and /dev/sdc is the other 500GB drive.\nSo, when formatting with a partition table of \"mbr\" on my 120GB drive, I did the normal 117GB of bootable ext4 and 3GB of swap. On the GRUB installation step, DO NOT choose Yes to put GRUB onto the \"first\" drive. Choose NO. This will bring up another screen that allows you to input /dev/sdX. In my case, I tried /dev/sdb and /dev/sdb1, but the installer would give me a fatal error every time, which still makes no sense.\nFinally, I had to format my 120GB drive with a partition table of \"gpt\". With GPT, you have to manually create a GRUB partition. That's the way things are done with GPT. So, the first partition I made for GRUB was 32.0 MB formatted for \"boot or something (forget wording)\". Second partition was my 3.0 GB formatted for \"swap\", at the \"end\". Third partition was the remaining space formatted as \"ext4\".\nNow, when choosing NO during the GRUB installation step, manually input /dev/sdb, not /dev/sdb1 surprisingly, and it then works. GRUB installs into the 32MB boot partition on the correct drive and the system boots normally. YAY!\nBTW, you have to choose Expert install from the menu at the beginning of the installation to do all this and format your HDD \"manually\" not \"guided\". Guided will always choose /dev/sda as the first drive and blinking cursor/no boot will result if /dev/sda isn't your OS drive.\n\nA: Hold shift during boot, then hit E to edit the GRUB entry.  Remove the part that says quiet splash and replace it with text to see what's happening during boot.\n\nA: I have had this problem in the past, and found that it appears to happen on some kernels and not others although I have not had this issue since upgrading to Meerkat. But often times I found I would have to select a prior Kernel to load into Ubuntu properly.\n\nA: Another thing I'd check is that your hard drive is healthy.  Check in System > Administration > Disk Utilities, look at the SMART status, it should be Disk is healthy, otherwise your drive might be failing.\n\nA: I've had that problem quite a few times now, but I could distinguish at least three different variants:\n\n*\n\n*resumes boot after pressing Enter\n\n*resumes boot without doing anything, after a while\n\n*never resumes boot, but accepts ctrl-alt-del, indicating that there's still some life in the kernel\n\nThis has led me to believe that when you see what you're describing, the actual problem is that the quiet boot option is hiding something from you. For instance, I could track down one of my incidents to the system recovering (not the usual routine check) my harddisk. I have since removed the quiet option from my grub entries.\n\nA: I had this problem with a new install of 11.10 server.\nI was able to switch to a VT with alt-F1, so the machine was alive but had switched to vt7, despite no X being enabled.\nI fixed it by altering GRUB_CMDLINE_LINUX_DEFAULT options from quiet splash to nomodeset which meant I got the proper boot information, followed by VT1.\n\nA: Verify your disk drive is seated correctly (especially if you are fooling around with your hardware). We just solved this problem because my admin came into my lab and popped out the disk drives and popped them back in and everything booted up nicely! I was swapping the drives between machines and being way too delicate when re-seating them, so they weren't fully connected to the machine, hence no Operating System to load.\n\nA: I encountered this issue and it turned out the problem was my hard drive being 100% full. Steps I took to troubleshoot and finally fix this were as follows:\n\n*\n\n*Boot to blinking cursor\n\n\n*Press Ctrl+Alt+Fx to enter Ubuntu's tty virtual console screen, where x is anything between 2 and 6. In my case I did Ctrl+Alt+F2\n\n\n*Log in using your username and password.\n\n\n*Type in df to check the storage and if indeed there is no more free space\n\n\n*If storage is the issue, clear some space by deleting unnecessary files.\n\n\n*To ensure kernel/grub settings are also not an issue, edit them settings by going to the grub settings file:\nsudo nano /etc/default/grub\n\n\n\n*Edit the GRUB_CMDLINE_LINUX_DEFAULT line in the grub settings file to say\nGRUB_CMDLINE_LINUX_DEFAULT=\"nomodeset noresume\"\n\n\n\n*Update grub settings sudo update-grub\n\n\n*Reboot by typing in reboot\n\n\n*Boot to blinking cursor and wait, it should now bring you to the login page! :)\n\nA: I had a similar issue in the past using the recommended version of a proprietary nVidia driver with a certain video card.  The solution was to boot into recovery mode, run the xfix option, then boot into the desktop.  Once in the desktop, I would go into the hardware drivers screen and select an older version of the driver.\n\nA: In my case for the above description (sometimes getting a black screen with a blinking cursor), lightgdm having a race condition and not being able to start properly was the issue; see my full answer to this other related question.\nSee the details of the solution here: http://www.webupd8.org/2013/01/ubuntu-lightdm-black-screen-when-using.html (see also this bug report).\nThe gist of it: Use gdm and not lightgdm (i.e. sudo apt-get install gdm, and choose gdm as default login manager when asked).\nHope this helps someone.\n\nA: I had this problem on some cheap HP notebooks with 10.04. I observed that often USB mouse is the cause. Try unplug it. And also, BIOS update may help.\n\nA: I experienced this problem today..and after several vain attempts to boot the system, I decided to boot in from a different Kernel. I have both 2.6.32-21-generic kernel and 2.6.32-25-generic, which is provided by Ubuntu. Usually I'm booting in from the 2.6.32.25 Kernel, but after the whole blank screen fiasco, I booted from 2.6.32.21 Kernel, and that allowed me to boot as usual...\n\nA: This is what I did wrong: I was installing 14.04 on to an old Acer Netbook, when I boot the Acer I have two options F2 to go into the BIOS to reset the boot sequence for the computer or F12 to reset the sequence for one session. Because I was installing from a memory stick, I stupidly reset the computer boot sequence instead of the session sequence to the memory stick. So the crucial boot files were installed onto the memory stick instead of the harddrive.  \n\nA: Advice:\nIf you have more than one hdd or SSD, take out (disconnect) all the rest but the one you need to install linux. More than one hdd/ssd, will bring the risk that the installer can go wrong or could install grub to another hdd than the one you are installing linux.\nProbably, the installer tend to go for the first hdd (the \"sda\") even you choose another.\nMy story:\nAfter installing Linux Mint 20 with success to a pc with a single hdd, I replace that hdd with other 2 hdd in the same pc, and I install Linux on the second hdd of this two. At the boot, I get an error about grub and a message: \"no such partition\".\nI reinstall again, choose new partition table (erase the disk) and on the boot I get the nice black screen and blinking cursor.\nReading here, I find that the installer is installing the grub on the first hdd, so I take out the first hdd (the \"sda\" which is not for linux) and I keep it only the second (the \"sdb\") to install linux. So, the old \"sdb\", become the \"new\" sda.\nAfter another reinstall, the boot was finally ok.\n\nA: In my case, it was due to the firewall. I opened the TTY console with Ctrl+Alt+F2 (or any function key from F2 to F6), then uninstalled firewalld and ufw\n\nA: This solution arises in ubuntu 20 when I updated nvidia-driver from additional driver.\nThe solution is\nfirst, got to grub menu\nIn the GRUB menu select the (recovery mode) entry and let the system boot.\nChoose root option\nRecovery Console must first be made Read/Write.\nPurge driver and reboot\nmount -n -o remount,rw /\nsudo apt-get purge '^nvidia-.*'\nreboot\n\n", "Q: When an application crash without output an error, is there a log that i can check? Sometimes it happen that some application crash without give no output error (conky in my case, probably is one of my configuration that is incorrect).\nIs there somewhere a error log that I can check to understand why it is crashed?\n\nA: crash files go into /var/log/crashes/ for use with apport to report bugs.  You can extract a core dump with apport-unpack, put that core dump through gdb, and find out what's causing the program to crash.\nThis is all assuming you're a programmer.  If you're not...well, you can't fix the crash anyway!\n\nA: For conky it could also be that there are entries in $HOME/.xsession-errors.\n\nA: Some applications have flags that can be used to turn on debugging, such as -d, -D, --debug, etc.  Check the application's man page (man [my-app]) or run the app with the -h flag to see if it has such an option.\nMany GUI apps write into $HOME/.xsession-errors so that's a good place to check for output.\nmaco's right that apport is probably the most sure-fire way to get good debug info.  Sometimes it doesn't capture the crash, though.\nIf all else fails, you can also force the info out of it by running the app in gdb.  It'd be something like:\n$ gdb my-app\n\n(gdb) run\n\n... do whatever is needed to get it to crash ...\n(gdb) bt full\n\nand go from there.\nIf you go the gdb route you'll also want to install symbols, as mentioned previously.  See https://wiki.ubuntu.com/DebuggingProgramCrash for handholding advice.\n\nA: Depends on the application. Different applications have different logging systems; there's no one central log that contains all the output from all the programs that run on your system.\nThat being said, a lot of programs do put their log files in the directory /var/log. The file /var/log/syslog (or maybe /var/log/messages), in particular, contains output from the \"system logger\", which is a service made available by the system that programs can use (if they choose to) for logging. But not all programs use it. Mostly, you'll find messages from low-level system services in that file, not the graphical applications you probably use normally.\nYou may want to read more about the locations of standard log files.\n\nA: you can go to /var/log/messages or crashes then you can run the grep command on those and search for the application your looking for the files can get pretty big sometimes. It will return information relevant to your applicaton. :)\n\nA: If you are launching your application from a .desktop launcher file, add the option Terminal=true to your .desktop file.  This will open up a terminal when you run the program, output on the terminal will be similar to what you'd see if you had run the program via the command line in the first place.  This way, when the GUI crashes or hangs, you can see what text output was leading up to it.\n", "Q: How to change \"Menu Key\" to Ctrl I know the easy ways to remap caps lock, etc, but I haven't found out how to change my Menu key to be an additional Ctrl key. Anyone know how to do this? Thanks.\n\nA: I'm kinda guessing based on how I've remapped Caps Lock before, but...\nCreate a ~/.Xmodmap file containing:\nclear 135\nkeycode 135 = Control_R\n\nI'm using 135 because that's the keycode xev told me on my keyboard when I hit menu.  Yours may vary.  Log out & back in to take effect.\nsetxkbmap -option ctrl:menu may work if this doesn't.\n\nA: Finally got it!\nMaco was close. The solution is (in .Xmodmap):\nremove Control = Control_R\nkeycode 135 = Control_R Control_R Control_R Control_R\nadd Control = Control_R\n\n", "Q: Access server by host name? I have a mixed network with mostly Windows machines, a Mac, and a few Linux boxes.  There is no DNS or WINS server, and adding one is outside of my control.  If I put a clean install of 10.04 desktop on a computer, then all other machines on the network can get to that machine by hostname just fine.  \nHowever, if I put 10.04 server on the same computer, then the other machines can only get to it by IP address.  The hostname does not resolve.  What do I need to do on the server so that all the other machines on the network can get to it?\n\nA: You have to have a DNS (Domain Name System) server somewhere to handle that name resolution.  Some routers have a DNS server coupled with their DHCP server.  Check your router and see if it has one and it's disabled.  Ubuntu automatically sends the configured host name out to the DHCP server when it requests an IP address, and if the router has an enabled DNS server, it should report that name/IP to the DNS server, also.\nShort of that, you can put the name and IP address of your Ubuntu box in the hosts file on the windows machine in c:\\WINDOWS\\system32\\drivers\\etc\\hosts.  Provided your Ubuntu machine's IP address doesn't change (or change often), that might be a simple, long term solution.\n\nA: This has to do with Avahi, a Zeroconf implementation which advertises hostnames on the local network. \nYou can get started with Avahi on your server by installing the daemon: \nsudo apt-get install avahi-daemon\n\nFrom that point, you should be ready to go. Check out the docs in /usr/share/doc/avahi-daemon/ if you have additional trouble. \n\nA: You configure nmbd with a netbios name and then you can use that netbios name on the local network without knowing the IP address.\nOne time, whilst talking to a Windows SysAdmin that I know, I was surprised to be told that when you plug a Windows PC into the network, even if you don't know the new IP of that machine, you can still find it on the network by using it's Windows name.\nI thought that this was some kind of crazy magic but it turns out you can achieve the same thing on Linux by installing, configuring and running nmbd. This is part of Samba.\nTo find out more, check out this link.\nIt sounds that this is what you are asking about.\n", "Q: Hibernate on Dell Inspiron 1525 I'm ahving a Dell Inspiron 1525.\nI installed there a stock Ubuntu 10. However I can see no \"hibernate\" item in the shutdown menu.\nIs ACPI supported on 1525? If it is, how can I make hibernate work there?\nSolved: my bad, swap wasn't on.\n\nA: Yes, ACPI should be supported on the Inspiron 1525 and hibernate should be available as an option on the shutdown menu.  I don't own a 1525, but do own a variety of other similar Dells (1420, 1425, 1505) all of which have functioning (albeit sometimes buggy) hibernate.\nIt is possible the hibernate feature was disabled for the particular model due to bugs.  That's really the only reason I could imagine it to be missing.  For instance, it might be you have a proprietary driver loaded that can't do it.\nIf you're curious if ACPI is present at all, look in /proc/acpi.\nIf you want to check if hibernate works manually, the kernel command to enable it is:\necho -n 4 | sudo tee /proc/acpi/sleep\nIf that doesn't work then it's likely hibernate is either disabled or not supported.  Check the ubuntu kernel bug reports for your card.\n", "Q: Possible to limit the size of a window (such as a browser window) to exact pixel dimensions? Is it possible set the size of a navigator or web browser window to exact pixel dimensions in Ubuntu?\n\nA: If you use Mozilla Firefox, you can also use the addon Firesizer. It has a small menu where you can select the size or customize your settings:\n\n\nA: If you're using Compiz (installed by default) there is a Window Rules plugin that can do this.  If you need this for web development, then you will be better off with various plugins specific to each browser; otherwise you may find this helpful.\nOpen CompizConfig Settings Manager1 from System → Preferences.  Navigate to the Window Rules plugin in the Window Management category (you'll see #1 below).  In the Size rules tab, add a new rule (#2), grab the criteria by clicking on the window (#3, #4).  Enter the size (you can see I previously added an example rule for Opera at 800x600), and this size will be used when matching windows are created.  You can prevent resizing in the Matches tab (Non resizable windows option) of the same plugin with similar matching rules (i. e. class=whatever).\nThe related and handy Place Windows plugin can be used to specify initial locations for windows.\n\n1 Not installed by default. Install the compizconfig-settings-manager and compiz-plugins-extra packages. You need the second package as it gives the Window Rules option in Compiz.\n\nA: You can right click on the lower right corner of your window and drag it. While you do this the dimension is shown and you can choose the exact size in pixels.\n\nA: No there isn't.\nHowever for FireFox as part of the Web Developer add on there is a window resize menu item for testing pages on different screen resolutions. \nThat resizes the FireFox window to an exact pixel size.\n\nA: For Nautilus you can also change the settings with gconf-editor. Go to apps -> nautilus -> preferences. On the right side there is an entry navigation_window_saved_geometry. Double-click on it and enter a number which fits you most.\n\nA: Many X applications also have a --geometry option that lets you specify the height/width and x/y position.  For instance:\ngnome-terminal --geometry=114x40+1920+547\nAnother tool that can be used is 'wmctrl'.  This allows you to alter properties of already running windows, including position and size.  For instance:\nchideok:~$ wmctrl -l -G | grep Possible\n0x02339ca2  0 558  111  1216 1006 chideok Possible to limit the size of a window (such as a browser window) to exact pixel dimensions? - Ubuntu - Stack Exchange - Mozilla Firefox\nchideok:~$ wmctrl -i -r 0x02339ca2 -e 0,100,100,100,100\nchideok:~$ wmctrl -lG | grep Possible\n0x02339ca2  0 110  146  100  100  chideok Possible to limit the size of a window (such as a browser window) to exact pixel dimensions? - Ubuntu - Stack Exchange - Mozilla Firefox\n", "Q: Why don't shortcut keys change when keyboard layout changes? When adding several keyboard layouts to Ubuntu (lucid), I experienced that any control key combination refers to the \"default\" keyboard layout. \nSpecifically, on a machine I have to prepare for others, I would like to set a default keyboard to a common layout. Me myself, I like to type in dvorak, and therefore set this as a secondary layout (in the System/Preferences/Keyboard/Layouts menu) so that I can switch to it when i am using the setup. \nThroughout the system, the control key combinations refer to the default layout. I.e. to type Ctrl+R for a reverse search in a terminal, I'll have to hit the R key on the common layout. \nAny ideas how to fix this? \n\nA: This is a known bug in GTK: https://bugzilla.gnome.org/show_bug.cgi?id=162726 -- although it is resolved as \"fixed\" based on the comments it seems the problem still exists :-/\nThe problem with this situation is that it is unclear whether it's a bug or a feature: In some (say, for example, Arabic) countries it is rather common to switch between two keyboard layouts during work (say, for programming vs. writing emails in your language). For these users it is more convenient having application shortcuts (like Ctrl+C for copy) always mapped to the same \"physical\" key, regardless of its meaning in the current keyboard layout -- most users have for example the copy&paste combination Ctrl+C/Ctrl+V deeply engraved in their \"muscle memory\". So, there does not seem to be a simple solution or fix that makes everyone happy...\n", "Q: How do I install XBMC? Where can I get XBMC for Ubuntu?\nI have the team-xbmc ppa added however they have no packages, is there an older deb or is there somewhere where i can get the source and build myself?\n\nA: \nFor Ubuntu 12.04 and newer\nClick on the button:\n\nor by simply opening a terminal and typing sudo apt-get install xbmc.\nAfter the release of Ubuntu 12.04 updates should be available in the stable XBMC PPA above and XBMC can be updated by adding the PPA and updating your system.\nsudo apt-add-repository ppa:team-xbmc/ppa\nsudo apt-get update && sudo apt-get upgrade\n\n\nA: The main XBMC PPA has been updated with the latest stable releases.\n\n\n*\n\n*What are PPAs and how do I use them?\n\nA: If you want to compile xbmc in Ubuntu, the following worked for me:\nDependencies\nsudo apt-get install git-core make g++ gcc gawk pmount libtool nasm yasm automake cmake gperf zip unzip bison libsdl-dev libsdl-image1.2-dev libsdl-gfx1.2-dev libsdl-mixer1.2-dev libfribidi-dev liblzo2-dev libfreetype6-dev libsqlite3-dev libogg-dev libasound2-dev python-sqlite libglew-dev libcurl3 libcurl4-gnutls-dev libxrandr-dev libxrender-dev libmad0-dev libogg-dev libvorbisenc2 libsmbclient-dev libmysqlclient-dev libpcre3-dev libdbus-1-dev libhal-dev libhal-storage-dev libjasper-dev libfontconfig-dev libbz2-dev libboost-dev libenca-dev libxt-dev libxmu-dev libpng-dev libjpeg-dev libpulse-dev mesa-utils libcdio-dev libsamplerate-dev libmpeg3-dev libflac-dev libiso9660-dev libass-dev libssl-dev fp-compiler gdc libmpeg2-4-dev libmicrohttpd-dev libmodplug-dev libssh-dev gettext autopoint cvs python-dev libyajl-dev libboost-thread-dev libplist-dev libusb-dev libudev-dev\n\nDownloading And Compiling xbmc\ncd\ngit clone git://github.com/xbmc/xbmc.git xbmc\ncd xbmc\n./bootstrap\n./configure\nmake\nsudo make install\n\n\nUbuntu 12.04(final)\nalthough you can install xbmc in 12.04 via software-center or sudo apt-get install xbmc, for those that want to compile xbmc in 12.04, for whatever reason(Like to see code pass by in the gnome-terminal for that geeky feel) Here is the code which enables said feeling.\nsudo apt-get build-dep xbmc\ncd\ngit clone git://github.com/xbmc/xbmc.git xbmc\ncd xbmc\n./bootstrap\n./configure\nmake\nsudo make install\n\nNote: Reboot after compiling for the XBMC icon to appear!\nSource:\n\n\n*\n\n*XBMC from source - EuroBytes\n\nA: XBMC - HOW-TO:Compile XBMC on Debian/Ubuntu\nI don't know how I missed that! \n\nA: For Ubuntu 12.04 & 12.10 you can use the following PPA from here: XBMC Nightly : Nathan Rennie-Waldock\nsudo add-apt-repository ppa:nathan-renniewaldock/xbmc-nightly\nsudo apt-get update\nsudo apt-get install xbmc\nI recommend this one because:\n\n\n*\n\n*No need to compile anything\n\n*Does not have dependencies issues with other packages\n\n*Solves an audio problem I was having with HDMI\n\n*Performance is MUCH better when having many movies (More than 900+ Movies)\n\n*Searching for Movie Data (Cover Art, Actor Information...) is MUCH faster\n\n*Loading and Reading are better\n\n*Respects Widescreen resolutions\n\n*Sound quality is better\n\n*BAD - It will appear almost daily to update since it is a Daily PPA which is why I recommend that, after downloading it the first time, Disable or ignore the PPA for a week at least. No sense in updating it everyday.\n\n\nThis are the problems I was having with XBMC that came with 12.04. This is because most of this problems are fixed in the Git repository but not yet applied to a stable release. This version however is very stable for me. Tested with 900+ movies, 8000+ songs and 17 TV series. Downloaded cover arts for all, lyrics, subtitles, etc.. No problem, not even one. The remote controller for android also worked perfectly.\n", "Q: Window decoration of emacs23 window on fluxbox is outside screen I am starting emacs remotely over an ssh connection. \nBut on the emacs window I cannot find a way to resize or move it. There is no fluxbox title bar visible, and I guess the title bar is above the visible viewport, because emacs starts vertically with more height than the screen has. The lower border of the emacs window is also below the viewport border, so I cannot resize the window.\nI am starting emacs like this:\nemacs23\n\nThis is the emacs version:\n\nThis is GNU Emacs 23.1.1 (x86_64-pc-linux-gnu, GTK+ Version 2.20.0)\n  of 2010-03-29 on yellow, modified by Debian\n\nThe remote system that runs emacs is 10.04 Lucid Lynx amd64. The local system is running 9.10 Karmic Koala 32 bit and Fluxbox 1.1.1-2 \n\nA: I found a workaround which I post as an answer, but I would prefer if someone comes up with a real solution:\nWhen I start emacs like this\nemacs23 -g 98x36\n\nI get a viewport that exactly fits my screen and all of the fluxbox window decoration is accessible.\nI found out the values 98 and 36 by trying different numbers.\n\nA: One workaround I can imagine is to press Alt, left-click on the window and drag it so that you can see the upper/lower border.\n\nA: You can start emacs in a terminal to start without a GUI. \nHow do you do this?\nOpen a terminal (Ctrl+Alt+T) and enter the following command:\nemacs -nw\n\nMight be convenient if you are using SSH.\n", "Q: Choosing a file system? I'm having a 250gb disk and 4gb ram.\nPlanning to use:\n/ (15GB)\n/swap (8GB)\n/home (the remaining)\n\nMy question is, for root and home, what file system should we choose. I see to many options... should I go for FAT32?\n\nA: You must go for a Unix-filesystem, supporting permissions and inodes, for Unix to work correctly.\nFAT32 doesn't support all the things Unix needs, so it will simply not work well.\nUnless you know exactly what you are doing and/or have plenty of time to spare, I would use the installation procedure suggestion.\n\nA: Absolutely do NOT go for FAT32!  \nYou need a real Linux filesystem to have correct permissions available.  ext4 is the default in Ubuntu nowadays and very good for SSDs.  If you want something with a bit more testing under its belt, go for ext3.\n\nA: NOO FAT32!!\nI would recommend the default ext4 or ext3; here is a summary of their advantages and disadvantages. \n\nA: Definitely use ext3 for root and home.  It's well tested and performance is fine for the vast majority of users.\nfat32 has many, many deficiencies when used with linux as others have pointed out.  For example, it's case insensitive, so it can't tell the difference between \"Foo\", \"FOO\", and \"foo\".\nThe one case where FAT32 has some usefulness (really, the only reason it's available as an option), is for compatibility with Windows such as if you're dual-booting and want to access documents between them.  If you really do need that, I would suggest making a separate FAT32 (or maybe NTFS) partition just for those shared files, and mount it as /srv/Shared/ or ~/Windows or some such.\n\nA: Even Microsoft has walked away from FAT32 these days. Windows machines use NTFS, and I remember hearing about a different low-level file system for small devices coming from MS. People use FAT32 because they're going to plug their thumbdrive into their Windows, their Mac, their Linux and their Blu-Ray player and want something that everything can read. If you're talking dual-boot, there might be some reason to have /home do FAT32 so that both OSes can read it, I guess, but unless that's the case, ext4.\n\nA: For what it's worth, this isn't an easy question to answer, there's allot of different possibilities, but I've been doing some reading on the subject. But there are some consensus points, no matter what distro you're using.\n1) Most distros will provide docs that detail exactly what they recommend.  /,/usr,/swap,/tmp,/boot, /home and /var\n2) Most distros use ext3 or ext4\n3) Most distros won't boot without a root and a swap (minimum)\n4) generally, doing a test install with the default options will show you the minimum of what the distro requires in terms of complexity.\nTo provide a sense of perspective, after chatting a bunch of different people, and perusing a bunch of different blogs and forums here's what I eventually settled on, and am running. a) 250mb boot b) 4gb swap c) 10gb root d) rest (330GB) home  {Ubuntu 10.04}\n", "Q: Blank screen on boot after upgrade from 9.04 to 10.04 with a toshiba tecra a2. Fix? I can boot into recovery via grub and the low graphics mode option works but I don't really know what to do from there to fix it so I can use a proper graphics mode. It is usuable now though some colours are missing.\nAccording to wikipedia the Tecra A2 has 16-64 MB DDR RAM Intel graphic adapter. If that is worth anything. In Windows these are driver details listed in the video properties: Intel 82852/82855 GM/GME Graphics Controller.\n\nA: These problem are usually seen in i8xx chips. Sadly ubuntu has not any proper solution for this. But they have published potential fixes. Just hope one of them work for you.\nAlso check out this post on ubuntugeek.\n\nA: I had the same problem, I tried everything I read on the web and nothing worked. Here is how I got my laptop working (New Dell E5510 with i5 Intel GMA HD Graphics).\n\n\n*\n\n*I had to (and it sounds like you already did) edit grub from a recovery console. This allowed me to actually boot up into a UI. \n\n*Add the xorg-edgers PPA to your apt-sources: https://launchpad.net/~ubuntu-x-swat/+archive/x-updates\n\n*Update your kernel to 2.6.35-14 (kernel image is available in apt-get)\n\n*Change your video driver to \"intel\" in your xorg.conf\nLet me know if you need exact details on any of the steps. This took me about 3 days to figure out (I did multiple installs, tried multiple kernels, and used tonsof xorg configurations). The above is the only thing that worked for me.\n", "Q: How can I fix 'no wubildr' error in WUBI on Windows 7? Good Evening All,\nI just got my HP Laptop Back from the factory and then I tried to install Ubuntu.\nIt got through the whole installation, however, when I restarted and chose Ubuntu a quick screen flashes that says:\n\nTry (hd0,0) NTFS5: no wubildr\n  Try (hd0,1) NTFS5:\n\nThen it quickly goes to the Boot Loader which I am presented with:\n\nWindows 7 (loader) (on /dev/sda1)\n  Windows Vista (loader) (on /dev/sda2)\n  Windows Vista (loader) (on /dev/sda3)\n\nOf course if I click Win 7 it'll go to the main screen to choose between Win 7 or Ubuntu, if I choose Vista, it'll come with an error of sorts.\nThe strange thing is, I looked in my C:/ Drive and I see wubildr and wubilder.mbr\nIdk if it makes a difference but I am running a 64-bit processor. Installed the 64-bit desktop version and am presented with ultra-fail.\nI've gone to: http://ubuntuforums.org/showthread.php?s=4d54a8d3760f6fe805156524b7ab9acf&t=798283&page=1\nBut have had no luck.\n\nA: I never found a real fix for it when I ran Wubi on my laptop. For me, it came down to finding the version of Wubi/Ubuntu that worked. For example, 10.04 (64-bit) refused to install properly, but 9.10 worked like a trooper (until kernel panicked a few days later, but that's a different story).\n\"No wubildr\" turned out to not be a problem in 9.10 -- I just had to wait a couple minutes and then the loading finished fine.\nStrangely, I have no issues running Wubi on my new desktop -- the \"no wubildr\" error doesn't show up at all.\n\nA: It is posible that wubi is looking on the hidden 100MB NTFS partision, that windows 7 some times makes, instead of your C drive.\nThat you are getting two bootloader steps one with Vista options sounds like you have installed grub in the normal fashion.\nI strongly advice you to use the CD installation for Ubuntu, on this setup, instead of Wubi.\n\nA: I would make sure your ntfs is clean.  Can you boot into your livecd and run a sudo ntfsfix /dev/sdaX where sdaX is your drive/partition (if this isn't installed, you can install the ntfsprogs package.  If you don't know what your drive was assigned, you can run sudo fdisk -l.\n", "Q: My home directory just goes away. Why? I'm running an older Dell GX280, with a new 500GB drive and 2GB RAM. Fresh install with my ~ directory copied from an older HD I got the 500GB to replace. I think I'm running ext4 on both my / and /home partitions. \nAnd, if I run for a few days, I lose my ~/ directory. By which I mean, I can do anything with any file and directory in ~/ if I know what I'm looking for, but if I do ls, or try tab-completion, or try to view it in nautilus, it hangs. Then, I reboot, and everything is back together. \nWhat is it? Where do I start looking for problems? I don't know where to start Googling for the answer.\nHere's my /etc/fstab\njacoby@oz:/var/log$ cat /etc/fstab \n# /etc/fstab: static file system information.\n#\n# Use 'blkid -o value -s UUID' to print the universally unique identifier\n# for a device; this may be used with UUID= as a more robust way to name\n# devices that works even if disks are added and removed. See fstab(5).\n#\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>\nproc            /proc           proc    nodev,noexec,nosuid 0       0\n# / was on /dev/sda1 during installation\nUUID=4f677505-0b67-47b0-bbb4-858ffc1fe125 /               ext4    errors=remount-ro 0       1\n# /alt was on /dev/sdb1 during installation\nUUID=b0eec90c-d312-4123-b78c-7487a3347888 /alt            ext4    defaults        0       2\n# /home was on /dev/sda6 during installation\nUUID=1def350e-fe9a-40e3-8162-0a9f7ff8d5ef /home           ext4    defaults        0       2\n# swap was on /dev/sda5 during installation\nUUID=e62cd8c5-6088-44a8-84a6-7d399e42d81d none            swap    sw              0       0\n/dev/fd0        /media/floppy0  auto    rw,user,noauto,exec,utf8 0       0\n\n\nA: Here's one thing I can think of that could explain your symptoms. If you have a mount point to a “flaky” filesystem, or a symbolic link to a mount point to a flaky filesystem, in your home directory, then most methods of listing your home directory could hang (including ls -l, ls -F, ls --color, but not plain /bin/ls) waiting for that flaky filesystem.\nPossible examples of flaky filesystems:\n\n\n*\n\n*An NFS/Samba mount where the server is not responding. This is mostly observed in unix enterprise environments.\n\n*A fuse mount that's hung on .\nUnmounting the offending filesystem may help; umount -l or umount -f may be useful in desperate circumstances (read the mount man page before using these options). For a fuse filesystem that's waiting on a process that isn't responding, try umounting with fusermount -u (or fusermount -uz if there are open files), and killing the non-responding process.\nTip: don't mount this kind of filesystems under a directory you traverse often, such as your home directory. Have a dedicated parent directory for such mount points, e.g., ~/mnt. The same goes for symbolic links that point into these filesystems.\n", "Q: Cloning Textmate's functionality with Vim Tips and advice on how to clone Textmate's functionality in Ubuntu. I've done some research on this in the past and I know this information is valuable to the community.\n\nA: snipMate.vim\nFor Textmate style snippet expansion in Vim.\nhttp://www.vim.org/scripts/script.php?script_id=2540\n\nA: Command-T\nThe Command-T plugin is un-do-without-able. It replicates TextMate's Go To File... functionality very nicely, plus of course you can set your own keymapping, and have files open in split windows, tabs, etc. \n\nA: NerdTree\nFor file exploration in Vim.\nhttp://www.vim.org/scripts/script.php?script_id=1658\n\nA: If vim is not a requirement (in the title you said Vim but in the text you said how to clone textmate in ubuntu) you should take a shot on emacs.\nIn emacs you can have a closer textmate experience, with a snap-open (ido-mode) snippets with yasnippet (compatible with textmate snippets) and an editing style a little closer to what you get on textmate.\n\nA: Fuzzy Finder was written by someone returning to Vim from Textmate.  \n\nA: try this Coming Home To Vim\n\nA: pathogen.vim\nReplicate TextMate's bundle functionality. After installing pathogen, you can drop plugins into a 'bundle' directory, pathogen manipulates vim's runtimepath so everything gets loaded.\nThis is especially great for using vim plugins which live on github. If you keep your config in a git repo, you can use submodules to help you keep everything up to date.\nhttp://www.vim.org/scripts/script.php?script_id=2332\n\nA: i've used vim and all its plugins brother if you want a more cooler experiance and you dont want to spend all your time learning just the editor  try gedit-plugins available in repo and check its site too \" best for programming \" :) ubuntu rocks\n", "Q: What is the Gnome equivalent to KDE KControl? I'm looking for the gnome equivalent program to kControl.\nI'm reading some online stuff and it says now run kControl, but I'm on gnome, so what is the program for gnome that serves the same purpose.\n\nA: You're looking for gnome-control-center. Its not exposed in the UI, but you can access it via the Run As dialog or the terminal. \n\n", "Q: Why 60+ console-kit-daemon processes? I have over 60 processes of console-kit-daemon that won't stop reappearing after I've used sudo killall console-kit-daemon. I have no idea what the daemon is for. \nI'm running ubuntu 10.04. What's going on?\n\nA: They're not processes, they're threads under one process. \nBy default htop shows threads and in this case, is very misleading. You can alter this by going into Setup (F2), Display options and checking Hide userland threads. \n\nPress F10 when you're done.\n", "Q: How to set up two screens in one vertical-one horizontal formation? I've tried to set up that configuration a lot of times, but I'm not able to make it work properly. I want to set up one of the screens as vertical and the other one as horizontal...\nI'm able to use then both as vertical or both as horizontal...\nPD: I have an NVidia card, I've talk with people that have ATI cards and appears to be easier...\nPD2: I'm using Ubuntu 10.04\n\nA: You can probably use the xrandr tool for this (assuming that your driver supports the xrandr extension - I guess most do).\nTo check what monitors are connected and if xrandr works just type in a terminal\nxrandr\n\nOn my system I get for example:\nLVDS1 connected\n[..]\nDP2 connected\n1920x1200 [..]\nNow you can configure the placement etc. of the different outputs.\nFor example:\nxrandr --output LVDS1 --mode 1280x800 --output HDMI2 --mode 1600x1200 --left-of LVDS1 --rotate left\n\nThis configures two screen side by side, the laptop-sceen is placed on the right of the external TFT and the TFT screen is rotated by 90 degrees (portrait mode).\nTo switch between different external monitors, often you need to switch one off, e.g. with\nxrandr --output HDMI2 --off\n\nbecause a lot of graphic cards just support 2 outputs enabled at the same time.\n\nA: I believe the this blog post discusses the affect your trying to achieve.  :)\nYou also might want to check out Xinerama\n\nA: I don't have enough rep to comment yet but I'd like to mention that although @garbagecollector's link is relevant, I believe that Ubuntu stopped using a default xorg.conf in 9.10. However I'm lead to believe it will respect an xorg.conf file if it exists.\nHere's a link I stumbled upon to use an xorg.conf file again:\nhttp://www.osguides.net/operation-systems/217-how-to-create-xorgconf-in-ubuntu-910.html\n", "Q: Is there a terminal/command-line interface to the 'Appearance Preferences' dialog? Hopefully the title sums it up, but I'm looking for a way of being able to switch the Appearance Preferences' Visual Effects option to 'None', from a terminal/script (and optionally later to be able to switch back to 'Normal', though that's not such a big deal).\nI'm a total Ubuntu-noob, so I can't tell you which window manager/widget-set/whatever I am using (Gnome 2.30.0?). It's on Ubuntu 10.4 patched up to date as of late July 2010.\n\nA: If all you need to do is to disable and enable effects this is fairly easy done with\nmetacity --replace\nto disable effects and \ncompiz --replace\nto enable effects. This is scriptable too.\n", "Q: Can I make PDF the default for 'print to file' I am using 10.04 and I use the 'Print to File' feature a lot but it's annoying to have to change the output option to to PDF each time.  Is there a way to make it the default? \n\n\nA: You can install the cups-pdf package, add a new printer of the type \"Generic CUPS-PDF Printer\", and then make that the default printer.\nI don't use this myself, so I am not sure if the quality of the PDFs that creates is different (for better or for worse) than what the \"save to file\" feature provides though.  (Maybe you can comment here on your experiences with it?)\n\nA: Here's how I made PDF the default:\nMake Print-to-File default to PDF in Firefox.    \nFirst, open Firefox, then:\n\n\n*\n\n*about:config\n\n*print.print_to_filename\n\n*/home/user/Desktop/mozilla.pdf\nIf the above instructions do not work, continue with the following:\n\n*Print something from an installed printer using Firefox (entry may not show otherwise)\n\n*about:config\n\n*Type \"print_to_filename\"\n\n*Identify the entry that has the exact name of the printer attached to your computer\n(e.g., print.printer_Canon-xxxx.print_to_filename)\n\n*Change the Value to: /home/user/Desktop/mozilla.pdf\n\n\nA: I did some looking around interesting question. There is some discussion on Ubuntu forums. \nHere are a couple of link I found useful, they seem to be talking about firefox method of changing it! I hope this helped you. :) \nHere is the blog post on the topic as well as couple of Ubuntu forum links discussing the topic.\n", "Q: Locking updates to a specific mirror My ISP offers a freezone Ubuntu mirror (http://ftp.iinet.net.au/pub/ubuntu/) however Ubuntu is constantly pulling updates from a US server that is\n\n\n*\n\n*slower\n\n*not inside my freezone\n\n\nHow can I force Ubuntu to use my local, freezone mirror before using others?\n\nA: Go to the menu System > Administration > Software Sources. There is a drop-down box labled \"Download from:\" where you can choose a mirror near you.\nIf this doesn't work as planned (might not since you have a \"custom mirror\") then you can edit the file /etc/apt/sources.list by typing sudo gedit /etc/apt/sources.list in a terminal and pressing enter, if you need help you can type man sources.list in the terminal.\nA source of the unwanted traffic might be from security.ubuntu.com this is where the security updates comes from, they can be turned off, but it's not recommended! \n", "Q: How do I output my audio input? A few iterations ago, I think this was Jaunty but could've been before, I would plug a 1/8\" audio cable from the line-out of a Windows netbook to the line-in of my Ubuntu machine, so I would have all the sound from both machines without having to plug both into a mixer which I don't have. I didn't do this much, as I was pretty-much happy with Banshee at the time. But with Karmic, and still with Lucid, I can only get the output if I'm recording with Audacity. Which I'm not going to do from my web-development and systems programming workstation.\nI can tell by plugging in headphones that my netbook has audio out working. I can see Sound Preferences that the Ubuntu machine is receiving them. I just want the old behavior back. Help?\n\nA: If you want to use existing pulse-audio tools, use pacat (which stands for pulse-audio cat).\nget your input device with\npactl list\n[...]\nSource #0\n        State: SUSPENDED\n        Name: alsa_output.pci-0000_00_1b.0.analog-stereo.monitor\n        Description: Monitor of Built-in Audio Analog Stereo\n        Driver: module-alsa-card.c\n[...]\n\ncopy the 'name' part \nand use it with pacat :\npacat -r --device=alsa_input.pci-0000_00_1b.0.analog-stereo | pacat -p --latency-msec=1\n\nwhere as device is the name you copied before. \nThis will cost a bit of CPU time (3,3% on my machine). \nYou can also pipe some audio converting software in between to filter, or use it over the network.\n\nA: If I understand correctly, you're trying to stream the microphone input to the audio output? The simplest I can think of is to use gst-launch for that. Open a terminal and type:\ngst-launch pulsesrc ! pulsesink\n\nThe press CTRL+C to stop streaming. You may have to install the gstreamer tools to have this available:\nsudo apt-get install gstreamer-tools\n\nNote that as I don't have any suitable audio source, I didn't actually try that so it may not work. Any feedback on whether it does would be appreciated.\n\nA: Bruno Girin's answer worked for me as well, but manually launching a process is somewhat annoying as this should just be automatic. A better solution is to install gnome-alsamixer and unmute the line-in option, as described here:\nNo sound from line-in\n", "Q: Web Server Best Practices: Directory Structure & Security I would like to utilize Ubuntu server as web server, but I want to make sure I follow best practices for setting things up.  I want to ensure I set the directory up in the best location and understand how to configure the appropriate security on that folder.  I would like to be able to FTP to the server and push files into the web folders, so I would like to under stand how to ensure that my PureFTPd user can manipulate files/directories within the web folders.\n\nA: What I did on my server so that my user could sftp things straight into /var/www is:\nsudo chgrp -R www-data /var/www\nsudo usermod -aG www-data $(whoami)\nsudo chmod -R 775 /var/www/*\nsudo chmod 2775 /var/www\n\nThis will put your user into a group that has group ownership on /var/www and all its child directories, set everything in /var/www recursively to allow your group write access, and set the setgid bit on the /var/www directory so that all files later created under /var/www maintain the same group ownership rather than having the group set to the creator's primary group.\n\nA: This is a very general question.\nObviously, you don't want to run your web server as root. However, the Ubuntu install already does that in the right way.\nFurthermore, on the apache website are some tips how to properly configure your directory. \nIn regards of ftp. You want to make sure you use a secure ftp server that does not send your usernames and passwords in plain text over the network. The Ubuntu help pages have a tutorial how to set up such an ftp server.\n\nA: When I have just an Ubuntu server, with multiple users using the server as a web server I scrap the /var/www directory because to me - /var/www is where you put web files globally. I update the /etc/skel directory and add a public and private folder with a symlink www -> public and update all my virtual hosts DocumentRoots to point to /home/<user>/public.\nI don't see /var/www as the place to put multiple user-level folders and files. That's what the /home/ directory is designed for! It keeps paths and directory structures clean.\n", "Q: Best way to clone an installation (copying to identical hardware) Kind-of like this question but slightly different (I think), in that I have 6 identical Acer Aspire Revo R3610 machines. One is (almost) configured to my requirements - when I'm done preparing it I'd like to make the other 5 machines absolutely the same. I'm very new to Ubuntu, what's the most straightforward (easiest) way of doing this?\nThe machines are going to live on different networks if that might otherwise be a problem (eg with Windows you can clone disks but you then have to make registry changes afterwards if they're going to run on the same network etc). The hardware in all 6 machines is, I stress, the same!\nHow can I efficiently clone one source image on to these identical machines?\nPlease restrict one software/solution per answer\n\nA: The easiest way to do this is to run a bare bones Ubuntu installation on your hard drive, install VirtualBox and set up a virtual Ubuntu machine.  Run your virtual machine and set up that installation just like you want it with all the bells and whistles you want.  Do all of your working and playing on the virtual computer.\nVirtualBox maintains the virtual machine as a large disk image file (.vdi) along with a few other much smaller configuration files.  Whenever you want to backup your virtual machine, just shut it down and copy its directory to your backup location.  I use a Passport external drive for this purpose.  \nRight now, there is both a Windows 7 and an Ubuntu 12 virtual machine on that external drive.  All of the system updates, programs, personal files, pictures, whatever, get saved in those virtual machines.  A backup of this type is very fast, as one big disk image file will transfer much quicker than a bunch of individual files would.  Since VirtualBox maintains the files in that format all the time, the virtual machine is always configured to be backed up.\nOne advantage of that setup is that I can run those virtual machines off the external drive on any computer with VirtualBox installed, so now, instead of lugging my computer all around, I just bring my external drive with both Windows and Ubuntu, install VirtualBox on whatever computer I plan to use (I have all the VirtualBox installation files also on my external hd - they are available for all the main operating systems), and I am ready to go.  I can either copy my virtual machine to the computer I am using, or just run it off of the external drive.\nIf your computer crashes and dies at some point, who cares, you just grab your Ubuntu installation disk, install it on your new or repaired computer, hook up your external drive, install VirtualBox, and copy your virtual machines back on to your computer - problem solved with minimal stress, loss of time, and loss of data.  How much data you lose depends on when you last backed up.  For myself, I do a new backup whenever I make a major change or add a hard to get program.  Just make sure that your virtual machine is operating normally when you do it.  You would not want to copy a corrupted machine over a good one.\nAnd no, I don't work for VirtualBox.\n\nA: Create an image using Remastersys, transfer it to a pen drive using the Startup Disk Creator utility and install on other system.\n\nA: Clonezilla sounds like it fits your needs\n\nA: Partimage\nAnother great cloning utility which I've used, as well. Features a terminal gui.\n\nA: I would get one computer all the way you want it, and install the openssh-server package. Generate a ssh key pair with ssh-keygen -t rsa. Add the public key to /root/.ssh/authorized_keys2. Then I would boot the new computers with a live cd and plug in a usb stick with the ssh private key. Use gparted to create a new partition. Then mount the new partition and run something like sudo rsync -avzx -e \"ssh -i /media/disk/path/to/privatekey\" --exclude=\".gvfs\" root@<ImageComputerIP>:/ /path/to/new/partition/\nUse the blkid command to find the UUID of the filesystem you just created. Edit the /path/to/new/partition/etc/fstab to reflect the new UUID (and filesystem type if you used a different filesystem.)\nThen I would follow the instructions on https://help.ubuntu.com/community/Grub2/Installing#via_ChRoot about how to install from a chroot.\nA simplified version of that page (which doesn't account for lvm, software raid, or bcache, or separate /boot like the wiki page does):\n\nMount the critical virtual filesystems. Run the following as a single command:\n\nfor i in /dev /dev/pts /proc /sys /run; do sudo mount -B $i /mnt$i; done\n\n\nChroot into your normal system device:\n\nsudo chroot /mnt\n\n\nReinstall GRUB 2 (substitute the correct device with sda, sdb, etc. Do not specify a partition number):\n\ngrub-install /dev/sdX\n\n\nRecreate the GRUB 2 menu file (grub.cfg)\n\nupdate-grub\n\n\nExit chroot: CTRL-D on keyboard \n\nBy the way, this works good for backup, too. Ubuntu, unlike Windows, doesn't seem to have problems being transplanted to different hardware. I've put hard disks from one computer in another and it did fine, and I've copied installs to different hardware and it did fine.\n\nA: I use ddrescue for exactly this task. It works flawlessly. Super simple.\nSee this thread on technibble for details\n\nA: dd\nA low level copy using dd would do the trick!\nWatch out for conflicting IP addresses and hostnames.\nBasically put the source drive and destination drive in the same machine, boot into a live cd.  And run something like the following where /dev/sda is the source and /dev/sdb is the destination:\ndd if=/dev/sda of=/dev/sdb bs=4096\nI remember the operands by:\nif -> input file\nof -> output file\nbs -> block size (how many bytes to read at a time)\n\nA: G4L\nGhost for Linux\nGhost for Linux is a hard disk and partition imaging and cloning tool similar to Norton Ghost(c) and (tm) by Symantec. The created images are optionally compressed, and they can be stored on a local hard drive or transferred to an anonymous FTP server. A drive can be cloned using the Click'n'Clone function. g4l  supports file splitting if the local filesystem does not support writing files >2GB. The included kernel supports ATA, serial-ATA, and SCSI drives. Common network cards are supported. It is packaged as a bootable CD image with an ncurses GUI for easy use.\n\nA: Fsarchiver\nI don't know why no one mentioned this. This is especially handy when you want to restore the partition's content on another file system type (for example, restoring ext4 content to ext2 or reiserfs) or you want to restore to an smaller partition.\nI used it and it's very easy. For example, to clone a partition say /dev/sda1 you use a command like this\nfsarchiver -A -j 2 -z 1 savefs /media/anwar/USB_Drive/myrootpartition /dev/sda1\n\nThe -A option allows you to copy partition even if it is used! Great feature!\n-j 2 says to use 2 CPU core for compression. Useful for multi-cored CPU and if you use compression\n-z 1 sets the compression level.\nTo restore the file system you used\nfsarchiver restfs /data/myrootpartition.fsa id=0,dest=/dev/sda2\n\nThe id=0 says you're restoring the first filesystem from the archive (Even if you don't saved multiple partitions on a single archive, you need to specify it). And dest=/dev/sda2 sets the destination of the restoring.\n\nA: I do this a lot, using rsync.\nFirst you can run rsync to load all the data to an external hard drive (your external hard drive should be in ext4 - I use this, so I know it works):\nI assume you have two partitions: /dev/sda1 (root) and /dev/sda2 (swap).\nRun in your original computer:\nsudo rsync -avuorpESHAX /* /your/hard/drive\n\nAfter copying the data, boot your next computer with an usb stick, and format the internal hard drive as the original hard drive.\nMount your external drive to /mnt, and copy the UUIDs of all partitions. Edit the UUIDs of the partitions of the new computer and put the same UUIDs you have copyied from the original data (it is in /mnt/etc/fstab).\nShut down the swap:\nsudo swapoff -a\n\nCreate a new swap using the original UUID, copyied from /mnt/etc/fstab:\nsudo mkswap /dev/sda2 -U original-UUID\n\n(I supose your swap is in /dev/sda2)\nNext, change the UUID of /dev/sda1: (the partition should be unmounted in order to change UUIDs)\nsudo umount /mnt\nsudo tune2fs /dev/sda1 -U old-UUID\n\nDone this, mount the destination partition:\nsudo mount /dev/sda1 /mnt\n\nReverse rsync to the destination:\nsudo rsync -avuorpESHAX /media/your-backup /mnt\n\nReinstall the grub:\nsudo grub-install --root-directory /mnt /dev/sda\n\nThis will work.\nRemember to edit /etc/hostname and /etc/hosts to change the hostname for each machine in order to avoid network conflicts.\n\nA: Having never done been in this predicament (I don't have hundreds of servers - I've always just used base images), I can only give you my gut instinct.\nThat aside, I would say netboot is probably your best bet. Create a master server, get it doing what you want and then have all your other machines boot and install from it. Scripting things to happen automatically (ala run-once) shouldn't be too hard. You do all the secondary things through kickstart.\nMore (although it's a little old): https://help.ubuntu.com/community/PXEInstallServer\nEdit: There's an application called system-config-kickstart that should help make generating the kickstart file quite a bit easier. YMMV.\n\n\nA: Another option for mass-installs is the Ubuntu Landscape/private cloud approach where you (basically) provision servers dynamically based on a pool of hardware. Clever stuff.\n", "Q: Run iTunes without virtualizing Windows? I know I could use VirtualBox or VMWare, but does anyone know of a way to run iTunes without having to run Windows virtually on Ubuntu? \nWill iTunes run using Wine?  Is there a better more native way to run iTunes?\n\nA: Use Banshee to import all meta data from itunes! \nIn Banshee, Import > Itunes library > navigate to the itunes file - and voa la!\nThis made my switch from itunes to ubuntu a cinch.\n\nA: iTunes on Wine is the closest thing to \"native\" you'll get but it's not supported very well and you won't get device syncing.\niTunes through VirtualBox is probably going to give you the highest quality experience.. You'll probably be able to use devices (read: iPods, iPhones, iRacks, etc) as you would with a real Windows install. It's just heavy.\nI do wonder why you want to run iTunes. If it's just for purchasing, playing and syncing audio files, there are alternatives (Rhythmbox, Banshee, Amarok, MPD+Frontends, etc) that are arguably better and are truly native applications. They just take a little getting used to.\n\nA: You can use itunes with either wine or PlayonLinux. PlayonLinux is best as performance wise. For installation instruction  see \nhttp://freshtutorial.com/install-itunes-ubuntu-linux/\n\nA: Unfortunately, everything I've read says this isn't possible. Your best bet is still a virtual machine or use Rhythmbox.\n\nA: http://appdb.winehq.org/objectManager.php?sClass=application&iId=1347\nAs the answer is to any question about Wine, kind of.\nYou could try, say, Songbird or something. Not really a satisfactory replacement for me, but, it's something.\nMeh, I had a hard time finding the right media player for Windows. I won't even try on Ubuntu.\n\nA: Ubuntu 10.04 should allow you to sync and manage your iPod or iPhone with Rhythmbox.\n", "Q: How to calibrate my touchscreen on a HP Pavilion tx2500? I have a laptop (HP Pavilion tx2500) with touchscreen functionality, it works fine but isn't calibrated, what is the best way to do it?\n\nA: Quotation from http://ubuntuforums.org/showthread.php?t=1478728#4\nThe 10-wacom.conf file that is referenced is the one in /usr/lib/X11/xorg.conf.d/\n\nThe calibration for a TX2500's stylus\n  is:\nOption      \"TopX\"      \"225\"\n    Option      \"TopY\"      \"225\"\n    Option      \"BottomX\"   \"26300\"\n    Option      \"BottomY\"   \"16375\"\n  The calibration for a TX2500's touch is:\nOption      \"TopX\"      \"200\"\n    Option      \"TopY\"      \"225\"\n    Option      \"BottomX\"   \"4000\"\n    Option      \"BottomY\"   \"3875\"\n  The calibration for a TX2z's stylus and touch is:\nOption      \"TopX\"      \"0\"\n    Option      \"TopY\"      \"0\"\n    Option      \"BottomX\"   \"9600\"\n    Option      \"BottomY\"   \"7200\"\n  You can add that to the 10-wacom.conf, or if that\n  fails to a section in xorg.conf.  I\n  think the wacom driver is suppose to\n  auto-calibrate your device.  Often\n  Xorg.0.log in /var/log has the\n  coordinates when the driver initiates\n  the device.\nThe Rotation HOW TO has scripts.\n  Just remember there has been a change\n  in the device name conventions.  Enter\n  'xinput --list' in a terminal to get\n  the new device name and substitute it\n  in the scripts (with the quotes) where\n  it says stylus or touch, etc.  You can\n  also use the device ID numbers.\n\n", "Q: Install installer package on an installed system? I know this will be an odd question, but I was wondering if anyone knew how to install the Ubuntu Installer package in an Ubuntu installation.  To clarify, when you boot up to an Ubuntu LiveCD, it's got the installer program available so that you can install Ubuntu to a drive.  Naturally, this program is not present in the installed Ubuntu.  Is there, though, a way to download and install it like other packages?\nInvariably, someone will ask what I'm trying to do, and the answer is that I don't really know.  I just kinda want to tinker around with the installer and look at it and play with it; no particular reason.  Curiosity, mostly.  Thanks in advance for the help!\n\nA: Try:\nsudo apt-get install ubiquity-frontend-gtk\n\n\nA: If you're looking to tinker with the installer, please do so within the confines of a running live CD, preferably using a virtual machine like KVM.  With some very small exceptions, ubiquity is written in Python, so you can install your favorite editor and modify it in place.\nEqually, if you're aiming to make large changes, you can get the latest copy from revision control by running bzr branch lp:ubiquity.  You can build a set of Debian packages using debuild, then copy them to and install them in the live environment.  Alternatively, you can NFS mount the portion of the ubiquity tree that you're working on in the live environment over top of the existing directory, edit files in the branch on your local machine, then immediately test them by running the installer.\nThe latter approach is a stripped down version of what I use while working on it, and I find it speeds up my development, prevents me from losing changes if the virtual machine goes down, and prevents my changes from becoming out of sync with changes to the branch.\n\nA: Do you mean Ubiquity? https://wiki.ubuntu.com/Ubiquity\n", "Q: How to remove a mounted volume icon on the desktop? Each time my 3G Vodafone k4505 Pen get's mounted by the system, I get a icon on my desktop.\nI would like to NOT have that icon each time I connect this 3g usb pen.\nHow can we accomplish this?\nThanks in advance,\nMEM\n\nA: *\n\n*Press Alt-F2 and enter gconf-editor.\n\n*Navigate to apps/nautilus/desktop.\n\n*Deselect volumes_visible.\n\n\n\nIf you want your other volumes to be visible, you will have to add them manually:\n\n\n*\n\n*Right click on desktop and click 'Create Launcher...'\n\n*Change the type to 'Location'\n\n*Change the name to suit you.\n\n*Browse for the volume.\n\n*Change the icon to the 'block device' icon at /usr/share/icons/YOUR_THEME/devices/48/block-device.svg\n\n*Click OK.\n\n\n\n", "Q: How to change screen brightness on Samsung R519 with nvidia driver Is there a way to set the screen brightness on a Samsung R519 with Ubuntu 9.10 and the nvidia drivers?\nI know that there is a way when using voRia's repository and the nouveau drivers. But switching between one and dual-screen mode takes too much time for daily use on a notebook.\n\nA: *\n\n*Open System → Administration → NVIDIA X Server Settings\n\n*Go to X Screen → X Server Color Correction\n\n*Set the Brightness to your liking.\n\n*Confirm the change by clicking on \"...seconds to confirm\"\n\n\nA: I made a project on code.google.com (script for this issue) \nhttp://code.google.com/p/ubuntu-brightness-laptop-r519/\nJust follow README.\n\nA: If you are using the proprietary drivers, you can install a program called nvclock (to do this you can search nvclock in the Ubuntu Software Centre). \nYou can then go to System -> Preferences -> Keyboard Shortcuts and create 2 new Actions (brightness-up and brightness-down). Set the commands to nvclock -S +5 and nvclock -S -5 respectively. Next choose a shortcut for each command. Normally, you can use your brightness fn keys to do this (eg. on my laptop fn+F7 and fn+F8).\n\n\n\nYou can then use these shortcuts to change the brightness.\nAt any time you can press alt-f2 and enter: nvclock -S x where x is a number that is the percentage screen brightness; eg. nvclock -S 100 sets maximum brightness. You can bind these to shortcuts too and use a terminal instead of Alt-F2 if you wish.\nYou can find out more about how to use the nvclock command by entering man nvclock in a terminal.\n\nA: sudo setpci -s 00:02.0 F4.B=42 (lowest level)\nsudo setpci -s 00:02.0 F4.B=FF (highest level)\nusing the following table:\n(based on:  /proc/acpi/video/GFX0/DD03/brightness )\nBrightness  %      HEX  \n26          30     42  \n34          40     56\n44          50     70\n57          60     92\n69          70     AF\n80          80     CC\n90          90     E5\n100        100     FF\n\nMore details at http://pimslinuxlab.wordpress.com/2009/12/25/setting-the-display-brightness-on-a-samsung-r519-laptop/\n", "Q: Where can I find an application use history? In Windows XP, you can find out how often an installed application was used by going to the Add/Remove Programs section.  You can also get an estimate of how often the application was used.\nIs there a way to do this in Ubuntu?\n\nA: No there's no facility for this that I know of. The closest you could come would be to see how recently files were accessed, but that access could be by any means not just a user running the program. Give this command a try at a shell prompt:\nls -ltu /bin | less\n\nOn my system it shows which utilities I've used most recently (but it also shows which ones were used most recently in cron jobs and scripts). You could do something similar with the files for a particular application, but it wouldn't be very meaningful.\n\nA: Install popularity-contest and run popularity-contest | grep '<OLD>' to find all the relatively unused packages.\nMore info on Debian's popcon README\n\nA: This sounds like something Gnome Activity Journal (Gnome Zeitgeist) could possibly do.  Its supposed to track everything that you do, open files, use apps, browse sites, etc.  With the data being captured, a little filtering the data and a nice UI gets you what you'd be looking for.\nIts under development still, unfortunately.\n\nA: You might try as well running that command on /usr/bin, since most graphical applications' binaries are installed there.\nls -ltu /usr/bin | less\n", "Q: Get lastest version of mono What is the best way to get the latest version of mono on ubuntu?\n\nA: Not sure it's the best option, but i use the repository of badgerports\nAbout badgerports:\n\nbadgerports is a software repository\n  for use with Ubuntu Linux 10.04.\n  Whilst on the whole it is a good idea\n  to use the software provided with your\n  Linux distribution, there are\n  sometimes bugs or major software\n  updates that cannot be included for\n  operational reasons. badgerports is a\n  home for a number of wayward software\n  packages, to enhance the Ubuntu\n  experience.\nThe primary purpose of badgerports is\n  to provide recent versions of the Mono\n  framework, and associated packages\n  such as F-Spot, Banshee, and\n  Monodevelop. Suggestions for other\n  packages to include are welcome, but\n  don't be offended if I decline for\n  whatever reason.whatever reason.\n\nYou can find the instructions on how to use it here\n", "Q: When will GNOME Shell be the default interface? In what Ubuntu release will gnomeshell become the default interface.\n\nA: I've changed this answer based on the new information that was released at the Ubuntu Developer Summit for 11.04.\nFor the foreseeable future, GNOME Shell is not be the default interface for Ubuntu Desktop. The developers are instead developing an expanded version of the Unity shell.\nThere are now a significant number of questions regarding Unity, GNOME 3 (of which GNOME Shell is a component), and planned developments of Ubuntu.\n\n\n*\n\n*Why is Ubuntu 11.04 switching to Unity?\n\n*Will Ubuntu 11.04 use GNOME 3?\n\n*Will there be a difference between Unity “Desktop” and Unity “Netbook” interface?\n\nPrevious answer\nAs far as I'm aware, the answer to this question is \"to be determined\".\nIt is my understanding that final decisions about the details of each release aren't made until the previous release has been completed. The release of Gnome 3 was delayed until early 2011 and Gnome Shell is not planned for 10.10 therefore a definitive answer must wait at least until after 10.10 is released in October. I would guess it will be a topic of discussion at the Ubuntu Developer Summit scheduled for late October.\n\nA: I think ... Never, it will be a desktop version of Unity.\n\nA: I'd guess that since Gnome Shell will not be released until late in the 11.04 release cycle that Ubuntu will hold off from making it default until 11.10. There is a lot of integration that will need to be done to preserve the Ubuntu design work & apply it to the Gnome shell framework.\n\nA: There have not been any published plans for setting it as the default, so at current it is impossible to say.\n", "Q: Can't install openSDK 6 - ubuntu 10.04 While trying to install openJDK to start installing netbeans 6.9 - I'm getting this: \n\nThe installation could have failed\n  because of an error in the\n  corresponding software package or it\n  was cancelled in an unfriendly way.\n  You have to repair this before you can\n  install or remove any further\n  software.\n\nI read it... and I have no clue what to do next. :( \nhow can we repair that?\nI have forget openSDK and I'm trying the java one. All seems to go well... but know I'm stuck here:\n\nAnd here is the amazing question:\nHow can I click or hit, or push or something, that OK?\nArrows, Page Up and Page Down work. \nEnter and Click don't.\nAnyone?\nK. Regards,\nMEM\n\nA: Run:\nsudo dpkg --configure -a\n\nEDIT:\nAs the original message says, you have to repair the error (run the above command) regardless.  However, if you do want to install the Sun JRE, you use tab to get to the OK.\n", "Q: What is the relationship between Ubuntu Single Sign On and Launchpad Login Service? Canonical operates at least two OpenID based login services within the Ubuntu online world: Ubuntu Single Sign On and the Launchpad Login Service. According to the information in the footer of both sites they share the same backing software which is called Canonical SSO provider.\nMy question is whether these two sites are entirely separate implementations or do they share the same user database? Alternatively, is there some other less direct relationship between the two services?\nIn other words, if I didn't have an account with either service and I created a new account with Ubuntu Single Sign On would I then also have a Launchpad Login Service account? What about the inverse scenario?\nI know that the Launchpad Login Service existed earlier than Ubuntu Single Sign On. I also know that I was able to use my existing Launchpad login details with the Ubuntu SSO when it was launched. However, I've never been clear if these are the same account or if my Launchpad account was copied to the newer service and they are now separate.\n\nA: Afaik Launchpad and Ubuntu SSO are the one and same user/password database. In this sense they're like a Google account or Yahoo account that uses the same username and password for multiple services/sites.\nNote: If you login to http://login.ubuntu.com you can manage your launchpad OpenID options.\n\nA: Yes, they share the same DB.  You only need one login for everything in Ubuntu.  I think it's actually that it was Launchpad Login Service and then they went and made it broader but the old name is still sitting around in some places and just hasn't been updated.\n\nA: Ubuntu SSO will replace LP's login service.\nSource: https://login.ubuntu.com/+description and https://login.ubuntu.com/+faq\n", "Q: How to merge several PDF files? There are a lot of software in Windows to merge PDF files but how can we do the same in Ubuntu?\n\nA: Use pdfsam http://www.pdfsam.org/ it's very good for splitting and merging pdfs\nsudo apt install pdfsam\n\n\nA: I use pdfseparate to extract specific pages from big pdf file: \npdfseparate -f  156 -l 157 input.pdf  output_%d.pdf \npdfseparate -f  1   -l 2   input.pdf  output_%d.pdf \n\nand aftewards I join them all via command: \npdfunite $(ls -v output_*.pdf | tr '\\n' ' ') out$(date  +%Y-%m-%d_%H_%M_%S ).pdf\n\nThis joins:\noutput_1.pdf output_2.pdf output_156.pdf output_157.pdf  \n\ninto:\nout2014-12-14_23_25_36.pdf\n\nMay be there is an easier way how to cope... :-)\nInstallation instructions:\nsudo apt install poppler-utils\n\n\nA: You can also use jPDFTweak, pdfsam or pdfjam.\n(That said, I use pdftk.) \n\nA: pdftk\nTo merge two pdf files, file1.pdf and file2.pdf:\npdftk file1.pdf file2.pdf cat output mergedfile.pdf\n\nMore info available hereWay Back Machine. \nTo install, run:\nsudo snap install pdftk\n\n\nA: You can use pdftk to merge and modify PDF documents in general. Alternatively there's an online service to do just that: http://www.pdfmerge.com/\n\nA: PDF Chain  \nA very nice solution is PDFChain. It's GUI is a frontend of PDFTK where you can merge, split or even add some background to your PDF files.\n\nA: PDF Arranger (install), formerly known as PDF-Shuffler.\nIf you want a tool with a simple GUI, try pdfarranger. It allows for merging of PDFs as well as rearranging and deleting pages. For batch processing and/or more complicated tasks, pdftk is of course more powerful.\n\n\nA: Ghostscript is a package (available by default in Ubuntu) that enables you to view or print PostScript and PDF files to other formats, or to convert those files to other formats.\nTo use Ghostscript to combine PDF files, type something like the following:\ngs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -dAutoRotatePages=/None -sOutputFile=finished.pdf  file1.pdf file2.pdf\n\nHere is a brief explanation of the command:\ngs         starts the Ghostscript program.\n-dBATCH    once Ghostscript processes the PDF files, it should exit.\n           If you don't include this option, Ghostscript will just keep running.\n-dNOPAUSE  forces Ghostscript to process each page without pausing for user interaction.\n-q         stops Ghostscript from displaying messages while it works\n-sDEVICE=pdfwrite \n           tells Ghostscript to use its built-in PDF writer to process the files.\n-sOutputFile=finished.pdf\n           tells Ghostscript to save the combined PDF file with the specified name.\n-dAutoRotatePages=/None\n           Acrobat Distiller parameter AutoRotatePages controls the automatic orientation selection algorithm: For instance: -dAutoRotatePages=/None or /All or /PageByPage.\n\nYour input files don't even need to be PDF files. You can also use PostScript or EPS files, or any mixture of the three.  \nThere is a lot you can do with Ghostscript. You can read its documentation for more details.  \nSource\n\nA: An alternative approach is to use Latex as explained in this post (without root access assuming that you have pdflatex installed):\nhttps://tex.stackexchange.com/questions/8662/merge-two-pdf-files-output-by-latex\nThis is useful in case you do not have the mentioned tools nor root privileges, but you do have pdflatex.\nI copy the tex code below to merge file1.pdf and file2.pdf. Create a file called output.tex and put:\n\\documentclass{article}\n\\usepackage{pdfpages}\n\\begin{document}\n\\includepdf[pages=-]{file1}\n\\includepdf[pages=-]{file2}\n\\end{document}\n\nAnd to compile, simply use: pdflatex output.tex\nThe merged file will be named as output.pdf.\n\nA: You also also use pdfunite to merge pdf documents :\npdfunite in-1.pdf in-2.pdf in-n.pdf out.pdf\n\nTo install pdfunite if it is not installed already, run:\nsudo apt-get install poppler-utils\n\n\nA: Give PDFMod a try, it’s from the GNOME project:\nhttps://wiki.gnome.org/Apps/PdfMod\nsudo apt install pdfmod\n\n\nA: Here is my approach:\n\n\n*\n\n*I wanted it to be easily accessible so I created a right-click shortcut in Nautilus (see https://help.ubuntu.com/community/NautilusScriptsHowto)\n\n*I wanted it to be very quick so I used pdfunite\n\n*pdfunite only accepts the filepaths in the middle of the command so I had to scratch my head to manage the spaces in the filepaths. So I took the assumption that all filepaths will start with \"/home/\" and end with \".pdf\"\n\n\nHere is the result:\n#!/bin/sh\nCLEANED_FILE_PATHS=$(echo $NAUTILUS_SCRIPT_SELECTED_FILE_PATHS | sed 's,.pdf /home/,.pdf\\\\n/home/,g')\necho $CLEANED_FILE_PATHS | bash -c 'IFS=$'\"'\"'\\n'\"'\"' read -d \"\" -ra x;pdfunite \"${x[@]}\" merged.pdf'\n\nJuste paste this script in \n\n/home/your_username/.local/share/nautilus/scripts\n\nand name it \"merge_pdfs.sh\" (for example). Then make it executable (right-click on merge_pdfs.sh -> Permissions tab -> tick \"Allow executing file as a program\"\nSo now to merge pdf files, you just have to select them -> right click -> scripts -> merge_pdfs.sh and it will create a \"merged.pdf\" file in the same directory\nHope it helps!\n\nA: You can see use the free and open source pdftools (disclaimer: I am the author of it).\nIt is basically a Python interface to the Latex pdfpages package.\nTo merge pdf files one by one, you can run:\npdftools --input-file file1.pdf --input-file file2.pdf --output output.pdf\n\nTo merge together all the pdf files in a directory, you can run:\npdftools --input-dir ./dir_with_pdfs --output output.pdf\n\n\nA: I did not find pdfarranger in snap (Ubuntu 22.04).\nThus I installed sudo snap install pdfmerger.\nThis tool also has a simplistic GUI and worked perfectly for me.\n", "Q: How to change the highlight color of the workspace chooser toolbar applet? A recent update to Ubuntu changed the way the workspace chooser panel applet worked.  It used to highlight the choosen workspace as orange, and other workspaces would be not colored.  Now it is the reverse.  Is there a way to change this to set it back to the way it used to be?\nThe new scheme is counter intuitive to me, and even though I've been using it for months I just can't get used to it.\n\nA: Those colours are part of the colour scheme provided by the desktop scheme. So the only solution I can think of is to go to System -> Preferences -> Appearance and change to a different desktop scheme or customise the current one.\n\nA: Try going to Appearance Preferences>Customize>Colors & see if you can change the color for tooltips. That might help you.....\n", "Q: Moving application windows from one workspace to another by dragging in the workspace chooser? The old workspace chooser allowed you to move application windows between workspaces by dragging them around in the workspace chooser.  I much prefer that to the new workspace chooser's method of dragging them off the side of the screen. For one thing, in order to drag a window from a different workspace into the one I'm working in, I have to switch workspaces twice and unmaximize a maximized window with the new method, where with the old I simply had to drag.  Is there anyway to get this old functionality back in Ubuntu 10.04?\n\nA: Turn off desktop effects.  This works fine with Metacity in 10.10, and I'd be really surprised if it was removed for one release.\n\nA: You can set a hotkey for moving windows between viewports--that can be helpful.\nCompiz also has the \"Expo\" function, which I think might be up your ally. It zooms out, and shows you every viewport. You can drag windows between them, and double click on one to go to it.\n", "Q: What does \"hardy\" mean in /etc/apt/sources.list? I see entries in /etc/apt/sources.list that say:\ndeb http://us.archive.ubuntu.com/ubuntu/ hardy universe\n\nI am using Ubuntu 8.04, and I don't know what \"hardy\" means, though I suspect it has something to do with version?\n\nA: Hardy is the name of the 8.04 Release, \"Hardy Heron\".\nEach Ubuntu Release follows the same pattern, year.month numbers for versioning, e.g 8.04 8.10, 10.04 (usually 2 releases every year) and a code name.\nUbuntu Releases are:\n\n\n*\n\n*4.10 - Warty Warthog\n\n*5.04 - Hoary Hedgehog\n\n*5.10 - Breezy Badger\n\n*6.06 - Dapper Drake\n\n*6.10 - Edgy Eft\n\n*7.04 - Feisty Fawn\n\n*7.10 - Gutsy Gibbon\n\n*8.04 - Hardy Heron\n\n*8.10 - Intrepid Ibex\n\n*9.04 - Jaunty Jackalope\n\n*9.10 - Karmic Koala\n\n*10.04 - Lucid Lynx\n\n\nThey appear on your sources list to indicate which release(version) of the repository you are using.\nPS: You must have also realized by now, that Ubuntu releases follow an alphabetical naming order, always using an adjective and an animal name. The next Ubuntu release (10.10) will be named Maverick Meerkat.\nPS2: The oficial Ubuntu page with all codenames, plus some discarded alternatives names can be found here, if you are curious about it.\n\nA: The Letter name is the \"codename\" during testing--when released it becomes the number release.\n", "Q: tmpfs for cowbuilder builds? I'm a packager, so I often need to use cowbuilder or pbuilder to build packages either for my own use or when I'm sponsoring somebody elses' work. \nOn my laptop, my disk isn't the fastest in the world, so I'm considering using tmpfs for the build area, /var/cache/pbuilder/build, to speed up the build process. Files in there can get fairly large, for example right now I've 2.2GB of data in that folder. In addition, cowbuilder works by making shallow COW copies (using hardlinks I think).\nWould it be feasible to mount the build directory under tmpfs? \nI'm on Ubuntu 10.04 Lucid Lynx, but will be moving shortly to the prerelease of Maverick Meerkat. My machine has 4GB of RAM.\n\nA: I've used a tmpfs for pbuilder before, and done some benchmarks against ext4. With 4GB of ram it ended up being between 30%-100% faster on the tmpfs for most packages, up to packages as big as Xorg.\nYou'll want to bind-mount /var/cache/apt/archives in order to get your package cache available in the chroot.\nYou can get a more efficient build with sbuild and an aufs union mount, where the base chroot won't be copied to ram.\n\nA: Keep in mind that hardlinks can't work across filesystems. I think using tmpfs would be bad.\n", "Q: How do I use \"virsh shutdown\" on KVM domains to shut down Ubuntu guests? I am using various KVM domains on a Ubuntu server. Both the host and guests run 10.04.1, 2.6.32-24 kernel, virsh reports version 0.7.5, KVM 0.12.3. The guests boot automatically when the host boots and they have <features><acpi/><features> in their configuration.\nI could never manage to make virsh shutdown MyDomain on the host to have any effect. It responds with Domain MyDomain is being shutdown and the domain keeps happily running. virsh list still lists them in the state running.\nvirsh destroy MyDomain works fine, but of course that's not really what I want, so most of the time I log into each one and shut them down manually, which is pretty annoying.\nI couldn't really find any information on how virsh shutdown tries to shut the domain down. Pointers to useful bits of documentation are welcome.\nWhat could cause this? How is it supposed to work?\n\nA: Check to see if you have the package acpid installed on each of the guests.\nI generally create new virtual machines using VMBuilder with the parameter --addpkg acpid and the only time I've had trouble shutting down Ubuntu guests using virsh was when the guest vm had crashed in some way.\n\nA: If you don't have that option, there are 'shutdown modes' you can utilize to trigger a shutdown \n$ sudo virsh shutdown --help\nOPTIONS\n[--domain] <string>  domain name, id or uuid\n--mode <string>  shutdown mode: acpi|agent|initctl|signal|paravirt\n\ni.e.,    \nsudo virsh shutdown domain1 --mode acpi\n\n", "Q: How do I make my own customized ubuntu sounds? I'd like to be able to either make my own sound theme or perhaps find one that's completely customizable i.e. how windows sound is customizable from the get go.\n\nA: Ubuntu uses freedesktop.org sound themes. For writing your own sound themes refer to the Sound Theme Specification. You can find sound themes on many sites, this one appears to be one of the more popular ones.\nThis question has some more detail on the files themselves.\n\nA: You can change the alert sound, or switch themes, in:\nSystem->Preferences->Sounds\n", "Q: Email application for the computer-impaired A member of my family has a moderate disability for dealing with computers.  He is largely unable to engage technology in general, and most on-screen GUIs are confusing and upsetting.  He is, however, able to use email and browse the Internet to a limited degree, and he wants to progress in that.  \nEvolution works fairly well for the email.  But I want to find a better software -- which in this case means simpler, easier and uncluttered.  \n\n\n*\n\n*Simpler   -- doesn't assume a heavy load of messages or super real-time exchange such as for chat.  Doesn't present many features beyond the minimum.\n\n*Easier   -- has a highly fool-proof GUI.  \n\n*Uncluttered  -- No sidebar with advertisements.  No extraneous pop-ups.\n\n\nI am certain the Gmail interface would not be acceptable (complex, visually cluttered, a bit hard to second-guess if you aren't computer-savvy).  Three years ago I tried Thunderbird, but Evolution seemed to have a better GUI.  \nI guess I'm looking for the email-browser equivalent of a Jitterbug phone.  Perhaps something designed for assistive technology is available.  What would you recommend?\n\nA: Mozilla came out with Thunderbird 3.0 not too long ago, and it seems simpler (once you set it up, of course). Then again, I thought gmail was incredibly simple, so...\nMy dad is also terrible with computers--although probably not that bad... And he loves his windows live mail box. I've been trying to get him to switch to gmail, but he refuses to try new things. So, if windows live works for him...\n\nA: I am not sure what exectly your family member needs, but just trying to help think out of the box (as I know about no mail client designed for this exact purpose):\n\n\n*\n\n*what about old-school plain HTML webmail applications?\n\n*what about something like Modest (which is simple because it was designed to run on small screens--not sure how that scales to big screens...)\n\n\nA: Claws Mail, if you are loking for a client.\n", "Q: 403 Forbidden Error when accessing enabled virtual host When accessing a site defined in my local dev environment, I can't seem to get past a 403 Forbidden error.\nUnder /etc/apache2/sites-available/ I have defined a file fun.local:\n<VirtualHost *:80>\n        ServerName fun.local\n        DocumentRoot /home/noah/work/fun\n        ErrorLog /var/log/apache2/fun-error.log\n\n        <Directory /home/noah/work/fun>\n                Options Indexes FollowSymLinks MultiViews\n                AllowOverride None\n                Order allow,deny\n                allow from all\n        </Directory>\n</VirtualHost>\n\nThe the apache error log for the site contains this error:\n[Sat Aug 21 13:34:34 2010] [crit] [client 127.0.0.1] (13)Permission denied: /home/noah/.htaccess pcfg_openfile: unable to check htaccess file, ensure it is readable\n\nI am running apache2 and ubuntu 10.04.\n\nA: Make sure to check the permissions on that directory. Realize that apache runs as the user 'www-data' and it will require read access to the files in that directory in order to function. \nTo check the permission run from the command line:\nls -al /home/noah/\n\nNote that Apache figures out if a directory is able to be served by checking the whole path for .htaccess files. This is in case there's a rule in /home/noah/.htaccess that says things should be denied, overriding the information setup in your virtualhost file. \nAllowing the www-data user to read the directory should help. The other thing you can do is to symlink the /home/noah/work/fun directory into /var/www where the apache user should be the default owner. \nLet me know if you need more details or if you can get there from here. \n\nA: You can use apache userdir module to achieve this.\nSee this post for details: Apache symlinked to home directory - Permission Errors\n", "Q: Instant Messager that supports video and voice chat Are there any instant messengers for Ubuntu that support video and audio chat?\n\nA: Empathy and Pidgin support video and audio chats over Google Talk/Jabber/XMPP protocol. You could also give the recently launched Google Video and Voice Chat an try.\nSkype also supports video and voice chat on Linux.\nOr you could use Ekiga (VoIP client) for video and voice.\nGyachi has this on their web page:\n\nThis Yahoo! client for Linux operating\n  system supports almost all of the\n  features you would expect to find on\n  the official Windows Yahoo! client:\n  Voice chat, webcams, faders,\n  'nicknames', audibles, avatars,\n  display images, and more. Yet, it\n  remains very light-weight and\n  memory-friendly.memory-friendly.\n\nMeebo is a web service that supports voice and video chats on Linux.\n", "Q: How do I communicate with the Ubuntu kernel team? How do I communicate with the Ubuntu kernel team?\n\nA: The Ubuntu Kernel Team is located in disparate cities throughout the world. We utilize IRC to communicate with each other as well as the Ubuntu user community. The team hangs out on the #ubuntu-kernel channel on FreeNode. There is usually someone from the team in the channel 24hrs a day Monday through Friday. If you do join the channel, please be patient after asking your question, if you don't get an answer right away.\nA good place to look for answers to these kinds of questions is the Ubuntu Kernel Team's wiki specifically the FAQ.\n", "Q: I'm getting an error when I try to install the Amazon MP3 Downloader When I run the .deb file I downloaded from here, I get this error:\nError: Dependency is not satisfiable: libboost-filesystem1.34.1\nDoes anyone know a work around for this?\n\nA: The Amazon MP3 Downloader package is meant for use with 9.04 and depends on some packages that are now out of date. Fortunately, you can download the now-outdated libboost-filesystem1.34.1 from packages.ubuntu.com and install it by hand.\nIf the Amazon .deb gives you further dependency errors, I can help you find those packages as well.\nI should mention that there are alternatives to the Amazon MP3 Downloader. Pymazon is an option, and there is now a Banshee extension to do the job.\n\nA: You'll notice that the version of that package in the lucid repos is:\nlibboost-filesystem1.40.0\n\nYou can tell by checking for the package on the system. From a terminal run the command:\napt-cache search libboost\n\nThe version is upgraded from the one that the Amazon downloader is looking for. According to the Amazon site, the downloader is compatitlbe with Ubuntu verion 9.04 which is a year old. Are you running a more recent version? \nThere is a note in this post here: http://blog.binarykatana.com/post/amazon-mp3-downloader-on-lucid/\nNote that if you use this you're performing some potentially bad/unsupported actions. Unfortunately the best solution would be for Amazon to better support their download client. \n\nA: If you follow the link given by the OP, it appears that Amazon has now made official their lack of Linux support for the MP3 Downloader. Their new Cloud Player does have a 'Download' option, though it's not as full-featured as I'd like. You can only download one song at a time, even if you buy the whole album, and it does not give you the nice [artist]/[album]/... directory structure that the Downloader did. Still, it's an option.\n", "Q: How do I get involved with the Ubuntu kernel? How do I get involved with the Ubuntu kernel?\n\nA: The kernel team is always interested in getting community help on the kernel. We need help triaging incoming bugs, reviewing patches proposed for the kernel, testing kernel images as well as helping to fix launchpad bugs. For more details see \"Getting Involved\".\nYou may also want to check out the Kernel Team's FAQ and the Kernel Team's wiki documentation.\n", "Q: Network print to brother MFC-7420 I am trying to pint to a Brother MFC-7420 from my ubuntu 10.04 machine.\nThe brother is attached to a windows XP machine and is shared.\nThis is what I have tried:\nSystem->Administration->Printing,\nAdd,\nExpand Network Printer,\nWindows Printer via SAMBA,\nBrowse (I can find the printer no problems here),\nFoward,\nChoose Driver Dialog,\nBrother,\nMy printer is not in this list\nSo the next thing I tried was to download the printer driver from here http://welcome.solutions.brother.com/bsc/public_s/id/linux/en/download_prn.html\nThe driver installed fine but my printer still does not appear in the list.\nI also tried installing the cups wrapper but that gave the following error.\n\nRestarting Common Unix Printing System: cupsd                         [ OK ] \n  cp: cannot stat `/usr/share/cups/model/MFC7420.ppd': No such file or directory\n  dpkg: error processing cupswrappermfc7420 (--install):\n   subprocess installed post-installation script returned error exit status 1\n  Errors were encountered while processing:\n  cupswrappermfc7420\n\nI tried connecting the printer directly but even though I have installed the driver, when I go to printers and click on the printer (it shows up fine as a USB printer) then it say searching for drivers and then gives me a list, this is the same list as before which doesn't have my printer.\nIt really shouldn't be this hard. on window you don't have to installing anything it just works and the same is true for my brothers Mac.\nHow do I print to my printer?\n\nA: You need to do some extra steps, please check this.\nYou only need to do the Pre-Required Procedure 2, that means opening a terminal and running:\n$ sudo aa-complain cupsd\n$ sudo mkdir /usr/share/cups/model\n\nAfterwards my test system installed the cupswrapper package and the printer appears on the selection list. I can't test if it works as I don't have that printer.\n\nA: For my Brother printer (MFC-8380DN), I had to manually enter the printer using the web interface. the url being http://localhost:631/printers. GNOME's CUPS interface failed to produce a test page. The steps necessary are listed here.\nI think the crucial step may have been using the IP address notation lpd://1.2.3.4/binary_p1 (with 1.2.3.4 replaced by the printer's IP address). I also installed the drivers from Brother's page.\n\nA: Try this- https://superuser.com/questions/260652/how-do-i-use-my-brother-mfc-7440n-from-debian-or-ubuntu\nIt uses a driver for a different printer that uses a similar printing engine.  It works fine for me on multiple models of Brother MFC.\n\nA: It is fairly rare to find drivers which match to your exact model. Luckily, most printers are very similar to a lot of other printers, so you can use the drivers for a similar model. Go through the list, find a driver for a similar model. Go for a MFC-7xxx if possible, but any MFC has a good chance of working (I am using the MFC-7840W driver for my MFC-6xxx printer right now). If at first you don't succeed, try again. It really should work without any additional software installed.\nEDIT: Make sure you use a color driver if you have a color printer. Iirc a 'W' at the end of the model number indicates black/white, but I could be wrong.\n", "Q: locale: Reset lost settings Due to some strange reason, I've lost some of my locale settings. I've managed to restore most of them using sudo dpkg-reconfigure locales:\nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n LANGUAGE = (unset),\n LC_ALL = (unset),\n LANG = \"en_US.UTF-8\"\n    are supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\nlocale: Cannot set LC_MESSAGES to default locale: No such file or directory\nlocale: Cannot set LC_ALL to default locale: No such file or directory\n\nSo I'm stuck with one missing value:\n$ locale\nlocale: Cannot set LC_MESSAGES to default locale: No such file or directory\nlocale: Cannot set LC_ALL to default locale: No such file or directory\nLANG=en_US.UTF-8\nLC_CTYPE=\"en_US.UTF-8\"\nLC_NUMERIC=\"en_US.UTF-8\"\nLC_TIME=\"en_US.UTF-8\"\nLC_COLLATE=\"en_US.UTF-8\"\nLC_MONETARY=\"en_US.UTF-8\"\nLC_MESSAGES=\"en_US.UTF-8\"\nLC_PAPER=\"en_US.UTF-8\"\nLC_NAME=\"en_US.UTF-8\"\nLC_ADDRESS=\"en_US.UTF-8\"\nLC_TELEPHONE=\"en_US.UTF-8\"\nLC_MEASUREMENT=\"en_US.UTF-8\"\nLC_IDENTIFICATION=\"en_US.UTF-8\"\nLC_ALL=\n\nAny idea how to restore them all?\nThanks,\nAdam\n\nA: Happens to me occasionally too. Not sure what causes it but I just fire off:\nsudo dpkg-reconfigure locales\n\nAnd that seems to fix it (for me)\n\nA: In case you've deleted some files, try reinstalling the locale package:\napt-get install --reinstall locales\n\nYou may want to do the same for language-support-(your langcode), language-pack-(your langcode)-base and other language packs (gnome, kde...) for your language.\n\nA: This is what I had to do to fix this:\nsudo apt-get install --reinstall language-support-en\n\n\nA: Any of given answers didn't help me, but I found this:\nhttp://ubuntuforums.org/showpost.php?p=12183173&postcount=6\nand it made the trick.\n\nA: I run into this problem from time to time and none of the above answers help me. What actually helps me is adding the following to /etc/default/locales\nLANG=\"en_US.UTF-8\"\nLANGUAGE=\"en_US\"\nLC_CTYPE=\"en_US.UTF-8\"\nLC_NUMERIC=\"en_US.UTF-8\"\nLC_TIME=\"en_US.UTF-8\"\nLC_COLLATE=en_US.UTF-8\nLC_MONETARY=\"en_US.UTF-8\"\nLC_MESSAGES=en_US.UTF-8\nLC_PAPER=\"en_US.UTF-8\"\nLC_NAME=\"en_US.UTF-8\"\nLC_ADDRESS=\"en_US.UTF-8\"\nLC_TELEPHONE=\"en_US.UTF-8\"\nLC_MEASUREMENT=\"en_US.UTF-8\"\nLC_IDENTIFICATION=\"en_US.UTF-8\"\n\n", "Q: Virtual Ubuntu Network Configuration I have Ubuntu as main OS. I have created virtual Ubuntu in Sun VirtualBox and I get this error: can not connect(ssh)/ping computers in local network.  If I configure network manually I even can not access to Internet. If I choose DHSP then I can access to Internet. Do you have some solution how to connect computers in local network from virtual Ubuntu?\n\nA: Setting your network connection type to Bridged will give your virtual machine its own IP address on your network, where it will be able to see any of the other machines, including the VM host.\n\nA: I used NAT in Sun VirtualBox network configuration. When I choose Bridge it worked...\n", "Q: Symlinks and their paths are confusing - how can they be used effectively? When exploring directories from a symlink (symbolic link) using Nautilus or Gnome Commander, the directory structure is displayed as if the symlink were a regular directory.  When I open a document, apps differ in how they treat the path.  For an .html document:\n\n\n*\n\n*opened w/ Firefox: Shows the real\npath as the address\n\n*opened w/ NetBeans:   ditto\n\n*opened w/ Gedit: Shows the symlink\npath as the address\n\n\n\n\n\n*\n\n*Do I need to pay attention to these\nvarying behaviors?\n\n*I feel insecure when the symlink\npath is offered (because of my\nWindows background) -- can I ignore\nthat?  Can I proceed with\nconfidence, and if so, does that\ncover all cases?\n\n*An app will occasionally ask me if I\nwant to preserve symlinks, treat\nsymlinks as actual links, and so on.\n(ex., copying in Gnome Commander presents \nan option called \"follow links\" ... which\nI assume means symlinks).\nYour guidelines for that?\n\n\nA: *\n\n*Not really, because either way you are still viewing/editing the files that the symlink is pointing to\n\n*When the symlink path is given, I think it means that the application thinks that the file is at that path; however, the data is still being read from/written to the same place in the file system (the original file). So yes, you can ignore it.\n\n*'Preserving symlinks', in my understanding, means that when you move a symlink file and it points to a relative path, the relative path will be adjusted so that it still points to the same file. It is probably a good idea to preserve symlinks. 'follow links' means that the action you are doing (such as copy) is done to the linked to files and all the files within the linked to directories. I think that if you follow links when copying, the actual files/folders will be copied to the new location. If you don't follow links, only the link is copied to the new address.\nThis wikipedia page has a detailed explanation of symlinks\n\nA: *\n\n*This might be a two-sided sword. In some way, for a casual user, the indication of a symlink might be confusing, while for an advanced user might be important. Maybe it would be good if those file browsers would have a configuration option that could make them give the functionality that is needed.\n\n*Not sure what you are insecure about. If you follow a symlink, it is not different as if it would be a normal path. It gives you additional flexibility in that you can change directories or files that are used. It is like an alias. Several names for the same thing.\n\n*When you copy a tree of directories, it makes a difference. You can either ignore all symlinks, and only copy all \"real\" directories or files, or copy the symlinks as symlinks, i.e. copy exactly the same, or duplicate the trees (or files) that are behind symlinks to distinct copies.\n\n\nA: Also the commmand readlink might also come in handy from the terminal if your ever unsure about were a particular symlink is directed to. \nUseage:\nreadlink [symlink]\n\n", "Q: What are the biggest barriers to walking the MOTU/developer path? For those who are not MOTU (people who maintain the Universe and Multiverse software repositories) and do not have plans of the \"I will apply to MOTU by $date\" variety:\nWhat keeps you and others like you from trying to become MOTU?  What makes you think you couldn't become one?  \nI'm referring to both social and technological barriers.\nEDIT:\nI'm only saying MOTU because it's a pretty generic group, but \"why aren't you packaging / patching and intending to eventually try for upload rights?\" is an even more general version.\n\nA: The biggest barrier I've found is the Ubuntu developer page: http://www.ubuntu.com/community/get-involved/developers\nSo many times, I've gotten enthusiastically determined to contribute at least 1 patch to Ubuntu... so I go to the natural place on the website... and end up lost in a sea of documentation. Hours later, I still have no idea what I should write a patch for. When I look through Ubuntu bugs, I often find patches... many that just sit there unused.\nAs far as packages go, I've tried to figure out how to make them, it's really confusing. I also tried to get involved in Launch Pad, but the interface is so much more complex than Source Forge, I couldn't get my own code on LP. It's very difficult for a new user.\n\nA: Being a MOTU is a responsibility.\nWell, obviously the #1 reason is not technically knowledgeable enough, and the #2 reason is having a squillion things you'd rather do. But amongst your target audience, I think the main reason is that it's a responsibility.\nIf I compile a package for myself, no one else cares about whether I've followed the technical and legal policies. No one will come to me expecting that I package a newer version. No one will ask me to fix bugs.\nIf I upload my package to a ppa, a few people may care. But the expectations aren't as high. I can just vanish and let people complain on their blog how sad it is that the package isn't available for natty narwhal.\nIf I become a MOTU, suddenly I have a big responsibility. Users will come to me with bug reports and complain if I don't solve them yesterday. Users will expect that I upload the new version of the package as soon as it's available upstream. I'll have to explain to nontechnical users how to figure out what they did wrong. Unlike posting on a forum, I'm not supposed to ignore the questions I don't feel like answering. And other developers might go after me because I messed up something — this can be intimidating.\nAnd what do I gain?\n\n\n*\n\n*A fuzzy feeling that I've helped people. That can matter. But if that's my main motivation, how can packaging software compare with helping at a soup kitchen or tutoring your out-of-work-immigrant neighbor's kids?\n\n*A bullet point on my resume? Meh, participating in a FOSS as a programmer will be much more appreciated. (It gives you experience with things like project management and long-term maitenance that are hard to teach in college courses.) In fact, being a DD/MOTU looks suspicious to the many employers who frown on politically-involved employees (you're openly giving political support to FOSS).\n\n*A feeling of satisfaction? Much less than writing my own program from scratch would. Programming is a lot more creative than packaging. There's a big sense of achievement in it. There's bragging rights. But in packaging? It's a chore. It's not glamorous.\n(That's a third-person “I” above. I think the reasons I give apply to most people but to varying extents. Personally it's mainly having a squillion things I'd rather do, and packaging lacking a sense of creative achievement.)\n(Out of curiosity, does Ubuntu lack manpower?)\n\nA: Language, my main problem is that I'm still not confident enough with English, being so, I can't understand easily what other developers are trying to tell me\n\nA: I think there are several reasons for this. I also think the reasons are often individual.\nOne of the issues at this time, is the change in the whole MOTU system. I believe, the changes can be confusing, and have been implemented more on technological lines and unfortunately did not bring the community fully on board (maybe just because it is confusing).\nI also think, in some cases the motivation to be a MOTU is not as clear as it could be. IMHO, being a MOTU is a responsibility, not a privilege. It is not about the title, but about the ability to help the Ubuntu community by the access rights that come with it. Due to this, it could be that the whole approval process could be modified (or extended). MOTUs usually nominate themselves, and then the board looks if they are ready to be MOTUs. Maybe it should be possible, that peers that believe that someone is ready to be a MOTU be able to nominate that person. This would IMHO represent more the fact, that the nomination is done to help the process, not to obtain a title. I understand that making this the sole way has its problems too, therefore, I rather see it as an alternative then the only way.\nI also know there have been some problems in the past with people focusing more on KDE. These problems have hopefully been addressed, but maybe it would good if that would also be more widely known.\nObviously, these are just a couple of issues that I have notice. People are different and will see different things, or be affected differently by the same thing. So, theses issues might not stop everyone, nor are they the sole reasons for this problem.\n\nA: What stop me to become a MOTU?\nEventhough Ubuntu is a very nice Community (I've not been flamed for n00bie questions, yet) I think that there is few / incomplete documentation about the packaging process (even Debian's New Maintainer Guide is full of \"this topic is out of the scope of this document\" lines). If you take that fact and think about people who's first language is not english (like me) the process is even more difficult and caothic.\nWith a simple, right to the point, documentation every thing would be easier all of us, but the people who has the technical skils to write that documentation are too busy to do it.\n\nA: I posted a few ideas here: http://blog.mitechie.com/2010/08/24/ubuntu-help-wanted/\nOne thing I really want to bring out is, I wonder how many developers don't use build systems that easily plug into the packaging tools. I'm doing python development. My world centers around setuptools and distribute, and yes, I can take something I build with those and export it over, but to what end? I already have something that's distributable. I wonder if the rise of scripting languages with their own build tools/distribution methods cause a lack of experience and desire in getting things put together with debian packaging tools and thus MOTU levels. \n\nA: For me it is probably time related. Currently I do not have a lot of time to invest.\nAnd I started of with bug triaging, but soon found out that things were a bit more complicated. And you really need to sink your teeth in it.\nThen there is bug fixing, which I know I would enjoy. What is keeping me from helping out there, is that you need to run a development branch or something. I once started to work on a papercut of mine in the System Monitor (https://bugzilla.gnome.org/show_bug.cgi?id=611738)\nSo I started off using Ground Control, to fetch the required source and get in there an fix the bug. However, it turned out not to be so easy, because of dependencies. I know that I should only work on the development version, and test if it is fixed there. However, just to try that I needed to download the source of many other gnome packages. Which is not that easy with groundcontrol. And you probably should do that on a work machine. So I stopped there. (Again it would take me too much time, just to get started for this)\nConcerning packaging, I am just not aware of anything that needs packaging. I have once done a tutorial on packaging, and found it not too difficult for small applications. However never went out looking for a list of stuff that needs packaging, because I know there probably is one... :)\nSo basically for me it is just time, I want to help out, but I just have a couple of hours (2 or something) every odd week or so. And in that small amount of time I seem to be unable to get started with this.\n\nA: I think the biggest technical barrier is knowing how to create Debian packages. While it is relatively simple to create a working package, it is much harder to create packages up to the standard of Debian and Ubuntu. Also, the guides on how to create packages normally deal with a situation in which you have the source code that requires compiling. This can be confusing for applications written in interpreted languages.\nThe biggest social barrier is probably knowing how to get packages uploaded into the universe/multiverse repositories. It is a lot simpler to just create your own ppa and upload packages there.\n\nA: Nowadays people like drive-by contributions.\n20 years ago you would typically focus a lot of your energy on a pet project, if you had one. Today you visit dozens of Internet pages a day, and there are lots of social networks or other communities, where you can contribute to wikis, forums and other stuff. While this has led to more people contributing, it also led to people expecting low barrier entries (a la \"just click the website to edit it). Otherwise they may just turn to other communities.\nTherefore you should look for barriers in the MOTU process. I remember the GroundControl project to lower the barrier for patch contributions in launchpad hosted projects. Maybe you need similar new tools, so new MOTU candidates don't have to fiddle with a lot of command line tools. While those current tools may be powerful, it probably takes a lot of energy to learn how to use them correctly.\n\nA: Provide better documentation.\nI have taken part in the developer weeks IRC sessions related to packaging and MOTU stuff (twice already) and found that during those sessions you typically have a vague understanding of the process. But if you look at the Ubuntu wiki pages two weeks later, you can't get all the pieces together anymore. Those pages often are kind of a bullet point lists from people who already understand the process in detail. But that is not enough to make the content understandable for newbies.\nSo maybe you should try to get the documentation wiki pages explain the process, tools and people involved in more detail. Or even with complete examples. During the IRC sessions there are always repeatable examples, maybe those make the difference to the wiki pages.\n\nA: When I create a package, it's usually to scratch an itch of mine, not because someone else wants the package. Checkinstall is good enough to make a package for me, and then my itch is scratched, and I have no personal incentive to go the extra distance to package it manually, and figure out all the dependencies and stuff.\nSo I guess that even if packaging for distribution is easy, it's still a lot more work beyond packaging for yourself.\n", "Q: Can I rebuild a package without recompiling the source? I am building a new .deb and want to fix lintian errors in the packaging.  However, every time I rebuild, the rules file does a 'make clean' and thus starts compiling again.\nIs there a way to instruct the build process that I do not want to recompile, that I'm just altering the packaging, and using the last set of binaries will be fine for now?\n\nA: Using ccache, you can build the package as normal, without actually recompiling unchanged source files. \nccache works by storing old results of compilations, and only rebuilds if the source actually changed. \ndebuild --prepend-path=/usr/lib/ccache --preserve-envvars=CCACHE_*\n\n\nA: That depends on how you're building the package. dpkg-buildpackage doesn't call the clean target if you pass it the -nc option. Another useful option for test build is -uc (don't sign the changes file). debuild inherits these options from dpkg-buildpackage.\nFor a test build, you can simply do fakeroot debian/rules binary (adjust the target as appropriate for a multiple-binary package).\n", "Q: How do I get my webcam to work I downloaded ubuntu over the weekend replacing Windows Vista and so far everything has been fantastic, except for one thing.  I cannot get my webcam to work.  I've tried camorama and camera monitor but they can't load an image.  Can anyone help with any apps that I can download?\nMany thanks\nUpdated 23/8/10:\nI have two webcams that I can use - a Microsoft Lifecam VX-3000 and a Trust WB-1400T webcam.\nI have downloaded 'Cheese Webcam Booth', 'Camorama Webcam Viewer' and 'Kamoso'.  I have read that there are a lot of problems using the MS Lifecam with Linux so any recommendations on webcams which work particularly well with Ubuntu would be very much appreciated.\n\nA: We need the make and model to really help you but you can look at the official support list here: https://wiki.ubuntu.com/HardwareSupportComponentsMultimediaWebCameras (note: some reports might be outdated)\nIf your webcam doesn't show there, edit your post, telling us what the webcam is.\n\nA: webcams that are ordinary no HD will work fine \"my webcam is a creative webcam Vista\" a very old one and the system detects it in a second.. in my experience webcams are the most annoying hardware to be used with linux there only a limited list of webcams that work FINE on linux and the others will give u headaches in installing then they'll be too dark. \nhere's a list of the most supported webcams,digicams on linux maybe it'll help u:\nLinux-drivers supported webcams and digicams list\n", "Q: Google Chrome removes itself from Menu on reboot Chrome removes itself from the Internet menu every time I reboot. How can I fix this? The only way to get it back is to reinstall Chrome. Is this a Dev issue or a general error?\nI am using Ubuntu 10.04.1 with Gnome. Chrome is the 6.0.495.0 dev version. I downloaded it here: http://www.chromium.org/getting-involved/dev-channel\n\nA: you can create new item on menu list. fill Name with >> Chromium Web Browser, fill Command with >> chromium-browser %U\nclose the Menu Editor, and now Chromium shortcut will appear on your main Menu. ;)\n\nA: This might be a bug in Chrome itself. This person has reported a bug in Launchpad with some information that might be useful. You should grab the information from that bug and file a bug in Google Chrome.\n\nA: I strongly recommend using Canonical's version of Chrome instead of Google's.  I know it's not going to be nearly as bleeding edge, but Google does not put a lot of effort into Ubuntu integration or testing, and this is only one of the types of problems you'll see from it.  Others include:\nIncomplete useragent: \"Linux\", but not \"Ubuntu\"\nWindow controls on the wrong side\n..and probably a lack of Ubuntu Menu bar support at some point, if Canonical modifies Chromium for Ubuntu Netbook Edition.  Seemingly little things, sure, but you've run into one and obviously decided it's worth fixing.\n\nA: Why not try installing the ubuntu chromium-browser from ppa which is recommended by ethana2. Usually  *.desktop file located at /usr/share/applications/ can be edited for displaying in application menu \n\nA: I had the same problem, but i solved it (for me).\nIf you are using the program \"Prey\" this might be the problem. Setting the 'Secure' option to OFF (in the 'actions to perform' section of your computer) fixed this problem for me.\n", "Q: How can I make a console window only appear if the command I'm running produces output? I run the following at regular intervals in order to sync my laptop with my desktop.  When there's nothing to do, and therefore no output from unison, i want it to complete silently; when there's syncing to be done, t want it to pop up in a terminal so I can accept or reject changes as required.  \nCurrently, it always pops up a window regardless and i'm harassed by occasional blank terminals appearing and disappearing.  Here's the command that I run automatically every 30 minutes or so:  \nps -e | grep -i unison || xterm -e 'unison -auto -perms=0 -terse Local_Sync'\n\nCan anyone think of a better way to accomplish this?\n\nA: You'd probably have to draw it out into a script where you could pipe the output to a variable, check if there's anything in that var and then echo it in an xterm if it has content.\n\nA: I agree with Oli, it would be much easier to do in a script which you can make a cron job\nto run every 30 minutes see\nman crontab\n\n", "Q: How do I setup a Ubuntu network? I do some voluntary work for a small private K-12 school, and they just received a donation of about 20 used computers from a large corporation.\nThey came with blank hard-drives, so I need to install an OS and I’m thinking Ubuntu might be a great option.\nIdeally, I would like to have central user accounts and shared central storage.\nIs there something similar to MS-AD for Ubuntu?\n\nA: If you want a more complete solution, I advice you to use OpenLdap.\nOpenLDAP give you the possibility to authenticate your LAN users across the network etc.\n\nA: For a school, the greatest solution is probably to install Edubuntu, using the LTSP server. It's more of a Citrix kind of approach, where you have one server with all the accounts, and all other computers are thin clients. It's quite easy to setup, and very scalable.\nNote that this can be combined with an LDAP server (even an AD if you want) on the LTSP server. There are documentations on how to scale LTSP with NFS/samba and LDAP.\n\nA: Rather than MS-AD you could use samba for networked drives you can set passwords on folders and stuff too if you need access permissions.\n", "Q: Unmanaged network icon - Network manangement disabled I was having problems connecting to the internet either by wireless or wired connection.\nI keep getting an icon in the systray that has a tooltip that says \"unmanaged\" and when I click on it I get a \"Network management disabled\". \nI googled and found the command:\nsudo dhclient eth0\n\nWhich finally enabled my network and I have net. The problem is I still get the icon with the some word \"unmanaged\" \nCan anyone help me out? I just want to know what is happening and why did I had to go to the command line to enable my network.\nI had to put the computer in sleep mode and then it wouldn't wake up, so I rebooted the machine. The network manager problems started again, this time the file mentioned by maco had the value set to true and it still wouldn't work.\nAnyone know how I can make this permanently work? I did a \nsudo init 0\n\nAnd when I booted the machine at a later time I had the network manager enabled.\nHave no clue why.\n\nA: I've just upgraded from Ubuntu 16.04 to 16.10. After that, this problem started to happen to me. In my case, I've solved it following the suggestion given in Ubuntu's launchpad:\ntouch /etc/NetworkManager/conf.d/10-globally-managed-devices.conf\n\nThis creates an empty file.\n\nA: You should look at the contents of the file /var/lib/NetworkManager/NetworkManager.state. It should look something like this:\n[main]\nNetworkingEnabled=true\nWirelessEnabled=true\nWWANEnabled=true\n\nChange any from 'false' to 'true' to re-enable networking. It may work better if you first stop NetworkManager:\nsudo stop network-manager\n\nAnd start it again once done. Or reboot :)\nIn any case, this is frequent when a suspended system fails to wake up. It should be fixed in Maverick.\n\nA: I just upgraded from Ubuntu 16.04 to 16.10. I have 3 network cards (all configured) and no Wifi. All 3 cards were disabled, all options on the Network Manager menu were greyed out, so clicking them does nothing. I fixed it by combining two of the solutions above:\nEdit /etc/NetworkManager/NetworkManager.conf and change:\nmanaged=false\n\nto\nmanaged=true\n\nRestarted network-manager:\nsudo service network-manager restart\n\nNo change. Then I tried:\ntouch /etc/NetworkManager/conf.d/10-globally-managed-devices.conf\nsudo service network-manager restart\n\nAll three network cards came back on-line.\n\nA: I find this happens after a bad shutdown.  Just change \nmanaged=false\n\nto\nmanaged=true\n\nin /etc/NetworkManager/nm-system-settings.conf\n\nNote: In newer versions of Ubuntu, the file is at /etc/NetworkManager/NetworkManager.conf\n\nA: This worked for Ubuntu 17.04\nsudo touch /etc/NetworkManager/conf.d/10-globally-managed-devices.conf\nsudo service network-manager restart\n\n\nA: Try right-clicking the NetworkManager icon and enabling the network from that menu.\n\nA: I installed ubuntu-gnome-desktop to ubuntu server 14.04.4 and the file was not \nnm-system-settings.conf, but \nNetworkManager.conf \nAs in sudo gedit etc/NetworkManager/NetworkManager.conf\nI could not find nm-system-settings.conf\nPerhaps it is not installed (nm-system-settings) as I do not see it on the gnome Panel bar in the gnome classic view desktop. Need to get the Network going to do updates and install gnome-session-flashback to get the Gnome-Flashback (Metacity) on 14.04.4 LTS, my Favorite desktop!\nI had not checked /var/lib/NetworkManager/NetworkManager.state before reboot but, perhaps it was updated after reboot as it was correct.\n", "Q: How to display UMTS signal strength? Using a random UMTS USB stick (Huwei 160 or something like this) works an current Ubuntu pretty much out of the box and the setup via network manager (nm-applet) is convenient.\nBut it does not display the current signal strength or modes of operation (which speed-mode is used etc.).\nWhat are useful tools to display/monitor such information?\n\nA: modem-manager-gui gives that info on \"info\" tab:\n\nIn distros other than Ubuntu, the package name can be modem-manager.\n\nA: There is nothing much that I am aware of that does this. I have written my own scripts that monitor the second usb serial connection and query for signal strength. \nSend a AT+CSQ and you will receive:\n+CSQ: n\nn is in the range 1 - 31, to convert this to dBm subtract 111\nThis is detailed in the GSM / 3GPP spec  http://www.3gpp.org/ftp/specs/html-info/27007.htm\n\nA: Since version 0.8.1 of network-manager is already all-inclusive (http://live.gnome.org/NetworkManager/ReleaseProcess).\nOtherwise you can use umtsmon (http://umtsmon.sourceforge.net/)\nor vodafoneMobileConnect (https://forge.betavine.net/projects/vodafonemobilec/)\nor bcm (https://forge.betavine.net/projects/bcm/)\nif you have a too old version of ubuntu that does not allow you to update network-manager.\n\nA: This screenlet works for me-\nWirelessScreenlet\nYou need to install screenlets first from the software center.\n", "Q: No Internet after reinstalling on Dell Mini 9 I had to reinstall 10.04.  It had been working with no problems and then I did something.  I decided that reinstalling the OS would be the easiest fix.\nAfter reinstalling I cannot access the internet.  I am using a Dell Mini 9.\nMight I need new drivers?\n\nA: This problem may occur in wireless internet connection. First connect with wired Internet connection.\nIn terminal\nsudo apt-get update\nsudo apt-get upgrade\n\nAnd then , you can try with wireless.\nYou also need to check\nSystem>Administration>Hardware Drivers\n\nA: It most certainly is your wireless which you may need to reinstall..First a little advice.Remove what was working before as it is out of date and reinstall the drivers for your ( I assume you have broadcom wifi - most dells mini 9s do ) broadcom.\nIt is quite simple and here is how to do it in 4 very easy steps in your terminal.\nsudo apt-get purge bcmwl-kernel-source\n\nthis removes your old driver\nsudo apt-get install bcmwl-kernel-source\n\nThis will reinstall it using the best set up for your version of Ubuntu\nThen the last steps areto switch it on so you do not have to reboot!\nsudo modprobe -r b43 ssb wl\n\nsudo modprobe wl \n\nIt will build the driver for you in  front of your eyes. \nHope that helps\n\nA: You probably need the firmware installed for the wireless card.  Start with the b43-fwcutter package.\n", "Q: Make Gnome shortcuts available to other users I have used Alacarte to add some shortcuts to my games start folder. Now I would like to make these shortcuts available for all users. How can I do this?\n\nA: All of your users's menu settings are stored in ~/.config/menus/.  All you have to do is copy yours to the desired users.\n\nA: To complite aperson's one - just copying files is not enough. You would also want to set proper permissions and ownership.\n\nA: Copy the appropriate .desktop files to /usr/share/applications.\n", "Q: How to make indicator-network work with DSL? I installed indicator-network on maverick and it shows only Ethernet with no option to add a DSL connection.I am using pppoeconf currently(could be the problem).\n\nA: indicator-network works with ConnMan instead of NetworkManager, and judging from their site ConnMan doesn't support PPP currently (it could be added with a plugin, if one exists).  (Also, this indicator is only going to be used for the Netbook Edition, not for the Desktop Edition.)\n", "Q: http://localhost/ not working I've just done a fresh install of Ubuntu (10.04.1) plus LAMP (via sudo tasksel install lamp-server) and everything is working fine. However, it does so until I need to work on localhost when I do not have an internet connection. For example, as soon as I unplug the ethernet cable from the NIC, localhost and 127.0.0.1 stop working. \nThe message I get from the browser is:\n\nThis web page is not available.\n\nThen, as soon as I plug the ethernet cable into the laptop again, everything is back to normal again. I need to work on localhost sometimes when I do not have access to the internet.\nAny idea how to fix this problem? I had this problem before, but can't remember what I did to resolve it.\n\nA: Check that you have this line in /etc/hosts:\n127.0.0.1       localhost\n\nIf it is not there, add it.\n\nA: if you are using firefox, Uncheck \nFile > Work Offline and then try again.\n\nA: Chrome doesn't like localhost. Try http://0.0.0.0/\n\nA: Update: The newest versions of Google Chrome have fixed this issue. It should be working now.\nIt sounds like you're using Google Chrome or Chromium - This is a bug in Chrome that I've been meaning to report (but never got around to it).  Google Chrome attempts to automatically detect a \"Working Offline\" status and will not allow the user to easily change it\nUnfortunately with Chrome right now, you must be connected to some form of network to use localhost.\n", "Q: Best way to remote restart Ubuntu from Windows machine Background: I'm looking to put a series of Ubuntu machines into retail locations, they're being used as dumb kiosks to show a series of slides onto large LCD panel TV screens. Once installed, they won't have a keyboard or mouse connected but will have a fixed IP on the local network. Everything is configured to auto-start, no automatic updates, no power saving etc - I think we're pretty-much good to go apart from one thing. I need the retail staff to be able to restart the boxes if a problem arises.\nWe have VNC running (now that we've turned off desktop enhancements!) so that we can remotely get into the machines if we need to, but that's not something we would allow the retail staff to do. The machines are going to be physically 'out of the way' (probably in the ceiling space) so the power button is not easily accessible!.\nI'd like to have some means of allowing the retail staff to restart the Ubuntu machine, from the desktop of one of their Windows terminals. I don't really want to give them some kind of raw terminal access (the command line will frighten them!) and I don't want them to use VNC (as stated above). Ideally there would be an icon on the Windows desktop, they double-click it, reply to a simple 'are you sure?' prompt, and then the Ubuntu box is told to restart. The Windows side of that won't be a problem, we can write something using Delphi, Python & Qt4, whatever - it's the Ubuntu side of it I'm stuck with.\nOut of sight/view, could I have a Windows program open a terminal across the network and tell Ubuntu to restart? Is this what SSH could be used for (I have never set that kind of thing up). The Windows programming side isn't really an issue, it's just that I'm a total Ubuntu noob and don't know where to start from the platform point of view.\nThe other thing we considered is also having the machine automatically restart itself at a set time each day (obviously out of store hours!). To me, that seems a bit unnecessary (though forcing a restart once a week/month might be worthwhile).\nAny thoughts or suggestions? Being able to restart the box on demand across the network is my prime requirement.\n\nA: \nOut of sight/view, could I have a Windows program open a terminal across the network and tell Ubuntu to restart? Is this what SSH could be used for[?]\n\nYes. That's effectively how I'd do it. First step is you'll want to install Putty on the Windows computers. This allows you to SSH in. But don't worry about that for now. Let's do this backwards, starting from the Ubuntu machine.\nI would write a script on the Ubuntu machine to do the restarting. If you can ssh in, chances are you don't need to do a full reboot. You could argue that you \"might as well\" but it often means the reboot takes four or five times longer than it needed to be; it's just a waste of time.\nYou should be able to get away with just restarting GDM (sudo restart gdm) so I'd write an interactive Python script that prompts the user to make sure they're sure they want to restart GDM and then restart it. After that, it would wait for five seconds, and then ask them if it's working. If not, do a full reboot (sudo reboot).\nEdit: There's also a possibility you might just be able to restart the application that these screens are displaying without even restarting GDM. I don't know what you expect to fall over but assume all three and give the user the option to restart each sequentially, starting with the app, then gdm, then the machine.\nYou can use curses to make this look prettier.\nNext up you need to make sure your ubuntu user can do these root-level commands. Run sudoedit /etc/sudoers and add something like this:\nCmnd_Alias REBOOT = /sbin/reboot\nCmnd_Alias RESTART = /sbin/restart\n\nuseraccount   ALL=REBOOT\nuseraccount   ALL=RESTART\n\nSubbing useraccount for the username of the account that would be running this script.\nYou should be able to log in via SSH and test the script now.\nThe last piece of the puzzle is hooking up SSH to Ubuntu and running the script automatically. You can use a certificate (it's probably more secure) but for this example I'll just use a plaintext password.\nputty.exe useraccount@1.2.3.4 -pw password -m commands.txt\n\nObviously sub out useraccount, 1.2.3.4 and password with real values. commands.txt should be a text file on the Windows computer containing something like this:\npython my_python_script.py\n\nNote: The path when you login with be /home/useraccount/ so either put your python script in there or alter the path in commands.txt.\nImportant Note: Putty will close as soon as its command finishes running. That means your Python script MUST be interactive (at least ask \"Press Any Key to Continue\" before exiting) or the user won't see any output. This is simple enough. You mentioned Python, so I assume you know (or know how to find out) how to do simple prompts. As I said earlier, a simple curses interface would look the most professional.\nImportant Note 2: Sometimes a machine/software fails to the point where a hard restart is the only option. If you're the computers in a space that is really hard to get to, it's certainly worth considering making sure you have access to their power supply so you can do a \"hard off-and-on\" as a last resort. Make sure you use a journalling filesystem so the staff don't screw it up if they use this too often and warn the staff that if they don't use it as a last resort, evil circus people will steal their children, etc. There are few things worse than a staffer who smacks the hard-reset button at the smallest hiccough.\n\nA: If you can configure ssh in the windows machine it should be quite easy. This is what I do right now to execute some remote command from one ubuntu server to another\nssh ip.number.0.28 -i /home/javier/.ssh/id_rsa_web -l javier \"cd /home/javier/sincrotod;./sincroniza.py\"\n\nThe -i part tells ssh to use a certificate instead of using a password login. The command line order to reboot a machine is reboot. You will need to be sure that the user used to log has permission to shut down the machine.\n\nA: http://web.archive.org/web/20100919000947/http://www.lockergnome.com/it/2005/03/11/running-a-program-on-a-remote-server-using-ssh/\n", "Q: What software is available to use TV tuner card? I am looking for software programs to use my TV Tuner card in Ubuntu.  I have mythTV installed and use it quite a bit.  But I am looking for a program that can tune my tuner card in just a window, not only a full-screen.   \nE.g. - I would like to watch something in a browser, while having a TV channel playing in another window.  Maybe a program like VLC that can control my tuner?\n\nA: MythTV can also be configured to run in a window. In the MythTV Frontend, go to Setup > Appearance and the first screen should look similar to the screen below. You can set the size of the menu here, and also if you want the playback to use the same size area. Setting the window border option will add or remove the window border, and setting fixed window size will make the windows either resizable or not.\n\nTo install MythTV in all currently supported versions of Ubuntu open the terminal and type:\nsudo apt install mythtv\n\n\nA: There is also Gnome's own DVB Daemon. As its name suggests it sits behind the scenes allowing applications to leverage its power. There is a Install totem-plugins-dvb-daemon that allows you to use it though I haven't tested a recent version, so I don't quite know how good it is.\nsudo apt-get install totem-plugins-dvb-daemon\n\nThat will get all the dependencies too.\n\nA: You could always use mpv which has evolved from MPlayer.\nmpv --fs dvb://[card_number@]channel\nmplayer -fs dvb://[card_number@]channel \n\nThe -fs flag enables full screen mode.\n\nA: You're requesting to watch TV with VLC - well it is possible. See this answer.\n\n\n*\n\n*TV with VLC \n\nElse some illustrations of the other applications:\n\n\n*\n\n*TV with Me-TV \n\n\n\n*\n\n*TV with Kaffeine \n\n\nA: Me TV is a pretty decent under-appreciated application for DVB-* devices.\nHas an EPG, even recording facilities. Much, much lighter than MythTV.\nTo install Me TV in Ubuntu 16.04 and earlier open the terminal and type:\nsudo apt install me-tv\n\n\nA: tvtime is probably the simplest window type TV viewer. It works well with ATI cards. To install tvtime in all currently supported versions of Ubuntu run the following command:\nsudo apt install tvtime\n\n\nA: You could always just do mythfrontend -w and run MythTV  in a window. You may have to do Alt + Space to bring up a menu and leave fullscreen mode. Also, as I recall. there's a setting for the frontend to always start in windowed mode.\n", "Q: How do I display more than 5 bookmarks in gnome-panel \"Places\" menu? I found a thread on the Ubuntu forums, but it requires me to change the source of gnome-panel and recompile.  Is that really the only option if I want to see more than 5 bookmarks in the \"Places\" menu?  I have a huge monitor -- it seems funny to only show two bookmarks and push the others into a separate \"Bookmarks\" sub-menu.\n\nA: \nIs that really the only option if I want to see more than 5 bookmarks in the \"Places\" menu?\n\nYes. I'm suffering the same issue. I've posted bugs on Launchpad (marked a dupe of this one) and Gnome's Trac. I there are multiple BrainStorm threads too.\nThere are two elegant solutions:\n\n\n*\n\n*Look at the resolution when gnome-panel loads, work out some render geometry based on the current theme and set a soft limit\n\n*Just use a gconf key-value to have a user-alterable number.\nBut both solutions require somebody to code them, somebody to accept one patch and then somebody to repackage the new version for Ubuntu... In short, it's a change that isn't going to happen soon (unless somebody steps up and gets something pushed in as a Papercut for Maverick - might be too late even for that)\nManually patching the code to have a higher fixed limit is a pain in the bottom but it does fix the problem and (in fairness) doesn't take all day to do. Just make sure you lock the version of your gnome-panel package so updates don't wipe your changes.\nI'll go and poke people upstream and see if anything can be done about this.\n", "Q: How can I check if a package is installed (no superuser privileges)? At our university we can get almost any ubuntu package installed we want, but we are not superusers ourselves (we need to request packages being installed).\nWith some libraries it is not always easy to know whether the package is already installed or not. Is there a simple way/command to check this?\n\nA: One more variant, using aptitude this time:\naptitude show <package>\n\nTab completion works here as well.\n\nA: You can use dselect. It provides non-su read-only access.\nAlso, dpkg -s <package name> provides a lot of details related to a package. Eg\"\nuserme:~$ dpkg-query -s sl\nPackage: sl\nStatus: unknown ok not-installed\nPriority: optional\nSection: games\n\n\nA: apt-cache policy <package name>\n\n\nA: You may use dpkg-query -s <package> 2>/dev/null | grep -q ^\"Status: install ok installed\"$  in scripts, since it returns exit code 1, if the <package> is not installed, and 0 if the <package> is installed.\n\nA: dpkg-query --showformat='${db:Status-Status}'\nThis produces a small output string which is unlikely to change and is easy to compare deterministically without grep:\npkg=hello\nstatus=\"$(dpkg-query -W --showformat='${db:Status-Status}' \"$pkg\" 2>&1)\"\nif [ ! $? = 0 ] || [ ! \"$status\" = installed ]; then\n  sudo apt install $pkg\nfi\n\nThe $? = 0 check is needed because if you've never installed a package before, and after you remove certain packages such as hello, dpkg-query exits with status 1 and outputs to stderr:\ndpkg-query: no packages found matching hello\n\ninstead of outputting not-installed. The 2>&1 captures that error message too when it comes preventing it from going to the terminal.\nFor multiple packages:\npkgs='hello certbot'\ninstall=false\nfor pkg in $pkgs; do\n  status=\"$(dpkg-query -W --showformat='${db:Status-Status}' \"$pkg\" 2>&1)\"\n  if [ ! $? = 0 ] || [ ! \"$status\" = installed ]; then\n    install=true\n    break\n  fi\ndone\nif \"$install\"; then\n  sudo apt install $pkgs\nfi\n\nThe possible statuses are documented in man dpkg-query as:\n   n = Not-installed\n   c = Config-files\n   H = Half-installed\n   U = Unpacked\n   F = Half-configured\n   W = Triggers-awaiting\n   t = Triggers-pending\n   i = Installed\n\nThe single letter versions are obtainable with db:Status-Abbrev, but they come together with the action and error status, so you get 3 characters and would need to cut it.\nSo I think it is reliable enough to rely on the uncapitalized statuses (Config-files vs config-files) not changing instead.\ndpkg -s exit status\nThis unfortunately doesn't do what most users want:\npkgs='qemu-user pandoc'\nif ! dpkg -s $pkgs >/dev/null 2>&1; then\n  sudo apt-get install $pkgs\nfi\n\nbecause for some packages, e.g. certbot, doing:\nsudo apt install certbot\nsudo apt remove certbot\n\nleaves certbot in state config-files, which means that config files were left in the machine. And in that state, dpkg -s still returns 0, because the package metadata is still kept around so that those config files can be handled more nicely.\nTo actually make dpkg -s return 1 as desired, --purge would be needed:\nsudo apt remove --purge certbot\n\nwhich actually moves it into not-installed/dpkg-query: no packages found matching.\nNote that only certain packages leave config files behind. A simpler package like hello goes directly from installed to not-installed without --purge.\nTested on Ubuntu 20.10.\nPython apt package\nThere is a pre-installed Python 3 package called apt in Ubuntu 18.04 which exposes an Python apt interface!\nA script that checks if a package is installed and installs it if not can be seen at: https://stackoverflow.com/questions/17537390/how-to-install-a-package-using-the-python-apt-api/17538002#17538002\nHere is a copy for reference:\n#!/usr/bin/env python\n# aptinstall.py\n\nimport apt\nimport sys\n\npkg_name = \"libjs-yui-doc\"\n\ncache = apt.cache.Cache()\ncache.update()\ncache.open()\n\npkg = cache[pkg_name]\nif pkg.is_installed:\n    print \"{pkg_name} already installed\".format(pkg_name=pkg_name)\nelse:\n    pkg.mark_install()\n\n    try:\n        cache.commit()\n    except Exception, arg:\n        print >> sys.stderr, \"Sorry, package installation failed [{err}]\".format(err=str(arg))\n\nCheck if an executable is in PATH instead\nSee: https://stackoverflow.com/questions/592620/how-can-i-check-if-a-program-exists-from-a-bash-script/22589429#22589429\nSee also\n\n*\n\n*https://stackoverflow.com/questions/1298066/check-if-an-apt-get-package-is-installed-and-then-install-it-if-its-not-on-linu/54239534#54239534\n\n*How do I check if a package is installed on my server?\n\nA: Simpler solution:\nThere is now an apt list command that lists installed packages.  You can also search for a specific package with\napt list <package>\n\nSee man apt for more information.\n\nA: I always just use this from the command line:\ndpkg -l | grep mysql\n\nso the above asks dpkg to list all the installed packages and then I grep for only those that have mysql in the name.\n\nA: You need to check the status printed by dpkg -l, example :\n$ dpkg -l firefox-esr vim winff\nDesired=Unknown/Install/Remove/Purge/Hold\n| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend\n|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)\n||/ Name                                 Version                 Architecture            Description\n+++-====================================-=======================-=======================-=============================================================================\nhi  firefox-esr                          52.9.0esr+build2-0ubunt amd64                   Safe and easy web browser from Mozilla\nii  vim                                  2:8.1.1198-0york0~14.04 amd64                   Vi IMproved - enhanced vi editor\nrc  winff                                1.5.3-3                 all                     graphical video and audio batch converter using ffmpeg or avconv\n\nHere both vim and firefox-esr are installed, therefore you can type : \n$ dpkg -l firefox-esr | grep -q ^.i && echo This package is installed. || echo This package is NOT installed.\nThis package is installed.\n$ dpkg -l vim | grep -q ^.i && echo This package is installed. || echo This package is NOT installed.\nThis package is installed.\n$ dpkg -l winff | grep -q ^.i && echo This package is installed. || echo This package is NOT installed.\nThis package is NOT installed.\n\n\nA: Example to use specific value as var in shell scripts (eg test.sh)\n#!/bin/sh\nPACKAGE=\"${1}\"\nINSTALLED=$(dpkg -l | grep ${PACKAGE} >/dev/null && echo \"yes\" || echo \"no\")\n\necho \"${PACKAGE} is installed ... ${INSTALLED}\"\n\nMake it executable and go start with:\ntest.sh openssh-server\n\nOr do whatever you want with in your scripts\n", "Q: What are some good GUI diff and merge applications available for Ubuntu? What are some alternatives to WinMerge and the pros and cons of each?\n\nA: Another one is diffuse\n\nIt is free, crossplatform (written in python), has source code highlight, can interact with many version control tools.\n\nA: Kdiff3\nIs a pretty good 3 way merge tool.\n\nSome of its features are:\n\n\n*\n\n*compares or merges two or three text input files or directories,\n\n*shows the differences line by line and character by character (!),\n\n*provides an automatic merge-facility and\n\n*an integrated editor for comfortable solving of merge-conflicts,\n\n*supports Unicode, UTF-8 and other codecs, autodetection via byte-order-mark \"BOM\"\n\n*supports KIO on KDE (allows accessing ftp, sftp, fish, smb etc.),\n\n*Printing of differences,\n\n*Manual alignment of lines,\n\n*Automatic merging of version control history ($Log$),\n\n*and has an intuitive graphical user interface.\n\n*Windows-Explorer integration Diff-Ext-for-KDiff3 - shell extension included in installer\nKDE-Konqueror service menu plugin\n\n\nA: The best I like is Meld\nThere are many choices available though. As a vim fan I find myself using vimdiff, kompare for the kde crowd - there also some paid version that have linux versions like Beyond Compare . The pros/cons depends on what you're looking for/looking to do. \nvimdiff is great because you can run it from a terminal, over an ssh connection, and if you already use vim, you get to keep your tools/config options. \nMeld has a pretty clean user interface, and does three way and directory diffs. You'll have to try a couple and see which does the job as you're expecting them to do for your own needs.\nTo install Meld from the Ubuntu repos, you can run:\nsudo apt-get install meld\n\nYou can then pick the files/folders to compare, and compare them:\n\n\n", "Q: How should I set up a Linux file server for data sharing with Windows PCs and a PS3? I have the following pieces of hardware I would like to network mostly for file sharing (media primarily): 1 gaming laptop, 1 i7 (2.3Tb storage) desktop, 1 P4 desktop (500g storage), and 1 250gig PS3.\nI am looking to setup a linux host (with a PS3 media server) with the i7 desktop but am concerned about leaving it on all the time. What stripped down, low energy usage distro can I couple with which windows & PS3 friendly software?\nAlso, how should i reformat my i7 (in terms of partitions, RAID options, whatever)? It has 2 1Tb drives (likely adding a third), and 1 320 gig.\n\nA: Here's how we have our media server set up at my house (Dell Blade server w/2 Pentium Dual Cores, 8gb RAM and a 1.5TB HDD and an old 80gb hdd).  It's very basic but works splendidly.\nMain OS: Ubuntu Server Edition (check the options for Samba during the install).\nHDD Setup: All ext4. The OS is on it's own 20gb partition on the 80gb drive with /home being on a separate partition.  The reason the main OS is on a separate drive is we were debating putting it on an SSD, but never got around to it.  The 1.5 TB drive is mounted to /media/data (make sure this is done in /etc/fstab, not manually, as mediatomb likes to have it available when it loads).\nMedia Sharing: Set up samba to share /media/Data (allow guest, no authentication sharing).  Standard samba setup really.  Install mediatomb (UPnP) and follow the instructions on their wiki regarding sharing with a PS3 (basically uncommenting 1 line in a config file).  Use the mediatomb web interface to select which directories you want to share.  Pretty easy.\nOther Thoughts: Read through the mediatomb options and wiki's, there's a lot of other features you can enable through the GUI and also the config file.  I know we changed the behavior it monitors directories and also how often it scans directories for new files.\nIt should be relatively easy to set up, and when you are done you have an excellent media server.\n\nA: Not too sure on the sharing with Windows, but as far as the ps3 goes, I use Playstation media server. It's written in Java so you can use it on any platform as long as you have java installed. It's probably the easiest thing I've found so far and I just keep it running all the time.\nhttp://code.google.com/p/ps3mediaserver/downloads/list\n\nA: Normally the easiest way to share files over a network is to use Samba which is very easy for sharing files with Windows. However, I don't think it works with the PS3. Your best bet is to use DLNA which you can use with a program called Rygel (Available from the Ubuntu Software Centre).\nI would recommend using plain Ubuntu but installing openbox which is a lightweight window manager and running a plain openbox session when it is acting as just a server (though you may want to do configuration in GNOME).\nI don't know much about RAID but I would install Linux on an 8GB ext4 partition on the 320GB drive and format all of the other space as ext3 to use as your media storage. It may be a good idea to use RAID to split the space into two where one mirrors the other to act as backup if you know how to do this.\n", "Q: Upload photos to Facebook page (not personal profile) A couple of the various Linux photo organizer applications (Shotwell & f-spot, at least) let you upload pictures to Facebook, but as far as I can see, that's limited only to albums on your personal page. Am I just missing something, and it is actually possible to use either Shotwell or f-spot to upload to albums in a page you are an administrator for? If not, is there another Picasa-type program that has this feature?\n\nA: @fluteflute is not totally wrong. It is right that, BY DEFAULT Picasa doesn't support Facebook (or Gallery2, Flickr or anything other than Picasaweb), but Picasa is extendable and has several modules to do so:\n\n\n*\n\n*http://apps.facebook.com/picasauploader/\n\n*http://googlesystem.blogspot.com/2007/06/picasa2flickr-upload-photos-from-picasa.html\n\n*http://codex.gallery2.org/Gallery2:Modules:picasa\nI've never used the Facebook or Flickr modules but the gallery2 one, yes, and it's not so easy to install at all, but it works.\nSo to answer Steve K, yes, you can use Picasa to upload your pictures to Facebook, but with the installation of a specific module.\n\nA: Shotwell can't currently do this.  I've ticketed it: http://trac.yorba.org/ticket/2942\nI'm not sure Facebook makes uploading to group pages available via their API.  If they do, I'd like to see this feature.\nNote that if you upload to your personal account, you can add those photos to a group you administer without re-uploading them through the browser.\n\nA: I don't have a page to try that so I can't tell, but you might want to try Digikam, which has a good uploader.\nIf all else fails, Picasa is available on Ubuntu, although not open-source.\n", "Q: Is there a Linux software RAID that can be shared with a windows installation? What are the options I've got when it comes to RAID and Windows?\n\nA: You have 3 \"models\" of RAID, and 3 answers to your question:\n\n\n*\n\n*The hardware RAID: It should work on Linux and Windows, and it's transparent and makes everybody believe there's just one drive (if you're doing RAID1 for example).\n\n*Semi-hardware RAID(or FakeRAID): In fact it's in reality 99% software RAID. Take a look at the FAQ about it. If you have a driver for Windows AND Linux, it's mostly OK.\n\n*Software RAID. I don't know any software that is compatible between Linux and Windows, so it's a no.\n\n\nA: dmraid should be able to do this. dmraid is the driver for so called \"FAKERAID\" solutions you on lots of motherboards these days, chipsets that offload all their work to the CPU.\nI can't guarantee it will work though. You'll need a supported dmraid chipset, some disks and a cross-platform filesystem to test it... And I seriously suggest you do test it before investing any data into the setup. \nAs far as filesystems go, NTFS support in Ubuntu is much better than ext-n support in Windows. At least it was the last time I checked.\n", "Q: Where can I find the source code for the Ubuntu Kernel? I'd like to build my own copy of the Ubuntu kernel. Where can I get the source code?\n\nA: Best place is from the kernel team git repositories, see:\n\n\n*\n\n*https://wiki.ubuntu.com/Kernel/Dev/KernelGitGuide\n\nA: For building kernels, it is strongly suggested that you use git to get\nthe latest source code from the Ubuntu kernel git repositories.\nThese repositories contain all updates to Ubuntu kernels, including ones\nwhich are proposed for release but not released yet. By fetching from\nthe repos, you will be guaranteed to have the latest code.\nIf you want to fetch the source for a specific release, you may check\nout the tag associated with that release. Tags are similar to this\nexample: \"Ubuntu-2.6.32-17.26\". The final number is an upload number\nwhich is sequentially increased, and the rest is the version number.\nYou can see a list of the Ubuntu kernel repositories here:\nhttp://kernel.ubuntu.com/git\nThis page also lists a number of repositories for individual developers.\nThe official Ubuntu kernel repositories begin with \"ubuntu/ubuntu-\"\nIf you are looking to just get the sources to the kernel that you are\ncurrently running you can:\n\napt-get source linux-image-$(uname -r)\n\n\nA: https://help.ubuntu.com/community/Kernel/Compile\nfollow this steps, before apt-get source you should run \nsudo apt-get build-dep --no-install-recommends linux-image-$(uname -r)\n\n\nA: I believe you can find the Linux Kernel maintenance here: LaunchPad: Linux Kernel\nHowever, while the kernel for Ubuntu may be referred to as the Ubuntu Kernel - it's actually the Linux Kernel modified by the Ubuntu Kernel Team. You can find more information about the Ubuntu Kernel Members and how to get the Ubuntu Kernel using Git on the Ubuntu Wiki: Kernel\n\nA: Download from the Git Repo:\ngit clone git://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/$RELEASE_NAME\n\nOn Jammy Jellyfish (22.04), for example:\ngit clone git://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/jammy \n\n\nA: You can get the unmodified Linux Kernel at kernel.org.\n", "Q: LDAP server set-up I'd like to set up LDAP to act as central authentication of 2 web applications running on the same server.\nWhats the simplest step-by-step way to go about this from scratch?\nIn the long run I'd also like to be able to administer the users on the system as simply as possible (think end users, not devs!)\n\nA: because ldap is VERY hard to setup for beginners i would recommend an server configuration tool. (trust me i have spent nights to fight against openldap)\nyou can checkout ebox (its a server managment gui) and it configure openldap-server + samba ( windows domain logons)\nDoku:\nhttp://doc.zentyal.org/en/directory.html\n\nA: Maybe this tutorial answers your question.\n\nA: Try to follow the chapter on installing and configuring an OpenLDAP server in the Ubuntu Server Guide.\n\nA: U can try all these links..\nhttp://times.usefulinc.com/2005/09/25-ldap\nhttp://www.howtoforge.com/installing-and-configuring-openldap-on-ubuntu-intrepid-ibex\nhttp://www.debuntu.org/ldap-server-and-linux-ldap-clients\nhttp://beginlinux.com/server_training/server-managment-topics/1017-ldap-client-on-ubuntu-804\n\nA: Look at this also: http://www.youtube.com/watch?v=DM_UQVVVtoY\nThe guy that made it, explains it fairly decent.\n", "Q: Where can I change the automatic lock screen preference? I'm using ubuntu in a VM, so, I leave it idle from time to time. When I go back obviously the screen is locked, but I would like to configure the idle time for something around 10 minutes. Where can I do this?\n\nA: Open up the screensaver preferences: System ➜ Preferences ➜Screensaver.  \nYou will see a slider to set the idle time:\n\n\nA: To prevent the screen from being locked when the computer wakes up from suspend or hibernation, do the following:\n\nopen gconf-editor\nnavigate to: apps > gnome-power-manager > lock\ndisable the appropriate flags.\n\nThis worked like a treat for me\nThanks\n\nA: Perhaps:\nSystem > Preferences > Power Management\nSystem > Preferences > Screen Saver\n\nA: To prevent the screen from being locked when the computer wakes up from suspend or hibernation, do the following:\n\n\n*\n\n*open gconf-editor\n\n*navigate to: apps > gnome-power-manager > lock\n\n*disable the appropriate flags.\n\n\nI know this is not related to running Ubuntu in a virtual machine, but it might be useful for others nonetheless.\n", "Q: How to assign a serial port to my bluetooth phone? I used hcitool scan to get the MAC address of my phone.\nThen I used sdbtool browse to find the channel of the \"Serial Port\" service.\nI put this information into /etc/bluetooth/rfcomm.conf and this is what the file looks like:\n\n#\n# RFCOMM configuration file.\n#\n\nrfcomm0 {\n    # Automatically bind the device at startup\n    bind yes;\n\n    # Bluetooth address of the device\n    device 00:00:00:00:00:00;\n\n    # RFCOMM channel for the connection\n    channel 00;\n\n    # Description of the connection\n    comment \"...\";\n}\n\nNote: The MAC address and channel are in there... I just don't want to print them here.\nI restarted the bluetooth service and went to /dev - but I couldn't see rfcomm0 or anything close to it in there.\nWhat am I doing wrong?\n\nA: Is it possible that your phone doesn't have serial port support?  My old blackberry didn't.\nI'd also advise you to try Blueman, which can scan and show the services available on your phone AND automatically bind it to network manager for tethering (although admittedly I think the latest bluez does that second part too now).\n", "Q: How can I make a program (using SDL) built on Ubuntu work on other systems? I'm writing a program that uses OpenAL. When I link against it (I'm using CMake), it also links against libpulse - PulseAudio. This results in the binary not working on other systems. Can I somehow not link against PulseAudio and still use OpenAL on Ubuntu?\nEdit:\nI just figured something out: It's not OpenAL that's dragging PulseAudio in, it's SDL. Is there anything I can do about that?\n\nA: Build the binary separately on each platform you want to supply binary packages for and make sure you distribute the source code so that people on other platforms can build it for themselves.\nNote that Linux focuses on source compatibility rather than binary compatibility. Most distributions are not binary compatible with each other (not even Ubuntu and Debian are completely compatible*).\nThis is a somewhat related question:\nTechnically speaking, what is different about Ubuntu compared to other Linux distributions?\n\nA: About the SDL pulseaudio you can simply install libsdl1.2debian-alsa, it will remove the pa-sdl version and link against ALSA libs. Still you are likely to get other binary/library related compatibilities like dv3500ea mentioned.\nA common approach to avoid system related dependency issues is by using static linking. This will make the binaries much larger because they include the required code from the libraries.\nFor more information on static linking check:\nhttp://wiki.linuxquestions.org/wiki/Static_linking\n", "Q: How do I install and manage RPMs? I have a burning desire to install RPMs onto my Ubuntu installation - is this possible? Can I use Yum - or another RPM Package Management tool?\n\nA: The short answer is, Don't!\nIf you got an RPM that is so important that you need to have it, there is probably a Ubuntu package as well; and, if not, it is probably worth going through the trouble of compiling it from source into the Debian package format (that Ubuntu uses as well). Now, there are certain times when you can't just recompile the software (if it's not opensource it's impossible) and in that case you can use the alien program. But, installing from RPM's is a little like putting gasoline in a diesel car - it might work, but you wont benefit from it in the long run!\nTo build a package from source, there is a guide on the Ubuntu Wiki; there is also a program called checkinstall that can do some tricks with a default source-tree without setting up build instructions for the package. If you think that someone else can benefit from the programs that you compile, you can setup a repository on launchpad and share the package goodness!\n\nA: Theres a GUI package manager named SmartPM on the Repos, it can handle .deb AND .RPM. Canonical contributed to this project up to November 2009.\nThe projects home page is here https://github.com/smartpm/smart\n\nA: If you really need to install RPMs on your system you should indeed try to convert them using 'alien'.\nPlease keep in mind that by default 'alien' will meddle with the version number of the package. If you want the version number to stay the same, pass the option '-k' when converting.\nYou should not try to use Yum or any other way of installing the RPMs, such as apt-rpm, themselves next to the existing DEB packages. The DEB and RPM systems manage the list of installed software separately and therefore don't know what packages were installed previously by the other system. If, e.g., you'd try to install a GUI-bearing application with an RPM-based package management system, it'll try to install vital system components itself, because it thinks they are not installed yet. This will either cause the installation to fail horribly, or overwrite vital system files.\n\nA: Alien is a tool that convert from one format(.deb or .rpm) to another (.deb, .rpm or tarball)\nAlien is not advised to use in converting from .deb to .rpm its perfect to use in converting .deb to tarballs\nAlthought Alien attempts to preserve meta-data when converting but it will still have Metadata & dependency problems make package less reliable and thus will conflicts ehen adding or removing distirbution packages in the future.\n\nA: Actually shortest option is \nsudo alien -i -k packagename.rpm\n\nDon't have an alien? Get one!\nsudo apt-get install alien\n\nAlien will convert rpm package into deb package, the -i option means install the converted package after is converted and the -k option ensure version is not +1 after conversion.\n\nA: Follow these instructions:\nalien -k avg71lms-r30-a0782.i386.rpm\n\nNow you should be having avg71lms-r30-a0782.i386.deb file.\nTo install .deb file:\ndpkg -i avg71lms-r30-a0782.i386.deb\n\nIf you don't use -k option you should see avg71lms_r30-1_i386.deb file the difference is it will add 1.\nInstall alien in Ubuntu:\nsudo apt-get install alien\n\nYou can check the above section for available options\n\nA: You will need alien to do that.\nsudo apt-get install alien\n\nThis will install all the required packages.Now you can start converting your .rpm files to .deb packages.\nAvailable Options for alien:\nConvert the package.rpm into a package.deb\nsudo alien -d package-name.rpm\n\nConvert the package.rpm into a package.deb, and install the generated package.\nalien -i package-name.rpm\n\nIf you want to keep alien from changing the version number use the following command\nalien -k rpm-package-file.rpm\n\n\nA: \nCan I use Yum\n\nI wouldn't recommend it. You probably could compile it but you wouldn't have any Ubuntu-compatible package repositories for it to handle.\nYou can convert single RPM files into DEBs with Alien:\nsudo apt-get install alien\nsudo alien my_package.rpm\nsudo dpkg -i my_package.deb\n\nNote: It might change the filename a little more than just the extension.\nThis won't work for everything as packages link to other packages to fulfil dependencies. Obviously Red Hat/Fedora/CentOS use different package names to Ubuntu so you're likely going to run into a whole load of pain.\nChances are if a DEB doesn't exist, you'll be better off just getting the source and compiling it.\n\nA: With alien I can just convert the .rpm file to a .deb file and simply install that one.\nAlien is available in the normal Debian repositories, so we can install it like this:\nsudo apt-get install alien\n\nTo convert it into a .deb package, we simply run\nalien *.rpm\n\n\nA: use alien which converts the rpm to deb and subsequently installs the deb. \n\nA: Here is a GUI for Alien (alien is an application to convert rpm to deb)\nhttp://code.google.com/p/foxoman/wiki/PackageConverter\n", "Q: How is the default TERM shell variable value set? After upgrading to Maverick I have my TERM variable set to 'dumb', this does not happen with the same home dir running from Lucid and I didn't manually changed anything related to TERM.\nAny idea where is the TERM variable expected to be set from?\n\nA: To elaborate on what Gilles says, suppose you are remote connecting to your ubuntu from Windows using Putty.\nIn the putty config options, under Connection->Data there is a setting called terminal-type string. You can set your TERM there and putty instructs SSH to set that environment variable. At some point after that your shell is going to be executed, probably /bin/bash and it gets its environment from its parent process, probably the sshd process.\nThe same holds true if you ssh from a remote linux box, its just that the local TERM environment variable is passed through via ssh to the remote connection.\nIn the case of a terminal emulator it is the job of the terminal emulator to set the TERM environment variable. e.g. getty sets TERM to \"linux\" and forks a shell process (/bin/bash). or gnome-terminal sets TERM to \"xterm\" and forks a shell process.\n\nA: To answer your question literally, the terminal emulator is supposed to set $TERM.¹\nTo solve your problem would require at least knowing what terminal emulator you use. It could be a bug or misconfiguration in the terminal emulator or a problem with your shell startup files (probably ~/.bashrc, but possibly ~/.bash_profile, /etc/bashrc, /etc/profile, ...).\n¹ Assuming you're not using a hardware terminal; then it would be the argument to getty, called from inittab (older releases using SysVinit) or /etc/init/tty*.conf (Ubuntu ≥9.10, using Upstart).\n\nA: If you want to change the terminal make sure you check out the update-alternatives functionality. \nFor instance:\nupdate-alternatives --config x-terminal-emulator\n\nMany of the various system default options in Ubuntu are set via this method. Another common one would be a www-browser\nupdate-alternatives --config x-www-browser\n\n", "Q: Dual Boot - Ubuntu 9.10, 10.04 - /home Cannot Be Initialized Upon Startup I recently installed 9.10 64-bit on a system that had 10.04 already installed.  I thought I performed this installation correctly, but when I came to grub2 and chose the option I wanted, I got some errors.\nFirst, I got the following message before the log in screen appeared:\nThe disk drive for /home is not ready yet or not present.\nContinue to wait; or press S to skip mounting or M for manual recovery.\nI rebooted and logged into the freshly installed 9.10 boot and this worked fine.  I found the partition that 10.04 is on and created a user directory in /home that is a copy of the 9.10 /home.  I named the user directory the same as it was previously, so there was no difference.\nI then changed ownership and group of this newly created directory and then rebooted.  I got the same error:\nThe disk drive for /home is not ready yet or not present.\nContinue to wait; or press S to skip mounting or M for manual recovery.\nbut this time when I press S to skip, I was able to log in and see my desktop.  The actions I did seemed to allow for log in but still the mounting of /home is not working as it should.\nOne thing I should mention.  When installing 9.10 64-bit, I had some extra hard disk space available and I chose to format this to ext4 and then mount it to /home.  This may be causing problems, but I thought when doing this it would mount to the /home for the new installation.  It seemed to try to mount it on the old installation, though (the 10.04 one).\nI hope this wasn't too confusing.  Any help is much appreciated.  \nThanks in advance.\nEDIT - For the 9.10 installation /etc/fstab:\n# /etc/fstab: static file system information.\n#\n# Use 'blkid -o value -s UUID' to print the universally unique identifier\n# for a device; this may be used with UUID= as a more robust way to name\n# devices that works even if disks are added and removed. See fstab(5).\n#\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>\nproc            /proc           proc    nodev,noexec,nosuid 0       0\n\n# / was on /dev/sda1 during installation\nUUID=10270f21-1c42-494b-bd3f-813c23f6d518 /               ext4    errors=remount-ro 0       1\n\n# /home was on /dev/sda6 during installation\nUUID=fc128610-a6d5-4d23-9898-064580419da0 /home           ext4    defaults        0       2\n\n# swap was on /dev/sda5 during installation\nUUID=d3644f61-b65c-4f30-9eb5-cda163f9fce5 none            swap    sw              0       0\n\nFor the 10.04 installation:\n# /etc/fstab: static file system information.\n#\n# Use 'blkid -o value -s UUID' to print the universally unique identifier\n# for a device; this may be used with UUID= as a more robust way to name\n# devices that works even if disks are added and removed. See fstab(5).\n#\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>\nproc            /proc           proc    defaults        0       0\n\n# / was on /dev/sda6 during installation\nUUID=28fd6eb0-38a2-4c22-86d8-f7dce7508ac4 /               ext4    errors=remount-ro 0       1\n\n# /home was on /dev/sda7 during installation\nUUID=97f82eca-0fdd-49e1-a12b-b4e1f6adbcbb /home           ext4    defaults        0       2\n\n# swap was on /dev/sda5 during installation\nUUID=d3644f61-b65c-4f30-9eb5-cda163f9fce5 none            swap    sw              0       0\n\n/dev/scd0       /media/cdrom0   udf,iso9660 user,noauto,exec,utf8 0       0\n\nEDIT 2:\nfdisk -l output:\nDisk /dev/sda: 250.1 GB, 250059350016 bytes\n255 heads, 63 sectors/track, 30401 cylinders\nUnits = cylinders of 16065 * 512 = 8225280 bytes\nDisk identifier: 0xcbcbcbcb\n\nDevice Boot      Start         End      Blocks   Id  System\n/dev/sda1   *           1        6231    50049483+  83  Linux\n/dev/sda2            6232       30401   194145525    5  Extended\n/dev/sda5           12158       12773     4939776   82  Linux swap / Solaris\n/dev/sda6            6232       12157    47600532   83  Linux\n/dev/sda7           12774       30401   141596878+  83  Linux\n\nPartition table entries are not in disk order\n\nblkid /dev/sda* output:\n/dev/sda1: UUID=\"10270f21-1c42-494b-bd3f-813c23f6d518\" TYPE=\"ext4\" \n/dev/sda5: UUID=\"d3644f61-b65c-4f30-9eb5-cda163f9fce5\" TYPE=\"swap\" \n/dev/sda6: UUID=\"28fd6eb0-38a2-4c22-86d8-f7dce7508ac4\" TYPE=\"ext4\" \n/dev/sda7: UUID=\"97f82eca-0fdd-49e1-a12b-b4e1f6adbcbb\" TYPE=\"ext4\"\n\n\nA: If you making a /home dir on the 10.04 means you don't intend for it to have a separate /home partition, then just delete\n# /home was on /dev/sda7 during installation\nUUID=97f82eca-0fdd-49e1-a12b-b4e1f6adbcbb /home           ext4    defaults        0       2\n\nfrom its /etc/fstab\n\nA: The home partition of your 9.10 install, uuuid finish in 19da0, doesn't seem to exist on your computer.\nIf you want to share your home partition in both OS, change it to the other uuuid in the 9.10 fstab.\nBut I don't believe that this is a great idea. Different version of every program are going to touch the same config files and sooner than later something will get funny.\nYou should probably repartition your disk to make space for another home. Assign it in 9.10. Mount the 10.04 home in another path and link the non-config files of the 9.10 install to it. Dirs like Documents, Music, etc...\nIf you don't want a separate home partition in 9.10 do as Maco told, just delete that line. Everything should be fine as now your home is probably on the f6d518 disk.\n", "Q: Changing my AIM alias in Empathy doesn't work I try to change my nickname for my AIM account in Empathy. And the change doesn't seem to take. Whatever I do, it just kind of stays the same. It works fine for my Google talk account... Iunno.\n\nA: This is a bug in Telepathy. \n", "Q: Is it possible to install Ubuntu on a corporate laptop that is currently running Windows XP with Utimaco's disk encryption software? A new laptop issued to me is now running a product called \"Safeguard Enterprise 5.35 Utimaco Software\".  Has anyone had success installing Ubuntu in this situation?\n\nA: It's your company's laptop not yours. You should probably ask them if they agree to you installing Ubuntu. It's unlikely as they usually have good reasons to run encryption software on it.\nThere are a couple of compromises: you can likely run Ubuntu inside a VM like Virtualbox and the cryptographic solution will still work.\n\nA: You cannot if the mbr is being watched for changes. It will always revert to the old state. You need to turn that specific routine off before installation. You should turn it on afterwards. (Utimaco system password is needed!) Anyway I would not recommend it, thogh it works fine.\nWhy not boot your Linux from a pendrive instead?\n\nA: Have you tried using Wubi? It comes with the Live CD. Just install it via Windows.\n\nA: I haven't used that software. Laptop hard disks are pretty cheap. If I had a corporate-issued laptop that I wanted to use to run Ubuntu, but I didn't think I would get meaningful support from the IT department, I'd buy my own hard disk, put their (the corporation's) hard disk in my desk drawer, and then install Ubuntu on my disk. If you ever quit or get fired or have to give the laptop back, take your hard disk out and give them back their (unused) hard disk.\nIn this circumstance, I'd give some serious though to encrypting either the entire system disk, or at least your home directory, because there's some chance that you will be separated from your laptop at some point in the future, and may have to negotiate (perhaps unsuccessfully) to get control of your hard disk again. \nOn the other hand, there's probably a reason I'm self-employed.\n", "Q: How do I handle patch rejects after applying patches with uupdate? I used uupdate to update a source package from 0.7.0 to 0.7.3.  It does this update with patches and I had a few patch rejects.  I am unsure what to do next.  Do I:\n\n\n*\n\n*edit the old source package (0.7.0) and then re-run uupdate?\n\n*edit the new source package (0.7.3) and then re-run uupdate?\n\n*edit the .rej files directly?\n\n*use a tool such as kdiff3?\n\n*try something else?\n\n\nAt this point, I'm thinking that the answer is to use a tool which is more along the lines of what I'm familiar with (coming from a Tortoise Merge and clearcase merge background).\nI have searched high and low for how people manage patch rejects and I've had no luck, so I will gladly RTFM if you can provide a link to a FM if one exists.\n\nA: I agree with @maco on manually resolving the conflict. Seeing the options you give, you probably need to really understand what uupdate does, which is:\n\n\n*\n\n*extract the new tarball in the parent directory ;\n\n*try to apply the previous diff.gz (unless you're using a v3 (quilt) style) to the new directory.\n\n\nThe patch rejections come from applying this diff.gz to the new directory.\nNow to go through your options:\n\n\n*\n\n*edit the old source package => you shouldn't modify the old source package in order to create the new one ;\n\n*edit the new source package and re-run uupdate => there is no point in doing so, because the patch fails to apply to the new source, and you shouldn't modify the original source (except with patches, which are found in the diff.gz) ;\n\n*edit the .rej files => the .rej files are here to show you what failed to apply ; editing them won't fix your issue but you should have a look at them to see if the failed changes need to be applied ;\n\n*use a diff tool => sure, that can be a good idea, (vim -d is your friend) although the .rej files should already give you an idea of what failed to apply. You can also read the previous diff.gz to have an idea of what files it was modifying.\nGenerally, most of the uupdate conflicts I've met were due to bad packaging in the previous version of the package, namely a diff.gz which modified the source instead of just adding a debian/ directory. This can be checked easily:\nzcat ../yourpackagename_0.7.0-1.diff.gz | diffstat\n\nwill give you the list of files modified by the previous patch (adapt the file name to your needs). If you find files that are not in the debian/ directory in this list, then your problem is most certainly there. In this case, check what has been changed:\n\n\n*\n\n*In most cases, it is an autotools mess when debuild -S was called: one of the autoconf/automake scripts was modified and this modification won't apply anymore. It is usually safe to drop this change in the new version ;\n\n*In some other cases, the source code has been patched manually (without using dpatch/simple-patchsys/quilt/whatever else). In this case, check if the patch should still be applied to the new version (read the changelog for example). If it does, then make a clean patch using a proper patch manager. Future packagers will thank you for that :-)\n\n\nA: I would just manually resolve the conflicts and run debuild -S as usual. \n", "Q: Used recursive chown on the root directory Im gonna need some help restoring my ssh settings as i screwed everything up by calling this command:\nchown -R user /\n\nAt the moment im not able to access the site through ssh/ftp since the ownership of all the files have been changed. I dont want to reset every ownership but if i could get ssh working i would be able to create a backup of my files and then get a clean install of ubuntu on my server.\nHere is the error that i get when im trying to restart ssh:\n/var/run/sshd must be owned by root and not group or world-writable.\n\nIm running ubuntu 10.04 LTS. Any help is very much appreciated.\nP.S. I am able to run ssh commands on a browser based AJAX console that my hosting company (linode) provides.\nThanks\n\nA: First to stop the error message change the owner of /var/run/sshd back to to root.\nThere might be more errors afterwoods, which probably mean you need to change other files too.\n\nA: Wow. You might be able to restore your permissions. It's a long shot but possibly worth considering if you've customised the install a lot.\nHere's something I just concocted. This should (not tested) set every file in the root group to be owned by root.\nsudo find / -group root -exec chown root {} \\;\n\n\nA: Well, best/easiest thing would be to restore your backup. You do backups, right?\nBesides, this blog post describes some approaches to reset permissions this via apt-get/dpkg. Before trying this, you should do something like Oli posted (chown everything or a subset back to root again).\nIf you don't do backups, now is the time to start! ;)\n", "Q: Weird Mouse Problem I'm facing a weird problem. My mouse automatically focuses on menu items. \nI'm unable to navigate menus with keyboard if the cursor rests on a menu item as it keeps stealing focus. I can live with this behaviour in regular apps but it won't let me play any full-screen games as the cursor remains locked in a fixed position.\nI tried turning off compiz and removing all the dotfiles but it didn't help. \nHere is a video my mouse stealing focus:\nhttp://dl.dropbox.com/u/275756/mouse.ogv\n\nA: Do you happen to use unclutter (as I do/did)?\nI see this behaviour when unclutter is running, but not when I kill it.  I am not sure why it happens, as it happens \"long\" before unclutter hides the mouse pointer.\nIt also seems like there are a bunch of bug reports related to this issue (only 3 or 4 out of 17 bugs are about unrelated issues, it seems).\n\nA: Can you try another mouse? I say that because I've had something like this before (way back when I was on Windows) and it was actually a dodgy connection in the mouse's cable that was causing tiny movements. It looks like your cursor doesn't move but there might tiny movements that you can't see.\nActually on that note you could fire up xev from a terminal and leave your cursor in the white box that pops up. If, once you've left the mouse alone, signals still explode out of the terminal, you've got a problem. You'll see which signals they are. If they're movement-related, it's probably a dodgy mouse.\nIf it's sending a full click, it could be hardware but it could also be accessibility settings kicking in. Check Preferences>Mouse>Accessibility and make sure \"Dwell Click\" is turned off.\n\nA: I cannot reply to other's answers yet, so here my comment to the first answer: please note that making 'unclutter' part of Ubuntu Maverick's default installation was a communication failure and not intended to happen. Indeed, the change was reverted quickly after 'unclutter' accidentally was made part of the default installation. If you have it installed still, you can remove it and should, if you want your installation to follow the official desktop.\n\nA: At around 00:20 in your video, did you click the window to focus it, or did the window focus automatically on mouse hover? It seems like something is left-clicking the pointing device (mouse/touchpad) every few seconds.\n", "Q: Good NVidia drivers for a GeForce GT 330M on a VAIO laptop? With the latest 3 distribution versions of Ubuntu I've always had problems with NVidia GPUs. Even when I installed the official commercial drivers (which are not in the repositories and are shown as proprietary) I also had problems with the display.\nThe specific version of the GPU I'm using now is GeForce GT 330M on a VAIO laptop. Can you guys recommend a driver that is stable and works well, supporting most (if not all) GPU features for NVidia GPUs? Have you had the same problems and how did you solve them?\n\nA: This is very specifically an issue with Sony VAIOs. The latest nvidia drivers should work but there's an EDID detection issue (how the video card finds out the monitors supported modes). \nThis post should provide a fix and there's a handy link at the bottom for ironing out any other quirks:\n\nWhat I found was that Lucid's kernel\n  (I believe all >= 2.6.32 kernels) has\n  built-in driver for nvidia, called\n  \"nouveau\". This one is built right\n  into initrd image and is the one that\n  causes the workspace to be bigger than\n  the actual screen.\nNaturally I though of installing\n  invidia drivers instead of nouveau,\n  but that wasn't easy. I couldn't\n  unload nouveau in any way (I believe\n  because it's built-in and not shipped\n  as module) and with nouveau loaded\n  nvidia's installer would fail.\nSo what I had to do first, was to\n  disable the nouveau driver. I did it\n  by putting the following parameter to\n  /etc/default/grub:\n  GRUB_CMDLINE_LINUX=\"nouveau.modeset=0\".\n  Then I had to invoke sudo\n  update-grub.\nHaving added this parameter, I\n  rebooted and got 800x600 resolution,\n  bacause now there was no driver in\n  kernel to support the 330M GPU (but\n  naughty nouveau was finally gone!).\n  Switching to command-line mode by\n  sudo service gdm stop and by\n  installing nvidia latest drivers\n  (195.36.24) I almost got it done, but,\n  not yet. Original nvidia driver\n  loaded, but failed to correctly draw\n  anything on the screen.\nAfter searching a bit I found on the\n  page linked in the bottom of this post\n  that Sony Vaio F's LCD panel EDID\n  isn't recognized by nvidia drivers\n  automatically, so you have to \"help\"\n  drivers in this matter: after\n  finishing installing nvidia drivers\n  (and before the reboot) you have to\n  add the following lines to \"Device\"\n  section of xorg.conf:\nCode:\nOption         \"ConnectedMonitor\" \"DFP-0\"\nOption         \"CustomEDID\" \"DFP-0: /proc/acpi/video/NGFX/LCD/EDID\"\n\nand only then reboot. You'll be happy\n  to see log-in screen in fullhd!\nNVidia's driver still behaves\n  strangely on my Sony (no sound over\n  HDMI, poorly working display backlight\n  settings, no ability to switch to text\n  mode via CTRL-ALT-N (1-6)), but\n  general functionality is ok, including\n  native fullhd desktop resolution, 3d\n  acceleration etc.\nPS A lot of Sony-Vaio F Series related\n  problems in Linux are discussed here:\n  http://code.google.com/p/vaio-f11-linux\n\n\nA: Try the latest 256.x nvidia drivers from the Xswat PPA - you don't have to recompile on each update.\nsudo add-apt-repository ppa:ubuntu-x-swat/x-updates\nsudo apt-get update \nsudo apt-get install nvidia-current nvidia-current-modaliases nvidia-settings\n\nYou might also need a sudo apt-get upgrade in there too if you already have old versions of those packages installed.\n\nA: But otherwise, check the supported chipsets in driver releases. Ubuntu doesn't use the very latest nvidia driver because they need to test them. This can mean that if your hardware is very new, the used driver wont work.\nTo find this out, find out what version Ubuntu ships in Synaptic (The nvidia-glx-185 package ships nvidia version 195.36.24) and compare that with the relevant page on nvidia.com. Here is the information on 195.36.24. Look under supported products and you'll see what hardware it supports. If yours is in there, awesome. If it's not then we have a problem.\nIn cases like this you have to go straight to the source and download the latest nvidia driver from nvidia. I personally get mine from the Linux Forum on NvNews (nvidia's forum). They don't package their installers as debs, they're just executables.\nOnce downloaded you need to:\n\n\n*\n\n*Go to a TTY (Control+Alt+F1)\n\n*Log in\n\n*sudo stop gdm to kill X\n\n*sudo sh NVIDIA-Linux-x86_64-256.44.run (but replace this with the actual file)\n\n*Assuming that goes well, it should build, install and load the kernel driver so just sudo start gdm to get back into X\n\n\nNote: Ubuntu's driver will automatically rebuild the nvidia kernel module when it updates its kernel (security updates, etc). Unless you want to get involved in some serious scripting trickery, the manually installed one wont. So after kernel updates you'll likely be dumped at a low-resolution screen with a prompt on what to do next. Click exit to prompt (or the one that sounds like that) and do what you did starting from point 2.\nNote on that Note: I recommend you never use the low graphics mode as it can disturb your desktop settings. Just get out of X, reinstall the driver and get back into X with full hardware capabilities.\n", "Q: How to set up good video support on radeon 3850 So, I've got radeon 3850 agp card. It seems that all videos and graphics are handled by CPU, according to cpu usage. All effects are enabled and working(like compiz), but videos and 3d are extremely slow and low-fps, though I use proprietary ati drivers. What do I need to do to get normal fps? Ready to answer additional questions.\nSo, I think 10.7 finally installed, but nothing new happend. Hi-res video still 0.3 fps.(video is 1280x720, screen is 1920x1080).\nDecided to show my xorg.conf:\nSection \"ServerLayout\"\n    Identifier     \"aticonfig Layout\"\n    Screen      0  \"aticonfig-Screen[0]-0\" 0 0\nEndSection\n\nSection \"Module\"\nEndSection\n\n\nSection \"Monitor\"\n    Identifier   \"aticonfig-Monitor[0]-0\"\n    Option      \"VendorName\" \"ATI Proprietary Driver\"\n    Option      \"ModelName\" \"Generic Autodetecting Monitor\"\n    Option      \"DPMS\" \"true\"\nEndSection\n\nSection \"Device\"\n    Identifier  \"aticonfig-Device[0]-0\"\n    Driver      \"fglrx\"\n    BusID       \"PCI:1:0:0\"\nEndSection\n\nSection \"Screen\"\n    Identifier \"aticonfig-Screen[0]-0\"\n    Device     \"aticonfig-Device[0]-0\"\n    Monitor    \"aticonfig-Monitor[0]-0\"\n    DefaultDepth     24\n    SubSection \"Display\"\n        Viewport   0 0\n        Depth     24\n    EndSubSection\n\n    EndSection\nThanks everyone, I also wanted to ask: everybody tell me, that this parameter:\ncreitve@localhost:~$ glxinfo|grep render\ndirect rendering: No (LIBGL_ALWAYS_INDIRECT set)\nOpenGL renderer string: ATI Radeon HD 3850\n\nmust be \"yes\", but I didn't manage to enable it. What do I need to get it running? Im sure, it's 100% related to my problem, right?\n\nA: 90% of the time this type of problem is resolved by doing a purge and reinstall of the driver stack, because either the mesa GLX driver or the kernel driver is messed up.  https://wiki.ubuntu.com/X/Troubleshooting/FglrxInteferesWithRadeonDriver\nAs far as open source drivers, xserver-xorg-video-ati in Lucid supports 2D but not 3D acceleration for this hardware, so depending on your definition of 'good' it likely isn't going to suffice for you.\n3D support is coming in Maverick, although there's still a lot that's incomplete.  See http://www.x.org/wiki/RadeonFeature for a detailed breakdown of the 3D support with this driver.  (Your card fits under the R600 column.)\nNote that with the open driver and AGP hardware, sometimes you have to tweak AGPMode either in BIOS or (for -ati) in the xorg.conf.  (See 'man xorg.conf' or 'man radeon').\n\nA: Have you tried the open source drivers? I have a slightly newer card (I think) and the proprietary drivers were slow, buggy, and leaked memory. The open drivers work perfectly. Have a look for the xserver-xorg-video-radeonhd packages.\n", "Q: Cannot Connect Modem ( /dev/ttySL0 ) Using gnome-ppp - Dial-Up Connection I'm trying to connect my Toshiba Satellite running Ubuntu 10.04 to my Eris running Android 2.1 through a Bluetooth connection and establish a dial-up connection (DUN) with the modem.  I can connect my phone to my laptop, and I can detect my modem (after installing drivers), which is located at /dev/ttySL0.  But when I launch gnome-ppp and enter my phone number (123 for PDA-Net) I get a dialog that says \"Connecting...  Sending Password\" with Log and Cancel buttons.  The log shows this:\n--> WvDial: Internet dialer version 1.60\n--> Cannot get information for serial port.\n--> Initializing modem.\n--> Sending: ATZ\nATZ\nOK\n--> Sending: ATQ0 V1 E1 S0=0 &C1 &D2 +FCLASS=0\nATQ0 V1 E1 S0=0 &C1 &D2 +FCLASS=0\nOK\n--> Modem initialized.\n--> Please enter password (or empty password to stop):\n--> Configuration does not specify a valid login name.\nThe PDA-Net DUN protocol is running and shows no error.  Any ideas?\nAny help is much appreciated.\n\nA: From the PDA-Net website:\n\nSince this is just a regular Bluetooth\n  DUN connection, you have 3 ways to\n  initiate the dialup: \n  \n  \n*\n  \n*You can use the Bluetooth software to connect if available. For some\n  drivers such as the BlueSoleil one,\n  this is the only way you can initiate\n  the connection. \n  \n*You can open network connections panel and launch the Bluetooth entry.\n  \n  \n  For 1 and 2, enter phone number #777\n  and empty username/password when\n  prompted.\n\n", "Q: Why isn't Gwibber working? (I thought I posted this earlier, but it's not here, so I guess I didn't.)\nSo, Gwibber isn't working. It as kind of almost working when I installed Ubuntu (10.4, 64-bit)--the \"broadcast accounts\" option under my name was doing what it does, but I still haven't seen the program actually function--and now, it's not opening, and \"broadcast accounts\" is not opening, but system->prefrences->broadcast preferences is opening.\nI had a problem at the beginning where my facebook account wouldn't register properly in \"broadcast accounts\". Then, I installed some basic update to gwibber, and then that worked fine. But just a little while later, nothing was working at all.\nIn case this is a clue: the top-right notification boxes seem to show up a whole box-area lower than they should. This is another annoyance, but I feel like it might possibly be solved if I get gwibber working.\n\nA: Filing a bug is your best bet, this isn't affecting all users.  If the software doesn't work as expected, it is a bug and it should be filed.  I can't speak for everyone, but I truely appreciate bug reports.  They are a vital part of development, we can't fix what we don't know is broken.\nPlease help make Ubuntu better by filing a bug and including the gwibber log file which can be found in ~/.cache/gwibber/gwibber.log \n", "Q: What's apt-get's equivalent option of this dpkg command? dpkg -L <package>\n\nThis command gives me a list of all the installed files, what's apt-get's equivalent option for it? I read the man page but couldn't figure out.\n\nA: There is no equivalent. apt-get is a layer on top of dpkg, not a replacement of it.\n\nA: Like Dennis said, apt-get is a layer on top of dpkg (or other local package managers such as rpm). dpkg manages the local packages on the machine, while apt-get provides a way to grab packages from distant repositories and resolve dependencies between packages that will be handed to dpkg.\ndpkg -L <package_file>\n\nlists the files provided by a package already installed on the machine.\nWith apt-get, you might want to list the files that a package provides, even if it is not installed in your system. Fortunately for you, there is a tool for that, called apt-file, which needs to be installed in addition to apt-get. You can use it this way:\n# Install apt-file\n$ sudo apt-get install apt-file\n# update apt-file's cache (different than apt-get's, namely apt-cache)\n$ sudo apt-file update\n# display the contents of a package\n$ sudo apt-file list <package_name>\n\nNote that apt-file uses special files on the package repository called Contents files. While all official repositories have these files, some third-party repositories might not have them, so apt-file won't be able to list the contents of packages on these repositories.\nman apt-file\n\nwill also list other nice things you can do with apt-file, such as apt-file search <keyword> which lets you find which packages provide a given file.\n\nA: apt-cache can be used for some stuff you might want to do:\nActually listing all packages:\nTo actually list all packages that is in apt-get's cache, use apt-cache pkgnames. This is very much the equivalent of dpkg -l for apt-get, except it only shows package names, and not any other information that dpkg might show.\nNOTE: Using apt-cache pkgnames will generate incredibly much output, on my system it is as much as 39553 lines. To see in advance how many lines it would be on your system, try using apt-cache stats (see below).\nSearching:\nUse apt-cache search <regex> [<regex> [...]] where <regex> is one or more regular expressions to search for.\nCounting:\nUse apt-cache stats to show some statistics about that cache since last apt-get update.\nFor instance, an example output might be:\nTotal package names: 39553 (1,582k)\n  Normal packages: 30033\n  Pure virtual packages: 511\n  Single virtual packages: 2762\n  Mixed virtual packages: 305\n  Missing: 5942\nTotal distinct versions: 32378 (1,813k)\nTotal distinct descriptions: 32378 (777k)\nTotal dependencies: 210651 (5,898k)\nTotal ver/file relations: 34931 (559k)\nTotal Desc/File relations: 32378 (518k)\nTotal Provides mappings: 5816 (116k)\nTotal globbed strings: 169 (2,278)\nTotal dependency version space: 1,052k\nTotal slack space: 73.4k\nTotal space accounted for: 10.0M\n\n\nA: It doesn't exist. You can use the GUI synaptic which will show you all the installed packages.\nShown below.\n\n", "Q: How do I set GNOME to \"focus follows mouse\"? I have two monitors that I use for development. I would like to use sloppy focus for switching between windows. sloppy focus -- whatever you mouse is hovering over is in focus.\nI know it's available in ubuntu 10.04. How do you enable it?\n\nA: System -> Preferences -> Windows\nCheck \"Select windows when the mouse moves over them\"\n", "Q: Ubuntu packaging in bzr A while ago there was talk of moving all (or at least some?) of the packaging effort to bzr branches on launchpad. I seem to remember there were a number of benefits mentioned, such as making it easier for new developers/packagers to contribute.\nCan anyone update me on whether this happened and what the benefits would be? (I might have got completely the wrong end of the stick on this, so feel free to correct me...)\n\nA: I don't have a current count, but I think most are imported.  You can try to checkout packages with bzr branch lp:ubuntu/PACKAGENAME or lp:ubuntu/maverick/PACKAGENAME, for a couple examples.  \nOf course, replace PACKAGENAME with the package you are looking for, and you can replace maverick with the release you are looking for, lucid, karmic, etc. You can make changes and push to your own bzr branches for sponsorship.\n\nA: Everything for which imports did not fail is in bzr right now.  KDE branches have tended to fail due to being massive, but I think that's being worked on.\nThe benefits would be that we don't have debdiffs sitting in Launchpad that all have overlapping version numbers and conflict.  Instead everyone can nicely merge into a single branch, reducing \"oops, your patch no longer applies\" round-trips.\n\nA: As others have mentioned, you can checkout packages with bzr branch lp:ubuntu/PACKAGENAME for the current developmental release or lp:ubuntu/lucid/PACKAGENAME, if you are looking for the source from Lucid for instance. Source packages from Debian are also imported. These can be fetched with lp:debian/PACKAGENAME or lp:debian/lenny/PACKAGENAME\nThis also allows us to easily browser the source of any Ubuntu or Debian package on-line via bazzar.launchpad.net. For instance, here is the banshee source package:\nhttp://bazaar.launchpad.net/~ubuntu-branches/ubuntu/maverick/banshee/maverick/files\nThe vast majority of packages in Ubuntu are availiable as bzr branches. As of this writting, only 597 of the thousand in Ubuntu are currently not up-to-date (This can be tracked on http://package-import.ubuntu.com/status/).\nOne of the major bennifits of distributed version control is that it can help with merging. Tasks such as viewing history and annotating to find who made a specific change and why are also made easier.\nA good introduction to the Ubuntu Distributed Development project can be found here:\nhttps://wiki.ubuntu.com/DistributedDevelopment/About\nDocumentation and how-tos can be found here:\nhttps://wiki.ubuntu.com/DistributedDevelopment/Documentation\n\nA: Quite a few people use bzr to manage their source packages. See the wiki for some information on how to do this.\n\nA: I think you're thinking of bzr-builddeb (manual). You can track it's development on bzr-builddeb's Launchpad page.\n", "Q: How to disable GNOME keyring? I want to disable GNOME keyring globally on my machine. So I deleted the lines\nauth    optional        pam_gnome_keyring.so\nsession optional        pam_gnome_keyring.so auto_start\n\nin /etc/pam.d/gdm. It seems to me that this has no effect. When I lock in the syslog writes\nAug 24 18:37:03 foobar gnome-screensaver-dialog: gkr-pam: unlocked login keyring\n\nand another user sees a menu window where he hs to enter his credentials. So what is the correct way to disable keyring for every user on that machine?\n\nA: For Gnome 3 (ubuntu 17.10 and later):\n\n\n*\n\n*ubuntu/windows key → \n\n*Startup Applications → \n\n*uncheck/remove SSH Key Agent/GNOME Keyring: SSH Agent\n\nA: I think you just disabled the auto-unlock.  To disable it completely, I suppose you could uninstall it.  If that makes the package manager unhappy, you could also sudo chmod -x /usr/bin/gnome-keyring\n\nA: Try this: System ⇒ Preferences ⇒ Startup Applications and uncheck gnome-keyring-daemon.\n", "Q: Jack and pulseaudio I want to run pulseaudio from startup to deal with system sounds etc and be able to run jack from qjackctl for use with audio applications (LMMS, ardour, rosegarden etc) I'm having issues when i start up, the sound applet does not allow me to control the volume. When I click sound preferences it says \"waiting for sound system to respond\" yet the sound still plays in rhythmbox etc. \n\nA: This might not be the correct answer, but I'd recommend bringing up JACK only when you need it. Otherwise, things can get crazy with sound.\n\nA: for some reason pavucontrol had been uninstalled. just had to reinstall it.\n", "Q: How can I get a Kernel Core Dump We're trying to debug a kernel panic/oops on Ubuntu 10.04.  The stacktrace isn't quite enough for us.  How can we configure the system to spit out a core dump and where can we find it after the crash?\nThere is a lot of information on how to get a user-mode core dump, but very little (or old) information on getting a kernel core dump.\nLKCD exists, but looks as though it hasn't been updated since 2002.\n\nA: Installing the linux-crashdump package will install the kexec tools and set up grub to pass the needed kernel options to have the crashdump kernel available.\nThis should automatically catch kernel crashes.  For non-crash kernel problems such as an oops you should be able to use the magic sysrq key's c command to kexec the crashdump kernel and get a dump.\nYou may also want to enable apport to have the dump nicely processed into a crash report for submission to Launchpad or for local retracing.  To do that you need to edit /etc/default/apport.\n", "Q: Automatically add new wireless access points I'm running Lucid on a few laptops, with xfce as the desktop environment.\nBefore Lucid, the little NetworkManager tray widget would automatically scan for access points for me. Now, however, I find that I have to go run iwlist myself to look for SSIDs (if I don't know one already) and manually add that to the list. Once I've done that, then it'll automatically connect (if the AP is configured that way).\nPart of what makes this a real pain is that the tray widget (sometimes) seems to not show itself at all when there's no current connection and no known access points. I have to kill NetworkManager (which is a pain, because init really wants to re-launch it), run iwlist to find an SSID, go to the (now showing) tray widget and add the SSID, and then re-start NetworkManager.\nI realize that the widget is just messing with a config file or two, and I'm happy to fool with those manually, but what I'd really like is for it to work the way it used to and just do the scan for me. Note that once I've got a connection up, then it shows me all the APs it can see, as before.\nI acknowledge that it's possible I screwed up some setup file, but I've really tried scrubbing everything back to \"as new\" state and that hasn't helped.  Am I crazy or did that stuff really change?\n\nA: You can ask upstart (the init daemon used on Ubuntu) to stop NetworkManager, that's much \"cleaner\" than killing the process yourself: sudo initctl stop network-manager (replace \"stop\" with \"start\" to start it manually again).\nAbout the issues with NetworkManager: it seems like it logs to /var/log/daemon.log; maybe you can find some useful messages there?\n", "Q: How do I use a second HDMI-connected monitor? I've looked around for answers to this, but nothing I've found has been relevant, which seems a little weird but there you go. All I'd like to do is drive a second monitor via HDMI from a laptop. From Windows 7 on this laptop that works fine, of course; it's actually surprisingly nice. Thus I know the hardware is OK.\nFrom another laptop I've got, one with an NVidia card, the NVidia settings app seems to do the trick (though it's clunky).  However, this laptop I'm using has an Intel GPU, and I can't find any information about how to get it to recognize that a second display is available. Is it even possible to do this dynamically, or do I need to statically alter my \"xorg.conf\" to make the second screen available?\nedit — sorry I should have noted that I run xfce. \n\nA: Open System/Preferences/Monitors and click 'Detect'.  This is the standard way and should \"Just Work\".  I assume you tried this already and it didn't just work.\nNext, I'd try doing it from the command line:  xrandr --auto\nIf that didn't work, time to debug.  Run xrandr by itself and examine the output.  It should show you that there is an HDMI output, and should indicate if you have a monitor connected to it, and should show what resolutions it supports.\nIf it all looks okay, you can force the monitor's setup using the xrandr command line tool.  See man xrandr or the various examples at http://wiki.ubuntu.com/X/Config.\nIf it doesn't look ok, well there's a whole host of different problems that could have resulted in that.  http://wiki.ubuntu.com/X/ collects a lot of wisdom for troubleshooting these sorts of problems.  For example, if your monitor is actually a TV, there's some workarounds for that.\n\nA: I ended up logging a bug, because it seems that the Intel driver simply doesn't detect the HDMI interface at all. Maybe it'll get fixed when they get the dual-chip driver done.\n\nA: For me, I just had to switch on the monitor connected via HDMI render it visible in the settings > monitors section. It'll automagically find the monitor. (ubuntu 15.04) HTH\n\nA: I'm running Xubuntu 16.04 (with xfce) on my laptop and ran into the same problem.\nHere's how I got it to work:\n\n\n*\n\n*Turn on your external monitor and connect it via HDMI cable to your laptop/desktop.\n\n*Go to Settings>Settings Manager>Display.\n\n*You should see a list of two displays in the left pane: your current display and another one for the external display. You current display should be highlighted in the list you should see a tick mark next to \"Use this output\".\n\n*Select the external display. Tick the \"Use this output\"\n\n*When done using the external display, select your original display \nand tick \"Use this display\"\n\n\nNote: If you plan on using the external display then you should tick \nthe \"Configure new displays when connected\".\n", "Q: Ubuntu Linux UFW Firewall, Local Intranet Access At home, I have Ubuntu server with the UFW firewall. What command do I type to turn on local intranet access to my web server, but keep the outside world out from my DSL modem?\n\nA: sudo ufw default deny\nsudo ufw allow from 192.168.1.0/24 to any port 80\n\nAssuming the web server is on port 80 and 192.168.1.x is your home subnet. If you explicitly want exclude your router, then assuming it's 192.168.1.1, it would be:\nsudo ufw deny from 192.168.1.1 to any port 80\n\n", "Q: Share Wireless connection with Wired Ethernet Port That's pretty much it. If I connect to the Internet on wlan0, how can I share this connection with a device plugged into my wired Ethernet port eth0?\n\nA: I had a MacMini running Ubuntu 9.10 using the Wireless connection for internet.  Then I connected my Xbox360 into the MacMini's ethernet port in order to use Xbox Live.\nIt's ridiculously easy.  Simply right click on your network manager and choose \"Edit Connections\".  Then in the \"Wired\" tab, you can either use your existing wired connection, (or create a new one by hitting the \"Add\" button, name your new connection \"Shared Network Port\" or something similar), pop into its IPv4 tab and in \"Method\", choose \"Shared to other computers\".  Apply everything and close the network manager windows.\nNow when you need to plug something into that ethernet port, you can share your WIFI internet conenction simply by clicking on network manager and choosing the \"Shared Network Port\" entry there.\nIf you want this to be a constantly used ethernet connection used for sharing and nothing else, feel free to edit \"Auto Eth0\" instead of creating a new entry like I describe above.  Creating a new entry gives you some flexibility to choose however.\nNote that this uses a bit of NAT (network address translation) magic to work properly, so the Xbox360 (or whatever you plug into your wired port) will get a funky IP address.\nFrom memory, it will only be able to see the internet too - I don't think you can see the host computer, the one with the internet connection.  You can set that up, but it requires a bit of messing about with DHCP servers, I believe.  I didn't need it, so I didn't go down that road.\n\nA: That is easy. Right click the network manager and click edit connections. \nThe under Wired tab, Add a new connection. Under the IPV4 Setting tab,  select \"Shared to others\" for Method. \nNow other machines should connect to LAN and get Internet access automatically.\n\n\nA: There is a simple guide at https://oracle-base.com/articles/linux/use-iptables-to-implement-packet-filtering-and-configure-nat. But I found out, that in Windows, the DNS address that the Linux PC is using, must also be given in Windows.\nI have a 3G USB modem connected to my Linux PC, and from that I have two Windows PC's that get internet. It's called (kernel) packet forwarding, and it's quite simple and quick to do - when you understand it finally.\nYou will need to find out your network interfaces names by running the command \"ifconfig\" on Linux (in the terminal), and \"ipconfig\" on Windows (in the command prompt). The interface names, on Linux, are at the leftmost side, like: enp2s0, enp3s0, enp0s18f2u6, lo. Now you set up packed forwarding:\n\n*\n\n*First you need to enable packet forwarding on your Linux PC (see that guide I linked from oracle-base.com).\n\n\n*Next, you can run these commands, as that oracle-base.com guide says (but wait, and read on):\nsudo iptables -I FORWARD -i my_lan_interface -o my_modem_interface -j ACCEPT\nsudo iptables -I FORWARD -i my_modem_interface -o my_lan_interface -j ACCEPT\nsudo iptables -t nat -I POSTROUTING -o my_modem_interface -j MASQUERADE\nBut there is a more robust way, that I found on the net:\nsudo iptables -t nat -A POSTROUTING -o my_modem_interface -j MASQUERADE --random\nsudo iptables -A FORWARD -i my_lan_interface -o my_modem_interface -j ACCEPT\nsudo iptables -A FORWARD -i my_modem_interface -o my_lan_interface -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\nsudo iptables -A FORWARD -j DROP\nHere's an explanation for the commands just above (the \"more robust\" example), in the same order:\n\n*\n\n*First command: enable masquerading on my_modem_interface so the source address is rewritten on outgoing packets. The --random flag is to have symmetric NAT.\n\nNow we are going to configure forwarding rules. iptables, by default, will unconditionally forward all traffic. Here we prefer to restrict inbound traffic from the internet and allow all outgoing:\n\n*\n\n*Second command: Allow traffic from my_lan_interface to my_modem_interface.\n\n*Third command: Allow returning traffic from my_modem_interface to my_lan_interface.\n\n*Fourth command: Drop all other traffic that shouldn't be forwarded.\n\nWhen you reboot your Linux PC, you will have to reenter these commands - I have a script that runs them at each boot. You can make these changes permanent with the appropriate \"service\" call (again, see the oracle-base.com guide given above), but I recommend running them at each boot (in a script), as you might want to experiment and change things, and undoing what you saved is another challenge. If something goes wrong, or you want to change things, or you just don't want this feature for your current session (or at all), then just reboot your PC and they're gone - but you must disable packet forwarding yourself (before rebooting write \"net.ipv4.ip_forward = 0\" in /etc/sysctl.conf) to fully disable this technology.\n\n\n*Now you have to create a network connection (Ethernet connection) between your Linux PC and your other computers. For example:\n\n*\n\n*A) On the Linux PC connected to the internet (I use Fedora), with the network connections manager, I create an Ethernet connection, select the appropriate interface (network card name, enp3s0 in my case) that will connect this Linux PC to my LAN. Be sure to select the right firewall zone or your LAN will not get internet. So since this is your internal LAN interface, set the firewall zone to \"trusted\", but the modem connection interface should be set to \"public\". Next, in the IPv4 settings tab, set that IPv4 must be used for the connection (IPv6 can be ignored), and select manual address setup. Now add the address 192.168.2.100 - this will be the address of this Linux PC on your LAN. The net mask will be set automatically (255.255.255.0, because this is a \"C class\" (private) address). Apply your settings and connect.\n\n\n*B) On the second PC (with Linux or Windows, connected by Ethernet cable to the first one above), also create a network connection (if it's Windows, look below for better details), select the appropriate network interface (the device/card which is connecting to the first PC), use manual IPv4 setup as above for the first PC, but here set the address 192.168.2.101 - this will be the address of this second PC on your LAN (these are \"private\" addresses, meaning that they will not be visible outside your LAN).\n\n\n*B1) If you want to connect Windows (operating system), go to \"Network and Sharing Center\"->\"change adapter settings\", and look for your network interface that corresponds to your LAN network card on this Windows PC, which is also connected by Ethernet cable to the first PC. Now, select that interface, right click for Properties. You will see a list. Here unselect \"Internet Protocol Version 6\" and double click on \"Internet Protocol Version 4\". Now you enter the address 192.168.2.101 - this will be the address of this Windows PC on that interface (on that [LAN/Ethernet] connection)). Tab down so netmask is filled out automatically (255.255.255.0). (The \"Network Profile\" can be set to \"public\".)\n\n\n*B2) It might be necessary to set the gateway address to the first Linux PC, so you would need to enter as gateway address 192.168.2.100.\n\n\n*C) Now, you must enter the DNS address that your first Linux PC is using. For example, my modem uses DNS address 192.168.1.1 (which I can find with the command \"nmcli device show  | grep IP4.DNS\", where interfacename is the name of your Linux interface connected to the internet). (If you connect to the internet with Windows, run \"ipconfig\" in the terminal/command prompt, look for a DNS address). And that's it. The DNS information is critical to getting an internet connection.\nSo putting it short:\nMy modem address: 192.168.1.100, DNS 192.168.1.1.\nLinux PC address on LAN: 192.168.2.100, packet forwarding enabled with iptables redirecting traffic, as explained above, firewall zone set to \"trusted\".\nWindows PC 1 address: 192.168.2.101 with DNS set to 192.168.1.1, network profile set to public. (Default gateway set to Linux PC: 192.168.2.100).\nWindows PC 2 address: 192.168.2.102 with DNS set to 192.168.1.1, network profile set to public. (Default gateway set to Linux PC: 192.168.2.100).\n(All computers connected together by a simple Ethernet switch with plain Ethernet cables (also called \"patch cables\" or \"patch cords\"), not crossed, because \"modern\" network cards do the crossing by themselves, so you can use crossed cables or not crossed cables, even mix them together in a connection.)\nThere is also a guide at: https://medium.com/@TarunChinmai/sharing-internet-connection-from-a-linux-machine-over-ethernet-a5cbbd775a4f, which uses Google's DNS addresses instead. Check it out.\n", "Q: How do I configure touchscreen on my HP tx1000 laptop running xubuntu? I tried looking online for all possible solutions and even installing evtouch package, but nothing seems to work. I know that the tx1000 series laptops are notoriously linux unfriendly. Does anyone have any ideas on how to get the touchscreen to work on them?\n\nA: It uses a proprietary driver called eGalax.  It's not available or supported in Ubuntu but here's a link to the driver download:\nhttp://home.eeti.com.tw/web20/eGalaxTouchDriver/linuxDriver.htm\nIdeally, the Linux kernel's general purpose evdev input driver should make the touchscreen \"just work\", however its support for touchscreen models is far, far from complete.  If you're really interested in getting it working and don't mind getting your hands dirty into some source code, you might be able to lend a hand to the evdev kernel developers to make it work for this hardware (or they might have some configurable settings you could try.)\nI wouldn't bother with evtouch for this hardware; it's not at all maintained and is being deprecated in favor of evdev.\n", "Q: Swiftfox without the file, view toolbar Is there a way to remove the File, Edit, View... toolbar from Firefox (so that I will have only the address toolbar visible)?\nI think in Windows from version 3.5 you can just right click on the toolbar and you can just  unselect it...\nI don't have Firefox installed, i use Swiftfox...\n\nA: I use the tiny menu extension to reduce the menu bar to an icon next to my address bar.\n\nOtherwise, you should be able to create a new toolbar and drag the menu bar onto it, then hide that toolbar.\n\nA: Try the Hide Menubar addon. The menubar is hidden by default but you can toggle it with the Alt key.\n\nA: I have used Tiny Menu extension in the past, but now I use Compact Menu 2. It works like a charm and you can put the menu anywhere.\nhttps://addons.mozilla.org/en-US/firefox/addon/4550/\n", "Q: System slows down until I move the mouse i installed a bunch of time many linux distro and never got this \"bug\".\nIt's kind of weird, the system run really fine , but when there is operation like update manager or download via any browser , etc. It goes well until a moment (never the same delay) and radically slow down or even stop , the pc doesn't freeze but the operation is paused , and when i touch the touchpad it continue .\ni suspected hard drive issue , so i changed it , a bios issue , except AHCI i can't modify anything..., also suspected that ACPI stop the drive so i unchecked the box but still the same bug.\nif anyone has already got this... it's not a deadly bug but a big annoyance.\n\nA: This sounds like a bug with something related to timer interrupts.  Basically, the kernel is waiting for an interrupt to give the next process a short slice of time to run, but the timer interrupt signal never fires.  And moving the mouse happens to fire an interrupt too, so that's why the kernel starts scheduling time for all applications again then.\nI suggest you file a bug report against the kernel on Launchpad.  The best way to do that on Ubuntu is by running the following command:\nubuntu-bug linux\n\nThat will collect info about your system (things like kernel version & hardware info), send it to Launchpad, and then open a browser to file a bug report.  If you don't have a Launchpad account yet, you'll be asked to create one.  Make sure to explain well what your problem is, and answer if more info is asked.\n", "Q: How do I get a 3G USB modem to work? Since at least Jaunty, I've tried to get my wife's 3G USB modem to work on Ubuntu, always with the same result - instant, complete system freeze.\nI've tried installing`wvdial and usb-modeswitch, I've read tons of documentation but it gets quite disjointed from one release to the next, nothing works. I can't run lsusb because the system hangs immediately.\nI'm using Lucid and it's a Rogers \"Rocket Stick\" (in Canada)\n\nA: Try this “automagic” script: sakis3g. No need to install anything, just run the script; it will guide you through menus.\nAfter you make it work, you can create a small script calling the sakis3g-script having set up some environment variables for your convenience. Here follows mine:\nexport BAUD=MAX MODEM=1bbb:0000 APN=3g-internet SIM_PIN=1234\n(sakis3g-script helper&)&\n\nThe $MODEM is the vendor-id:product-id code so I don't have to select it everytime I start the sakis3g-script; $APN is your provider's suggested login name; the SIM_PIN is rather obvious.\nSee also that question in SuperUser.\n\nA: The real answer is to start with a supported device. See http://en.wikipedia.org/wiki/NetworkManager for a list of working devices.\n", "Q: Belkin wireless 802.11g USB network adapter  not working Hello everyone I really am new to this Ubuntu thing. I am now running the latest Ubuntu and windows on the same PC. Wireless connections work fine on windows but connects and disconnects on Ubuntu.\nI am on ADSL with wireless router (Belkin and Belkin wireless network adaptor).\nrussell@ubuntu:~$ dmesg | grep rt \n[ 0.000000] KERNEL supported cpus: \n[ 0.000000] Movable zone start PFN for each node \n[ 0.000000] ACPI: PM-Timer IO Port: 0x408 \n[ 0.000000] Allocating PCI resources starting at 80000000 (gap: 80000000:50000000) \n[ 0.000000] Booting paravirtualized kernel on bare hardware \n[ 0.000000] Enabling unmasked SIMD FPU exception support... done. \n[ 0.000000] virtual kernel memory layout: \n[ 0.004287] mce: CPU supports 4 MCE banks \n[ 0.035629] ftrace: converting mcount calls to 0f 1f 44 00 00 \n[ 0.185268] ACPI: (supports S0 S1 S4 S5)\n[ 0.193969] pci 0000:00:1c.0: PME# supported from D0 D3hot D3cold \n[ 0.194048] pci 0000:00:1d.0: reg 20 io port: [0xbc00-0xbc1f] \n[ 0.194117] pci 0000:00:1d.1: reg 20 io port: [0xb000-0xb01f] \n[ 0.194189] pci 0000:00:1d.2: reg 20 io port: [0xb400-0xb41f] \n[ 0.194257] pci 0000:00:1d.3: reg 20 io port: [0xb800-0xb81f] \n[ 0.194485] pci 0000:00:1e.2: reg 10 io port: [0xc000-0xc0ff] \n[ 0.194495] pci 0000:00:1e.2: reg 14 io port: [0xc400-0xc43f] \n[ 0.194554] pci 0000:00:1e.2: PME# supported from D0 D3hot D3cold\n[ 0.193969] pci 0000:00:1c.0: PME# supported from D0 D3hot D3cold \n[ 0.194048] pci 0000:00:1d.0: reg 20 io port: [0xbc00-0xbc1f] \n[ 0.194117] pci 0000:00:1d.1: reg 20 io port: [0xb000-0xb01f] \n[ 0.194189] pci 0000:00:1d.2: reg 20 io port: [0xb400-0xb41f] \n[ 0.194257] pci 0000:00:1d.3: reg 20 io port: [0xb800-0xb81f] \n[ 0.194485] pci 0000:00:1e.2: reg 10 io port: [0xc000-0xc0ff] \n[ 0.194495] pci 0000:00:1e.2: reg 14 io port: [0xc400-0xc43f] \n[ 0.194554] pci 0000:00:1e.2: PME# supported from D0 D3hot D3cold\n[ 0.194714] pci 0000:00:1f.1: reg 10 io port: [0x00-0x07] \n[ 0.194724] pci 0000:00:1f.1: reg 14 io port: [0x00-0x03] \n[ 0.194735] pci 0000:00:1f.1: reg 18 io port: [0x00-0x07] \n[ 0.194746] pci 0000:00:1f.1: reg 1c io port: [0x00-0x03] \n[ 0.194759] pci 0000:00:1f.1: reg 20 io port: [0xf000-0xf00f] \n[ 0.194819] pci 0000:00:1f.2: reg 10 io port: [0xd000-0xd007] \n[ 0.194829] pci 0000:00:1f.2: reg 14 io port: [0xd400-0xd403]\n[ 0.194714] pci 0000:00:1f.1: reg 10 io port: [0x00-0x07] \n[ 0.194724] pci 0000:00:1f.1: reg 14 io port: [0x00-0x03] \n[ 0.194735] pci 0000:00:1f.1: reg 18 io port: [0x00-0x07] \n[ 0.194746] pci 0000:00:1f.1: reg 1c io port: [0x00-0x03] \n[ 0.194759] pci 0000:00:1f.1: reg 20 io port: [0xf000-0xf00f] \n[ 0.194819] pci 0000:00:1f.2: reg 10 io port: [0xd000-0xd007] \n[ 0.194829] pci 0000:00:1f.2: reg 14 io port: [0xd400-0xd403]\n[ 0.194839] pci 0000:00:1f.2: reg 18 io port: [0xd800-0xd807] \n[ 0.194848] pci 0000:00:1f.2: reg 1c io port: [0xdc00-0xdc03] \n[ 0.194858] pci 0000:00:1f.2: reg 20 io port: [0xe000-0xe00f] \n[ 0.194892] pci 0000:00:1f.2: PME# supported from D3hot \n[ 0.194957] pci 0000:00:1f.3: reg 20 io port: [0x500-0x51f] \n[ 0.195097] pci 0000:01:00.0: reg 24 io port: [0x9000-0x907f] \n[ 0.195212] pci 0000:00:1c.0: bridge io port: [0x9000-0x9fff] \n[ 0.195287] pci 0000:02:05.0: reg 10 io port: [0xa000-0xa0ff] \n[ 0.195360] pci 0000:02:05.0: supports D1 D2\n[ 0.194839] pci 0000:00:1f.2: reg 18 io port: [0xd800-0xd807] \n[ 0.194848] pci 0000:00:1f.2: reg 1c io port: [0xdc00-0xdc03] \n[ 0.194858] pci 0000:00:1f.2: reg 20 io port: [0xe000-0xe00f] \n[ 0.194892] pci 0000:00:1f.2: PME# supported from D3hot \n[ 0.194957] pci 0000:00:1f.3: reg 20 io port: [0x500-0x51f] \n[ 0.195097] pci 0000:01:00.0: reg 24 io port: [0x9000-0x907f] \n[ 0.195212] pci 0000:00:1c.0: bridge io port: [0x9000-0x9fff] \n[ 0.195287] pci 0000:02:05.0: reg 10 io port: [0xa000-0xa0ff] \n[ 0.195360] pci 0000:02:05.0: supports D1 D2\n[ 0.195367] pci 0000:02:05.0: PME# supported from D1 D2 D3hot D3cold \n[ 0.195437] pci 0000:00:1e.0: bridge io port: [0xa000-0xafff] \n[ 0.224801] system 00:01: ioport range 0x4d0-0x4d1 has been reserved \n[ 0.224807] system 00:01: ioport range 0x290-0x29f has been reserved \n[ 0.224813] system 00:01: ioport range 0x800-0x87f has been reserved \n[ 0.224819] system 00:01: ioport range 0x880-0x88f has been reserved \n[ 0.224836] system 00:0b: ioport range 0x400-0x4bf could not be reserved \n[ 0.279897] pcieport 0000:00:1c.0: irq 24 for MSI/MSI-X – Raven Aug 27 at 0:42 edit \n[ 0.195367] pci 0000:02:05.0: PME# supported from D1 D2 D3hot D3cold \n[ 0.195437] pci 0000:00:1e.0: bridge io port: [0xa000-0xafff] \n[ 0.224801] system 00:01: ioport range 0x4d0-0x4d1 has been reserved \n[ 0.224807] system 00:01: ioport range 0x290-0x29f has been reserved \n[ 0.224813] system 00:01: ioport range 0x800-0x87f has been reserved \n[ 0.224819] system 00:01: ioport range 0x880-0x88f has been reserved \n[ 0.224836] system 00:0b: ioport range 0x400-0x4bf could not be reserved \n[ 0.279897] pcieport 0000:00:1c.0: irq 24 for MSI/MSI-X\n[ 0.279910] pcieport 0000:00:1c.0: setting latency timer to 64 \n[ 0.287215] Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled \n[ 0.291459] input: Macintosh mouse button emulation as /devices/virtual/input/input2 \n[ 0.299338] ehci_hcd 0000:00:1d.7: cache line size of 128 is not supported \n[ 0.346769] ehci_hcd 0000:00:1d.7: USB 2.0 started, EHCI 1.00 \n[ 0.347042] hub 1-0:1.0: 8 ports detected [ 0.347617] hub 2-0:1.0: 2 ports detected \n[ 0.348036] hub 3-0:1.0: 2 ports detected [ 0.348459] hub 4-0:1.0: 2 ports detected \n[ 0.348891] hub 5-0:1.0: 2 ports detecte – Raven Aug 27 at 0:43 edit \n[ 0.279910] pcieport 0000:00:1c.0: setting latency timer to 64 \n[ 0.287215] Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled \n[ 0.291459] input: Macintosh mouse button emulation as /devices/virtual/input/input2 \n[ 0.299338] ehci_hcd 0000:00:1d.7: cache line size of 128 is not supported \n[ 0.346769] ehci_hcd 0000:00:1d.7: USB 2.0 started, EHCI 1.00 \n[ 0.347042] hub 1-0:1.0: 8 ports detected \n[ 0.347617] hub 2-0:1.0: 2 ports detected \n[ 0.348036] hub 3-0:1.0: 2 ports detected \n[ 0.348459] hub 4-0:1.0: 2 ports detected \n[ 0.348891] hub 5-0:1.0: 2 ports detected   \n[ 0.349073] PNP: PS/2 appears to have AUX port disabled, if this is incorrect please boot with i8042.nopnp \n[ 0.349998] serio: i8042 KBD port at 0x60,0x64 irq 1 \n[ 0.350404] rtc_cmos 00:03: RTC can wake from S4 [ 0.350475] rtc_cmos 00:03: rtc core: registered rtc_cmos as rtc0 \n[ 0.350506] rtc0: alarms up to one month, 242 bytes nvram, hpet irqs – Raven Aug 27 at 0:43 edit \n[ 0.349073] PNP: PS/2 appears to have AUX port disabled, if this is incorrect please boot with i8042.nopnp \n[ 0.349998] serio: i8042 KBD port at 0x60,0x64 irq 1 [ 0.350404] rtc_cmos 00:03: RTC can wake from S4 \n[ 0.350475] rtc_cmos 00:03: rtc core: registered rtc_cmos as rtc0 \n[ 0.350506] rtc0: alarms up to one month, 242 bytes nvram, hpet irqs\n[ 0.355364] Using IPI No-Shortcut mode \n[ 0.356078] rtc_cmos 00:03: setting system clock to 2010-08-27 10:13:42 UTC (1282904022) [ 0.763804] sd 3:0:0:0: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA \n[ 0.763811] sd 2:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA \n[ 0.826587] udev: starting version 151 \n[ 0.860561] hub 1-1:1.0: 4 ports detected \n[ 1.116873] USB Mass Storage support registered. \n[ 2.734937] hub 3-2:1.0: 4 ports detected \n[ 13.477205] udev: starting version 151 – Raven Aug 27 at 0:43 edit \n[ 0.355364] Using IPI No-Shortcut mode\n[ 0.356078] rtc_cmos 00:03: setting system clock to 2010-08-27 10:13:42 UTC (1282904022)\n[ 0.763804] sd 3:0:0:0: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n[ 0.763811] sd 2:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n[ 0.826587] udev: starting version 151\n[ 0.860561] hub 1-1:1.0: 4 ports detected\n[ 1.116873] USB Mass Storage support registered.\n[ 2.734937] hub 3-2:1.0: 4 ports detected\n[ 13.477205] udev: starting version 151\n[ 13.686799] Linux agpgart interface v0.103\n[ 13.953260] USB Serial support registered for generic\n[ 13.958045] USB Serial support registered for GSM modem (1-port)\n[ 13.973144] option 3-2.4:1.0: GSM modem (1-port) converter detected\n[ 13.973594] usb 3-2.4: GSM modem (1-port) converter now attached to ttyUSB0\n[ 13.973643] option 3-2.4:1.1: GSM modem (1-port) converter detected\n[ 13.973747] usb 3-2.4: GSM modem (1-port) converter now attached to ttyUSB1\n[ 13.686799] Linux agpgart interface v0.103\n[ 13.953260] USB Serial support registered for generic\n[ 13.958045] USB Serial support registered for GSM modem (1-port)\n[ 13.973144] option 3-2.4:1.0: GSM modem (1-port) converter detected\n[ 13.973594] usb 3-2.4: GSM modem (1-port) converter now attached to ttyUSB0\n[ 13.973643] option 3-2.4:1.1: GSM modem (1-port) converter detected\n[ 13.973747] usb 3-2.4: GSM modem (1-port) converter now attached to ttyUSB1\n[ 13.973783] option 3-2.4:1.2: GSM modem (1-port) converter detected\n[ 13.973908] usb 3-2.4: GSM modem (1-port) converter now attached to ttyUSB2\n[ 14.068472] parport_pc 00:09: reported by Plug and Play ACPI\n[ 14.068526] parport0: PC-style at 0x378, irq 7 [PCSPP,TRISTATE]\n[ 14.172348] lp0: using parport0 (interrupt-driven).\n[ 16.456225] ppdev: user-space parallel port driver\nrussell@ubuntu:~$\n\n\nA: We are going to need more info to be able to help you. Like what type of wireless adapter are you using and what Ubuntu version are you using.\n------ TRY 1: Failed\nOne generic tip is to System->Administration->Hardware Drivers. Maybe you need to download some driver. If your wireless card is listed in the window that opens, please click the button to install it's drivers.\nBut with so little info this is just a blind shot.\n------ TRY 2: Failed\nThank you for all the info. Belkin is famous for using different chipsets in the same product, F5D7050 uses at least 3 different chipsets. Anyway, the window's driver filenames are gold. Your card is likely a rt2500.\nThe most common problem with this card is that multiples modules (kinda of windows drivers) try to use it, conflicting. You will need to do some file-editing-foo to solve it.\nPress ALT+F2 or open a console. Type or copy/paste:\ngksudo gedit /etc/modprobe.d/blacklist.conf \n\nNow at the end of the file append this two lines:\nblacklist rt2500usb\nblacklist rt2800usb\n\nAnd reboot, if you are lucky it should be working after the reboot. If not, there are probably other kind of conflict, edit the file again, remove the lines, reboot, open a console and type:\ndmesg | grep rt\n\nSeems like no rt* modules is beign loaded. So it's my mistake. But if the wifi works (at times) it must be loading some drivers and windows drivers make it look like a rt2500... \n----------- TRY 3: Never Tested\nAnother shot. There are some reports of disconnections with people using rt* chipsets with the current kernel. You can try to update your kernel.\nYou need to add this PPA to your software sources. In the PPA page you can found detailed instructions about how to add them, but in short, you must open System->Administration->Sotware Sources, click on the \"Other Software\" tab, click add and write there ppa:kernel-ppa/ppa.\nAfterwards you need to install the updated kernel. The easiest way is to open the Ubuntu Software Center, under get software select the new PPA and in the right panel choose to install the Complete Generic Linux Kernel, if you see two choose the one without pae in its name.\nReboot and let's hope that the linux gods will smile on us this time.\nIf you have any problem with the new kernel, you press ESC while booting for a menu that will let you boot from the old one.\n----------- RESOLUTION: OP just build another adapter\nUsually the easiest solution.\n", "Q: What can we do to increase participation in Global Jams? Our global jam is coming up this weekend, and I wonder what we can do to increase participation and also collaboration between the different events. Maybe we still have time to implement some of the suggestions.\n\nA: Starting a twitter account. Posting updates and relevant news. Reaching out to prominent bloggers in the Ubuntu and Linux world. Posting on forums, just getting the word out. I see on your website you have badges. Get as many people as possible to post the badge maybe some sort of contest. But then again people only do what they want to.\nAlso directing people with a very specific goal, much like a video game. Help them feel that they are actually contributing in a measurable way. reputation or goal bars for example.\nEither way goodluck! :)\n\nA: I think a big thing is that concrete > vague. Tools like harvest and such that help users find specific items to work on will help increase participation and work. I'd love to see each area (packaging, bugs, docs) have someone up the team work on a \"todo\" list of things they'd like to see get done for the Jam. This way the participants and would-be participants can go through the list and hopefully get more useful concrete accomplishments done. I know our Jam is very vague. \"Let's all get together, have some pizza, and find something to do\". I'm sure a lot of time won't be very Jam productive while it will be fun for us :)\n\nA: what I've found works well is to have a bit of structure to it.  Have a rough timetable of what you and your team want to do. Keep it basic, cover the small things like logging into launchpad creating an account, there will be people who've not done it before, lets encourage all levels to take part. \nNext talk about bug and how the role of logging one has an effect, now talk about triaging them. \nThere are different levels of a global jam, so why not get people working in groups of 2-3 people who work on different areas, like wiki clean up, bugs, documentation, plans for the team for the future.\nTake a break and chat about the work you've done, don't forget about the online community, join in #ubuntu-locoteams and let others know how you are getting on,  if you've reported a bug poke someone to verify it. \n", "Q: Overriding a executable to add a default flag Here's my boggle. I use gmplayer to play all my videos. 99.9% of the time everything works fine but in that 1-in-1000 case, a video might be corrupted. gmplayer plays the video but it cries like an angry, hungry baby, popping up windows left, right and centre. In really bad videos this actually slows down the whole system as it spawns hundreds of error windows (compiz applies effects, etc). It also steals focus and occasionally cancels Christmas.\nIn the command-line mplayer these messages are just throw out to the command line. Using mplayer-proper might be an option if I can't use gmplayer but it's not quite as good for my needs.\nI have found a workaround. If you add -msglevel all=0 to the gmplayer call, errors are suppressed. Useless from a debug perspective but I'm not attempting to debug videos here, just watch them.\nWhat I want to do is \"alias\" or \"proxy\" the gmplayer command so when you run gmplayer from the command line or by association, it actually runs gmplayer -msglevel all=0. I gather that just adding a bash alias won't work for associated (as in double clicking on a video in gnome) plays.\nWhat are my options for hard-proxying the command. This only needs to work for one user but I'm open to system-wide changes too.\n\nA: You can set this option in one f the mplayer option files, this will then be the default behaviour. For system wide change /etc/mplayer/mpplayer.conf of just for that user create ~/.mplayer/mplayer.conf and put it in there.\nAdding this to ~/.mplayer/mplayer.conf works:\nmsglevel=all=0\n\n\nA: You could edit the /usr/share/applications/mplayer.desktop file to adujst the way the gmplayer command is called from the menu. Be sure to use dpkg-divert to make this change consistent locally:\n$ sudo dpkg-divert /usr/share/applications/mplayer.desktop\n\nThis will tell dpkg to keep your modified version of the file in future package upgrades.\n\nA: I am not totally sure how to complish this. other than writing a script that calls your executable with flags. But I know that in Eclipse that there is a eclipse.ini file in the same directory as the excutable that allows you to pass flags. Maybe looking into that you can write a similar file for gmplayer\nI hope this helps. :)\n\nA: The easiest way to do this, is probably the following:\n\n\n*\n\n*rename the executable in /usr/bin\n\n*put in its place a script that will call the executable under the new name, that adds your argument.\n#!/bin/bash\noriginal-gmplayer -msglevel all=0 $@\n\nAlternatively, you could put this script in the bin directory in your home, and make sure this bin directory is in your path (needs to be set system wide in order to work for applications that are not called from terminal)\n\nA: As a different solution, use smplayer instead, which has the distinction of being actually maintained, and works great (which you cannot say of gmplayer).\n\nA: You can create a symlink to your command. Create a command named mygmplayer, then verify where is your actual gmplayer command with whereis or which, then create a symlink to you command.\nHere an example\n $ echo '#!/bin/bash' > /home/user/mygmplayer\n $ echo \"gmplayer -msglevel all=0\" >> /home/user/mygmplayer\n $ chmod a+x mygmplayer\n $ which gmplayer\n /usr/bin/gmplayer\n $ sudo mv /usr/bin/gmplayer /usr/bin/gmplayer.old\n $ sudo ln -s /home/user/mygmplayer /usr/bin/gmplayer\n\nBye.\n", "Q: How can I read Skype's menus on a dark theme? If you use skype with the default 10.04 theme you can't read any menu because the font and background colours are too similar.\n\nA: Click on the skype symbol on the bottom left. Click on Options, six entry if you are not able to see it at all.\nIt will open a new window, on the right there is a combo box labeled \"Choose Style\", click on it and choose Desktop Setting. Restart Skype.\n", "Q: Monochrome Pidgin tray icons Can anyone point me towards monochrome Pidgin tray icons, and tell me how to install them?\n(I know I should be using the Messaging Menu indicator applet or whatever it's called, but at the moment I prefer not to, and use the standard Pidgin tray applet)\n\nA: I think this post at \"OMG! Ubuntu\" would help you get what you are looking for. If not, I'd recommend you search the site as I have run into numerous posts there about monochrome app icons both for the desktop as well as for the indicator applet (a.k.a \"tray\")\n", "Q: Network Manager or WICD? A couple of years ago when I first began using Ubuntu I had issues with Network Manager and so I switched to wicd which works perfectly. (I forget the exact issues, but wicd solved the problems)\nI am about to do a fresh install and curious as to whether I should continue with wicd? Or is Network Manager up to the job now?\nThanks.\nAddendum I ask because a friend recently switched his laptop over to Ubuntu and had wireless troubles until switching over to wicd. My situation is with a desktop using wireless.\n\nA: NetworkManager and WICD don't exactly have the same feature set yet. WICD tends to deal well with wireless and basic ethernet connectivity, but doesn't yet support VPNs, DSL, 3G/CDMA and many other features which are becoming more and more popular. That's without counting \nAs far as wireless support is concerned, WICD sometimes gives the user a chance to use their device because it deals with wireless differently than NetworkManager (although both use wpasupplicant). That said, wireless support in NetworkManager keeps getting better, is receiving a lot of attention from the upstream developers and kernel folks to fix driver issues.\nBottom line is, you can choose whichever application you happen to prefer, but if NetworkManager works for you, sticking to the default is probably what will get you the best results in the long run, since you will be able to benefit from the other features if you end up needing them. If not, at least try it and file bugs so that it ends up working for you and others with similar issues.\n\nA: Now, NetworkManager works well. I suggest it. nm-applet works fine also whith VPN and wi-fi networks. And it is supported by Canonical.\n\nA: If you're having a problem with Network Manager it's likely a problem with the driver. Since it's been a few years then you're probably better off with sticking with the default unless you have a problem.\nThere are two ways to fix wireless problems in Linux. Fixing the driver or working around it. \nAs Dan Williams (who is one of the main developer's for network-manager) has chronicled in his blog, sometimes it takes a long time; there are many moving parts, the kernel, the applet, and talking to the manufacturer of the hardware (if they even care) and then getting all that shipped to users. This takes longer than working around the issue, but in the end is a more sustainable model and gets everyone better drivers in the end. Network Manager and WICD don't exactly have the same feature set yet. WICD tends to deal well with wireless and basic ethernet connectivity, but doesn't yet support VPNs, DSL, 3G/CDMA and many other features which are becoming more and more popular. \nThis isn't meant as a slight towards the WICD folks, it does help people get online and that's great, but fixing it all the way down the stack is a better overall for Linux. Bottom line is, you can choose whichever application you happen to prefer, but if NetworkManager works for you, sticking to the default is probably what will get you the best results in the long run, since you will be able to benefit from the other features if you end up needing them. Network Manager, as the default network tool in Ubuntu is also supported by the Ubuntu team.\nThe linux wireless project maintains a page of wireless cards and chipsets and what features they support, and is a good guide to supporting manufacturers that maintain good drivers.\n\nA: I had to move away from network-manager to wicd a year ago. I decided to give network-manager another try on upgrade to 11.04, and so far so good. The specific issue I had that forced me to move has been resolved. But it all depends on your specific configuration.\nThe details into why I moved to wicd a year ago, for what it's worth:\nWhy I moved to WICD\n", "Q: MediaWiki export in OpenOffice.org 3 I've just recently found an article that describes some default functionality in OpenOffice.org 3 that isn't present in my install on 10.04 - This entry details that the Export functionality post 2.4 should have MediaWiki listed - but I only see XML,HTML, and PDF in the export options. Was this removed by the maintainers of this package in Ubuntu - or is there a package I haven't downloaded.\nHow do I restore this functionality?\n\nA: Ensure that openoffice.org-wiki-publisher is installed:.\nopenoffice.org-wiki-publisher \n", "Q: What's wrong with my cron.hourly configuration? Every hour I get an email with error like this,\nSubject: Cron <root@supa> root    cd / && run-parts --report /etc/cron.hourly\n\n/bin/sh: root: not found\n\nContents of /etc/crontab is as follows, either I remove user \"root\" or not (6th column), I get the same error.\nSHELL=/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\n# m h dom mon dow user  command\n11 *    * * *   root    cd / && run-parts --report /etc/cron.hourly\n25 6    * * *   test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )\n47 6    * * 7   test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )\n52 6    1 * *   test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )\n#\n\nThere are two files in my cron.hourly directory,\n$ ll /etc/cron.hourly/\ntotal 0\nlrwxrwxrwx 1 root root 25 2009-10-29 09:24 ntpsync -> /home/<user>/bin/ntpsync\nlrwxrwxrwx 1 root root 28 2009-10-23 10:33 foo -> /home/<user>/bin/foo\n\nFirst script reads as follows,\n$ cat ~/bin/ntpsync\n#!/usr/bin/env bash\necho \"user: $USER\"\nif [[ \"$USER\" == \"root\" ]] ; then\n    ntpdate ntp.ubuntu.com\nelse\n    sudo ntpdate ntp.ubuntu.com\nfi\n\nEven I remove both scripts in my /etc/cron.hourly/ directory, I still get the same error email every hour. I tried to restart cron and I still get the same error email. The next idea I have is to reboot but I'd avoid that.\n$ sudo /etc/init.d/cron restart\n\nMy Ubuntu version is as follows,\n$ cat /etc/lsb-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=8.04\nDISTRIB_CODENAME=hardy\nDISTRIB_DESCRIPTION=\"Ubuntu 8.04.1\"\n\nUpdate: I removed the 6th columns \"root\" from my /etc/crontab file earlier because when I searched online someone mentioned that could fix the problem. Now I think the problem was that I was messing around with the system crontab config instead of that of the root's.\n$ sudo crontab -l\n# m h  dom mon dow   command\n17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly\n25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )\n47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )\n52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )\n\n\nA: The default crontab file from the cron package (3.0pl1-100ubuntu2.1 this is the latest version of ubuntu 8.04) looks like this:\nSHELL=/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\n# m h dom mon dow user  command\n17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly\n25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )\n47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )\n52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )\n\nYou should just be able to take this and paste it into the file, but you might also want to make sure that you have the latest version of the package. You can do this by doing:\napt-get update\napt-get install cron\n\nUpdate:\nThere are two different types of crontab's one is the system's crontab that is located in /etc/crontab. This crontab has this fromat:\nminute hour dayOfMonth month dayOfWeek userToRunAs restOfLineIsCommand\n\nThe other type is the users crontab's this can be modified by using the crontab. The actual configuration is located in /var/spool/cron/crontabs/USERNAME and is always executed as the user that owns it, and thous the format of that file is:\nminute hour dayOfMonth month dayOfWeek restOfLineIsCommand\n\n\nA: I know you said you still get the errors after you remove the \"root\" in the sixth column, but it really looks like the issue.\nFor example, look at the other lines.  They all start with \"test\".  That's not a user, that's the beginning of a command.  Removing the \"root\" would make your command start with \"cd\".\nEspecially since the error message says it can't find \"root\" which is the error you get when you try to run a program that doesn't exist.\nSo I'd say try removing that again.\n\nA: Your /etc/crontab looks funny indeed. Every line should actually have a user column actually, which is the funniest part. For example, mine reads:\n# /etc/crontab: system-wide crontab\n# Unlike any other crontab you don't have to run the `crontab'\n# command to install the new version when you edit this file\n# and files in /etc/cron.d. These files also have username fields,\n# that none of the other crontabs do.\n\nSHELL=/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\n# m h dom mon dow user  command\n17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly\n25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )\n47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )\n52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )\n#\n\nBy the way, it is usually not a good idea to touch this file. If you need to add more generic crontabs, use /etc/cron.d for this. You can try to restore the default configuratino for the cron package with:\n$ sudo apt-get install --reinstall --yes -o DPkg::Options::=--force-confmiss -o DPkg::Options::=--force-confnew cron\n\nand see if it fixes the issue.\n\nA: There are really two issues at play here. One (the more obvious) is the improper 6th column in root's personal crontab. The second silent one - is that ever command after the hourly cron line in /etc/crontab is not executing properly. The fixes are below:\n\nYou can remove the bogus user crontab file by running sudo crontab -r\n\nOnce that's complete you'll need to add the root user in the /etc/crontab file for each line after the hourly cron line - like so:\nSHELL=/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\n# m h dom mon dow user  command\n11 *    * * *   root    cd / && run-parts --report /etc/cron.hourly\n25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )\n47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )\n52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )\n#\n\nThis should resolve those email issues.\n\nA: Do it:\n# crontab -r\n\nAnd do NOT do it:\n# crontab /etc/crontab\n\nInstead, edits file /etc/crontab manually.\n", "Q: UbuntuOne contact synching for Thunderbird? Is it possible to sync UbuntuOne contacts with Thunderbird's address book?\n\nA: Michael is correct. Thunderbird doesn't integrate with CouchDB (yet :) so the only way to get it to sync with the Ubuntu One cloud is through our mobile phone contacts sync service since Funambol (our technology partner) has developed an add-on for that application. They also have add-ons for MS Outlook and the Mac Address Book applications.\nCurrently their add-on does not support Thunderbird 3 (so jumpnett is correct) but they're working on supporting that version of the application.\nThanks!\n\nA: It is supported, but not quite as elegantly as Evolution syncing.  Here's the step-by-step:\nhttps://wiki.ubuntu.com/UbuntuOne/Tutorials/Contacts#Sync%20Thunderbird%20contacts\nBasically, you must tell Ubuntu One you have a mobile phone (you can fake it) and then install the mobile phone syncing plugin for Thunderbird and point it at Ubuntu One.\n\nA: As of 11.10 (a year and a half after you asked) the answer is a resounding \"yes.\" At this stage integration works well.\n", "Q: How to Write a Shell Script to Move Files from FTP Server to Network Share Drive I have customers who upload large amounts of data to my FTP server (an Ubuntu 9.10 machine).  Once the files are uploaded, I am faced with transferring them to a local Droboshare network drive so our technical support staff can retrieve them and analyze the issue.\nAfter I mount the network share at /media/<sharename> I run this command manually to get these files:\nsudo mv /home/ftp/<data_dir>/<file_name> /media/<network_share>/<ftp_user_data>\nbut this takes forever and if there are tens or hundreds of files, I can't realistically do this over and over again.  I thought it would be nice to have a script that I could run periodaclly to transfer a group of these files to the network share.  I can sort them as the technical support staff uses them.\nI am still new to Linux and writing shell scripts.  Anyway to do this easily?  Just to add to the description here, the files could be ZIP files, FASTA files, TAR.GZ files, and/or TXT files.  Also, if the ZIP files are large, certain zipping programs convert these to ZIP.001, ZIP.002, ZIP.003, etc...  So the file type in this FTP directory could be quite varied.\nI was thinking the way I can identify these files is by simply transferring ALL files in the directory (although this may take a while) or to somewhat designate a subset of these, according to time completed or something like this.\nI'm open to ideas.  Thanks in advance.\n\nA: Why not just make the FTP folder the actual mount point for the network drive? I run into a similar issue where I'm constantly backing up VirtualMachines on a Linux machine to a Windows network share (since the majority of the company infrastructure is Windows). This is my structure:\n/media/windows-share is my mount point\nFor continuity I've created a symlink in my backup application:\n/opt/backup/mnt so if the mount point changes in the future my program doesn't need an update.\nLastly I employ a cool little tool called autofs (sudo apt-get install autofs) That guide is decent (and up to date) - though I've employed this with a slightly different approach on my blog.\nIn your case I would create a symlink where my FTP dropbox is (/home/ftp/<data_dir>/) to the appropriate network folder in /media/<network_share>/<ftp_user_data> that way there's no wasted time in transferring across disks and the files are available immediately.\n\nA: For duplicating files from here to there (or there to here), rsync is a swiss army chainsaw which will likely do what you want.\n\nA: You could try to process files as soon as they're uploaded to the FTP, using a technology sucha s inotify. inoticoming is a tool you can use for that, see http://manpages.ubuntu.com/manpages/lucid/man1/inoticoming.1.html.\n", "Q: Is git-svn in the 10.04 repos broken? Has anyone seen problems with git-svn not installing properly from synaptic in 10.04? Anyone know how to fix this?\n\nA: Oops, it's the git-xxxx format for git commands has been depreciated. git svn seems to work.\nhttps://bugs.launchpad.net/ubuntu/+source/git-core/+bug/598593\n", "Q: How do I set up an HP remote control? I have an old receiver (USB) and remove control that i am trying to get working on Ubuntu with Boxee. \nAny suggestions for setting this up? software I need. \n\nA: Install gnome-lirc-properties \"Infrared Remote Control\" from Ubuntu Software Center or\nsudo apt-get install gnome-lirc-properties\nIt will set up the configuration for your remote in lirc and allow you to test the remote.\nAfter setting that up you need to set up your remote with boxee file. Next Boxee needs a config file for the remote. Copy /opt/boxee/system/Lircmap.xml to $HOME/.boxee/Lircmap.xml. \nNow open the Lircmap.xml copy that is in the UserData folder, and add the code from this forum post just before the ending  tag:\n<remote device=\"Streamzap_PC_Remote\">\n    <pause>PAUSE</pause>\n    <stop>STOP</stop>\n    <forward>&gt;&gt;</forward>\n    <reverse>&lt;&lt;</reverse>\n    <left>LEFT</left>\n    <right>RIGHT</right>\n    <up>UP</up>\n    <down>DOWN</down>\n    <select>OK</select>\n    <pageplus>CH_UP</pageplus>\n    <pageminus>CH_DOWN</pageminus>\n    <back>EXIT</back>\n    <menu>MENU</menu>\n    <title>PLAY</title>\n    <info>More</info>\n    <skipplus>&gt;&gt;|</skipplus>\n    <skipminus>|&lt;&lt;</skipminus>\n    <display>Teletext</display>\n    <start>Home</start>\n    <record>RECORD</record>\n    <volumeplus>VOL_UP</volumeplus>\n    <volumeminus>VOL_DOWN</volumeminus>\n    <mute>MUTE</mute>\n    <power>POWER</power>\n    <myvideo>Videos</myvideo>\n    <mymusic>Music</mymusic>\n    <mypictures>Pictures</mypictures>\n    <mytv>TV</mytv>\n    <one>1</one>\n    <two>2</two>\n    <three>3</three>\n    <four>4</four>\n    <five>5</five>\n    <six>6</six>\n    <seven>7</seven>\n    <eight>8</eight>\n    <nine>9</nine>\n    <zero>0</zero>\n    <mytv>RED</mytv>\n    <mymusic>GREEN</mymusic>\n    <mypictures>YELLOW</mypictures>\n    <myvideo>BLUE</myvideo>\n</remote>\n\nEdit the keys for your particular remote.\nSave the file and open Boxee, and the remote should now work.\n", "Q: Most elegant way to check if a process is running, and start if not? I've been messing around with various ways to do this in bash, and I've found pgrep program > /dev/null || program to be the shortest/most elegant way of doing this.  Is there a better method than this?\n\nA: With pgrep, you might match other programs than just yours. If you want to be sure to match the right program, use pidof instead.\nYou could also use start-stop-daemon with a PID file. start-stop-daemon will check if the program is running and start it if required. This is what is used in most init scripts.\n\nA: [ -z `pidof program` ] || echo \"program runing\"\n# or \n[ -z `pidof program` ] && OtherProgram \n\n", "Q: Extracting meta data from raw images (DSLR camera) I am searching for a tool, that extracts meta data out of raw images produced by a digital SLR (in my case Canon EOS 550D).\nThe photos can be converted by a recent version of ufraw (here is the PPA for that).\nWith my compact camera I simply use exif, which only works on jpg and does not work with raw images.\nAny hints?\n\nA: From the description of the package exifprobe:\n\nExifprobe reads image files produced\nby digital cameras (including several\nso-called \"raw\" file formats) and\nreports the structure of the files and\nthe auxiliary data and metadata\ncontained within them. In addition to\nTIFF, JPEG, and EXIF, the program\nunderstands several formats which may\ncontain \"raw\" camera data, including\nMRW, CIFF/CRW, JP2/JPEG2000, RAF, and\nX3F, as well as most most TIFF-derived\n\"raw\" formats, including DNG, ORF,\nCR2, NEF, K25/KDC/DCR, and PEF.\nhttp://www.virtual-cafe.com/~dhh/tools.d/exifprobe.d/exifprobe.html\n\nDoes that work?\n\nA: I would use exiv2 tool this is the same library as ufraw/darktable uses for accessing exif data in raw images.. http://www.exiv2.org/\nwhich also does support some MakerNotes from manufactors such as Nikon/Canon.\nWith exiv2 it also possible to look at some advanced technical data about image. For example \nexiv2 -P nxytv your_raw_file\n\nwill output all tags as\ntag hex code tag name tag data type tag plain data tag interpreted data\nwhich contains, for example, ColorMatrix and CameraCalibration values.\n\nA: From your comment I get it that what you ultimately want to do is renaming the file based on the date. If that's the only reason why you want to use a commandline tool instead of a GUI, you could try phatch (in the repositories) instead of doing the EXIF extraction/file renaming yourself.\nPhatch allows to batch process images (i.e. perform a set of actions on every image in a folder for example). One of the possible actions is rename and you can use Variables like <Exif_Image_DateTime> to rename it based on the EXIF data. Once you defined and saved your list of actions, you can also use phatch from the commandline.\n\nA: If I were you, I'd consider writing a little Python script to do this, pulling in pyexiv2. It's extremely easy to use:\n>>> metadata = pyexiv2.ImageMetadata('test.jpg')\n>>> metadata.read()\n>>> metadata.exif_keys\n['Exif.Image.ImageDescription',\n 'Exif.Image.XResolution',\n 'Exif.Image.YResolution',\n 'Exif.Image.ResolutionUnit',\n 'Exif.Image.Software',\n 'Exif.Image.DateTime',\n 'Exif.Image.Artist',\n 'Exif.Image.Copyright',\n 'Exif.Image.ExifTag',\n 'Exif.Photo.Flash',\n 'Exif.Photo.PixelXDimension',\n 'Exif.Photo.PixelYDimension']\n>>> metadata['Exif.Image.DateTime'].value\ndatetime.datetime(2004, 7, 13, 21, 23, 44)\n\nNote: Different cameras use different fields for dates. Check first to see what keys are available.\nIt should support raw images. I know it does for the NEF raw files my Nikon creates.\nIf it doesn't, do you have JPEG versions too with similar names (ie different extensions)? Even if it can parse your RAW files, it might be worth ticking through the JPEGs for its EXIF data because it'll likely be a bit faster.\nTip: You can use the Python shell instead of having to write a \"proper\" Python script. This is good for testing things out but if you want something you can use over and over again, you probably want to write a script.\n\nA: My favorite answer for fussing with EXIF data is exiftool. It's portable, free, open, written in Perl, and can be used as a Perl module for those so inclined.\nIt even works on Windows.\n", "Q: User account messed up. How to restore functionality? Complete story:\nWhen I installed Simon Tatham's Portable Puzzle Collection via Ubuntu software center, I noticed some of the newest puzzles were missing. So I decided to get the source files and compile them myself. I uninstalled the collection and downloaded the appropriate tar.gz file from the creator's website.\nWhen I tried make, I got many error messages and I found out I was missing some libraries. I went on installing lib-gtk-2.0 (I think) and my first compilation ever on linux was a success.\nI didn't have any decent shortcuts on the appropriate subfolder on the gnome menu (I'm using UNE), so I used alacarte to attach the correct images to the shortcuts.\nThe first thing I noticed was that the other user accounts didn't have the shortcuts as well. Also, all games suffered from the same problem. Whenever the user opened the system menu in any game, that menu remained drawn forever on the window.\nI didn't like that at all, so I decided to only keep the puzzles that were missing form the original collection and reinstall the rest from Ubuntu software center. I though I would at least have most of the games behaving correctly. Therefore, I used alacarte again to delete the \"common\" shortcuts. After the installation though, I wasn't getting any of the shortcuts on the gnome menu (other user accounts had them correctly), so I decided to delete alacarte's configuration files found inside ~/.config/? (I'm not in front of an Ubuntu-running computer at the moment, so I can't tell for sure).\nNow my user account profile is broken. When I log on, the top (and only) bar is not loading at all. I don't want to mess up the profile further so I decided to stop here and ask for help. How to restore the top gnome bar missing and have my shortcuts working correctly from now on? Deleting and recreating the user account is not an option.\nSorry for the long story (I believe it was necessary to explain the steps I took in order to help others help me). Kudos to the guy who can also tell me why the system menus didn't work correctly when I compiled the games myself.\nUpdate:\nI'm also missing the windows title bars and borders around. Also the z-order of the windows cannot be changed (Gnome is not bringing the active window in front). Finally, under \"Files & Folders\" no shortcuts are not working (I'm getting the message \"No application is registered as handling this file\").\n\nA: When you \"remove\" a menu entry with alacarte, what it really does is create a user-local file that describes the application according to the FreeDesktop.org \"Desktop Entry Specification\", and indicates that it should be hidden from the menu.  Local \"desktop entry\" files override system-wide ones.  These local files are located in ~/.local/share/applications/.  Remove the local *.desktop file, and the system-wide one (as installed by the package) will take over again.\n\nA: I assume (perhaps incorrectly) that the UNE uses the same config as normal gnome. To reset your menus to a system-wide standard, run this:\nmv ~/.config/menus ~/.config/backupmenus\n\nIf you can't log in graphically (to the point where you can get a terminal window up), Control+Alt+F1 will give you a text login from whence you can fire off the command.\nI suspect the menu isn't loading because there's something awry with the config - that's usually how these things work. If resetting the menu structure doesn't work, you might want to try moving the whole of .config, .gconf, .gnome and .gnome2 out the way, in that order, to see if any fixes things.\n\nA: gconftool --recursive-unset /apps/panel && killall gnome-panel (from #ubuntu's ubottu) will reset your panels to the default.  If alt+f2 is available you can just run that from there.\n\nA: I have read in OMG Ubuntu that the new beta of UbuntuTweak can do it with a single click. I had never tried it (the new function, I did try UbuntuTweak but I didn't like it), it's beta software, etc, etc, all the usual warnings, but you can try it as a last measure.\n", "Q: Touchpad mouse stopped working after partition changes Because my ubuntu partion was to small, I have enlarged it with the Ubuntu LiveCD + GParted.\nAll went fairly well (it said there were 2 warnings, but nothing severly), but afterwards, after I have logged in, the touchpad stops working.\nStrange thing is, in the login screen, it still works perfectly, and an external USB mouse also works.\nI have a HP DV6 2030sd laptop with Ubuntu 10.04 installed.\nDoes anyone know what steps I can take to solve this problem?\n\nA: I've got it working after switching the hardware enable/disable touchpad button.\n", "Q: upstart, exec and stderr I am using syslog-ng on a Ubuntu Lucid machine with the following upstart script:\n# syslog-ng - system logging daemon\n#\n\ndescription     \"Syslog-ng daemon\"\n\nstart on (local-filesystems and net-device-up IFACE!=lo)\nstop on runlevel [!2345]\n\nexpect fork\nrespawn\n\npre-start script\n    test -x /usr/sbin/syslog-ng || { stop; exit 0; }\n    mkdir -p -m0755 /var/run/syslog-ng\nend script\n\nexec /usr/sbin/syslog-ng -p /var/run/syslog-ng/syslog-ng.pid\n\nWhen the syslog-ng configuration file is wrong, syslog-ng outputs an error message on stderr. Unfortunately, this error is caught by upstart and doesn't get to the console when starting the service, so there is no way to know why the service start failed.\nIs it normal that upstart would catch stderr? Can it be set?\n\nA: This is documented in init(5); you can add the following line to your /etc/init/syslog-ng.conf to see output:\nconsole output\n\n\nAlternatively, you can see output from all upstart scripts when you add the following to the kernel boot parameters:\nINIT_VERBOSE=yes\n\nYou can do that temporarily by editing the parameters in the grub menu during boot, or (more) permanently by editing /etc/default/grub and adding it to GRUB_CMDLINE_LINUX, then afterwards run update-grub.\nFor more information and best practices,  see The Upstart Cookbook.\n\nA: If the stdout is getting through what you can do is. which will pipe the stderr to stdout which should solve your problem. :)\nsyslog-ng 2>&1\n\n", "Q: Delete eth0 avahi from the ifconfig list Hello this is the response I get from ifconfig. Now I have two eth0 things being showed up. I need to delete the second one which says eth0:avahi. I posted my ifconfig's response on a site as I has problem using wired internet, and they suggested to remove the eth0 avahi, to get internet.\nBut I am a newbie to linux networking and have no idea how to delete this.\nresponse for ifconfig\neth0 Link encap:Ethernet HWaddr 18:a9:05:22:cd:f9\nUP BROADCAST MULTICAST MTU:1500 Metric:1\nRX packets:0 errors:0 dropped:0 overruns:0 frame:0\nTX packets:0 errors:0 dropped:0 overruns:0 carrier:0\ncollisions:0 txqueuelen:1000\nRX bytes:0 (0.0 B) TX bytes:0 (0.0 B)\nInterrupt:28 Base address:0x4000\n\neth0:avahi Link encap:Ethernet HWaddr 18:a9:05:22:cd:f9\ninet addr:169.254.10.43 Bcast:169.254.255.255 Mask:255.255.0.0\nUP BROADCAST MULTICAST MTU:1500 Metric:1\nInterrupt:28 Base address:0x4000\n\nlo Link encap:Local Loopback\ninet addr:127.0.0.1 Mask:255.0.0.0\ninet6 addr: ::1/128 Scope:Host\nUP LOOPBACK RUNNING MTU:16436 Metric:1\nRX packets:796 errors:0 dropped:0 overruns:0 frame:0\nTX packets:796 errors:0 dropped:0 overruns:0 carrier:0\ncollisions:0 txqueuelen:0\nRX bytes:64016 (64.0 KB) TX bytes:64016 (64.0 KB)\n\nwlan0 Link encap:Ethernet HWaddr 00:26:82:3c:ac:27\ninet6 addr: fe80::226:82ff:fe3c:ac27/64 Scope:Link\nUP BROADCAST MULTICAST MTU:1500 Metric:1\nRX packets:52142 errors:0 dropped:0 overruns:0 frame:0\nTX packets:30404 errors:0 dropped:0 overruns:0 carrier:0\ncollisions:0 txqueuelen:1000\nRX bytes:60816983 (60.8 MB) TX bytes:4160159 (4.1 MB)\n\n\nA: The ethX:avahi (or whatever your interface's name is) will disappear as soon as you get either a fixed or dynamic IP from e.g. a router.\nIn case you're using the command line you can use this:\nsudo ifdown eth0 && sudo ifup eth0\nor\nsudo /etc/init.d/networking restart\nAlthough the avahi interface can be annoying, it should only show up when you didn't get any IP.\nLike Elias said you can also try to disable to daemon by editing /etc/default/avahi-daemon to have it look like this:\nAVAHI_DAEMON_DETECT_LOCAL=0\nTo sum up I suggest you simply restart your networking and if there is a router willing to give you an IP then your avahi interface should be gone.\nThis is my interfaces file just in case:\nauto lo\niface lo inet loopback\nauto wlan0\niface wlan0 inet dhcp\nwpa-conf /etc/wpa_supplicant/wpa_supplicant.conf\n\nps: as you can see I'm using wpasupplicant and got rid of network-manager but that's unrelated to the avahi issue.\n\nA: Avahi is a daemon (a service) which is responsible for several things, including attributing you an IP address when DHCP (automatic IP address from a DHCP server on the network) fails.\nThe fact that eth0:avahi appears means that the system failed to get an IP on the eth0 interface (your wired network interface).\nNormally, NetworkManager should take care of attributing an IP automatically to eth0. However, you could try to force it. Your /etc/network/interfaces doesn't list eth0, so what you can try is the following.\nFirst, edit /etc/network/interfaces (with sudo gedit /etc/network/interfaces for example) so it reads this:\nauto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet dhcp\n\nThis will tell the computer to consider getting an IP automatically for eth0.\nThen, restart the network with:\n$ sudo /etc/init.d/networking restart\n\nIf it still doesn't work, there might be other issues:\n\n\n*\n\n*are you sure there is a DHCP server on your network? If there isn't, you'll have to setup the IP address manually;\n\n*if you have a DHCP server, it probably means that your problem is a hardware issue. Check that the cable is well plugged and lights are on on both sides of it.\n\n\nA: Hello I am new at ubuntu as well.\nI had a similar problem to the one described above and I caused it myself.\nMy linux version is Ubuntu 10.04.1 LTS and I use eth0 to connect to a dsl modem/router which also is a dhcp server for the pc in eth0.\nI was reading a book about linux and tried to use the \"ifdown eth0\" and \"ifup eth0\" command but I was getting the following results.\nsudo ifdown eth0\nIgnoring unknown interface eth0=eth0.\nifdown: interface eth0 not configured\n\nsudo ifup eth0\nIgnoring unknown interface eth0=eth0.\n\nI look it up in the internet and it found that in the /etc/network/interfaces file there should have the record I show bellow for the eth0 in order for these commands to work.\n#The loopback network interface \nauto lo\niface lo inet loopback\n\n#The primary network interface\nauto eth0\niface eth0 inet dhcp\n\nI only had only the lo record in my file and although I connected to the internet without a problem from the time I installed ubuntu I added the eth0 record as well.\nAs it is mentioned above I restarted the network and everything seemed to work just fine.\nAnd I could use the ifdown and ifup commands.\nUntil I opened my pc again after a pc shutdown and a CPE restart.\nI couldn't not browse in the web and if remember correctly I couldn't even ping my router. From what I understand the eth0 was not getting an IP address from the dhcp of the router.\nAlso I had the exact same ifconfig result that is shown above in the threads beginning.\nIn my case I could solve my problem by doing \"sudo ifdown eth0\" and then \"sudo ifup eth0\". The eth0 got an IP address and everything worked just fine. Of course every time I had a shutdown I had to repeat the process.\nToday I looked the avah that is mentioned in the ifconfig response and I checked to see if it was turned on my pc.\n$ cat /etc/default/avahi-daemon\n# 1 = Try to detect unicast dns servers that serve .local and disable avahi in\n# that case, 0 = Don't try to detect .local unicast dns servers, can cause\n# troubles on misconfigured networks\nAVAHI_DAEMON_DETECT_LOCAL=1\n\nI guess it is turned on although it doesn't mention anything about the dhcp.\nIn my case i remove the eth0 entries from the /etc/network/interfaces and I got back in the situation I was before.\nI cannot use the ifup and ifdown command but after a shutdown eth0 got it's IP from my routers dhcp without a problem.\nWhat I haven't done is set my avahi setting to 0 and then add the eth0 in the /etc/network/interfaces file to see what happens.\nI hope my writtings help and not confuse.\nRegards\nElias\n\nA: Check if avahi is listed in your /etc/network/interfaces file. If it is, delete it from there.\n\nA: for ubuntu20, ifconfig has\nenp0s31f6:avahi: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500\n        inet 169.254.4.163  netmask 255.255.0.0  broadcast 169.254.255.255\n        ether f8:75:**:**:**:**  txqueuelen 1000  (Ethernet)\n        device interrupt 16  memory 0xea200000-ea220000 \n\n\nSettings > Network:\n　select 169.xxx.xxx.xxx connection, click ⚙️ icon:\n　　click remove connection profile\n\nthen, enp0s31f6:avahi will gone\n", "Q: How do I play a midi from the command line in Ubuntu? I'd like to do something like\n$ play filename.mid\n\nand hear the midi file played without opening up a graphical program.  Is there a package for Ubuntu that can do this?\n\nA: You'll likely want the playmidi package (sudo apt-get install playmidi) which will allow you to play midi files from the command line.\nplaymidi filename.mid\n\nA: fluidsynth from http://www.fluidsynth.org/.\nUse it like this:\nfluidsynth /some/dir/with/sundfonts/some_soundfont.sf2 some.mid\nYou can find soundfonts here: https://musescore.org/de/handbuch/soundfont\nAnd quite a nice collection of MIDI files to try this out here: http://garyrog.50megs.com/midi1.html\nI especially like the soundfont \"Timbres of Heaven\" from http://midkar.com/soundfonts/.\n\nA: I know this thread is old, but I was looking for answers for a Raspberry Pi but didn't find any. After more work I came up with the following, it may work in Ubuntu too. The output is through a cheap USB to midi interface.  \nOn Raspbian Jessie Lite with no extra installs:\npi@pizerow:~$ aconnect -l  \nclient 0: 'System' [type=kernel]  \n0 'Timer           '  \n1 'Announce        '  \nclient 14: 'Midi Through' [type=kernel]  \n0 'Midi Through Port-0'  \nclient 20: 'CH345' [type=kernel]  \n0 'CH345 MIDI 1    '  \npi@pizerow:~$ aplaymidi --port=20:0 myfile.mid  \n\n\nA: There are many different packages/commands you can try:\n\n\n*\n\n*wildmidi (as used by gstreamer)\n\n*timidity (found this very CPU intensive)\n\n*playmidi (never tried personally)\n\n\nA: If you have fluidsynth installed, you can also play Midi files with VLC by installing the vlc-plugin-fluidsynth package.\n\nA: Another alternative besides Fluidsynth nowadays is Timidity. Install the packages timidity, timidity-interfaces-extra and freepats (the latter is about 30MB, but smaller than the sf2 files in fluid-soundfont-gm).  Then the following should work:\ntimidity -Os midi.mid\n\n", "Q: What is difference between the options \"autoclean\", \"autoremove\" and \"clean\"? apt-get has a few options which looks the same to me: autoclean, autoremove and clean. What do each of them do?\n\nA: autoclean: removes all stored archives in your cache for packages that can not be downloaded anymore (thus packages that are no longer in the repo or that have a newer version in the repo).\nclean: removes all stored archives in your cache.\nautoremove: a whole different thing, this option makes apt look for packages that are installed as dependency of an already uninstalled package and removes them. This is used to clean up unused dependencies that remain on your system.\nAnswer found: http://ubuntuforums.org/showthread.php?t=394952\n\nA: From the apt-get man page:\n\n*\n\n*clean:   clean clears out the local repository of retrieved package files.\nIt removes everything but the lock file from\n/var/cache/apt/archives/ and /var/cache/apt/archives/partial/. When\nAPT is used as a dselect(1) method, clean is run automatically.\nThose who do not use dselect will likely want to run apt-get clean\nfrom time to time to free up disk space.\n\n\n*autoclean: Like clean, autoclean clears out the local repository of retrieved\npackage files. The difference is that it only removes package files\nthat can no longer be downloaded, and are largely useless. This\nallows a cache to be maintained over a long period without it\ngrowing out of control. The configuration option\nAPT::Clean-Installed will prevent installed packages from being\nerased if it is set to off.\n\n\n*autoremove: is used to remove packages that were automatically\ninstalled to satisfy dependencies for some package and that are no\nlonger needed.\n\nEvery command has a manual page, if you want to know what their parameters are or what each of them do, just type in the shell `man `  Ex. `man apt-get`\n\n*\n\n*manpage for the apt-get command \n", "Q: How to fix SSL error from Python apps (urllib) when behind HTTPS proxy? Example of a failure:\n***** Processing account GMail\nCopying folder structure from Gmail to MappedIMAP\nEstablishing connection to imap.gmail.com:993.\nWARNING: Error occured attempting to sync account GMail: [Errno 8] _ssl.c:490: E\nOF occurred in violation of protocol\n\n\nA: Check out Greg's post here:\nhttp://blog.grossmeier.net/2009/01/25/imapfilterofflineimapmsmtpmuttabook/\nIt's a really good summary and he has a sample .offlineimaprc for Gmail. His has a much different RepositoryRemote section\n[Repository RemoteGmail]\ntype = IMAP\nremotehost = imap.gmail.com\nremoteuser = $user@gmail.com\nremotepass = yep\nssl = yes\n\n\nA: It looks like there is a bug in the way either Gmail or whatever offlineimap uses (OpenSSL I assume?) implements SSL?\n\nA: https://bugs.edge.launchpad.net/ubuntu/+source/python2.6/+bug/94130\nThis is a bug in python/urlib[2] there are some fixes in python2.6/2.7 but apps need to be ported as well.\nEDIT\nexcept that I'm wrong. It uses python ssl module, which uses OpenSSL.\n", "Q: How can I install a Gnome Applet without privileges I would like to install stackapplet, but I don't have superuser privileges to install the deb file and the admins will not install it for me.\nI'm confident that I must be able to install this applet without privileges, but I can't seem to find a really good guide.\nWhat are the steps I need to take to install this applet?\n\nA: AFAICS you cannot install stackapplet without superuser privilege because every gnome applet has Bonobo control file (GNOME_AppletName.server) which is in /usr/lib/bonobo/server You Must have bonobo control file to use applet and you cannot edit /usr/lib/bonobo folder unless you have sudo privilege. There is also bonobo-activation-config file in /etc/ which i believe contains path for the bonovo server files. If you can add your custom path then it may help but again you need sudo to edit that file.\nBut i cannot say its impossible :) there might be some way which i don't know.\n\nA: I am sorry I have not been able to test the following , but I hope it gives us some direction \nhttp://old.nabble.com/installing-a-panel-applet-without-being-root-td9261908.html\n", "Q: How do I make Gnome (and Gnome applications) automatically detect a wvdial connection? I use wvdial in order to connect to the internet using a cdma usb modem that isn't detected by the nm-applet.  \nHowever, once I've connected, gnome and other gnome applications don't seem able to determine that I am connected to the internet. (e.g. empathy, ubuntu one remain offline,  firefox \"work offline\" has to be disabled manually) \nThe desired effect is:  I connect via wvdial and gnome detects this and enables everything appropriately. \n\nA: There are 3 possible solutions:\n\n\n*\n\n*make NetworkManager recognize your CDMA modem (via ModemManager)\n\n*make wvdial support the NetworkManager dbus protocol\n\n*find another tool that supports both\n\n", "Q: Closing lid freezes laptop Closing the lid on my Dell Studio 15 which is running Ubuntu 10.04 freezes the screen. This is a new problem in Ubuntu 10.04 which did not exist in 9.10\nI have tried playing with all the settings in System->Preferences->Screensaver but nothing seems to make any difference. (please note the Power Management settings are accessible from here so I have tried those too.)\nI don't need hibernate or suspend. I just want to be able to close the lid, and then open it and still have a working laptop.\nIs their a settings somewhere that will make Ubuntu ignore the lid closing?\n\nA: I solved this by changing to the closed source FLGRX driver.\n\nA: These settings are in System -> Preferences -> Power Management.\n\n\nA: Make sure there is no SD card inserted.\nhttp://ubuntuforums.org/showthread.php?t=1478787 has 120,000 views of 980 responses - it is still possible that one of the solutions will work for you.\nhttp://bugs.launchpad.net/bugs/585765 is about the most useful bug report, although https://bugs.launchpad.net/bugs/528981 worked for me (mainline kernel 2.6.34 solution).\n\nA: gconftool-2 --type string --set /apps/gnome-power-manager/buttons/lid_ac \"nothing\"\n", "Q: Text editor capable of running complex Regular Expressions? I want to find a text editor capable of running and mainly storing regular expressions for later re-use. It should also be able to run them across multiple files.\nI know I can get all that with grep, but there is not much for re-use on it. I was able to get some regular expression functionality on Gedit with plugins, but not nearly close to my needs.\nThere is EditPad Pro for Windows (runs on wine) but native is always better :)\n\nA: If you just want to run regex against a bunch of files, I think it's time for you to learn about sed and awk\n\nA: You can use a combination of GEdit and the plugin Advanced find / replace plugin for gedit that you can find in http://code.google.com/p/advanced-find/.\nFrom 2012 it has the feature of bookmark an expression so you can reuse it. Also it can search and replace for opened files, for files in a folder (with a filter) or inside a text selection.\nAbout how to install, you can follow the instructions in its wiki page http://code.google.com/p/advanced-find/wiki/Installation.\nBasically what you must do is:\n\n\n*\n\n*Download the correct version for your gedit from http://code.google.com/p/advanced-find/downloads/list.\n\n*Decompress it.\n\n*Run install.sh (without sudo).\n\n*Go to preferences / plug-in and activate it.\n\n\nA: The two classic open source Unix editors are GNU emacs and (g)Vim and both work fine on Ubuntu. They both have more features than you can learn about in a lifetime, including what you're after. There are plenty of others two too, but you might as well start with the best. (I'll try not to get into which of these is better, since it's already an epic holy war.)\nBy the way, sed is probably a better alternative than grep for RegEx manipulations from the commandline, and you can write and save scripts for it. (Of course you can use perl, awk and python for reg ex too.)\nSome inspiration from xkcd: http://imgs.xkcd.com/comics/real_programmers.png\n\nA: Geany has a good set of find:\n\nreplace:\n\nand file searching:\n\nfeatures. It doesn't have any inbuilt ability to save regular expressions for later although you could always store them in a text file.\nIt does have history for find/replace but this is limited to one session.\n\nA: I wanted to add a comment pointing to this answer, but since apparently I don't have enough reputation for that, I'll duplicate it here as an answer of my own: RegExr is the best tool I've ever used for text manipulation using regular expressions. It will even explain each part of the regex for you!\nIt is an online tool, but there's a desktop version. This uses Adobe AIR, which has been discontinued for Linux, so you might need to install it following these excellent step-by-step instructions. After that, download the .air file for RexExr desktop page linked above, and you should be able to open it with the AIR installer. Then edit away!\n\nA: I'm really surprised nobody mentioned 'medit'...  search/replace has simple check box telling medit that the criteria you entered is a regex expression...  can be as simple or complex as you like..\n\nA: Atom has this function. Download and install the \"deb\" package.\nPress CTRL + F and click the .* button to go into regex mode.\nAlternatively, you can press CTRL + ALT + /\nAlso on github.\nRelated question on how to use regex in atom.\nOr you can use cat and sed. \nUse sed -e to simply print the changes. Use sed -i to actually edit the contents of the file.\nSee here for more info.\nYou can also use egrep to use regular expressions with grep.\nIf you just need find replace functions, gedit accepts regular expressions if you press CTRL + F.\nYou can also do regular expressions in vim.\n\nA: Eclipse is best though a bit heavy for the purpose.\nAll findings are available in a separate pane. (skeleton)\nYou can jump immediately to any of them.\n", "Q: Alt+Printscreen stopped working, how to find processes listening to events Very odd issue today. I was going to post a thread about another issue and wanted to take a screenshot of a terminal window. I got it all prepped, hit Alt+Printscreen and nothing happened.\nI went into Keyboard Shortcuts to see if redefining the shortcut worked. It did. I tried to set it back to Alt+Printscreen but the window just sat there listening for a keypress. It's as if I never pushed a key. \nBoth the Alt and Printscreen keys work independently just fine... I've also tried looking at the output of xev as I press the keys. It hears the Alt press but doesn't hear the Printscreen afterwards.\nI've tried this from both within Compiz and plain metacity. I also have a spare keyboard and that shows identical behaviour (one keyboard is PS/2, the spare is USB - so not a port issue).\nIt's like there's something sitting in the event chain spitting on the event so that nothing else can hear it. My question is basically: how can you find the processes responding to certain events?\nAs requested:\noli@bert:~$ xmodmap -pke | grep -i mode\nkeycode  82 = KP_Subtract XF86_Prev_VMode KP_Subtract XF86_Prev_VMode\nkeycode  86 = KP_Add XF86_Next_VMode KP_Add XF86_Next_VMode\nkeycode 100 = Henkan_Mode NoSymbol Henkan_Mode\nkeycode 203 = Mode_switch NoSymbol Mode_switch\n\nAnd \noli@bert:~$ xmodmap -pke | grep -i print\nkeycode 107 = Print Sys_Req Print Sys_Req\nkeycode 218 = Print NoSymbol Print\n\nEdit: When I posted this I was on Lucid with a home-built 2.6.35 kernel. It turns out my issue is related to the kernel and not X.\nSomebody somewhere has decided that alt-printscreen should render a SysRq event. Technically speaking, perhaps it should but this breaks what-must-be over a decade of Linux and Windows \"known behaviour\".\n\nA: Per my edit, this appears to be directly linked to the kernel version 2.6.35 (and probably subsequent kernels) whereby alt+prscr renders a sysrq event.\nSysRq appears to be unbindable (at least from my messing around) but you can disable the silly new behaviour by adding the following to /etc/sysctl.conf:\nkernel.sysrq = 0\n\n\nA: Since you indicate PrintScreen works but alt+printscreen doesn't, it could be something to do with your modifier mapping. \nIf you have 2 Alt keys, can you try with both and see if behaviour is same ? \nAlso, can u run the command xmodmap -pke | grep -i mode in a terminal and check if that indicates one of the alt keys is mapped as \"Mode switch\" key ? Typically you would see 1 or more keysym lines containing codes assigned to the Mode switch key.\nAlso run xmodmap -pke | grep -i print in a terminal and see if the codes printed to the right of the equal sign match with the below line. \nkeycode 107 = Print Sys_Req Print Sys_Req\n\nSee this page for explanation of the syntax of the keysym line.\n\nA: Reported bug is there.\nhttps://bugs.launchpad.net/ubuntu/+source/metacity/+bug/642792\n\nA: Did you try just using Print Screen?  I've never heard of using Alt with it.\n", "Q: Is there any way to turn my laptop into a wireless access point for other devices? \nPossible Duplicate:\nHow to set up ubuntu as wireless accesspoint? \n\nIs there an easy, simple way to setup a wireless network so my laptop (which is connected by a wired connection) can share that connection with my mobile phone and other devices?\nThank you for any answers in advance!\n\nA: *\n\n*Right click the Network Manager applet and click \"Edit Connections\" \n\n*Go to \"Wireless\" tab and click \"Add\"  \n\n*Enter \"ICS\" in the \"Connection name\" field  \n\n*Enter \"ICS\" in the SSID field  \n\n*Change the Mode to \"AdHoc\"\n\n*Go to \"IPv4 Settings\" and select Method \"Shared to other computers\"\n\n*Connect to the ICS wireless network\n\n\nThese steps are from memory and might be incomplete. WPA2 security seems not to work.\nSee http://www.ubuntugeek.com/creating-an-adhoc-host-with-ubuntu.html also.\n\nA: see How to set up Ubuntu as wireless accesspoint?\n", "Q: Do AppIndicators work on Xubuntu? I don't have access to an Xubuntu install right now so I thought I'd just ask this here.\nDoes Xubuntu (or more specifically, the XFCE panel) support AppIndicators?\nI'm porting an application to use them and I am curious to know if my app will work there.\n\nA: It should definitely be possible because the indicators are made to be cross-platform.\nIt appears that someone has developed an xfce panel applet to do provide this functionality:\nhttp://goodies.xfce.org/projects/panel-plugins/xfce4-indicator-plugin\nIt doesn't seem very mature though - its at version 0.0.1, which is the first stable release. It is not packaged but is available as source code.\n\nA: *\n\n*There is an XFCE panel plugin that should make it possible to put most GNOME panel applets into the XFCE panel.\n\n*The indicator applet is a GNOME panel applet.\n\n\nMaybe you can try if 1 supports 2?\n", "Q: Ubuntu Server on 5 year old PC I was recently downloading Ubuntu server to put on an old machine to serve media around my house. \nI was wondering why they recommend the 64-bit version of there server? Does this affect anything if I am putting it on a 5 year old computer? What about 32 bit?\nAlso if you could recommend some best practices for a home server. I would like to share files stream. Also host some webpages as well as use it as my git repository.\nA tutorial links would be appreciated or very explicit advice :)\nPlease and thank you.\n\nA: 64bit is recommended because most (probably all) systems sold today as servers are 64bit and have much more than 4GB of RAM, making 64bit necessary.   If you're talking about normal 5 year old PC hardware though, I really doubt it's 64bit with 8GB of RAM, so go for 32bit.\nI would just install openssh-server and use that to handle both SSH and SFTP (and by extension SSHFS, which lets you have a networked filesystem).\nSSHFS howto here:  https://help.ubuntu.com/community/SSHFS\nApache2 or lighttpd for web hosting, depending what you want.  Apache2 is pretty easy to get going.  Just install it, and put your index.html or index.php (or whatever) in /var/www/  If you SFTP things to /var/www/stuff/ then others can download them from their web browser instead of needing to know how to use SFTP too.\n", "Q: How to set up apache with fastcgi and a simple test script? It's been a few days that I'm trying to set up fastcgi with apache on a Kubuntu server. Despite searching everywhere, I cannot make it to work. If I try to run the site with the cgi application, apache hangs and after the timeout returns a 500 error.  \nHere is what I did:  \n\n\n*\n\n*I made sure that mod_fastcgi is installed and enabled:\n# pwd\n/etc/apache2/mods-enabled\n# ls -l f*\nlrwxrwxrwx 1 root root 30 2010-07-22 10:01 fastcgi.conf -> ../mods-available/fastcgi.conf\nlrwxrwxrwx 1 root root 30 2010-07-22 10:01 fastcgi.load -> ../mods-available/fastcgi.load\n\n\n*As far as I am aware, fastcgi.conf is properly configured:\n<IfModule mod_fastcgi.c>\n  AddHandler fastcgi-script .fcgi\n  #FastCgiWrapper /usr/lib/apache2/suexec\n   FastCgiIpcDir /var/lib/apache2/fastcgi\n</IfModule>\n\n\n*I am using this very simple sample script to test the set up:\n#include <iostream>\nusing namespace std;\nint main()\n{\n        cout<<\"Content-type: text/plain\"<<endl<<endl;\n        cout<<\"Hello World!\"<<endl;\n         return 0;\n}\n\n\n*I compiled it. It works fine from the command line.\n\n*I placed it within a folder visible from the web server: http://127.0.0.1/fcgitest/run.fcgi \n\n*At first I get: \"Forbidden. You don't have permission to access /fcgitest/run.fcgi on this server.\".\n\n*I add a .htaccess file in the folder:\nOptions +ExecCGI -Indexes\n\n\n*And now, when I try to access the script address from my web browser, I get the symptom I described at the beggining: the browser first hangs, and after the timeout, I get a 500 Internal Server Error.\n\n*The apache error.log say:\nContent-type: text/plain\nHello World!\n[Sat Aug 28 09:08:23 2010] [warn] FastCGI: (dynamic) server \n\"/var/www/fcgitest/run.fcgi\" (pid 27758) terminated by calling exit with status '0'\n\nIt seems the output is written to the error logs!! Is there a missing socket configuration, somewhere??\n\nA: As noted by joschi, CGI != FastCGI . A CGI script would fail in this context.\nhttp://127.0.0.1/doc/libapache2-mod-fastcgi/mod_fastcgi.html\nhttp://www.fastcgi.com/mod_fastcgi/docs/mod_fastcgi.html\nFastCGI Specification Compliance \nThe FastCGI specification is not implemented in its entirety and I've deviated a bit as well resulting in some Apache specific features.\nThe file descriptors for stdout and stderr are left open. This is prohibited by the specification. I can't see any reason to require that they be closed, and leaving them open prevents FastCGI applications which were not completely ported to FastCGI from failing miserably. This does not mean the applications shouldn't be fixed such that this doesn't occur, but is invaluable when using a 3rd party library (without source code) which expects to be able to write to stderr. Anything written to stdout or stderr in this manner will be directed to the main server log.\n\n", "Q: Setting http proxy in Awesome WM I have installed awesome on top of Ubuntu 10.04 and switch between Gnome and Awesome sessions (partly because I am still learning awesome and partly because I use a few apps that require Gnome desktop). Further I need to use a proxy server @ work whereas @ home I have a direct connection.\nUnder GNOME, I have defined 2 locations with gnome-network-properties (hereafter, g-n-p) and switch between these as needed.\nHowever, when I login to awesome, I am left with the settings as set in my last GNOME session. I can't invoke g-n-p because it needs gnome-settings-daemon to be running which is of course not the case. If I need to change I need to logout and in twice (once into GNOME to switch location and then back into awesome). Since I use many apps within awesome that use system proxy settings (Synaptic, Firefox) I'd like to be able to centrally switch the proxy configuration without leaving the awesome desktop.\nI understand running gnome-network-properties sets some gconf-editor keys and also updates *_proxy environment vars in /etc/environment (and probably elsewhere also). Is there a way to achieve the same effect via a script or some replacement tool for g-n-p that doesn't use gnome-settings-daemon ?\n\nA: You can start gnome-settings-daemon as part of your Awesome start up process. I usually invoke it manually when needed. \nAdd this to your ~/.config/awesome/rc.lua file: \n   awful.util.spawn_with_shell(\"gnome-settings-daemon\")\n… if you want to run it on startup. For me, at least, this was a lot easier than any other method I've tried. \n\nA: I made a script to be asked for passwords, now I can use gnome-network-properties apply system-wide without running gnome-settings-daemon.\n/usr/lib/polkit-gnome/polkit-gnome-authentication-agent-1 &\ngnome-network-properties\nkillall polkit-gnome-authentication-agent-1\n\n\nA: Since you're using Awesome (as I do :) ) you might be interested in a solution that is not dependend on running the gnome-blob-softwares...\nHere is the script that I run when Awesome starts (in fact I have a \"master\" script that is ran from ~/.config/awesome/rc.lua and that launches this script)\nexport no_proxy=localhost,127.0.0.1,*.example.com\nexport http_proxy=http://ex.example.net:8080/\nexport https_proxy=https://ex.example.net:8080/\nexport ftp_proxy=ftp://ex.example.net:8080/\n# export socks_proxy=\"\"   # I do not use this\n\n# Configuration\ngsettings set org.gnome.system.proxy.http host 'ex.example.net'\ngsettings set org.gnome.system.proxy.http port 8080\ngsettings set org.gnome.system.proxy.http use-authentication false\ngsettings set org.gnome.system.proxy use-same-proxy false\ngsettings set org.gnome.system.proxy.https host 'ex.example.net'\ngsettings set org.gnome.system.proxy.https port 8080\ngsettings set org.gnome.system.proxy.ftp host 'ex.example.net'\ngsettings set org.gnome.system.proxy.ftp port 8080\ngsettings set org.gnome.system.proxy.socks host ''  # I do not use this\ngsettings set org.gnome.system.proxy.socks port 0\n\n# Enabling\ngsettings set org.gnome.system.proxy mode 'manual'\ngsettings set org.gnome.system.proxy.http enabled true\ngsettings set org.gnome.system.proxy ignore-hosts \"[ 'localhost', '127.0.0.0/8' ]\"\n\n", "Q: Higher screen resolution in VirtualBox? I've just installed Ubuntu 10.04 into VirtualBox on Windows 7.  \nUnfortunately the only options showing for screen resolution are 640x480 and 800x600 and the monitor is showing as 'Unknown'.\nHow would I go about upping the resolution to 1280x1024 (I'm on a 1600x1200 monitor)? \nUpdate\nI tried mounting the VirtualBox 'Guest Additions' ISO (from the VBox 'Devices' menu) and doing sudo sh ./VBoxLinuxAdditions-x86.run \nfrom the mounted drive, which gave 2 new listed resolutions after a reboot (1024x768 and the 16:9 version of that resolution). These worked when I selected them but disappeared when I switched back to another resolution. I tried rebooting and running VBoxLinuxAdditions-x86.run again but onlu the 2 low res options listed this time.\nI think I'm going to reinstall...  \nSeems to be a VBox problem rather than an Ubuntu problem as after reinstalling 10.4 overwriting the original virtual partition, sudo sh ./VBoxLinuxAdditions-x86.run now has no affect at all. \n\nA: Once the Vbox Additions has been instaled (and reboot the guest os), press Host + H, then maximise the window, thats sould do the trick..\nIf not, maybe you are using an old version of vbox (therefore, the Vbox Additions might has an incompatibility..)\n\nA: Try increasing the amount of RAM allocated to the Virtual Box. Worked for me.\nTo do this, stop the VM, then in VirtualBox go to the Settings for the VM. Go to the Display section. You can increase the Video Memory there. Mine was 1MB; I increased it to 32MB and that allowed me to use my 24\" monitor fully.\n\nA: *\n\n*Settings > Video > Video Memory = 128 MB, Enable 3D acceleration = true.\n\n*Install GuestAdditions\n\n*On Host machine, in cmd/bash, run \nVBoxManage setextradata global GUI/MaxGuestResolution any\n\n\n*create /etc/X11/xorg.conf file with content:\nSection \"Device\"\n  Identifier      \"Configured Video Device\" \nEndSection\nSection \"Monitor\" \n  Identifier      \"Configured Monitor\"\nEndSection \nSection \"Screen\"  \n  Identifier      \"Default Screen\" \n  Monitor         \"Configured Monitor\"\n  Device          \"Configured Video Device\" \n  SubSection \"Display\"\n    Modes \"1920x1080\" \n  EndSubSection\nEndSection\n\n\n*For running VM:  \nHost Key Right Ctrl at default + Home = view full screen.\nI have tried to exclude every step except GuestAdditions installation. You need every one of them.\n\nA: Edit: http://www.linuxformat.com/forums/viewtopic.php?p=103289\n\n*\n\n*Start Virtual Box and log into Ubuntu.\n\n\n*Hit your host key(right Ctrl by default)so you can get your mouse pointer outside the virtual machine.\n\n\n*Go to top of virtual window, click on devices then select Install Guest Additions\nYou will see a window pop up inside Ubuntu showing you that there are some new files mounted in a virtual CDROM drive. One of those files should be VBoxLinuxAdditions.run\nYou must run the file with some admin permissions so do that this way...\n\n\n*Click inside the Ubuntu screen again then go to Applications > Accessories then Terminal. The terminal window is where you will run the file from, but first we must navigate to the correct directory.\n\n\n*Type cd /media/cdrom0 (then hit enter, there is a space after cd!)\n\n\n*Next type dir (You should seeVBoxLinuxAdditions.run among the files displayed)\n\n\n*Finally type sudo sh ./VBoxLinuxAdditions.run (yes, that is a full stop before the slash!)\nAfter you hit enter and it has done its stuff, the files are now accessible from Ubuntu.\n\n\n*You now need to reboot the virtual machine or press Ctrl+Alt+Backspace.\n\n\n*Log onto the Ubuntu desktop and go to System > Preferences then Screen Resolution. You should now have more options than the three low resolution options you had at the beginning of the day!\nIf the resolution you want is not one of the newly listed ones displayed then follow these steps:\n\n*\n\n*Open the terminal window (Applications > Accessories then Terminal)\n\n\n*Type sudo gedit /etc/X11/xorg.conf (case sensitive)\n\n\n*It will ask you for a password which is the same as the one you log in with(see sudo).\n\n\n*The text editor loads and you should see a lot of text in the window. First make a backup of this file by going to File then Save as and change the filename to xorgbak.conf\n\n\n*You now need to hunt through the text until you see the display resolutions listed. The ones you will be concerned about will be listed under bit depth 24 or bit depth 16 (as these depths are the ones that give you a large array of colors.)\n\n\n*The idea here is to have your favorite screen resolution included in this list. Do this by either inserting it before the other listed resolutions in the exact same manner or typing it over one of the others. (you will only need to do this for the ones under bit depth 24 and 16)\n\n\n*You must now do a \"save as\" but be careful here as this time we need to call the file xorg.conf again. If you just hit save here you would have overwritten the backup file you created which is not what we want.\n\n\n*Once you have completed the previous step, you are done. Hit Ctrl+Alt+Backspace to restart your Virtual Box instance, log in and enjoy your new screen resolution options!\n\nA: I can tell you how I do this with Mac OS X as the host system. Maybe it will work on Windows too.  \n\n\n*\n\n*I start ubuntu in VirtualBox\n\n*I open up the terminal on Mac OS X\n\n*and execute \"VBoxManage controlvm [name] setvideomodehint 1280 1024 24\" (replace [name] with the name of your ubuntu vm)\n\n\nA: I had the same problem and was able to fix it by using the xrandr utility. I followed this article to fix the issue.\nhttp://www.ubuntugeek.com/how-change-display-resolution-settings-using-xrandr.html\nSometimes this may help you. Give it a try. \n\nA: I was able to fix this problem by shutting down my VirtualBox virtual machines, quitting VirtualBox, and running this command in a Terminal:\nVBoxManage setextradata global GUI/MaxGuestResolution any\n\nThen start VirtualBox back up and the problem should be fixed!\n\nA: Following command worked for me\nOpen Terminal and type: \nsudo apt-get install dkms\nSource: http://www.virtualbox.org/manual/ch04.html\nRestart VirtualBox\n\nA: Apart from installing the Guest Additions plugin, note that the maximun display size may be capped in VirtualBox general preferences panel:\n\nAlso, check autoResize option and VirtualBox will automatically set the display size as you resize or maximize the window.\n\nA: Devices > Install Guest Additions, let it run then log out.\nWhen you've been returned to the login screen you'll see it's the full size of your monitor. Log in and you're good to go.\n\nA: What driver is specified in ur xorg.conf? AFAIK, after installing guest additions the 'vboxvideo' should be used:\nSection \"Device\"\n    Identifier   \"Configured Video Device\"\n    Driver     \"vboxvideo\"\nEndSection\n\n\nA: After installing guest additions:\nGo to settings > Display \nIncrease video memory and enable 2D and 3D video acceleration.\n\nA: It is probable that your brand new install of a linux distro on your Virtualbox is still fresh and that much more needs to be done to set up your environment, not the least of which is to enable the X Window system if all that you are seeing are display settings for 4:3 aspect ratio and entering 'startx' at the command prompt does nothing.\n..at your terminal prompt, enter the following:\nsudo apt-get install dkms\nsudo apt-get update\nsudo apt-get install linux-headers-`uname -r`\nsudo apt-get install --reinstall xorg\nstartx\n\nIf you had set your virtual machine to fullscreen mode prior to entering 'startx', then the screen will automatically adjust to 16:9 aspect ratio, with tool and task bars in their proper places.\n\nA: I did this setting and all was OK:\n\n\nA: I had the same problem and then found out that if you launch the virtual machine > click \"view\" on the toolbar > click \"auto-resize guest display, then your virtual machine will have the same screen resolution as your own screen.\n\nA: You need to install the VBox guest utilities to add support for the virtualised graphics hardware.\nsudo apt-get install virtualbox-guest-utils virtualbox-guest-x11 virtualbox-guest-dkms\n\nPreviously you might have needed the \"ose\" versions:\nsudo apt-get install virtualbox-ose-guest-utils virtualbox-ose-guest-x11 virtualbox-ose-guest-dkms\n\n\nA: This may have already been resolved but I had this issue and fixed it very simply, I just updated VirtualBox to the latest version then re-installed the guest additions. \n\nA: VirtualBox 4.3.12 was preventing the above solutions from working on my Windows system.\n4.3.18 was released somewhen around 2014/10/10 (2014 Oct 10), all of the above works since installing that.\nThe \"VBoxManage setextradata global GUI/MaxGuestResolution any\" command appeared to work previously, that is to say it didn't throw any errors.\nInstalling guest additions had previously complained that the header files were not installed, however they absolutely WERE (& have been left untouched) as evidenced by the fact that installing guest additions under 4.3.18 upgrade does not throw the error when building the shared folders module.\n\nA: Here is a 2016 updated answer that worked for me.\nTo start, I'm on Mac 10.11 (El Capitan), and my VirtualBox is 5.0.26. I'm running Ubuntu 14.04 LTS in this example (I need to upgrade my Ubuntu eventually).\n\n\n*\n\n*Start your VM\n\n*Select \"Devices -> Insert Guest Additions CD image...\" (no, you don't actually need a CD, this is virtual)\n\n*This will open a window asking for your root password\n\n*A terminal window will open. If it asks about re-installing over a previous version of guest additions, type \"yes\" and hit return\n\n*Restart your VM\n\n*Once the VM is up and running again, go to \"View -> Virtual Screen 1 -> [whichever resolution you want]\".\n\n\nMy options were all the way from 640x480 to 1920x1200. Once I selected a new resolution, I did not have to restart the VM again, it automatically scaled.\n\nA: If none of the answers helps you fixing the issue (like it was situation with me), then verify on your Host OS that in \"Screen resolution\" window (Control Panel > Appearance and Personalization > Display) whether the displays are aligned and not like in picture from the following link:\nPreview of settings on Host OS that caused me issue with maximum resolution on Guest OS\nIf someone is confused because of the value of shown Display field, the reason is that I don't use Windows 7 as my Host OS, so I've used it on VirtualBox in order to simulate problem.\nIf you would like to use different resolution on each monitor and/or you are not sure how to align displays in previous window, clicking on \"Detect\" button should do things properly for you.\nYou probably wouldn't suspect that that causes problem because, if you use Windows 7 (or any newer versions of Windows) as Host OS, it will successfully render image on your monitors, even when the set positioning is distorted as shown.\nI've been struggling with this problem on many tested Guest OSs like Ubuntu, Windows XP and Windows 7 (so the issue in my case wasn't related to Ubuntu nor Linux at all) and after properly configuring that setting, I was able to choose larger desired resolution in my Guest OS (of course, you should previously install VBox Guest Additions as it is stated in several answers).\n\nA: My problem/solution was actually strange, I had a another laptop/monitor with a lower resolution set up in Windows as a main display. Therefore no matter what, even if I had a max option in View/Virtual Screen 1920x1200, this time it was not checked. I am using i3 GUI , gnome behaved even more strangely. Once I configured my 4k 3840x2160 in Windows as a main monitor, VirtualBox adapted correctly. \n(Maybe I combine it with a lot of solution here at stackexchange and other websites.) ,but setting up the 4k display as a main display in Windows was basically a solution for me.\nNote: Also previously I configured linux ubuntu resolution via command line by a process of these commands - How to set a custom resolution?\notherwise a one-liner resolution appliance command line and few easy steps\neval $(cvt 2220 1250  60 |sed 's/Modeline/xrandr --newmode /g'|sed -n '1!p')\nwhat this one liner does:\n(1st/3 part generates dimensions, 2nd/3part uses output and replaces with xrand to create logical display, 3/3part it has on the first line comment so it starts at 2nd line)\nas a proper result resolution might be afterwards reevaluated and adjusted, therefore find out the created resolution by xrand command appended in the end of output, \n1) assign the resolution to a specific display - \nxrandr --addmode VGA-1 \"2224x1250_60.00\"\n2) output the desired resolution on the display\nxrandr --output VGA-1 --mode \"2224x1250_60.00\"\n\nA: Because my reputation is not enough to add a comment for @maco's answer, I'm writing this as an answer.\nI'm using Ubuntu 16.04 and I installed the VBox utilities as @maco's answer however when I locked the screen I could not used my keyboard and mouse anymore. There is a bug report about that. I found the solution here and totally it took me 2-3 hrs. \nI hope it helps for whom having the same issue :)\n\nA: The scale factor in the virtual machine settings did the trick for me. I set it from 100% to 200%.\n\nNote: I have a Huawei Matebook X Pro.\n\nA: It took me quite a while to finally make it work (I think it was installation of VirtualBox Guest Additions and VirtualBox Extension Pack which did the trick for me eventually) but before I managed to make it work I was just using Remote Desktop to connect from my Linux host to Windows guest. I used Remmina (RDP protocol) and by just selecting Use client resolution option I got my host system native resolution straight away.\nI still like this approach actually: you can start VM in a headless mode and it just feels... lighter, but the drawback of this method is that the video throughput via RDP connection, at least in my case, is substantially lower than when using native VirtualBox window, though it is noticeable only when you try to do GPU-intensive things like playing HD videos, I don't see much of a difference otherwise. I did try to improve Host <-> Guest network connection performance using dedicated Host Only network with virtio network adapter but I guess the bottleneck is probably somewhere in FreeRDP implementation.\nStill Remote Desktop could be a quick solution for someone who is struggling to make it work and needs native host resolution in Guest VM.\n\nA: Running Mint 20.1. Got a VM to resize with bigger resolution. Here’s how:\n1. Ran VirtualBox. Got the Oracle VM VirtualBox Manger. \n2. Made a new VM “Virtual Mate”. Type: Linux. Version: Ubuntu 64 bit. \n3. Gave it 8192 GB memory. \n4. Virtual hard disk. VDI. Dynamically allocated. 20 GB. \n5. Settings – Display – gave it 128 MB. 3D acceleration for the VMSVGA. \n6. Settings - Storage – attached the Mate iso.\n7. Ran it. Immediate installation, erase and install. Done. \n8. Restarted. To “Remove the installation media”, just hit Enter. Logged in.\n9. Closed the VM window, and saved this machine state. \n10. Ran it. Devices – inserted guest additions CD – did the autorun. \n11. It wanted the restart; did that. Logged in. \n12. Resized with resolution change worked. \n\nIt won’t resize until you’ve logged in.\n\nA: The issue for me was virtual box additions were not installed.  I thought I install them however it actually failed because GCC and Perl and Make were not installed.  Before you install the virtual box additions run the following (in ubuntu)\nsudo apt-get install gcc make perl\nThen install guest additions like described in previous posts\n\nA: All I had to do was go into the guest OS's display settings and change it to maximum resolution. (Make sure in the VirtualBox settings that you don't have it set to a maximum width of about 600px).\n\n\nA: Setup: I am using an Ubuntu VM in VirtualBox on a Windows host\nVirtualBox has a feature called \"Scaled Mode\" (View > Scaled Mode) - When enabled, it allows you to simply drag and resize the window. However, this does not change the resolution of the window (you will find the icons and text to be a little blurry). To actually change the resolution you must install the GuestAdditions software.\nYou can read about GuestAdditions in the official VirtualBox docs: https://www.virtualbox.org/manual/ch04.html\nFrom the above documentation:\nThe Oracle VM VirtualBox Guest Additions for Linux are provided on the same virtual CD-ROM file as the Guest Additions for Windows. See Section 4.2.1.1, “Installing the Windows Guest Additions”.\nTIP: I followed all of the steps above, but found that the window was not resizing when I dragged it. I then clicked on the CDROM icon (GuestAdditions was still mounted) and just right clicked the autorun.sh file and selected \"Run as program\" - This seemed to do the trick in terms of actually installing it. Rebooted again and this time I was able to drag the window and found that it would actually change the resolution.\n", "Q: What spreadsheet programs are available? I want to know if there are any other spreadsheet programs besides OpenOffice.org Calc.\n\nA: Try http://projects.gnome.org/gnumeric/\n\nA: For text-only use in a terminal, there's sc (man page).\nIf the first link is not working, you can try the Ubuntu Packages site.\nAlso for text terminals, Lotus 1-2-3 for Unix has been ported to Linux.\n\nA: Check these out... here is list of all spreadsheet software for linux... :)\nhttp://www.linuxlinks.com/Software/Spreadsheets/\nelse u can try koffice, staroffice and gnome-office.\nI hope this helped.. :)\n\nA: For large spreadsheets, Gnumeric is the way to go!  Libreoffice is too slow for plotting graphs with large multi-column datasets, but gnumeric handles them far better with high responsiveness.\n\nA: Gnumeric\nGnumeric is part of 'GNOME Office' suite, which means it stylistically fits into Ubuntu, but can just as easily be used on its own.\nTo install Gnumeric in all currently supported versions of Ubuntu open the terminal and type:\nsudo apt install gnumeric\n\n\n\nA: There's a Chinese clone of MS Office, called WPS Office. It offers both ribbon and toolbar-based user interfaces, which you can switch on the fly. It is not open source, though.\n\nFor more details and installation instructions, see this OMG! Ubuntu! article.\n", "Q: How do I put Ubuntu on a NON-flash external USB hard-drive? Amazingly enough, circumstances have left me without a single USB flash drive, or a working CD-R drive. Also, because I moved about six months ago, I got rid of all my extra Ubuntu CDs that I used to get by mail. (cleanup win, hindsight fail)\nAnd yet, I need to get a live Ubuntu going to boot up a wonky desktop computer.\nI tried using unetbootin to put a live CD install onto a portable USB hard-drive, but it won't boot from it (NTLDR missing error).\nIs this because the disk is NTFS (which it is)? or for some other reason? Is there a difference between booting from a portable USB thumbdrive and a portable USB hard drive, other than potential performance?\n\nA: There's no difference between a flash drive and a usb hard drive. Both can be used as a boot medium, and in the same way.\nIf you want to put the live system (installer) on the disk, the partition needs to be FAT32. NTFS cannot be read at this stage. So the partition you boot from (where the live cd contents are put) needs to be formatted as FAT32.\nYou can also install Ubuntu to the external hard drive, of course, just as you could with a flash drive. That's a different operation from using the drive as a live cd boot medium.\n\nA: If you're talking about what I think you're talking about, running Ubuntu/Linux off of a external hard drive connected via USB then it's actually quite simple to do. Here are the steps, or rather, the steps I took. \nPlease Note: The following steps were tested using Ubuntu Version 9.10, but has not been tested with the later versions. Use at your own risk & discretion.\nWhat You Will Need\n\n\n*\n\n*A Computer with Internet access.\n\n*A LiveCD or LiveUSB with Ubuntu.\n\n*An external Hard Drive with USB capability.\n\n\nWhat To Do\n\n\n*\n\n*Open up your computer and remove the Hard Drive.\n\n*Plug in your external USB Hard Drive via the USB cable.\n\n*Stick in your LiveUSB or LiveCD and then boot up your PC.\n\n*Open up the boot menu, and choose to boot from the LiveCD/LiveUSB.\n\n*During the installation process you should your external hard drive listed, install Ubuntu to that.\n\n*Finish the installation process, turn off your PC, and put your other hard drive back into your computer.\n\n*Reboot your computer, go to the boot menu and select your external hard drive and attempt to boot from it. If it does congratulations, you now have an external hard drive with a full fledged Operating System on it.\n\n*Enjoy your external hard drive running Ubuntu/Linux!\nPlease do let me know if this helps you! If not let me know about that too. :)\n\n\nA: You can use $ sudo aptitude install ubiquity\nInstall that on your machine (that's the-ubuntu-installer), then go through installation instruction make sure you set up partions on the usb-drive & at the last step select advanced and make sure the bootloader is installed on to usb-drive as well.\nThis will give you portable-ish Ubuntu on usb-drive. (ext4 etc.)\nCurrently the only tool that works for installing Ubuntu on NTFS is wubi but that's to be installed along with Windows.\n\nA: If the computer is attached to the Internet, then use Wubi.\nhttp://wubi-installer.org/\n\nA: Maybe somebody from the Israeli locoteam is nearby and can help you out with a live-CD or USB or such?  Try the chat, forums, etc.\n", "Q: How do I changed the language used by the Gnome spell checker? I'm a Canadian, but often get American spelling suggestions from the spell checker in Ubuntu.  How do I switch to a Canadian dictionary?\n\nA: The spell checker is based on your Locale - if you switch it to en_CA (or en_GB if en_CA is not available) you should be more Canadian like spellings.\nGet a list of installed languages with the following:\nlocale -a\nYou can view your current selected locale with:\nlocale\nOnce you've selected the one which best suites you - you can update it here:\nsudoedit /etc/default/locale\nBe aware if an entry from locale -a ends with .utf8 it needs to be entered as .UTF-8 in the default locale.\nAfter you make those changes you'll need to reboot for them to apply.\n\nA: Marco Ceppi is right about this being based on the locale, but the easiest way to change this is through System -> Administration -> Language Support in the graphical user-interface (it will also make sure all the right packages are installed, etc.).\n", "Q: Can you get a Source RPM to build as a DEB? The manufacturer of our printer (Canon) does provide Linux printer drivers for most its printers. However, they are all 32bit and only the newer printer drivers are available in both DEB and RPM. The older are only provided as RPM files.\nI use 'alien' to convert the RPM files to the DEB format so I can install the drivers. However, lately it seemed Canon has screwed the new drivers for the Canon PIXMA iP3300 up a bit in the build process of the RPMs.\nAlthough all printer-specific RPM packages are available, the cnijfilter-common package, containing the vital CUPS filter, is distributed as a Source RPM (*.src.rpm). Very useful to build your own drivers if you want to ('rpmbuild --rebuild cnijfilter-common-2.70-2.src.rpm'), but not so much when you run a Debian-based operating system.\nMy question is: is it easy to convert a Source RPM to something you can easily build as a DEB, or will I have to manually convert the Source RPM to something usable?\n\nA: Fundamentally no - because of the way RPM and DEB packages go about managing packages building a DEB straight from src.rpm isn't likely.\nYou can still build RPMs with Ubuntu using the rpm pacakge (sudo apt-get install rpm) Once that's intalled you can run rpmbuild on the rpm src as you would on a RH system. Then continue with your conversion to DEB via Alien or however else you would.\n\nA: Yes, you can. Sort of. Unpack the rpm with rpm2cpio and cpio, unpack the sources, create a debian/ dir inside and use the contents of the .spec file to create debian/control, debian/changelog, debian/rules, debian/copyright. Some packaging knowledge is definitely required for that last step though.\nThen again, if all you want is the sourcefilter, maco's advise will get you there much quicker :)\n\nA: No you can't. But if you have the source RPM, that means you have the source code, so you can package it as a DEB anyway, which is good news!\nThe simplest way to make a quick DEB package is to use checkinstall.\n\nA: Extract the contents of the RPM with cpio then you can grab the CUPS filter out of it and paste it wherever in the filesystem it goes.\n\nA: This answer on Launchpad indicates that someone got your printer working by selecting the Canon bjc-7000 driver.\n\nA: You can (most of the time) u need to use a program called Alien (sudo apt-get install alien) \nThis program converts RPM to DEB.\nHowtoForge Tutorial\n", "Q: Why does my workspace intermittantly hold at partial dimness? The workspace between the top and bottom Gnome panels occasionally dims about 25% and holds there for an unpredictable period of time.  Sometimes it never recovers to full brightness.  The cursor moves but buttons are non-responsive.  Most often this happens in Firefox but is not restricted to this one program.  The top and bottom Gnome panels remain fully functional.  \nThe processor stays at an approximately steady 40% \"User\" use.  The memory hovers at about a 40% mixture of \"User\", \"Buffers\" and \"Cached\" use.  Network and disk activities flatline.\nSometimes the workspace un-dims itself and returns full control.  When it does not the only things that work are pressing the automatically presented force quit button, typing \"xkill\" from a terminal or choosing to restart.  Usually the application that dimmed can be restarted without restarting the operating system.  I've experienced this in both Karmic and Lucid.  \nWhat am I missing?\n\nA: Compiz dimms windows that are frozen or don't answer to window management events. The dimming is normal and just a way to inform you that this app is not listening to inputs.\n\nA: Are you using Compiz when this happens? The way to check this is to go to system / preferences / appearance / visual effects, and see if it's set to anything but \"None\". If it is set to something other than \"None\", does the problem go away when you use \"None\" instead?\nHope this helps, regardless.\n", "Q: Copying data from server to PC on the same network I am recently setup a server to host my \"data\" movies and music and such. \nI was trying to copy the data back to my home computer using this command\nscp files/on/server user@homecomputer:/home\n\nthe response was unknown user@computer, then i replaced with the ip address still same difference. How can i fix this?\nPlease and thank you.\n\nA: It's very unlikely that you have write access to /home (you'll need to specify something like /home/user instead).\n\nA: Could you post the exact error message? Perhaps the user-name on your home computer is another one?\n\nA: Do you have the openssh-server package installed on the second computer? If not, install it; that should make it possible to connect with ssh/scp/sftp to the second computer?\n\nA: I can't give a definitive answer without knowing your network organization (which you should have described more precisely), but here's some information that may help you.\nYou mention a “PC on the same network”, but also a “home computer”. Is your “home computer” really on the same network as the server? If not, maybe the home computer is behind a firewall and you can't initiate a connection from the server to the home computer, only from the home computer to the server. In particular, if the home computer is behind a NAT and the server is outside the NATed area, the server simply can't see the home computer.\nOther answers have noted potential problems with your command. If you had cut and pasted the exact error message (which you should have done), it would have been possible to tell whether these potential problems were actual problems.\nIn any case, reverse ssh connections (i.e. ssh from home to server then back from server to home) are hard to manage (potential firewall trouble, potential authentication trouble, need to run an ssh server locally). So instead of initiating the copy from the server, initiate it from the home computer.\nFurthermore, scp is not a particularly good tool to copy a large number of files. If you want to make a one-time copy, or if you're always going to copy files from the server to the home computer and never the other way round, use rsync. If you want to keep the two computers synchronized, use unison — it's easier to use and less error-prone than rsync for two-way synchronization.\n", "Q: Top software to install on Live USB drive, for Windows recovery purposes I installed the latest Lubuntu image on a pen drive(2GB), using Ubuntu's Startup Disk Creator.\nMy goal for this pen drive is for maintenance of old Windows XP machines.\nWhat software should I install for this?  Whether it is already in the Ubuntu repository or not.\nNote:\n\n\n*\n\n*This is a Community Wiki page.  \n\n*I already know some of what to install and that that there are preconfigured distributions for this purpose.  I just want a public list for reference (In case I missed something).\n\n*Please mention ONE software per question posted, for better voting.\n\n\nA: testdisk/photorec. Great tools for recovering deleted files and repairing disk partitions.\n\nA: gparted, if it's not the part of default install.\n\nA: dd, for low level transfer between drives. It should already be there, so you won't need to install it, but it's good to be aware of.\nHere's an example from Wikipedia to copy a partition from one drive to another:\ndd if=/dev/sda2 of=/dev/sdb2 bs=4096 conv=noerror\n\nThere's a lot more you can do with this, like rewriting arbitrary blocks, creating drive images, converting files, etc.\n\nA: The second one is foremost a great tool to recover lost files.\n\nA: Disk Usage Analyzer.  Handy for verifying where big files are located.  It's found in the repository, if it's not part of the default install.\n\nA: You might also want to look in to creating a windows live cd, or windows-pe as it is also come times called.\nhttp://www.nu2.nu/pebuilder/\n\nA: I do it too.\nThe first thing that I install to it is Avast!. It's a great way of checking windows machines for viruses.\n\nA: Ophcrack, for Windows password recovery (aka password cracking).\n\nA: clamav, for antivirus protection.  It can be found in Ubuntu's repository.\n\nA: AVG, for antivirus protection.\nYou can download the .deb file from their web site.\n", "Q: What is the default character encoding? I don't myself know how deep this question actually goes (for example, for all I know there could be several, depending on my task).\nParticularly, I am interested in what kinds of strings are used to name files and folders on the system.\nI am also interested in how strings are represented by default for a bash or python script.\n\nA: The default character encoding is UTF-8 (Unicode), though almost all (quite possibly all on a default install) file names are regular ASCII characters, common to most encodings.\nI don't know what you mean by \"how many strings are represented by a bash or python script\". You can use Unicode characters in bash scripts on Ubuntu, but usually with a bash script, you call other programs, and whether those other programs will handle them is another matter. It's certainly possible to do so with Python too, though you'll want to familiarize yourself with the packages and settings related thereto.\n\nA: *\n\n*Encoding of filenames on the filesystem is utf-8.\n\n*Bash thinks in bytes, not with strings-with-encoding-knowledge. So no default encoding. gnome-terminal's default encoding is utf-8\n\n*Python's default encoding is ascii\n\n", "Q: Modifying /etc/hosts does not have an effect I'm attempting to block myself from time-wasting websites but changes I make to /etc/hosts. For example:\n127.0.0.1   localhost\n127.0.1.1   ross-laptop\n\n127.0.0.1   bing.com\n\n# The following lines are desirable for IPv6 capable hosts\n::1     localhost ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\nff02::3 ip6-allhosts\n\nI can access bing.com in a freshly opened Chrome or Firefox - why is this not working?\n\nA: Have you tried putting the 127.0.0.1 entries on the same line?\n120.0.0.1 abc bing.com foo\nThat should work.\n\nA: You'll find the browsers and the system will cache things for you. In order to get this to apply right off the bat you should make sure to clear caches and restart your browser. In order to test this out, try performing a dns check from a terminal such as\nping bing.com\n\nYou should get it replying back from 127.0.0.1. If this works then your hosts file change is good, but it's just cached in your browser. \n\nA: Open Terminal (ALT+F2).\nType sudo -i in the input field. Check the Run in terminal option. Finally click Run button.\nType your password if necessary and press enter. Then enter the following commands.\ngedit /etc/hosts\n\nYou will get Gedit Text Editor window.\nFor Example, if we need to block Facebook add the following lines just after 127.0.0.1 localhost.\n0.0.0.1 facebook.com    \n0.0.0.1 www.facebook.com\n\nBy doing this, it will block the site in all browsers including Google Chrome, Chromium, Mozilla.\nThat's it. When you now open www.facebook.com or facebook.com, you cannot access it. To enable back Facebook, remove the lines we added from the file /etc/hosts.\nSource - Subin's Blog\n\nA: Besides CragM's solution, remember you can use all 127.x.x.x address for this purpose, don't repeat the same address.\n127.0.0.1   localhost\n127.0.0.2   ross-laptop\n127.0.0.3   bing.com\n127.0.0.4   foo.com\n127.0.0.5   bar.com\n......\n\n\nA: Modifying /etc/hosts looks like a global hack. I'd suggest setting up a local http proxy instead (squid, privoxy etc) and point your browser to use it. This way you would get a more flexible way of managing blacklists at proxy level.\n", "Q: How do I remove the Ubuntu boot option created by Wubi? My friend installed Ubuntu on a separate partition on a PC with Windows 7 using Wubi. But by mistake he reformatted the drive containing Ubuntu. He is still getting Ubuntu option in the boot menu. How can it be completely removed?\n\nA: You will need to uninstall Ubuntu from Windows 7 - you can do this in the Add/Remove software section of the control panel or by running Wubi installer again (It should inform you that you need to uninstall first).\n\nA: You can also use EasyBCD to remove the boot option, but you should try uninstalling first.\nhttp://neosmart.net/dl.php?id=1\n\nA: Try this tutorial: Easily Set Default OS in a Windows 7 Dual-boot Setup\nIn the last step change the dropdown to Windows 7 (there should also be a Ubuntu/Wubi option). You can also change the \"Time to display list of operating systems\" to '0', or something very short.\n\nAlternatively you can try the Ubuntu Wiki instructions for manual removal of Wubi.\n\nA: If you have reformatted the drive containing Ubuntu and you still have Ubuntu entry in your Windows boot manager, you can remove that obsolete entry by following this simple procedure:\n\n\n*\n\n*Open open cmd as administrator. Type cmd in the start menu of Windows, right click and select Run as administrator.\n\n*Then use this command to see the entries in the boot manager\nbcdedit\n\nThis will give you an output like below. (My output is missing Ubuntu, but you will have one)\nC:\\Windows\\system32>bcdedit\n\nWindows Boot Manager\n--------------------\nidentifier              {bootmgr}\ndevice                  partition=G:\ndescription             Windows Boot Manager\nlocale                  en-US\ninherit                 {globalsettings}\ndefault                 {current}\nresumeobject            {bbc2fcc5-e344-11e1-9ade-bd05d50dfb31}\ndisplayorder            {current}\ntoolsdisplayorder       {memdiag}\ntimeout                 30\n\nWindows Boot Loader\n-------------------\nidentifier              {current}\ndevice                  partition=C:\npath                    \\Windows\\system32\\winload.exe\ndescription             Windows 7\nlocale                  en-US\ninherit                 {bootloadersettings}\nrecoverysequence        {bbc2fcc7-e344-11e1-9ade-bd05d50dfb31}\nrecoveryenabled         Yes\nosdevice                partition=C:\nsystemroot              \\Windows\nresumeobject            {bbc2fcc5-e344-11e1-9ade-bd05d50dfb31}\nnx                      OptIn\n\nThough I'm missing an entry with description ubuntu. Note or copy the value of identifier in that entry. It will be a number like this {bbc2fcc7-e344-11e1-9ade-bd05d50dfb31}\n\n*After you copied the identifier of Your Ubuntu entry, use this command to clear that\nbcdedit /delete {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx} /cleanup\n\nOf course replacing the value of {xxxx...} there. \nNow reboot to see that your Obsolete Ubuntu entry is deleted. (Actually you won't see this if you do not have more than one Windows, since Windows will be booted automatically without showing the OS choice menu)\n\nA: I don't think its Ubuntu problem.\n(assuming that you are using windows)\nYou have to edit your boot.ini file \n\nRun->msconfig->BOOT.INI->check all boot drives\n\nIf it does not find any OS mentioned in boot.ini file, it shows you an error message saying that your path is invalid and asks if you want to remove it. Just conform it and you are done.\nWorks in windows XP. I hope its same in windows 7 too.\n\nA: The question is if it is Grub or the Windows boot menu that your friend sees?\nGrub in the MBR requires rewriting the MBR which isn't easy from inside modern versions of Windows.\nTHe Windows boot menu can be fixed in the System control panel.\n\nA: If Wubi does not appear in Add / Remove programs, you should be able to download it again, run it, and it will jump straight into the uninstall process.\nIf that does not work, the following manual steps will get rid of it, save removing registry keys:\n\n\n*\n\n*Remove the Wubi directory, if present.\n\n*Remove any wubildr files in your C: drive.\n\n*Use bcdedit /delete to remove the Wubi entry from the Windows bootloader.\n\n\nA: Remove Ubuntu or XP from the Windows 7 Boot Menu\nIf you’ve ever used a dual-boot system and then removed one of the operating systems, it can still show up in Windows 7’s boot menu. We’ll show you how to get rid of old entries and speed up the boot process.\nhttp://www.howtogeek.com/howto/17903/remove-ubuntu-or-xp-from-the-windows-7-boot-menu/\n\nA: This works: Run a cmd as administrator. \nbcdedit\n\nwill give you the following output:\nWindows Boot Manager\n--------------------\nidentifier              {bootmgr}\ndevice                  partition=G:\ndescription             Windows Boot Manager\nlocale                  en-US\ninherit                 {globalsettings}\ndefault                 {current}\nresumeobject            {bbc2fcc5-e344-11e1-9ade-bd05d50dfb31}\ndisplayorder            {current}\ntoolsdisplayorder       {memdiag}\ntimeout                 30\n\nWindows Boot Loader\n-------------------\nidentifier              {current}\ndevice                  partition=C:\npath                    \\Windows\\system32\\winload.exe\ndescription             Windows 7\nlocale                  en-US\ninherit                 {bootloadersettings}\nrecoverysequence        {bbc2fcc7-e344-11e1-9ade-bd05d50dfb31}\nrecoveryenabled         Yes\nosdevice                partition=C:\nsystemroot              \\Windows\nresumeobject            {bbc2fcc5-e344-11e1-9ade-bd05d50dfb31}\nnx                      OptIn\n\nThough I'm missing an entry with description ubuntu. Note or copy the value of identifier in that entry. It will be a GUID like this: {bbc2fcc7-e344-11e1-9ade-bd05d50dfb31}\nAfter you copied the identifier of Your Ubuntu entry, use this command to clear that:\nbcdedit /delete {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx} /cleanup\n\n", "Q: Set Boinc as a screensaver I have a BOINC Manager installed contributing to World Community Grid.  \nIs there a way to set this to run as a screensaver visually in Ubuntu?\n\nA: Unfortunately this is not an option for the Ubuntu/Linux version. \n(NB: It has been suggested that running the screensaver uses CPU power that could be used to contribute even more data!)\n\nA: It looks like it is built in Boinc, but hasn't sucessfully been ported to the various distro's screensavers\nhttp://www.spy-hill.com/~myers/help/boinc/unix-screensaver.html\nhttp://boinc.berkeley.edu/dev/forum_thread.php?id=7139\nWould be nice if this was enabled\n\nA: I assume you do know that, but just to be sure: You are not trying to make BOINC work during the times that you don't use the computer yourself, or are you? Because you can configure that behaviour in the BOINC manager, even without it being the active screen saver.\n", "Q: Is there an up-to-date VLC PPA for 10.04? I'm looking for updated VLC builds for Lucid.\nI was using c-korn, but it's gone.\n\nA: The PPA installable by sudo add-apt-repository ppa:ferramroberto/vlc has been set up due to the demise of c-korn and contains 1.1.4 currently. (Maverick contains 1.1.3 at present.)\nFor your information and future reference I found this by going to the Launchpad vlc Ubuntu package page and clicking on \"Other versions of 'vlc' in untrusted archives\".\nReference: How to use PPAs\n\nA: This link will give you a PPA that has VLC 1.1.4. I installed from here and have had no problems.\nhttp://www.webupd8.org/2010/08/install-vlc-114-in-ubuntu-via-new-ppa.html\n", "Q: Server Converting Files for iPhone I would like to convert videos I download to the iPhone format on my server and be able to access and play them on my iPhone. \nI looked into Handbrake, but I wasn't sure if it would work on the server. \nAny suggestions you may have to set this up would be much appreciated. \nPlease and thank you.\n\nA: There is a command line version of handbrake that should work on your server. Below are instructions for installing from a PPA and converting the files using the command line.\n$ sudo apt-get install python-software-properties\n$ sudo add-apt-repository ppa:stebbins/handbrake-snapshots\n$ sudo apt-get update\n$ sudo apt-get install handbrake-cli\n$ HandBrakeCLI --preset \"iPhone & iPod Touch\" -i input.xxx -o output.mp4\n\n\nA: I don't have an iPhone anymore, but back when I had one, I made a little script to do just that.\n Here it is :\n#!/bin/bash\nif \"$1\" == \"\"\nthen\n    echo This script this script takes a video file as parameter, and tries\n    echo to convert it to MPEG-4 in an iPhone-compatible format.\n    echo A file list, or wildcards caracters can be used as parameters.\n    exit 0\nfi\n\nfor file in $@\ndo\n    ffmpeg -i $file -f mp4 -vcodec mpeg4 -maxrate 1000 -b 700 -bufsize 4096 -g 300 -acodec aac -ab 192 -s 480x320 $file.mp4\ndone\n\nYou can copy it and paste it as a new text file. Then make this file executable (chmod +x [filename]) and run it from the commandline, with the source video file as parameter (multiple files can be put as parameters, for multiple conversions, and wildcards are accepted).\nThe resulting file will be named the same as the source, with the \".mp4\" extension added to it.\nLooking at it, it seems you only need ffmpeg to use it. Maybe some codecs also, but I guess you have them already if you already played with video conversion :)\nIf you don't already have it installed, try :\nsudo apt-get install ffmpeg\n\nHope this helps.\n", "Q: Laptop fan not turning on when needed It looks like my fan in my laptop is not turning on when appropriate. I already removed granola (maybe it disables it far too long?)\nWhen I put the computer in sleep mode and resume it immediately turns on the fan (the cpu was waaaaay overheated). So the question is: why does it not turn on when needed.\nThere are multiple issues here: Why, and how to diagnose this issue? How can I control when the fan should turn on, how do I test that the code is turning on my fan, how do I turn on the fan manually through a command if all hell breaks lose?\n\nA: It appears it may have been granola. After removing it it seems the fan does turn on, as I hear it working at low speeds at the moment.\nWill experiment more, though I can still use help finding out how to diagnose the problem anyways just incase it was not granola and instead a random issue.\n", "Q: Sound in Wine only partially working I don't use Wine much, but saw this about running the BBC Doctor Who games\nOMG! Ubuntu\nI only get sound for the first few seconds and then nothing. In the Wine Config it auto-selected ALSA. The Test Sound button there makes a few odd noises and locks up that screen.\nAny fixes for this?\n\nA: You can try to disable Hardware Acceleration in Wine Configuration.\nOpen Wine configuration, go to the Audio tab, on the bottom make sure that Hardware Acceleration is set to Emulation.\n\nA: You may need to close other audio-using programs before running Wine, particularly Firefox if you have any flash videos (youtube, etc) open.  PulseAudio's Alsa compatibility layer does not like Wine very much, and sometimes the audio system breaks entirely when Wine uses it.\nI also find it helpful to set my IM status to away so that the IM client doesn't create sounds while I'm running one of these applications.\nYou may also need to run killall -9 pulseaudio in a terminal once the audio has gotten off and Wine has exited.  This will forcekill PulseAudio, which will then restart itself in a couple seconds.\nThe long term solution to this problem is to improve either Wine or PulseAudio.  The PulseAudio developers have been pretty clear that they don't want to support Wine's \"abuses\" of the ALSA API, so the only solution for Wine is to stop using ALSA and instead have a PulseAudio output path for audio.  You can read more about this here: http://yokozar.org/blog/archives/178 -- as far as time goes, Wine's OpenAL layer (and therefore PulseAudio support) is being actively worked on by two developers but I don't know when it will enter the code.\n\nA: For who is still interested in these issues:\nThe developers of Wine have made it pretty clear that they are not going to support PulseAudio.\nWine in the Ubuntu repositories is delivered with a PulseAudio driver that is not support by Wine.\nSo it's a dead end here. Neither Alsa nor PulseAudio is working optimal and sound playback in Wine is still terrible.\nBesides there's currently a backlog of problems with Ubuntu 12.04 (see the forum on the Wine website).\nAs far as I can tell it's quite safe to assume that Wine for Ubuntu is dead now.\n", "Q: How to convert mkv to dvd or avi I have some mkv files, and while Totem plays them perfectly, when i use Devede to burn them to dvd it all gets messed up: the video is ok, but the audio is out of sync.\nI did see that Devede does write my dixv avi files correctly to disk.\nSo i am thinking what the best way could be to convert my mkv for playback on dvd?\nI was thinking maybe converting them to avi first? But i did not find a good way for that to happen.\nWhat do you suggest?\n\nA: Yes, I agree Handbrake is nice.\nHowever, if you want a simple and easy app, you can use MobileMediaConvertor. It almost converts anything. Website\nArista Transcoder from software center is good too.\n\nA: There is an option called convert/save in vlc \"media\" option. I think the shortcut key is ctrl + R. It surely converts to mp4. Will this help:\nhttp://www.linuxquestions.org/questions/linuxanswers-discussion-27/discussion-avi-to-dvd-360138/\n\nA: I think vlc supports converting to avi and i think it plays mkv as well.\nIn media menu there is an option for convert/save\nVLC Transcode\n\nA: For the old \"command line magic\" I like using mencoder, which is part of MPlayer. Then I use dvdwizard to make the DVD.\nThe basic command line to convert anything into a PAL 16:9 dvd vob file\nmencoder <name of input file> -vf scale=720:576 -ofps 25 -ovc lavc -vf-pre scale=720:-3,expand=720:::::16/9:16,harddup -lavcopts vcodec=mpeg2video:keyint=15:vrc_buf_size=1835:vrc_maxrate=9800:vbitrate=2500:aspect=16/9:vstrict=0 -of mpeg -mpegopts format=dvd -srate = 48000 -o <name of output file>\n\nOf course I never write all that, I have a script that wraps all that and gives me a few \"simple\" options for things like 2 pass encoding, frame rate, audio codec, removing video noise, and sharpening the picture...\nThe script is avi2vob.\nTo convert a bunch of videos to 24fps 16:9 video, with 2 pass encoding and video sharpening\navi2vob -f -2 -s1 -d video1.avi video2.mkv video3.flc\n\n\nA: Handbrake is the best video converter tool I know.\nFrom the details page:\n\nSupported Sources:\nAny DVD-like source: VIDEO_TS folder, DVD image or real DVD (unencrypted--protection >methods including CSS are not supported internally and must be handled externally with >third-party software and libraries), and some .VOB and .TS files\nMost any multimedia file it can get libavformat to read and libavcodec to decode.\nOutputs:\nFile format: MP4 and MKV\nVideo: MPEG-4, H.264, or Theora\nAudio: AAC, CoreAudio AAC (OS X Only), MP3, or Vorbis. AC-3 pass-through, DTS pass-thorugh >(MKV only)\n\nYou can install it via Software Center or sudo apt-get install handbrake-gtk if you use their PPA:\ndeb http://ppa.launchpad.net/stebbins/handbrake-snapshots/ubuntu UBUNTU_VERSION main\ndeb-src http://ppa.launchpad.net/stebbins/handbrake-snapshots/ubuntu UBUNTU_VERSION main \n\nA: Even I convert .mkv videos to .avi to play them on my gothic dvd player. The best program to do this seamlessly (according to me, atleast) is Avidemux. :))\n\nA: I had a similar problem once; If I remember correctly, I fixed it by checking \"file already has AC3 audio\" or similar in the DeVeDe menu (advanced options). That is, if your MKV has AC3 audio in it ;) \n\nA: Personally recommend three solutions to convert MKV to AVI.\nHandBrake: it's free and has the feature of converting MKV to AVI. \nCons:\n\n\n*\n\n*HandBrake is too professional to handle for most people;\n\n*It doesn't support MOV as output format.\n\n\na video tool which can convert MKV to AVI. It's not expensive and runs well on Mavericks and Windows 8. Most of all, the converted video will keep the same quality with the original video. \n", "Q: Windows executables are started with archive manager I have Wine installed and several Windows applications installed there run fine, if I start them using the right mouse menu \"Open with Wine program loader\". But if I try starting an .exe file by just double clicking instead, the archive manager tries to open the executable.\nHow do I fix that?\nAnd something like a bonus question as a former Windows user: Can this be done easily for a single file I currently see in the file manager (similar to the \"Open with...\" context menu in Windows) and for many file types together (like in Windows, using the menu \"Folder settings\" in the Explorer)?\n\nA: From 17.04, the wine packages have become wine-stable and wine-development. These are coinstallable, so the wine.desktop file is not installed in /usr/share/applications by either of these packages to avoid conflicts. Hence, Wine does not have an entry in the Open With menu. From /usr/share/doc/wine-stable/README.Debian.gz:\n\nTo enable system-wide support for .exe files execute the following\n  command (replace /usr/share/doc/wine with\n  /usr/share/doc/wine-development if you use wine-development):\n$ sudo cp /usr/share/doc/wine/examples/wine.desktop /usr/share/applications/\n\nTo support this only for your current user execute:\n$ cp /usr/share/doc/wine/examples/wine.desktop ~/.local/share/applications/\n\nTo remove these native file type associations again execute the\n  following commands:\n$ sudo rm -f /usr/share/applications/wine.desktop\n$ sudo update-desktop-database\n$ rm -f ~/.local/share/applications/wine.desktop\n$ rm -f ~/.local/share/applications/wine-extension-*\n$ update-desktop-database ~/.local/share/applications/\n\n\nThis is slightly mistaken, it's /usr/share/doc/wine-stable, not /usr/share/doc/wine.\nsudo cp /usr/share/doc/wine-stable/examples/wine.desktop /usr/share/applications/\n\nAnd Wine should start showing up in the Open With lists for selection.\n\nA: The reason why this occurs is in this bug report, which I provided a patch for about 2 years ago: https://bugs.launchpad.net/ubuntu/+source/file-roller/+bug/351429\nRegardless, the workaround I generally use is to just right click the application and select open with Wine.\n\nA: Right-click, select Properties, open the \"Open With\" tab, and make Wine the default application for EXE files.\n\nA: That does not always work. Some settings for file type handling can be found in \n.local/share/applications/mimeapps.list\n\nIn that file, I found the follow line: \napplication/x-ms-dos-executable=file-roller.desktop;wine.desktop;\n\nand changed it to \napplication/x-ms-dos-executable=wine.desktop;\n\nAfter saving the file the result is active immediately. \n", "Q: Setup suspend-on-lid-close/Fn+F4 outside of KDE/Gnome? On current Ubuntu (10.04) suspend-on-lid/FN + F4 only works if some powermanagement-applet of KDE/gnome is running.\nBut what about suspend-to-lid if you are working on the console or using a non-bloated window-manager?\nWhat is the current mechanism to configure suspend-on-lid system wide?\nWhat of hald/udev/acpid/foo-kit/random-thing is the right place to hook this feature in?\nWhat is the up-to-date command to suspend from the command line/script?\necho -n mem > /sys/power/state\npm-suspend\npmi\n\nor something else?\nBtw, if it matters, I want to configure it on some Thinkpads.\n\nA: Ryan Thompson described how the system works in an answer to my question earlier.\nSo, you just need to change /etc/acpi/lid.sh to do whatever you want instead of blanking the screen.\n\nA: Ok, finally I have configured the suspend-on-lid-close action everywhere via acpid.\nFor minimal changes to existing system wide config files (i.e. less manual overhead for the next upgrade), I did it like this:\ncd /etc/acpi\nmkdir local\necho -e \"#!/bin/sh\\npm-suspend\" > local/lid.sh.post\nchmod u+x local/lid.sh.post\n\nIt is then automatically called by /etc/acpi/lid.sh (if no gnome/kde power-manager running). I used pm-suspend, because it is already used in /etc/acpi/sleep.sh.\nNow I have to figure out how to enable Fn+F4 system wide ...\nEdit: Well, it seems that Fn+F4 -> sleep (everywhere) should work out-of-the-box under Ubuntu, because the thinkpad-acpi module is loaded by default (when booting a thinkpad) and the default \n/sys/devices/platform/thinkpad_acpi/hotkey_mask\n\nmasks the Fn+F4 event, s.t. an ACPI event should be generated. A default acpid should then call /etc/acpi/sleep.sh (which calls pm-suspend).\nFirst tests of Fn+F4 did not work (i.e. did not trigger acpi events) - but some strange side-effect (e.g. \ncat /sys/devices/platform/thinkpad_acpi/hotkey_mask\n\n, toggling the thinklight via\necho on > /proc/acpi/ibm/light\n\nor something like this) made it work now ...\n\nA: I run the AwesomeWM on Lucid from my X201 Thinkpad. I just run the gnome-power-manager applet in my WM instance by having it setup in my autostart script for Awesome. It does eat up a little ram (30M res) but works well with the normal hibernate/suspend modes. The nice thing is it also gives me my battery indicator and such as well. \nI know it's not just the script commands, but my understanding is that there more than just a script to run. It starts up and monitors some events, dbus, etc. \n", "Q: How to run cron job when network is up? I have some anacron jobs which run daily. The scripts update local bzr and git repositories. Naturally these scripts need working network connections. I'm on a laptop and often wired and wireless internet do not come up fast enough. This causes my cron job to time out when pulling the repositories =(\nSo:\nHow to make sure the internet is up before running specific cron jobs? Or how to fail a job if there is no network, such that it is retried by anacron later again?\n\nA: I made a cron that did a ping test on a DNS server to ensure networking. Something like this:\nping 8.8.8.8 -c 1 -i .2 -t 60 > /dev/null 2>&1\nONLINE=$?\n\nif [ ONLINE -eq 0 ]; then\n    #We're offline\nelse\n    #We're online\nfi\n\nRecently I've used something like this:\n#!/bin/bash\n\nfunction check_online\n{\n    netcat -z -w 5 8.8.8.8 53 && echo 1 || echo 0\n}\n\n# Initial check to see if we are online\nIS_ONLINE=check_online\n# How many times we should check if we're online - this prevents infinite looping\nMAX_CHECKS=5\n# Initial starting value for checks\nCHECKS=0\n\n# Loop while we're not online.\nwhile [ $IS_ONLINE -eq 0 ]; do\n    # We're offline. Sleep for a bit, then check again\n\n    sleep 10;\n    IS_ONLINE=check_online\n\n    CHECKS=$[ $CHECKS + 1 ]\n    if [ $CHECKS -gt $MAX_CHECKS ]; then\n        break\n    fi\ndone\n\nif [ $IS_ONLINE -eq 0 ]; then\n    # We never were able to get online. Kill script.\n    exit 1\nfi\n\n# Now we enter our normal code here. The above was just for online checking\n\nThis isn't the MOST elegant - I'm not sure how else to check via a simple command or file on the system, but this has worked for me when needed.\n\nA: I think you can use Upstart to help you there. Mind you, I haven't tested that code below  works but something very similar should.\n# /etc/init/update-repositories.conf - Update local repos\n#\n\ndescription     \"Update local repos\"\n\n# this will run the script section every time network is up\nstart on (net-device-up IFACE!=lo)\n\ntask\n\nscript\n    svn up && git fetch\n#   do some other useful stuff\nend script\n\nThat pretty much it. You might want to add some code to check that it does not run very often. You might also want to add start update-repositories to your crontab, it'll make sure your update will happen if you are on the net constantly for a prolonged period of time.\n\nA: You can talk to NetworkManager to see whether you are connected or not:\n$state = $(dbus-send --system --print-reply \\\n    --dest=org.freedesktop.NetworkManager \\\n    /org/freedesktop/NetworkManager \\\n    org.freedesktop.NetworkManager.state 2>/dev/null \\\n| awk '/uint32/{print $2}')\nif [ $state = 3 ]; then\n    echo \"Connected!\"\nelse\n    echo \"Not connected!\"\nfi\n\n\nA: Just to wrap up a couple of the options here into a single script:\n#! /bin/bash\n# This script checks that the interface is up, and that an internet connection is available\n# It is based on code from http://askubuntu.com/questions/3299/how-to-run-cron-job-when-network-is-up\n#\n# Then it sleeps for a random number of seconds between 30 and 600.\n# This is based on code from http://tldp.org/LDP/abs/html/randomvar.html\n#\n# Collated by @JonTheNiceGuy on 2015-10-15\n\nfunction check_ipaddr\n{\n  # Here we look for an IP(v4|v6) address when doing ip addr\n  # Note we're filtering out 127.0.0.1 and ::1/128 which are the \"localhost\" ip addresses\n  # I'm also removing fe80: which is the \"link local\" prefix\n\n  ip addr | \\\n  grep -v 127.0.0.1 | \\\n  grep -v '::1/128' | \\\n  grep -v 'inet6 fe80:' | \\\n  grep -E \"inet [[:digit:]]+\\.[[:digit:]]+\\.[[:digit:]]+\\.[[:digit:]]+|inet6\" | \\\n  wc -l\n}\n\nfunction check_google\n{\n  netcat -z -w 5 8.8.8.8 53 && echo 1 || echo 0\n}\n\nuntil [ `check_ipaddr` -gt 1 ]; do\n  sleep 2\ndone\n\nuntil [ `check_google` -eq 1 ]; do\n  sleep 2\ndone\n\nsleep $((RANDOM%570+30))\n\nI plan to maintain this script at https://gist.github.com/JonTheNiceGuy/5cf4a23c8f2f755a9ca4\n\nA: To expand on nixternal, the fping binary is excellent for that.  You can cook it up in one-liners as in\n$ fping -q yoo.mama && echo yes\n$ fping -q www.google.com && echo yes\nyes\n$ \n\nAs you see, yoo.mama does not like me but Google does.  In crontab, you'd do something like\n5 5 * * *  root   fping -q google.com && /some/script/I/want --to --run\n\n\nA: What I do is create a shell script that does what you need, ie. checks for network connection and then fires off the updates. Then call the script from cron.\n\nA: until ifconfig eth | grep -qE 'addr:([[:digit:]]+\\.?)+'; do\n   sleep 2\ndone\n\n\nA: I've defined a bash alias to answer this question:  \nalias netstate='ip link show | egrep -q '\\''UP,LOWER_UP.* state UP'\\'' && echo UP || echo DOWN'\n\nYou could use it, or process the output of ip link show yourself.\nTo handle \"net goes down/net comes up\" see my net-o-matic script at net-o-matic\n\nA: I found ping solutions gave me network errors which spammed my logs unless I laboriously directed errors to /dev/null\nNetwork Manager can be used:\nif nmcli general | grep \"^connected\" >/dev/null\nthen\n   echo \"nmcli connected\"\nfi\n\n", "Q: Which IDE should I use for Vala? I think the title explains it already...\n\nA: There is new project called Valama, you can check:\nhttps://github.com/Valama/valama\nIt uses gtksourceview, so editor experience is similar to gedit, but it's still in early development phase.\nUPDATE: It is getting better every day, there is active development on going.\n\nA: There are two plugins for Gedit that provide Vala support.  Valencia and VTG both add autocompletion, symbol browsing and basic project management through makefiles\nValencia is the easier of the two to setup because VTG depends on gtksourcecompletion, but VTG has made several recent releases.\nhttp://yorba.org/valencia/\nhttp://code.google.com/p/vtg/\n\nA: Anjuta supports vala since ver. 2.31.3 and there's a nice plugin for gedit. http://redmine.yorba.org/projects/valencia/wiki\n\nA: I can't recommend an IDE specifically, but I can recommend Geany as a great text editor.\n\nA: Val(a)IDE seems to be the only IDE with Vala support, so if you want an IDE that is properly the way to go. Personally I use Vim for my coding needs, I think it makes good sense to use a powerfull editor instead of a single purpose IDE.\nInstead of knowing 20% of the commands (keyboard shortcuts) in five IDE's I can get to know 99% of the commands in one editor.\n\nA: Surprised no one has mentioned Gnome Builder.\nUpon opening the IDE, you can see the kinds of projects it supports (which also includes ones written in Vala):\n\n\nA: As @aperson said, Geany is a very good text editor - It is lightweight with lots of features. It also supports vala (you need to install valac first though for full vala features). A lot of its features are IDE like eg. you can build/run with 1 click.\n\nTo install, run sudo apt-get install valac geany or search for 'valac' and 'geany' in Ubuntu Software Centre.\n\nA: You could use Val(a)IDE, you can find the source/binary at launchpad\nThe link to Val(a)IDE given by SourceLab seems to be broken. \nReferences:\n\n\n*\n\n*Vala (programming)\n\n*Official Vala Documentation\n", "Q: What's the Bitwise Tunnnlier equivalent for Ubuntu? I used Tunnlier in windows and it was perfect. After migrating to Linux I, surprisingly,  can't find anything that does the following:\n\n\n*\n\n*manage my SSH connections\n\n*use Terminal and SFTP browser\n\n*save my connections as profiles to load later\n\n\nI found PuTTY and gSTM, but they really don't do what I mentioned above.\nWhat do you recommend?\n\n\nmoved here from superuser\n\nA: Afaik there is no program that can do this for you for Linux. You can do this on Linux, but there isn't a pretty GUI for doing it.\nPassword-less login can be done by using ssh-keys (You might still want a password for you ssh-key, but you only have to enter it once!) Have a look here.\nBy configuring the ssh client on a host basis you can have individual settings for different hosts. Have a look at the file in /home/user/.ssh/config (it might not be there, but just create it.) Mine looks something like this:\nCheckHostIP yes\nConnectionAttempts 3\nServerAliveInterval 10\n\nHost router\n        HostName 10.0.0.1\n        User root\n\nHost test\n        HostName test.example.org\n        User test32\n        ForwardX11Trusted yes\n        ForwardX11 yes\n        Compression yes\n        CompressionLevel 6\n\nHost lucretia\n        User lasse\n        HostName 8.8.8.8\n\nHost home\n        User coax\n        HostName 8.8.8.9\n\nHost lovelace\n        User lasse\n        HostName 8.8.8.10\n\nHost mailserver\n        User lasse\n        HostName 8.8.8.11\n        ForwardX11 yes\n        ForwardX11Trusted yes\n\nEverything before the first Host deceleration is common to all connections. For more options look at the man-page for ssh_config.\nWhen you have set up the config file then you can use ssh home instead of ssh 8.8.8.9 -l coax These options also applies to nautilus for ssh:// browsing. \nYou then have two options for quick launching a ssh terminal session, one is to create a gnome-terminal session for each and create launchers that runs gnome-terminal --profile='profile-name'.\nThe other option is to install sshmenu, imho not a super app, but it does a good job of supplying quick access to remote terminals.\n\nA: Nautilus (Applications -> Accessories -> File Browser) provides support to connect to ssh servers and browse files over sftp and to save the connections as profiles (Saved data includes server name, share name, username, password).\nTo open sftp, go to Places -> Connect to Server... and choose \"SSH\" or FTP as the type and enter the rest of the details - see this guide for detailed steps. By giving a bookmark name, this connection profile will be stored for easy access in the left-hand side pane (View -> Side Pane).\nOnly thing I don't know a way to do within nautilus is \"Open a terminal\", for which u can use Putty, etc. Agree it is not yet as integrated as the option you mention, but it may be possible to find a way to \"Open a Terminal\" while on an sftp location to open an ssh connection in a terminal and jump to the directory.\n\nA: Try HotSSH (found in the repositories). It manages the ssh connections very nicely, including connection sharing. I don't think it handles SFTP, though as someone else has noted, you can do that through Nautilus.\n\nA: Pretty simple: PAC Manager. Download from http://sourceforge.net/projects/pacmanager/ or, even better, add the GetDeb page to repositories and then update and apt-get install pac\n\nA: You manage the different connections in different programs that use them.\nHere's what you do:\n\n\n*\n\n*add the SSH as a mount using nautilus (Locations -> Connect to server) and mark 'add bookmark'\n\n\n*\n\n*put your public key in the .ssh directory on the server. It's not smart to keep reconnecting with your real password all the time. You should be using a password less setup, if you want to prevent any man in the middle attacks.\n\n*gnome-do automatically indexes known ssh hosts, so you can connect quickly using that. There is also an ssh applet, and you can offcourse just add a few aliases to your bash.\n", "Q: Why are notifications so low? Whenever notifications show up, they are much lower than I would expect. In most screenshots I see, they are directly under the top panel, but for me, there's a large gap:\n\nIs there any way to change the position?\n\nA: You can customize their placement and appearance: http://www.omgubuntu.co.uk/2010/06/customize-the-ubuntu-notification-bubbles/\n\nA: This was a change in Ubuntu 9.10 (Karmic).\nThe space above is left intentionally blank because it is for \"confirmation\" bubbles: for instance volume, screen brightness, etc... (often controlled on keyboards buttons on using laptop buttons).\n\"Notification\" bubbles appear in this space slightly further down.\nNot everyone likes this, but this is the way the powers that be want it...\n\n\nA: I might be wrong but I think that's the default from Maverick onwards - they were much higher in Lucid, but it were moved lower so that the first notification didn't obscure the typical place where window controls land.\nNo, as far as I know, there's no way to modify the placement or positioning of the notifications.\n[Edit : Of course, Maverick isn't out yet - are you running one of the Betas or is this Lucid you're talking about? My Lucid build has notifications higher than your screenshot, just under the top panel.]\n", "Q: Cannot get 'default' Apache VirtualHost to work I've changed this from the original VHost but it should still work in my mind:\nListen 80\nNameVirtualHost *:80\n<VirtualHost *:80>\n ServerName localhost\n ServerAdmin ross@localhost\n\n DocumentRoot /var/www\n <Directory /var/www/>\n  Options Indexes FollowSymLinks MultiViews\n  AllowOverride None\n  Order allow,deny\n  allow from all\n </Directory>\n\n ErrorLog /var/log/apache2/error.log\n\n # Possible values include: debug, info, notice, warn, error, crit,\n # alert, emerg.\n LogLevel warn\n\n CustomLog /var/log/apache2/access.log combined\n</VirtualHost>\n\nThe only difference between this and other working VHosts is that /var/www requires higher privileges to access it - I get a \"Could not connect\" error which I assume is a 500 error (Chrome hides the status codes and I can't remember). What can I do to make this work?\n\nA: Try performing a manual connection using telnet from a terminal window:\ntelnet localhost 80\n\nIf you receive a connection refused message, the daemon is not running or starting up propertly. From there it would be a good idea to inspect your Apache error log (/var/log/apache2/error.log) to find out why.\n\nA: Could not connect is not a 500 error. It means apache is either not running or not reachable.\n\nA: This is a guess, but I think Apache runs as the www-user login, or similar.  Does it have rights to the root of /var/www?  I think by default, Apache points to symlinks off an /etc/apache2/default directory or something like that.  Working from memory here, and no expert though.  Sorry.\n", "Q: Why might I want to use a clipboard manager? I recently saw this poll asking for the \"Best Linux Clipboard Manager\". What actually is a clipboard manager and in what situations would a clipboard manager be useful?\nAre there some differences in the default clipboard behaviour of Ubuntu to other (Windows or Mac) systems?\n\nA: I tried a clipboard manager once called Parcellite and now I cannot live without it.\nA clipboard manager is one of those things that you never need until you try it and then without realising it, you can't work properly without it.\nNot only is it really useful when editing code and config files ( because you can store more than one thing on the clipboard at a time meaning you can cut a bit here, copy a bit here, paste the second bit, then paste the first bit and so on ) but it is also really useful as a quick temporary storage. \nI use it to store URLs, phone numbers, configuration snippets etc, whilst I am working on something.\nIf it is something I want to keep for a while I will paste it into Tomboy but a lot of information you need is only required for perhaps fifteen minutes, and it is as easy as hitting Ctrl+C and it is there, using notes or files is over kill for this ort of information. Normally you would have to rely on your memory, or I believe you can use sliced up tress to store information too.\nIt is a brain extension that means I don't have to remember things. \n\nA: There is a small but extremely annoying bug that more or less requires a clipboard manager to fix.\nTake an application, like Firefox; copy some text or a picture then close Firefox, then try and dump it into a document. It won't work, because of a holdover from the UNIX days. The clipboard does not actually 'copy' it simply notes where to take the media from, and if you close the program it notes it down.\n\nA: With a clipboard manager, you can get things like history and formatting stripping.  Some clipboard managers even allow you to paste things across the network.\nAs for the differences between the cliboard behavior between windows and ubuntu, the only thing that comes to mind is that you have two clipboards:  your normal copy+paste and highlight+middle-click.\n\nA: Persistence is probably the best selling point for me. Most CBMs allow you to store the same items across sessions (even platforms), mobile (if your profile is) and especially in the case of X-based applications, selected items* are remembered after the source application closes (something that is not natively true).\nMultiple clipboards is something I don't use too much but it' very handy if you find yourself juggling several bits and bobs at once. You can do all your copying at once and then get on with whatever you're doing. Less back-and-forth.\nThese are both negatives if you regularly copy sensitive data as it could be a security issue.\n* Just an explanation: you do know you effectively get two clipboards out the box? There's the traditional Control+C, Control+V clipboard but there's also something called \"primary selection\". Select some text and then middle click where you want it pasted. I find this very useful for quick, precise, multiple pasting.\n\nA: If you have multiple files you want to rename still paste able after you copy something else. \nI use xclip for copying commands i enter alot. \nThe main use is being able to copy more than once and being able to paste whichever you want.\n\nA: For some repetive tasks, that call for the same 3 or 4 copies, it makes your life way easier to keep them in a manager.  Even as opposed to keeping a gedit doc open with them in it as well.\nI've found that it saves a good amount of time and is worth wild.\n\nA: Maybe you don't want to use one.  The nice bit about running one, however, is it doesn't get in your way if you never use it.  This is what I do, and I rarely find it useful; but it won't (or shouldn't, at least) noticeably affect performance on 10 year old or newer desktop systems.\nPerhaps I almost always don't need it because I do the majority of my text editing in [g]vim, which already has a similar feature through registers (:help registers if you're curious).  Registers provide vim with a built-in clipboard manager, which works only inside vim; so if you want the same ease within another text editor (though I doubt it would be quite as easy), you could find one useful.  Between vim and other programs, I just use the primary selection and regular clipboard, and that's been plenty.\nRemember that you already have two \"clipboards\" on *nix systems: the primary selection plus the clipboard (there's actually more, but they're very rarely used).  This is a feature of the X Window System.  Whenever you select something (i.e. highlight), you can enter it in another program with a middle-click.  Wikipedia's article isn't kidding that you'll predominately use the primary selection once you get used to it.\nHowever, programs usually limit use of the primary selection to text.  For example, open both nautilus and a text editor.  Select a few files, then try to middle-click in the text editor: it won't work.  (Nautilus doesn't acquire the primary selection so you'll get whatever was previously there, if anything.  It could have been designed to do this differently, but it wasn't—I don't know if this was deliberate or not.)  Copy those files to the clipboard (ctrl+c or edit > copy), then paste in your text editor to get the filenames.\n\nA: In addition to the reasons you might deliberately want to use multiple clipboards (personally, I don't), they can work around a problem where some applications fail to retain their content on the clipboard when you quit them.\nThis is most visible (highly annoying) on Firefox on GNOME (see bug 311340 for teeth-grindingly slow progress).\n\nA: Because you save a lots of time. Having the last 10 copied item ready to paste will you make a lot more productive.\n", "Q: Make a USB port pretend to be a USB drive I have a low-powered networked Ubuntu pc next to my tv. I also have a Humax PVR. The PVR has an option to record to a USB drive instead of its internal disk. \nI'd like recording to be accessible on the network so I was wondering if it's possible to get a USB male-to-male (A-to-A) lead, connect Ubuntu to PVR and have Ubuntu pretend to be a USB disk.\nI've see this the other way around. The Nokia N8** tablets were natively just seen as disks but with some hacking could be USB hosts.\nOne side-note: I have other USB devices, plugged into the Ubuntu machine, that need to to work as usual.\nEdit: I'm open to hardware solutions but I'd rather not have to buy a NAS that has USB and Ethernet to sit in the middle.  Is a USB File Transfer Cable (or similar) an option?\n\nA: I'm afraid that simply isn't possible. The N**0 devices had special circuitry in them that allowed them to do this (I had an adapter I could use to plug my flash drive into my N800 - it was awesome.), read up on USB On The Go if you're interested. Normal USB controllers, alas, cannot be set to do this. It is possible that could get a NAS with USB, which would perform as you like. It looks like certain plug computers can do it as well. But what you describe, with your hardware, is impossible (To the best of my knowledge). Sorry!\n\nA: USB A-A cables are against the standard and will connect the two power supplies together and probably fry one or both connected systems.\nRemember, in USB power is connected FIRST, then data.\n(That being said, I do have one in my possession; it's the cable to an old wifi dongle. It is not a USB transfer cable - those have a box in the middle that handles the wiring properly. It's a true, against the standard A-A cable.)\n", "Q: Is there any GUI tool for Upstart Is there currently any GUI based application to show currently running services, with buttons to start and stop services?\nIt doesn't necessarily need to be able to set boot up behaviour.\n\nA: Yes, jobs-admin is the new GUI which uses jobservice to configure Upstart scripts.  It's in Maverick's repos, but there's a PPA available at https://launchpad.net/~jpeddicord/+archive/jobtools for Lucid.\n\nA: I believe Boot-Up Manager is what you're looking for (package name is bum).\n\n", "Q: How to get Lilliput USB monitor working? Okay, I just got a Lilliput 7\" USB Monitor:\n\n(source: thinkgeek.com)\nUnfortunately, I am having some trouble getting it to work in Ubuntu.\nIt is a DisplayLink device, so it should work in Ubuntu.\nHere is the output of lsusb:\n\n...\nBus 002 Device 007: ID 17e9:02a9 Newnham Research\n...\n\nI modified my xorg.conf file to accommodate the device.\n\n# nvidia-settings: X configuration file generated by nvidia-settings\n# nvidia-settings:  version 1.0  (buildd@yellow)  Fri Apr  9 11:51:21 UTC 2010\n\n# nvidia-xconfig: X configuration file generated by nvidia-xconfig\n# nvidia-xconfig:  version 1.0  (buildmeister@builder58)  Fri Mar 12 02:12:40 PST 2010\n\nSection \"ServerLayout\"\n    Identifier     \"Layout0\"\n    Screen      0  \"DisplayLinkScreen\" 0 0\n    Screen      1  \"Screen0\" RightOf \"DisplayLinkScreen\"\n    InputDevice    \"Keyboard0\" \"CoreKeyboard\"\n    InputDevice    \"Mouse0\" \"CorePointer\"\n    Option         \"Xinerama\" \"0\"\nEndSection\n\nSection \"InputDevice\"\n\n    # generated from default\n    Identifier     \"Mouse0\"\n    Driver         \"mouse\"\n    Option         \"Protocol\" \"auto\"\n    Option         \"Device\" \"/dev/psaux\"\n    Option         \"Emulate3Buttons\" \"no\"\n    Option         \"ZAxisMapping\" \"4 5\"\nEndSection\n\nSection \"InputDevice\"\n\n    # generated from default\n    Identifier     \"Keyboard0\"\n    Driver         \"kbd\"\nEndSection\n\nSection \"Monitor\"\n    Identifier     \"Monitor0\"\n    VendorName     \"Unknown\"\n    ModelName      \"LPL\"\n    HorizSync       30.0 - 75.0\n    VertRefresh     60.0\n    Option         \"DPMS\"\nEndSection\n\nSection \"Monitor\"\n    Identifier     \"Monitor1\"\n    VendorName     \"Unknown\"\n    ModelName      \"BenQ T705\"\n    HorizSync       31.0 - 83.0\n    VertRefresh     56.0 - 76.0\nEndSection\n\nSection \"Device\"\n    Identifier     \"Device0\"\n    Driver         \"nvidia\"\n    VendorName     \"NVIDIA Corporation\"\n    BoardName      \"GeForce 8400M GS\"\nEndSection\n\nSection \"Device\"\n    Identifier     \"Device1\"\n    Driver         \"nvidia\"\n    VendorName     \"NVIDIA Corporation\"\n    BoardName      \"GeForce 8400M GS\"\n    BusID          \"PCI:1:0:0\"\n    Screen          1\nEndSection\n\nSection \"Screen\"\n    Identifier     \"Screen0\"\n    Device         \"Device0\"\n    Monitor        \"Monitor0\"\n    DefaultDepth    24\n    Option         \"TwinView\" \"0\"\n    Option         \"metamodes\" \"DFP: nvidia-auto-select +0+0\"\n    SubSection     \"Display\"\n        Depth       24\n    EndSubSection\nEndSection\n\nSection \"Screen\"\n    Identifier     \"Screen1\"\n    Device         \"Device1\"\n    Monitor        \"Monitor1\"\n    DefaultDepth    24\n    Option         \"TwinView\" \"0\"\n    Option         \"metamodes\" \"CRT: nvidia-auto-select +0+0\"\n    SubSection     \"Display\"\n        Depth       24\n    EndSubSection\nEndSection\n\n#################################################\n\nSection \"Files\"\nModulePath      \"/usr/lib/xorg/modules\"\nModulePath      \"/usr/local/lib/xorg/modules\"\nModulePath      \"/usr/local/lib/xorg/modules/drivers\"\nEndSection\n\n############### DisplayLink Stuff ###############\nSection \"Device\"\n    Identifier      \"DisplayLinkDevice\"\n    driver          \"displaylink\"\n    Option  \"fbdev\" \"/dev/fb1\"\nEndSection\n\nSection \"Monitor\"\n    Identifier      \"DisplayLinkMonitor\"\nEndSection\n\nSection \"Screen\"\n    Identifier      \"DisplayLinkScreen\"\n    Device          \"DisplayLinkDevice\"\n    Monitor         \"DisplayLinkMonitor\"\n    DefaultDepth    16\n    SubSection \"Display\"\n        Depth   16\n        Modes   \"800×480\"\n    EndSubSection\nEndSection\n\nAll I get is a green screen.\nAny tips or advice would be appreciated!\n\nUpdate: I discovered that X11 was having trouble finding the displaylink_drv.so module, so I fixed that. Then my XServer completely crashed. (Segmentation fault, I believe.)\nNow I'm really confused.\n\nA: It's actually working... and I all did was restore xorg.conf.backup. Weird. Oh well.\n\nA: There is a quite detailed blog post from July 2010 - it certainly seems more complicated than it should be, and not quite a perfect outcome either.\n\nA: Displaylink added Open Source on their support/feedback forum.\nDisplayLink drivers Open Source\nI hope this will open up some better solutions and support for these DisplayLink USB displays.\n", "Q: How to change icons in the side pane of the Nautilus file browser? Right-click in the main panel allows to change icons associated to files of directories, and this is cool for content organization and so on.\nUnfortunately, right click on small directories on the side pane does not allow to change its properties (such as icon).\nI try to change the original directory icon, expecting that its side pane version would change accordingly, but surprisingly, nothing appends...\nAny idea?\n\nA: You currently cannot change the icons used in the places and bookmarks menus in nautilus.\nThis is a bug. \nSee this bug report on launchpad\nand this bug report on GNOME bugzilla\n", "Q: Keyboard layout on Ubuntu won't go away! So, I installed Ubuntu (Using Gnome) with keyboard layout US International with Dead Keys enabled. Now I've set this to US International with Alt-Gr Dead Keys enabled. I added the latter and deleted the first. I then clicked \"Apply to entire system\" and closed the keyboard manager.\nNow whenever I reboot, the old keyboard lay-out is re-added to the list and set to the default keyboard layout. The keyboard with US International with Alt-Gr Dead Keys enabled is still in that list so it doesn't completely revert to the installation settings, making me conclude that it must have saved the settings.\nHow can I make this keyboard ghost go to the eternal /dev/null plane so that it will never rise from the grave again? (How to get rid of the thing...)\n\nA: Apparently setting the keyboard layout you wish to use when logging in solves this problem.\nWhen logging in, as you are about to enter your password in GDM, there is a discreet menu option on the toolbar at the bottom.\nChanging the setting here will cause Ubuntu to use the correct keyboard setting not just for that session but for subsequent log ins.\n", "Q: With a launcher for a terminal application, how can I keep the terminal open after the program is complete? I have a terminal command I run from an application launcher. This works great, however sometimes the command fails, so I'd like for the terminal to stay open so I can see the results. How can I do this?\n\nA: Your launcher is running a script right?\nAt the end of your script add\nread -p \"Press any key to exit > \" -n1 junk\necho \n\nThen your script will wait until you choose to end it.\n\nA: In your .desktop shortcut, use this\nExec=gnome-terminal -x bash -c \"YOUR_SCRIPT; exec $SHELL\"\n\nAfter your script is finished, the Bash process will replace itself with a new invocation of itself.\nIf you need to pass quoted arguments to your script, you have to escape the quotes:\nExec=gnome-terminal -x bash -c \"YOUR_SCRIPT \\\"arg with spaces\\\"; exec $SHELL\"\n\n\nA: A slightly different approach from the other answers: run your command and if that fails, then spawn a shell.  This way you don't have to hold the terminal open (which doesn't distinguish between command success or failure), and you might find that shell particularly useful in failure.  To close it, just use Ctrl-D (EOF), \"exit\", Alt-F4 (or whatever your window manager uses to close windows), etc.\nsuccess-or-shell\n#!/bin/sh\n[ $# -eq 0 ] && {\n  echo \"$(basename $0): no command\" >&2\n  exit 1\n}\n\"$@\" || {\n  echo \"failed: $?\"\n  exec $SHELL\n}\n\nPlace this file somewhere, such as ~/bin, then use \"success-or-shell your original command\" in your launcher.\n\nA: Assuming your command is called mycommand, I'd change my launcher to run this:\ngnome-terminal -e \"mycommand|less\"\n\nIf you want a more permanent, perhaps cleaner solution, open up gnome-terminal, go to Edit, Profile preferences and click the Title and Command tab. Change the \"When command exits\" option to \"Hold the terminal open\".\nWhen you execute commands, it should now leave the terminal open when something runs.\nEdit: If you don't really care about the terminal, you could just use xterm's hold flag:\nxterm -e \"mycommand\" hold\n\n\nA: This answer gives the best answer I've seen so far to doing what you want.  They recommend making a script with the commands to execute and use it with the --init-file parameter (bash specific, but you could probably do the same for csh/tcsh/zsh, etc):\n#!/bin/bash --init-file\ncommands to run\n\n... and execute it as:\nxterm -e /path/to/script\n# or\ngnome-terminal -e /path/to/script\n# or\nthe-terminal -e bash --init-file /path/to/script/with/no/shebang\n\n\nA: Use the watch command. \nFormat: watch -n60 myCommand, or watch -n60 \"my command string\"\n\n\n*\n\n*the -n specified the number of seconds to wait between calls to myCommand; ex: the above command will call myCommand every 60 seconds, forever. \n\n*If the command is multiple words, put it inside double quotes: \"my command string\". \n\n\nLet's say you want a Launcher which displays the disk usage, and stays open for the reader to see. I'd simply use this command inside the Launcher:\nwatch -n60 \"df -h\", which calls df -h now every 60 seconds.\nI like this over the accepted answer of gnome-terminal -e \"mycommand|less\" because I'm running Xubuntu, which uses a different terminal by default.\n\nA: Try right-clicking the launcher and entering properties.\nThere should be an option to keep the terminal window open\n\nIn the .desktop file, there should be the entry X-KeepTerminal=true\n\nA: This question has a good answer, that worked for me.\nLong story short: every terminal emulator has a different way to keep its window open when a command exits.\nIf you want to use a specific terminal app, then you can add the appropriate command-line option it provides, if present, like roxterm --hold. Or for just your own use, you can toggle an option in the settings window for that emulator (like \"keep window open after command exits\").\nIf you want to use the default terminal app, (like via x-terminal-emulator or exo-open) then you need to use a trick in the script itself: open another shell at the end of it, like ...; bash.\nThis also works well for applications that have a \"Custom Action\" feature, like Application Finder (xfce4-appfinder) and Thunar. For example:\nThunar\nName: Show Path in Terminal\nCommand: exo-open --launch TerminalEmulator bash -c \"echo '%f';bash\"\n\nApplication Finder\nPattern: $\nCommand: exo-open --launch TerminalEmulator bash -c \"%s;bash\"\n\nIn the above examples, exo-open --launch TerminalEmulator opens the default terminal emulator, and everything after that is read as a command to run. bash -c runs a new bash shell process with the specified command. \"...;bash\" is the command, that when finished, runs a new bash shell process which keeps the terminal window open.\nAnother idea is to add sleep 36500d to the end of a script, which gives you 100 years to review the output.\nYou can also have your script listen for a terminal close signal, and override (or \"trap\") it.\nDesktop Entry\nExec=exo-open --launch TerminalEmulator bash -c \"function handle_sigint() { echo 'SIGINT received... but I will not close by myself.'; }; trap 'handle_sigint' 0; while true; do echo 'Running script...'; sleep 1; done;\"\n\nThis all works for a script file. Unfortunately, I'm having trouble getting any of the above to work from a desktop entry file (.desktop).\n\nA: AFAIK, The terminal won't be held open unless you use the \"hold\" option for your respective terminal emulator.\nFor example, for the xfce4-terminal, in order to make a launcher (menu item) that executes some command in a terminal window that is to be held open even after the command finishes its execution, one must use the following command for the launcher/menu item:\nxfce4-terminal -H -e 'put command to execute here'\n\n(-H is the hold flag that is required to prevent the terminal window from closing after command execution.\n-e flag makes the terminal execute the command in the string following -e when the terminal starts up\n)\n", "Q: How enable/disable WiFi adapters individually under 10.04 I have a laptop with an internal wifi G adapter, and I have an external USB wifi adapter that is compatible with N. the internal wifi can be disabled using a little switch on the side of the laptop. However, when I disable it using the switch, it disables ALL Wifi adapters, internal or external.\nI want to use the external USB adapter, since it's faster. \nAlso, on my EeePC, I cannot seem to be able to disable the internal WiFi adapter. The blue light remains ON, which means I cannot use my EeePC in an airplane.\nHow can I fix those problems ?\nThanks :-)\n\nA: For your first problem you can disable it by blocking the driver from loading. Use lsmod to find the driver it uses and then add blacklist that-driver to /etc/modprobe.d/blacklist.conf (on a new line). Bit of a sledgehammer approach but it would disable it. \nI don't know if this would actually disable the hardware so it might still eat battery.\n", "Q: How to open a nautilus directory and select a file in it from the command line? I know how to open directory, but I do not know how to select a file from the command line.\nEdit:\nI do not know how it works, but when I move any file to a directory and then open the directory that this file is selected.\n\nA: I think it's actually easier than it seems. What I tried is just this:\nnautilus <path_to_file>\n\nAt first, the file doesn't look to be selected, but that's just because the nautilus window isn't active. If you click on it, you'll see that the file name is selected.\nSince I guess you want to have that extra visual feedback, I used xdotool to make a simple test to select /var/log/dpkg.log as follows:\nnautilus /var/log/dpkg.log && sleep 3 && xdotool search -name log windowactivate\n\nWhat you should see is that nautilus in opened with using /var/log/ directory and that after three seconds the window is activated (the window name is just log) and the file name is highlighted since it's selected.\nNote: in this example if sleep is set to a shorter time you might not get the expected result since you need the window to be properly displayed before trying to activate it.\n\nA: I don't think there's an option to do this.\nSee:\n\n\n*\n\n*man nautilus\n\n*nautilus --help\n\n*http://live.gnome.org/Nautilus\nYou can open a file as if you had double clicked it in nautilus using the xdg-open command:\nxdg-open file\n\nIf you really wanted to have this specific feature, it would require hacking on the Nautilus code.\n\nA: The gnome-open command will open a directory with the appropriate application, which in this case is Nautilus:\ngnome-open PATH\n\nThis will open the directory /tmp using the Nautilus file browser:\ngnome-open /tmp\n\nOR:\ncd /tmp\ngnome-open .\n\nI like the gnome-open command because you can use this exact same command to open a file with the appropriate application. No need to remember any funny flags. It just works.\ngnome-open file.pdf will open the PDF in a PDF browser.\ngnome-open file.zip will open a zip file using the Zip archive viewer.\n\nA: When you in an xterm, navigating directories on the command line, and then want to pop up a nautilus window for that directory, do this:\nnautilus --browser .\n\n", "Q: What is the difference between Hibernate and Suspend Logout, Restart and Shutdown are all self explanatory to me. \nWhat are the differences between Suspend and Hibernate on the shutdown menu?\n\nA: *\n\n*Logout:  Stops user applications specific to users.\n\n*Shutdown:  Completely power off your system viz. PC, laptop.\n\n*Restart:  Power off and then start again.\n\n*Suspend/sleep: Put your computer at very low power state, screen off but everything else is on but at very low power so that you can resume your work where you left off but if battery die you loose all your unsaved data.\n\n*Hibernate: suspend to disk; includes power-off, looks like shutdown. Basically, everything in the Ram is copied to swap memory and system shutdown completely. when you start your computer back everything copies back to Ram and you continue where you left off.\n\nA: Try this command: \npm-suspend-hybrid\n\nHybrid-suspend is the process where the system does everything it needs to hibernate, but suspends instead of shutting down. This means that your computer can wake up quicker than for normal hibernation if you do not run out of power, and you can resume even if you run out of power.\n\nA: The power-management scripts use these terms:\n\n\n*\n\n*suspend -- suspend to ram; some folks call this \"sleep\"\n\n*resume -- restart after suspend to ram; does not use grub\n\n*hibernate -- suspend to disk; includes power-off, looks like shutdown\n\n*thaw -- restart after suspend to disk; includes a trip through grub\n\n\nBonne chance.\n\nA: Suspend does not turn off your computer. It puts the computer and all peripherals on a low power consumption mode. If the battery runs out or the computer turns off for some reason, the current session and unsaved changes will be lost.\nHibernate saves the state of your computer to the hard disk and completely powers off. When resuming, the saved state is restored to RAM.\n", "Q: Setup Blue Eyeball Webcam for Ubuntu Lucid Lynx for Skype My Blue Eyeball Webcam works for the application cheese out-of-the-box in Ubuntu.  Now I would like to use it for Skype for which it does not work.  What can I do?\nUPDATE3:\nI had limited time to return the webcam, so I returned it and bought one that was on the list of webcams supported in Skype.\nUPDATE2:\nOn this site: \nhttps://wiki.ubuntu.com/SkypeWebCams\nthey give the following tips when webcams work in cheese but not skype. I don't understand some, do they look like they would help?\n~http://code.google.com/p/gstfakevideo/\nWorks right away in cheese. To get skype video, run \"LD_PRELOAD=/usr/lib32/libv4l/v4l1compat.so skype\" at the command line (NOTE the LIB32!!!)\nSkype 2.0.0.72: You should setup ov51x-jpeg  (version here: 1.5.8) and \"sudo modprobe ov51x-jpeg forceblock=1\" or edit /etc/modprobe.d/options and add there \"options ov51x-jpeg forceblock=1\". Loading ov51x-jpeg without forceblock-option results in a black video stream for skype, while it works fine using \"cheese\".\nworks with cheese ootb but not in Skype. works in Skype (2.1.0.47) when setting \"LD_PRELOAD=/usr/lib/libv4l/v4l1compat.so skype\"\nUPDATE:\nI have included output of diagnostic programs.\nv4l-info\n### v4l2 device info [/dev/video0] ###\ngeneral info\n    VIDIOC_QUERYCAP\n    driver                  : \"uvcvideo\"\n    card                    : \"Blue Eyeball 2.0\"\n    bus_info                : \"usb-0000:00:1d.7-3\"\n    version                 : 0.1.0\n    capabilities            : 0x4000001 [VIDEO_CAPTURE,STREAMING]\n\nstandards\n\ninputs\n    VIDIOC_ENUMINPUT(0)\n    index                   : 0\n    name                    : \"Camera 1\"\n    type                    : CAMERA\n    audioset                : 0\n    tuner                   : 0\n    std                     : 0x0 []\n    status                  : 0x0 []\n\nvideo capture\n    VIDIOC_ENUM_FMT(0,VIDEO_CAPTURE)\n    index                   : 0\n    type                    : VIDEO_CAPTURE\n    flags                   : 0\n    description             : \"YUV 4:2:2 (YUYV)\"\n    pixelformat             : 0x56595559 [YUYV]\n    VIDIOC_ENUM_FMT(1,VIDEO_CAPTURE)\n    index                   : 1\n    type                    : VIDEO_CAPTURE\n    flags                   : 1\n    description             : \"MJPEG\"\n    pixelformat             : 0x47504a4d [MJPG]\n    VIDIOC_G_FMT(VIDEO_CAPTURE)\n    type                    : VIDEO_CAPTURE\n    fmt.pix.width           : 640\n    fmt.pix.height          : 480\n    fmt.pix.pixelformat     : 0x56595559 [YUYV]\n    fmt.pix.field           : NONE\n    fmt.pix.bytesperline    : 1280\n    fmt.pix.sizeimage       : 614400\n    fmt.pix.colorspace      : unknown\n    fmt.pix.priv            : 0\n\ncontrols\n    VIDIOC_QUERYCTRL(BASE+0)\n    id                      : 9963776\n    type                    : INTEGER\n    name                    : \"Brightness\"\n    minimum                 : -10\n    maximum                 : 10\n    step                    : 1\n    default_value           : 4\n    flags                   : 0\n    VIDIOC_QUERYCTRL(BASE+1)\n    id                      : 9963777\n    type                    : INTEGER\n    name                    : \"Contrast\"\n    minimum                 : 0\n    maximum                 : 20\n    step                    : 1\n    default_value           : 12\n    flags                   : 0\n    VIDIOC_QUERYCTRL(BASE+2)\n    id                      : 9963778\n    type                    : INTEGER\n    name                    : \"Saturation\"\n    minimum                 : 0\n    maximum                 : 10\n    step                    : 1\n    default_value           : 7\n    flags                   : 0\n    VIDIOC_QUERYCTRL(BASE+3)\n    id                      : 9963779\n    type                    : INTEGER\n    name                    : \"Hue\"\n    minimum                 : -5\n    maximum                 : 5\n    step                    : 1\n    default_value           : 2\n    flags                   : 0\n\n### video4linux device info [/dev/video0] ###\ngeneral info\n    VIDIOCGCAP\n    name                    : \"Blue Eyeball 2.0\"\n    type                    : 0x1 [CAPTURE]\n    channels                : 1\n    audios                  : 0\n    maxwidth                : 1600\n    maxheight               : 1200\n    minwidth                : 48\n    minheight               : 32\n\nchannels\n    VIDIOCGCHAN(0)\n    channel                 : 0\n    name                    : \"Camera 1\"\n    tuners                  : 0\n    flags                   : 0x0 []\n    type                    : CAMERA\n    norm                    : 0\n\ntuner\n\naudio\n\npicture\n    VIDIOCGPICT\n    brightness              : 45875\n    hue                     : 45875\n    colour                  : 45875\n    contrast                : 39321\n    whiteness               : 38010\n    depth                   : 16\n    palette                 : YUYV\n\nbuffer\n\nwindow\n    VIDIOCGWIN\n    x                       : 0\n    y                       : 0\n    width                   : 640\n    height                  : 480\n    chromakey               : 0\n    flags                   : 0\n\ncamorama -D\nVIDIOCGCAP\ndevice name = Blue Eyeball 2.0\ndevice type = 1\ncan use mmap()\n# of channels = 1\n# of audio devices = 0\nmax width = 1600\nmax height = 1200\nmin width = 48\nmin height = 32\n\nVIDIOCGWIN\nx = 0\ny = 0\nwidth = 800\nheight = 600\nchromakey = 0\nflags = 0\n\nVIDIOCGWIN\nx = 0\ny = 0\nwidth = 800\nheight = 600\nchromakey = 0\nflags = 0\n\nVIDIOCGPICT:\nbright = 45875\nhue = 45875\ncolour = 45875\ncontrast = 39321\nwhiteness = 38010\ncolour depth = 16\nYUYV\n\n\nA: See which v4l (video 4 linux) profile your webcam supports; there are two versions; v4l and v4l2.\nSkype may only use one profile and the driver only provides the other.\n", "Q: How to change time-zone settings from the command line I have a virtual machine that is set to PST that a couple of colleagues have in different time-zones.\nIf I wanted to change the time-zone to EST and GMT, what do I need to do?\n\nA: Edit the timezone file at the /etc folder as:\nEtc/GMT\n\nYou can use the next format:\nRegion \"/\" City \n\nExample of /etc/timezone:\nEurope/Athens\n\nor\nEurope/Paris\nEurope/London\n\nYou may experiment with the: dpkg-reconfigure tzdata\nand check cat the timezone file.\nYou must reboot or start again a service (not the ntp service). I do not know which one.\nIf somebody knows please share with us. \n(Tested on Ubuntu 15.10 the change is taken into account instantly)\n\nA: To run one program with a different time zone setting, set the TZ environment variable, e.g. run TZ=Pacific/Kiritimati date to see what time it is on Christmas Island, or export TZ=Pacific/Kiritimati to have the setting last for a shell session.\n\nA: cp -p /usr/share/zoneinfo/US/Pacific /etc/localtime\n\nI recommend AGAINST linking like mentioned by others.  If some script accidentally over writes your /etc/localtime file, then it overwrites your Pacific timezone file... and it's a bit of a pain to replace it.\nJust copy the Pacific file over the localtime file with the command above.\n\nA: As root you have to execute:\ndpkg-reconfigure tzdata\n\nA menu based tool should be started that allows you to change the timezone.\n\nA: The following also work.  For GMT:\nln -sf /usr/share/zoneinfo/GMT /etc/localtime\n\nFor EST:\nln -sf /usr/share/zoneinfo/EST /etc/localtime\n\n\nA: Use timedatectl\nsudo timedatectl set-timezone <timeszone>\n\n\nExamples:\n\n*\n\n*Timezone as EST\n  sudo timedatectl set-timezone EST\n\n\n\n*Timezone as UTC\n  sudo timedatectl set-timezone UTC\n\n\n\n*Listing all valid Timezones\n  timedatectl list-timezones\n\n\nThis command is perfect for automation scripts since it doesn't require any user interaction while compared to the other given answer based on dpkg-reconfigure tzdata.\n\nA: The most ease way especially to a server is to list timezones:\ntimedatectl list-timezones\n\nAnd choose yours, for example:\ntimedatectl set-timezone Europe/Athens\n\nThats it! , :-)\n\nA: I use the following script to ask the user which timezone to set, and then confirm it has indeed been set:\n#!/bin/sh\nsudo timedatectl set-timezone $(tzselect)\necho\necho timedatectl says:\ntimedatectl\n\nI call it tz-set.\n\nA: As root you have to execute:\nln -fs /usr/share/zoneinfo/Europe/Warsaw /etc/localtime && dpkg-reconfigure --frontend noninteractive tzdata\n\nA: This worked for me on GCP Ubuntu 14 via SSH\n\n\n*\n\n*sudo su\n\n*cp /usr/share/zoneinfo/Asia/Singapore /etc/localtime\n\n*Restart the server\n\n*Done\n\n", "Q: Modules aren't loading - or something even more serious is wrong I am trying to solve this problem. In the process, I messed up the kernel configuration and some of the modules aren't loading.\nWhenever I start that particular kernel, I get a message saying \"Module nvidia could not be found.\" This of course means the USB module isn't working either. No mouse.\nThankfully I had another kernel installed that I'm using now - but I'd like my other one back.\nI can remember some of the steps I took - I edited some of the arguments being passed to the kernel - but I just got rid of those by editing the line when GRUB started - and it still didn't fix anything. The only other thing I remember is messing with initramfs.\nHow would I go about fixing that? I can boot to a console, but I'm not very familiar with any command-line text editors. Is there a way to fix this from the kernel I'm using right now?\n\nA: If you have a working kernel, I'd say the easiest route to success is the Etch-A-Sketch approach. Boot into the working kernel, remove the broken kernel, nuke its /lib/modules/<kernel-version> (or /lib64/) dir and when it's all dead, reinstall the kernel.\nIf you need to target the issue, check the logs. /var/log/kern.log should show up module loader explosions IIRC.\n", "Q: My processor is 64-bit - does that mean I need the amd64 image? My processor is an Intel Core 2 Duo P8600 (2.40GHz). As far as I know that's a 64-bit processor - I'm a bit confused as the architecture is called AMD 64, is this a generic name given to 64-bit architectures? I've heard of x64 but can't see a release labelled with this.\n\nA: You can use both the x86 and the amd64 images. And yes the initial generic name for the architecture was amd64 because it was developed, well, by AMD. Anyway, today is usually know as x86-64 or even x64.\n\nA: Intel licensed the AMD64 instruction set for their non-Itanium 64 Bit CPUs. Then, yes, AMD64 is one generic name for the x86 64 bit architecture.\nOf course your CPU can run 32 bit x86 kernels as well - but this is not recommended since you lose all the benefits of the x86-64 architecture (mainly bigger address space and more registers).\n\nA: X64, amd64 and x86-64 are names for the same processor type. It's often called amd64 because AMD came up with it initially. All current general-public 64-bit desktops and servers have an amd64 processor.\nThere is a processor type called IA-64 or Itanium. It's only found in supercomputers and a few high-end servers.\nA 64-bit processor can run a 32-bit system, so you have a choice of installing the amd64 version or the i386 version. Here are a few points of comparison:\n\n\n*\n\n*A few years ago, some programs had bugs when compiled for 64-bit processors, but that's mostly a thing of the past.\n\n*You can run 32-bit programs on a 64-bit system; the converse is not true.\n\n*A 32-bit kernel can access more than 4GB of RAM, so having more than 4GB of RAM is not a compelling reason to run a 64-bit kernel. On the other hand, a 32-bit program can only access less about 3GB of memory.\n\n*Which one is faster depends on the application (number crunching can be more than twice as fast in 64-bit mode, while symbolic manipulation can be more than twice as slow).\nIf in doubt, on an amd64-capable processor, use an amd64 distribution.\n", "Q: Is there a way to disable kernel updates? I run a more recent kernel (2.6.34) than the ones supplied with the Update Manager. I am tired of updates asking me to reboot every week or so and screwing my grub.cfg (this probably deserves it's own question).\nHow can I disable those updates painlessly?\nThanks.\n\nA: Go to System → Administration → Synaptic Package Manager.\nHighlight the installed kernel and choose Package → Lock Version on the menu bar.\nIf for some reason you still get prompted for update you can use\nsudo aptitude hold <the installed kernel package>\nto the same effect.\ndpkg --set-selections serves the same purpose, too.\n", "Q: Shortcut key for Terminator lands in the \"/\" directory I bound the command \"terminator\" to Super + T in the shortcut keys configuration.\nThis is nice and all except terminator starts with / as the current directory, not ~. How to change this?\n\nA: You will need to update the shortcut to the following command:\nterminator --working-directory=~\n\nFrom the MAN page:\n\n   --working-directory=DIR\n          Set the terminal's working directory\n\n\n\nA: Run the command as \nterminator --working-directory=~\n\ninstead of just \nterminator\n\n", "Q: How to get second display to work alongside primary display? I've almost got this problem solved... I've got both displays working now. The secondary display is displaying a purple background. Unfortunately, I can't use it. (I can't move the mouse into it, etc.)\nHere is the output of xrandr --verbose --screen 1:\n\n\nScreen 1: minimum 320 x 200, current 800 x 480, maximum 800 x 480\nLILLIPUT USB Mo connected (normal)\n Identifier: 0x175\n Timestamp:  271103\n Subpixel:   horizontal rgb\n Clones:    \n CRTC:       0\n CRTCs:      0\n Transform:  1.000000 0.000000 0.000000\n             0.000000 1.000000 0.000000\n             0.000000 0.000000 1.000000\n            filter: \n EDID:\n  00ffffffffffff0031900120eb030000\n  2013010380101778ca54548f54599726\n  cb545400000001010101010101010101\n  010101010101540b208030e02d102830\n  7304000000000018000000fd00374118\n  2905000a202020202020000000fc0055\n  5342204d6f6e69746f720a0a00000010\n  00000000000000000000000000000028\n  800x480 (0x176)   29.0MHz -HSync -VSync +preferred\n        h: width   800 start  840 end  888 total  928 skew    0 clock   31.2KHz\n        v: height  480 start  503 end  506 total  525           clock   59.5Hz\n\n\nAnd here is my xorg.conf file:\n\n# nvidia-settings: X configuration file generated by nvidia-settings\n# nvidia-settings:  version 1.0  (buildd@yellow)  Fri Apr  9 11:51:21 UTC 2010\n\n# nvidia-xconfig: X configuration file generated by nvidia-xconfig\n# nvidia-xconfig:  version 1.0  (buildmeister@builder58)  Fri Mar 12 02:12:40 PST 2010\n\nSection \"ServerLayout\"\n    Identifier     \"Layout0\"\n    Screen      1  \"DisplayLinkScreen\" RightOf \"Screen0\"\n    Screen      0  \"Screen0\" 0 0\n    InputDevice    \"Keyboard0\" \"CoreKeyboard\"\n    InputDevice    \"Mouse0\" \"CorePointer\"\n    Option         \"Xinerama\" \"0\"\nEndSection\n\nSection \"Files\"\nEndSection\n\nSection \"InputDevice\"\n\n    # generated from default\n    Identifier     \"Mouse0\"\n    Driver         \"mouse\"\n    Option         \"Protocol\" \"auto\"\n    Option         \"Device\" \"/dev/psaux\"\n    Option         \"Emulate3Buttons\" \"no\"\n    Option         \"ZAxisMapping\" \"4 5\"\nEndSection\n\nSection \"InputDevice\"\n\n    # generated from default\n    Identifier     \"Keyboard0\"\n    Driver         \"kbd\"\nEndSection\n\nSection \"Monitor\"\n    Identifier     \"Monitor0\"\n    VendorName     \"Unknown\"\n    ModelName      \"LPL\"\n    HorizSync       30.0 - 75.0\n    VertRefresh     60.0\n    Option         \"DPMS\"\nEndSection\n\nSection \"Device\"\n    Identifier     \"Device0\"\n    Driver         \"nvidia\"\n    VendorName     \"NVIDIA Corporation\"\n    BoardName      \"GeForce 8400M GS\"\n    BusID          \"PCI:1:0:0\"\n    Screen          0\nEndSection\n\nSection \"Screen\"\n    Identifier     \"Screen0\"\n    Device         \"Device0\"\n    Monitor        \"Monitor0\"\n    DefaultDepth    24\n    Option         \"TwinView\" \"0\"\n    Option         \"metamodes\" \"DFP: nvidia-auto-select +0+0\"\n    SubSection     \"Display\"\n        Depth       24\n    EndSubSection\nEndSection\n\n#################################################\n\n############### DisplayLink Stuff ###############\n\nSection \"Device\"\n    Identifier      \"DisplayLinkDevice\"\n    driver          \"displaylink\"\n    Option  \"fbdev\" \"/dev/fb0\"\nEndSection\n\nSection \"Monitor\"\n    Identifier      \"DisplayLinkMonitor\"\nEndSection\n\nSection \"Screen\"\n    Identifier      \"DisplayLinkScreen\"\n    Device          \"DisplayLinkDevice\"\n    Monitor         \"DisplayLinkMonitor\"\n    DefaultDepth    16\n    SubSection \"Display\"\n        Depth   16\n        Modes   \"800×480\"\n    EndSubSection\nEndSection\n\n\nUpdate: After adding...\n\nXinerama \"1\"\n\n...I now have the secondary screen mirroring the primary one. But I'm hoping I can have separate displays.\n\nA: I fixed it. The problem is that in order to use Xinerama, both displays must be using the same bit depth. (16 bits)\n", "Q: How to get the mime type of a file from the command line? I'm trying to get the mime type of a file from the command line as a printed string (eg. application/vnd.oasis.opendocument.spreadsheet).\nI looked up how to do this and found the xdg-mime command.\nFrom reading the man page (man xdg-mime), it seems I should run xdg-mime query filetype FILE. However, when I run this with any file it prints nothing and exits.\nIs there a way to fix this? An alternative command?\n\nA: The great answer on this page can be put in a function or script like so:\nExample\n$ mime_type.sh /etc/passwd  \ntext/plain\n\nmime_type.sh\nfunction mime_type()\n{\n  file --mime-type -b $*\n}\n\nmime_type $*\n\n\nA: mimetype /path/to/file\n\nTested in 18.04\n\nA: xdg-mime and file query different databases (xdg-mime is more comprehensive). See Why the difference between the results with \"file --mime-type\" and \"xdg-mime query filetype\"? for more discussion.\nxdg-mime does not work correctly from a non-desktop session (e.g. if you're SSH'd into a machine).\n\nA: Use file --mime-type -b filename\nLook at file --help for more tips. \n", "Q: Chromium, Tweetdeck, and Geany don't work when set to run at login I have \"automatically remember running applications when logging out\" enabled in \"Startup Application Preferences\". However, some programs don't work with this setting: namely Chromium  TweetDeck and Geany; none of these programs are restored whenever I restart the machine. Other programs such as Firefox, Gedit, Terminal are able to be restored automatically on restart.\nIs there any way I can have ALL of these programs restored appropriately on startup? or at least Chromium?\n\nA: The only suggestion I can make is you just add start up entries for each of them (in system, prefs, start up applications) and file a bug.\nThis means they will always load up on login but that sounds desirable.\n", "Q: How to move boot and root partitions to another drive I have two drives on my computer that have the following configuration:\nDrive 1: 160GB, /home\nDrive 2: 40GB, /boot and /\n\nUnfortunately, drive 2 seems to be dying, because trying to write to it is giving me errors, and checking out the SMART settings shows a sad state of affairs.\nI have plenty of space on Drive 1, so what I'd like to do is move the / and /boot partitions to it, remove Drive 2 from the system, replace Drive 2 with a new drive, then reverse the process.\nI imagine I need to do some updating to grub, and I need to move some things around, but I'm pretty baffled how to exactly go about this. Since this is my main computer, I want to be careful not to mess things up so I can't boot.\n\nA: If you replace the drive right away you can use dd (tried it on my server some months ago, and it worked like a charm).\nYou'll need a boot-CD for this as well.\n\n\n*\n\n*Start boot-CD\n\n*Only mount Drive 1\n\n*Run dd if=/dev/sdb1 of=/media/drive1/backuproot.img - sdb1 being your root (/) partition. This will save the whole partition in a file.\n\n\n*\n\n*same for /boot\n\n\n*Power off, replace disk, power on\n\n*Run dd if=/media/drive1/backuproot.img of=/dev/sdb1 - write it back.\n\n\n*\n\n*same for /boot\nThe above will create 2 partitions with the exact same size as they had before. You might need to adjust grub (check macos post).\nIf you want to resize your partitions (as i did):\n\n\n*\n\n*Create 2 Partitions on the new drive (for / and /boot; size whatever you want)\n\n*Mount the backup-image: mount /media/drive1/backuproot.img /media/backuproot/\n\n*Mount the empty / partition: mount /dev/sdb1 /media/sdb1/\n\n*Copy its contents to the new partition (i'm unsure about this command, it's really important to preserve ownership, cp -R won't do it!) \ncp -R --preserve=all /media/backuproot/* /media/sdb1\n\n\n*\n\n*same for /boot/\nThis should do it.\n\nA: My final solution to this was a combination of a number of techniques:\n\n\n*\n\n*I connected the dying drive and its replacement to the computer simultaneously.\n\n*The new drive was smaller than the old, so I shrank the partitions on the old using GParted.\n\n*After doing that, I copied the partitions on the old drive, and pasted them on the new (also using GParted). \n\n*Next, I added the boot flag to the correct partition on the new drive, so it was effectively a mirror of the old drive.\n\n\nThis all worked well, but I needed to update grub2 per the instructions here.\nAfter all this was done, things seem to work.\n\nA: You'll need to boot from a live cd.  Add partitions for them to disk 1, copy all the contents over, and then use sudo blkid to get the UUID of each partition.  On disk 1's new /, edit the /etc/fstab to use the new UUIDs you just looked up.\nUpdating GRUB depends on whether it's GRUB1 or GRUB2.  If GRUB1, you need to edit /boot/grub/device.map\nIf GRUB2, I think you need to mount your partitions as they would be in a real situation. For example:\nsudo mkdir /media/root\nsudo mount /dev/sda1 /media/root\nsudo mount /dev/sda2 /media/root/boot\nsudo mount /dev/sda3 /media/root/home\n\n(Filling in whatever the actual partitions are that you copied things to, of course)\nThen bind mount /proc and /dev in the /media/root:\nsudo mount -B /proc /media/root/proc\nsudo mount -B /dev /media/root/dev\nsudo mount -B /sys /media/root/sys\n\nNow chroot into the drive so you can force GRUB to update itself according to the new layout:\nsudo chroot /media/root\nsudo update-grub\n\nThe second command will make one complaint (I forget what it is though...), but that's ok to ignore.\nTest it by removing the bad drive.  If it doesn't work, the bad drive should still be able to boot the system, but I believe these are all the necessary steps.\n", "Q: Get a file's emblem from command line? I'd like to be able to determine what emblem a file has from the command line.  Is there a way to determine this?  Also, is there a way to apply emblems from the command line?\nI usually have a cron job that trashes files over 7 days old in my ~/Downloads, but I'd like to be able to only delete files that don't have a particular emblem (my seeding torrents).  I've been applying these emblems manually, but if I can automate that as well, that'd be awesome.\nMy usual cron job is just a simple find command:\nfind /home/zach/Downloads/ -ctime +7 -exec trash {} \\;\n\nEdit:\nI solved my own question.\nBonus:\nTo elaborate on exactly what I'm doing, I use deluge-torrent to manage my downloads.  I am now using the execute plugin to run this script on torrent complete:\n#!/usr/bin/env bash\n# deluge gives the download directory name as the third argument\ngvfs-set-attribute -t stringv \"$3\" metadata::emblems ubuntuone-unsynchronized\n\nI then created my trasher.sh (this requires the trash-cli package):\n#!/usr/bin/env bash\n[[ \"$(gvfs-info -a metadata::emblems $*)\" =~ \"ubuntuone-unsynchronized\" ]] || trash \"$*\"\n\nNow, I just modify my cron to:\nfind /home/zach/Downloads/ -maxdepth 1 -ctime +7 -exec /home/zach/Scripts/trasher.sh {} \\;\n\nAnd voila!  Now Deluge can manage its downloads, while my cleanup script can safely cleanup old files without interfering with seeding torrents.\n\nA: <Juhaz> in ##gnome on freenode got it.\ngvfs-info -a metadata::emblems FOLDER\nwill retrieve the emblem of a folder/file and\ngvfs-set-attribute -t stringv FOLDER metadata::emblems EMBLEM\nwill allow you to set emblem of the folder/file.\n\nA: This post explains how emblem information is stored in a XML file under ~/.nautilus/metafiles. First you'd need to test if the XML related to each download exists, and if so, whether it contains the emblem of your choice.\n", "Q: Why does gnome-session crash my TightVNC session and how can I fix it? I'm running ubuntu 9.10 x64, with the stock tightvncserver (1.3.9).\nWhen I start tightvncserver, I can connect with the windows tightvnc client and get the empty desktop with a single terminal. When I then try to start gnome-session it promptly crashes.\nThe last lines on the tightvncserver log are:\n01/09/10 10:53:18 Got connection from client 192.168.1.31\n01/09/10 10:53:18 Using protocol version 3.8\n01/09/10 10:53:18 Enabling TightVNC protocol extensions\n01/09/10 10:53:20 Full-control authentication passed by 192.168.1.31\n01/09/10 10:53:20 Pixel format for client 192.168.1.31:\n01/09/10 10:53:20   32 bpp, depth 24, little endian\n01/09/10 10:53:20   true colour: max r 255 g 255 b 255, shift r 16 g 8 b 0\n01/09/10 10:53:20   no translation needed\n01/09/10 10:53:20 Using tight encoding for client 192.168.1.31\n01/09/10 10:53:20 rfbProcessClientNormalMessage: ignoring unknown encoding 8\n01/09/10 10:53:20 Enabling X-style cursor updates for client 192.168.1.31\n01/09/10 10:53:20 Enabling cursor position updates for client 192.168.1.31\n01/09/10 10:53:20 Using image quality level 6 for client 192.168.1.31\n01/09/10 10:53:20 Enabling LastRect protocol extension for client 192.168.1.31\n01/09/10 10:53:20 rfbProcessClientNormalMessage: ignoring unknown encoding -223\nxterm:  fatal IO error 11 (Resource temporarily unavailable) or KillClient on X server \":3.0\"\n\nThe output from gnome-session (obtained from gnome-session | tee output) is:\nGNOME_KEYRING_SOCKET=/tmp/keyring-mUVFSj/socket\nSSH_AUTH_SOCK=/tmp/keyring-mUVFSj/socket.ssh\nGNOME_KEYRING_PID=2783\n** (<unknown>:2779): DEBUG: Client registered with session manager: /org/gnome/SessionManager/Client2\nChecking for Xgl: not present.\nxset q doesn't reveal the location of the log file. Using fallback /var/log/Xorg.0.log\nDetected PCI ID for VGA:\nChecking for texture_from_pixmap: not present.\nTrying again with indirect rendering:\nChecking for texture_from_pixmap: not present.\naborting and using fallback: /usr/bin/metacity\n\nI've checked the /var/log/Xorg.0.log but this contains nothing pertinent to the vnc session.\nI am currently successfully using tightvncserver on other 9.10 systems. The system which exhibits the problem does not differ from my other working systems in any way that seems significant to me.\nWhat I'd like to know is:\n\n\n*\n\n*What I should be doing to find out further information on what is failing\n\n*What is causing the crash\n\n*How can I fix it?\n\n\nA: To answer how to diagnose your problem specifically, the first step would be to enable apport crash reporting on the system and then attempt to reproduce the crash. Once you've caused TightVNC to crash again, if it was the type of crash that apport should catch, a crash report should have appeared in /var/crash. You should be able to point ubuntu-bug at the crash report file to have it submit a bug report to launchpad.\nThat said, a while back I went through several of the vnc servers, looking to use one in the way you describe, as a separate session rather than to duplicate a running desktop. As I recall, tightvncserver crashed on me a lot, and based on the launchpad bugs for the package, it seem that a few other people see the same thing.\nI ended up using vnc4server , which has worked pretty well for me over multiple releases. That said, in maverick, I'm getting bitten by bug 655886 when using a gnome session, so it's not perfect.\n\nA: I've had a lot of problems when using tightvnc when desktop effects are enabled (eg. compiz). Try disabling compiz and see if that solves your problem. You can disable it via System --> Preferences --> Appearance, and then selecting the Visual Effects tab (Select \"None\").\nIf that doesn't help you out, you'll probably have to run gnome-session using the strace tool. This will display every system call that gnome-session is running and hopefully give an indication of which one is causing you troubles.\n", "Q: auto bcc is not working when contain attachment in Postfix I'm using postfix smtp and adding always_bcc.\nalways_bcc = admin@somesite.com\n\nIt's working fine without attachment. When I add attachment, auto bcc is not working and admin didn't get email.\nHow to fix that problem ?\n\nA: This is not answer i just trying to say a way to debug your postifx server configuration \n\npost postconf -n\n\nand see the postfix Troubleshooting process here\nalso see Postfix sends all log messages to /var/log/mail.log. However error and warning messages can sometimes get lost in the normal log output so they are also logged to /var/log/mail.err and /var/log/mail.warn respectively. \n", "Q: How does Ubuntu handle deadlock situations? I need links to some documentation which states how Ubuntu handles deadlock, which method does it apply?\nPlease note am asking this question as am a new user regarding the os and therefore really confused google is not helpful\nEDIT-- additional details\n(kernal and user space in general\nhow to compare linux with an ms windows)\n\nA: From my understanding the Linux Kernel (and by proxy Ubuntu) ignores deadlocks. They happen so infrequently that the cost to manage them (monitoring, resolution) far exceeds the benefit. The least costly way to manage them is to simply ignore them (Whereas other applications like databases run in to Deadlocks more frequently, Linux does not).\n\nA: Deadlocks can occur in lot of different situations and may or may not be handled. If they are handled, they are handled in different ways. In order to received a specific answer, you would have to specify a particular area (i.e. networking, memory management, or specific applications). Is your question more academic, or do you have a particular problem?\n", "Q: Is there a way to use *some* packages from upcoming version of Ubuntu? For my work I need to stay close to 2.8 version of llvm (not yet released). I found out that Maverick will have it installed and already have some prepackaged version. \nIs there a way I can use just this packages (and all the packages it depends on) in my current Ubuntu installation? Some kind of repository maybe?\n\nA: I don't think too many people are going to get enthusiastic about packaging it until it nears its release. That's still the best part of a month away. All the llvm ppas\nIn the meanwhile, you might be able to just pull in the llvm-2.8 packages from Maverick. I say \"might\" because it just doesn't work all the time. Sometimes the dependencies run too deep and you end up pulling in so much of Maverick things become unstable.\nOtherwise you're left with compiling it yourself. That should be well within your abilities but generally speaking, this could upset anything that depends on llvm. I think as it is, nothing in Lucid depends on llvm (it's not installed here) so you might be fine.\nIf you are going to compile, the Getting Started with the LLVM System is going to be your main reference for the next few hours.\nAnother option is developing against Lucid's 2.7 and testing on a Maverick install. The most convenient way for a sole-developer would be through a virtual machine (ie VirtualBox). This is extra-handy as you'll be in a good position to file bugs where they need filing so you're not left with a buggy environment when you do upgrade your dev machine to Maverick.\n\nA: Your best bet is to use LLVM from a ppa packaged for you version (lucid?). You can search PPAs at https://launchpad.net/ubuntu/+ppas .\nIf you can't find it in a ppa, you can try just downloading and installing the maverick package(s) and if they don't have many dependencies (or the versions of the dependencies are the same in lucid and maverick) there's a good chance that it'll work. Note that this is not recommended, though.\n\nA: I don't see any prepackaged setups for it, for the latest version you would need to compile it yourself. the getting started guide explains getting the source, setting up your environment and building the suite.\nThe first 3 points in the guide cheekily starts off with\n\n  \n*\n  \n*Read the documentation.\n  \n*Read the documentation.\n  \n*Remember that you were warned twice about reading the documentation.\n  \n\n", "Q: How can I completely remove wireless drivers? On my laptop the wireless seems to be detected but it fails to connect. Even turning the switch on and off seems to have no effect. This is the output of lspci command:\n06:02.0 Network controller: Broadcom Corporation BCM4318 [AirForce One 54g] 802.11g Wireless LAN Controller (rev 02)\n\nI have the package b43-fwcutter istalled. Some people told me if I remove the linux driver and  install Ndiswrapper the proplem would be solved. Is that true? And if the answer is yes how can I do that?\n\nA: There is a help page that explains all the details of making this wireless chip work on different Ubuntu releases. \n", "Q: External hard drive permissions problem with apache since 10.04 upgrade I have a Fat32 external hard drive plugged into my server at home and since upgrading to Ubuntu 10.04 (from 8.10 - it was a bug jump!) I've been having permissions trouble with it.\nIt used to be mounted as root automatically and I think the permissions were pretty much 'ignored'. Since the upgrade, it is being mounted with the group and owner being my user. Obviously, I need access as my user and this is no problem still. However, I am also running a PHP script (via apache) that serves certain files to authenticated users. This is now no longer working.\nIf I run PHP as my user there is no problem (obviously). However, when running under www-data it cannot access the drive so my script is now failing.\nThe permissions on the drive look like this at the moment:\ndrwx------ 1 adamnfish adamnfish\n-rwxrwxrwx 1 adamnfish adamnfish\n\nfor folders and files respectively.\nIt's very clear what the problem is (only adamnfish can access the drive!) but I have no idea how to fix the problem. I've tried mounting the drive every which way and even using GUI tools to try and set the bitmask properly!\nThe hard drive is always plugged in, but sometimes I kick its power cord while tidying up (so the solution needs to be resilient to plugging / unplugging the drive) and I reboot the machine from time to time (so ideally it'll be an fstab entry or something so I don't need to manually unmount and remount with the correct permissions every time).\nThanks in advance, I know this will be obvious to a lot of people but I've been pulling my hair out!\n\nA: Please read this Ubuntu wiki entry, especially the part about fstab and its options:\nhttps://help.ubuntu.com/community/AutomaticallyMountPartitions\nThe important thing to understand is that you actually specify the permissions on the mount location, for example /mnt, and the device that will be mounted to that mount location will have those permissions.\nSo just add an entry to fstab that mounts your fat32 disk to /mnt for example end set the correct permissions on that folder.\nThere is also a handy tool for managing storage devices that you might like, called pysdm: http://pysdm.sourceforge.net/\n", "Q: Chromium doesn't work My chromium browser doesn't work for some reason. What I mean by that is that it doesn't even start up when I click on chromium icon or choose chromium from applications menu. What might be the problem?\nAfter typing: chromium-browser in the terminal I get this:\n/home/freshnrg/.themes/T-ish-Brushed-Overlaid/gtk-2.0/gtkrc:56: Clearlooks configuration option \"sunkenmenu\" is not supported and will be ignored.\n/home/freshnrg/.themes/T-ish-Brushed-Overlaid/gtk-2.0/gtkrc:57: Clearlooks configuration option \"menuitemstyle\" is not supported and will be ignored.\n/home/freshnrg/.themes/T-ish-Brushed-Overlaid/gtk-2.0/gtkrc:58: Clearlooks configuration option \"listviewitemstyle\" is not supported and will be ignored.\n/home/freshnrg/.themes/T-ish-Brushed-Overlaid/gtk-2.0/gtkrc:59: Clearlooks configuration option \"progressbarstyle\" is not supported and will be ignored.\nSegmentation fault\n\nSo nothing about any errors connected to chromium because all that is just my ubuntu theme errors witch i get all the time. don't understand that Segmentation fault not sure if that has anything to do with chromium.\nafter typing: rm -rf ~/.config/chromium\nand then: chromium-browser\nchromium actually starts from scratch asking if I want to import bookmarks from firefox and it doesn't matter what I choose because that is it. After that nothing happens and chromium still doesn't work.\nRe-installation didn't helped. I still get segmentation fault error.\nEDIT: I've done all this, went back to official version 5.0.375.127, I've re-installed it couple of times and still nothing. I still have that segmentation fault error.\nEDIT: It's definitely something to do with dropbox. After installing dropbox on my new account Chromium stopped working. How can I get rid of dropbox on my old account as I've uninstalled it and deleted all the files that has anything to do with dropbox but I still can't get Chromium to work?\n\nA: Wild shot: Do you have the new Ubuntu font beta installed?.\nThere are a couple of reports on the net that this font crashes Chrome: upstream bug, ubuntu bug.\n\nA: I had something like this a very, very long time ago. I wonder where you're getting chromium from. \n5.0.375.125~r53311 seems to be the latest official version (there is a slightly newer proposed version) but the current chromium-daily PPA is at 7.0.512.0.... I'm always slightlt dubious of people who suggest just blindly upgrading things but in this case it might help you get it working.\nTo install the PPA:\nsudo add-apt-repository ppa:chromium-daily/ppa\nsudo apt-get update\nupdate-manager\n\nThen just install the updates. You'll get a lot of updates through this and it's quite likely you might find something breaks as this is bleeding-edge software.\nIf you find it doesn't work or something else breaks, you can go back to stock versions with ppa-purge:\nsudo apt-get install ppa-purge\nsudo ppa-purge chromium-browser\n\n\nA: I am not sure what build you are running (beta, dev, daily or stable). The instructions I am providing you with will move you to the stable build.\nsudo apt-get purge chromium-browser\n\nThis will purge Chromium. Now to remove other relate files\nsudo rm /etc/apt/sources.list.d/chromium-daily-[build]-lucid.list /etc/apt/sources.list.d/chromium-daily-[build]-lucid.list.save\n\nThis removes the PPA for the build you are using. Replace [build] with the build you are using. Tab completion can help.\nrm -rfv ~/.config/chromium/\n\nThis will remove the you Chromium settings.\nsudo add-apt-repository ppa:chromium-daily/stable\n\nThis will ad the stable PPA.\nsudo apt-get update\n\nThis will refresh the list of packages.\nsudo apt-get install chromium-browser\n\nThis install the stable version Chromium. If this doesn't work try changing your theme. The terminal output mentions you theme.\n\nA: Try launching it from the commandline: open a terminal (Applications->Accessories->Terminal) and type: chromium-browser.\nIf it launches, then you have a problem in your shortcut (very unlikely). You can edit it from System->Preferences->Main menu.\nIf it doesn't launch, you should get some error message displayed that should explain why it failed. If you can't fix it yourself based on that, please copy those messages to your original post, so that we can try helping you :)\nIn any case, you can try removing your local settings for it (under your HOME folder, delete the .config/chromium folder) so that it is restarted clean next time (as if you just installed it). Now be cautious: this will delete all your settings, including bookmarks...\nTo do that, under a terminal, type:\nrm -rf ~/.config/chromium\nEDIT: the \"Segmentation fault\" is actually very interesting: it tells that Chromium crashed in an ugly fashion (not because of a handled error, but because it tried to do something wrong on the system).\nEither it is an issue with the installation, or with a plugin that you added to it...\nI think you should completely uninstall it, and reinstall it again, just to see if it solves the issue.\n", "Q: Google Voice and Video: Video is not supported on this OS Im running the latest release version (5.0.372.127) of chrome on karmic koala x86. I just installed Google Voice and Video chrome plugin with out problems but if I try to start a video call then I get this message (in the chat window).\n\nVideo is not supported on this OS.\n  Learn more...\n\nThe learn more... is static text i.e. no link so thats not much use. A quick google shows that ubuntu does support this feature, theres even a thread here.\nAny ideas?\n\nSorry if Iv'e omitted any crucial information, let me know and Ill update the question ASAP.\n\nA: You need to use something like Empathy (sudo apt-get install empathy in the command line or via Applications -> Ubuntu Software Center) or Pidgin (sudo apt-get install pidgin in the command line or via Applications -> Ubuntu Software Center) which are both IM application for the desktop that support a wide variety of protocols (Google Voice and Video included) in order to connect to the Google Talk servers and other gTalk user.\nEmpathy is the default IM client for Ubuntu and should already be installed on versions 10.04 and higher.\nIt appears you can download install the Linux plugin for Google Chat here ensuring you select the proper architecture. I was unable to test it, but the download and installation on 10.04 was clean.\n\nA: By installing that .deb, it seems to work in chromium 5.0.375.125 on Ubuntu 10.04. I haven't actually made a call but it pops up a little window allowing you to dial a number.\nThis plugin is a browser plugin that requires you to go into the gmail web interface to use it.\nIf Empathy has Google voice and video support as @Marco Ceppi says, then it would be better to use that. \n", "Q: Boot with \"noacpi\" automatically from hard drive? If I boot ubuntu from the live cd without any special options I get the following message:\n\n[    0.040001] Kernel panic - not syncing: IO-APIC + timer doesn't work! Boot with apic=debug and send a report.  Then try booting with the 'noapic' option.\n  [    0.040001]\n\nSo I booted with the noapic option (and the acpi=off option because the noapic option alone didn't work). It booted fine and I was able to install. Then after the restart I got the above message again. Is there a way to tell ubuntu to use the noapic option when booting from harddrive?\n\nA: If you're using GRUB2 (clean-installs of Ubuntu 9.04 and later), edit /etc/default/grub and change the following line: (this may look different on your system, I just took it from mine as an example)\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nomodeset\"\n\nAdd noacpi, or whichever kernel option you want, anywhere in the line.  \nIf you're using GRUB Legacy (if you upgraded from a version of Ubuntu before 9.10), please see the GRUB page in the Ubuntu Wiki for details on how to edit your /boot/grub/menu.list to accomplish the same as above.  \n\nA: To do this you must change the boot parameters through Grub. Open /etc/default/grub as root. Add noapic to the GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\" or similar. Then run update-grub as root.\n", "Q: How can I view a Microsoft Publisher .pub file? I need to view a .pub file. How can I view the file or convert it to a more mainstream format (such as a PDF?)\n\nA: In case anyone runs into this question, a Microsoft Publisher importer is expected in LibreOffice 3.7. More info: \nhttp://libregraphicsworld.org/blog/entry/microsoft-publisher-support-makes-its-way-to-libreoffice\nhttp://fridrich.blogspot.ch/2012/06/libreoffice-ms-publisher-import-filter.html\n\nA: I spent a long time investigating this recently as I needed to index .pub files for use in Xapian.\nThe conclusion is that the only thing that can read .pub files is publisher.\nYou can run publisher in CrossOver Office with some success. I have used this in the past and I had no problems.\n\nA: This website: http://www.zamzar.com/ appears to be able to convert .pub files to a number of formats including .odt and .pdf (source: http://blog.zamzar.com/2008/01/25/convert-ms-publisher-files-pub-files-to-doc-pdf-odt-rtf-and-more/)\nThe file needs to be under 100MB and the converted file will be sent to you by email.\n\nA: LibreOffice Draw now can open .pub document.\n\nA: I don't know of any applications that do this but, you can use this to convert PUB files to PDF. An alternative would be to install Microsoft Publisher through Wine (available in the repositories).\n\nA: The only website able to convert PUB files online to PDF I found was http://convert.neevia.com/\n\nA: I know this isn't an actual ubuntu software, but this website can help you. It converts the pub file to pdf\nhttp://pubtopdf.com\n\nA: How to view a Microsoft Publisher .pub file and convert it to PDF on Linux Ubuntu\nA couple answers mention LibreOffice and/or LibreOffice Draw. Here are some more details on that.\nI just tested these steps on Linux Ubuntu 20.04, with LibreOffice 6.4.7.2.\n1. GUI method: open it up in LibreOffice Draw:\nIn any of the LibreOffice programs, including Draw, Calc, Impress, or Writer, go to File --> Open... --> navigate to your .pub file, select it, and click on the Open button.\nIt will open up in LibreOffice Draw, regardless of which LibreOffice program you used to go to File --> Open.\nOnce it is open in LibreOffice Draw, you can optionally export it as a PDF if you want by going to File --> Export As --> Export as PDF... --> change any export settings you'd like to and click on the Export button.\nDone.\n2. Command-line method: convert .pub files to .pdf from the terminal\nLibreoffice also supports a fantastic --headless command-line option which lets you convert from .pub to .pdf files from the command-line! I learned how to do this by studying this answer here: Command libreoffice --headless --convert-to pdf test.docx --outdir /pdf is not working. The command I came up with, which works great, is this:\nlibreoffice --headless --convert-to pdf:draw_pdf_Export \"path/to/myfile.pub\"\n\nIt takes just a couple seconds.\nOther attempts\nI tried opening it up in Google Drive/Google Docs too, since that work great for converting Excel and Microsoft Word docs between formats, but it looks like Google doesn't yet support the .pub file format. Perhaps they will in the future.\n", "Q: How to create and administer multi-architecture PPAs? I have a program that needs to be recompiled for every ubuntu version.\nCurrently I am packaging it using Ubuntu's PPA just for the current distribution.\nEventually, I have to provide packages for the previous ubuntu version.\nI am not sure how to accomplish this.\nHow does the Ubuntu PPA build server works - does it just look at the distribution field in the most current changelog entry (in the debian/changelog file) to determine for what distribution the package should be build?\nThe debian specification allows to add multiple distributions into the distribution field. But this does not seam to help me.\nSome ubuntu documents talk about encoding the distribution name into the version number (in the debian changelog file).\nBut how does this work in practice? A new version of the program is available, then what? Do I add for each distribution a new changelog entry and the PPA buildserver builds automatically for each distribution new packages after dput'ing it up? Or does the PPA buildserver just looks at the first changelog entry?\n\nA: Regarding the naming conventions, the standard is to do something like this:\n\n\n*\n\n*1.0-0ubuntu1  for the package that ends up in Ubuntu's official archive\n\n*1.0-0ubuntu1~lucidppa1  for the version of that package you put in your PPA for lucid\n\n*1.0-0ubuntu1~karmicppa1  for the version of that package for Karmic\n\n\nThe reason is that a ~ in the version field represents \"less than nothing\" for a version number.  So if someone adds your PPA at Karmic, they'll get the ~karmicppa1 package.  When they then upgrade to Lucid (and readd your PPA), it'll be replaced with the Lucid PPA package.  If your package then gets into the official archive, the transition away from your PPA will go smoothly.\nThe other advantage is that putting the release in the version field makes it clear which release the files apply to (and subtly reminds you to upload one per release).  You may also need different branches for each Ubuntu release for when you have different dependencies, for instance.\n\nA: The way to go is to upload once for every Ubuntu version.\nLaunchpad won't build packages for Ubuntu versions that are no longer supported, and only build a package for one specific version of Ubuntu. The targeted version is (as you already know) specified in the changelog file, by the newest entry!\nRemember to be aware that the packages your program depends on might not be available at the same version across all versions of Ubuntu.\nYou also talk about \"multi-architecture\" (architecture = CUP type, eg. x86, LPIA, AMD64) this makes no difference since every package uploaded is build for all available architectures as long as you have Architecture: any in the package definition (debian/control) file, this also allows you to make the package depend on different packages for different architectures (be defining the package more than once)\n\nA: Launchpad has a new feature currently in beta which allows you to build your package for multiple ubuntu versions at once without any extra work. You can even automatically build  your packages every day. https://help.launchpad.net/Packaging/SourceBuilds/GettingStarted\n\n", "Q: Easily add mount points to Ubuntu Is there a nice, possibly GUI way to add mount points to partitions in Ubuntu?\nFor some reason, the mount point for my windows NTFS partition which was recognized during the installation is gone. In \"Computer\" the library still exist, but there's no mount point in fstab or mtab.\nHow can I add it again, so that it'll be nicely accessible from gnome as it used to be?\n\nA: pysdm is a gui to your /etc/fstab.  It has a basic wizard and makes it easy to configure your drives and where they mount.\n\n\nA: NTFS Configuration Tool\nYou can install it from Ubuntu Software Center.\n\nA: Nautilus uses gvfs to do mounting without modifying /etc/fstab. Can you access the partition in Nautilus? If you're trying to access it from a shell prompt but can't, try ls -l ~/.gvfs. You should see something there that corresponds to your NTFS partition.\n", "Q: Ubuntu freezes after installation on HP Compaq nx9020 with Intel graphics 855MG I have a HP Compaq nx9020 notebook with Intel graphics 855MG. When I installed Ubuntu 10.04 in text mode everything worked fine, but after a reboot the notebook is freezing after the loading screen with Ubuntu.\nWindows works fine so I guess the hardware is ok.\nIf I use vesa drivers I don't see anything in graphic modes. Console works fine.\nHow can I sort this out?\n\nA: Lucky you to have i855.\nAfter selecting your username click the box in the bottom right that says GNOME and switch it to Xterm, then enter the following commands:\nsudo add-apt-repository ppa:glasen/intel-driver \nsudo apt-get update && sudo apt-get upgrade\nsudo add-apt-repository ppa:glasen/855gm-fix\nsudo apt-get update && sudo apt-get install dkms 855gm-fix-dkms\n\n", "Q: Can I override an SD card's write-protect switch? The write-protect switch on an SD card doesn't connect to any internal electronics, so it must just be respected by the software controlling the card reader.\nIs there any way for me to override this setting and mount a write-protected card with read-write permissions?\n\nA: Not likely. The read/write access is set by the drive's firmware and is usually impossible to change.\n\nA: Yes you can overide. on one side of ther SD_card there is a small nik ( remember cassette tapes ). if you cover this with some thin card (selotape works too, but needs several layers ). then it will allow the transfer of music pictures etc, onto the protected sd-card.\n", "Q: Gwibber and OAuthcalypse My Gwibber app in 10.04 seems to have fallen victim to the OAuthcalypse. I understand that the latest version of Gwibber has this corrected. What is the easiest way to install a version of Gwibber that will work once again with twitter?\n\nA: UPDATE\nThe gwibber version with fixed Twitter OAuth is now in lucid-updates Running your update manager via either: System -> Administration -> Update Manager , (or sudo apt-get update && sudo apt-get upgrade) should trigger the update process.\n\nThe easiest way to grab the latest version of Gwibber is to add the ubuntu-desktop PPA (which includes the latest updates for desktop software, including Gwibber)\nFrom command line:\nsudo add-apt-repository ppa:ubuntu-desktop/ppa\nsudo apt-get update\nsudo apt-get upgrade\n\nIf you don't want the whole ubuntu-desktop ppa (which you may not - though it can be quite helpful to avoid issues of this nature in the future) you can simply add the Gwibber Daily PPA which will only provide the updates for Gwibber\nsudo add-apt-repository ppa:gwibber-daily/ppa\nsudo apt-get update\nsudo apt-get upgrade\n\nAfter the upgrade you will need to restart Gwibber:\ngwibber-service restart\n\nIf that method does not work open the Gwibber interface then choose Gwibber->Quit and Launch it again either from the Message Indicator Applet or via Applications->Internet->Gwibber Social Client\nOnce Gwibber has restarted you will need to authenticate your Twitter account. Open the client and navigate to Edit->Accounts then click Authorize on your Twitter account in order to complete the process.\nThe Oauthcalypse caught me off guard too - even though I was watching the Countdown to OAuthcalypse I failed to relate that to Gwibber\n\nA: Add the Ubuntu Desktop PPA\nsudo add-apt-repository sudo add-apt-repository ppa:ubuntu-desktop/ppa\n\nand update\nsudo apt-get update && sudo apt-get upgrade\\\n\nthen restart Gwibber\ngwibber-service restart\n\n[Source: WebUpd8]\n", "Q: How to debug Nautilus extension? I recently installed mpd-gnome which among other things adds a nautilus extension nautilus-mpd.py. This extension does not seem to be working so I decided to run nautilus from the command line to see if it threw up some kind of error regarding the extension. Unfortunately as soon as I attempted this nautilus forked to the background or something.\nHow can I see exactly why my extension isn't work?\n\nA: I recall I was able to run nautilus from a terminal when debugging extensions myself; if you kill and then immediately restart nautilus, you should have it running from the command line:\nnautilus -q && nautilus ~/\n\nI was able to confirm that this works on Lucid. Note that passing in some directory when launching nautilus is important, otherwise it will fork off in the background.\n\nA: If you want nautilus to stop permanently, open up gconf-editor and set /desktop/gnome/session/required_components_list to windowmanager,panel (removing \"filemanager\").  Then log out and back in.\nTo restore previous behavior, change the gconf key back to windowmanager,panel,filemanager.\n", "Q: Mouse no longer works My mouse was working fine up until this morning. Since then my mouse has stopped working. However the red led bottom is still on and it works in Windows on same machine. The keyboard is unaffected. There is not error messages fired at boot time. What can be the possible reason and how can this be solved.\n-- EDIT --\nYesterday I went Out of Space. so I cleared /tmp, /var/tmp. after some googling I saw few guys in some forum clearing /var/cache. So I cleared /var/cache too. and everything went nice even after that.\nNow on morning Its actually gdm is refusing to take any input (not even keyboard Inputs)\nI thought to reinstall gdm. But apt is complaining about missing /var/cache/apt\n\nA: I am not sure however it might get solved by rebuilding /var/cache.\nBut You really donno What file to put. Just Copying from others might not solve the problem untill you know the trigger point (e.g. exactly which folder/file is missing there).\nI've reinstalled hal. and It Started working again. :-)\nsudo apt-get --purge -remove hal\nsudo apt-get install hal\n\nHowever Now I think. just making the following directories manually should work.\n/var/cache/apt\n/var/cache/apt/archives/partial\n/var/cache/debconf\n/var/cache/gdm\n\nand expecially /var/cache/hald\nHowever I am not still sure whether it will work or not without a /var/cache/hald/fdi-cache \nand I don't think its possible to make this one manually. unless you copy from others. However I do still have hope that you don't need to create /var/cache/hald/fdi-cache manually\n\nA: Update the BIOS on the computer. I bet you that's where the problem originates from.\n\nA: If you have too many USB devices plugged in, they may be underpowered. \nAlso there seems to be some (random) bug in modern kernels where a powered usb device confused the kernel and it stops loading up other usb devices.\n\n\n*\n\n*Unplug every USB device\n\n*Boot up to the GDM\n\n*Reconnect your keyboard and mouse\n\n*If needed, try them on different USB ports.\n\n*Give it a few seconds\n\n\nIf this solves your problem, go get yourself a powered USB hub. If you already have a powered USB hub, try removing the power to it, during boot, and connecting the power as soon as the GDM is in front of you.\n", "Q: Sound and sound applet disappeared and won't come back Recently (I don't don't know when, might have been after an update) the sound indicator  disappeared from my panel, and I haven't been getting any sound either. I tried installing the indicator-sound package, but all I got was this error message:\n  The following packages have unmet dependencies:\n  indicator-sound: Depends: libido-0.1-0 (>= 0.1.1) but it is not going to be installed\n  E: Broken packages\n\nSeems to be a bug, but how do I get around it? Could I install an older version of libido? If so, how do I do that?\nEverything had worked fine until a couple days ago, so I'm sure that the package is the problem.\nEDIT:The command $ dpkg --get-selections | grep libido returns the following output:\nlibido-0.1-0                    deinstall\n\n\nOk, that's embarassing. Yesterday I uninstalled and reinstalled the libido package half a dozen times, and the indicator-sound package kept reporting the same error. Today, however, I just installed the libido package and now the indicator-sound package installed with no errors. Maybe the system needed a reboot or something.\n(Should I answer my own question or just wait for a moderator to close it?)\n\nA: Ok, I manage to solve it. I just installed the libido package and now the indicator-sound package installed with no errors. Maybe the system needed a reboot with the package uninstalled or something. If someone's having this problem, you can try:\nsudo apt-get remove libido-0.1-0 \nsudo apt-get remove indicator-sound\n\nRestart your computer (this is the part that seems to have solved it). And then reinstall both packages.\nsudo apt-get install libido-0.1-0 \nsudo apt-get install indicator-sound\n\nIt's worth mentioning that, even after the reboot, the terminal kept reporting error messages when I tried to install  indicator-sound. But after I reinstalled libido manually, the indicator-sound installed without issues.\n", "Q: Alternative desktop managers Gnome is a reasonable desktop manager, but it doesn't seem to match Mac OSX or Windows 7. Are there any alternatives for Ubuntu that focus more on usability? \n\nA: The most common other two used with Ubuntu are KDE and XFCE. Both are available as pre-packaged distributions known as Kubuntu and Xubuntu and both have live CD's available if you just want to try them out. (Of course you are free to download and install them to your existing Ubuntu install if you don't want to start from scratch).\nIf you are looking for something that is closer to windows 7 or OS x then KDE might be worth a look. In my opinion it has a better looking interface than Gnome. It does have it's quirks though and doesn't really have any more of a focus on \"usability\" than gnome does.\nXFCE focuses on simplicity and productivity.\nThere are many others. You can find a partial list and some points of comparison on the wikipedia comparison of X-Window System desktop environments\n\nA: \nbut it doesn't seem to match Mac OSX or Windows 7\n\nI'm not sure that's a valid complaint. Just because something is different, doesn't mean it's less accessible or less usable.\nNeither Gnome, KDE (or many other environments) are trying to be the same as Windows or Mac as they believe there are user experience and accessibility issues with them. They're both trying to be something new that works better.\nGnome plans to move even further away from both Window and Mac in future releases by bringing in an interface called Gnome Shell. You can try this out today if you wish but it's a way off from being complete.\nNow, if you're looking to clone the Windows 7 or OSX interfaces on a Linux computer, that can be done with a bit of modification. Check out a site like gnome-look.\n\nA: There is also the possibility of just adjusting the (gnome)desktop so it looks similar to windows or mac.\n\n\n*\n\n*If you install gnomenu and adjust your compiz settings, you will get a similar experience as in Windows 7.\n\n*You could install cairo dock which looks quite similar to the mac bottom panel\n\n*There is AWN, a dock too, but different than cairo.\n\n*A combination of them all is also possible.\nYou will find them all in launchpad.net\n\nA: If you want to get a Windows 7 look and feel check out this theme: http://gnome-look.org/content/show.php/Win2-7+Pack?content=113264\nReally it's more of a complete make-over, so be sure to read all the instructions carefully!  Even if you don't want it, it will give you insight into changes you can make to not necessarily get the look but get the feel.  The AWN dock with the DockbarX applet is highly recommended as a Gnome Panel replacement.\nGnomenu can replicate the Windows 7 menu, but that's a step backwards imo.  Nautilus Elementary with Gloobus Preview can give you Mac's Quick Look feature.  I've never used a Mac, but I love that feature!  Nautilus Actions can add items your File Manager context menu and Wine can let you install Windows apps like Utorrent.  The Screenlets app will allow you to install desktop widgets.\nThe Global Menu applet will give you your apps' menus in the panel (I'm told this is like Mac). Window Buttons will allow you to have your close, minimize, and maximize buttons in the panel.  With these two applets you can hide your maximized windows' title and menu bars giving you much more vertical space.  (I'm assuming you have CCSM already?!)\nI could go on, but I think that's plenty.  Have fun Google-ing, and here's a few places to start:\nNevermind.  I can't post more than one link because I'm told it might be spam.  Whatever.  Good luck.\nEdit:  I should note that by installing Compiz Config Settings Manager you will get, imo, functionality superior to just about everything, plus cool eyecandy.  There's tiling, window placement, transparency, zoom, Expo, add and arrage virtual desktops, and more.  Compiz makes Ubuntu/Gnome so easy to use that I find it literally HARD to use Windows 7 and only log into it when I have absolutely no choice (which is almost never).  This is just my opinion though.\nI also didn't mention Easystroke, a system wide mouse gesture program available in the repositories, which is fantastic.  You can configure that to move/tile windows, open menus, go back or open new tabs in Firefox/Chrome/Opera, and so on.  And don't forget about the super convenient launcher Gnome-do.\nThe best thing?  All free and available in the repositories.\n\nA: You can install either KDE or Xfce environments easily from an existing ubuntu installation or from their liveCDs.  I will assume you already have a working ubuntu install and want to switch desktops without reinstalling.\nFor a full KDE environment plus KDE applications, install the kubuntu-desktop meta-package from the main repositories.  Kubuntu is focused on being \"friendly\", which might match up better with your usability needs.  Their website is http://kubuntu.org.\nFor a full Xfce environment plus lightweight applications, install the xubuntu-desktop meta-package from the 'universe' repository.  Xubuntu is focused on being fast - their website is http://xubuntu.org .\nThese are official ubuntu packages and use most of the same underlying systems and applications as the standard Ubuntu desktop.  You can install these alternative desktops easily using your package manager/software center by looking for the appropriate package listed above.   Note that kubuntu-desktop in particular will bring in many applications/libraries as dependencies, since it uses the KDE equivalents of a lot of Gnome software (Koffice rather than Evolution, Amarok rather than Banshee, etc).  \n", "Q: System76 using ATI cards in their laptops -- good or bad? I've purchased several System76 desktops and have been pleased with them. They can only be configured with nVidia cards. That's why I was surprised to see that their Pangolin Performance laptop can only be configured with \"ATI Mobility Radeon HD 4570 Graphics with 512MB GDDR2 Memory.\" I'm a little concerned given ATI's historically poor Linux performance. Have things changed that much?\nI contacted System76 and they said they regularly offer both ATI and nVidia on and off, and that ATI cards give more bang for the buck. Really? With Linux?\n\nA: Recent Radeon HD cards have been working very well with the open source drivers. I have a multiscreen setup even! \nI would not hesitate to recommend the Desktop equivalents, so I would not be worried about using the laptop mobility versions, especially if System76 have tested them.\n\nA: Your information is quite old. After AMD bought ATI, the situation changed quite a bit. However this is really only for newer cards, R500 & up. AMD have been releasing documentation without an NDA.\nflgrx is still there, and supposedly better. I don't know; I don't use it. I happen to like the Free Drivers.\nFree Drivers, I hear that R300 is still supposedly the best supported chipset, but in the last two releases (9.10 & 10.04) performance really went downhill for me in Ubuntu, but that might be that the drivers were reverse engineered instead of being made with actual documentation.\n\nA: I have ATI Mobility Radeon HD 4570 on my Asus K50AB laptop, and i am satisfied with performances with proprietary driver.\nBut only after i added custom PPA to fix fix maximize delay/lag\nAnd after fixing video tearing:  See this article from #ubuntuRoot\nFinal conclusion: ATI should make better drivers.\n\nA: There's a discussion of this over at the forums with isantop from System76.\nhttp://ubuntuforums.org/showthread.php?t=1562742\n", "Q: Grub no longer boots after kernel update (second time now) Some weeks ago I configured a dual boot laptop to run Xubuntu 10.4 on the third partition of my disk (i.e. I had to set the installation location manually). Everything was fine until I had installed the bunch of automatic updates (including a new kernel), which were discovered after Wifi was finally working. After rebooting, Grub didn't boot into Xubuntu anymore (which it did several times before), but just showed a prompt. I managed to get the system repaired using a live CD and a good hour of Internet reading.\nFor some weeks everything was fine, including automatic updates. Yesterday I got a new kernel through automatic updates. And guess what? The laptop refused to boot afterwards.\nTo me it looks like every kernel update makes my system unbootable. How can I prevent this besides the obvious \"Don't install updates\"? Is there anything else I should inspect or monitor on that system? Or are my conclusions about the kernel update completely wrong and I should look for something else causing these symptomes?\nEDIT: Some more details as asked in the comments: I didn't start Windows between the update and the crash, so for me it seems to be related to Xubuntu only. Grub is Grub2 (version 1.98something). /boot/grub/grub.cfg looks like this:\n\n#\n# DO NOT EDIT THIS FILE\n#\n# It is automatically generated by /usr/sbin/grub-mkconfig using templates\n# from /etc/grub.d and settings from /etc/default/grub\n#\n\n### BEGIN /etc/grub.d/00_header ###\nif [ -s $prefix/grubenv ]; then\n  load_env\nfi\nset default=\"0\"\nif [ ${prev_saved_entry} ]; then\n  set saved_entry=${prev_saved_entry}\n  save_env saved_entry\n  set prev_saved_entry=\n  save_env prev_saved_entry\n  set boot_once=true\nfi\n\nfunction savedefault {\n  if [ -z ${boot_once} ]; then\n    saved_entry=${chosen}\n    save_env saved_entry\n  fi\n}\n\nfunction recordfail {\n  set recordfail=1\n  if [ -n ${have_grubenv} ]; then if [ -z ${boot_once} ]; then save_env recordfail; fi; fi\n}\ninsmod ext2\nset root='(hd0,5)'\nsearch --no-floppy --fs-uuid --set c1550ae8-66af-414c-874d-15cb43176ba5\nif loadfont /usr/share/grub/unicode.pf2 ; then\n  set gfxmode=640x480\n  insmod gfxterm\n  insmod vbe\n  if terminal_output gfxterm ; then true ; else\n    # For backward compatibility with versions of terminal.mod that don't\n    # understand terminal_output\n    terminal gfxterm\n  fi\nfi\ninsmod ext2\nset root='(hd0,5)'\nsearch --no-floppy --fs-uuid --set c1550ae8-66af-414c-874d-15cb43176ba5\nset locale_dir=($root)/boot/grub/locale\nset lang=de\ninsmod gettext\nif [ ${recordfail} = 1 ]; then\n  set timeout=-1\nelse\n  set timeout=10\nfi\n### END /etc/grub.d/00_header ###\n\n### BEGIN /etc/grub.d/05_debian_theme ###\nset menu_color_normal=white/black\nset menu_color_highlight=black/light-gray\n### END /etc/grub.d/05_debian_theme ###\n\n### BEGIN /etc/grub.d/10_linux ###\nmenuentry 'Ubuntu, mit Linux 2.6.32-24-generic' --class ubuntu --class gnu-linux --class gnu --class os {\n    recordfail\n    insmod ext2\n    set root='(hd0,5)'\n    search --no-floppy --fs-uuid --set c1550ae8-66af-414c-874d-15cb43176ba5\n    linux   /boot/vmlinuz-2.6.32-24-generic root=UUID=c1550ae8-66af-414c-874d-15cb43176ba5 ro   quiet splash\n    initrd  /boot/initrd.img-2.6.32-24-generic\n}\nmenuentry 'Ubuntu, mit Linux 2.6.32-24-generic (Wiederherstellungsmodus)' --class ubuntu --class gnu-linux --class gnu --class os {\n    recordfail\n    insmod ext2\n    set root='(hd0,5)'\n    search --no-floppy --fs-uuid --set c1550ae8-66af-414c-874d-15cb43176ba5\n    echo    'Linux 2.6.32-24-generic wird geladen …'\n    linux   /boot/vmlinuz-2.6.32-24-generic root=UUID=c1550ae8-66af-414c-874d-15cb43176ba5 ro single \n    echo    'Initiale Ramdisk wird geladen …'\n    initrd  /boot/initrd.img-2.6.32-24-generic\n}\nmenuentry 'Ubuntu, mit Linux 2.6.32-21-generic' --class ubuntu --class gnu-linux --class gnu --class os {\n    recordfail\n    insmod ext2\n    set root='(hd0,5)'\n    search --no-floppy --fs-uuid --set c1550ae8-66af-414c-874d-15cb43176ba5\n    linux   /boot/vmlinuz-2.6.32-21-generic root=UUID=c1550ae8-66af-414c-874d-15cb43176ba5 ro   quiet splash\n    initrd  /boot/initrd.img-2.6.32-21-generic\n}\nmenuentry 'Ubuntu, mit Linux 2.6.32-21-generic (Wiederherstellungsmodus)' --class ubuntu --class gnu-linux --class gnu --class os {\n    recordfail\n    insmod ext2\n    set root='(hd0,5)'\n    search --no-floppy --fs-uuid --set c1550ae8-66af-414c-874d-15cb43176ba5\n    echo    'Linux 2.6.32-21-generic wird geladen …'\n    linux   /boot/vmlinuz-2.6.32-21-generic root=UUID=c1550ae8-66af-414c-874d-15cb43176ba5 ro single \n    echo    'Initiale Ramdisk wird geladen …'\n    initrd  /boot/initrd.img-2.6.32-21-generic\n}\n### END /etc/grub.d/10_linux ###\n\n### BEGIN /etc/grub.d/20_memtest86+ ###\nmenuentry \"Memory test (memtest86+)\" {\n    insmod ext2\n    set root='(hd0,5)'\n    search --no-floppy --fs-uuid --set c1550ae8-66af-414c-874d-15cb43176ba5\n    linux16 /boot/memtest86+.bin\n}\nmenuentry \"Memory test (memtest86+, serial console 115200)\" {\n    insmod ext2\n    set root='(hd0,5)'\n    search --no-floppy --fs-uuid --set c1550ae8-66af-414c-874d-15cb43176ba5\n    linux16 /boot/memtest86+.bin console=ttyS0,115200n8\n}\n### END /etc/grub.d/20_memtest86+ ###\n\n### BEGIN /etc/grub.d/30_os-prober ###\nmenuentry \"Microsoft Windows XP Professional (on /dev/sda1)\" {\n    insmod ntfs\n    set root='(hd0,1)'\n    search --no-floppy --fs-uuid --set 883cb1b73cb1a09c\n    drivemap -s (hd0) ${root}\n    chainloader +1\n}\n### END /etc/grub.d/30_os-prober ###\n\n### BEGIN /etc/grub.d/40_custom ###\n# This file provides an easy way to add custom menu entries.  Simply type the\n# menu entries you want to add after this comment.  Be careful not to change\n# the 'exec tail' line above.\n### END /etc/grub.d/40_custom ###\n\n\nA: I had this happen on a new Ubuntu 12.10 (desktop) install on a laptop. The system booted fine after the initial install, and then after getting a kernel update (from the initial set of updates), it would go through the GRUB menu, boot the kernel, and then a black screen, with no passphrase prompt.\nIt seems the problem is related to video. What I've found consistently fixes it, but is less pretty, is to edit /etc/default/grub, and remove the quiet and splash options from GRUB_CMDLINE_LINUX_DEFAULT, and running update-grub. If you already can't boot, then when the GRUB menu comes up, press E to edit your GRUB command line and remove those options, then ctrl-X to boot.\nThis bug suggests trying plymouth:force-drm as a GRUB boot option, which makes it not use the kernel framebuffer driver. This also seemed to work, except it still didn't use the splash screen, and booted in text mode.\nFor what it's worth, my laptop has two graphic chipsets: Intel (using the i915 kernel driver) and Nvidia GTX680M (still working on making this work accelerated). It may be the presence of two different graphics devices is making the boot non-deterministic.\n\nA: It grub doesn't boot, it means that either it's configuration is corrupted, or that its code has been overwritten. \nThere are possible reasons for this:\n\n\n*\n\n*certain windows software overwrites hidden (random) space on your hard drive. They do this for DRM reasons. However, I assume that the issue pops up immediately after upgrading the kernel, and then restarting, so this likely isn't it.\n\n*you don't have any free space left on your ubuntu partition (or at least the one holding grub). Make sure you do. I'm putting my money on this one, for now.\n\n*grub auto re-configures itself every time you install a new kernel. Try to reconfigure it manually and see if there is any error output. Run 'sudo update-grub' in a terminal to do this. You'll have to type your password and it should output some stuff.\n\n*you say it's the third partition of your disk; is it a removable disk? Like an external hard-drive or an internal hard-drive? Because it that case the device numbering may be different from installation time.\n\nA: Everytime there is a new kernel added as part of software update, the grub configuration is updated. So the information Javier Rivera requested is very important. The relevant config file is /boot/grub/grub.cfg - in case you don't find it then look for /boot/grub/menu.lst\nAlso, you can run update-grub and check if you get any errors - pls post the result of that also. If, however, update-grub is successful, then a workaround would be to manually run this everytime your updates include a new kernel.\n", "Q: Does Firefox have something similar to ActiveX in terms of security vulnerabilities? People always say that Linux is more secure than Windows. The main reason seems to be the general system design philosophy and the fact that users are users and not root.\nOne main security concern when using Windows and Internet Explorer seem to be ActiveX. Every few days I read about another kind of exploit using ActiveX, and almost always the workaround is to deactivate ActiveX. I read that so often I wonder why people bother to activate ActiveX at all. (One reason might be that the name contains \"active\"; another might be the windows update function.)\nUsing Ubuntu and Firefox, I always feel so safe when reading about the ActiveX exploits. I know that there are many other security vulnerabilities that use JavaScript and/or Adobe Flash, but as far as I understand those kind of security vulnerabilities can only do as much damage as my user rights allow. Of course that doesn't help much when the malware wants to destroy all of my data - but most malware today only wants to use my PC as a botnet drone and so is not interested in destroying my data.\nSo the question again: does Firefox running under Ubuntu have something similar to ActiveX, in terms of security vulnerabilities?\nAnother question which may be identical: can a security vulnerability involving Adobe Flash and/or JavaScript be \"easily\" exploited to do as much damage as an ActiveX exploit?\nWhen I say \"easy\" I mean that the attack does not need to exploit another component of the system to elevate user rights. For example, an exploit involving Adobe Flash will gain access to my PC using my user rights, and then proceed to exploit some known vulnerability in X to gain root access. That is not \"easy\".\n\nA: \ndoes firefox under ubuntu has something similar to activeX, in terms of security vulnerability?\n\n‘ActiveX’ can be considered in two parts, the object model and the installation method. Firefox has something similar—and cross-platform compatible, Ubuntu or other—for both.\nThe object model of ActiveX is Microsoft COM; Firefox's equivalent is XPCOM. Many other Windows features and applications that are nothing to do with web browsing use MS COM, and there have traditionally been endless problems where COM controls that were not written for secure web usage were nonetheless available to web pages. This caused many compromises. Firefox is better off here as XPCOM is not shared with the rest of the system. Newer versions of IE have better controls for mitigating what sites are allowed to use what controls.\n(As a side-issue, because many add-ons for Firefox are themselves written in JavaScript, a high-level scripting language, they are often more secure from buffer overflow and string handling errors than extensions for IE which are commonly written in C[++].)\nThe control-downloader part of ActiveX has also been cleaned up a bit since the bad old days when anything in the My Computer zone could install any software it liked, and aggressive loader scripts could trap you in an alert loop until you agreed to approve the ActiveX prompt. Firefox's equivalent, XPInstall, behaves largely similarly, with the ‘information bar’ on all but Mozilla's sites by default and a suitable warning/prompt before installation.\nThere is another built-in way you can compromise yourself in Mozilla: signed scripts. I have never seen this actually used, and certainly there'll be another warning window appear before a script gains extra rights, but it kind of worries me that this is available to web pages at all.\n\nfor example an exploit through flash will gain access to my pc under my user rights\n\nYes, the majority of web exploits today occur in plugins. Adobe Reader, Java(*) and QuickTime are the most popular/vulnerable. IMO: get rid of those, and use FlashBlock to only show Flash when you want it.\n(*: and Java's dialogues before it lets you give up all security to some untrusted applet is a bit bare too.)\nUbuntu gives you some questionable plugins by default, in particular a media player plugin that will make every vulnerability in any of your media codecs exploitable through the web (similar to the Windows Media Player plugin, only potentially with many more formats). Whilst I have yet to meet an exploit targeting Linux like this, that's really only security through obscurity.\nNote that ActiveX itself is no different. A web browser compromise based on ActiveX still only gives user-level access; it's only because prior to Vista everyone habitually ran everything as Administrator that this escalated to a full-on rooting.\n\nand then follow to exploit some known vulnerability in X to gain root rights. that is not \"easy\".\n\nMaybe, maybe not. But I think you'll find the damage some malware can do from even a normal user account is quite bad enough. Copy all your personal data, observe your keypresses, delete all your documents...\n\nA: It depends on the nature of the vulnerability.  Sometimes you're \"lucky\" and the vulnerability \"just\" allows for some limited disclosure, but often the vulnerabilities allow for arbitrary code execution.  At that point, you're in deep doo-dah, just as deep as ActiveX problems.  And those holes can be in the handling for image files (malicious images), or for sound, or almost anything else.\nActiveX was worse because it provided a way for code writers to declare \"If this is installed, it's safe to be referenced from a web-page\" and a lot of coders turned that on without understanding the implications, so there were a lot of targets and it would be easy to get out.  But you have just as much exposure from bad handling of weird numbers in image files.  It's just that the image-file problems are fixed by updating the browser.\nThe only defense against any of this is to use sandboxing, which limits what a process running as a user can do.  OpenBSD pioneered making this popular with privilege separation of various daemons (most notably OpenSSH, so you're using this on Ubuntu now).  Chrome popularised this for web-browsers, but only has sandboxing on some platforms.  Ironically perhaps, for a while you were probably safer with Chrome on Windows than any graphical browser on Linux.  Fortunately, this is changing.  I believe that some partial protection is in the Linux releases now.  The Capsicum project showed how this could be done more fully on FreeBSD (with a capability system) and hopefully at some point the Linux kernel devs will stop fighting over which security model is best and just go with something that becomes near-universally available for web-browsers to rely upon, rather than the blunt hammer that is the suid wrapper which allows for chroot pseudo-sandboxes.\nhttp://www.cl.cam.ac.uk/research/security/capsicum/ is good if you want to explore capability systems for sandboxes and see how things might get better.\n\nA: AFAIK an ActiveX exploit can't do harm outside your user's rights either (without using other exploits, as you indicate).  The main problem on Windows was that almost everybody was working as Administrator most of the time...\n\nA: I just want to mention that Linux is theoretically less safe than Windows 7, which has some cool security features.\nThe reason there are no Linux Viruses is the same why there are almost no commercial Linux games: the producers go with the masses, and the masses use Windows. \nSo the most secure way is to use alternative products (like Firefox was some years ago, today Firefox exploits are used quite often).\nNow to answer your questions:\nAs far as I know ActiveX-Exploits don't concern Firefox.\nI feel quite safe browsing with Linux and Firefox, however using Opera could be more secure as Opera is much less popular.\nWhat you should consider is having a strong Password if your SSH is open to the Internet as there are lots of scanners that try to hack your ssh to install strange things on your PC (disable direct root access in /etc/ssh/sshd_config).\nI think most other attacks are specific to one user, so if you don't have any company secrets or enemies in general your Computer should be quite safe.\n", "Q: Magick Jack or equivalent on Ubuntu I hate to have the Windows PC just for the sake of running my Magick Jack on, Have long since left Windows for Ubuntu for all my home PC's. \nHas anyone figured out, how to get this or an alternative working on Ubuntu?\n\nA: Based on the Wikipedia article this is a VoIP solution that doesn't support linux (and apparently it also got lots of criticism about privacy issues).\nMaybe you can switch to another VoIP provider indstead?  Most VoIP providers that use SIP (the standard protocol for VoIP) work fine with open source applications used in Ubuntu, and there are also hardware-based SIP solutions.  (And of course there is also Skype.)\n\nA: According to their \"tech chat\" MagicJack were planning to bring out Linux support in Q1 of this year. Until that happens, tt seems like your best bet is to use a virtual machine running Windows - check out this mailing list post for details of how somebody else got it working.\n", "Q: gnome-do style keyboard shortcuts in Unity Will the Unity launcher in 10.10 UNE have gnome-do style keyboard shortcuts?\ni.e. Super+Spacebar for quick search and application launch\nIf not, can it be customized to allow this?\n\nA: Edit: As of Ubuntu 11.04, this answer is wrong.  See What are Unity's keyboard and mouse shortcuts? for a large number of keyboard shortcuts, including an Alt+F2 launcher.\nAs far as I'm aware this is currently not possible.\nOne of the requirements for switching to Unity on the desktop is that it needs accessibility work.  A part of this work will be to ensure that Unity can be driven by the keyboard, so I would expect that this will be possible in the Ubuntu 11.04 release.\nWhat I use for Do-style keyboard shortcuts in Unity is Do; it's a great complement to the Unity shell.  The main problem is that Unity eats win keypresses, so the default Do shortcut is not available.  It's easy to change the Do keybinding to something else, though.\n\nA: System>Preferences>Keyboard Shorcuts>Show the panel's \"Run Application\" dialog box\nThis launches gnome-keybinding-properties.  From there you should be able to change the default, alt+f2 to alt+space.\n\nA: Alt + F2 is not working 'cos is a function of gnome-panel, Unity uses is proper panel. Super enable numerical shortcuts to sidebar elements. That's all for now.\n\nA: Yes, but not out of the box. After upgrading to Ubuntu Netbook 10.10, install gnome-do and then modify its default shortcut key.  The windows key is hijacked by Unity, so the default gnome-do run shortcut Win-Space won't work. Change it to something else like Alt-Space and you'll be good to go with a slick run dialog!\n\nA: You can, for now, bind the keyboard shortcut Alt+F2 to the command \"unity --show\" to bridge the period of no keyboard shortcuts being available. Far from ideal, but workable in the meantime.\n", "Q: How do I get Evolution to apply filters automatically? I am using an IMAP email account. I created a filter in Evolution to move email from a specific high-volume source into a particular folder, to keep the Inbox uncluttered. I noticed that incoming emails are coming straight into the Inbox. If I select Messages->Apply Filters, then they are moved into the folder. Is there an option to make this filtering apply automatically to all new emails?\n\nA: There is a setting in the account configuration somewhere where you can switch filtering on/off for that account.  Maybe check if it's on?\n", "Q: Installing Ubuntu on Acer Veriton L460 with AR5001 wifi card I'm going to try and set up wifi on a computer with Ubuntu installed where it doesn't work out of the box.  The computer is an Acer Veriton L460 with a AR5001 wifi card.  There are two options as far as I know:\n\n*\n\n*Use MadWifi\n\n*Use ndiswrapper\n\nThere are steps for using Madwifi here:\nhttp://ubuntuforums.org/showthread.php?t=1305514\nSome hints for ndiswrapper are here:\nhttp://ubuntuforums.org/archive/index.php/t-240280.html.\nThe driver seems to be available here: http://www.netgate.com/support/Drivers/STA_24071bin/Install/.\nSo my questions are, are there any other types of ways to do this?  Are there any positives and negatives for chosing MadWifi or ndiswrapper?  Has anyone had success installing this particular wifi card in ubuntu, and if so what did you use?\n\nA: If you're using a recent version of Ubuntu, the built-in ath5k driver should kick in and work. If it doesn't, it might be getting locked out by older ath drivers.\nClick here to see how to block the old drivers.\nath5k will generally deliver better results than madwifi. And madwifi is better than ndiswrapper IMO.\n\nA: In addition to what Oli says, the kernel team maintains newer versions of wireless drivers for you, which could provide better support. You can access them by installing the linux-backports-modules-lucid package.\n", "Q: Non-ASCII characters show as boxes in textbox of VB.Net application under Mono I'm running Ubuntu 9.10 (can't upgrade due to some applications being incompatible with later versions), with all updates installed.\nA colleague has written a VB.Net application which seems to run correctly under Mono, however there is an issue with characters in text boxes: if they are not strictly ASCII, they show as boxes (the typical Windows replacement character).\nAt first I thought it was an issue with Greek characters (which we use); however, I attempted to insert some accented western characters (like é, which is in the typical western 1252 Windows codepage), and these too showed up as boxes too, so it's not strictly an issue with Greek.\nI attempted to type Greek in a textbox: the word «Δοκιμή» (test). I then selected what I typed, pressed Ctrl-C, switched to a native text editor and pressed Ctrl-V. The result was “ÎÎ¿ÎºÎ¹Î¼Î®”, which is the greek word pretty messed up (think UTF-8 interpreted as Latin-1; I work a lot with Unicode, so it's easy to recognise such stuff :) However, if you want to verify, start a Python interpreter in a UTF-8 capable terminal and try:\n>>> a=\"ÎÎ¿ÎºÎ¹Î¼Î®\"\n>>> print a.decode(\"utf8\").encode(\"latin1\").decode(\"utf8\")\nΔοκιμή\n\nwhich is what I typed).\nNow, the application also embeds an Internet Explorer control; Mono does well emulating it (I think it uses a Gecko engine), and in a textbox inside that IE control, I can type fine and see any non-ASCII character I want.\nI would like to know whether there is an issue with my mono configuration or even if it's a known bug; VB.Net is supposedly Unicode-capable, but I don't know anything about the Unicode-capability of the standard controls it uses.\nSo, if you can help me, please advise: what can I do on the Ubuntu side to remedy the situation?\n\nA: I assume the VB.NET application is using Microsoft's .NET GUI stuff and not the Gtk or Qt bindings for .NET?  Just guessing, but maybe the problem is related to the fact that Windows (and maybe .NET too?) uses UCS-2 (or UTF-16?) and (most) Xorg applications use/expect UTF-8?\nAnyway, looks like there is a bug somewhere, and like you say, something gets converted one time too many...\n", "Q: Is there a way to turn a VirtualBox image into an .iso? I'm in a bit of a pickle here; my main computer has trouble with the Nouveau open source driver for NVIDIA cards. As this problem is seemingly quite complicated, I was wondering if there was a way to add/install the NVIDIA driver from Jockey onto a Ubuntu/Kubuntu .iso file.\nOne possible way could be VirtualBox, but I don't even know if a VirtualBox image can be turned into an installable ISO.\nI know Linux Mint comes prebundled with it, but I'd much prefer to stick to the Ubuntu line (what can I say? I happen to like appindicators and polish! :P)\n\nA: I think you'd be able to use Remastersys inside of a virtual machine to make an installer for that system.\n", "Q: How do I create a udev rule for my logitech webcam With my webcam plugged in at boot, it always defaults to /dev/video0 and my TV-card defaults to /dev/video1. Tvtime defaults is using /dev/video0. I know that I can run Tvtime with the --device option and force it to switch to /dev/video1, but if i happen to have my webcam unplugged when I boot, the TV-card becomes video0.\nThis is very inconvenient, as I have tried to write a \"udev\" rule, to make the webcam video5 but have not been able to get it to work.\nThis is the rule I tried to use: \nSUBSYSTEM==\"video4linux\", BUS==\"usb\", SYSFS{idvendor}==\"046d\", SYSFS{idProduct}==\"0807\", NAME=\"video5\"\n\nI saved this in /etc/udev/rules.d/75-mystuff.rules, and also tried with a lower number, 15-mystuff.rules, which didn't work.\nI am using Ubuntu 10.04 64bit. Any help to resolve this will be very much appreciated.\nThanks\n\nA: Jan Claesys idea is likely more practical, but...\nSYSFS syntax is deprecated or going to be deprecated. You should use ATTRS. The rule should look like:\nSUBSYSTEM==\"video4linux\", BUS==\"usb\", ATTRS{vendor}==\"0x046d\", ATTRS{device}==\"0x0807\", NAME=\"video5\"\nNote the 0x to denote a hexadecimal value.\nI can't test the rule on my end, but I expect it to work.\n\nA: If using the --device option is not really a problem, you can probably use the link to the device under /dev/v4l/by-id/ instead.  I think that one should always be the same...\n", "Q: How do I launch a remote firefox window via SSH? When I SSH to a remote box\n$ ssh -X remotebox\n\nthen start firefox on the remote box\nremotebox$ firefox\n\nand I have firefox running on my local machine, a local firefox window will open. no firefox process is running on the remote box.\nIf firefox is not running on my local machine then a remote firefox window will open.\nWhy is it opening a local firefox window? How can i prevent that?\n\nHere some more information of my local system.\nLinux lesmana-laptop 2.6.32-24-generic #42-Ubuntu SMP Fri Aug 20 14:24:04 UTC 2010 i686 GNU/Linux\n\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 10.04.1 LTS\nRelease:    10.04\nCodename:   lucid\n\nDISPLAY=:0.0\n\nMozilla Firefox 3.6.8, Copyright (c) 1998 - 2010 mozilla.org\n\nInformation of remotebox.\nLinux dxray 2.6.22.19-0.4-default #1 SMP 2009-08-14 02:09:16 +0200 x86_64 x86_64 x86_64 GNU/Linux\n\nLSB Version:    core-2.0-noarch:core-3.0-noarch:core-2.0-x86_64:core-3.0-x86_64:desktop-3.1-amd64:desktop-3.1-noarch:graphics-2.0-amd64:graphics-2.0-noarch:graphics-3.1-amd64:graphics-3.1-noarch\nDistributor ID: SUSE LINUX\nDescription:    openSUSE 10.3 (X86-64)\nRelease:    10.3\nCodename:   n/a\n\nDISPLAY=localhost:15.0\n\nMozilla Firefox 3.0.14, Copyright (c) 1998 - 2009 mozilla.org\n\nThe following command starts a remote firefox session with a remote firefox window.\nremotebox$ firefox -no-remote\n\nThe following command produces a brief delay, then drops back to prompt and a local firefox window pops up. No firefox process running on the remotebox.\nremotebox$ firefox\n\n\nInformation of remotebox2.\nLinux marvin 2.6.31-22-generic #60-Ubuntu SMP Thu May 27 00:22:23 UTC 2010 i686 GNU/Linux\n\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 9.10\nRelease:    9.10\nCodename:   karmic\n\nDISPLAY=localhost:11.0\n\nMozilla Firefox 3.6.8, Copyright (c) 1998 - 2010 mozilla.org\n\nThe following command on remotebox2 starts a remote firefox session as expected.\nremotebox2$ firefox\n\nI do not know why firefox on remotebox2 starts a remote session instead of a local session.\n\nA: besides firefox -no-remote  another parameter is firefox -no-xshm which reveals the technique used to make it work.\nX11 shared memory is an interprocess communication technique which can be used by all applications connected to a given x server session. It can be used to perform drag & drop, and other kind of desktop interaction.\nIt can be (and is) used also to implement \"open once\" applications, in order to reduce the footprint (or the number of windows).\nSince the X11 protocol is network transparent the \"shared memory\" is extended also to remote X11 clients.\n\nA: You can try this, when you connected to machine (ssh user@host; note: without -X option), first type the follow command \nexport DISPLAY=:0 \n\nthis would change the default display to that of the current desktop screen. And then just type \nfirefox\n\nto have firefox spawned on the desktop window.  Ensure that you have logged into the desktop, without which (no logins) you will get the following error; \nfirefox: cannot connect to X server :0\n\nThis method would work for locked desktops as well.   Please ensure that you have logged in on the desktop and the ssh shell with the same username.\nWhen there are multiple desktop sessions, each session is identified by a different number as :0, :1, :2, etc.  \n\nA: Simple remote browsing\nIf you'd like to browse the web locally as if you were sitting in front of a remote box:\n$ ssh -X username@remote.example.com\n\nthen run Firefox inside the remote terminal session:\n$ firefox https://test-ipv6.com/\n\nNotice the usage of -X flag in the ssh command.\nYou can also do both steps in a single go, like shown below:\n$ ssh -X username@remote.example.com firefox http://test-ipv6.com/\n\nTunnelling a remote IP:port\nIf you have an application running remotely which exposes some sort of web frontend, you will be interested on exposing the remote IP:port as if it is a local IP:port. In this case, the -L option defines a correspondence between localhost:localport and remotehost:remoteport, as shown in the pseudo command below:\nssh -L localhost:localport:remotehost:remoteport remoteuser@remotehost\n\nFor example:\n$ ssh -L 127.0.0.1:18080:internal.example.com:8080 username@router.example.com\n\nthen run Firefox locally:\n$ firefox http://127.0.0.1:18080\n\nIn the example above, you are connecting via SSH onto username@router.example.com, and you are interested on a web frontend exposed at internal.example.com:8080. This remote IP:port will be exposed locally at 127.0.0.1:18080.\n\nA: None of the other solutions worked for me, so this was after a little bit of searching on other sites.\nYou need to run firefox in a separate process the same way you would if you were doing it all on the local machine.  Use the profile manager to create a new profile as follows.\nexport MOZ_NO_REMOTE=1\nfirefox -ProfileManager\n\nTo keep things consistent, I decided to name each new profile on the external machine the same as the hostname.\n\nA: Try firefox -no-remote\n\nA: Note, I did dome digging as this was bugging me and you can also just add:\nMOZ_NO_REMOTE=1\nexport MOZ_NO_REMOTE\n\nto your profile.\n\nA: I'll just add what worked for me. Simply using firefox -no-remote failed with the usual error\nError: GDK_BACKEND does not match available displays\n\nHowever, the following worked:\nssh -Y user@host\nfirefox -no-remote\n\nThe -Y option enables trusted X11 forwarding. Trusted X11 forwardings are not subjected to the X11 SECURITY extension controls. You could consider adding -C option to ssh command for enabling compression as well.\n", "Q: Connecting to VPN prevents access to normal web sites I have Ubuntu 10.04 installed with OpenVPN, and when I connect to a VPN, http access to non VPN sites stops working, until I close the VPN connection. To be more specific, both Chrome and Firefox stop being able to load sites like google.com. Sites on my companies intranet are accessible, as well as pages from localhost.\nI have asked the Ubuntu gurus at my company, and they can't fix the problem. I have no proxies set up, and the VPN connection uses Automatic VPN with no routes.\n\nA: I recently had this same problem.  \nFirst question is: Can you ping the sites?\nSecond question: If you can, what packet size can you ping up to \"ping -s 1300 www.google.com\"\nFor me it was to do with the MTU and the fact that the VPN was not correctly detecting the MTU size and at the same time not allowing fragmentation.\nnetwork manager in 10.04 has these values hard-coded.\nI found a bug about it, it has a patch but I don't think its going to be in 10.04:\nhttps://bugs.launchpad.net/ubuntu/+source/network-manager-openvpn/+bug/112248\nI manually compiled network manager, set the VPN MTU to 1300 and the mss bit on and the whole thing worked again.\n\nA: As mentioned before, this seems to be a routing issue. I know that some other VPN client/server are imposing a blocking mode, so that everything actually goes through the VPN. What you want is know as \"Split Mode\",where part of the routing is going through the virtual adapter, forwarded as encrypted, and the rest goes as usual. Since there seems to be more flexibility under Linux, you should be able (as root) to view your actual routes and change those, or change them in the configuration. \nNote that some servers may be able to FORCE a routing to the server, blocking any other route. This may be based on thepolicy and configuration of the VPN server. I use OpenVPN to access a restricted networking in Ottawa for ethical hacking, and the addressing is using non-routable addresses, so the routing is for a specific netmask only. Once I am connected, I can still connect to gmail.com to retrieve my email, while having access to the protected network.\nOne of the reeasons to do this on VPN is that some organizations do not want to have split connections to avoid infomration leaks that could happen, should ouy have a trojan that could spy on you.\n", "Q: Multiple network connections, where does traffic get routed through? My thinkpad has two network interfaces, one wired and one wireless. Both interfaces can be connected to a router which in turn is connected to the Internet.\nIf both interfaces are connected, are both interfaces used simultaneously or just one at a time. How can I tell which interface is used?\n\nA: Network interfaces have a \"metric\" value. If multiple interfaces can reach to the gateway, the one with the smallest metric will be used.\nYou can try typing netstat -r at the command line to have a look at that.\nifconfig will give the metric for each interface as well.\n\nA: I activated my wired eth0 and wifi eth2 with network manager (both dhcp):\n\n$ route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.1.0     0.0.0.0         255.255.255.0   U     1      0        0 eth0\n192.168.1.0     0.0.0.0         255.255.255.0   U     2      0        0 eth2\n169.254.0.0     0.0.0.0         255.255.0.0     U     1000   0        0 eth0\n0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 eth0\n\ntcpdump -n -i eth0 shows traffic, while tcpdump -n -i eth2 doesn't.\nSo let's try to reorder the interfaces in the routing table:\n\nsudo route del -net 192.168.1.0/24 dev eth2\nsudo route add -net 192.168.1.0/24 dev eth2\nsudo route -n add default gw 192.168.1.1 dev eth2\n\nNow the routing table is:\n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0 eth2\n192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0 eth0\n169.254.0.0     0.0.0.0         255.255.0.0     U     1000   0        0 eth0\n0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 eth2\n0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 eth0\n\nnow tcpdump shows all the traffic going through the eth2 interface.\n", "Q: Problems with SCID I've recently installed scid from ubuntu repositorys. I've met with 2 problems.\n1) After install ; there isn't any shortcut made to run program; so I have to either run it from console or make my own shortcut.My experience so far was that shortcut is made during install.\n2) I can't change width of gui after starting it; only length.\n\nA: 1.\nMenu options aren't \"shortcuts\", they are based on special *.desktop files (that also specify the document types it can open and other information about an application).  It seems like no *.desktop file is provided for scid (or it doesn't include the necessary info for a menu item) and as a result the menu system doesn't know about it.\nIf you want a menu item to be shown automaticly after the install, the best you can do is file a bug about it, and if you like to help you can also provide a working *.desktop file, or even better a debdiff, as an attachment to the bug report.  Also, asking the upstream author to provide a *.desktop file would help for the future.\n(If you want to know how to create a *.desktop file and/or a debdiff, maybe ask separate questions about that; that way they will be easier to find in the future.)\n2.\nThat sounds like a limitation that the program author is responsible for.  You can try to contact the author and ask if he/she wants to change it (or why not).\n", "Q: No Alt+F2 in Ubuntu Netbook 10.10? I am stumped. I upgraded from 10.04 to 10.10 Beta 3 and for some reason I can't get Alt-F2 to do anything. Is this a known bug or am I just not doing the right thing?\n\nA: It is a known bug: https://bugs.launchpad.net/ubuntu/+source/gtk+2.0/+bug/398826\n\nA: As a workaround you could install gnome-do. \napt://gnome-do\nIf you run this program, you can press Meta+Space, and then type in a command.\nThis will accept the same commands as the ALT+F2 dialog, and more.\n\nA: This is a known limitation of the new Unity shell. The bug to track is here: https://bugs.launchpad.net/unity/+bug/580295\n\nA: Like the others said, Alt-F2 is gone in netbook-edition 10.10 because of the switch to Unity.  And as other suggested, gnome-do is a good replacement.  \nHowever, there is one more important step to make it work.  The default keyboard shortcut for the Gnome-do menu, Super + Spacebar (aka Win key + space), won't work because Unity grabs use of the Super key.  SO, after installing gnome-do you'll need to modify this.  You can do this by running gnome-do from a terminal and using the drop down preference menu to modify the shortcut.  I like Ctl Alt Space.\n\nA: There shouldn't need to be a workround if this is going to be used as a default. More forward thinking from Canonical it seems is needed. \n", "Q: What's happening with windicators? Will they be available in 10.10 or not? \n\nA: They will not be included in Ubuntu 10.10. There's nothing about Windicators in the Blueprints for Maverick.\nFrom a developer Q&A:\n\n[20:36]   QUESTION: ok, giving you a break from Compiz, what can you tell us about the windicators, and the new decoraters? Suggestion if I may, I love the new theme but if I could adjust the window border/header to fit a darker theme that would be awesome\n  [20:36]  thanks ;-)\n  [20:37]  we do plan to keep working on gtk changes for csd\n  [20:37]  client side decoration\n  [20:37]  it means it will gtk drawing its decorations directly\n  [20:37]  rather than compiz\n  [20:38]  but that's quite some work to do and we will need to think about non gtk softwares\n  [20:38]  so while this work continue it will not likely go in 10.10\n  [20:38]  the changes are often discussed on the ayatana list though\n  [20:38]  so feel free to join them to discuss it with them\n\nIn other words, there are complications that will take more time to work out for differing systems.\n\nA: Windicators were pushed back to 11.04.\nThat's juts taken from a forum post but we're past the feature freeze now. Assuming the design team aren't going to have a repeat of the button-side fiasco, it's just bug-fixing herein.\n\nA: There are a few technical hurdles (client side decoration must be implemented first), etc.\nBut by far the biggest issue is that no one has been able to come up with a good use case for them.  Believe me, it's not for lack of trying either.  You'll note Mark's blog post doesn't even cite particular examples of something that really needs to be a windicator.\nThis shouldn't be too surprising, as we've never had windicators but have come up with many other solutions to the problems a theoretically good windicator might solve. \nFor instance, if it's that the window requires some action, it can call for attention (flash in taskbar).  If the action is urgent, the window can pop to the front.  In both cases the actual text of the window itself provides far more space and context to display what's important than a small icon in the corner would.\nSo that leaves us with only unimportant and optional things that might exist as windicators.  But these are already there in the form of window controls and program menus.\n", "Q: How to save font choice in gVim? I'm running Ubuntu 9.10. Whenever I open the gvim application, I have to select a custom font (Edit→Select font). I would like gvim to remember my choice. Perhaps I need to edit the ~/.vimrc file, I am not sure.\nHow can I make gvim remember my preference?\n\nA: Close. Set the font through the gui, then use the command (: to get the prompt) set gfn? to get the current font string. It should look something like this:\nguifont=Mono Uralic 10\n\nThen edit/create ~/.gvimrc and add the line:\nset gfn=Mono\\ Uralic\\ 10\n\nNote: You need to escape the spaces from the output (as I have above)\n\nA: Here's an automated approach. (I've also made the code below a plugin.)\nSelect the font you want to use.\nPaste this into Gvim in command mode (to set up the map):\nmap -- :let @a=&gfn<CR>:e ~/.gvimrc<CR>Go<Esc>\"apV:s/ /\\\\ /g<CR>Iset guifont=\n\nThen type -- (to activate the mapping).\nYou should now be editing your .gvimrc with your current font set at the bottom. Save the file and open another Gvim to test that it works correctly.\n\nWhat the mapping does:\n\n\n*\n\n*:let @a=&gfn<CR> Copy the current font setting into our a register\n\n*:e ~/.gvimrc<CR> Edit our gvimrc (whether it exists or not)\n\n*Go<Esc> Add a new line to the end of the file\n\n*\"ap Paste the font setting\n\n*V:s/ /\\\\ /g<CR> Escape spaces\n\n*Iset guifont= Put the set variable text before our setting\n\n\nA: two options here to save font choice for Gvim\n\n\n*\n\n*in $HOME/.vimrc file (this config file is for terminal Vim):\n\n\nif has('gui_running')\n    set guifont=Consolas\\ Regular\\ 12\nendif\n\n\n\n*make a separate config file for Gvim, $HOME/.gvimrc:\n\n\n\" use vim config\nsource $HOME/.vimrc\n\" set gui font\nset guifont=Consolas\\ Regular\\ 12\n\nCurrently, I am using Vim8.0, thus the vimscript grammar is different from version 7.x\n", "Q: How can I make and distribute an Ubuntu screensaver? I have no programming language preferences and I have a good knowledge of OpenGL coding. If I could use something like OpenFrameworks or Processing as a base, that would be ideal.\n\nA: A screensaver in Linux is a pretty simple thing made up of two key parts:\n\n\n*\n\n*A graphical application that renders the images.\n\n*A .desktop file pointing to that application.\n\n\nI'm not sure what end-result you're trying to achieve so I'll start in reverse. The .desktop files for existing screensavers live in /usr/share/applications/screensavers/. Here's ubuntu_theme.desktop for an example of what you're aiming for:\n[Desktop Entry]\nName=Floating Ubuntu\nComment=Ubuntu logo floating around the screen\nExec=floaters /usr/share/pixmaps/ubuntu-screensaver.svg\nTryExec=floaters\nStartupNotify=false\nTerminal=false\nType=Application\nCategories=GNOME;Screensaver\nOnlyShowIn=GNOME\n\nIf you want to float a different image around, you could just clone the launcher, and replace /usr/share/pixmaps/ubuntu-screensaver.svg with your own image (use SVGs where possible as they scale a lot better).\nIf you want to write your own binary for a completely custom screensaver, you should probably start here: http://www.dis.uniroma1.it/~liberato/screensaver/\nIt uses very simple X graphics to do some pretty simple things. You can pimp it out with OpenGL but it's important you get the basics laid out first.\nOnce you're done, packaging is its whole set of problems but for a very simple package, you can quickly bang a package out following something like this: https://help.ubuntu.com/community/PythonRecipes/DebianPackage\nBut if you're serious about distributing this to lots of people you probably want to start with a PPA (a private repository). You can read about PPAs, building source packages, the build process, etc on LaunchPad's help system.\n", "Q: Can not paste into Gnome Terminal from Netbeans When I copy something from another window then my terminal and want to paste it into my terminal (on the command line) the paste option in Edit is grayed out. Ctrl+V does not work in GNOME Terminal 2.29.6.\nI try to copy form netbeans into a terminal. If I paste it somewhere else, in gedit for example, it gets pasted. So it is copied. \nUsing Ctrl+Shift+C/V does not work.\nIs this a settings of from some sort?\n\nA: Ctrl+V is not a bound combination in terminals. The terminal application ignores the keyboard event and passes it onto whatever's running. This is desirable because you don't really want the terminal window interfering with your keyboard events.\nRight-click and click paste. Or use Primary Selection (highlight some text and middle-click).\nEdit: I've just learned something! Shift+Insert will work if you want a keyboard input method. It's a primary-selection-based insert method, so just highlight and go.\nEdit 2: I can't stop learning new things! As ændrük says, Ctrl+Shift+V works as a proper clipboard paste. So you've got lots of options. They're just not the standard key-combos.\n\nA: Oli and user1974 suggested using Primary Selection (an X-Windows feature), but I needed these details to do so:\n1.) Highlight text in NetBeans (don't worry about copying it)\n2.) Middle-click in GNOME Terminal to paste it there\nNo other suggestions worked for me, but this worked like a charm.  There is a bug entered at netbeans.org for this.\n\nA: tldr- use Shift+Insert\n\nCtrl+C and Ctrl+V were keyboard shortcuts created for GUI applications. Apparently has something to do with Xerox.\n\nBefore there was Ctrl+C, Ctrl+X, and Ctrl+V.. there was\n\nCtrl+Insert, Shift+Delete, and Shift+Insert\nThey were defined in 1987 by the IBM Common User Access\nThese shortcuts often work in cases where the modern ones do not.. ie, in a terminal.\n\nA: You can also change the system default keymappings - so you can ctrl+v into terminal. \n\n\nA: I had this same problem with Rubymine, where I was unable to copy from Rubymine and paste into terminal with CTRL-SHIFT-V.  Given that I do this tens of times daily, I had little interest in copying to gedit every time and then copying to terminal, so I figured out a solution that doesn't require it:\nhttp://www.williambharding.com/blog/technology/fix-it-ubuntu-ctrl-shift-v-wont-paste-into-terminal/\nShort story: OpenJDK doesn't play nice with the clipboard.  I am guessing that this would apply to Netbeans as well as Rubymine since both run via a Java VM.\n\nA: You need to append a Shift when pasting into the Terminal: Ctrl+Shift+V Same with copying a selection only using a C instead:\nCtrl+Shift+C\nShift is the escape sequence for shortcuts when using the Gnome Terminal.\nAlternatively you can Right Click->Paste\n\nA: Copy text by highlighting it with your mouse.  Usually you can use Ctl+C or right click the selection select \"copy\" from the popup menu as well.\nPaste text by clicking your middle mouse button.  Ctl+V also works in many places and so does Shift+Insert.\nWhat to do when that doesn't work\nThe problem occurs when different applications use different clipboards.  You will successfully copy the text to a clipboard in Application A, but when you go to Application B to paste, it will try paste from a different clipboard.  In Windows all applications use the same clipboard.  \nThere are several solutions.  Probably the easiest one to get working is to install Parcellite.  \nInstall parcellite\nsudo apt-get install parcellite\n\nRun parcellite\nparcellite&\n\nA clipboard icon will show up in the system tray.  \nUse parcellite\n\n\n*\n\n*Copy some text.  \n\n*Click the clipboard icon in the system tray and select what you want from the menu.  \n\n*Paste your text.\n\n\nA: It sounds like the text was not actually copied in the first place. If there is anything available to paste on the clipboard, then Edit -> Paste will be clickable.\nIn Gnome Terminal, the keyboard shortcut for pasting is usually Ctrl+Shift+V.\n\nA: There is a bug in Linux that sometimes de-selects copied information when trying to copy/paste between 2 different applications.  I recommend installing a clipboard manager, then you will see this bug in action.  Parcellite is my favorite.  If you are using Debian/Ubuntu paste \"sudo apt-get install parcellite\" (no quotes) into a terminal (ha,ha) or use Synaptic to install it.  This bug affects all programs, not just the terminal.\nAfter you install and start Parcellite (Applications -> Accessories -> Parcellite) you will see a clipboard icon in your systray.  Recreate the bug, and then click the tray icon.  You will see that the info was copied but is grayed-out, i.e., not selected.  Click it to select it and then you can paste to your heart's content.  This is one of the most annoying bugs of all time and has been around for years.\n\nA: It's a bug in gnome-terminal. You can try xfce4-terminal.\n\nA: I have the same problem with copying from Netbeans to terminal. It seems that when you Ctrl+C in Netbeans, it isn't copied in pure text format, so you can't paste it in terminal which require that kind of format (this is an assumption based on my experience ;) ).\nSo, how do I do it? Just copy from Netbeans, then paste it in some text editior, on example gedit, then copy it again and just paste in terminal.\n\nA: highlight text, middle click.\nThat's my favorite, quick, easy, works with other apps too.  You just have to be careful with your clicks as you can mess up the highlight.  (ie, you can't highlight the text, click around, highlight other text, and then hope to middle click the text from earlier.)\n", "Q: After startup, why do I have to run /etc/init.d/networking restart for networking to work? I just fixed the grub install, and found that my wired network connection did not work. I eventually got it working, but each time I restart, I have to manually restart the networking service to bring up the network. How can get the network to come up automatically?\nHere's the pertinent info.\nRunning ifup gave:\n$sudo ifup eth0\nUnknown interface eth0=eth0\n\ndhclient, didn't work either. I eventually had a look at /etc/network/interfaces, and eth0 was missing:\nauto lo\niface lo inet loopback\n\nwhich I changed to:\nauto eth0\niface eth0 inet dhcp\n#auto lo\n#iface lo inet loopback\n\nThe error produced by ifup went away but dhclient still still wouldn't give me an ip, but restarting the network interface did:\n$ sudo /etc/init.d/networking restart\n * Reconfiguring network interfaces...                                          RTNETLINK answers: No such process\nThere is already a pid file /var/run/dhclient.eth0.pid with pid 1421\nkilled old client process, removed PID file\nInternet Systems Consortium DHCP Client V3.1.3\nCopyright 2004-2009 Internet Systems Consortium.\nAll rights reserved.\nFor info, please visit https://www.isc.org/software/dhcp/\n\nListening on LPF/eth0/6c:f0:49:e3:26:fd\nSending on   LPF/eth0/6c:f0:49:e3:26:fd\nSending on   Socket/fallback\nDHCPRELEASE on eth0 to 192.168.1.1 port 67\nsend_packet: Network is unreachable\nsend_packet: please consult README file regarding broadcast address.\nInternet Systems Consortium DHCP Client V3.1.3\nCopyright 2004-2009 Internet Systems Consortium.\nAll rights reserved.\nFor info, please visit https://www.isc.org/software/dhcp/\n\nListening on LPF/eth0/6c:f0:49:e3:26:fd\nSending on   LPF/eth0/6c:f0:49:e3:26:fd\nSending on   Socket/fallback\nDHCPDISCOVER on eth0 to 255.255.255.255 port 67 interval 6\nDHCPOFFER of 192.168.1.101 from 192.168.1.1\nDHCPREQUEST of 192.168.1.101 on eth0 to 255.255.255.255 port 67\nDHCPACK of 192.168.1.101 from 192.168.1.1\nbound to 192.168.1.101 -- renewal in 37830 seconds.\nssh stop/waiting\nssh start/running, process 1801\n\nHere are the related syslog entries for the system start up, and after restarting the network:\nSep  3 13:38:50 storm-rider kernel: [   15.490593] type=1505 audit(1283535469.269:2):  \n\noperation=\"profile_load\" pid=735 name=\"/sbin/dhclient3\"\nSep  3 13:38:50 storm-rider kernel: [   15.490754] type=1505 audit(1283535469.269:3):  operation=\"profile_load\" pid=735 name=\"/usr/lib/NetworkManager/nm-dhcp-client.action\"\nSep  3 13:38:50 storm-rider kernel: [   15.490833] type=1505 audit(1283535469.269:4):  operation=\"profile_load\" pid=735 name=\"/usr/lib/connman/scripts/dhclient-script\"\nSep  3 13:38:50 storm-rider kernel: [   15.670581] ACPI: resource piix4_smbus [0xb00-0xb07] conflicts with ACPI region SOR1 [0xb00-0xb0f]\nSep  3 13:38:50 storm-rider kernel: [   15.670581] ACPI: If an ACPI driver is available for this device, you should use it instead of the native driver\nSep  3 13:38:50 storm-rider kernel: [   15.674793] EDAC MC: Ver: 2.1.0 Aug 19 2010\nSep  3 13:38:50 storm-rider kernel: [   15.680588] EDAC amd64_edac:  Ver: 3.2.0 Aug 19 2010\nSep  3 13:38:50 storm-rider kernel: [   15.681182] EDAC amd64: This node reports that Memory ECC is currently disabled, set F3x44[22] (0000:00:18.3).\nSep  3 13:38:50 storm-rider kernel: [   15.681196] EDAC amd64: ECC disabled in the BIOS or no ECC capability, module will not load.\nSep  3 13:38:50 storm-rider kernel: [   15.681196]  Either enable ECC checking or force module loading by setting 'ecc_enable_override'.\nSep  3 13:38:50 storm-rider kernel: [   15.681196]  (Note that use of the override may cause unknown side effects.)\nSep  3 13:38:50 storm-rider kernel: [   15.681224] amd64_edac: probe of 0000:00:18.2 failed with error -22\nSep  3 13:38:50 storm-rider kernel: [   15.769839]   alloc irq_desc for 16 on node 0\nSep  3 13:38:50 storm-rider kernel: [   15.769844]   alloc kstat_irqs on node 0\nSep  3 13:38:50 storm-rider kernel: [   15.769860] HDA Intel 0000:00:14.2: PCI INT A -> GSI 16 (level, low) -> IRQ 16\nSep  3 13:38:50 storm-rider kernel: [   15.823915] Console: switching to colour frame buffer device 80x30\nSep  3 13:38:50 storm-rider kernel: [   15.917876] nvidia 0000:01:00.0: PCI INT A -> GSI 18 (level, low) -> IRQ 18\nSep  3 13:38:50 storm-rider kernel: [   15.917890] nvidia 0000:01:00.0: setting latency timer to 64\nSep  3 13:38:50 storm-rider kernel: [   15.917899] vgaarb: device changed decodes: PCI:0000:01:00.0,olddecodes=io+mem,decodes=none:owns=io+mem\nSep  3 13:38:50 storm-rider kernel: [   15.918099] NVRM: loading NVIDIA UNIX x86_64 Kernel Module  195.36.24  Thu Apr 22 19:10:14 PDT 2010\nSep  3 13:38:50 storm-rider kernel: [   16.561300] r8169: eth0: link down\nSep  3 13:38:50 storm-rider kernel: [   16.561648] ADDRCONF(NETDEV_UP): eth0: link is not ready\nSep  3 13:38:50 storm-rider kernel: [   17.444914] EXT4-fs (sda3): mounted filesystem with ordered data mode\nSep  3 13:38:50 storm-rider init: smbd main process (1038) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider init: smbd main process (1045) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider init: smbd main process (1050) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider init: smbd main process (1055) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider avahi-daemon[957]: Network interface enumeration completed.\nSep  3 13:38:50 storm-rider avahi-daemon[957]: Registering HINFO record with values 'X86_64'/'LINUX'.\nSep  3 13:38:50 storm-rider avahi-daemon[957]: Server startup complete. Host name is storm-rider.local. Local service cookie is 49883856.\nSep  3 13:38:50 storm-rider init: smbd main process (1060) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider init: smbd main process (1067) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider init: smbd main process (1072) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider init: smbd main process (1077) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider init: smbd main process (1082) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd main process ended, respawning\nSep  3 13:38:50 storm-rider init: smbd main process (1087) terminated with status 1\nSep  3 13:38:50 storm-rider init: smbd respawning too fast, stopped\nSep  3 13:38:50 storm-rider NetworkManager:    SCPlugin-Ifupdown: update_connection_setting_from_if_block: name:eth0, type:802-3-ethernet, id:Ifupdown (eth0), uuid: 681b428f-beaf-8932-dce4-687ed5bae28e\nSep  3 13:38:50 storm-rider NetworkManager:    SCPlugin-Ifupdown: autoconnect\nSep  3 13:38:50 storm-rider NetworkManager:    SCPluginIfupdown: management mode: unmanaged\nSep  3 13:38:50 storm-rider NetworkManager:    SCPlugin-Ifupdown: devices added (path: /sys/devices/pci0000:00/0000:00:0a.0/0000:03:00.0/net/eth0, iface: eth0)\nSep  3 13:38:50 storm-rider NetworkManager:    SCPluginIfupdown: locking wired connection setting\nSep  3 13:38:50 storm-rider NetworkManager:    Ifupdown: get unmanaged devices count: 1\nSep  3 13:38:50 storm-rider NetworkManager:    SCPlugin-Ifupdown: (37841184) ... get_connections.\nSep  3 13:38:50 storm-rider NetworkManager:    SCPlugin-Ifupdown: (37841184) ... get_connections (managed=false): return empty list.\nSep  3 13:38:50 storm-rider NetworkManager:    Ifupdown: get unmanaged devices count: 1\nSep  3 13:38:50 storm-rider NetworkManager:    SCPlugin-Ifupdown: devices added (path: /sys/devices/virtual/net/lo, iface: lo)\nSep  3 13:38:50 storm-rider NetworkManager:    SCPlugin-Ifupdown: device added (path: /sys/devices/virtual/net/lo, iface: lo): no ifupdown configuration found.\nSep  3 13:38:50 storm-rider NetworkManager:    SCPlugin-Ifupdown: end _init.\nSep  3 13:38:50 storm-rider NetworkManager: Loaded plugin ifupdown: (C) 2008 Canonical Ltd.  To report bugs please use the NetworkManager mailing list.\nSep  3 13:38:50 storm-rider NetworkManager: Loaded plugin keyfile: (c) 2007 - 2008 Red Hat, Inc.  To report bugs please use the NetworkManager mailing list.\nSep  3 13:38:50 storm-rider NetworkManager: <info>  WiFi enabled by radio killswitch; enabled by state file\nSep  3 13:38:50 storm-rider NetworkManager: <info>  WWAN enabled by radio killswitch; enabled by state file\nSep  3 13:38:50 storm-rider NetworkManager: <info>  (eth0): carrier is OFF\nSep  3 13:38:50 storm-rider NetworkManager: <info>  (eth0): new Ethernet device (driver: 'r8169')\nSep  3 13:38:50 storm-rider NetworkManager: <info>  (eth0): exported as /org/freedesktop/NetworkManager/Devices/0\nSep  3 13:38:50 storm-rider NetworkManager: <info>  modem-manager is now available\nSep  3 13:38:50 storm-rider NetworkManager: <WARN>  default_adapter_cb(): bluez error getting default adapter: The name org.bluez was not provided by any .service files\nSep  3 13:38:50 storm-rider NetworkManager: <info>  Trying to start the supplicant...\nSep  3 13:38:51 storm-rider dhclient: No DHCPOFFERS received.\nSep  3 13:38:51 storm-rider dhclient: No working leases in persistent database - sleeping.\nSep  3 13:38:51 storm-rider avahi-autoipd(eth0)[1103]: Found user 'avahi-autoipd' (UID 103) and group 'avahi-autoipd' (GID 110).\nSep  3 13:38:51 storm-rider avahi-autoipd(eth0)[1103]: Successfully called chroot().\nSep  3 13:38:51 storm-rider avahi-autoipd(eth0)[1103]: Successfully dropped root privileges.\nSep  3 13:38:51 storm-rider avahi-autoipd(eth0)[1103]: Starting with address 169.254.10.181\nSep  3 13:38:52 storm-rider gdm-session-worker[1113]: GLib-GObject-CRITICAL: g_value_get_boolean: assertion `G_VALUE_HOLDS_BOOLEAN (value)' failed\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Sucessfully called chroot.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Sucessfully dropped privileges.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Sucessfully limited resources.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Running.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Canary thread running.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Watchdog thread running.\nSep  3 13:38:52 storm-rider polkitd[1203]: started daemon version 0.96 using authority implementation `local' version `0.96'\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Sucessfully made thread 1195 of process 1195 (n/a) owned by '1000' high priority at nice level -11.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Supervising 1 threads of 1 processes of 1 users.\nSep  3 13:38:52 storm-rider NetworkManager: <info>  Unmanaged Device found; state CONNECTED forced. (see http://bugs.launchpad.net/bugs/191889)\nSep  3 13:38:52 storm-rider NetworkManager: <info>  Unmanaged Device found; state CONNECTED forced. (see http://bugs.launchpad.net/bugs/191889)\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Sucessfully made thread 1241 of process 1195 (n/a) owned by '1000' RT at priority 5.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Supervising 2 threads of 1 processes of 1 users.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Sucessfully made thread 1242 of process 1195 (n/a) owned by '1000' RT at priority 5.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Supervising 3 threads of 1 processes of 1 users.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Sucessfully made thread 1244 of process 1244 (n/a) owned by '1000' high priority at nice level -11.\nSep  3 13:38:52 storm-rider rtkit-daemon[1197]: Supervising 4 threads of 2 processes of 1 users.\nSep  3 13:38:52 storm-rider pulseaudio[1244]: pid.c: Daemon already running.\nSep  3 13:38:53 storm-rider anacron[1405]: Anacron 2.3 started on 2010-09-03\nSep  3 13:38:53 storm-rider kernel: [   79.823450] CPU0 attaching NULL sched-domain.\nSep  3 13:38:53 storm-rider kernel: [   79.823454] CPU1 attaching NULL sched-domain.\nSep  3 13:38:53 storm-rider kernel: [   79.823456] CPU2 attaching NULL sched-domain.\nSep  3 13:38:53 storm-rider kernel: [   79.823457] CPU3 attaching NULL sched-domain.\nSep  3 13:38:53 storm-rider kernel: [   79.823458] CPU4 attaching NULL sched-domain.\nSep  3 13:38:53 storm-rider kernel: [   79.823460] CPU5 attaching NULL sched-domain.\nSep  3 13:38:53 storm-rider kernel: [   79.903191] CPU0 attaching sched-domain:\nSep  3 13:38:53 storm-rider kernel: [   79.903193]  domain 0: span 0-5 level MC\nSep  3 13:38:53 storm-rider kernel: [   79.903195]   groups: 0 1 2 3 4 5\nSep  3 13:38:53 storm-rider kernel: [   79.903199] CPU1 attaching sched-domain:\nSep  3 13:38:53 storm-rider kernel: [   79.903200]  domain 0: span 0-5 level MC\nSep  3 13:38:53 storm-rider kernel: [   79.903201]   groups: 1 2 3 4 5 0\nSep  3 13:38:53 storm-rider kernel: [   79.903203] CPU2 attaching sched-domain:\nSep  3 13:38:53 storm-rider kernel: [   79.903204]  domain 0: span 0-5 level MC\nSep  3 13:38:53 storm-rider kernel: [   79.903205]   groups: 2 3 4 5 0 1\nSep  3 13:38:53 storm-rider kernel: [   79.903208] CPU3 attaching sched-domain:\nSep  3 13:38:53 storm-rider kernel: [   79.903209]  domain 0: span 0-5 level MC\nSep  3 13:38:53 storm-rider kernel: [   79.903210]   groups: 3 4 5 0 1 2\nSep  3 13:38:53 storm-rider kernel: [   79.903212] CPU4 attaching sched-domain:\nSep  3 13:38:53 storm-rider kernel: [   79.903213]  domain 0: span 0-5 level MC\nSep  3 13:38:53 storm-rider kernel: [   79.903214]   groups: 4 5 0 1 2 3\nSep  3 13:38:53 storm-rider kernel: [   79.903216] CPU5 attaching sched-domain:\nSep  3 13:38:53 storm-rider kernel: [   79.903217]  domain 0: span 0-5 level MC\nSep  3 13:38:53 storm-rider kernel: [   79.903218]   groups: 5 0 1 2 3 4\nSep  3 13:38:53 storm-rider anacron[1405]: Normal exit (0 jobs run)\nSep  3 13:38:56 storm-rider avahi-autoipd(eth0)[1103]: Callout BIND, address 169.254.10.181 on interface eth0\nSep  3 13:38:56 storm-rider avahi-daemon[957]: Joining mDNS multicast group on interface eth0.IPv4 with address 169.254.10.181.\nSep  3 13:38:56 storm-rider avahi-daemon[957]: New relevant interface eth0.IPv4 for mDNS.\nSep  3 13:38:56 storm-rider avahi-daemon[957]: Registering new address record for 169.254.10.181 on eth0.IPv4.\nSep  3 13:39:00 storm-rider avahi-autoipd(eth0)[1103]: Successfully claimed IP address 169.254.10.181\nSep  3 13:39:14 storm-rider init: ssh main process (944) terminated with status 255\nSep  3 13:39:14 storm-rider ntpdate[1514]: can't find host ntp.ubuntu.com\nSep  3 13:39:14 storm-rider ntpdate[1514]: no servers can be used, exiting\nSep  3 13:39:54 storm-rider AptDaemon: INFO: Initializing daemon\nSep  3 13:40:13 storm-rider dhclient: Internet Systems Consortium DHCP Client V3.1.3\nSep  3 13:40:13 storm-rider dhclient: Copyright 2004-2009 Internet Systems Consortium.\nSep  3 13:40:13 storm-rider dhclient: All rights reserved.\nSep  3 13:40:13 storm-rider dhclient: For info, please visit https://www.isc.org/software/dhcp/\nSep  3 13:40:13 storm-rider dhclient: \nSep  3 13:40:13 storm-rider avahi-autoipd(eth0)[1103]: Got SIGTERM, quitting.\nSep  3 13:40:13 storm-rider avahi-autoipd(eth0)[1103]: Callout STOP, address 169.254.10.181 on interface eth0\nSep  3 13:40:13 storm-rider avahi-daemon[957]: Withdrawing address record for 169.254.10.181 on eth0.\nSep  3 13:40:13 storm-rider avahi-daemon[957]: Leaving mDNS multicast group on interface eth0.IPv4 with address 169.254.10.181.\nSep  3 13:40:13 storm-rider avahi-daemon[957]: Interface eth0.IPv4 no longer relevant for mDNS.\nSep  3 13:40:13 storm-rider dhclient: Listening on LPF/eth0/6c:f0:49:e3:26:fd\nSep  3 13:40:13 storm-rider dhclient: Sending on   LPF/eth0/6c:f0:49:e3:26:fd\nSep  3 13:40:13 storm-rider dhclient: Sending on   Socket/fallback\nSep  3 13:40:17 storm-rider dhclient: DHCPDISCOVER on eth0 to 255.255.255.255 port 67 interval 8\nSep  3 13:40:25 storm-rider dhclient: DHCPDISCOVER on eth0 to 255.255.255.255 port 67 interval 12\nSep  3 13:40:39 storm-rider dhclient: There is already a pid file /var/run/dhclient.eth0.pid with pid 1421\nSep  3 13:40:39 storm-rider dhclient: killed old client process, removed PID file\nSep  3 13:40:39 storm-rider dhclient: Internet Systems Consortium DHCP Client V3.1.3\nSep  3 13:40:39 storm-rider dhclient: Copyright 2004-2009 Internet Systems Consortium.\nSep  3 13:40:39 storm-rider dhclient: All rights reserved.\nSep  3 13:40:39 storm-rider dhclient: For info, please visit https://www.isc.org/software/dhcp/\nSep  3 13:40:39 storm-rider dhclient: \nSep  3 13:40:39 storm-rider dhclient: Listening on LPF/eth0/6c:f0:49:e3:26:fd\nSep  3 13:40:39 storm-rider dhclient: Sending on   LPF/eth0/6c:f0:49:e3:26:fd\nSep  3 13:40:39 storm-rider dhclient: Sending on   Socket/fallback\nSep  3 13:40:39 storm-rider dhclient: DHCPRELEASE on eth0 to 192.168.1.1 port 67\nSep  3 13:40:39 storm-rider dhclient: send_packet: Network is unreachable\nSep  3 13:40:39 storm-rider dhclient: send_packet: please consult README file regarding broadcast address.\nSep  3 13:40:39 storm-rider dhclient: Internet Systems Consortium DHCP Client V3.1.3\nSep  3 13:40:39 storm-rider dhclient: Copyright 2004-2009 Internet Systems Consortium.\nSep  3 13:40:39 storm-rider dhclient: All rights reserved.\nSep  3 13:40:39 storm-rider dhclient: For info, please visit https://www.isc.org/software/dhcp/\nSep  3 13:40:39 storm-rider dhclient: \nSep  3 13:40:39 storm-rider NetworkManager: <info>  (eth0): carrier now ON (device state 1)\nSep  3 13:40:39 storm-rider kernel: [  186.096615] r8169: eth0: link up\nSep  3 13:40:39 storm-rider dhclient: Listening on LPF/eth0/6c:f0:49:e3:26:fd\nSep  3 13:40:39 storm-rider dhclient: Sending on   LPF/eth0/6c:f0:49:e3:26:fd\nSep  3 13:40:39 storm-rider dhclient: Sending on   Socket/fallback\nSep  3 13:40:41 storm-rider avahi-daemon[957]: Registering new address record for fe80::6ef0:49ff:fee3:26fd on eth0.*.\nSep  3 13:40:43 storm-rider dhclient: DHCPDISCOVER on eth0 to 255.255.255.255 port 67 interval 6\nSep  3 13:40:43 storm-rider dhclient: DHCPOFFER of 192.168.1.101 from 192.168.1.1\nSep  3 13:40:43 storm-rider dhclient: DHCPREQUEST of 192.168.1.101 on eth0 to 255.255.255.255 port 67\nSep  3 13:40:43 storm-rider dhclient: DHCPACK of 192.168.1.101 from 192.168.1.1\nSep  3 13:40:43 storm-rider avahi-daemon[957]: Joining mDNS multicast group on interface eth0.IPv4 with address 192.168.1.101.\nSep  3 13:40:43 storm-rider avahi-daemon[957]: New relevant interface eth0.IPv4 for mDNS.\nSep  3 13:40:43 storm-rider avahi-daemon[957]: Registering new address record for 192.168.1.101 on eth0.IPv4.\nSep  3 13:40:43 storm-rider dhclient: bound to 192.168.1.101 -- renewal in 37830 seconds.\n\n\nA: Ubuntu uses NetworkManager to handle your networking by default these days.\nThere is already a pid file /var/run/dhclient.eth0.pid with pid 1421\n\nis probably telling you that NetworkManager had already started dhclient for you.\nYou could verify that by running\nps -o ppid= -p 1421\n\nthen\nps -o cmd -p <the number printed by the above command>.\n\nor do it in one step using\nps -o cmd -p `ps -o ppid= -p 1421`\n\nchanging 1421 to whatever pid the \"There is already a pid file...\" message says.\nTo configure NetworkManager, right click on the network icon in the corner of the screen, or run nm-tool from the command line.\nGoogle \"NetworkManager\" for more information.\nAnd removing \"lo\" from /etc/network/interfaces sounds like a bad idea to me in any case.\n", "Q: How do I upgrade to Ubuntu 10.04.1 LTS I want upgrade from Ubuntu 10.04 LTS to Ubuntu 10.04.1 LTS. Is there a basic update? How do I do it?\n\nA: The release of Ubuntu 10.04.1 LTS is basically only an updated installation CD. If you have a completely updated installation of Ubuntu 10.4 LTS, you are effectively running Ubuntu 10.04.1 LTS.\nUnlike other release updates, maintenance updates don't display a special prompt in the Update Manager so it's easy to not even notice when they're installed.\n\nA: If you've been installing updates via the Update Manager or apt then you're probably already running 10.04.1. You can confirm your version by executing lsb_release -a on the command line.\nThe official documentation for upgrading can be found here.\n", "Q: How to make my proxy settings change depending on the network I connect to? My company's corporate network requires me to set a network proxy to access the net, but when I am anywhere else, I don't need it.\n The proxy settings in Ubuntu (System -> Preferences -> Proxy server) allowed me to create \"locations\" that I can manually select. Then I have a \"default\" location (with no proxy) and a \"work\" location (with my company's proxy in it).\nIs there a way to make Ubuntu automatically select the \"work\" location based on the connection I'm using? I thought I could use the IP subnet (very specific) to detect where I am, but I have no idea how to set it up...\nEdit: I really need to have the proxy settings set at the system level. All my network connections (IMAP, SMTP, chat, etc) need to go through the proxy. Not only the web browser.\n\nA: I can think of one way, but setting it up will be a bit obscure.\nBasically you could use a PAC file\nInstall a web server on your system, any tiny web server will do, you don't need a huge system like apache.\nCreate a file wpad.dat with PAC directives that match based on your source address, and then configure your system to use the correct proxy.\nIn firefox, configure the proxy to point at your local PAC file.  It would probably be something like http://localhost/wpad.dat.\nYour PAC file might look somewhat like this (untested).  See here for more PAC examples.\nfunction FindProxyForURL(url, host) {   \n  // If on a internal/LAN IP address, send traffic direct.\n  if (isInNet(myIpAddress(), \"10.10.1.0\", \"255.255.255.0\"))\n  {        \n    return \"PROXY 1.2.3.4:8080; PROXY 4.5.6.7:8080; DIRECT\";\n  }\n  else\n  {\n    return \"DIRECT\";\n  }\n}\n\nI have never tried it, and I am not at a system to test, but you may even be able to specify the PAC file using a file:// URL in firefox, which would mean you could skip setting up the web server.\nOf course there is also the quick and easy solution, but it does require a little effort on your part as you move between locations.  Install the Quick Proxy Firefox extension, and just click the button on your tool bar to toggle the proxy on or off.  If you are willing to deal with this with a Firefox extension you can also try FoxyProxy, it supports setting up multiple proxy profiles, and you can easily switch between profiles.\n\nA: In Ubuntu 10.10 the .pac script works well. As Zoredache explained, set up a webserver, put a pac file there, open System->Preferences->Network Proxy and set the \"Autoconfiguration URL\" to the pac file location.\nExample of a PAC file that checks for one's own IP address:\n/var/www/selectProxy.pac:\nfunction FindProxyForURL(url, host)\n {\n if (myIpAddress() == \"192.168.22.63\") { \n return \"PROXY 192.168.22.8:8080\";\n }\n else {\n return \"DIRECT\";\n }\n }\n\nIn Network proxy prefs: the URL would be:\nhttp://localhost/selectProxy.pac\n\n\nA: As an addition to Zoredache's answer, you could use a script in /etc/network/if-up.d to generate a snippet in /etc/profile.d/ containing your proxy shell variables. Note that this will only work with new shells.\nAdditionally, this method might be used to generate a WPAD-file, to which you could point any browsers supporting this.\n\nA: This is a pretty old post, but I found this.\nHave a look:\nhttp://marin.jb.free.fr/proxydriver/\nYou can install the .deb package provided for Ubuntu. This is basically a shell script that changes the environment variables when your network changes. You can configure the settings for each network by editing the config files (automatically) created in /etc/proxydriver.d/\n\nA: I have the same problem. Please generalize any answers to include my situation. \nI use my laptop at home on wireless: -- always eth1 interface\nstatic IP address (192.168.1.10)\nWhen I go to work I plug it in: -- always eth0 interface\ndynamic IP address (10.10.xx.xx), AND a proxy: 10.10.123.123 port 8888\nI want Ubuntu to automatically set the IP address and proxy based on which interface I'm using.\n(I've messed around in /etc/network/interfaces [see \"man interfaces\" and /etc/resolv.conf to no avail.\n\nA: I use the PAC file approach and it works well for browsing but not so well for many other applications that don't understand PAC files - I'm guessing that when an app asks for \"proxy config\" via the API, they just get the PAC file URL back if you are using one.\nFor user applications that either don't have proxy support or don't understand PAC files (like Empathy), I use tsocks (because I use an SSH tunnel for my proxy support).\nLinking a JavaScript engine or a PAC parser to every application that supports basic proxy config seems like overkill. This seems to be a case that could benefit from some underlying platform support with an API call that actually interprets the PAC file and returns the result, instead of it's URL.\n\nA: this is an old post at this point, but I came here looking for a way to do this and found a different answer. The answer I'm working with lies in a package called 'whereami' and requires you to define your work's sub-net in its detect.conf file and then define the proxy server on the whereami.conf file. Should work, and I'll post with any issues I have.\nGood luck!\n", "Q: How can I get my Microsoft Lifecam VX-1000 webcam microphone to work? How can I get my webcam's (Microsoft Lifecam VX-1000) microphone to work?\nIt uses the uvcvideo driver and video quality is perfect on both Cheese and Gmail's Video Chat.\n\nA: Click on the 'sound menu' in the panel and go to \"Sound Preferences\". On the input tab, you should be able to change the device to your webcam. To check it's working talk or tap the microphone, to check that the Input level bars change.\n\n\nA: If you’re using the Microsoft LifeCam VX-1000 or VX-3000 and are having trouble with your microphone, could you please do the following?\n1.-\nAccording to the GSPCA, this fix will be included in kernel 2.6.36 and newer. So until Ubuntu uses kernel 2.6.36 or newer, you will need to install the updated drivers yourself.\nyou can obtain the new kernel here\n32 bits : linux-image-2.6.36-020636-generic_2.6.36-020636.201010210905_i386.deb \n64 bits : linux-image-2.6.36-020636-generic_2.6.36-020636.201010210905_amd64.deb    \nInstalling required packages\ni. RIGHT CLICK on the package , SELECT \"Open with GDebi Package Installer\".\nii. If there is no error message then CLICK on \"Install Package\" button.\nREBOOT your system and login with the new kernel\n2.- another option is compile GSPCA :\ndownload the GSPCA driver from the following link and extract it:\nhere\nThen just open a terminal and change to the extracted directory, then run “make” and “sudo make install”.\nIt is inconvenient, but thats the only option until the kernel includes it by default.\nbut kernel 2.6.36 is released yesterday so better option is \"3\"\nP.D if you need to compile something you need this package installed :\n\nsudo apt-get install build-essential install linux-headers-'uname -r' linux-source-'uname -r'\n\n", "Q: How do I monitor disk activity on a specific drive? I'd like to watch disk activity on my USB external hard drive. I know that I can use iotop to monitor disk I/O for each running process, but is there a way to get a measure per filesystem?\n\nA: dstat is better than iostat for strictly monitoring disk activity.\nI am running the following command while moving files from one harddrive to another\ndstat -D sda,sdc\n\nfor more info, have a look at this page\nhttps://help.ubuntu.com/community/DiskPerformance\n\nA: I'm not skilled in this area, but iostat comes to mind. You can install it with the sysstat package. Good luck!\n\nA: Using iostat from the sysstat package provides a single snapshot of results since startup.  Use of the interval parameter will append the results for only the last interval to the output.  Example, iostat 10 will first show the \"since boot\" values then continue to add the last 10 seconds of statistics to the output, every 10 seconds.  Include the -y option to omit the first display of statistics since boot but understand that the command will appear idle for the specified interval while the system collects the first snapshot.\nI've found this most effective when combined with the watch command and indicating to only collect for a single interval of statistics.  For example:\nwatch -t -n 0.1 iostat -p sda,sdc -d -t -y 5 1\n\nThis gives a refresh every 5.1 seconds of activity statistics for the last 5 seconds. To break down the options and parameters...\n\n*\n\n*The first -t tells watch to omit the header. This is to avoid confusion that otherwise the header will include \"Every 0.1s\" which does not represent the snapshot of data.\n\n*The -n 0.1 tells watch to run the following command every 0.1 seconds.  This is the smallest interval for watch (procps-ng 3.3.9) but don't worry, it isn't actually running the command every 0.1 seconds.  It will run the command 0.1 seconds after the prior instance completes.\n\n*The -p sda,sdc tells iostat to only display stats for these devices.\n\n*The -d tells iostat to only display device utilization, relevant since the question was concerning disk activity.\n\n*The second -t switch tells iostat to include the time of the refresh in the statistics.  This is useful since the earlier omission of the watch header removed the time display that would have been there.\n\n*The -y switch omits the first screen of \"since boot\" statistics from the interval display.  Without this the result would be a display of the statistics since boot updating at the interval of the watch command.\n\n*The 5 1 are the iostat interval parameters. In this case capture 5 seconds of statistics once (the 1).  Because the -y switch was used this will only present a single screen of data.\n\nIt will take 5 seconds for iostat to collect the data, it will then be displayed in watch, and 0.1 seconds later watch will trigger the iostat command again.  5 seconds later the new data will replace the old, watch will wait 0.1 seconds, wash, rinse, repeat...\n\nA: Try with nmon\nsudo apt-get install nmon\n\nTry: \nnmon\n\nOutput Like below: \n\nPress d = Disk Press c = CPU Press r = RAM, Press v = Virtual Memory, Kernal Status press K, Press N = network  and Press q or x to exit\n\nA: In order to monitor disk IO per device and process in one glance, consider using glances.\nhttps://nicolargo.github.io/glances\nYou can install it with pip:\npip install glances\n\n", "Q: How do I play an MP3 or WAV through the computer's internal speaker? I'd like to have a script play a pretty chime sound as a notification, but I want it to use the internal speaker because the external sound system isn't always powered on.\nBeeping is not an option; it makes passers-by think there is something wrong.\n\nA: The internal speaker typically cannot do anything but beep. It's not usually connected to any sound hardware.\nhttp://en.wikipedia.org/wiki/PC_speaker\n", "Q: Any howtos on de-Xen'ing a box? I have a box that has Xen on it.  It currently has only one DomU.  Given that Xen isn't supported in the newer versions of Ubuntu...are there any good HOWTOs or other instructions for removing Xen?\nMy specific situation is:\n 3 drives mirrored via RAID1 software raid.\n LVM on top.\nI was thinking something like removing one of the drives, getting my DomU to boot of that and then re-RAID1 from that drive.  But I'm not really sure how to go about doing that with mdadm. :-/\n\nA: I don't know raid setups, but I think you are forgetting the problem that you need package changes to boot a xen system in an ordinary way. \nThere are xen-specific packages like libc-xen and xen-specific kernels.\nYou either want to chroot into it and revert those packages to normal. After that the partition could behave like a normal server setup. \nBut for your sanity, i would just backup your data and reinstall.\nYou may also want to investigate if it's possible to migrate Xen to KVM. That is: turning the partition into a qcow2 file. \n", "Q: How to make USB drive as local repository I copied \"archives\" folder (/var/cache/apt/archives) from another computer which was fully updated and had some packages that i want. Can someone guide me how to add my USB drive in repository list so that i can install those packages from it?\nThanks.\n\nA: I don't think there is a way to add this as a repository but you can use it to install the packages by copying the contents to your /var/cache/apt/archives. To do this, press alt-f2, enter gksudo nautilus and do the copy. Once you have done, make sure you close the file manager window because it is not a good idea to use the file manager as root except for the tasks that absolutely require it.\nTo view/install these packages, run System -> Administration -> Synaptic Package Manager, click the 'Origin' button and choose 'Local' from the list.\nIn the future, you are better off using a program called aptoncd which can be installed from the repositories. It can be used to create a CD image that can be added as a software source.\nThis image can be transported on a usb stick.\nThe easiest way to add the image as a software source is to burn it to a CD/DVD. You then need to go to System -> Administration -> Software Sources, click 'Other Software' and click 'Add CD-ROM...'.\nIf you want to use the ISO image as a software source without burning it, the process will be a bit more complicated. You will need to open a terminal Applications -> Accessories -> Terminal and run these commands:\nsudo mkdir /aptoncd-mountpoint\nsudo mount /media/USB/aptoncd.iso ~/aptoncd-mountpoint -oloop\nsudo apt-cdrom -d=/aptoncd-mountpoint add\n\n(source: http://www.debianhelp.org/node/10486)\nIf you want to download packages on one computer (Linux, Mac or Windows) and install them on an Ubuntu system, you can use keryx.\n\nA: You should build a repository in a local directory and point a file: URI entry to your APT sources (see URI SPECIFICATION in man sources.list):\ndeb file:/home/user/repository\n\nTo make apt work, you need to create a list of packages (Packages.gz) for APT to consume. This is explained in detail here. For your case, it should be quite easy. I refer you to the \"Trivial Repositories\" section of the manual. It should be as easy as changing to, say, /home/user/repository and running\ndpkg-scanpackages binary /dev/null | gzip -9c > binary/Packages.gz\n\nThen after a apt-get update, the packages should become available. Perhaps if you want to make this source take precedence over others, you need to assign it a higher priority; for that see the APT manual pages.\n\nA: If you want to use a official CD / USB / ISO image from Ubuntu as repository, you can add this into /etc/apt/sources.list:\ndeb file:/media/usb xenial main restricted\n\nfirst, you need to mount your image in /media/usb (for example) and change xenial for your image version.\nThe server edition only contains main and restricted, while the Desktop version additionally contains universe and multiverse.\nMy personal case:\nAfter installing Ubuntu (in a server without internet), I forgot to tick the \"OpenSSH server\" box so the installation finished without it. I tried to dpkg -i openssh....deb but as it requires several dependencies, it was better to do it appropriately. At the end, the selected answer in this page helped me to find out how to use my image as repository and it worked without issues.\nThis can be useful if you are looking for a way to downgrade a package to an specific version included in an image.\n\nA: You have backup copies of the package files (that you have downloaded in another computer) in your USB drive. In this situation just create a folder in your home directory, say, ARCHbackUP. Copy all the files from USB to this folder and then follow the codes below:\ncd ~\nsudo chown -R username:username ARCHbackUP/.\ngenisoimage -o ARCHbackUP.iso -R -J ~/ARCHbackUP\nmv -u ./ARCHbackUP.iso ~/\nsudo apt-get clean #cleans the /var/cache/apt/archives directory.\nsudo mkdir /mnt/load_iso\nsudo mount -o loop ARCHbackUP.iso /mnt/load_iso #mounts the iso archive.\ncd /mnt/load_iso #taking you in the mounted directory.\nsudo cp -r -n ./. /var/cache/apt/archives\ncd ~\nsudo umount /mnt/load_iso #unmount the mounted iso archive.\nsudo rmdir /mnt/load_iso #deletes the mount point load_iso.\n\nNow all the package files and updates you've downloaded are in the apt-get install search path of your system. Now open your terminal and issue sudo apt-get install package_name to install new packages or sudo apt-get upgrade to update installed packages offline.\n\nA: You can customize a DVD yourself, refer to http://www.hiroom2.com/2016/08/12/ubuntu-16-04-install-package-from-dvd/ for detail.\nps. I have tried this method on Ubuntu server 16.04 (as it support software RAID), and install ubuntu-desktop with customized DVD.\n\nA: I was really searching for the same thing for Debian Jessie, but stumbled on this site and found this thread to be more helpful then others. Here is what might work for some ubuntu/ debian-variant fellows. \nFirst, you need to mount your USB in your file manager (probably, Nautilus). Usually it auto-mounts with the default settings though.\nAs @lepe suggested, i edited the /etc/apt/sources.list and added the following line after some fiddling around:\ndeb file:/media/your_username/DEBIAN\\ 8_1_/dists/jessie jessie main contirb\n\nIt worked like a charm. Hope this helps someone although this post is a bit old.\n", "Q: How to watch eurosport player? They use silverlight -- therefore I installed moonlight but still get a black screen.\nIs there a way to watch it on Ubuntu? I now use a virtual (windows xp) machine so I can still watch it, but would like to know it there are possibilities.\n\nA: Normally speaking, Moonlight would do the job. However Eurosport (amongst others) employ a  layer of DRM that Microsoft have not published technical documentation for. If they did, the DRM would likely be rendered completely useless as anybody could write an application that decoded their customers' streams.\nIn the future there might be the possibility of a binary-only distributed plugin that contains the DRM decryptor but this relies on Microsoft to both release the technical specs under NDA to Mono devs and then agree a licensing term that allows redistribution.\nThe Mono devs probably have enough technical know-how to reverse-engineer the DRM but they'd probably find their patent-protection contract torn and then a nice little lawsuit to follow. Marinated in a DMCA broth (Novell is US-based).\n\nA: Eurosport Player now works in Ubuntu with Firefox and Chrome without any additional steps.\nHardware acceleration does not work though, but it is browser limitation on Linux based systems.\n\nA: You might want to try the Moonlight 3 Preview (this was needed for watching some Olympic video for instance, so may well work for Eurosport)\n", "Q: Tool to add shapes, annotations and text using templates to images Often I need to annotate (draw some arrows, lines, basic shapes like squares, ellipses etc and enter some text) on top of pictures (JPG, PNG images) and screenshots (again png images). I would also need to be able to crop, resize etc.\nI tried the Gimp but I could only enter text and perform all image transformations but couldn't find a way to draw boxes etc.\nI finally settled to Openoffice.org draw, but I know that isn't what I want, because in oodraw I need to insert my pic into a drawing and resize it (or the drawing) to fit and then go about making changes and finally export to png...\nIs there any image editor that allows adding shapes and text to jpg & png files and save the modified file in its place? If the tool can also have template collections (like dia does) for shapes that is an added bonus.\n\nA: You also might want to try GnuPaint or Krita.  Not sure if it's exactly what you're looking for, but they might work for you.  Both are in the Software Center.\nGnuPaint\n\nKrita\n\n\nA: On Ubuntu (or Linux Mint), try Kolourpaint. It's easy to use and has the features you describe.\n\n\n\nA: Flameshot\nIt comes with some cool annotation features like Freehand drawing, Lines, Arrows, Boxes, Circles, Highlighting, Blur, etc.\nIt also comes with many on-screen buttons as well lots of customization options.\n\nIts written with QT/C++ and it's very easy to install in Ubuntu(18.04+).\napt install flameshot\n\nYou can also try to compile for older versions.\n\nA: I use LibreOffice impress https://www.libreoffice.org/discover/impress/ for annotations. \nJust copy paste the image into the slide and add all the shapes and text which will serve as annotations. Then export to any of many available formats, like JPEG, PDF, etc. \nAnnotating with Impress keeps \"annotations\" as a separate layer allowing you to edit them at any time. On the other hand, if you annotate with, say, Shutter editing tool, once you saved the image with the annotations, you cannot undo the changes (you'll need to re-annotate the entire image from the initial state or use eraser tool to make corrections to existing annotations).  \n\nA: If you want to stay in gimp, you can add boxes and circles/ellipses. Use the rectangle or ellipse selection tool, and when you have the marching ants, on the main menu click Edit/Stroke Selection, then make your line style choice.\nThere are gimp plug ins to do arrows (that I have not tried), however it took only a few minutes to find a clip art site, copy an arrow image, convert it to a transparent-background gif using these directions, and add it as a new layer to the image. The arrow layer can be moved, rotated, scaled, colored, etc.\n\nA: Ksnip\nBecause I run KDE using GTK themed apps like Shutter is not ideal. After doing some research I settled on ksnip as a screenshot tool.  It has pretty much everything you asked for (if you need to crop, just do it by taking another screenshot).\n\nInstall\nYou can install ksnip buy downloading the .deb packages here\nhttps://github.com/DamirPorobic/ksnip/releases\nor check if it's already in your version of Ubuntu's repository vi apt:\n$ sudo apt install ksnip\n\nOr via snap:\n$ sudo snap install ksnip\n\nBuild and install from source\n$ sudo apt install g++ build-essential \\\nlibqt5core5a libqt5dbus5 libqt5gui5 \\\nlibqt5network5 libqt5svg5-dev libqt5widgets5 \\\nlibqt5x11extras5-dev qt5-default qt5-qmake \\\nqttools5-dev qttools5-dev-tools \\\ncmake cmake-extras extra-cmake-modules\n\n$ git clone https://github.com/ksnip/kColorPicker\n$ cd kColorPicker/\n$ mkdir build && cd build\n$ cmake .. && make\n$ sudo make install\n\n$ git clone https://github.com/ksnip/kImageAnnotator\n$ cd kImageAnnotator/\n$ mkdir build && cd build\n$ cmake .. && make\n$ sudo make install\n\n$ git clone https://github.com/ksnip/ksnip\n$ mkdir build && cd build\n$ cmake .. && make\n$ sudo make install\n\n\nA: You can use firefox or Chrome web browser to do this. On firefox you have to install fireshot addon and on chrome \"screen capture\"\nhttps://​addons.mozilla.org/en-US/firefox/​addon/​fireshot\n\nUnfortunately fireshot works on Windows only. Here's a list of such addons. Please test them on your own.\n    https://addons.mozilla.org/en-US/firefox/search/?q=screen+grab&appver=11.0&platform=linux\nScreen Capture will do on Chrome\nhttps://chrome.google.com/webstore/detail/cpngackimfmofbokmjmljamhdncknpmg\n\n\nA: I recommend the \"Awesome Screenshot\" extension, You can easily add there text, simple arrows and other shapes.\nGoogle Chrome\nhttps://chrome.google.com/webstore/detail/awesome-screenshot-screen/nlipoenfbbikpbjkfpfillcgkoblgpmj\nFirefox\nhttps://addons.mozilla.org/en-US/firefox/addon/awesome-screenshot-capture-\nOpera\nhttps://addons.opera.com/en/extensions/details/awesome-screenshot-capture-annotate/\n\nA: I would use Inkscape\n(that can be installed from the Ubuntu Software Centre or sudo apt install inkscape).\n\n\nYou will need to right click the image, select Open With → Other Application…\nand chose Inkscape from the list. After you have done this the first time, you can just Right Mouse Click → Open With → Inkscape.\nThis will import the image into Inkscape and the page will be sized to fit the image. You can then make your annotations.\nTo save it, you need to use File → Export Bitmap, click Browse… and chose your original image.\n\nA: Warning: Shutter is severely broken in Ubuntu 18.04 and was briefly dropped from Ubuntu for some releases, but it is now available again in 22.04 and newer.\nShutter (which you can install from the Ubuntu Software Centre or sudo apt-get install shutter) is a tool which has a variety of options for taking and annotating screenshots. (Note: You can annotate any images of your choice, not just screenshots.)\n\n\nA: Xournal++ is the tool for freehand note taking or annotating pdf files, or anything you cut and paste in your document(text, graphics). I use Xournal++ in combination with a stylus for true free hand input as my goto tool when giving lectures online. This allows me to use any reference material as a background such as pdf documents or images and add annotations in real time while explaining the subject at hand.\nInstall using snap, more installation options here.\nsudo snap install xournalpp\n\nHere is an example screenshot from Xournal++ website\n\n\nA: No one is talking about Image Magick. It is the simplest and the fastest app with one of the goals of is to make annotations.\nIt can be installed by sudo apt install imagemagick and launch the GUI from the search activity (dash). Here is the screenshot.\n\n\nA: You can take a look here, u'll find a lot of funny chrome extensions:\nhttps://chrome.google.com/webstore/search-extensions/screenshot?hl=en-US\nAnd this articile talks about some others:\nhttp://www.hongkiat.com/blog/top-web-annotation-and-markup-tools/\n\nA: You can use Pixtick. Web tool, no installation required and free.\nhttp://www.pixtick.com\n", "Q: Gnome does not remember last file location if you untar a file If I download a packed file, and then want to open, the gnome file system points me to my home directory.\nI want to go some other path, so I browse there and unpack it.\nA moment later, another packed file download, and this time it points me to my home directory again, instead of the last location I unpacked the tar file.\nIs it possible in gnome to make it remember the last location where you unpacked a file some moments ago?\nUsing ubuntu 10.04, fresh install.\n\nA: There is a bug and a patch submitted, but unfortunately the patch has been sitting there idle for almost two years. \n", "Q: Moving the Start menu bar How do I move the start bar on top to the right or left edge of the screen? \n\nA: Assuming you mean the Gnome 'panel', right click on it and go to 'Properties'. Then change the 'orientation' option. \nNote that if you want to move it to the left or right, and are using the default Ubuntu themes, you will probably want to change the background colour to a solid fill for aesthetic purposes.\n\n\nA: You can move the whole bar, by holding the ALT key and dragging (holding the left mouse button) the bar to the side you want it to be.\nYou can move individual items, by right clicking the item, and then deselecting the last option called 'pin to panel' (or something similar, i'm not sure what the english translation is). After it is no longer pinned, you can move individual items in two ways:\n\n\n*\n\n*you can drag them using middle-click (clicking the scrollwheel on your mouse)\n\n*you can right click and select 'move' and then move the item without dragging\n\n\nA: The \"start menu bar\" is called the panel. To change it's orientation, right click on it on the empty part, then select Properties. You should see this dialog, which you can select the orientation on.\n\n\nA: Here is another answer assuming you just want to move icons.\nright_click on icon -> uncheck Lock To Panel -> now you can move the icon.\n\nA: alt + windows key + right click on bar --> properties\n", "Q: How to configure partitions across two physical drives? I am a Linux/Ubuntu newbie installing Ubuntu Server 10.04 on a fresh box as a web server.\nMy box has two physical drives (40GB and 160GB), and I wish to use them both.\nWith no previous experience in installing Ubuntu, what partitions should I create that will best utilize my disk space, but also be stable with reasonable performance?\n\nA: Although it should be possible to create one partition that spans more than one physical drive, it's not a recommended path.\nYou are better off creating more than one partition, that just happen to live on different drives. \nYou want to use it as a server. Will you be using the home directories? Or will you keep most of your data in /var/www-data ? \nCommon paths to separate on different partitions are:\n/boot -> this is often a separate partition, so you can use a different filesystem (grub doesn't support all filesystems)\n/var  -> this is assumed to contain data that changes a lot\n/home -> this if often separated so you can easily reinstall without loosing user's files \n/tmp  -> this is assumed to have temporary data\nAlso, keep in mind you will need a separate swap partition no matter what you do. \nI would put the swap-partition, and the /var partition on the fastest physical drive. \nEDIT: Let's assume your fastest drive is the 40 gb one. In that case you may want to put /var/www-data on your larger drive, and just keep the root '/' and the swap on the fastest physical drive. This would mean you have three partitions: swap, / and /var/www-data. No need to separate the rest.\n\nA: You could use lvm or software-raid to create a virtual device that concatenates the space of both disks.\nCreating then just one filesystem (and perhaps a swap partition) on that virtual device would maximize your disk utilization.\nBut it is not recommended since if one of your hard disks fails your complete file system is unusable.\nI.e. you add the hard-disk fail probabilities.\nThus, just create the system (boot + swap + /) on the 40 GB one. And mount the 160 one as /home or /var depending on where do you want to save the most data ...\n", "Q: What is LVM and what is it used for? As a Linux/Ubuntu newbie, what is LVM and what is it used for?\nIn terms of a web server installation, what benefits does it provide?\nWould you recommend using it?\n\nA: What kind of applications or content are you planning to host ? If it is a personal server or something for a small organization, you probably can get by without using LVM.\nLVMs are useful if you need partitions etc across multiple disks. I doubt you would need it, given that you're asking here regarding it :)\n\nA: Without answering your question directly (which the other posters already did), there is an easy answer about whether or not you need LVM: If you don't know some feature during installation in detail, leave it at its default setting. The default configuration will be fine for most users (including me and probably you). :)\n\nA: I know that this thread is old and that the OP has a lot better understanding of this, but I came across this thread whilst looking up something with LVM and thought I'd put my 2c in.\nThe short answer is that increasing the size of a partition on the disk is a pain.\n\nI have an AWS (EC2) server I use for backups (using rsnapshot). As I start backing up more servers or the data changes more frequently I need more space.\nMy backup drive is currently a 250GB EBS volume that is now completely full and I want to increase it to 350GB in size, so I went to the AWS control panel, created a snapshot of the drive, created a new EBS volume from the snapshot and attached it. I now have a 250GB EXT4 partition full of data on a 350GB drive.\nI want to tell Ubuntu to use the larger space but I can't use resize2fs to increase the partition size and fdisk doesn't let me change the partition size either. Instead it only lets me delete the partition, create a new one at the larger size and then I have to Rsync the files across with the correct command line to also copy hardlinks.\nThat's a lot of work, so I recently set it up using LVM and now I can take the new, larger EBS disk and easily increase the LVM volume on it, then a quick resize2fs to tell the EXT4 filesystem that it's got some new space and bam, problem solved without having to copy hundreds of gigabytes of data. LVM is a saviour.\nAlternatively I could just mount another EBS volume extend the LVM to that and now it's spread over multiple disks but it's seen as only one partition, sweet!\n\nA: Benefits\nYou can think of LVM as \"dynamic partitions\", meaning that you can\ncreate/resize/delete LVM \"partitions\" (they're called \"Logical\nVolumes\" in LVM-speak) from the command line while your Linux system\nis running: no need to reboot the system to make the kernel aware of\nthe newly-created or resized partitions.\nOther nice features that LVM \"Logical Volumes\" provide are:\n\n\n*\n\n*If you have more than one hard-disk, Logical Volumes can extend\n over more than one disk: i.e., they are not limited by the size of\n one single disk, rather by the total aggregate size.\n\n*You can set up \"striped\"  LVs, so that I/O can be distributed to\n all disks hosting the LV in parallel. (Similar to RAID-0, but a\n bit easier to set-up.)\n\n*You can create a (read-only) snapshot of any LV.  You can revert\n the original LV to the snapshot at a later time, or delete the\n snapshot if you no longer need it.  This is handy for server\n backups for instance (you cannot stop all your applications from\n writing, so you create a snapshot and backup the snapshot LV),\n but can also be used to provide a \"safety net\" before a critical\n system upgrade (clone the root partition, upgrade, revert if\n something went wrong).\nWhile being most useful on server systems, I think that features\n1. and 3., combined with LVM's ability to create/resize/delete LVs on\nthe fly, are quite handy on desktop systems as well.  (Especially if\nyou experiment a lot with the system.)\nDownsides\nOf course, all of this comes at a price: the initial setup of LVM is\nmore complex than just partitioning a disk, and you will definitely\nneed to understand the LVM terminology and model (Logical Volumes,\nPhysical Volumes, Volume Groups) before you can start using it.\n(Once it is set up, using it is much easier, though.)\nAlso, if you use LVM across hard drives, you may lose all your data when only one drive fails.\nRecommended reading\n\n\n*\n\n*LVM HOW-TO from The Linux Documentation Project.\n\nA: The main benefit from using LVM is if you have more than one harddrive. With LVM you can group the hardrives into one huge one. \nAlso you can add more space to this group if you add more harddrives.\nWith LVM you can simple work like you have only one single huge harddrive.\nDespite that LVM supports a lot expert features.\n", "Q: How to use Rhythmbox python console Maybe this is obvious and I am missing it, or maybe someone's already written a great guide and my (seeming exhaustive) googling is failing to turn it up, but I cannot figure out for the life of me how to get the darn python console in rhythmbox to do anything!\nI've enabled it from the plugin menu, and then open it using Tools->Python Console.\nIt prints\nYou can access the main window through the 'shell' variable :\n<rb.Shell object at 0xa6cdd24 (RBShell at 0xa14e000)>\n>>> \n\nBut anything I type at the prompt does nothing!\nI've tried help, I've tried exit(), I've tried print \"hello world\", nothing does anything!\nAll of these things work, of course, in a normal python console. I haven't a clue what the devil the difference is here! Am I supposed to do something other than hit enter?\n\nA: The Rhythmbox Plugins Writing Guide has several examples of commands you can use in the Python console to control playback and modify Rhythmbox:\n\n\n*\n\n*Play/Pause\nshell.props.shell_player.playpause()\n\n\n*Stop\nshell.props.shell_player.stop()\n\n\n*Next track\nshell.props.shell_player.do_next()\n\n\n*Add a song to the Play Queue\nshell.add_to_queue(\"file://awsome_song.ogg\")\n\n\n*Display a visualization\nimport gst\ngoom = gst.element_factory_make (\"goom\")\nsink = gst.element_factory_make (\"ximagesink\")\ncolour = gst.element_factory_make (\"ffmpegcolorspace\")\nb = gst.Bin()\nb.add (goom, colour, sink)\nb.add_pad(gst.GhostPad(\"sink\", goom.get_pad(\"sink\")))\ngoom.link(colour)\ncolour.link(sink)\nshell.get_player().props.player.add_tee(b)\n\n\nA: As with any Python object, you can find out a lot about it by using the dir() method on it. This will give you a good place to start.\nYou can access the main window through the 'shell' variable :\n<rb.Shell object at 0x9e9675c (RBShell at 0x987b018)>\n>>> dir(rb.Shell)\n['__class__', '__cmp__', '__copy__', '__deepcopy__', '__delattr__', '__dict__',\n'__doc__', '__format__', '__gdoc__', '__getattribute__', '__gobject_init__', \n'__grefcount__', '__gtype__', '__hash__', '__init__', '__module__', '__new__', \n'__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__',\n'__subclasshook__', 'add_to_queue', 'add_uri', 'add_widget', 'append_source',\n'chain', 'connect', 'connect_after', 'connect_object', 'connect_object_after',\n'disconnect', 'disconnect_by_func', 'do_notify', 'emit', 'emit_stop_by_name',\n'freeze_notify', 'get_data', 'get_party_mode', 'get_player',\n'get_playlist_manager', 'get_properties', 'get_property',\n'get_source_by_entry_type', 'get_ui_manager', 'guess_source_for_uri', \n'handler_block', 'handler_block_by_func', 'handler_disconnect',\n'handler_is_connected','handler_unblock', 'handler_unblock_by_func', 'load_uri',\n'notebook_set_page', 'notify', 'notify_custom', 'present', 'props',\n'register_entry_type_for_source', 'remove_from_queue', 'remove_widget',\n'set_data', 'set_properties', 'set_property', 'stop_emission', 'thaw_notify',\n'toggle_visibility', 'weak_ref']\n\nYou can then dir() any of the interesting-looking properties, like 'get_player', perhaps.\nAnother good place to look is if you see a __doc__ attribute on the object.\n>>> print rb.Shell.__doc__\nObject RBShell\n\nSignals from RBShell:\n  visibility-changed (gboolean)\n  visibility-changing (gboolean, gboolean) -> gboolean\n  create-song-info (RBSongInfo, gboolean)\n  removable-media-scan-finished ()\n  notify-playing-entry (gboolean)\n  notify-custom (guint, gchararray, gchararray, GdkPixbuf, gboolean)\n\nProperties from RBShell:\n  no-registration -> gboolean: no-registration\n    Whether or not to register\n  no-update -> gboolean: no-update\n    Whether or not to update the library\n  dry-run -> gboolean: dry-run\n    Whether or not this is a dry run\n  rhythmdb-file -> gchararray: rhythmdb-file\n    The RhythmDB file to use\n  playlists-file -> gchararray: playlists-file\n    The playlists file to use\n  selected-source -> RBSource: selected-source\n    Source which is currently selected\n  db -> RhythmDB: RhythmDB\n    RhythmDB object\n  ui-manager -> GtkUIManager: GtkUIManager\n    GtkUIManager object\n  clipboard -> RBShellClipboard: RBShellClipboard\n    RBShellClipboard object\n  playlist-manager -> RBPlaylistManager: RBPlaylistManager\n    RBPlaylistManager object\n  removable-media-manager -> RBRemovableMediaManager: RBRemovableMediaManager\n    RBRemovableMediaManager object\n  shell-player -> RBShellPlayer: RBShellPlayer\n    RBShellPlayer object\n  window -> GtkWindow: GtkWindow\n    GtkWindow object\n  prefs -> RBShellPreferences: RBShellPreferences\n    RBShellPreferences object\n  queue-source -> RBPlayQueueSource: queue-source\n    Queue source\n  library-source -> RBLibrarySource: library-source\n    Library source\n  sourcelist-model -> RBSourceListModel: sourcelist-model\n    RBSourcelistModel\n  sourcelist -> RBSourceList: sourcelist\n    RBSourcelist\n  source-header -> RBSourceHeader: source header widget\n    RBSourceHeader\n  visibility -> gboolean: visibility\n    Current window visibility\n\nSignals from GObject:\n  notify (GParam)\n\n\nA: Holy crap, I just found out what the problem was (2.5 years later)—for some reason my \"enter\" key maps to two different key events depending on whether numlock is on or off. When numlock is on, it returns KP_ENTER, and when numlock is off, it returns Return. I always have numlock on, because I prefer entering numbers with the keypad. \nUnfortunately, the python console in Rhythmbox only recognizes Return to run a command—the KP_ENTER event just enters a line break...\nBut easy fix, just turn off numlock when using the console. I've ran into this problem in a few other applications (usually games), so I'm going to look into a better long-term solution (maybe forcing both to map to Return somehow)...\n", "Q: How do I print CD Cover in Ubuntu? I have and HP Officejet 6500 Wireless printer and I'm running Ubuntu 10.04 32bit. I want to print CD covers, what kind of software can i use to do that? I already tried glables, Gimp, and Image viewer. \n\nA: The default cd-burn application in Ubuntu, called Brasero, actually has a build-in CV Cover printer.\n\n\n*\n\n*Launch brasero\n\n*Select any of the project types\n\n*Click on the menu 'extra'\n\n*Select 'CD Cover Printer'\n\n\nIt will fill the cover with the data from the project. For music this would be the tracklisting. For files this would be the file-listing, etc.\n\nA: There's also Kover, disc-cover, and CDcover that might work for you.  They're all in the repos.\n\nA: What was the problem with glabels ? Any specific feature you're looking for ?\nYou could also try Koverartist\n", "Q: How to configure export formats in LyX? Whenever I try to view a PDF of a document in LyX, I get this error:\n\nI get similar errors for DVI and postscript.\nIf I go through File->Export, the only options are other LyX formats and Docbook. There isn't even an option to export to LaTeX.\nHow do I configure LyX to export to these formats? Is there at least a way for me to convert to LaTeX so I can use pdflatex to create a PDF?\nEDIT: Strangely, this problem fixed itself. I can't think of anything I changed to make it happen. Perhaps a software update fixed this.\n\nA: I haven't found a way to stop these errors but I have found some workarounds that give a nicely formatted output:\neLyXer\neLyXer is a program available in the software repositories as elyxer that converts a document in LyX format to a nicely formatted HTML document. This can be viewed by a web browser and converted to a PDF/PS via print to file.\nView Source + pdflatex\nTo view the LaTeX source, select View->View Source. This displays a split-screen. To get the complete LaTeX document make sure the 'Complete Source' box is ticked. This text can then be copied and pasted into a text editor. The command line tool, pdflatex can be used to convert the LaTeX document to a PDF. The PDF file can be converted to other formats via the pdf2* and pdfto* sets of commands.\ndocbook-utils\nThe package docbook-utils can convert a file in docbook format to several other formats including PDF, PS and HTML.\n\nA: When things go awry like this, best is to:\nsudo apt-get purge lyx\n\nThen: \nmv ~/.lyx ~/.lyx.bak\n\nThis will make sure that you start with a fresh config. \n", "Q: iFolder on ubuntu 10.04 32bits I'm trying to install iFolder on Ubuntu 10.04 32bits by following the steps presented at https://help.ubuntu.com/community/iFolderInstall.\nWhen issuing the command\nbzr-buildpackage\n\nit seems to download simias.tar.gz and after that, i get the following errors\ntar -xzvf \"simias.tar.gz\"\ntar: simias.tar.gz: Cannot open: No such file or directory\ntar: Error is not recoverable: exiting now\ntar: Child returned status 2\n...\n\nAny help would be greatly appreciated\n\nA: Try that:\nThe simias.tar.gz file is downloaded as \"download\".\nAll you have to do is to add a line in the file \"rules\" just before the tar command.\nmv download simias.tar.gz\n\nIt should work.\n\nA: I am using the iFolder client on Ubuntu successfully. There are .debs available here:\nhttp://sanjayayogi.com/debs\nI found the link in a Google Group about this:\nhttp://groups.google.com/group/ifolder-ubuntu-debian-dev\nHere is a useful guide to install iFolder Server on Ubuntu, plus a ton of useful comments:\nhttp://www.x2b4.com/howto/how-to-install-ifolder-on-ubuntu-server\n(but I am running an OpenSuse 11.2 virtual machine for it, it's easier.)\nWatch out if you run fully encrypted home folders, because you will either have to place your iFolders and the .local/share/simias folder in an unencrypted part of your disk, or recompile Simias.\n\nA: Unfortunately iFolder on Ubuntu has never really worked right, despite efforts from multiple people to get it to work, so it's likely the instructions you are following are out of date and unmaintained.\nIf you need a file syncing service there is Ubuntu One, Dropbox, and you can also try Sparkleshare.\n", "Q: How do I create a movie DVD? I would like to create a movie DVD that contains some pictures and small movies. I'm not after anything too fancy, just the ability to add some music, create a title screen and add a menu. Basically, something like Windows Movie Maker. \nWhat would be my best option?\n\nA: There's a new software for authoring DVD's, it is named Bombono.\nJust give a:\nsudo apt-get install bombono-dvd\n\n\nA: I love OpenShot and DeVeDe, but I would like to mention DVDStyler too. ;) And if you want to create photo slideshows, then go for 2ManDVD.\n\nA: Another good alternative to Windows Movie Maker is OpenShot which has more features than pitivi but still manages to have a simple, easy to use interface. A good program for writing videos to DVD (With support for titles and menus) is DeVeDe.\nBoth of these applications are available to install from the Ubuntu Software Centre.\n\nA: You can create a video DVD using Brasero CD-creator, which you can find in the multimedia menu. \nIf you launch it, you can select 'make a video CD/DVD'. \nThen you can add movies to it. \nIf you want to edit your movies, you can use Pitivi, also found in the multimedia menu.\n", "Q: How can I use cron to schedule a script that implements daylight saving on a non- DST aware application when my server automatically uses DST? My server (running ubuntu 8.04LTS server) reports the time as 9:38PM BST right now. BST (British Summer Time) is 1 hour ahead of UTC (or Greenwich Mean Time if you really want to confuse matters)\nThe act of parliament defines that we in the UK use BST for\n\nthe period beginning at one o'clock,\n  Greenwich mean time, in the morning of\n  the last Sunday in March and ending at\n  one o'clock, Greenwich mean time, in\n  the morning of the last Sunday in\n  October.\n\nNo problems scheduling this in cron but I don't know what date format/timezone I should be using. Do I set it to move forward at 1AM but back at 2AM when it ends? That makes sense if the machine uses BST but then I worry that that cron will not trigger at 2AM because the system clock might get reset back to 1AM before it has a chance to trigger - thus making my script run 1 hour late.\nOr does it just use UTC?\n\nA: The answer lies in the cron sources (which you can get by apt-get source cron),\nparticularly in the main loop at lines 159--272 of file cron.c.\ncrond sleeps for a minute, then wakes up and queries the\nsystem time, comparing it to its own idea of time (i.e., what time it\nwould be if nothing altered the clock).  Based on the difference\nbetween the actual and the expected time, crond takes different\nactions; two of them are relevant in your case:\n\n\n*\n\n*Time has leaped forward more than 5 minutes but less than 3 hours\n(DST starts): cron runs wildcard jobs scheduled at the actual time,\nand any job scheduled at a fixed time between the computed time and\nthe actual time.  Relevant source is at lines 221--247:\n  /*\n   * case 2: timeDiff is a medium-sized positive number,\n   * for example because we went to DST run wildcard\n   * jobs once, then run any fixed-time jobs that would\n   * otherwise be skipped if we use up our minute\n   * (possible, if there are a lot of jobs to run) go\n   * around the loop again so that wildcard jobs have\n   * a chance to run, and we do our housekeeping\n   */\n  Debug(DSCH, (\"[%d], DST begins %d minutes to go\\n\",\n      getpid(), timeRunning - virtualTime))\n  /* run wildcard jobs for current minute */\n  find_jobs(timeRunning, &database, TRUE, FALSE);\n\n\n  /* run fixed-time jobs for each minute missed */ \n  do {\n     if (job_runqueue())\n             sleep(10);\n     virtualTime++;\n     find_jobs(virtualTime, &database, FALSE, TRUE);\n     set_time();\n  } while (virtualTime< timeRunning &&\n      clockTime == timeRunning);\n  break;\n\n\n*Time has gone backwards less than 3 hours (DST ends): just run\nwildcard jobs, skip fixed-schedule jobs since they have already\nrun.  Relevant source is at lines 247--258:\n/*\n * case 3: timeDiff is a small or medium-sized\n * negative num, eg. because of DST ending just run\n * the wildcard jobs. The fixed-time jobs probably\n * have already run, and should not be repeated\n * virtual time does not change until we are caught up\n */\nDebug(DSCH, (\"[%d], DST ends %d minutes to go\\n\",\n    getpid(), virtualTime - timeRunning))\nfind_jobs(timeRunning, &database, TRUE, FALSE);\nbreak;\n\nSo, when entering DST, you should have no problem: your script will be\nrun (either just before, or immediately after the time leap).\nWhen exiting DST, there is a risk that your (fixed-time) job will be\nskipped, if you schedule it exactly at 1 o'clock.  My suggestion\nwould be to schedule the run either 1 minute before 1 o'clock, \nor at 2 o'clock (or after). \n\nA: You may try to toggle the UTC=no if it's yes or vice versa in /etc/default/rcS. To do this, run:\ngksu gedit /etc/default/rcS\n\n\n\n*\n\n*Change UTC=no to UTC=yes, or\n\n*Change UTC=yes to UTC=no.\n\n\nSave the file, quit the text editor, and reboot your PC.\n", "Q: How can I use local .deb files in my pbuilder builds? Often I need to create packages which another package depend on (i.e. build dependencies). Instead of having all those packages first being build in my ppa (which can sometimes take some time), I would like to use the results directory from pbuilder as a source for the pbuilder itself.\nHow can I do this? Can I do this via a hook? \n\nA: This can be done a few ways. As mentioned by adol, the Ubuntu wiki has a nice example of how to do this by creating a local repository with mini-dinstall and adding that to your pbuilder config. Dennis' answer about using dpkg-scanpackages works as well.\nI've been doing this recently with apt-ftparchive. I like this approach since I find it very light weight. Here's annotated example of what I do:\n# From my ~/.pbuilderrc file\n\n# Location of the dir where you keep pbuilder hook scripts.\nHOOKDIR=\"/home/andrew/.pbuilder-hooks\"\n\n# Path to your local repo to be used as a mirror written as apt source line.\nOTHERMIRROR=\"deb file:///home/andrew/pbuilder/local_repo ./\"\n\n# Path to your local repo. This tells pbuilder to mount this directory so it is available in the chroot.\nBINDMOUNTS=\"/home/andrew/pbuilder/local_repo\"\n\n# As we need to have the apt-ftparchive command, we need to insure this package is installed.\nEXTRAPACKAGES=\"apt-utils\"\n\nYou also need a pbuilder hook:\n# From my ~/.pbuilder-hooks/D5update-local-repo file\n\n# Path to the local repo.\nLOCAL_REPO=\"/home/andrew/pbuilder/local_repo\"\n\n# Generate a Packages file.\n(cd $LOCAL_REPO ; apt-ftparchive packages . > Packages)\n\n# Update to include any new packages in the local repo.\napt-get update\n\nNow all you have to do is drop the packages into your local repo and they will be available to pbuilder. If you are trying to chain build a string of dependencies you can make you pbuilder results directory as your local repo directory.\nYou can probably imagine other variations on this. For instance, you could use dput with a post_upload_command to generate the Packages file instead of using the hook.\nThis Debian wiki page could also be helpful.\n\nA: You can stick them in a simple repo created with dpkg-scanpackages and make that available via apache. Then update pbuilder's apt config to use your repo.\n", "Q: Proprietary BCM wireless driver ceased to work Suddenly, the propriety Broadcom STA wireless driver ceased to work on my Inspiron 1525 Dell. All of a sudden, when I turned on the laptop the tooltip of the wireless indicator in the top panel shows networking disabled.\nThis also cause the wired network interface not to work, unless I manually dhclient it.\nIndeed, lsmod doesn't show anything with bcm in it.\nHow can I further troubleshoot the issue?\n\nA: Look at the file /var/lib/NetworkManager/NetworkManager.state. Very likely the attribute NetworkingEnabled  or WirelessEnabled is set to false. \nMake sure the two lines show\nNetworkingEnabled=true\nWirelessEnabled=true\n\nsave the file and the restart the network-manager daemon with\nsudo stop network-manager\nsudo start network-manager\n\nAfter this your network should come up again. \n", "Q: How can I stream my desktop via Ustream? I'm looking to stream my desktop live via a service such as ustream and having extreme difficulty in finding a solution.\nI've tried WebcamStudio and it could only use FME files which don't work with Ustream. \n\nA: Steps:\n\n\n*\n\n*Install webcam studio ( http://sourceforge.net/projects/webcamstudio/files/ )\n\n*start webcamstudio\n\n*click Sources => Desktop\n\n*click the Play icon\n\n*you can checkout a preview with the Show Preview button\n\n*login to ustream and click start broadcast\n\n*in the flash input dialog choose webcamstudio\ncredits go to: http://ubuntuforums.org/showpost.php?p=9517840&postcount=16\n\nedit: Testet this at lucid and it is working.\n", "Q: How can I make sure that pinning with apt-get is compatible with virtual packages? In order to allow php5.2 being used on lucid, I created a ppa (ppa:txwikinger/php5.2) and build several php5.2 packages there. In order to prefer those packages I have given instructions to pin them. However, the packages php5-mcrypt and php5-imap do not correctly load due to the dependency to phpapi, even phpapi is provided by i.e. php5-cgi, php5-cli which are available. What is the problem?\n\nA: I found the problem. I made a mistake with the pinning conditions. \nEdit:\nThe version of the pinning did not match what could be found or was missing for the package depending on the virtual package.\n", "Q: How do I convert .ts files into something useful? I have a file that ends in .ts, which according to wikipedia is an MPEG2 file. I've never run into a file like this so I want it want the file to be in a more common format/container to use on multiple devices.\n\nA: From looking at this forums thread I can make it into a matroska file, which I already use.\n ffmpeg -i input.ts -vcodec copy -sameq -acodec copy -f matroska output.ts\n\nI was able to encode this despite this information the seems to indicate that I needed to compile ffmpeg from source. The downside to this is that it doesn't encode the file, so the file is as large as the MPEG2 file. More answers with recommendations for encoding .ts->MPEG4 would help me out.\n\nA: I tend to recommend leaving files in their original state, as any conversion has a chance to introduce loss. The .ts video format is a container format for MPEG, known as \"Transport Stream\", which is used most frequently by digital broadcasting systems (digital cable, satellite, etc). Many applications are unfamiliar with how to decode it, since it has a very different multiplexing format than the more conventional MPEG container known as \"Program Stream\", which is what is used on DVDs, and what is produced by many encoder cards. The difference between TS and PS is only how the packet structure is built; the A/V data inside it is the same.\nTo get better interoperability, I recommend converting the container from TS to PS. Virtually every piece of software that can decode TS can decode PS, so it's almost always better to have PS file. One of the simplest remuxing tools I've found to use is avidemux. Just choose \"copy\" for the video and audio streams, and choose the \"PS\" container format for MPEG:\n\nThen just save out the result. This can also be done using ffmpeg. You just need to select the copy codec for each stream type:\nffmpeg -i input.ts -vcodec copy -acodec copy output.mpg\n\n\nA: .TS files are technically just MPEG2 files. You can use pretty much any converter (avidemux, handbrake or even ffmpeg directly).\nBut the only reason to do so would be filesize. Mpeg2 files play pretty much everywhere.\nThe only confusing part is the actual file-extension.\nYou can safely and freely rename them to .mpeg\nPS. By turning it into Matroska, you just made is very hard for people on other systems to be able to play the file. I understand picking a free codec, and then choosing the appropiate container, but if you keep it at MPEG2, why change the container to something relatively obscure?\n\nA: Actually .ts files are created by DVB-S/DVB-S2 tuners capable of recording transponder streams and can contain mpg2 AC3 AAC h264 mp3, as well as other data ie Teletext or EPG.\n.ts files contain in most cases just AV data but are not limited to that. VLC can play ts files directly and give You some info about some of the streams in it.\nIm personally using a sat tuner that records HD channels in .ts files (h264 video and in most cases multiple AAC mp3 mpg2 audio streams). So basically .ts files can contain many different things Its just container format created for sending digital broadcasts over loosy media. \nVLC can also convert betwen formats (hevent done this myself) \n\nA: I usually use HandBrake to convert all kind of video files to iPhone-compatible format. Maybe you can use it to convert the .ts files into MP4. Check this HandBrake PPA to install it.\n\nA: The handling of TransportStream files produced by DVB-S recorders depends on the contained video and audio stream. For material in SD quality it is likely that you can use a tool chain consisting of ProjectX and mplex to convert the stream into a standard MPEG container. If the video stream is HD, try MKVMerge to convert it into an MKV file. Both ways are described in detail this blog post.\n\nA: The ffmpeg program has been deprecated in favor of avconv.\nYou can pass the same arguments to avconv to convert from transport stream to program stream mpeg or matroska.\nMPEG:\navconv -i input.ts -acodec copy -vcodec copy output.mpg\nMatroska:\navconv -i input.ts -acodec copy -vcodec copy output.mkv\n", "Q: multi-touch support with fujitsu t900 The pen works great out of the box. Any idea how to get multi-touch working?\nThanks!\n\nA: Please see this to get help with MultiTouch in Ubuntu:\nhttps://wiki.ubuntu.com/Multitouch#Community%20Help\nMake sure you include the result of lsusb when you ask your question there. Thank you!\n\nA: Multitouch is supposed to be better supported in Maverick...\nhttp://www.markshuttleworth.com/archives/455\nMaybe you just have to wait, or if you can't, install the Beta :-)\n", "Q: How can I start DHCP3-server later, so that it waits for a bridge interface to initialise before loading? I have Ubuntu 10.04 server currently setup with dhcp3-server as well as a bridged interface (br0) for use with virtual machines. The problem I have is that when the server reboots, dhcp3-server fails to load because of the extra delay caused by bringing up the bridged interface.\nEssentially br0 doesn't have an IP address for use with DHCP3-Server until late in the boot cycle, well after DHCP3-server has attempted to load.\nOnce the server has booted I can run '/etc/init.d/dhcp3-server start' without any issue.\nIs there any way I can either:\n- Force dhcp3-server to wait until the interface has loaded before attempting to load?\n- Start dhcp3-server after everything else has loaded up?\n\nA: You could modify the /etc/init.d/dhcp3-server startup script to wait for\nan IP address to be available on br0.  For instance: (Warning: untested code!)\n# wait 5 secs between br0-ready tests\nwait_time_between_probes=5\n# maximum number of attempts (i.e., timeout)\nmax_attempts=10\n\nlog_progress_msg \"Waiting for br0 to get an IP address\"\nfor n in $(seq 1 $max_attempts); do\n  if /sbin/ifconfig br0 | egrep -q \"inet addr:\" ; then\n    # IP address ready on br0, exit loop\n    break\n  else\n    sleep $wait_time_between_probes\n  fi\ndone\nif [ \"$n\" = \"$max_attempts\" ]; then\n    log_warning_msg \"Maximum number of attempts reached, but br0 has no IP address yet\" \n    log_warning_msg \"Continuing anyway but DHCP3 server might not start correctly\"\nfi \n\nThe snippet should go into the startup script, within the case ... start) part, \nbefore startup of the DHCP3 daemon.  Of course, you\nshould tune the wait time and number of attempts to match your\nenvironment (how long does it take maximum for br0 to get the IP\naddress?)\n\nA: One solution is to tell the dhcp-server not to start automatically and then add the following two lines to you /etc/network/interfaces file for you bridge definition\npost-up /etc/init.d/dhcp3-server start\npre-down /etc/init.d/dhcp3-server stop\n\nSo it will end up looking like this\niface br0 inet static\n    bridge_ports eth0 eth1\n    address 192.168.1.2\n    broadcast 192.168.1.255\n    netmask 255.255.255.0\n    gateway 192.168.1.1\n    post-up /etc/init.d/dhcp3-server start\n    pre-down /etc/init.d/dhcp3-server stop\n\nThis way the network management (ifup/ifdown, NOT network-manager) will start the DHCP server after bringing up the bridge, and shut it down before removing the bridge.\n", "Q: Can't join wifi ad hoc network created by MyWi I want to do iPhone tethering using MyWi, I can see the network it creates but I just can't join. Having WEP security on would throw me into the passphrase input again and leaving it unprotected doesn't connect.\n\nA: Ad-Hoc network in Ubuntu are a little tricky. I had to set one up myself and it took me a while to realize how silly the solution is!\nThe problem is, even after you declare the connection ad-hoc, the ad-hoc infrastructure is not selected by NM. (come to think of it, maybe I should file a bug against that)\nThe solution is to right-click on the nm-applet, select Modifying connexions (translating from french, so option name might differ a little bit here), and go to the Wireless tab.\nClick on your Connection's name and click edit.\nNow, make sure the Mode is set to Ad hoc and the IPv4 and IPv6 tabs methods are set to \"local link only\"\nafter this, it should work. If not, let us know!\n\nA: Make sure you are using it with the correct security type. Most keys are 40/128bit.\n", "Q: Partition advice, how can I stop running out of space on \"/\" partition? I run Ubuntu 10.04 on an EEEPC with a 4GB fast SSD set as the / partition, and a 16GB slower SSD set as the /home partition. I keep running out of space on \"/\", and can no longer install the latest updates, or new apps.\nHow can I better manage the partitions to avoid this problem? Bear in mind that the large SSD is lower performance so I don't think I should use this for the OS. Is it possible to install apps to a different partition when using apt?\nAny advice?\nThank you.\n\nA: Here are some ways to reduce the space taken up by packages:\n\n\n*\n\n*Remove your auto removable packages: \ngo to System -> Administration -> Synaptic Package Manager. Click the 'Status' button in the bottom left. Click the Installed (auto removable) filter. Click on one of the packages and press Ctrl-a to select them all. Next right click on one of the packages and click 'Mark for Removal'. Then click the Apply button in the toolbar. \n\n*Delete your cached packages:\nin Synaptic, click Settings->Preferences and click the 'Files' tab. Click the button that says 'Delete Cached Package Files'.\n\n*Set it so that packages are deleted once installed:\nin Synaptic, click Settings->Preferences and click the 'Files' tab. Click the radio button that says 'Delete downloaded packages after installation'. \nYou could create a bash script to automate these tasks:\n#!/bin/sh\n#~/clean.sh\napt-get autoremove\nrm /var/cache/apt/archives/*.deb\n\nThis could be run with this command:\nsudo ~/clean.sh\n\nDiagnosing where the space has gone:\nGo to Applications -> Accessories -> Disk Usage Analyser.\nClick the 'scan filesystem' button:\n\nThis should give you a breakdown of what space is being used and where:\n\nSeparating parts of the filesystem to different drives/partitions:\nIt is possible to put parts of the filesystem (such as /var or /usr) onto a separate  partition on a different drive. The process would be the same as separating yout /home partition, which you have already done.\nThese tutorials: http://www.psychocats.net/ubuntu/separatehome and http://www.psychocats.net/ubuntu/mountlinux should give you the necessary information for this.\n\nA: First, follow dv3500ea's advice on removing cruft and analysing disk usage.\nIf you still don't have enough space on your system partition, move part of the system to the home partition. Don't create a new partition on the 16GB drive though, use the existing partition so you don't have to worry about choosing a size.\nPick one or more large part of the system for which you don't care about the speed difference.\nThis must be a part of /usr or /var, as the rest might be needed during boot time before the /home partition becomes available. Move that part to the /home partition, and create a symbolic link on the system partition. For example, /usr/share/doc looks like a good candidate, so run the following commands:\nsudo mv /usr/share/doc /home/usr-share-doc\nsudo ln -s /home/usr-share-doc /usr/share/doc\n\n\nA: On my old EEE701 with 4Gb, I found that Synaptic keeps all old deb files after downloading them in /var/cache/apt/archives.  If you set this to clear out after download, you might find that 4Gb is enough on its own.\nIn Synaptic, go to settings/preferences, choose the Files tab and select the middle option :\n\n", "Q: How can I map Super + UpArrow to PageUp? I'd like to map \n\n\n*\n\n*Super + UpArrow to PageUp\n\n*Super + DownArrow to PageDown\n\n*Super + Left to Home\n\n*Super + Right to End \non an Apple aluminum wireless keyboard. Those who know the keyboard would note that it already does these with the Fn key by default; that's fine, and I'd like to keep that, but be able to do the same with a one-handed key combination as well, hence my wanting the Super mappings.\nI've been searching around for a possible way to do this via xmodmap for 3 hours, yet nothing has worked. \n\nA: try editing your /usr/share/X11/xkb/symbols/pc keyboard definition\n(this will change your bindings globally, if you want something more fine tuned, there is some more work to do, like creating a custom keymap or a custom variant)\nas you can see here:\n\nkey  {        [  Prior                ]       };\nkey  {        [  Next                 ]       };\n\nas you can see the key PGUP is bound to \"Prior\". While:\n\n key  {        [  Left                 ]       };\n key  {        [  Down                 ]       };\n\nLEFT and DOWN keys are bound to \"Left\" and \"Down\".\nThe part between brackets [ ] is a list of symbols to be generated. You can put more than one. The first one is the symbol associated with the unmodified key, while other positions are for symbols associated with the key + some modifier.\nCommonly it's used to define the behavior of the key plus the \"SHIFT\" modifier:\n\n  key  {        [         l,    L               ]       };\n  key  {        [ semicolon,    colon           ]       };\n\nBut also other modifiers can be specified, for example in the esperanto map (epo):\n\n  key   { [ jcircumflex,  Jcircumflex,  bracketleft,   braceleft  ] };\n  key   { [ hcircumflex,  Hcircumflex,  bracketright,  braceright ] };\n\nyou can type a [ character by typing AltGr + key  (the [ key on the us keymap), and { by Shift+AltGr + key .\nSo far so good. The sequence we can understand from looking at some simple examples is:\nplain shift altgr shift+altgr\n\nHowever, we want to be able to bind our LEFT and RIGHT key to the plain and CTRL+ALT modifiers. How to achieve that?\nI have no idea, and never tried, but I'd take inspiration from /usr/share/X11/xkb/symbols/pc:\n\nxkb_symbols \"function\" {\n    key  {\n        type=\"CTRL+ALT\",\n        symbols[Group1]= [ F1,  XF86_Switch_VT_1 ]\n    };\n\nPerhaps we can do the same thing for our arrow keys. Let's try to add the following lines:\n\n key  { type=\"CTRL+ALT\", symbols[Group1]= [  Left, Prior                ]       };\n key  { type=\"CTRL+ALT\", symbols[Group1]= [  Down, Next                 ]       };\n\nJust below the original definitions of LEFT and DOWN, in the bottom part of the 'pc' file.\nAnd then restart the X server. Sorry, but I cannot close my session right now to test it.\nBTW, you might be interested in http://code.google.com/p/partiwm/wiki/xpra, so that you can restart the X session and still preserve some applications across restarts.\n\nA: I've tried something similar using xmodmap and its cognates and didn't succeed. Try xbindkeys in conjunction with xdotool. This is what I put in ~/.xbindkeysrc to bind numeric keypad 1 and 2 to Ctrl-PageUp and Ctrl-PageDown:\n\"xdotool key ctrl+Prior\" \n  Release + KP_End\n\n\"xdotool key ctrl+Next\" \n  Release + KP_Down\n\n", "Q: Black tty 1-6 screens After installing Ubuntu 10.04 I had some flickering issues, so I tried upgrading drivers and such, then I installed the fglrx driver and the flickering have gone away but when trying to access the TTY screens from 1-6 the screen goes blank. I'm able to get back in to gnome on tty7.\nany one have a suggestion on what to try here?\n\nDennis\nthe output is:\nglennwiz@Linux-laptop:~$ sudo cat /dev/vcs1\nUbuntu 10.04.1 LTS Linux-laptop tty1\n\nLinux-laptop login:    \n\nNerdfest im using radeon x1300\nlspci output\n00:00.0 Host bridge: Intel Corporation Mobile 945GM/PM/GMS, 943/940GML and 945GT Express Memory Controller Hub (rev 03)\n00:01.0 PCI bridge: Intel Corporation Mobile 945GM/PM/GMS, 943/940GML and 945GT Express PCI Express Root Port (rev 03)\n00:1b.0 Audio device: Intel Corporation N10/ICH 7 Family High Definition Audio Controller (rev 01)\n00:1c.0 PCI bridge: Intel Corporation N10/ICH 7 Family PCI Express Port 1 (rev 01)\n00:1c.1 PCI bridge: Intel Corporation N10/ICH 7 Family PCI Express Port 2 (rev 01)\n00:1c.3 PCI bridge: Intel Corporation N10/ICH 7 Family PCI Express Port 4 (rev 01)\n00:1d.0 USB Controller: Intel Corporation N10/ICH7 Family USB UHCI Controller #1 (rev 01)\n00:1d.1 USB Controller: Intel Corporation N10/ICH 7 Family USB UHCI Controller #2 (rev 01)\n00:1d.2 USB Controller: Intel Corporation N10/ICH 7 Family USB UHCI Controller #3 (rev 01)\n00:1d.3 USB Controller: Intel Corporation N10/ICH 7 Family USB UHCI Controller #4 (rev 01)\n00:1d.7 USB Controller: Intel Corporation N10/ICH 7 Family USB2 EHCI Controller (rev 01)\n00:1e.0 PCI bridge: Intel Corporation 82801 Mobile PCI Bridge (rev e1)\n00:1f.0 ISA bridge: Intel Corporation 82801GBM (ICH7-M) LPC Interface Bridge (rev 01)\n00:1f.2 IDE interface: Intel Corporation 82801GBM/GHM (ICH7 Family) SATA IDE Controller (rev 01)\n01:00.0 VGA compatible controller: ATI Technologies Inc M52 [Mobility Radeon X1300]\n02:06.0 CardBus bridge: Texas Instruments PCIxx12 Cardbus Controller\n02:06.2 Mass storage controller: Texas Instruments 5-in-1 Multimedia Card Reader (SD/MMC/MS/MS PRO/xD)\n02:06.3 SD Host controller: Texas Instruments PCIxx12 SDA Standard Compliant SD Host Controller\n02:06.4 Communication controller: Texas Instruments PCIxx12 GemCore based SmartCard controller\n08:00.0 Ethernet controller: Broadcom Corporation NetXtreme BCM5753M Gigabit Ethernet PCI Express (rev 21)\n10:00.0 Network controller: Intel Corporation PRO/Wireless 3945ABG [Golan] Network Connection (rev 02)\n\n\nAnyone have a suggestion?\n\nA: I know this thread has been dead for quite a while now, but the problem may still exist for some of you, as it did for me until some moments ago.\nHere is how to get your tty-consoles back if you just get black screens after hitting Ctrl+Alt+F1 to F6:\n\n\n*\n\n*In a console, run\nsudo apt-get install v86d\n\n\n*When installation finishes, open:\ngksudo gedit /etc/default/grub\n\n\n*Find the line that reads:\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet\"\n\nNote: there may be more entries between the \"\"s, depending on previous changes.\nReplace it with (or expand accordingly):\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet nomodeset video=uvesafb:mode_option=1280x1024-24,mtrr=3,scroll=ywrap\"\n\n\n*Find another line which reads:\n#GRUB_GFXMODE=640x480\n\nAnd replace it with:\nGRUB_GFXMODE=1280x1024\n\nNote: be sure there's no # in front.\n\n*Save and close the editor.\n\n*Now open:\ngksudo gedit /etc/initramfs-tools/modules\n\nAt the end of the file, add the line:\nuvesafb mode_option=1280x1024-24 mtrr=3 scroll=ywrap\n\n\n*Save and close the editor.\n\n*Finally run:\nFRAMEBUFFER=y | sudo tee /etc/initramfs-tools/conf.d/splash && sudo update-grub2 && sudo update-initramfs -u\n\n\n*Now reboot. After reboot, your tty-consoles should be accessible again.\nSource: crunchbanglinux.org: How to fix tty1-6 (Ctrl+Alt+Fx terminals) if they are not working\n\nA: Per this answer on another site:\n\nI needed to create the file\n  /etc/modprobe.d/radeon-kms.conf, add\n  following line\noptions radeon modeset=0\n\nand had to restart. Now flickering is\n  gone. :)\n\n\nA: I remember that I had that problem a couple of years ago with a computer running an ATI card. IIRC the solution was to give the kernel a different resolution in the boot options.\nYou can try to add a vga=785 to your boot command. If you hit SHIFT while Ubuntu is starting to load, you should be able to see a GRUB menu. Press 'e' and you must be able to edit the boot command. At the end of the line that starts with \"linux\" append vga=785 at the end. Hit CTRL+X to boot.\nYou can try with some other resolutions, you can find instructions to create mode numbers in this wiki.\nNote that I can't check this and it's based in my very flawed memory. Hope that it works. Don't hesitate to downvote it if it is just a too wild guess.\n", "Q: Nvidia proprietary driver performance in 10.10 I've just upgraded to Maverick 10.10 beta and notice heavy performance penalty on my Nvidia GT240 card. Will it be fixed for release?\nEDIT:For me, 260.19.12 fixes all bugs. Perfomance & stability now perfect!\n\nA: For those that don't know the specifics, the driver version is the recently-released 256.53. This was released in a rush after the previous version turned out to be a huge performance slug in certain situations.\nHowever, there are still lots and lots of people (myself included) having problems with 256.53. This may be related to the kernel (as everybody involved seems to be on 2.6.35) but either way, the fix has to come from Nvidia.\nAnd even if they do managed to get a new version out before Maverick releases, it needs testing and pulling into Ubuntu. Do not trust to hope.\nI personally suggest you report your issue, along with a bug log (read the stickies) on the nvidia linux forum. In my experience, you'll get a lot more feedback there than you will through the standard support mechanism.\n\nA: If performance is really woeful and you can extract some specific test-cases which exhibit this terrible performance then it can be possible to fix or work-around the slowness.\nFor example, earlier in the cycle there was a huge performance regression in Cairo which resulted in gradient drawing becoming incredibly slow.  That was discovered to be due to Cairo turning on support for server-side gradients, which the drivers didn't support properly.  And so Cairo was patched to avoid the slowness.\nIn that case the problem was narrowed down by a small test-case: rendering a GTK progress bar, which had a gradient on it.\nIf you can come up with a small, simple test-case, there's hope - you can file a Launchpad bug.  If not, head to the nVidia forums as others have suggested.\n\nA: Proprietary drivers can only be improved or updated by the owner (Nvidia). Installing the nvidia driver will enable your 3D acceleration and allow Ubuntu to run Unity. To install the latest driver via terminal check this webpage out for an easy guide. Ubuntu Proprietary Drivers\n\nA: Most likely not.\nIt is the proprietary driver so there is not much Canonical or the community can do about it.\nThe only chance that it will be improved is if it is the kernel interface to the driver that is causing the performance penalty but I have no knowledge about that sort of thing.\nTry going to NVIDIA support.\n", "Q: How to troubleshoot Ubuntu One in Maverick beta? I just updated to the Maverick beta (actually it's a fresh install, and not an upgrade of 10.04).  But now \"Ubuntu One\" doesn't show up in my me-menu thing.  In addition, when I go to Ubuntu One from System->Preferences and attempt to log in from there it will sometimes look like it works, but other times it won't do anything.  When I go to the command line and type u1sdtool -s it will either say something like \"doing auth dance\" or \"auth failed\" and often it has never even prompted me to log in or try to get a new password (even though I know it's correct).\nAnyway, this is the main hangup I have with the Maverick beta.  I can't get to my ubuntu one account from the native client.\nIs this a widespread issue? Is there something I can do to fix this?\n\nA: The Ubuntu One team welcome any testing support that you can provide. If you encounter a problem during an Ubuntu alpha or beta phase, please file bugs at our Launchpad site.\nhttps://bugs.launchpad.net/ubuntuone-client\nBefore filing a bug, though, it would be helpful if you search/scan over the existing bugs in order to reduce duplicates.\nThe issues that you point out have already been reported so we're working on them ;) They should be revolved very soon.\nThanks!\n\nA: I had similar issues at one point, iirc these steps fixed it for me... but I can't test it atm.\n\n\n*\n\n*Quit the Ubuntu One client (open a terminal window & run \"u1sdtool -q; killall ubuntuone-login\" without the quotes)\n\n*\n\n*Open Applications->Accessories->Passwords and Encryption Keys\n\n*Click on the plus symbol next to \"Passwords: login\" to expand the list\n\n*Right-click on the Ubuntu One token and select \"Delete\"\n\n*Go to https://one.ubuntu.com/account/machines/\n\n*Click on the checkbox next to your computer\n\n*Click the \"Remove selected computers\" button\n\n*Open System --> Preferences -->Ubuntu One\n\n*a web page should open, prompting you to add your computer to your Ubuntu One account\n\n*Add your computer\n\n\n", "Q: Disable wireless on startup I use Ubuntu 10.04 and I see, that every time when I start it enables Wireless Connectivity.\nI know, that there is a topic about it on Ubuntu forums, but I think I will get old before I get an answer there (if there is one). \nI would like to disable it by default, but to have possibility to enable or disable it later.\nI want to know how to disable the wireless adapter. Something like Fn + ... in Windows, but in windows it remembers the last state. In Ubuntu the wireless adapter is always enabled at startup.\nWhen I press Fn+F2 it disables those diodes and Wireless + Bluetooth.\n\nA: You can stop it connecting to specific connections automatically quite easily.\n\n\n*\n\n*Right click the Network Manager notification applet\n\n*Click Edit Connections...\n\n*Under the Wireless tab, click edit on the connection(s) you want to disable by default and click edit.\n\n*Uncheck Connect automatically\n\n*Click apply, close the window, rinse and repeat.\n\n\nWhen you want to connect, just left click the applet and select an access point.\nNote: This doesn't power off the wifi card and it'll still be searching for wireless access points. This might not be what you're looking for. But if it is, great!\nNote 2: If your connection drops, it won't automatically reconnect.\n\nA: Create session on startup application such as:\nSettings >> Preference >> Startup Application\nAdd then fill command :\ndbus-send --system --type=method_call --dest=org.freedesktop.NetworkManager /org/freedesktop/NetworkManager org.freedesktop.DBus.Properties.Set string:org.freedesktop.NetworkManager string:WirelessEnabled variant:boolean:false\nfalse means off but it can be to enable by fn+F2 or something else.\n\nA: There are so many ways to disable the card. The simplest I would say would be to put:\nsudo ifdown wlan0 \n\nin your /etc/rc.local above the line exit 0. This should disable the wireless card (replace wlan0 with your wireless interface card)\nIf you want to enable/disable on a keyboard press, this thread on Ubuntu Forums explains how to link a keyboard event to a script. If you want it to toggle when you push keys you will have to add some logic to the script. Though the simplest way might be to have one key to enable and another to disable.\ndown script\n    #!/bin/bash\n    IFACE=wlan0\n    ifconfig ${IFACE} down\n\nand \nup script \n    #!/bin/bash\n    IFACE=wlan0\n    ifconfig ${IFACE} up\n\n\nA: I use wicd instead of NetworkManager.\nIt remembers wi-fi state after reboot/next boot. Don't know how, but it does. :)\nIf you don't need some NM features, use wicd. It's easyer to use and control.\n\nA: If your FN+F2 do not work in Ubuntu (it should, mine does in an Asus EeePC netbook), then i really reccomend you using Jupiter. Its a sweet, well polished notification area applet.\nWith it, you can enable and disable Bluetooth and WiFi separately, as well as other nice controls for notebooks and netbooks. It remembers the state after reboot and even remember the state per power source (meaning it can always turn WiFi ON when you plug in power, and automatically turn it OFF when you are on battery). And you can bind all actions to keystrokes.\nA nice review, and some screenshots: http://www.webupd8.org/2010/06/jupiter-take-advantage-of-asus-super.html\nOfficial project page: http://www.jupiterapplet.org/\nPPA (for automatic updates in APT/Synaptic/Software Center: https://launchpad.net/~webupd8team/+archive/jupiter\nWiki (great thecnical documentation): http://sourceforge.net/apps/mediawiki/jupiter/index.php?title=Main_Page\n\nA: Wireless can be enabled or disabled using rfkill tool.\nHere is solution based on it, that will allow to save state and restore it at system startup.\nStep 00: creation of file to store wifi state\ncd /usr/local/etc\nsudo touch .wifistate\nsudo chmod 666 .wifistate\n\nStep 01: script\n    #!/bin/bash\n    IFACE=\"wlan1\"\n    STATE_FILE=\"/usr/local/etc/.wifistate\"\n\n    STATE=\"$(iwconfig $IFACE | grep Tx | cut -d '=' -f2 | grep off)\"\n    if [ \"$STATE\" ]\n    then\n       rfkill unblock wifi &&\n       echo 1 > \"$STATE_FILE\" &&\n       echo \"Wireless enabled\"\n    else\n       rfkill block wifi &&\n       echo 0 > \"$STATE_FILE\" &&\n       echo \"Wireless disabled\"\n    fi\n    exit 0;\n\nStep 10: making script executable\nchmod +x <script name>\n\nStep 11: modifying Ubuntu startup script\nopen /etc/rc.local in any text editor (must be edited as root) and add following code \nbefore exit 0; line:\n    FILE=\"/usr/local/etc/.wifistate\"\n    if [ -r \"$FILE\" ]\n    then\n       if [ $(cat $FILE) -eq 0 ]\n       then\n          rfkill block wifi\n       fi\n    else\n       rfkill block wifi\n    fi\n\nDone, now script from step 01 may be linked to keyboard event. After first use it will write 0 or 1 in .wifistate file, and on system startup rc.local script will take attempt to read this value and, if it is 0, disable wifi. \nIf .wifistate file does not exist, by default wifi will be disabled at startup.\n\nA: try sudo iwconfig wlan0 txpower off\nreplace wlan0 with eth2 or whatever is your wifi interface.\nthis will disable your wifi antenna and save power, but it doesn't prevent Network Manager from trying to connect so you might want also to disable network manager's wifi auto connect settings as described by Oli.\n\nA: Try looking under 'System > Preferences > Network Connections > Wireless' and make sure none of the listed wifi spots are set to auto connect. This will not stop wireless starting, but will stop it from making any connections.\n\nA: Install sysv-rc-conf then run it as root and make sure there is an X at runlevels S 0 1 2 for wpa-ifupdown or simply type sudo sysv-rc-conf --level S012 wpa-ifupdown on after installing.\n\nA: Run sudo lshw -c network and look for the name of the driver for your wireless card. Run lsmod | grep DRIVERNAME to show the exact name of the driver. Then add a line to /etc/modprobe.d/blacklist.conf that says blacklist EXACTDRIVERNAME. This will stop the wifi module from being loaded at boot time. Run sudo modprobe EXACTDRIVERNAME at any time to restart the wifi.\nThis works quite effectively, but is not the best solution. It does not disable the Wireless card. It just prevents the OS from using it, but it may still be on, consuming battery power.\n\nA: Whatever the reason is for what you're trying to disable it, I'm not sure if it works for every laptop, but it worked for me: with a plugged LAN cable Ubuntu ignores the wi-fi, thus making you able to sorta \"turn it off\" prior to system loading.\n\nA: Bruteforce would be the blacklisting of the wifi-kernel modules:\n\n\n*\n\n*dmesg | grep atheros (or whatever in your pc) or lsmod\n\n*look for that driver/module in /lib/modules//kernel/drivers/wireless/...\n\n*create a blacklist file \"no-wireless.conf\" in dir /etc/modules.d, containing\n# blacklist wifi\nblacklist [a blacklist line for each name of your wifi modules eg. ath...]\nblacklist rfcomm\nblacklist mac80211\n--\nBut you can't enable wifi anymore after boot, except you remove this file from modprobe.b and reboot \nPS: Don't forget, before you should backup your system somehow (eg with ubuntu live or whatever)\n(Sorry didn't read that post underneath)\n", "Q: How to make my own Dropbox / Ubuntu One server at home? Does anybody know of any resources that can show me how to make my own \"Dropbox, Ubuntu One\" server at home?\nI really like the idea of these services, but I don't want to put my 'stuff' in the clouds. Ideally, it should have a client that runs on Linux and Windows.\nI tried to setup iFolder on my Ubuntu 10.04, but without any success so far.\n\nA: i heard about Syncany on the Ubuntu UK Podcast, currently beta but looks like it meets the requirements\n\nA: There are actually lots of them.\n\n\n*\n\n*SparkleShare (deps: git/subversion, mono, python) at github\nGUI-based sync software.\na. Versioning: through a source control system, hence it's mutex-based on a central server through a version number.\nb. State: under development\nc. Pros: OSS, mono-based so easily moddable, Cons: user-level process, GC-dependent, ineffective sharing protocol by orders of magnitude as git is primarily for small text files, fairly hard to compile (I tried). Using high-level tools.\n\n*lipsync (deps: Unison, rsync)\nCommand-line service-based software.\na. Versioning: through the rsync delta algoritm. I assume programmer must choose conflict resolution.\nb. State: I can't find its source code, so I have no idea. The only things in his git repo are binaries.\nc. Pros: nice setup, using middle-level tools.\n\n*iFolder - Novell's Dropbox. \nI haven't studied its source yet. I just want to get this edit over with and if people are interested I'll add more.\na. Versioning:\nb. State: Problematic getting it to even compile on Ubuntu, let alone packages. Here's a detailed install guide.\nc. Pros: Windows X64 client, mature, AD-integration with ACLs, features no other project has started to implement. I think this might be a good starting point. Cons: Novell might not use its public svn repo as the primary repo and only do code-drops. I don't know exactly about this though. Might be too coupled to openSUSE to easily install on Ubuntu. To check out its algorithms.\n\n*scp/rcp - deprecated in favor of rsync\n\n*DRDB - block device mirroring tools for distributed RAID-1, i.e. a server-variant of dropbox. I haven't checked out its source code yet, but it's linux only. The actual algorithm would probably be easy to combine with the source code in my musings below this software-listing.\na. Versioning: internal message format over LAN/WAN\nb. State: seems mature enough\nc. Pros: stable enough for linux, Cons: no other operating systems are supported\n\nRight now I'm investigating improving compile-times on a Virtualized Windows 7, where the compile-times on a Windows 7 on metal is 40 s, but virtualized approx 3m 20s. I'm thinking of writing an ioctl driver that is a write-through cache that looks like a ram-disk for selected folders on NTFS.\nUsing the above software, I think a week's worth of 2-3-person full-time development would produce a usable Alpha that doesn't lose you files by combining the above softwares.\n\nOn my system then, the general idea would be;\n\n\n*\n\n*Mount a virtual drive \\?{GUID}, that is the ram-disk and RW-cache. The software creating this virtual drive takes two input parameters (that are vital):\na. The target folder; this is the SMB folder, so I will be letting the operating system's network stack handle the actual IO. In my case this is in turn the VMWare virtual folder, that has in itself a target on an ext4 drive, but it could easily be your file server using SAMBA/SMB.\nb. The path of the folder to be mounted, e.g. C:\\ramdisk    \nThis code for creating virtual volumes be taken from TrueCrypt's code, in /Driver/DriverFilter.c (among other files)\n\n*The drive uses SMB/the VMWare/network protocol to fetch data when it starts; it fetches with a low task priority, asynchronously from the network and fills its cache. It could use a simple compacting algorithm and have 1 thread that uses message-box type continuation passing to get great performance. On Windows it could use the normal async IO calls, and on linux it could use the epoll/inotify implementation and take code from nginx.\n\n*My service that is the ram-disk mounts the unnamed ramdisk drive as an NTFS folder. All programs can continue writing to C:\\ramdisk, or whatever I call it.\n\n*Async copy from network still going on. With a read-rate of approx 100 MiB/s and 2 GiB ramdisk, it would be 20.5 s to read all data.\nEach call to read would perform an in-CPU calculation of the index into a fixed n:ulong GiB max sized array. It would require conflict resolving though or read-write locks. If we'd implement a conflict-resolve algoritm like those available through Microsoft Sync, we could pass each chunk that conflicts as a message to another conflict resolve-process. Dropbox solves it by creating a new file and naming it \"PrevFileName Username's Conflicted Copy (yyyy-MM-dd).ext\". Perhaps this could be altered through a small widget, if one is compiling against that single source -- the widget would detect outstanding changes as messages/events and choose the conflict resolution protocol. As such, when programming against a folder in exclusive-mode, the Windows VM could set the widget to 'exclusive'.\nThis would have these PROs\n\n\n*\n\n*It would be non-blocking / async\n\n*It would make the assumption but not require that one computer will be writing mostly to the files.\n\n*It would work for arbitrarily large files\n\n*It would work on *nix and Windows by tying together the mentioned projects.\n\n*It would work when high read-performance is needed (i.e. the files are physically located on disk)\n\n*When the conflicting events are reached, one could provide a user interface app that allows the user to write/download plugins that act sanely for different sorts of events -- i.e. different sorts of files. E.g. a text file could be brought up with Kompare/WinDiff, while a binary would be duplicated and saved as another file.\n\n\nA: Currently there's not a great open source alternative that's going to work out of the box. The best thing to keep an eye on is the sparkleshare project: http://www.sparkleshare.org/\nHopefully that will grow into a great, do it yourself, alternative. \n\nA: I don't think this is quite what you are looking for, but it depends on your intended usage.\nCrashPlan is a backup software package and related online backup hosting service, but what's different is that their software has a mode that allows you to have your data backed up over the internet (or LAN) to another PC running the software.\nThis means the destination doesn't have to be in the cloud. It's not quite like dropbox in that it's more about backing up rather than syncing and accessing files from everywhere, but if it's just backups you want then it works well. If you want to access the backed up files from the other PC I think you can do a \"local restore\" but it's not something I've tried.\nThe basic software package is free and supports the \"backup to another computer\" mode, but only does scheduled backup but there is a \"pro\" version of the software that also costs and does real time syncing rather than just the scheduled backups. (Cloud storage is also an optional pay per month extra)\n\nA: I use Unison for the client and rsnapshot (rsync with perl script) for backup the server.\n\nA: If you want to set up two (or more) machines with a replicated folder, have a look at glusterfs.\nIt is easy to set up if you follow the GlusterFS User Guide.\n\nA: No one's mentioned bitorrent sync? Runs on anything - Ubuntu, windows, many common smartphone OSes, raspberry pi.... you name it, it probably works, and as a regular user. Encrypted transfers, files arn't stored on the cloud (though I think bittorrent runs the tracker for it), reasonably fast, you can selectively share folders, and almost no complication involved, you just need to copy and paste a key to the other system. \nOnce it is set up, it just works.\n\nA: OwnCloud! sounds like something you're looking for.\n\nA: I'm keeping my eye on AeroFS. It looks like it could be a Dropbox-like service where storage in the cloud is optional. Don't know if/when they will implement mobile support and I guess that would require that you sync those files to the cloud aswell. I'm primarily interested in a fairly painless syncing solution between Windows, Mac and Linux computers.\nThey are in early beta but you can signup for an invite if you want.\n\nA: I use apache with mod_dav (webdav) for a apache webserver, I can mount it as a drive and up/download files over web. This is pretty simple, but might cover your needs.\n\nA: While there are interesting alternatives listed here already and this is an older question, I am convinced that this topic is clearly not outdated and - on the contrary - is gaining more and more importance, due to the last privacy breaking events.\nI want to share my own experience therefore.\nMy current solution for an own hosted cloud alike environment is Seafile.\nSeafile features:\n\n\n*\n\n*Web based cloud access\n\n*Clients for Linux, Windows, Mac, iOS (not free), Android\n\n*User/group management\n\n*File organization via different libraries\n\n*Automatic file synchronisation via client software\n\n*Possibility to publish files via creating public links\n\n\nMy Seafile experiences:\n\n\n*\n\n*Installation was dead easy and quick! (on a slim debian vm, with files stored via share to the physical host dmraid 5)\n\n*User interface clean and functional\n\n*Client software clean and functional\n\n*There were no functional issues for me, until now! (using this since a few weeks now)\n\n*Feature set is basic (compared to owncloud e. g.), but I emphasize that everything works here!\n\n*No direct proxy support (at least for the linux client - and the webinterface!). Note: the webinterface works, but download of files via webinterface does not work behind a proxy - don't know if this is possible somehow\n\n\nAs I don't need proxy support, I am really satisfied with Seafile!\n\nA: I use SSHFS to mount directories on my server as local directories on my desktop and laptop.  All file changes are saved directly onto the server.  Unlike dropbox though, the files are not stored locally on your client machines.  I think this is great because you don't have to worry about syncing and versioning, but it's not ideal for offline use or very large files.\nIt's very direct and simple, and I find it to be the best solution.  The only thing I don't use it for is large media like pictures and movies because all files get accessed over the network.  Those I sync with Rsync.\nLink to SSHFS documentation --> http://fuse.sourceforge.net/sshfs.html\n", "Q: Download Flock browser in command line Is Flock browser available in Ubuntu 10.4. If so how do I download in command line. Is it perhaps:\nsudo apt get Flock browser\nNot sure, will appreciate some help. Thnxs\n\nA: From the commandline I would do (using GetDeb-Packages):\nsudo bash -c \"echo deb http://archive.getdeb.net/ubuntu lucid-getdeb apps games >> /etc/apt/sources.list\"\nwget -q http://archive.getdeb.net/getdeb-archive.key -O- | sudo apt-key add - \nsudo aptitude install flock\n\n\nA: Try something like:\nwget http://ftp.osuosl.org/pub/flock/releases/2.0.3/l10n/en-CA/flock-2.0.3.en-CA.linux-i686.tar.bz2\nUnpack and follow the installation instructions.\n(That's en-CA for Canadian English; there are different localizations.)\n\nA: I've written up a how-to previously, here.\nYou'll have to install libstdc++5 so it works properly.\n\nA: It is probably not available in the core repositories:\napt-cache search flock\n\nreturns nothing like that on an Ubuntu system.\n", "Q: Clock running too fast I'm currently (for some days now) having the problem, that my Ubuntu clock runs too fast. and by too fast I mean like: last time I adjusted it was at 4 PM, now (10:25 PM) it shows 10:57 PM ! Any ideas how to fix that?\nCould it have something to do with handbrake? (I'm currently ripping my DVD collection, so handbrake is always running).\nMy System:\nUbuntu 10.4, all updates, handbrake from getdeb (0.9.4 I think), Intel Core2Quad, 4 GB Ram, NVidia GTX 260 (195.36.24 according to nvidia-settings)\n\nOutput of dmesg \nOutput of cat /proc/interrupts\nOutput of cmdline:\nBOOT_IMAGE=/boot/vmlinuz-2.6.32-24-generic\nroot=UUID=082d6800-413b-43d7-b4d1-b96b0d774f32 ro quiet splash\n\n\nA: Maybe your CMOS battery is getting empty (the battery on the motherboard itself).\nYou can hit F1 (or DEL according to you motherboard) at the first seconds during pc starup to enter BIOS. \nin the BIOS you can check the hardware clock. \nJust let the computer run and check if the time stays correct (during this time you can't use your computer)\nIf the hardware clock is not running correctly, you can replace the battery.\nhttp://www.computerhope.com/issues/ch000239.htm\n\nA: While I'm not sure what is causing your system clock to drift so badly, you can install ntpd to keep your clock in hand - it continuously adjusts the system clock based on the calculated drift.\nsudo apt-get install ntp\n\nBy default it syncs to ntp.ubuntu.com but you can edit /etc/ntp.conf if you want to change the NTP server. For more details see the NTP page in the server guide.\n\nA: If I recall an article I read once on lwn.net\nOnce the computer is booted it keeps track of time by the clock frequency of the system as this is more accurate than the quartz in the cmos and saves an expensive and (relatively) slow BIOS call.\nThere was a problem with virtual machines having their CPU time sliced that caused the problem.\nThis person has a good breakdown of how to edit the grub boot options:\nhttp://ubuntuforums.org/showthread.php?t=956263\nWhich basically says to edit the /boot/grub/menu.lst and add clock=tsc to the boot options\n\nA: Just a guess, try un-installing VirtualBox.\n", "Q: Alternative to Photoshop or Paint.NET I have been moving toward Ubuntu from a long time Windows development background. The one program I cannot seem to do without is a graphic editor. I have seen recommendations for programs, but they turn out to be directed at children or tailored to working with personal photographs.\nI am looking for something more for programming tasks like analysing colors, resizing, creating web graphics, etc. I have used Photoshop in the past and more recently have mostly used Paint.net for Windows.\nIs there a program for Ubuntu that covers this area?\n\nA: The only real issue interface wise is GIMP is not PhotoShop.  So if you learned where things are in PS then GIMP will be a bit frustrating at first.  Of course there are some folks who do there best to make GIMP like PS, like GimpShop (discontinued).\nHere is a good rundown of Linux based graphics programs:  http://www.linuxlinks.com/article/2008091312364896/Graphics.html\n\nA: For paint.NET?  Definitely Pinta.  And if you don't mind installing KDE dependencies be sure to try Krita as well.\nPersonally I barely use anything other than Inkscape, but that's because I do more creating than modifying.\n\nA: As GIMP does (several) things differently than the other software, may I suggest the following resources, which might help you get things done:\n\n\n*\n\n*http://www.gimpusers.com/\n\n*http://the-gimp.deviantart.com/ (tutorials, brushes, etc.)\n\n*http://gimp-users.deviantart.com/ (tutorials, brushes, etc.)\n\n*http://www.gimpedtutorials.com/\n\n*http://gimpguru.org/\n\n*http://registry.gimp.org/\n\n*http://tutorial-city.deviantart.com/gallery/24413134\n\n*http://blog.meetthegimp.org (added 2013-07-22)\n\n\nI hope they are useful to you.\n\nA: For a Paint.NET alternative look here: Is there a Paint.NET alternative?\n\nA: GIMP (install) should do the job.\nMany people I know complained that GIMP has an awkward and unintuitive user interface, but hopefully you can get used to it and get the job done.\n\nA: As others have said GIMP is an excellent graphics program. I personally have not had any problems with the interface - I find it pretty intuitive. It is one of the featured applications in the Ubuntu Software Centre.\nFor creating web graphics, Inkscape (also a featured app) may be a better tool. It creates files in SVG format and can export to the usual .png, .jpg, .bmp etc. SVGs are good because they are scalable, so don't deform when resized. They also have the ability to be interactive using Javascript. SVG is a web standard.\nSpecifically for the 'programming' side of things you could use ImageMagick. It has a command line interface and also has bindings to many popular languages (including C, C++, perl, python, ruby, java). The ImageMagick program and its various language bindings are available from the software repositories.\nTo automate simple processes such as resizing, you can use Phatch. It is available from the software repositories.\n\nA: I'm using GIMP most of the time for adjusting photos (f.i. color-balance, gamma-correction), retouching (removing unwanted objects) and even changing the background.\nPicasa3 is a useful photo-management-program with some basic features (clipping, red-eye-removal, changing color-ratio, ...). Most of the people I know are happy with Picasa. I primarily use Gimp and use Picasa afterwards to upload the photos (sharing, printing, saving)\nSometimes I use Xara Xtreme to create some extra effects.\n\nA: You can also try proprietary Pixel\nIts interface is very similar to Photoshop.\n\nA: Or, you could just go on line to http://pixlr.com/editor/  and use it for free without any download or installation. It will open your psd with layers, and has most of the same effects.\n Deal-breakers for me are no rulers or guides, and canvas size in pixels only, no option in inches, so not good for printing exact sizes.\n\nA: Have a look at Bibble. This commercial photographic workflow program works fine, very fine, on my Ubuntu 64 bit machine.\nThe look and feel are much like Photoshop.\n\nA: As far as I know, GIMP would be your best free alternative to Photoshop. By far. If you are unhappy with GIMP consider using Photoshop through WINE. To see how, Click here\n\nA: GIMP should be the answer for both paint.net and Adobe Photoshop. I have been using GNU/Linux since 2002 and i am a professional photographer and graphic designer and i know the importance of Adobe Photoshop. I should say that more than 95% of what you can do in photoshop can be done in GIMP. This is your best alternative. Don't worry about the user interface, once you get used to it, you will become super-productive.\n", "Q: How do I install fonts? How do I install fonts on Ubuntu Linux? I need them to be available in gimp.\n\nA: Copy the fonts to /usr/local/share/fonts or a subfolder (such as /usr/local/share/fonts/TTF) and then run sudo fc-cache -fv. There are some graphical programs you can install to make this easier, but I've never felt the need to try any of them. The Ubuntu wiki page on Fonts here may be of help too.\nGIMP will find them in there then.\n\nA: Installing font is just copying its file to specific directory.\nThere can be different directories on different systems. For example at my system they are:\n\n\n*\n\n*/usr/share/fonts/ — fonts for all users \n\n*~/.local/share/fonts/ — fonts for particular user\n\n\nThere can be any subdirectories you want. It may help you to organize your font collection. \nHere is the command to get list of font files that your system uses.\nfc-list -f '%{file}\\n' | sort\n\nLook at it and you'll get the idea of where fonts are located in your system. \n\nA: Installation of fonts from 3rd party websites is almost too easy. Download and save the file somewhere to your computer:\n\nThen double click the font to load the font interface:\n\nSelect the Install Font button located at the bottom right of the screen.\n\nA: There is also an application called fontmatrix that can help install and manage fonts on Ubuntu. To quote the introduction on the website:\n\nFontmatrix is a real Linux font manager, available on any platform and as well for KDE (which already had Kfontinstaller) as for Gnome.\n  It's purpose is to recursively query the fonts (ttf, ps & otf) in the directories you give it to search, sort them quickly, (avoiding bugged or broken ones) and show them.\n  Then, you can tag them, sub-tag, re-sort according various tags, preview... Even create a pdf Font Book...\n\n\nFontmatrix has been available to install from the Ubuntu universe repository since jaunty, and version 0.6.0+svn20100107-2ubuntu2 is currently in maverick and natty. A brief explanation about using fontmatrix is available on their website.\n\nA: Many fonts are packaged for Ubuntu and available via the \"Fonts\" category of the Ubuntu Software Center. If you prefer apt-get, search for packages starting with otf- or ttf-.\nFont files that are placed in the hidden .fonts directory of your home folder will automatically be available (but /etc/fonts/fonts.conf indicates it will be removed soon.). You can also place them in the ~/.local/share/fonts directory on newer versions of Ubuntu per the comments below.\nYou can also double-click on the font file (or select Open with Font Viewer in the right-click menu). Then click the Install Font button.\nIf you need the fonts to be available system-wide, you'll need to copy them to /usr/local/share/fonts and reboot (or manually rebuild the font cache with fc-cache -f -v).\nYou can confirm they are installed correctly by running fc-list | grep \"<name-of-font>\"\nYou may need to restart some programs, like OpenOffice Writer, before they actually show the new fonts (usually such programs are caching the font list when they start up).\nEdit: Changed advice to manually install into /usr/local/share/fonts instead of /usr/share/fonts to reflect comments and best practice.\n\nA: Also, there are lots of fonts available as software packages. Font packages are named in the form ttf-* or otf-*. It is better to install fonts as packages instead of manually if possible. You can use tools such as Synaptic, apt-get or the Ubuntu Software Centre. The Software Centre has a dedicated fonts section.\n\nA: In addition to manually installing them inside ~.fonts (see bobince's answer) and FontMatrix (what nhandler shows you), there is also another font manager aptly named Font Manager (install Ubuntu package for 10.10, or download package for 10.04 and maybe older versions) that is quite lightweight (and has a Gtk GUI).\n\nA: If you want to have fonts available exclusively to Gimp, see this answer.\nIn a nutshell, you copy the fonts files to Gimp's own font folder, or tell Gimp where you have the folder(s) with your fonts.\n\nA: Another question, about installing Google Fonts, was closed as a duplicate of this one, though it isn't really (being rather narrow).\nA better answer than the one provided there (i.e. to go to Google Fonts and look up the font and go through their weird downloading system) is to get it directly from Github, e.g.:\nRoboto Mono font files\nThe rest of them are available at https://github.com/google/fonts/tree/master/apache, and there's also a ZIP file of them available from the main https://github.com/google/fonts#readme page.\nSo, if you want to script this stuff (e.g. regularly download the latest version), you can do it with a Git checkout, or by using wget or curl to pull down the exact files you want.\nPS: There's another duplicate question at \"Downloading Google Fonts\". It details some other methods, like using an installer script from googlecode.com and (for more than the Google Fonts) using tasksel.\n\nA: You don't have to install as root. Create a folder called .fonts in your home directory (if you don't already have one), drop the font file in there, run Gimp, job done.\n(You may have to enable Edit->Preferences->Views->Show hidden and backup files in Nautilus to be able to see .fonts and other ‘hidden’ folders in your home, if you haven't already.)\n\nA: If you install font(s) in folder .fonts in your home directory (another directory $HOME/.local/share/fonts in ubuntu 18.04 is ok) , you may need to run fc-cache -rv (not sudo) in order to cache fonts in your home directory as well.\n\n\nA: Font Manager\nApplication for Install and Manage fonts.\nCan install Multiple Fonts.\nTo install fonts Click on Manage Fonts Button and select Install Fonts Option.\n\nFont Manager can be installed from apps.ubuntu.com or and with Software Centre. If with commandline ;\nsudo apt-get install font-manager\n\n\nA: This method worked for me in Ubuntu 18.04 Bionic Beaver.               \n\n\n*\n\n*Download the file containing the desired fonts.\n\n*Go the directory where the downloaded file is.\n\n*Right click on the file. A black \"Box\" will appear with many commands.\n\n*Select \"OPEN WITH FONTS.\" Right click on it.\n\n*Another box'll appear. You'll see a green \"INSTALL\" button at the top right corner.\n\n*Click on that and the fonts will get installed.\n\n\nYou can go into the fonts directory or use a program like LibreOffice to verify the installed fonts.\n\nA: I think the best way is to use gfinstall script, install it and you just say gfinstall whicheverFont and it will install it, you can also specify it to install locally (for the current user) or globally for all users\nEdit: I made this script so that I don't have to download, copy and paste fonts each time\n", "Q: dosfsck \"Unable to create unique name\" I have an Archos 605 media player that seems to have become corrupted, so I'm trying to run fsck on it. It mounts as a FAT32 hard drive, so I ran \n\nsudo dosfsck -a\n\nand this is what I got:\n\ndosfsck 3.0.7, 24 Dec 2009, FAT32, LFN\n  There are differences between boot\n  sector and its backup. Differences:\n  (offset:original/backup)   65:03/00\n  Not automatically fixing this. Unable\n  to create unique name\n\nI suspect this means I'm screwed, but I'd appreciate any additional insight from someone who knows more about dosfsck than I do.\n\nA: it sounds like the partition table is screwed up. \nFortunately there is a good linux tool to get it back working\n\nhttp://en.wikipedia.org/wiki/TestDisk \nsudo apt-get install testdisk\nthe wiki contains a good guide for exactly your problem (recover fat32 partition)\n\nhttp://www.cgsecurity.org/wiki/TestDisk_Step_By_Step\n\nA: Another solution I use:\nfsck.vfat -r /dev/sdXn\n\nI asked for use partition table backup (yes) and fix some clusters issue (I select no).\nAfter that I rerun and fix Free cluster summary wrong. Next I run:\nsudo dosfsck -w -l -a -v  /dev/sdXn\n\nand it report that all ok!\nSee blog http://tech-vaults.blogspot.com/2011/10/fsckvfat-unable-to-create-unique-name.html\n", "Q: Automatically change resolution when connecting an external monitor, nvidia driver I run ubuntu on my macbook pro, with nvidia proprietary driver.\nI've made a little hack script http://www.coldcode.net/2010/05/nvidia-auto-display.html which detects the presence/absence of an external monitor and switches the resolution accordingly.\nDoes anybody know of a better way to do that? \nMy script also works around specific issues of the nvidia partial xrandr implementation; assuming a xrandr compliant xorg driver, is there a way to do the same thing in a less hackish way?\n\nA: Have you heard of disper ( http://willem.engen.nl/projects/disper/ ) ?\nAlso has a PPA under http://launchpad.net/~disper-dev/+archive/ppa\n\nA: I've found that running gnome-display-properties (on 10.04 at least) will automatically detect and configure my resolution based on the monitors I have connected at the moment.  Then I can simply dismiss it (using the 'Close' button, 'Apply' works also but requires confirmation which takes another click and is unnecessary).  So I've added an icon to my topbar and so far that's been so much better than resetting X like I used to do that I've been to lazy to look for a one click solution or even an automatic one such as your script.\nI have a large monitor at work but usually just use my laptop alone at home so its 2 clicks when I get to work in the morning and 2 when I get home.\nUpdate:\nShould have checked first.  I'm actually NOT using the proprietary driver right now and I vaguely recall that's because having compiz effects was less important to me than not restarting X twice a day to switch monitors.  So my answer may be completely useless to you.  I'll delete if anyone can confirm that.\n", "Q: How to troubleshoot/bug report a problem that only appears right after startup? Recently the network manager applet has been crashing immediately after startup and only at startup. It remains stable throughout the rest of the day.  How would I begin to discover what the issue is?  There must be a general method of attack on a problem like this.  Normally I would try running the program from the terminal to see if any error messages are printed but nm-applet does not seem to crash once I restart it.\n\nA: You might want to look into ~/.xsession-errors for relevant error messages.\n\nA: dmesg.  I'd also collect the chipset and driver versions of all your network devices and confirm there are no open bugs in Launchpad for network manager.\n", "Q: How can I stop bluetile from changing the window manager theme? When I start bluetile it replaces the current theme of the window manager. How can I keep the current theme and settings, and still use bluetile?\n\nA: If I'm reading the bluetile site properly, it is a window manager itself, so when you load it, it replaces your window manager, which is where your theme is coming from.  If you watch the video he explains the theme, the buttons have been modified to fit in with the tiling aspect of things.\nthats my guess at least.\n", "Q: How can I set different sensitivities for two mice at the same time? I often use a USB mouse and my laptop's pointing stick at the same time. I can adjust the sensitivity in Mouse Preferences, but the sensitivities of the two mice are so different that I cannot find a compromise setting.\nIs there a way to specify a different sensitivity setting for each mouse?\n\nA: You can use xinput to set the sensitivities/accels for the mice.\n$ xinput list\n⎡ Virtual core pointer                      id=2    [master pointer  (3)]\n⎜   ↳ Virtual core XTEST pointer                id=4    [slave  pointer  (2)]\n⎜   ↳ Logitech USB-PS/2 Optical Mouse           id=8    [slave  pointer  (2)]\n⎜   ↳ Microsoft Microsoft® Nano Transceiver v2.0    id=10   [slave  pointer  (2)]\n⎜   ↳ Microsoft Microsoft® Nano Transceiver v2.0    id=11   [slave  pointer  (2)]\n⎜   ↳ Macintosh mouse button emulation          id=13   [slave  pointer  (2)]\n⎣ Virtual core keyboard                     id=3    [master keyboard (2)]\n    ↳ Virtual core XTEST keyboard               id=5    [slave  keyboard (3)]\n    ↳ Power Button                              id=6    [slave  keyboard (3)]\n    ↳ Power Button                              id=7    [slave  keyboard (3)]\n    ↳ Microsoft Microsoft® Nano Transceiver v2.0    id=9    [slave  keyboard (3)]\n    ↳ AT Translated Set 2 keyboard              id=12   [slave  keyboard (3)]\n\nFrom that output take the numeric id of the mice. I'll provide an example for my Logitech mouse. For multiple mice rinse and repeat.\nSo for my logitech I will use xinput get-feedbacks <device name> and xinput set-ptr-feedback <device name> <threshold> <num> <denom>\n$ xinput get-feedbacks 8\n1 feedback class\nPtrFeedbackClass id=0\n    accelNum is 3\n    accelDenom is 10\n    threshold is 4\n\nThe accel is set as a fraction so you need to set the nom and denom for it:\n$ xinput set-ptr-feedback 8 4 3 1\n$ xinput get-feedbacks 8\n1 feedback class\nPtrFeedbackClass id=0\n    accelNum is 3\n    accelDenom is 1\n    threshold is 4\n\n", "Q: From the time Ubuntu font is released, how long will it take for major websites(facebook, yahoo, google etc.) to support it? The title explains it already...\n\nA: The font is supported on any website that uses generic font families - serif, sans and mono. If you want the Ubuntu font to be used, you will need to set the default sans font (the Ubuntu font will be a sans font I think) in your browser options to the Ubuntu font. You could even set the serif font to the Ubuntu font but you will get a 'sans' look instead of a 'serif' look. \n\nIt is unlikely that a website will set the font specifically to the Ubuntu font, if that's what you mean. Using a specific font is discouraged in web design because users might not have this font on their system. The closest you will get (this is only likely to happen on Ubuntu related sites) is to have sites that say 'use the Ubuntu font if possible and fall back to the default sans font if the Ubuntu font is not installed' by setting the font-family to \"ubuntu,sans-serif\".\n\nA: Supported? never.\nBut if you like to use it anyway, take a look at http://code.google.com/webfonts or http://typekit.com/\nHowever, this question belongs more to http://doctype.com/ \n\nA: Since most websites only use the most standard fonts, the answer is: Probably never.\nBut seriously... :)\n", "Q: Change font used in the tab-bar of TreeStyleTab Firefox 3.6.8 on Ubuntu 9.10; using TreeStyleTab 0.10.2010040201.\nI use the tab-bar on the right, and I would like to see more of the tab names without widening the bar. The default font used is Sans, I believe; I would like to use something like condensed DejaVu Sans. I haven't found anything in the settings, nor in the about:config page, so I presume I can play some .css trick, but I don't know where to start.\nHow can I do this change?\n\nA: Install Stylish extension:\nhttps://addons.mozilla.org/en-US/firefox/addon/2108/\nThen add this script:\n@namespace url(\"http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul\");\n\n.tabbrowser-tabs .tab-text {\n font-size: 4mm !important;\n font-family: Condensed DejaVu Sans !important;\n font-weight: bold !important;\n color: #ffffff !important;\n text-shadow: 0 0px 2px rgba(0,0,0,2),\n        0 0 1px rgba(0, 0, 0,1) !important;\n}\n\nChange options to your linking.\nIt will look like this:\n\n\nA: You can tweak firefox UI fonts, colors etc by editing the userchrome.css file. The process is explained with a long list of snippets for \"common\" tweaks here. Or if u just want to tweak the font, you can check this is a short tutorial.\nAs per the official mozilla howto\n\nNeither userChrome.css nor userContent.css exist by default. If\n  you want them, you create them in the\n  chrome subdirectory underneath the\n  user's profile directory.\n  userChrome.css controls CSS for the UI\n  chrome of the Mozilla application;\n  userContent.css controls CSS for\n  content inside windows.\n\n", "Q: Monitor resolution 1366 x 768, with bad EDID detected I'm having trouble getting a cheap LCD 18.5 inch monitor to work properly with Ubuntu 10.04.1. The brand is \"Great Wall\".\nIt's supposed to have resolution 1366x768, but I can only set it as 1360x768.\nI have Ubuntu installed on an external hard drive, and for what it's worth, at work I have a nicer 18.5 inch monitor, HP brand, also 1366 x 768, and it works perfectly when I boot there.\nI have tried using cvt, but it gives me this:\n$ cvt 1366 768\n# 1368x768 59.88 Hz (CVT) hsync: 47.79 kHz; pclk: 85.25 MHz\nModeline \"1368x768_60.00\"   85.25  1368 1440 1576 1784  768 771 781 798 -hsync +vsync\n\nI managed to add this 1368 x 768 mode to my xorg.conf, that I generated using some command I can't remember now (sorry!), but it looked just as bad as 1360 x 768, so I undid the change.\nI can live with it for watching video, but any extended OpenOffice session makes me want to poke my eyes out :)\nI'm using Intel graphics:\n00:02.0 VGA compatible controller: Intel Corporation 82915G/GV/910GL Integrated Graphics Controller (rev 04)\nAny suggestions? Can I get the EDID out of the HP monitor and try to override it for the monitor at home? (and cross my fingers)\nEDIT: I have added the xorg-edgers PPA, and it didn't make any difference.\nHere is my Xorg.0.log in case it helps: http://clippy.cz.cc/index.php?show=124\nEDIT2: I got the modeline for 1366 x 768 on the HP monitor at work. Going to try it at home and see what happens. This is what I got from the Xorg.0.log when booting the computer with my external HD with Ubuntu 10.04:\nModeline \"1366x768\"x0.0   85.50  1366 1435 1578 1790  768 771 781 798 -hsync +vsync (47.8 kHz)\n\nEDIT3: Tried the modeline above, and it gave similar results to modelines for 1360 and 1368.\nBut then I noticed something, so see below for the answer to my own question :)\n\nA: Well, this will teach me to actually spend appropriate money on monitors...\nThis \"Elcheapo\" Great Wall monitor (obviously made in China) just \"says\" that it can do 1366x768... What it actually does is simply accept higher resolutions, and downscale everything to 1280x768.\nI noticed in one of the info screens of the monitor setup menus (the ones you get by pressing the buttons on the edge of the monitor itself) that, no matter which modeline I set, it always reported the resolution as 1280x768, though I didn't get that resolution offered by the System->Preferences->Monitors application.\nSo I used cvt to generate a modeline for that resolution:\n$ cvt 1280 768\n# 1280x768 59.87 Hz (CVT) hsync: 47.78 kHz; pclk: 79.50 MHz\nModeline \"1280x768_60.00\"   79.50  1280 1344 1472 1664  768 771 781 798 -hsync +vsync\n$ xrandr --newmode \"1280x768_60.00\"   79.50  1280 1344 1472 1664  768 771 781 798 -hsync +vsync\n$ xrandr --addmode VGA1 \"1280x768_60.00\"\n\nThen I finally could choose 1280x768 resolution in the System->Preferences->Monitors application.\nAnd lo and behold! Fantastically clear, crisp text!!! I've lost 86 horizontal pixels over what was advertised, but it's well worth it.\nSomeday I might try this screen with Windows, but with no computer running that at home, it will be a while... But I doubt Windows can make pixel columns magically appear in an LCD screen! :)\n", "Q: Video tearing sorted now Low cube performance I've just sorted out the tearing in videos on my PC following this guide:\nhttp://ubuntuforums.org/showthread.php?t=1390284\nHowever before this i had a wonderfully performing cube, Nice smooth and no/very little tearing (at least only around the sides) Now however the cube feels slow when rotating and i get some sort of tearing (white lines) underneath my gnome panel when 'landing' on a desktop\nAny ideas how i can return to the previous performance of the cube without turning sync to VBlank off?\n\nA: The original questioner's comment on nate8nate's answer confirms that Ubuntu \"10.10 with the new 260 Nvidia graphics driver\" fixes the problems.\n", "Q: How do I modify my PATH so that the changes are available in every Terminal session I want to add a directory to search my search path. I know I have to modify the PATH environment variable. However, I want the change to be permanent, so that it is always in effect, for every Terminal (bash) window I open.\nThere is an overload of confusing and possibly conflicting information in https://help.ubuntu.com/community/EnvironmentVariables\nI am using Ubuntu 10.04. Suppose I want to add /usr/local/foo to my PATH. Which file (.bashrc, .profile, .bash_login, etc...) should I modify and what should the new line(s) look like?\n\nA: To reload .profile and take changes effects without logout/login, run:\nsource ~/.profile\n\n\nA: You can add the path to /etc/environment, but be aware that no shell expansions will work; the variable will be set to literally the characters you enter.\n\nA: Before setting a PATH variable, you need to understand why you are setting the PATH variable. The Path variable is where the system tries to search when you issue some command in your terminal.\nExample: whereis ls command shows ls is there inside /bin.\nThe ls command only works if /bin is registered in the path variable.\necho $PATH gives the currently registered locations. If you want to add another custom location to your path variable there are several ways you can try.\n\n*\n\n*PATH=\"$PATH:/someLocation\" New Path variable is only valid till your terminal closes. No other terminal will be affected. No subprocess can use the new variable.\n\n\n*export PATH=\"$PATH:/someLocation\" New Path variable is valid till your terminal close also all subprocesses will get the new Path variable. No other terminal will get a new variable.\n\n\n*export PATH=\"$PATH:/someLocation\"\nAdd this line into the .bashrc file present in your home folder. Which is called every time a new bash shell is created. This means you get a new Path variable exported every time a new terminal is opened. But this variable is created for only bash shells. You can use the old Path variable in other shells(ksh, sh, ssh ..).\n\n\n*export PATH=\"$PATH:/someLocation\"\nAdd this line into the .profile file present in your home folder. Which is called every time you log in. This means you get a new Path variable exported every time your session is created. Which is available everywhere.\nIf you can't find the .profile or .bashrc file in your home folder, try to create a new one. Sometimes these files won't be created by the system.\nps: Works in ubuntu. Open to any corrections.\n\nA: I got it to work by modifying ~/.profile\nIt looks like adding ~/bin to my path was a bad example, as there is already code in ~/.profile to do that automatically, if the directory exists.\nTo add the usr/local/foo directory to my path for every session going forward, I add/edit the following line at the end of my .profile:\nexport PATH=$PATH:/usr/local/foo\n\nHowever, to make this take effect, I needed to log out and log back in (simply closing the Terminal window and opening a new one did NOT work).\n\nA: You can modify the .bashrc file in your $HOME directory.\nAt the very end of this file, add the line:\nexport PATH=\"$HOME/directory_to_include_in_path/:$PATH\"\n\nYou can also modify the .profile file, also in your $HOME directory, including the following line:\nPATH=\"$HOME/directory_to_include_in_path/:$PATH\"\n\nThis worked for me.\n\nA: The following command adds a path to your current path:\nexport PATH=$PATH:/my/custom/path\n\nIf you want your setup to execute this command every time, there are a number of places where you can put it. When you login, the following scripts will be executed in this order:\n/etc/profile      (which starts by loading everything in /etc/profile.d)\n~/.profile        (which starts by loading ~/.bashrc if you are running bash)\n\nNotes\n\n\n*\n\n*~/.profile  is only loaded if ~/.bash_profile and ~/.bash_login DO NOT EXIST. Otherwise, at least bash, will load them instead. It is advisable to use .profile and not the bash specific scripts. So, if in these attempts you created .bash_login, please delete it now.\n\n*~/.bashrc is only loaded if you are running an interactive session. (something with a prompt where you can actually type something).\n\n*~/.bashrc is loaded again and again, every time you open up a new terminal. So a new tab in gnome-terminal, a new virtual terminal, etc. So even if you don't login again, .bashrc is loaded (and thereby resets its environment) every time you open a new shell.\n\n*Things like byobu should really go into .profile, (otherwise it won't work ;-)\n\n*Things like paths should go into .profile if you want them to work outside of the interactive sessions. (say when you press Alt+F2 in GNOME)\n\nA: If you have ohmyzsh goto your home directory via the terminal and type \nnano .zshrc \nAt the end of the file enter \n\nexport PATH=\"$HOME/directory_to_include_in_path/:$PATH\"\n\nFinally restart your terminal. Worked for me. Hope this was helpful.\n\nA: This is what worked for me\nWhile setting JAVA_HOME variable\nIn the Terminal, run to create the variable\necho 'export JAVA_HOME=“/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home' | sudo tee -a ~/.profile\n\nrun to add the variable to the Path\necho 'export PATH=\"${JAVA_HOME}/bin:$PATH\"' | sudo tee -a ~/.profile\n\nthen \nsource ~/.profile\n\nTo see if the variable is set correctly run\nvi .profile\n\nthen :q to quit\nTo modify the .profile file (In case of a correction) run\nsudo vi .profile\n\nPress I to insert.\nAfter modifications press Esc and :wq to save and quit. \n\nA: First add a shell script to the /etc/profile.d directory.\necho 'export PATH=$PATH:/path/to/app' | sudo tee /etc/profile.d/custom-apps-path.sh > /dev/null\n\nThe app will then be available via direct invocation the next time you login to the shell.\nTo make the app instantly available in the current shell, run the following command:\nsource /etc/profile.d/custom-apps-path.sh\n\n\nA: Going through the basics, I will suggest the following steps:\n\n\n*\n\n*It's recommended to set environment variables in /etc/environment\n\n*Open the file as superuser in an editor as it's a read only file e.g.    gedit:\ngksu gedit /etc/environment\n\n\n*System will need password to open it in editable mode. Enter your superuser password and get file opened in a new gedit window. \n\n*Add new line at the end of file with \nexport PATH=$PATH:/usr/local/foo\n\n*Save and close the window. It will get command back to terminal.\n\n*Refresh the environment by running the following command: \n. /etc/environment\n\n\n*You may check by executing the following command:\necho $PATH\n\n", "Q: suspend doesn't work on Dell Inspiron 1525 I'm having a Dell Inspiron 1525. Suspend and resume were working correctly.\nAll of a sudden, when I click the suspend menu option the system doesn't get suspended. Instead, it is being locked. Viewing dmesg output reveals\n[48214.876143] sky2 eth0: disabling interface\n[48215.844400] PM: Syncing filesystems ... done.\n[48215.872063] PM: Preparing system for mem sleep\n[48215.872070] Freezing user space processes ... (elapsed 0.00 seconds) done.\n[48215.873464] Freezing remaining freezable tasks ... (elapsed 0.00 seconds) done.\n[48215.873582] PM: Entering mem sleep\n[48215.873597] Suspending console(s) (use no_console_suspend to debug)\n[48225.872091] usbhid 6-2:1.0: suspend error -5\n[48225.872100] pm_op(): usb_dev_suspend+0x0/0x20 returns -5\n[48225.872104] PM: Device 6-2 failed to suspend: error -5\n[48225.872106] PM: Some devices failed to suspend\n[48225.876917] PM: resume of devices complete after 4.807 msecs\n[48226.076192] PM: resume devices took 0.204 seconds\n[48226.076203] PM: Finishing wakeup.\n[48226.076205] Restarting tasks ... done.\n[48226.388912] sky2 eth0: enabling interface\n[48226.390582] ADDRCONF(NETDEV_UP): eth0: link is not ready\n[48227.894532] sky2 eth0: Link is up at 100 Mbps, full duplex, flow control rx\n[48227.894999] ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready\n[48237.172073] eth1: no IPv6 routers present\n\nIn particular usbhid 6-2:1.0: suspend error -5. Google didn't find anything useful about that.\nHow can I further troubleshoot this matter?\n\nA: The line\nPM: Device 6-2 failed to suspend: error -5\nsuggests that there is a problem with suspending with that device. You can find out what is on Bus 6.2 by doing lsusb and looking at that.\nIf the problem persists, file a bug report with \"ubuntu-bug linux\"\n\nA: I think there might be clues earlier in the dmesg output.\nDo\ndmesg -T|grep Freez -A4\n\nto look for particular processes that stops suspend from suspending, does it give anything?\nIn that case, see my answer here: How to make \"suspend\" option to work? on how to automatically kill them before suspend.\n", "Q: change directory (cd) but by replacing a part of the path only Not sure if it is possible, but i seem to remember from my old days using AIX it was possible to change my path by just saying which part of the path needed to be replaced by something else. For instance, say i have two paths:\n/etc/application-2.0.1/options/default\n\nand\n/etc/application-1.0.8/options/default\n\nthat i could switch from folder 1 to 2 using a command like \ncd /2.0.1/1.0.8/\nwhich would replace, in the path, the string 2.0.1 to 1.0.8. Obviously this does not work for me now. But is there a way to do this? \n\nA: This should work in bash on ubuntu 10.04 : cd ${PWD/old/new}. Basically this replaces first occurrence of old in your present working directory with new. 2 examples below.\nExample 1\ning02741@hoster:~$ cd /home/ing02741/Videos/\ning02741@hoster:~/Videos$ cd ${PWD/ing02741/koushik}\ning02741@hoster:/home/koushik/Videos$ \n\nExample 2\ning02741@hoster:~/src/cdtest$ mkdir dir-v1.0.1 dir-v2.2.2 dir-v3.0.7\ning02741@hoster:~/src/cdtest$ mkdir dir-v1.0.1/ind dir-v2.2.2/ind dir-v3.0.7/ind\ning02741@hoster:~/src/cdtest$ cd dir-v1.0.1/ind/\ning02741@hoster:~/src/cdtest/dir-v1.0.1/ind$ cd ${PWD/1.0.1/2.2.2}\ning02741@hoster:~/src/cdtest/dir-v2.2.2/ind$ \n\nBorrowing on idea of sepp2k's answer, you could make a function like this\nfunction mycd { cd ${PWD/$1/$2} }\n\nand then use something like mycd 2.0.1 1.0.8 to switch.\n\nA: I have used (and missed) this feature myself.  It depends on which flavor and/or release of *nix you are using.  If you use bash, here is a handy way to extend the builtin cd to include this functionality.  Put this in your .bashrc (or to test paste it in your bash shell and hit enter).\nfunction cd() { if [ $# -eq 2 ]; then builtin cd \"${PWD/$1/$2}\"; else builtin cd \"$1\"; fi }\n\n\nA: You're probably remembering history expansion. I don't know what was available in your shell on AIX, but one way to do this in bash is ^2.0.1^1.0.8.\nHistory expansion is less useful with shells like bash and zsh that have powerful command line editing. You can use arrow keys to recall previous commands, and Alt+. to insert the last word of the previous command (press it twice to reach the command before that and so on).\n\nA: If you are a vi fan you could enable the vi mode in your shell (bash set -o vi for example) and use the command mode of vi ...\nOr you could do crazy history expansion (tested in zsh, perhaps in bash as well):\n$ cd /etc/application-1.0.8/options/default\ncd: no such file or directory: /etc/application-1.0.8/options/default\n\n$ !!:s/1.0.8/2.0.1/\ncd /etc/application-2.0.1/options/default\ncd: no such file or directory: /etc/application-2.0.1/options/default\n\n\nA: cd `pwd | sed 's/2\\.0\\.1/1\\.0\\.8/'`\n\nHowever this isn't very pretty. You can pretty it up a bit, by putting it in a function:\nfunction mycd { cd `pwd | sed s$1` }\n\nAnd then calling it like:\nmycd '/2\\.0\\.1/1.0.8/'\n\nYou still need to escape the dots, though, but I'm sure this can be worked around as well with a bit of thought.\n\nA:  ^2.0.1^1.0.8 \n\nThe above command swap 2.0.1 to 1.0.8 in last command, its work in bash\n\nA: To ensure that -P|-L|- work use the following:\nfunction cd () {\n    typeset arg=\n    case $1 in -|-L|-P) arg=$1 ; shift ;; esac\n    [ $# -gt 1 ] && {\n        builtin cd $arg \"${PWD/$1/$2}\"\n    } || {\n        builtin cd $arg \"$@\"\n    }\n}\n\n\nA: If you use zsh as shell you can just enter cd 1.0.8 2.0.1.\n\nA: Not sure about AIX, but I remember this as an old Korn shell trick on the Solaris boxes I used to administer. In your example, you'd type in the command:\ncd 2.0.1 1.0.8\n\nSome more info here.\n", "Q: Setting up a 3M Serial Touchscreen I've been attempting for quite a long time to get a Serial 3M Touchscreen to work on Ubuntu 10.04.\nThe closest post I could find to what I needed was this one:\nhttp://ubuntuforums.org/showthread.php?t=1508944&highlight=3m+touchscreen\nUnfortunately, I get to where I touch the screen and the mouse jumps to the top right corner and that is it.  The calibration software doesn't really work (straight from 3M).  Either sometimes it won't start, or there is something wrong with it.\nIt now looks like the problem has to do with the calibration software not recognizing the attached touchscreen.  With some changes to the installation script, I was able to get the calibration software to install properly.\n#!/bin/bash\n#\n# Copyright 2007-2009 3M. All rights reserved.\n#\n# This script installs the MT7 touch screen driver\n# During installation, all directories must be writeable.\n#\n\n# These symbols point to where the MT7 software binaries and data reside.\n# The script attempts to detect where the installation kit is. If this\n# fails, you need to set BinDir.\n# The data directory must be on writeable media. The script normally uses\n# the directory where the installation kit resides as the data directory.\n# If you need the data directory to be elsewhere, set DataDir.\nBinDir=\"\"\nDataDir=\"\"\n\n# If desired, define a file to contain driver startup options and set\n# the TwDrv_Cfg symbol to the full path of the file. Normally this is\n# not needed.\nTwDrv_Cfg=\"\"\n\n# This symbol points to where the Java VM binaries reside.\nJavaBinDir=\"\"\n\n# These symobls point to system and applictaion directories other than\n# those specific to the MT7 software\nUdevDir=\"/etc/udev\"\nHotplugDir=\"/etc/hotplug\"\nXorgDir=\"/usr/lib/xorg/modules/input\"\nXFree86Dir=\"/usr/X11R6/lib/modules/input\"\nLibDir=\"/usr/lib\"\nSEDir1=\"/usr/selinux/booleans\"\nSEDir2=\"/selinux/booleans\"\nLSBDir=\"/lib/lsb\"\n\n# The InitDir symbol points to where this script places an 'init' script.\n# If left blank, this script first looks for /etc/init.d and then /etc/rc.d.\n# If this is not appropriate or this script otherwise fails, set this value.\nInitDir=\"\"\n\n# This symbol enables permission for some MT7 shared objects on\n# SELinux systems. On most systems SEGivePermission is texrel_shlib_t.\n# Change this variable if another security type is appropriate.\nSEGivePermission=\"texrel_shlib_t\"\n\n# This symbol affects when the X input driver converts raw touch screen\n# coordinates into screen coordiates. Normally, the X input driver reports\n# the raw coordinates to the X server which then calls an conversion\n# routine. Some versions of the X server expect the initial report to\n# contain converted coordinates. If your touch behavior is off and\n# calibration does not address the problem, set ConvertAtRead to true.\nConvertAtRead=\"false\"\n\n# This symbol defines the name of the xorg.conf file to generate if one is\n# not found. Starting with X server version 1.5, this file is not\n# automatically generated. This file is needed for MT 7 for Linux to work.\n# If you want the file to reside elsewhere, set this symbol.\nXorgConf=\"/etc/X11/xorg.conf\"\n\n# These symbols define where the 50MT7-xinit script needs to go and what\n# suffix it requires. The script places this file automatically in\n# /etc/X11/xinit/xinitrc.d and /etc/X11/Xsession.d without a suffix. If\n# your distribution requires another location or requires a suffix on the\n# file, set these symbols.\nXinitDir=\"\"\nXinitSuffix=\"\"\n\n# Determine the installation directory\nif [ -z $BinDir ]\nthen\n   if [ $(echo $0 | grep ^/) ]\n   then\n      BinDir=$0\n   else\n      BinDir=$(echo $PWD\"/\"$0 | sed s#[.]/##)\n   fi\n   BinDir=$(echo $BinDir | sed s%/[^/]*$%%)\nfi\n\n# Determine if the system is compatible\n$BinDir/TwCompat\nif [ $? != 0 ]\nthen\n   echo \"ERROR: MT7 for Linux not installed - shared memory support not detected\"\n   exit\nfi\n\n# Determine the data directory\n[ -z $DataDir ] && DataDir=$BinDir\n\n# Create the data and fifo directories\nif [ $DataDir != $BinDir ]\nthen\n   [ -e $DataDir ] || mkdir $DataDir\n   chmod a+w $DataDir\n   ln -s $DataDir $BinDir/data\nelse\n   [ -e $BinDir/data ] || mkdir $BinDir/data\nfi\nchmod a+w $BinDir/data\n[ -e $BinDir/data/fifo ] || mkdir $BinDir/data/fifo\nchmod a+w $BinDir/data/fifo\n\n# Determine the init script directories\nif [ -z $InitDir ] && [ -d /etc/init.d ]\nthen\n   if [ $(ls -l /etc/init.d/ | sed -e /functions/d -e /^total\\ [0-9]*$/d | wc -l) != 0 ]\n   then\n      InitDir=\"/etc/init.d\"\n   fi\nfi\nif [ -z $InitDir ]\nthen\n   if [ -e /etc/rc.d/rc.local ]\n   then\n      InitDir=/etc/rc.d\n   else\n      InitDir=$BinDir\n   fi\nfi\n\n# Install the init script\n[ -e $InitDir/TWDrvStartup ] && rm -f $InitDir/TWDrvStartup\nsed -e s#%BINDIR%#$BinDir#g \\\n    -e s#%INITDIR%#$InitDir#g \\\n    -e s#%LSBDIR%#$LSBDir#g \\\n    -e s#%TWDRV_CFG%#$TwDrv_Cfg#g $BinDir/TWDrvStartup.ORIG \\\n    >$InitDir/TWDrvStartup\nchmod a+x $InitDir/TWDrvStartup\nif perl $BinDir/TwIsThere.perl chkconfig\nthen\n   chkconfig --add TWDrvStartup >/dev/null\nelif perl $BinDir/TwIsThere.perl update-rc.d\nthen\n   update-rc.d TWDrvStartup defaults >/dev/null\nelif [ -e $InitDir/rc.local ]\nthen\n   sed -e '$ a\\\n%INITDIR%/TWDrvStartup start\n' $InitDir/rc.local >$InitDir/rc.local.TEMP\n   rm -f $InitDir/rc.local\n   sed -e s#%INITDIR%#$InitDir# $InitDir/rc.local.TEMP >$InitDir/rc.local\n   rm -f $InitDir/rc.local.TEMP\n   chmod +x $InitDir/rc.local\nelse\n   echo \"Cannot install the init script\"\nfi\n\n# Test for USB support\nif [ -z $(uname -r | grep ^2\\.4\\.) ]\nthen\n   # Copy the udev rules script\n   Hotplug=0\n   if [ -d $UdevDir/rules.d ]\n   then\n      if [ -e $UdevDir/rules.d/99-TwDriver.rules ]\n      then\n         rm -f $UdevDir/rules.d/99-TwDriver.rules\n      fi\n      sed s#%BINDIR%#$BinDir#g $BinDir/99-TwDriver.rules.ORIG \\\n         >$UdevDir/rules.d/99-TwDriver.rules\n      Hotplug=1\n   fi\n   if [ -d $HotplugDir/usb ] && [ -e $HotplugDir/usb.agent ]d\n   then\n      [ -e $HotplugDir/usb/TwHotplug ] && rm -f $HotplugDir/usb/TwHotplug\n      sed s#%BINDIR%#$BinDir#g $BinDir/TwHotplug.ORIG > $HotplugDir/usb/TwHotplug\n      chmod a+x $HotplugDir/usb/TwHotplug\n      [ -e $HotplugDir/usb.usermap ] || echo \"# Created by MT7\" >$HotplugDir/usb.usermap\n      sed <$HotplugDir/usb.usermap >$HotplugDir/usb.usermap.TEMP '$ a\\\n# TwHotplug is for the MT7 for Linux software\\\nTwHotplug            0x0001      0x0596   0x0000    0x0000       0x0000      0x00         0x00            0x00            0x06            0x00               0x00               0x00000000\n'\n      rm -f $HotplugDir/usb.usermap\n      mv $HotplugDir/usb.usermap.TEMP $HotplugDir/usb.usermap\n      Hotplug=1\n   fi\n   if [ $Hotplug == 0 ]\n   then\n      echo \"Hotplugging of USB touch screen controllers is not supported\"\n   fi\nelse\n   echo \"USB touch screen controllers are not supported under kernel 2.4\"\nfi\n\n# Test for the version of C++ standard libraries\nif [ -e $LibDir/libstdc++.so.6 ]\nthen\n   CppExt=\"6\"\nelif [ -e $LibDir/libstdc++.so.5 ]\nthen\n   CppExt=\"5\"\nelse\n   echo \"Cannot find needed libstdc++.so in $LibDir\"\n   CppExt=\"\"\nfi\n\n# Link the libraries into /usr/lib\nperl $BinDir/TwLibInstall.perl install $LibDir $BinDir/lib*.so\nif [ x$CppExt != x ]\nthen\n   perl $BinDir/TwLibInstall.perl install $LibDir $BinDir/so$CppExt/lib*.so\nfi\n\n# Link RnR sensitive files\nif [ x$CppExt != x ]\nthen\n   $BinDir/TwLibTest $LibDir/libTwSystemRnR12.so\n   if [ x$? != x0 ]\n   then\n      rm -f $LibDir/libTwSystem.so\n      ln -s $LibDir/libTwSystemRnR12.so $LibDir/libTwSystem.so\n      ln -s $BinDir/TwMonitorRnR.bin$CppExt $BinDir/TwMonitor\n   else\n      $BinDir/TwLibTest $LibDir/libTwSystemRnR.so\n      if [ x$? != x0 ]\n      then\n         rm -f $LibDir/libTwSystem.so\n         ln -s $LibDir/libTwSystemRnR.so $LibDir/libTwSystem.so\n         ln -s $BinDir/TwMonitorRnR.bin$CppExt $BinDir/TwMonitor\n      else\n         ln -s $BinDir/TwMonitor.bin$CppExt $BinDir/TwMonitor\n      fi\n   fi\nfi\n\n# Copy the X input driver\nXCopyDefault=0\nif [ -d $XorgDir ]\nthen\n   XDir=$XorgDir\n   if [ -z \"$(X -version 2>&1 | grep X\\.Org[^1]*1\\.[4-9]\\.)\" ]\n   then\n      XSrc=$BinDir/twxinput_drv.so\n   elif [ -z \"$(X -version 2>&1 | grep X\\.Org[^1]*1\\.[5-9]\\.)\" ]\n   then\n      XSrc=$BinDir/twxinput_drv.so.1.4\n   else\n      XSrc=$BinDir/twxinput_drv.so.1.5.1\n      XCopyDefault=1\n   fi\nelif [ -d $XFree86Dir ]\nthen\n   XDir=$XFree86Dir\n   XSrc=$BinDir/twxinput_drv.so\nelse\n   XDir=\"\"\n   echo \"Cannot install the X input module\"\nfi\nif [ -d $XDir ]\nthen\n   [ -e $XDir/twxinput_drv.o ] && rm -f $XDir/twxinput_drv.o\n   [ -e $XDir/twxinput_drv.so ] && rm -f $XDir/twxinput_drv.so\n   ln -s $XSrc $XDir/twxinput_drv.so\nfi\n\n# Install the xinit scripts\nif [ -d /etc/X11/xinit/xinitrc.d ]\nthen\n   sed s#%BINDIR%#$BinDir#g $BinDir/50MT7-xinit.ORIG \\\n      >/etc/X11/xinit/xinitrc.d/50MT7-xinit$XinitSuffix\n   chmod a+x /etc/X11/xinit/xinitrc.d/50MT7-xinit$XinitSuffix\nfi\nif [ -d /etc/X11/Xsession.d ]\nthen\n   sed s#%BINDIR%#$BinDir#g $BinDir/50MT7-xinit.ORIG \\\n      >/etc/X11/Xsession.d/50MT7-xinit$XinitSuffix\n   chmod a+x /etc/X11/Xsession.d/50MT7-xinit$XinitSuffix\nfi\nif [ x$XinitDir != x ]\nthen\n   sed s#%BINDIR%#$BinDir#g $BinDir/50MT7-xinit.ORIG \\\n      >$XinitDir/50MT7-xinit$XinitSuffix\n   chmod a+x $XinitDir/50MT7-xinit$XinitSuffix\nfi\n\n# Set up the SELinux security types\nif [ -d $SEDir1 ]\nthen\n   SEDir=$SEDir1\nelif [ -d $SEDir2 ]\nthen\n   SEDir=$SEDir2\nelse\n   SEDir=\"\"\nfi\nif [ x$SEDir != x ]\nthen\n   chcon -t $SEGivePermission $LibDir/libTwSystem.so\n   chcon -t $SEGivePermission $LibDir/libTwConfig.so\n   chcon -t $SEGivePermission $LibDir/libTwIO_Utilities.so\n   chcon -t $SEGivePermission $LibDir/libTwAppIO_JNI.so\n   chcon -t $SEGivePermission $LibDir/libTwCommon_JNI.so\n   chcon -t $SEGivePermission $LibDir/libTwConfig_JNI.so\n   chcon -t $SEGivePermission $LibDir/libTwUI_JNI.so\n   chcon -t $SEGivePermission $LibDir/libTwUICP.so\n   [ -e $XDir/twxinput_drv.so ] && chcon -t $SEGivePermission $XDir/twxinput_drv.so\nfi\n\n# Set up the configuration\n[ -d /dev/shm ] && rm -f /dev/shm/*TwConfig*\nsed s#%BINDIR%#$BinDir#g $BinDir/TwFramework.cfg.ORIG >$BinDir/TwFramework.cfg\n$BinDir/TwCfgUtil /u $BinDir/TwFramework.cfg\n$BinDir/TwCfgUtil /u $BinDir/TwFactory.cfg\n\n# Produce the Remove script\nsed -e s#%BINDIR%#$BinDir#g \\\n    -e s#%UDEVDIR%#$UdevDir#g \\\n    -e s#%XDIR%#$XDir#g \\\n    -e s#%LIBDIR%#$LibDir#g \\\n    -e s#%SEDIR%#$SEDir#g \\\n    -e s#%HOTPLUGDIR%#$HotplugDir#g \\\n    -e s#%INITDIR%#$InitDir#g \\\n    -e s#%XINITDIR%#$XinitDir#g \\\n    -e s#%XINITSUFFIX%#$XinitSuffix#g \\\n    $BinDir/Remove.ORIG >$BinDir/Remove\n\n# Produce the X input script\nsed -e s#%CONVERT%#$ConvertAtRead#g \\\n    $BinDir/TWXinputInstall.perl.ORIG >$BinDir/TWXinputInstall.perl\n\n# Produce the CP start script\nsed -e s#%JAVABINDIR%#$JavaBinDir#g \\\n    -e s#%BINDIR%#$BinDir# \\\n    $BinDir/StartCP.ORIG >$BinDir/StartCP\n\n# Set any necessary permissions\nchmod a+x $BinDir/TwCalib\nchmod a+x $BinDir/TWXinputInstall.perl\nchmod u+x $BinDir/Remove\nchmod a+x $BinDir/StartCP\n\n# Copy the default xorg.conf\nif [ $XCopyDefault == 1 ]\nthen\n   $BinDir/TWXinputInstall.perl -find\n   if [ $? == 1 ]\n   then\n      cp -a xorg.conf.ORIG $XorgConf\n   fi\nfi\n\nUsually this puts out this error, although I don't think the errors are critical (warnings?):\nupdate-rc.d: warning: /etc/init.d/TWDrvStartup missing LSB keyword 'required-start'\n\nupdate-rc.d: warning: /etc/init.d/TWDrvStartup missing LSB keyword 'required-stop'\n\nupdate-rc.d: warning: TWDrvStartup start runlevel arguments (2 3 4 5) do not match LSB Default-Start values (2 5)\nupdate-rc.d: warning: TWDrvStartup stop runlevel arguments (0 1 6) do not match LSB Default-Stop values (0 1 3 4 6)\nln: creating symbolic link `/home/kioskadmin/Desktop/twscreen/TwMonitor': File exists\nroot@kiosk1:/home/kioskadmin/Desktop/twscreen# \n\nI also asked this question on Super User quite a long time ago, although other than the link to the Ubuntu forums, nothing.  If I recall correctly, no one on the Ubuntu Forum was very helpful beyond pointing me to the same post. It seems \"touchscreens\" is a specialized topic that not a lot of people know much about.\nMy questions:\n1  Any tips to get this to work correctly?  My major problem seems to be the newer boot process in 10.04.\n2  Any alternative calibration software or touchscreen driver that may work or is worth trying? (serial, not USB).\nIt seems that the the driver is not initiating correctly. The calibration software and control panel do not detect the controller for some reason.  My assumption at the moment is that the init script is not correct, most likely due to changes in Ubuntu's start-up process.\nEdit:\nIt seems I can now run the control panel script correctly, I was having problems with Java, but I just had to execute it differently.  Now I have the problem that the control panel and calibration software cannot detect the touchscreen. Everything runs, but just can't find it,  even though it's connected and it responds if I enable the screen manually.\nThe error is, \"touchscreen 1 is not present\".\n\nA: On maverick,add this PPA and try \nppa:utouch-team/utouch\n\nA: Please see this to get help with MultiTouch in Ubuntu: https://wiki.ubuntu.com/Multitouch#Community%20Help\nMake sure you include the result of lsusb when you ask your question there. Thank you!\nHowever this may not be enough to properly configure your device drivers. I would suggest filing a bug.\n\nA: Run the /opt/twscreen/Remove script.\nedit the /opt/twscreen/TWDrvStartup.ORIG file and update the BEGIN INIT INFO to look like this:\n### BEGIN INIT INFO\n# Provides: TwDriver\n# Required-Start:\n# Required-Stop:\n# Default-Start: 2 5\n# Default-Stop: 0 1 3 4 6\n# Description: Start the MT 7 touch screen driver\n### END INIT INFO\n\nRun the /opt/twscreen/Install \n", "Q: Multiple shortcuts for same functionality I really like some of my shortcuts but I find at times there are other ways I would like to invoke the same shortcut.\nFor example: \nCtrl + Alt + Left/Right \nSwitches workspaces left/right respectively.  \nI want a mouse click to perform this same functionality.  My mouse wheel can go left/right and I want to map this to go left/right in my workspaces but I also want the keyboard shortcut to remain.\n\nA: If you are using Compiz (chances are that you are) you can install Advanced Desktop Effects Settings (ccsm), either from the Software Center or from the command line\nsudo apt-get install compizconfig-settings-manager\n\nNow go to System-> Prererences-> CompizConfig Settings Manager.\nClick on the Viewport Switcher icon. The window should change, go to the Desktop-bases Viewport Switching. Click on the buttons after Move Prev and Move Next (labeled Disabled on the screenshot). A new window will open, click enabled, another one will open, here you can select a mouse button for each action there, always or only when the mouse is in some screen places or when a special key is pressed.\n\n\n\nA: Just wanted to add that you can also use your regular (vertical) mouse wheel axis to switch workspaces by adding Mouse4 and Mouse5 actions on the (left and right) screen edges. It's very intuitive and works very well. I can be configured in the Rotate Cube plugin.\n", "Q: How to make HP IR6 remote control work? I've been using an HP Pavillion dv4-1430us laptop with Ubuntu 10.04 installed on it. I want to use the IR6 remote control that comes with the laptop on my Ubuntu. However, I've failed to do so after several attempts.\nCould anyone please let me know about the complete and detailed procedure to get the remote working in Ubuntu 10.04?\n\nA: Here's what worked on my HP-2140us:\n\n\n*\n\n*Install the \"Infrared Remote Control\" app from the software center\n\n*If you haven't installed lirc before, you'll get a config screen; if the install completes without one, open a terminal and type sudo dpkg-reconfigure lirc\n\n*Select ENE KB3926 as your receiver and None as your transmitter.\n\n*Open Preferences > Infrafed Remote Control, unlock and set the \"IR Remote Control\" settings to Manufacturer: HP, Model:TSGH-IR01\n\n*Press a few buttons on the remote and make sure they come up in the \"Configuration Test\" area.  If they do, you're done!\n\n\nFinally, if you plan to use the remote with rhythmbox/totem/banshee/etc., you'll need to enable the lirc/remote control plugins in those apps.\nupdate: you might need to restart after step 3\nupdate 2  For Rhythmbox support add this in ~/.lircrc:\nbegin\n    prog = Rhythmbox\n    button = PlayPause\n    config = playpause\nend\n\nbegin\n    prog = Rhythmbox\n    button = Skip\n    config = next\nend\n\nbegin\n    prog = Rhythmbox\n    button = Replay\n    config = previous\nend\n\nbegin\n    prog = Rhythmbox\n    button = VolUp\n    config = volume_up\nend\n\nbegin\n    prog = Rhythmbox\n    button = VolDown\n    config = volume_down\nend\n\n\nA: I was able to make my HP IR remote work only with rhythmbox:\n\n\n*\n\n*Install gnome-lirc-properties using Software Center or apt-get\n\n*Edit the hardware.conf file\nsudo -H gedit /etc/lirc/hardware.conf:\n\nadd this text:\n#Chosen Remote Control\nREMOTE=\"ENE KB3926 B/C/D (ENE0100) CIR port\"\nREMOTE_MODULES=\"lirc_dev lirc_ene0100\"\nREMOTE_SOCKET=\"\"\nREMOTE_LIRCD_CONF=\"/etc/lirc/lircd.conf\"\nREMOTE_LIRCD_ARGS=\"-d /dev/lirc0\"\n\n\n*Copy the configuration from this URL\n\n*Paste it to lirc.conf (open it like this)\nsudo -H gedit /etc/lirc/lircd.conf\n\n\n*Reboot\n\n*Test if the IR is working\nIn the terminal type the comand irw and press the remote control buttons to check.\n\n*In Rhythmbox go to Edit > Plugins and enable the LIRC plugin.\n", "Q: Does Ubiquity support installing via PXE? I have a PXE server at home for doing network-based installs, which uses the text-based alternate installer.\nHowever in 10.10 the Ubiquity (aka graphical) installer has some really nice features; like installing in the background while I fill out my user information, installing updates as part of the install, and it looks pretty great.\nIs there a way to set up netboot with ubiquity so I can use my existing PXE server but have a nice graphical installation?\n\nA: The trick is to load a minimal system with NFS-Support. This system can start the graphical installer. This hotwo should help setting this up.\nIf you like experimenting around with pxe I recommend fog, this has alot of features and will setup part of the installation by itself. It will also allow you to backup partitions over network and load them back.\n\nA: You need to export the live filesystem over NFS, and set the NETBOOT and NFSROOT kernel command line parameters.\nSee this help document (under \"A variation\") for the full details.\n", "Q: Smartphones and Ubuntu It is time for a new cell phone and I am facing the difficult question: which one?\nI would like to get a smartphone and am now browsing around the web to see\nwhich smartphone provides the best support for Ubuntu and can synchronizes best with Ubuntu.\nAny tips, info and experience to share?\n\nA: The Nokia N900 is a full-on Linux smartphone. A little less popular than Android, but capable of communicating with your Ubuntu installation through Samba, NFS, Ethernet, USB, etc.\n\nA: Do not get a Samsung Galaxy S,  \nSamsung rolls out updates via it Kies software. Kies only runs on windows. Samsung does not provide over the air updates.\nThis means that you will have no way of updating your phone with official firmware. \nI found this out the hard way. I assumed it would be like every other android phone and get updates over the air. Sadly it does not.\n\nA: I've only had experience with BlackBerry phones.  BlackBerry phones which have added microSD cards installed are recognized as digital audio players in Ubuntu when connected via USB cable.  As such, you can drag and drop MP3 music files, photos, MS Office documents (if you use Documents to Go) or compatible eBooks onto the drive within their designated folders.  Video is a bit trickier on older BlackBerrys like the Curve or the Pearl as they need to be reduced in resolution to fit the native screen and compressed for size (this can be done with the software program Handbrake).  BlackBerrys tend to prefer the MP4 file container.\nLike other phones, a Windows machine with native desktop software (BlackBerry Desktop) is required to back up mail, calendar and contact information as well as update the OS.  Though the newer model BlackBerrys do allow over the air OS updates if you have a good data plan.\n\nA: As others have mentioned, Android-based phones work out of the box. My Nexus One shows up as mass storage, which lets me manage it via my music player, photo editor, etc. You can drag and drop things to it like any device: \n\nThe one problem with the default music application (Rhythmbox) is that the playlists currently do not sync. This problem will be addressed in a future version. However the Banshee media player currently manages this quite well, which is what I use to manage the music on my Nexus.\nThe other downside for you might be that you have to use Google services to get the over-the-air syncing goodness. So if you have your contacts/calendar/email locally in your applications then you have to find a syncing solution vs. if you use gmail everything just works transparently. Some people might not like this but I find it to be a very handy feature. Having owned both a blackberry and an iPhone 3G (which I needed to plug in and sync) there's much less hassle to have everything syncing over-the-air.\nAlso, depending on whether your carrier has Android 2.2 and doesn't disable tethering it just works when you plug it in.\n\nA: I have an Android device (Motorola Milestone, called \"Droid\" in the US) that works great with Ubuntu... but you actually don't need to \"sync\" it, since the purpose of Android is to sync with your Google account.\n Then I have my Thunderbird + Lightning synced with my Google mail/contact/calendar (also works with Evolution), and I have the Android smartphone doing the same on its side.\nYou also can use UbuntuOne contact syncing if you prefer (works on Evolution, Thunderbird, and Android devices). It is still in beta, and seems to be targetted for paying users, but it may be a solution, if you don't want to rely on Google only :)\nThen for music: Rythmbox can see it when I plug it on USB, and I can manage my phone's playlist from it. For photo/video/whatever, the phone is actually seen as a USB drive, so you can go put/remove files as you like.\nNo issue so far, I really find it easy to use.\nEdit: About the iPhone... I guess it's worth some comments :)\nWe already have questions about iPhone syncing with Ubuntu on this site. Run a search for \"iPhone\" to find more. But you'll find all needed information here: https://help.ubuntu.com/community/PortableDevices/iPhone\nBasically: it works, at least for music/video/podcast syncing. You can even get tethering working. Contact/calendar cannot be synced, but you can sync your iPhone to Google, so it's not a big deal.\nNow the fact is that some things will require iTunes. For instance: Application management, phone's upgrade and phone's settings backup. And iTunes doesn't work on Linux :(\nI am mentionning it because I know people are advertising the support of iPhones on Ubuntu, while this support is not as complete as you might think.\nI had an iPhone some times ago. Great device, but I had to sell it because of this incompatibility (and other personal reasons). No fun to have a VM just for iTunes :-(\n\nA: In general Android phones will work best. They behave out of the box, like a camera, a removable drive and an mp3-player. Bluetooth also works. (and the phone runs linux like Ubuntu, which is kind of cool)\nFor Ubuntu One, they seem to focus on iPhone support for syncing first. So if you want to synchronize your tomboy notes or your ubuntu-one files over the air, the iPhone is the better choice.\n[editoral comment removed]\n", "Q: In regards to memory usage, what are buffers? Just took a look at the memory usage (with free -m) on one of my Ubuntu servers and saw this:\n             total       used       free     shared    buffers     cached\nMem:           751        624        127          0        256        236\n-/+ buffers/cache:        131        619\nSwap:          299          0        299\n\n\n\n*\n\n*What is a buffer? \n\n*If something needed RAM to process something, would a buffer give up its allotment (like cache would)?\n\n*Is there any way I can find what's using the 256MB of memory for buffer?\n\n*Should I be worried?\n\n\nA: *\n\n*The developers of the linux memory management have a short technical description of it (look for the \"Buffer Cache\" topic).\n\n*Buffers that aren't needed at the moment can make way for more urgent memory needs.\n\n*The kernel is using it.\n\n*No.\n\n", "Q: Can you install Ubuntu from a liveCD via vnc or similar? It is possible with other distros! If so, how do you do it?\n\nA: The only thing that I can think of is booting to the liveCD environment, bring up a VPN server like x11vnc, connect remotely, then manage the install.\nI'm confused though what advantage this gives you, as you still require a physical presense to put in the CD and do other things. I suppose you could do enough automation to grub to boot from an ISO, and automate the ISO so that it automatically starts the VPN server, but that seems like a huge amount of work for such a small problem.\n", "Q: How can I reduce the time taken to login by postponing/delaying some startup applications? I have setup some applications to startup on each login (e.g., redshift-gtk, gtg) automatically but after adding these to startup applications (System -> Preferences -> Startup Applications) obviously the time taken to login has increased. Due to all this the time it takes for my panels, desktop etc to appear is too long - until which I am forced to wait.\nI don't need these apps to be available immediately, but it would be good if they startup eventually, meanwhile the ubuntu menu/panel is available for running other apps that I might need to.\nI tried using at command, with the intention of editing all startup applications to put the commands in the at queue, but this didn't work since the apps don't get the necessary environment variables (like DISPLAY).\nIs this what nice command is used for? Any other ideas how I can accomplish this? If possible, I would like to avoid editing the startup applications commands, since this would mean a lot of effort to replicate on other machines I use.\n\nA: I found that just using sleep 10 && COMMAND as the command name didn't work. I had issues with both conky and xchat loading too early and getting corrupted somehow. I had to write a little script called ~/bin/startup and put this in it:\n#!/bin/bash\nsleep 10\nxchat &\nconky &\n\nYou need change its permissions to be allowed to be executed with chmod +x ~/bin/startup and then just replace the start-up applications entry with the command startup and it'll fire off everything in the script.\nYou could have one file for each application if you were that way inclined.\n\nA: Use the 'sleep' command.\nIn System -> Preferences -> Startup Applications, edit the command for the programs you want to delay to:\nsleep 10 && COMMAND\n\nReplace 10 with the number of seconds you want it to wait and COMMAND with what was in the command box originally.\n\nA: The number of seconds needed to wait for your desktop to load is arbitrary and can change depending on the situation. Instead of sleep, try using the following to run startup applications as soon as the system load has declined:\n(Edit: Added koushik's suggestion.)\n#!/bin/bash\n# \n# Delays running an application until the system load has declined.\n# \n# Usage:\n#   run-when-load-low 'your command here'\n\necho \"export DISPLAY=$DISPLAY; $1 &\" | batch\n\nexit 0\n\nSave it as ~/bin/run-when-load-low and add run-when-load-low 'COMMAND' in Startup Applications Preferences.\nNotes on this method:\n\n\n*\n\n*The script above is what has worked for me. It passes only the DISPLAY environment variable to the application. For most desktop applications this will be all you need. With that said, be sure to consider any special cases and keep this fact in mind when troubleshooting anything that isn't behaving correctly. A good place to start if you think an application might need other environment variables passed is printenv and the application's documentation, though I personally haven't run into this problem yet.\n\n*My understanding of the system \"load\" value is that it does take into account IO waits, so delayed applications should not accidentally start too soon during the CPU usage lulls caused by desktop processes waiting on IO. This is not an area I know much about though, so please correct me if I am wrong here.\n\n*batch only affects when applications are run; it does not alter their priority/niceness.\n\n*This should go without saying, but if your system always has a high load, applications scheduled using this method might never run.\n\n*If you need to run an application with a parameter that contains spaces, you can escape them using the backslash: run-when-load-low 'gedit My\\ Notes.txt'. If you really need to pass single-quoted parameters to your application, you'll have to use double quotes in the startup command: run-when-load-low \"gedit 'My Notes.txt'\". For anything more complicated than this, you're probably best off just modifying a copy of the script with your command hard-coded.\n\n", "Q: How to check if Network Proxy is really applied? I'm trying to set Network Proxy to use my LAN's internet connection to update packages.\nwhile the proxy settings works on my firefox, but the package manager still cannot connect to Internet. I have set proxy in System >> Preferences >> Network Proxy and I have entered the user/pass for the proxy in 'Details' too.\nHow can I make sure that the Proxy Network is applied correctly?\n\nA: Have you clicked the Apply System Wide (highlighted) button? If you don't proxy settings are local to your Gnome session and therefore when root goes off to download packages, it won't use the same network settings.\n\n\nA: There's a bunch of good answers above that will help you if you're having problems (which is what your question implies).  However, this is an answer to the narrow question of checking whether the Network proxy settings have been applied:\nMethod 1:\nStart a new shell (xterm), then check the environment variables:\n% env | grep -i proxy\nhttp_proxy=http://172.17.0.130:8080/\nftp_proxy=ftp://172.17.0.130:8080/\nall_proxy=socks://172.17.0.130:8080/\n...\n\nNote that existing shells will not have updated environment variables.  So if you're executing a command that looks at environment variables for its proxy settings, start it in a shell created after the changes to the proxy settings.\nMethod 2:\n    Use gconftool to query the gconf settings (which are stored under ~/.gconf):\n% gconftool -R /system/proxy \n old_ftp_port = 0\n old_ftp_host = \n old_secure_port = 0\n old_secure_host = \n autoconfig_url = \n mode = manual\n ftp_host = 172.17.0.130\n secure_host = 172.17.0.130\n ...\n\n% gconftool -R /system/http_proxy \n use_authentication = false\n authentication_password = \n authentication_user = \n ignore_hosts = [localhost,127.0.0.0/8,*.local,...]\n use_http_proxy = true\n port = 8080\n use_same_proxy = true\n host = 172.17.0.130\n\nAs others have noted, be sure that your browser and other apps are set to \"Use System Proxy Settings\".\n\nA: If you try:\ncurl http://www.google.com\n\nfrom the command line, then if you get HTML back the proxy is working.\n\nA: To set a proxy temporarily you can fire up a terminal and enter \nexport http_proxy=\"http://yourproxy:yourport\"\nThen start the program, e.g. Synaptic for package management. The console might give you helpful output on what goes wrong.\n\nA: First of all make sure you click on \"Apply system-wide...\" whenever you change proxy settings in the gnome-network-properties (System -> Preferences -> Network Proxy). This sets http_proxy and related environment variables. This should be available to all programs started after the proxy setting is \"Applied system-wide...\". To be really sure, you can logout and back-in to double-check this.\nIf you open a terminal and use the command set | grep -i proxy you would see the relevant environment variables set. Ideally this should be enough.\nHowever, I have faced situations where all the above still doesn't work: Synaptic or apt-get (over commandline) can't connect to the internet through the proxy even after it is set in the above way. In such cases, one solution is to add a file in /etc/apt/apt.conf.d with specific proxy configuration for apt (this will be used by apt-get, aptitude, synaptic and Ubuntu software center).\nFollow the below steps:\n\n\n*\n\n*Create /etc/apt/apt.conf.d/40proxy\ngksudo gedit /etc/apt/apt.conf.d/40proxy\n\n*Put the following contents into it - modify the contents to suit your situation.\nAcquire::http::Proxy \"http://proxy.site.com:8080\";\nIf you have a user-name & password you could encode the same in the proxy url (like so, http://username:password@proxy.site.com:8080) or you can use something like ntlmaps for better control.\nMore info could be found here.\n\nA: I'm using a proxy also, and I had to set the proxy settings specifically for Synergy and update manager (using Synergy: Configuration->Preferences->Network). There's no option there to use the \"system settings\", and even if it should work, changing the proxy server at the system level never made me able to update :-(\nI'm interested in a solution that make it work though :-)\n\nA: anyone thought to check/add settings to:\n/etc/environment\ntry it with:\nhttp_proxy=\"http://user:password@proxyserver:port\"\nhttps_proxy=\"http://user:password@proxyserver:port\"\nftp_proxy=\"http://user:password@proxyserver:port\"\n\nA: Click on \"Apply System-Wide...\" and check that all your internet applications are set to use the system proxy. There's nothing more to it than this. There's no need to tamper with configuration files and start-up scripts.\n\nA: Applying system-wide is not enough ! I think maybe ISA Server or maybe synaptic reset connection for each query to the web this issue that login and password authentication lie down. Or maybe ISA Server do not accept to transmit query that do not answer on HTTP protocol, but It's not my favorite.\n", "Q: Text box select issue I have this issue where the entire text in text boxes is selected whilst I'm typing in it. For example, in FireFox search box I'd try to type \"foo\" but end up with \"o\" because I managed to type \"fo\" before everything was selected, and then typed \"o\" which replaced the \"fo\".\nWhen it happens, it is incessant - not just a one-off. But it doesn't happen all the time, and I haven't managed to figure out what causes it to start and stop.\nIs this a known problem with an easy solution?\nEDIT: this has nothing to do with touchpad. I get this occasionally even on a machine without one. I can usually rectify the issue just be alt-tabbing about a few times.\n\nA: This has also been reported as a bug at https://bugs.launchpad.net/bugs/641300.\n\nA: Do you have a touchpad? Without any more information given here, the most likely case in my experience is inadvertent events by the touchpad since it notices not only touches but also close proximity movements. However, due to the lack of information, this is just a guess.\n\nA: I have the same problem, and it's infuriating me!  I just took a closer look at what was happening:\n\n\n*\n\n*with my mouse over the text field, this problem occurred\n\n*I could type characters quickly, and when I slowed down is when it seemed to select everything\n\n*At first, it would only happen if there were 9 characters or under\n\n*Having convinced myself it is not due to my touch pad sending false clicks, I moved my mouse off of the text field and the problem persisted\n\n*At some point, the upper cap on the number of characters replaced went down to 5\n\n\nWith my extremely limited understanding of firefox, I think it may be due to a plug in.  Unless, @Kent, have you made another firefox profile?  That is the only odd thing I have done to my firefox...\n\nA: I have been experiencing this problem intermittently for several months across to systems. Ubuntu 10.04 laptop and 10.10 desktop both are up to date. \nWhilst most frequently it happens in the search box but occasionally i have the noticed the same thing happen when i go the the subject field of a new email in gmail (rare but happens) so i suggest it is not limited to the search box. \nAnother bug i've noticed that seems to occur at similar times (and also seems to be fixed by alt-tabbing) is that when i type in the search box i dont get a search on my history. Usually when i start typing say 'mail' i get a drop down including 'mail.google.com' but at these times this doesnt happen. I can't say for sure these bugs are related as i haven't tested the correlation enough yet. \n", "Q: VB.NET programming in Ubuntu I have just started at sixth form college, and I'm going to take a Computing A-level. I have been informed all the programming in the first year is in VB.NET on Windows (I believe you are allowed more freedom in the second year...)\nI do have a Windows XP partition and you can download Visual Basic Express Edition for free, however I would like to know to what extent am I likely to be able to use Ubuntu (Mono or anything else) for my studies? Can anyone give me any pointers of where to start?\nRealistically if this is to work I need to be able to use the same files/projects/whatever on both Ubuntu and Windows - so I can work from Windows machines at college, and more importantly so teachers can look at and mark my work! (I don't really want to make a point of asking my teacher about my Ubuntu use, I'd prefer to blend in and be a normal student...)\n\nA: It really depends on your syllabus.\nMono does have VB.NET language support but the framework is somewhat different in places and I'd predict that as much of your work will be about the .NET framework as it is the core language. It might not be as it sounds like it's at a fairly elemental level (no offence intended!)\nEven if the work is just language-orientated, as you say, you're not going to get the silly Visual Studio meta project files. You could have problems opening things and (again, as you say) you'll definitely have problems getting things to other (perhaps less competent) people.\nWith this the case, and you still want Ubuntu as your main system, VirtualBox sounds like the best way of remaining compatible with your coursework. It's much more convenient than dual-booting but it requires you have a more-than-average computer for a good experience (especially with something stodgy like VS.NET).\nOr beat your teacher into learning and teaching Python. By far a simpler and better language.\n\nA: Use MonoDevelop but beware of the quirks of X-platform .NET development\nFirst, install mono by either finding it in the Software Centre or typing\nsudo apt-get install monodevelop mono-vbnc\n\nMonoDevelop is pretty equivalent to Visual Studio Express the major differences being:\n\n\n*\n\n*MonoDevelop doesn't support WPF (Windows Presentation Foundation) but that shouldn't matter much as Microsoft has plans to kill WPF with the arrival of Windows 8. \n\n*Verify that the correct .NET framework target is being used. After creating a solution, right click on the project and goto Options->Build->General. Not much different from targeting a specific version of .NET on Windows. \nAside from those issues, I haven't really found anything missing that I can't live without.\nThe only other issue (non mono related) that may come back to bite you is the classic line ending problem. *nix still uses LF and Windows still uses CRLF for line endings so, when you transfer your source files back and fourth between Windows/*nix. AFIAK, MonoDevelop saves source files in UTF-8 by default but VS saves source files in Windows ASCII (with windows-1252 latin ASCII with windows specific line endings). If you receive source files that were created using Visual Studio you may need to convert the format to get it to work in *nix.\nAs you can see, x-platform .NET development can be a little challenging at first but IMHO, it's worth it. I like MonoDevelop's non-cluttered interface (the visual effects in VS just get in the way most of the time), it loads in a fraction of the time that VS does (useful if you don't typically leave your IDE open all the time), it takes up a fraction of the space with no extra unnecessary addons (VS is really obnoxious about this).\nInstalling it was easy as sudo apt-get install monodevelop. Also, popular tools like NUnit (for unit testing) have been ported over to and work flawlessly in *nix. The Windows version of MonoDevelop kinda sucks (or at least it did last time I tried it).\nUpdate:\nTo get VB code to compile you'll also need to install the VB compiler module:\nsudo apt-get install mono-vbnc\n\nI also updated this answer to remove some of the problems that are no longer relevant.\n", "Q: How can I use NetworkManager in GDM? I need to connect to a specific wireless network before being able to successfully connect to my user account, since it needs access to a secured LDAP server.\nThe same applies when I am outside of the office, where I need to connect to a VPN before I can log in.\n\nA: Turns out it's pretty simple; just need to add a .desktop file in the directory:\n/usr/share/gdm/autostart/LoginWindow/\n\nA quick way to do this is to copy the nm-applet.desktop file from /etc/xdg/autostart:\ncp /etc/xdg/autostart/nm-applet.desktop /usr/share/gdm/autostart/LoginWindow/\n\n", "Q: How to remove envelope from Indicator applet without uninstalling the indicator-messages package? I am tired of the envelope in the indicator applet (also known as the messages menu) because I don't use it so I would like to get rid of it but I don't have root access so I can't remove it by uninstalling the indicator-messages package. Is there another way to disable this applet?\nDoesn't the indicator applet offer a way to select which indicator is displayed or not?\n\nA: http://ubuntuforums.org/showthread.php?t=1470786 according to this you can go to karmic like applet by removing indicator-applet from panel and adding gnome-volume-control-applet in startup application\n\nA: Based on Riccardo Murri's answer (Sep 8 '10 at 13:19) I have checked the code and noticed that only modules that end in .so are loaded from INDICATOR_DIR (/usr/lib/indicators/3).\nif (!g_str_has_suffix(name, G_MODULE_SUFFIX)) {\n   return FALSE;\n}\n\nSo  \ncd /usr/lib/indicators/3; sudo mv libmessaging.so libmessaging.so.disabled\n\ndid the trick for me on 10.04, Lucid.\n\nA: If you just want the messaging menu to hide you can blacklist all of the applications that are in it.  You can do that by copying all the application links to your local black list directory.  Here is the command line way to do that:\n  mkdir -p ~/.config/indicators/messages/applications-blacklist\n  cp /usr/share/indicators/messages/applications/* ~/.config/indicators/messages/applications-blacklist\n\nThe first time you create the blacklist directory you'll need to restart your session (log out and back in) and then the messaging menu should hide itself.\n\nA: Looking at the source of indicator-applet-0.3.7, it seems you cannot:\nevery installed module in some \"INDICATOR_DIR\" (it's\n/usr/lib/indicators/3 on my 10.04 box) is loaded.  The\n\"INDICATOR_DIR\" is defined as a compile-time constant, so there is no\nway to change it on a installed system.  The relevant source is at\nlines 703--728 in applet-main.c:\n    /* load 'em */\n    if (g_file_test(INDICATOR_DIR, (G_FILE_TEST_EXISTS | G_FILE_TEST_IS_DIR))) {\n            GDir * dir = g_dir_open(INDICATOR_DIR, 0, NULL);\n\n            const gchar * name;\n            while ((name = g_dir_read_name(dir)) != NULL) {\n                    /* ... some lines omitted for brevity ... */\n                    if (load_module(name, menubar)) {\n                            indicators_loaded++;\n                    }\n            }\n            g_dir_close (dir);\n    }\n\nAs a workaround, you could (warning: untested!):\n\n\n*\n\n*compile your own version of indicator-applet, specifying a\n different \"INDICATOR_DIR\": if you pass\n --enable-localinstall to ./configure, then \"INDICATOR_DIR\"\n will be located in $libdir/indicators/2 and you can also set\n $libdir via command-line options to ./configure.\n\n*within your own INDICATOR_DIR, only activate the indicators you\n want (just symlinking the system-wide ones should suffice)\n\n*use a ~/.gnomerc or ~/.xsession file to modify PATH so that \n your own indicator-applet binary comes before the system-wide\n one. \n", "Q: Lenovo ThinkPads, brightness function keys make two steps instead of one, looking for workaround do you know any workaround for this very long lasting bug buried somewhere in kernel or in gnome-power-manager, please? Thanks in advance. See description:\nhttps://bugzilla.gnome.org/show_bug.cgi?id=579224\n\nA: as a workaround suggest the \"brightness\" applet in gnome\nhttp://library.gnome.org/users/gnome-power-manager/stable/applets-general.html.en\n\nA: Seems to work fine on 11.04, with a Thinkpad T42.\nThe reason, as given above, is that the version of the thinkpad_acpi module that you have is not masking the brightness hotkeys correctly. This means that when you press a hotkey for brightness up or down, the bios grabs it, changes the brightness and also produces an ACPI event. The acpi drivers then generate a virtal keypress, something like X86FreeBrightnessUp, or whatever it is. The gnome power manager responds to this perceived keypress by increasing the brightness again.\nUpgrade, or do a search for thinkpad_acpi hotkey mask and change the default mask to one that masks the brightness hotkeys.\nYou find similar issues for volume, though in that case it is due to the hardware and software mixers both being increased by the same button.\n", "Q: Ubuntu finances and future of project What are the chances that the Ubuntu Project will die if its primary source of funds are removed? In other words, how healthy are the finances of the Ubuntu sponsors Canonical? Is Ubuntu losing money?\n\nA: Mark Shuttleworth started an Ubuntu Foundation with an initial funding committment of $10m. This trust that has the purpose of giving Ubuntu continuity should Canonical ever be dissolved.\nFoundation annoucement\nThe funding is sufficient to 'meet the public commitments to keep Ubuntu entirely free of charge, as well as meeting commitments of support for extended periods.\"\n\nA: There are two things to understand to answer your question :\n\n*\n\n*first, Canonical is backing Ubuntu. Not Mark Shutleworth. What I mean there is that Canonical is a commercial company that sells services (training, support, customizations for OEM...). Last time I heard from them, they were making some money, not enough to be profitable, but they are not crashing either.\n\n\n*second, Mark Shuttleworth created the \"Ubuntu Fundation\", an association whose purpose is to fund the Ubuntu development/support, if Canonical fails. The Fundation has 10M$ in cash, and is doing nothing with it (well, I guess they have placed the money somewhere, but that's not the purpose). It is in a \"dormant\" state, and will be activated if Canonical cannot support Ubuntu anymore. If it is ever activated, it will pay the Ubuntu developer to continue their job, as long as possible, and at the minimum until the existing Ubuntu release reaches their respective end of life.\nThe important point here is that neither Ubuntu, Canonical, nor the Ubuntu Fundation are dependant on Mark Shuttleworth's money. He already gave some of it to those institutions, and now they own it... So even if Mark Shuttleworth spends all his millions, Ubuntu should stay in good shape.\n", "Q: Desktop doesn't remember brightness settings after a reboot Every time I reboot my machine the brightness goes back to 100% in Gnome. I wish it would keep the last setting. Is there anyway?\n\nA: Here is a quick workaround for that :-\nTry testing the setting by typing this command in terminal \necho 0 > /sys/class/backlight/acpi_video0/brightness\n\nif the brightness changes to minimum, you have got it right !\nEdit the /etc/rc.local file by typing \nsudo -H gedit /etc/rc.local    \n\nin terminal\nComment out the exit 0 by adding # in the beginning such that it looks like this :-\n#!/bin/sh -e\n#\n# rc.local\n#\n# This script is executed at the end of each multiuser runlevel.\n# Make sure that the script will \"exit 0\" on success or any other\n# value on error.\n#\n# In order to enable or disable this script just change the execution\n# bits.\n#\n# By default this script does nothing.\n\n#exit 0\n\nthis is necessary otherwise it wont work !\nafter this add the following line in the file\necho 0 > /sys/class/backlight/acpi_video0/brightness\n\nsuch that it looks like this :-\n#!/bin/sh -e\n#\n# rc.local\n#\n# This script is executed at the end of each multiuser runlevel.\n# Make sure that the script will \"exit 0\" on success or any other\n# value on error.\n#\n# In order to enable or disable this script just change the execution\n# bits.\n#\n# By default this script does nothing.\n\n#exit 0\necho 0 > /sys/class/backlight/acpi_video0/brightness\n\nreplace 0 with the required brightness value ( ranges from 0 to 10 )\nsave the file and exit.\nReboot to see the changes.\nNote:- you may have to replace acpi_video0 with your device code if you have a different one (it's mostly acpi_video0). Most users won't need to do so.\n\nA: To adjust screen brightness in 11.10, you will need to access the \"System Settings\":\n\n\n*\n\n*Right-click directly to the right of your username in the toolbar in the upper-right corner of your screen. \n\n*Select \"System Settings.\"\n\n*Select \"Screen\". \n\n*Drag the slider with your mouse to adjust screen brightness. \nIf Ubuntu isn't remembering your adjustment, you may use an application or you may need to use the workaround for GNOME: \nBrightness setting not saved in Ubuntu 11.10\n\nA: Here is a great work around I found, credit and thanks to thaelim on Ubuntu forum How to get effective display brightness management under Unity/Gnome Shell just download the script edit the perimeters at the beginning of the script and save it when your done to your home folder. Heres the download of the full script brightmanager.py\nThese are the variable perimeters to change to your desired settings, as you can see I like mine at 20 all the time with no idle timeout.\nIDLE_DIM_TIME = 0\nIDLE_DIM_AC = False\nIDLE_DIM_BATTERY = False\nIDLE_BRIGHT = 20\nBRIGHT_BATTERY = 20\nBRIGHT_AC = 20\n\nAfter saving then open a terminal and enter\nchmod +x brightmanager.py\n\nThen open up startup applications from the dash, click on the add button, name your start up application, and enter your command as:\npython /home/david/brightmanager.py\n\nreplacing \"david\" with your home folders name, then add a description and click add, logout, and back in, and your done, you now have brightness settings for battery, AC, and idle. \n\nYou will want to do this for each user and each user should have their own copy of the script in their home folder with their own desired settings in the beginning of the script. \n\nA: The file /etc/rc.local should look like this:\n#!/bin/sh -e\n#\n# rc.local\n#\n# This script is executed at the end of each multiuser runlevel.\n# Make sure that the script will \"exit 0\" on success or any other\n# value on error.\n#\n# In order to enable or disable this script just change the execution\n# bits.\n#\n# By default this script does nothing.\necho 0 > /sys/class/backlight/acpi_video0/brightness\nexit 0\n\nPer @zerdo: In my dell studio 1558 the brightness setting is stored in /sys/class/backlight/intel_backlight/brightness.  Just change the path if your computer doesn't use the acpi_video0 folder.\nAlso, per @Nick :\nIf this is the only answer you read, note that the 0 in echo 0 is going to be your default brightness setting. I had set this up and it was driving me crazy for a long time : every time I booted up, it would set it to the lowest brightness setting. I prefer mine to start at max brightness, so I used echo 10 instead. Your hardware might vary in brightness scale.\n\nA: This function, the backlight control, is dependent on your bios and kernel version.\nTry these four things.\nKernel (boot) options\nWhen you boot, at the grub screen, hit e to edit. To the kernel line add nomodeset acpi_backlight=vendor Some hardware may work with different options.\nIntel - nomodeset acpi_backlight=intel\nAcer - acpi_backlight=acer_acpi or even acpi_osi=Linux acpi_backlight=legacy.\nAs you can see, you may need to google search for your settings.\nquiet splash nomodeset acpi_backlight=vendor\n\nIf that works, edit /etc/default/grub and add those options to the default options.\n# command line\nsudo -e /etc/default/grub\n\n# graphical\ngksu gedit /etc/default/grub\n\nEdit the \"GRUB_CMDLINE_LINUX_DEFAULT\" line so it looks like this\n    GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nomodeset acpi_backlight=vendor\"\n\nSave your edit, update grub\nsudo update-grub\n\nCommand line\nIf that does not work, you can try to manually set the brightness. \nNote: Path may vary with hardware / kernel version, may be /proc/acpi/video0 ..., you may need to browse the /proc/acpi directory to find the brightness setting and adjust the following commands accordingly.\ncat /proc/acpi/video/VGA/LCD/brightness\n\nThe output of that command varies a bit with hardware, 1 -> 10 , 1 -> 12 , 1 -> 100 ??? Choose a value and set it (choose the value for your hardware).\nsudo echo 80 > /proc/acpi/video/VGA/LCD/brightness\n\nIf that works, add it to /etc/rc.local\n# command line\nsudo -e /etc/rc.local\n\n# graphical\ngksu gedit /etc/rc.local\n\nAdd in your setting above \"exit 0\"\necho 80 > /proc/acpi/video/VGA/LCD/brightness\n\nxbacklight\nYou can also try xbacklight\nsudo apt-get install xbacklight\n\nYou then adjust with the command line\n# For 80 % brightness\nxbacklight -set 80\n\nAgain, add that to /etc/rc.local\n# command line\nsudo -e /etc/rc.local\n\n# graphical\ngksu gedit /etc/rc.local\n\nAdd in, above \"exit 0\"\nxbacklight -set 80\n\nsetpci\nYou can try to set your brightness with setpci\nThe general syntax is \nsudo setpci -s <address> f4.B=your_setting\n\nYou identify your pci bus address with\nsudo lspci | grep VGA\n\nExample\n00:02.0 VGA compatible controller: Cirrus Logic GD 5446\n\nsetpci -s 00:02.0 F4.B=80\n\nIf you get your setting wrong, most likely you will just loose your display, and have to reboot. As this is a hardware setting, you really need to identify your hardware and research the settings first.\nExamples\nIntel - https://bbs.archlinux.org/viewtopic.php?id=74914\nToshiba - http://www.linlap.com/wiki/toshiba+satellite+t130\nAcer extensa - https://bugs.launchpad.net/ubuntu/+source/linux/+bug/518002\nUbuntu man page setpci\n\nA: This is supposed to be configurable in the energy options, set the brightness to the desired level and it will always be used. If you use a laptop you will also need to configure the level for battery mode as well...\nI found that Gnome has some issues about lcd panel brightness, e.g. if I run on battery mode and set the brightness manually to a given level and leave the laptop unattended for 10 seconds it will go back to the preset brightness when I take control back. Same goes when on A/C mode except it takes longer so goes unnoticed more easily. I believe all those settings should be saved somewhere and restored - at least for A/C mode.\nEDIT: For gnome3 this does not work (at least for me).\n\nA: There seems to be a bug report about this:\nhttps://bugs.launchpad.net/ubuntu/+source/upower/+bug/840707\nFor me, it has worked to place:\necho 0 > /sys/class/backlight/acpi_video0/brightness\n\nin /etc/rc.local.\nOr, as others suggested,\necho 5 > /sys/class/backlight/*/brightness\n\nmight work.\n\nA: The \"Screen\" option of \"System Settings\" works OK, and in /sys/class/backlight/acpi_video0/brightness the option also change accordingly, but the problem is that nothing happens with the real brightness. \nI found the solution to my problem: \nAdd the next option under your \"Device\" section in /etc/X11/xorg.conf and restart:\nOption \"RegistryDwords\" \"EnableBrightnessControl=1\"\nThis worked for my NVIDIA card (Ubuntu 11.10 x64 on Toshiba Satellite L745-SP4142CL)\n\nA: *\n\n*If use nVidia just open dash home and type \"NVIDIA X server setting\".\n\n*Then click \"X Server Color Correction\" under X Screen O.\n\n*Reduce the Brightness level.\n\n*Click \"Confirm current changes\" before the time runs out.\n\n*Choose Quit to save the change.\n\n\nIt worked for me with the following spesifications:\n\n\n*\n\n*Toshiba Satellite L745\n\n*Intel Core i3\n\n*NVidia GeForce with CUDA\n\n*RAM 6 GB\n\n\nA: I found a workaround on webupd8: Fix brightness getting reset (to a very low value or maximum) on reboot in Ubuntu\n\n  \n*\n  \n*The first thing you need to do is to find out which ACPI interface (acpi_video) controls the brightness. This can be done by looking into your Xorg log file to see which acpi_video was loaded. To do this via command line, simply use the following command:\ngrep acpi_video /var/log/Xorg.0.log\n\nThe command above should display an output similar to this:\n[     7.385] (--) intel(0): Found backlight control interface\nacpi_videoX (type 'firmware') for output LVDS1\n\nwhere acpi_videoX is acpi_video0 or acpi_video1. This is the acpi_video module that controls the brightness, so remember it for the next steps.\nIf the command above doesn't display any output and you have a folder called intel_backlight under /sys/class/backlight/, then use intel_backlight as the ACPI interface for the next steps.\n  \n*Next, set (via keyboard Fn + brightness keys) your laptop's brightness to the level you want Ubuntu to use after when it starts.\n  \n*Now we'll have to get the actual brightness value you set under step 2. To do this, run the following command:\ncat /sys/class/backlight/acpi_videoX/brightness\n\nwhere acpi_videoX is the ACPI interface which controls your laptop's brightness, which you found out under step 1.\nRemember this value for the next step.\n  \n*The next step is to create a file (as root) called fixbrightness.conf in your /etc/init/ directory, for example:\ngksu gedit /etc/init/fixbrightness.conf\n\nAnd in this file, paste this:\ndescription \"Sets brightness after graphics device is loaded\"\n\nstart on graphics-device-added\n\ntask\n\nexec /bin/echo BRIGHTNESS_VALUE > /sys/class/backlight/acpi_videoX/brightness\n\nhere, you need to\n  \n  \n*\n  \n*replace BRIGHTNESS_VALUE with the brightness value you got in step 3\n  \n*replace acpi_videoX with the ACPI Interface that controls your laptop's brightness, which you found out in step 1.\nThen save the file.\n  \n*Reboot and the low or maximum brightness issue after reboot / logout should be fixed.\n\n\nA: Run\necho 2 > /sys/class/backlight/acpi_video0/brightness\n", "Q: How can I audit users and access attempts to SSH on my server? I've had a few security problems with a server of mine, a few SSH users have been setting up fires aka giving problems.\nI would like to:\n\n\n*\n\n*Track user logins and logouts\n\n*Track activity of these SSH, in order to discover any malicious activity\n\n*Prevent users from deleting logs\n\n\n\nI am not much of a sys admin and I am quite inexperienced in this matter, so any kind of advice would be very welcome and very helpful. :)\n\nA: [DISCLAIMER] I realize I am late to the party, but I would like to paste an answer that I gave to another question, because I feel like it can offer some good insight to readers, and this question seems to be the go-to place for basic ssh info.\nThere was a similar problem that struck me after reading this question here on AskUbuntu and checking my VPS, only to see a bazillion of brute force attempts. That is when I decided to take action.\nNow according to the question I linked to, if you would like to see failed login attempts on your machine over ssh (could be brute force attempts or anything), try typing this:\ngrep sshd.\\*Failed /var/log/auth.log | less\n\nIf the output consists of multiple lines, that is many brute force attempts, especially if they have happened between short intervals, you might want to do the following pieces of action:\nChange the ssh configuration file\nTo do this, open the file located at /etc/ssh/sshd_config with your favourite editor, like this vim /etc/ssh/sshd_config.\n1. Try to move ssh from port 22:  Now locate the line that reads:\n# What ports, IPs and protocols we listen for\nPort 22\n\nand comment out Port 22, and use anyone you might like. Example:\n# What ports, IPs and protocols we listen for\n# Port 22\nPort 28934\n\nPlease remember that ports below 1024 need special (root) permission. I do not know how this could interfere with it, but I am just saying.\n2. Disable Root logins via ssh: Since the root username is predictable and provides complete access to your system, providing unfettered access to this account over SSH is unwise. Locate the line reading PermitRootLogin and set it to no.\nPermitRootLogin no\n\n3. Disable password authentication: Generate and use SSH keys to log into your system. Without passwords enabled, attackers will need to guess (or steal) your SSH private key in order to gain access to your server. Something that is very very difficult. Proceed to find the line that reads PasswordAuthentication and set it to no\nPasswordAuthentication no\n\n!WARNING! Before doing so, please consult this guide over here on how to set up certificate authentication.\nNOTE: After you have made the changes use sudo /etc/init.d/ssh restart. To connect to another port via ssh use: ssh username@hostname.com -p <port_number>.\nSetup a firewall\nPlease check out this guide on how to set up the extremely powerful and effective firewall, which is integrated into Linux, IPTables.\nSetup scripts to help you with security\nOne that I use personally and quickly comes to mind is Fail2Ban. Fail2ban will monitor your log files for failed login attempts. After an IP address has exceeded the maximum number of authentication attempts, it will be blocked at the network level and the event will be logged in /var/log/fail2ban.log. To install it: sudo apt-get install fail2ban\nCheck command history via ssh\nThere is a linux command, named history, which allows you to see which commands have been input up until that point. Try typing history in a terminal to get to see all commands up to that point. It could help if you were root.\nTo search for a particular command try: history | grep command-name\nTo list all commands after ssh: fc -l ssh\nYou can also edit commands using vi (haven't tried it vim, though I assume it works as well): fc -e vi\nYou can also delete the history: history -c\nNOTE: If you are not a fan of the command history there is also a file in your home directory (cd ~), called .bash_history (if you are using bash) that you can cat to see all that has been typed in the bash shell.\n\nA: A bit overkill, but you can see everything that is run on your system using the \"process event connector\":\nhttp://www.outflux.net/blog/archives/2010/07/01/reporting-all-execs/\n\nA: Since we're talking about SSH servers, I will give you command line solutions.\n\n\n*\n\n*Track user logins and logouts. That's easy, the file /var/log/auth.log should have this information.\n\n*Track activity of those users: If they are fairly innocent, you can check the file .bash_history in their home dir. You will see a list of the commands that they executed. The problem is of course that they can delete or edit this file.\n\n*Prevent users from deleting logs: Users shouldn't be able to touch auth.log. In order to stop them from playing with .bash_history you need to do a couple of tricks. \n\n*What if the user manages to obtain root access? : You're screwed. Unless they make a mistake they will be able to hide all their footsteps.\n\nA: *\n\n*Javier already answered this one: /var/log/auth.log\n\n*I have found a great article about this here.\n\n*If your users don't have access to root then your log files should be safe. You can try to build some custom rules in the sudoers file to restrict what your users can access and how. Also you can increase the log level for the sshd daemon.\n\n\nA: Apart from the login itself there is no safe way to track/log users actions after they log in, assuming they have basic Linux knowledge they will be able to disable shell logging or simply running commands from other shells (e.g. python).\nInstead you should be conservative about providing ssh access, do they really need it ? It's not very common to grant ssh access unless you are on the shell providing business.\n", "Q: Auto-start service on bootup that depend on network I have a particular service (in this case OpenFire) that runs at startup.  When it starts, it attempts to connect to a database at a given hostname.  At startup time it fails to connect to that database because it cannot find the host in DNS.\nMy best guess is that this service is executing on startup before networking has initialized and DNS servers have been obtained from DHCP.  Is there any way to specify startup service dependencies that must be met before executing the /etc/init.d/ script?\n\nA: Forget about upstart. There are much easier ways to do this.\nPut a script that launches Openfire here:\n /etc/network/if-up.d/\n\nIf openfire has to run as your user, so something like:\n#!/bin/sh\nsu -c \"openfire\" myUserName\n\nMake sure you mark it as executable:\nsudo chmod +x /etc/network/if-up.d/openfire\n\nLikewise you can close openfire, when you loose your network connection, by putting a script in /etc/network/if-down.d/ that kills it:\n#!/bin/sh\nkillall openfire\n\n\nA: You could look in /etc/rc0.d for the service; it will have S##[name], for example, S35networking.\nSo if you make it say S36openfire then it should load just after networking.  Or make the number 99 (instead of 36) and it will load last, giving the network time to do its thing.\nHope that'll do the trick for you.\n\nA: if you don't configure your network using NetworkManager, you can try to configure your upstart conf to depend on networking:\n\nstart on starting networking\n\nor\n\nstart on starting network-interface\n\nI don't know how it interacts with NetworkingManager, perhaps NM triggers some events which are detectable through upstart.\n", "Q: Script to dial 3g link in case network is down? I want to set up an Ubuntu router with automatic fail-over to a 3G link. I can probably set up routing and link aggregation, but I don't know how to monitor link status and dial the 3G link in case it is down. Pointers to helpful resources greatly appreciated.\n\nA: I'm not sure there's anything out there that could do this for you... However, you could, with a bit of scripting, a bit of Googling, cobble together a script that:\n\n\n*\n\n*Every 10 minutes, pings google with a timeout of 2 seconds and only from your \"fixed\" connection (not the 3G one) (use the -I flag).\n\n*If the ping succeeds, and you're on the fixed connection, do nothing. \n\n*If you're on 3G and the ping over the fixed connection works, take the 3G adapter down.\n\n*If it fails, bring up the 3G adaptor.\n\n\nHere's my quick attempt:\n#! /bin/bash\n\nCONNECTION=1\n\nmain()\n{\n    if ping -q -c 1 -w 1 -I eth0 google.com > /dev/null ; then\n        echo \"Connection is ok!\"\n\n        if [ $CONNECTION -eq 0 ] ; then\n            # take the 3g connection down\n            ifconfig 3GADAPTERNAME down\n            CONNECTION=1\n        fi\n    else\n        echo \"Connection is dead! Long live the connection!\"\n\n        if [ $CONNECTION -eq 1 ] ; then\n            # turn the 3g connection on\n            ifconfig 3GADAPTERNAME up\n            CONNECTION=0\n        fi\n    fi\n\n    sleep 5\n    main\n}\n\nmain\n\nObviously replace 3GADAPTERNAME with your adapter's name. switch out eth0 if your main connection is different. Make sure it is set to automatically connect (so when it's allowed to, it does). The script will need to run as root.\n", "Q: How to find (and delete) duplicate files I have a largish music collection and there are some duplicates in there. Is there any way to find duplicate files. At a minimum by doing a hash and seeing if two files have the same hash.\nBonus points for also finding files with the same name apart from the extension - I think I have some songs with both mp3 and ogg format versions.\nI'm happy using the command line if that is the easiest way.\n\nA: List of programs/scripts/bash-solutions, that can find duplicates and run under nix:\n\n\n*\n\n*dupedit: Compares many files at once without checksumming. Avoids comparing files against themselves when multiple paths point to the same file.\n\n*dupmerge: runs on various platforms (Win32/64 with Cygwin, *nix, Linux etc.)\n\n*dupseek: Perl with algorithm optimized to reduce reads.\n\n*fdf: Perl/c based and runs across most platforms (Win32, *nix and probably others). Uses MD5, SHA1 and other checksum algorithms\n\n*freedups: shell script, that searches through the directories you specify.  When it finds two identical files, it hard links them together.  Now the two or more files still exist in their respective directories, but only one copy of the data is stored on disk; both directory entries point to the same data blocks.\n\n*fslint: has command line interface and GUI.\n\n*liten: Pure Python deduplication command line tool, and library, using md5 checksums and a novel byte comparison algorithm. (Linux, Mac OS X, *nix, Windows)\n\n*liten2: A rewrite of the original Liten, still a command line tool but with a faster interactive mode using SHA-1 checksums (Linux, Mac OS X, *nix)\n\n*rdfind: One of the few which rank duplicates based on the order of input parameters (directories to scan) in order not to delete in \"original/well known\" sources (if multiple directories are given). Uses MD5 or SHA1.\n\n*rmlint: Fast finder with command line interface and many options to find other lint too (uses MD5), since 18.04 LTS has a rmlint-gui package with GUI (may be launched by rmlint --gui or from desktop launcher named Shredder Duplicate Finder)\n\n*ua: Unix/Linux command line tool, designed to work with find (and the like).\n\n*findrepe: free Java-based command-line tool designed for an efficient search of duplicate files, it can search within zips and jars.(GNU/Linux, Mac OS X, *nix, Windows)\n\n*fdupe: a small script written in Perl. Doing its job fast and efficiently.1\n\n*ssdeep: identify almost identical files using Context Triggered Piecewise Hashing\n\n\nA: If your deduplication task is music related, first run the picard application to correctly identify and tag your music (so that you find duplicate .mp3/.ogg files even if their names are incorrect). Note that picard is also available as an Ubuntu package.\nThat done, based on the musicip_puid tag you can easily find all your duplicate songs.\n\nA: FSlint has a GUI and some other features. The explanation of the duplicate checking algorithm from their FAQ:\n1. exclude files with unique lengths\n2. handle files that are hardlinked to each other\n3. exclude files with unique md5(first_4k(file))\n4. exclude files with unique md5(whole file)\n5. exclude files with unique sha1(whole file) (in case of md5 collisions).\n\nfslint installation instructions\n\nA: Another script that does this job is rmdupe. From the author's page:\n\nrmdupe uses standard linux commands to search within specified folders for duplicate files, regardless of filename or extension. Before duplicate candidates are removed they are compared byte-for-byte. rmdupe can also check duplicates against one or more reference folders, can trash files instead of removing them, allows for a custom removal command, and can limit its search to files of specified size. rmdupe includes a simulation mode which reports what will be done for a given command without actually removing any files.\n\n\nA: I use komparator - sudo apt-get install komparator (Ubuntu 10.04+ ) -  as GUI-tool for finding duplicates in manual mode.\n\nA: For Music related duplicate identification and deletion Picard and Jaikoz by http://musicbrainz.org/ is the best solution. Jaikoz I believe automatically tags your music based on the data of the song file. You don't even need the name of the song for it to identify the song and assign all meta data to it. Although the free version can tag only a limited number of songs in one run, but you can run it as many times as you want. \n\nA: Have you tried\nfinddup\n\nor \nfinddup -l\n\nI guess it works fine.\n\nA: I use fdupes for this. It is a commandline program which can be installed from the repositories with sudo apt install fdupes. You can call it like fdupes -r /dir/ect/ory and it will print out a list of dupes. fdupes has also a README on GitHub and a Wikipedia article, which lists some more programs.\n\nA: dupeGuru has a dedicated mode for music. It is a cross-platform GUI program and, as of today (February 2021), it is in active development, although it is unclear which releases work on which systems. Check its documentation.\n", "Q: Laptop's Internal bluetooth not being recognised by ubuntu: how to diagnose the problem? I have an Acer Aspire 4810T with ubuntu 10.04 installed on it. Fn+F3 should turn on/off the internal bluetooth receiver. But it does nothing. The \"bluetooth\" menu in System > Preferences says \"your computer does not have any bluetooth adapters plugged in\". I have bluez and bluez-utils installed. Other people have reported that bluetooth works out of the box on the timeline series of laptops with ubuntu. (Although others say that upgrading to a newer version of ubuntu rather than doing a fresh install can break things...)\nVarious things I've read on forums that it is suggested I try have failed. hcitool dev gave an empty output (Just a line that said \"Devices\" and nothing else.) hciconfig finished with no output. lshw | grep Bluetooth -A15 also finished with no output.\nI'm not sure what the next step is in diagnosing what the problem is. What can I do now to figure out where the problem is?\n\nA: First of all check if Bluetooth is turned on in BIOS.\nMake sure there are no any more switch to turn it on/off. Not with only Fn+F3\nUse lsusb | grep -i bluetooth to see if system recognises you BT device.\np.s. Have you already used BT on this notebook before? Because you may have standard case with BT indicators and switches, but no BT really installed. Just asking.\n\nA: On my Inspiron 1420N, the bluetooth radio is, internally, a USB device and specifies that in it's complete USB ID.\nTry lsusb | grep Bluetooth, and if that doesn't return anything, try it lowercase.  If that doesn't return anything, open a new tab in the terminal, maximize it, enter sudo lshw and copy the entire thing to paste.ubuntu.com..  Then post a link here so somebody can look through it for you.  You might at that point consider doing the same thing with lspci and lsusb, posting a separate Ubuntu Pastebin link to each.\n\nA: You might want to check your system log with the dmesg command in a terminal. Do that after you tried to activate the device and see whether the log gives you some usefull information on what happened\n", "Q: Moving Wubi Installed on an External Hard Drive to a Laptop I downloaded the 64-bit ISO of Ubuntu, mounted it with Daemon Tools, and installed it on an WD 500 GB \"My Passport\" Hard Drive. I did this with the drive attached to my desktop machine. When I rebooted the desktop, it asked me if I wanted to boot into Ubuntu or not. Now, my thinking was \"if I plug this drive into my laptop, it should give me the same Ubuntu option\"....Yeah, not so much. It just boots straight into Windows Vista. I tried changing the boot order on the laptop (it's a Toshiba), but there was no option for booting from USB. This may be the true problem. If it is, I'll take that issue to superUser. :D\nAnyone have any suggestions to solve my issue?\n\nA: Since you have installed Ubuntu while on your desktop as Wubi installation, I believe there will be no grub installed on the desktop harddrive. Wubi modifies the vista bootloader to provide a Ubuntu boot option. It does so by modifying the boot.ini in the vista partition.\nIf, for example, Vista is installed in C drive, you would find C:\\boot.ini which is a text file specifying the boot options. You can open that file on the host system to see how this is done on the desktop system.\nCaution Wubi installs are by-design not portable across Windows installations (even between 2 machines having same version of Windows - Pls don't even try to copy the boot.ini anywhere else.). This is because of the following\n\n\n*\n\n*Wubi installs the entire ubuntu OS + persistent data into what appears to be a file to windows (see the 2nd item in this section of wubi faq\n\n*Location of the mount point of the drive is not expected to consistent across all systems and hence the location of this above file as the bootloader sees it can vary from one pc to another.\n\n\nInstalling Ubuntu onto an external harddrive is an excellent option of being able to have your favourite os on-the-go and due to the above reasons doing it in a \"Wubi-mode\" kind of defeats that purpose.\nMy suggestion would be, if possible, to have Ubuntu on the external hard-drive as a normal install. If you could eke out some space for a new partition in the disk using gparted in the livecd/liveusb then you could follow this tutorial to even migrate your existing Wubi install into the new partition.\nThis link has comprehensive info on wubi that might be helpful.\n\nA: The boot-loader on your first machine was replaced with GRUB. The laptop still has the Vista Loader on it.\ngrub-install is probably the easiest way to get the boot record on the laptop changed to GRUB, but I'm intentionally not giving you details as you should take the time to ensure that you understand the options you pass, lest you make the laptop unbootable.\nThere is also a way to get the Vista boot-loader to allow it to recognize the Ubuntu partition, but that is as flexible, convenient, and as well-documented as one might expect from Vista.\nYou don't specify the vintage of the laptop, but USB boot came much later than boot from CD-ROM. You may well have to boot your laptop with a LiveCD in order to get GRUB loaded on it.\nOh, and Wubi can be used to install Ubuntu, but that it does so is a secondary feature, and LiveCDs are preferred.\n", "Q: USB Storage Device Automount Under Ubuntu 10.04 one of the problems which appeared is that USB devices would no longer automatically mount when plugged in. Normally I would get a pop up message asking what application I wanted to open the newly plugged in device with, however now that doesn't happen.\nThis happens regardless of the way the device is formatted (NTFS or FAT32) and all other USB devices (printer, keyboard and mouse) work perfectly. \nMy current solution is the mount them manually using sudo mount dev/... /medai/... however to be honest I'm just getting tired of having to do this.\nI'm happy to post any extra information you are likely to need. I know there will be lots of places I could look to find out what's going wrong but I have no idea where to start really.\n\nA: Solved, at least for me. \nI think it is a hardware issue, because I tried a 12.04 live CD in my desktop and everything works fine. I tried at my laptop and it doesn't open the USB automatically.\nAny way the solution that I found is to install usbmount by running the command below on the terminal:\nsudo apt-get install usbmount\n\nThen USB mounts fine and automatically.\nMore info in this page. I also installed autofs.\nHope this works for you.\n\nA: In gconf-editor, look under /apps/nautilus/preferences. There should be a setting called \"media_automount\". Ensure that it is checked. There is also an option called \"media_automount_open\" that you can set if you wish it to open the media in nautilus automatically in addition to mounting it. \n\nA: Something is broken in an update I guess. Try running: \nsudo mkdir /dbos \nsudo fdisk -l\n# find your memory stick\nsudo mount /dev/sdc /dbos\n# now your memory stick is in /dbos\n\n\nA: Try in Nautilus → Edit → Preferences → Media\n\nA: This happened to me in xubuntu. It used to mount automatically but now it does not. My workaround was I installed an extra package called usbmount.\nsudo apt-get install usbmount\n\nA: If you run (Alt+F2) \"ubuntu-bug storage\", your problem is the very first option. It may not be a bug, but a bug report would be the easiest way to rule that out.\nOh and please post a link to the bug report here if you do.\n\nA: It is a known issue with 10.04 if you have a floppy drive. Here is a solution: \n\n\n*\n\n*Open a terminal (Ctrl+Alt+F2).\n\n*Type: gksu gedit /etc/fstab\n\n*Add a # before the line that contains fd0.\n\n*Then in terminal type: rmmod floppy\n\nA: It sounds like you've exhausted most normal fixes. A forced fix might come about if you go into your BIOS settings and verify that you have 'boot from removable/flash drives' set to ON. \nIf it is set to OFF and you toggle it ON, perhaps booting with a non-bootable flash drive in a port, the operating system may be forced to reassign how it manages flash devices. At worst it may spit out another error that could lead you to finding out what is wrong.\n\nA: USB mount only works with small drives, MY LG 500 GB didn't automount and not even with the ubuntu bug storage report... This happened with me twice... the first time I was a linux newbie and I had to format my entire disk again... and now that this happened... nothing actually works EXCEPT.. DISK UTILITY... JUST download it and go to terminal and sudo palimpsest It detects the partition, and lets u check for every kind of error there is and for the mounting issue all u gotta do is just click mount... U get a link for the mounted file and thats it...\nHope this helps anyone...\n"]