["Q: Issues while attempting to open a java project with Netbeans on Ubuntu Mate 15.10 Well, i just moved from windows and installed Netbeans to do some java projects, but I can't manage to open, either my old projects or even a new one. Here's some screenshots:\nwhile attempting to open an old project\nAnd for a new one\nIt's weird it says JDK is missing since, as you can see, everything needed is installed:\ndaniel@daniel-VGN-NR230FE:~$ java -version\njava version \"1.8.0_77\"\nJava(TM) SE Runtime Environment (build 1.8.0_77-b03)\nJava HotSpot(TM) Server VM (build 25.77-b03, mixed mode)\n\nAnd this is it! Thanks for your attention! :)\n\nA: You currently have JRE installed, not JDK. NetBeans needs JDK to work properly. Install it by running:\nsudo apt-get install openjdk-7-jdk\n\n", "Q: Unable to successfully mount Samsung phone Running 15.10 Wily. Installed using the minimal ISO (network install) and selected Xubuntu core. After installing procinfo and running ls_usb, I can see the device when it's plugged in\nBus 001 Device 004: ID 04e8:6860 Samsung Electronics Co., Ltd Galaxy (MTP)\n\nHowever, the device cannot be found to interact with it and mount the filesystems. I tried following Will's instructions in this thread here, but when I reached step six,\nsudo mtpfs -o allow_other /media/mtp/phone\n\nI get the following\n    Listing raw device(s)\nDevice 0 (VID=04e8 and PID=6860) is a Samsung Galaxy models (MTP).\n   Found 1 device(s):\n   Samsung: Galaxy models (MTP) (04e8:6860) @ bus 1, dev 11\nAttempting to connect device\nError 2: PTP Layer error 02ff: get_handles_recursively(): could not get object handles.\nError 2: Error 02ff: PTP: I/O error\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 7: Found a bad handle, trying to ignore it.\nError 2: PTP Layer error 02ff: get_handles_recursively(): could not get object handles.\nError 2: Error 02ff: PTP: I/O error\nListing File Information on Device with name: (NULL)\nLIBMTP_Get_Storage() failed:-1\nError 2: PTP Layer error 02ff: Error getting friendlyname.\nError 2: Error 02ff: PTP: I/O error\n\nthe first time. I tried a second time after dis- and then re-connecting the device again and got\nListing raw device(s)\nDevice 0 (VID=04e8 and PID=6860) is a Samsung Galaxy models (MTP).\n   Found 1 device(s):\n   Samsung: Galaxy models (MTP) (04e8:6860) @ bus 1, dev 12\nAttempting to connect device\nListing File Information on Device with name: Garm\n\nNow, entering t the final command\nls -lt /media/mtp/phone/Card\n\nreturns an error\nls: cannot access /media/mtp/Android: Transport endpoint is not connected\n\n(I replaced 'phone' with 'Android' in the folder name and commands to better fit my usual naming scheme; it still says 'phone' above because I simply copy->pasted from the other thread)\nPlease advise.\nFurther information::\nFollowing another thread which suggested the problem might lie with udev, I attempted this solution, to be greeted with the following error\nadduser: The group `fuse' does not exist.\n\nwhen attempting to add myself to the group. Should I have such a group?\nIn order to avoid conflicting 'solutions' (and keep the install as clean as possible), I have since removed\n\n\n*\n\n*/etc/udev/rules.d/51-android.rules\n\n*mtpfs, mtp-tools (apt-get purge)\n\n*the the /media and /media/mtp folders we created (one was busy and had to be deleted after reboot)\n\n\nSo we should be starting fresh, having undone reversed my earlier attempts.\n\n\n*\n - \n\n\nA: Try running:\nsudo apt-get install jmtpfs\n\nThen connect your phone to computer via USB and enable transfer files on mobile.\nYour phone should be detected.\n", "Q: How do I partition my system so that my SSD houses ONLY the Ubuntu OS and will allow ONLY the Ubuntu OS to reside there? I just built a new computer. I have a 128GB SSD and a 1TB HDD. For speed and lack of clutter, I want my OS to be the only thing inhabiting my 128GB SSD.  I want to allow only Ubuntu itself to be able to modify the 128GB SSD. My hope is to use the 1TB HDD For any and all programs, leaving the OS to operate freely and quickly, on its own, on the uncluttered 128GB SSD.\n\nA: You can separate the base of your Ubuntu installation (/) from the main data area (/home). This is done during installation.\n\n\n*\n\n*Boot into the Ubuntu installer and choose the Try Ubuntu before installing option when prompted.\n\n*Open Gparted and let it scan your drives.\n\n\nSince your drives are new, I'm going to outline a few extra steps here to make sure everything goes well.\n\n\n*\n\n*Select one of the drives from the dropdown in the top right of the window. Either one is fine, and one should already be selected. Just make sure it isn't your USB stick or DVD.\n\n*Under the Device menu at the top of the window, select Create a new partition table.\n\n*Choose the GPT option and Apply out of the window.\n\n*Select the other drive and follow the same process.\n\n*Now, re-select the drive you selected first.\n\n*Right click the area that says Unallocated Space, and choose the option to create a new partition in that space.\n\n*Make the filesystem of that new partition ext4, and make sure it is going to be made a Primary Partition. You can give the drive a label if you want, but it is completely optional.\n\n*Do the same partition creation process for the second drive.\n\n*Now that you have all those operations queued, click the green check-mark at the top of the window to apply them.\n\n*Once that is done, close Gparted and open the Ubuntu installer.\n\n*Go through the steps until you are prompted with a window that gives you options on how you want to install Ubuntu. Choose the Something Else... option and click Next.\n\n*Here, right click the partition on your SSD and go into its Properties.\n\n*Make the mountpoint / and hit OK. You can check the option to format as ext4 if you want, but you don't need to.\n\n*Go into the Properties of the HDD partition and mount it as /home.\n\n*Once all that's done, continue with the installation.\n\n*Reboot once the installation is done, and you should have Ubuntu on your SSD and your data on your HDD.\n\n\nIf you ever end up running out of space on the SSD (very unlikely unless you make another partition on it), you can move some folders from the SSD over to the HDD and symlink to them from their original locations, but this doesn't always work very well, and cannot be done with many folders. It would have to be another question with another answer.\nIf you have any questions, comment.\n\nA: Much has already been written here on an optimal partion scheme for a combination of an SSD with a HDD. There are basically two approaches, each with advantages and disadvantages, we may consider according to our personal preferences.\nKeep all except HOME on the SSD\nFor this we choose \"Do something else\" on installing Ubuntu to install all of the OS on the SSD (mount point /) but format the HDD with mount point /home.\nAdvantages:\n\n*\n\n*easy distribution upgrade or re-installing by having HOME on it's own partition/drive.\n\n*no additional configuration for data directories.\n\n*added new users will use the HDD for HOME without further configuration steps.\n\nDisadvantages:\n\n*\n\n*Cache and application's configuration files will be slower.\n\n*Huge applications (i.e. games) may need considerable space on the SSD.\n\nKeep all but huge data on the SSD\nFor this we will install Ubuntu completely on the SSD but create symlinks to data directories pointing to their physical location on the hard drive.\nAdvantages:\n\n*\n\n*Fastest speed for OS and application's caches.\n\n*Differential backups for configurations or huge data made somewhat easier.\n\nDisadvantages:\n\n*\n\n*needs some configuration to be made for each user.\n\n*An Ubuntu re-install may accidentally overwrite settings files.\n\n\nWhichever you choose it may be better to put swap at the end of the hard drive.\n", "Q: Draftsight 2016 Top Menus absent I upgraded to Draftsight 2016 on Ubuntu 14.04 LTS.\nNow, when I start, there is no menu on the top. \n\nMouse hover\nDoes anybody have an idea how to get the menu back?\n\nA: The same thing happened to me. There seems to be a conflict with an older config file.\nGo to ~/.config folder and rename the DraftSight folder (e.g. to DraftSight.bak) so that DraftSight creates a new config folder. The menus should then reappear when you open DraftSight, but you will have to go through the configuration options to set it up the way you had it before.\n\nA: What helped to me after upgrading to 2016 was copying the xml file from\n~/.config/DraftSight/12.1.2/Workspace/ to \n~/.config/DraftSight/13.0.9/Workspace/\nas it was absent in the folder for the newer version (only files .original and .bak were there, probably backups not loaded by Draftsight). \n\nA: If you are trying to get the tools to show up again, you have to right click where the should be and select main, then choose the tool set you would like.  Hope this is helpful.\n", "Q: How to Remove the Restart Notification (One Time) Sometimes, when I upgrade my kernel or remove older kernels, the system nags me to reboot. I'm aware of this, and I don't want to reboot most of the time. I've notice this not only happens with the update-manager, but also with cairo-dock. How can I remove this notification, not forever, but for this time.\n\nA: OK so I have been researching and experimenting, and here's what you need to do. Delete the following files, and optionally restart any process that's nagging you.\n/var/run/reboot-required\n/var/run/reboot-required.pkgs\n\n", "Q: Ubuntu Settings Add Recording Device I want to add my internal audio as a recording device so I can record my mic and the computer audio (while wearing headphones) in Audacity.\nI'm opening up the sound settings in Ubuntu to get to the following page\n\nHow can I add my internal audio to the list here?\n\nA: Most modern sound adapters have output monitoring channels. Unity/Gnome default sound settings tool (part of unity-/gnome-control-center) does not list them on input tab.\n\n\n*\n\n*Install PulseAudio volume control tool (part of upstream project)\nsudo apt-get install pavucontrol\n\n\n*Run it and go to Input Devices tab.\n\n*Look down to the right corner, Show: drop list, set it to All Input Devices (Default: All Except Monitors)\n\n*As it shows up, you can set it as default.\n\nIf you can't find it, then either it is not supported by driver or hardware itself. You may need to create a virtual loopback.\n\nA: This wiki page covers how to create a dummy audio input using PulseAudio, which can then be recording using Audacity.\nIt uses the PulseAudio Volume Controller (which is available in the default repos, sudo apt-get install pavucontrol), and creates an application stream which Audacity will read as input.\nIt is much better explained on the above wiki page.\n\nA: First and foremost check the Mic by recording and running the following command in a terminal window: \nMake sure the device is not set to Mute, then type\n\narecord test.wav\n\nand speaking into your microphone. To stop this command press Ctrl+C.\nThis will test basic recording functionality by creating test.wav in your HOME directory. Open this file to determine whether you successfully captured audio when using the arecord command. This may not work if the system has not detected your input device as default. \nNOTE: If this fails, in some cases you may need to configure your ALSA setup or by troubleshooting as per the instructions.\nIn Audacity:\nGo to menu: Edit ▸ Preferences ▸ Devices. Go to section Recording\nChoose the appropriate recording device (make sure the device is plugged-in)\nClick OK\nNow Record the audio,Then You should see the audio sensor responding and you should be able to playback the audio.\nElse, Try this (#Mitch)\n", "Q: Just installed Ubuntu on Windows, is there a way to boot into Ubuntu using Windows 10? I have Ubuntu on Windows 10 now and wonder if it's possible to actually boot into Ubuntu through Windows 10. Anyone knows? \n\n\nA: Ubuntu on Windows is a product distributed by Microsoft for their Windows 10 operating system.\nIt is not a full Ubuntu virtual machine including a kernel, and doesn't \"boot\", it is an Ubuntu userspace (ie the programs that make up Ubuntu) made to run under Windows.  You can't \"boot into Ubuntu\" from it.  But you can run most common Ubuntu tools from the command line.\n", "Q: Any help on installing themes for Conky? I'm trying to install a theme for Conky, but the instructions are unclear.\nIt says to put .conky-vision-icons and .conkyrc into the ~ directory.\nBut where is ~? I have unhid the folders but there's still no ~.\nAny ideas?\n\nA: ~ refers to your home directory.  if your username is algonquin, then /home/algonquin is equivalent to ~\n", "Q: Where are changelogs for updates to \"apt\"? Today, I received updates including an update to the apt package.\nStart-Date: 2016-04-07  06:33:13\nCommandline: apt-get dist-upgrade\nUpgrade: apt:amd64 (1.0.1ubuntu2.11, 1.0.1ubuntu2.12), apt-transport-https:amd64 (1.0.1ubuntu2.11, 1.0.1ubuntu2.12), apt-utils:amd64 (1.0.1ubuntu2.11, 1.0.1ubuntu2.12), libapt-inst1.5:amd64 (1.0.1ubuntu2.11, 1.0.1ubuntu2.12), apt-doc:amd64 (1.0.1ubuntu2.11, 1.0.1ubuntu2.12), libapt-pkg4.12:amd64 (1.0.1ubuntu2.11, 1.0.1ubuntu2.12)\nEnd-Date: 2016-04-07  06:33:39\n\nman apt tells me that ...\n\napt (Advanced Package Tool) is the command-line tool for handling\n        packages. It provides a commandline interface for the package management\n        of the system. See also apt-get(8) and apt-cache(8) for more low-level\n        command options.\n\nHowever, I would like to know what changes have been made in this version (and subsequent versions) that may affect my usage of the package. Where can I find such information?\nI have already read several older sources of information including Oli's comprehensive answer.\n\nA: One way:\n$ sudo apt-get changelog apt > ~/apt-changelog\n[sudo] password for dkbose: \nGet:1 Changelog for apt (http://changelogs.ubuntu.com/changelogs/pool/main/a/apt/apt_1.0.1ubuntu2.12/changelog) [439 kB]\nFetched 439 kB in 4s (92.1 kB/s)\n$ \n\nA second way:  \nsudo apt-get install apt-listchanges\n\nBut apt-listchanges will work for all subsequent installs made using APT, not just for a specific package.\nA third way is to examine /usr/share/doc/libapt-pkg4.12/changelog.gz.\n", "Q: Grub is showing Ubuntu but not loading it First of all thanks to all sharing all kinds of useful info.\n   I have one similar problem, want to take inputs from you.\n   In my Laptop I am using wind7 and Ubuntu12.04 as dual boot.\n   it worked fine many days, recently I am seeing one problem.\n   Grub is showing both Wind7 and Ubuntu in boot options, but when I select Ubuntu it is loading only black screen with white cursor blinking. If I select wind7 it is loading wind correctly and working fine. Only problem with Ubuntu loading.\n   It worked previously, now only it is giving problem. What way I have to proceed. I need inputs from you.\n   As I have important data in Ubuntu partition I don't want to experiment my own loosing data.\nThanks in advance.\n\nA: Three possible solutions which are as simple as they are safe. \n\n\n*\n\n*From grub, navigate to Advanced options for Ubuntu and try using an older kernel. (This has been a reoccuring theme throughout my endeavors.)  \n\n*On 12.04 you should be running Upstart by default. Not entirely too likely but if by chance you somehow switched to systemd, navigate to Advanced options for Ubuntu and select an option that states Upstart will be used. (upstart and systemd handle the starting of services during boot)\n\n*If you have a black screen with a visible cursor, there could be an issue with your display manager. When you arrive at this part, bypass xserver by entering a virtual terminal by pressing ctrl+alt+F1. Login with your credentials and type sudo dpkg-reconfigure lightdm. Selecting your display manager will revert any accidental changes back to their default settings. ctrl+alt+F7 will take you back to the graphical interface. \n", "Q: Booting issue, Lenovo G580 Dual boot I have Lenovo G580 (core i5 2.5 GHz), with dual boot (Windows 7 & Ubuntu 14.04). Since last 3 year, it was running smoothly without any issue. \nThere was heating issue because of lots dust in cooler. 5 days ago, when i switched on my laptop, the splash screen appeared with message (\"Lenovo\" and Press F2 ... F12 to choose boot option). From this point everything was normal. After, this screen was blank, no any further processing (GRUB was not loading, from where i used to select an OS to boot).\nI switched off the laptop, and again tried to switched, i saw the same problem persist there.  Then, i open the back of laptop and removed the RAM and again installed the RAM after cleaning. Then, switched on, It was same as earlier (GRUB was not loading after splash screen). I switched off and switched on again by pressing POWER button, and i kept press F12, to select a source to boot (HDD, DVD, ...) I chosen, HDD to boot, and then GRUB loaded, i choose to boot Windows and then Ubuntu after restart. Both OS was working fine, including GRUB. \nBut, now this same happening on daily basis. I took the laptop to repairing center, they tried to boot, and same issue came. They pressed F12 and then again GRUB loaded from where they choose to boot, and OS was working very fine without issue. They said there is no issue in your laptop.\nWhen, I shut down / hibernate my laptop and leave it off for an hour or less time. And then switch on, its work fine. But when i switch on the laptop after 8 or more hours , the issue as again there. This is why repairing center couldn't find the issue. \nI unable to understand, weather its hardware issue or just issue of GRUB? Please, help me come out from this issue.\nThanks\n\nA: Pavan,\nIt looks like BIOS related issue. \nMake sure that you have upgraded to latest BIOS.\n\nA: True. It is possible BIOS issue. I have Lenovo laptop too. BIOS upgrade is possible only in windows. You must download the BIOS update file from the lenovo support web page (be sure that you select your exact model of computer!) and follow the instructions there. After update you will not see GRUB anymore. It will boot directly into windows. To repair this you must go into BIOS and under BOOT options select ubuntu (or move it to the top...ubuntu boot manager must be before the windows boot manager)\n", "Q: Error compiling AODV-UU (modversions.h: No such file) i have to compile aodv routing protokol, but i get error like this\nmake -C /home/andri/Downloads/aodv-uu-0.9.6/lnx KERNEL_DIR=/lib/modules/3.13.0-24-generic/build KCC=gcc XDEFS=-DDEBUG\nmake[1]: Entering directory `/home/andri/Downloads/aodv-uu-0.9.6/lnx'\ngcc -Wall -Wno-strict-aliasing -O2 -D__KERNEL__ -DMODULE -nostdinc -DMODVERSIONS -include /lib/modules/3.13.0-24-generic/build/include/linux/modversions.h -I /usr/lib/gcc/x86_64-linux-gnu/4.8/include -I/lib/modules/3.13.0-24-generic/build/include -DDEBUG -c -o kaodv-mod.o kaodv-mod.c\ncc1: fatal error: /lib/modules/3.13.0-24-generic/build/include/linux/modversions.h: No such file or directory\ncompilation terminated.\nmake[1]: *** [kaodv-mod.o] Error 1\nmake[1]: Leaving directory `/home/andri/Downloads/aodv-uu-0.9.6/lnx'\nmake: *** [kaodv] Error 2\n\nplease help me. \n\nA: You need to install linux-headers\nsudo apt-get install linux-headers-3.13.0-24\n\nI am not sure this will be enough, because I don't know which other packages you do not have installed.\n", "Q: Screen Goes Blank After Boot Once I start my computer Ubuntu starts to boot by showing the splash screen. Then once the splash screen goes away the login screen appears, but then quickly goes blank. \nI uploaded a YouTube video showing exactly what's going on: https://youtu.be/WUogY4_Zf-E\nThis started happening after I rebooted my computer after I installed kde-desktop. \n\nA: This happened to me a while back.  It would get to the login screen, and I could type in a username/password, but at some point it would go blank, and restart X.  \nIt eventually went away when I upgraded to a different video driver, and inspite looking for it, I couldn't find anyone else talking about the same symptoms.  \nI suggest you try a few things, which you may already have done.  Firstly try pressing Ctrl+Alt+F9 to see if you can terminate X and get back to the text screen.  Secondly try ssh-ing into the machine when it's gone black, see if it's still running, or if it has kernel dumped.  \nIn my case it would come back, after a restart, but it was pretty much guaranteed to die when it was first started, then as I said, it started working perfectly, before ultimately, my GPU died.  My laptop is an XPS, and apparently its a common problem that they run hot, over time, and the GPU comes unsoldered.  The blank screens could a sign of something crashing intermittently.  \n", "Q: Webex on Ubuntu 16.04 I'm trying to get Webext to work.  I read this http://www.linuxintro.org/wiki/Use_WebEx_with_Linux\nwhich tells me to check for missing dependencies via \nldd *.so | grep \"not found\"\nIt gives me this list:\n~$ ldd .webex/1524/*.so | grep \"not found\"\n    libgtk-x11-2.0.so.0 => not found\n    libgdk-x11-2.0.so.0 => not found\n    libXmu.so.6 => not found\n    libXtst.so.6 => not found\n    libstdc++.so.6 => not found\n    libXt.so.6 => not found\n    libXi.so.6 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n    libjawt.so => not found\n    libasound.so.2 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n    libjawt.so => not found\n    libXmu.so.6 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n    libuuid.so.1 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n    libstdc++.so.6 => not found\n\nBut if I try to install these 'missing' dependencies I am informed that they are already at latest version.  E.g.\n~$ sudo apt-get install libgtk2.0-0\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nlibgtk2.0-0 is already the newest version (2.24.30-1ubuntu1).\n0 to upgrade, 0 to newly install, 0 to remove and 0 not to upgrade.\n\nSo don't know how to get this going.  Anyone have webex working?\n\nA: I fixed Desktop Share Webex feature on newly installed 16.04 by this way:\nhttps://askubuntu.com/a/363400\nbut i replaced 'openjdk-7-jre' to 'openjdk-8-jre' and 'icedtea-7-plugin' to 'icedtea-8-plugin'\nThere are still 'not found' files in the webex directory, and audio calls still does not work, but i don't need it (we use skype)\n\nA: I was able to get it working pretty well thanks to Yuri's answer and some of the others here. I thought I could provide some additional details and explicit steps.\nFirst, I'm running Oracle's JDK 8, installed via PPA, on a 64-bit platform. This works to launch the meeting dashboard, but desktop sharing doesn't work, because WebEx uses a 32-bit foundation. So I added the 32-bit architecture:\nsudo dpkg --add-architecture i386\nsudo apt update\n\nThen I installed the 32-bit packages:\nsudo apt install openjdk-8-jre:i386 libxmu6:i386 libpangoxft-1.0-0:i386 libpangox-1.0-0:i386 libxv1:i386\n\nThis pulls in a whole bunch of dependencies. After the packages are installed, the WebEx libraries show all dependencies met (except for libjawt.so, which is provided by the JRE):\n$ ldd ~/.webex/T30_MC/*.so | grep \"not found\"\n        libjawt.so => not found\n        libjawt.so => not found\n\nRestart Firefox (I'm not sure if this was strictly necessary, but I wanted to be sure it got all the new libraries). After this, I was able to join my meeting and see the shared desktop. I haven't yet tried audio, as the meeting I was in didn't have web audio enabled.\n\nA: I think the issue is not the lack of dependencies in Linux, the problem is the WebEx update a couple of weeks ago.\nI read in other blog, that new WebEx is not longer supporing JAVA, reason why is not working for us.\n\nA: I used this approach following by \nsudo dpkg --add-architecture i386\nsudo apt-get update\nsudo apt-get upgrade\n\nand restarted firefox.\n\nA: apt-get install openjdk-8-jre:i386\n\nThe above command should fix most of the issue, if not all of it. I also did the below to finish it off.\napt-get install libuuid1:i386 libasound2:i386 libxt6:i386 libxmu6:i386\n\n\nA: I tried adding the following: \nOPTION 1\nsudo apt-get -y remove icedtea-7-plugin:i386 icedtea-netx:i386\nsudo apt-get -y install openjdk-8-jre:i386 libxmu6:i386 icedtea-8-plugin firefox\nsudo update-alternatives --set mozilla-javaplugin.so /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/IcedTeaPlugin.so\n\nOPTION 2\nsudo dpkg --add-architecture i386\nsudo apt-get update\nsudo apt-get upgrade\n\nAnd now I can open the WebEx just fine, but I am unable to use the audio option, and I cannot see what others are sharing, does anybody knows if this can be fixed in Ubuntu 16.04?\n", "Q: Directory structure for storing images in a file system What is the best directory structure for storing personal images in a file-system?\nI have seen this structure in the past: YYYY/MM/DD/\nBut I am unhappy with it.\nIf I want to share a single day via DropBox or OwnCloud the directory name is too short.\nI want the per-day directory name to be more meaningful.\n\nA: Don't forget you can have duplication without making things too hairy.\n/year/\n/year/year-month-day/\n/year/year-month-day/year-month-day-hour-minute-counter.jpg\n\nYou're going to have, what, at most, 60-80 subdirectories at the first level, 366 at the next level (probably much fewer) and however many photos you take in a day on the next level.\nNormally I'd suggest doing this with rename but it's fairly complicated to read from EXIF data so I'd probably suggest something like Phatch, available from the phatch package.\nEither way, make sure you get a backup before you start, or start with a small number of photos.\nOr both.\n", "Q: Clean Install to \"upgrade\" from 14.04 to 16.04 on Acer (AMD), and going back? I wish to perform a clean install of 16.04 on my Acer Aspire laptop, which is currently running 14.04 LTS 64-bit. How do I go about this?\nAlso, can I go back to Trusty Tahr if I don't like Xenial Xerus?\nInfo\n3.2 G memory \nAMD A6-1450 APU with Radeon HD Graphics x 4\nGallium 0.4 on AMD KABINI\n378.7 GB disk space\n\nA: Use CloneZilla to perform a complete system backup, install Xenial Xerus and if you don't like it or it doesn't work the way you expected it, then ... try to fix it first ;) \nAnd if it still doesn't work you can use your image created with CloneZilla and restore your system exactly the way it was before.\n", "Q: How to Enable or Show Ubuntu or Mac style Dock Bar in Ubuntu? I want to know How to Enable/Disable Dock bar in Ubuntu. i.e: How to Disable when we dont need it and how to re-enable it, in Ubuntu?\n\nA: I'd recommend CairoDock for Ubuntu (https://help.ubuntu.com/community/CairoDock). I haven't used it yet, but it seems to be very popular (and customizable). Let me know if this solves your question.\n\nA: Cairodock. I use it and it is pretty good, it has alot lf customization options, there are a bunch of different  themes created by the community, if you search on the ubuntu app store(or whatever it was called, I dont really use it xD) its there, just install and use it, you might need to add it to the startup if you want it to run as soon as you enter the OS, or you can use the GNOME enviroment :)\n\nA: Docky is your solution, install it via synaptic or apt-get. It really looks like a Mac doc with simple customization and very light weight too. \n", "Q: How to remove a browser malware in google chrome Ubuntu 14.04 Whenever I am opening Chrome I am redirected to demo.opera-mini.net/public/ page. I google it and found most solutions related to registry config edit to remove it from Windows environment as they are saying its malware. How do I remove the same from my Google Chrome in Ubuntu 14.04 LTS.\nImage -\n\n\nA: I hit the reset button and its gone now, not pretty sure if it really wiped out from my system, but its not prompting anymore.\n\nThis option is under Settings -> Show advanced settings...\n\nA: You probably installed some application/extension that have changed your startup Google Chrome tab.\nYou can change Google Chrome startup behavior in Google Chrome settings.\nOpen Google Chrome and, on the right of top bar, you can see an hamburger menu or 3-dot menu. Click on it and select Settings.\nYou should see On startup section as showed below:\n\nClick on Set pages, from popup that it will open remove unwishied tab and add your preferred website.\nFor example I use google as startup tab.\n\nUpdate\nIf this not work you could try to watch if there is strange extensions installed on your browser. To do this in Chrome type this in search bar:\nchrome://extensions/\n\nAnd look at your extensions. If there is something that you haven't installed, uninstall it.\n", "Q: Not able to send/receive emails outside my Domain from recently configured email-server  Email-server setup is not working on Ubuntu 16,postfix,dovecot.\n below are the config/facts\n\n\n*\n\n*Registered a domain say atul.com\n\n*ISP is comcast who blocks port 25\n\n*Created A record @ -- 1.2.3.4\n\n*No CNAME except www\n\n*MX Record mail -- @\n\n*all ports are open like 110, 143,993,995,465,587\n\n*I am able to send/receive mail at local users with xyz@atul.com, root@atul.com, atul@atul.com\n\n*I am able to telnet mail.atul.com 465 and @587\n\n*I do not have any mail subscription/account @godaddy.com\n\n*I allowed all necessary ports on my router\n\n\n\nMy Doubts/Questions:\n\n\n*\n\n*Why I am not able to receive email from outside domain? (even when I am able to telnet on mail.atul.com 587)?\n\n*Why I am not able to send mail to outside from my domain? while I tried setting my relayhost on below settings\n\n\n\nrelayhost = blank\nrelayhost = *\nrelayhost = email.secureserver.net\n\n\nMy Question on relayhost is : \n\n\n*\n\n*Can't I setup my independent mail server? without any intervene by comcast or godaddy? Because I don't want to use their mx records or smtp server.\n\n*What all I need to do if I don't want to use their MX Records (smtp server)\n\n*Please Guide me to place correct values for below Fields\n \nA Record, \nCNAME, \nMX Record , \nmyhostname, \nmydestination,\nrelayhost\n\nBelow are the Different configuration I am using...\nmain.cf\nmyhostname = mail.atul.com\n\nmydestination = atul.com, mail.atul.com localhost.localdomain, localhost\n\nrelayhost = [email.secureserver.net]\n\nmaster.cf\n# ==========================================================================\n\n# service type private unpriv chroot wakeup maxproc command + args\n\n# (yes) (yes) (no) (never) (100)\n\n# ==========================================================================\n\n#smtp inet n - - - - smtpd\n#smtp inet n - - - 1 postscreen\n#smtpd pass - - - - - smtpd\n#dnsblog unix - - - - 0 dnsblog\n#tlsproxy unix - - - - 0 tlsproxy\nsubmission inet n - - - - smtpd\n-o syslog_name=postfix/submission\n-o smtpd_tls_security_level=encrypt\n-o smtpd_sasl_auth_enable=yes\n-o smtpd_reject_unlisted_recipient=no\n-o smtpd_client_restrictions=$mua_client_restrictions\n-o smtpd_helo_restrictions=$mua_helo_restrictions\n-o smtpd_sender_restrictions=$mua_sender_restrictions\n-o smtpd_recipient_restrictions=\n-o smtpd_relay_restrictions=permit_sasl_authenticated,reject\n-o milter_macro_daemon_name=ORIGINATING\nsmtps inet n - - - - smtpd\n-o syslog_name=postfix/smtps\n-o smtpd_tls_wrappermode=yes\n-o smtpd_sasl_auth_enable=yes\n-o smtpd_reject_unlisted_recipient=no\n-o smtpd_client_restrictions=$mua_client_restrictions\n-o smtpd_helo_restrictions=$mua_helo_restrictions\n-o smtpd_sender_restrictions=$mua_sender_restrictions\n-o smtpd_recipient_restrictions=\n-o smtpd_relay_restrictions=permit_sasl_authenticated,reject\n-o milter_macro_daemon_name=ORIGINATING\n\n10-master.conf\nservice imap-login {\n\ninet_listener imap {\n        #port = 0\n}\n\ninet_listener imaps {\n    port = 993\n    ssl = yes\n }\n\nservice lmtp {\n      unix_listener /var/spool/postfix/private/dovecot-lmtp {\n      mode = 0600\n      user = postfix\n      group = postfix\n  }\n}\n\nAny Help will be highly appreciable, Thanks in Advance\nMore info added below atul.com is not real domain I changed the name\nnslookup\n> set type=MX\n> atul.com\n\nNon-authoritative answer:\n*** Can't find atul.com: No answer\n\nand When I do \n\n> mail.atul.com\nServer:     75.75.75.75\nAddress:    75.75.75.75#53\n\nNon-authoritative answer:\nmail.atul.com   mail exchanger = 10 atul.com.\n\nAuthoritative answers can be found from:\n\n\nA: What you want to do is not possible. You need an open port 25.\nPort 587 is the \"submission\" port, it is used only by end-users wishing to send e-mail through an external SMTP server.\nAfter that, when two servers are communicating with each other to transmit a message to its destination, only port 25 is used.\n", "Q: Ubuntu Touch Documents Viewer wont Install I am trying to install the Document Viewer on Ubuntu Touch. I had it installed before but entered read-write mode, and screwed things up. Therefore I reflashed Ubuntu Touch using,\nubuntu-device-flash touch --channel=ubuntu-touch/stable/ubuntu --bootstrap --wipe\n\nThis appears to have reinstalled Ubuntu Touch, but I can't install Document Viewer. When I try it downloads to 100% then says \"Download or install failed. Please try again.\". Any suggestions on how to fix this would be appreciated.\n\nA: I was on OTA 9 and after I upgraded to OTA 10 the document viewer installed without issue.\n", "Q: Non-interactive area overlapping desktop on lubuntu I'm running Lubuntu on a virtualbox and after certain time, one part of my screen will just lost control and can't interact with anything behind that area.\nAlso, right clicking on that area will show the context menu in Open Box style while my default desktop is lubuntu.\nHow do I fix this?\nupdate\nI think it has something to do with Netbeans. Because it appears that everytime it happens, Netbeans is running.\n\nA: I think I've found a solution. The problem doesn't happen anymore (tested for 2 days so far).\nI removed the openbox desktop environment\nsudo apt-get purge openbox obconf obmenu\n\nAlso removed Cairo. I'm not sure which one solved the problem, but definitely not needing them anymore.\nHow to remove desktop environments?\n", "Q: How to assign /home partition of LinuxMint when I replace LinuxMint with Ubuntu I have recently bought a HP laptop and installed 64-bit LinuxMint 17.3 XFCE edition. The partitioning that I have done is 50GB for root, 8GB for swap and the remaining disk space ~407GB as /home. Now, I want to remove LinuxMint and install 64-bit Ubuntu 16.04 when it arrives.\nI do not wish to partition my hdd again and I have quite a lot of data in my /home partition.\nCan I install Ubuntu 16.04 on the root partition and will it automatically use the /home partition as its home? Or, would I need to do some extra configuration to assign this /home partition to Ubuntu?\nPlease help.\n\nA: By default Ubuntu will create a dual boot with the existing Mint, or it will wipe and overwrite all of your hard drive(s), depending on your choice.\nTo install Ubuntu on the existing Mint partition with keeping HOME on the other partition you need to choose \"Do someting else\" on installation.\nThis will open the graphical partition manager Gparted for a custom partitioning of your drive(s). You may not need to create new partitions but you should take care on where the mount points are. \n\n\n*\n\n*Take care to tick format for the root partition at mount point / (where Mint resides) only.\n\n*Do not tick format for your previous home partition. Choose this partition to have its mount point /home.\n\n\nA: \nCan I install Ubuntu 16.04 on the root partition and will it automatically use the /home partition as its home?\n\nThe easiest method is to tell it to do so yourself. \n\nOr, would I need to do some extra configuration to assign this /home partition to Ubuntu?\n\nPick \"something else\" and mount the partitions Mint is installed on as /home without formatting it. You can also set / and swap from the partitions you already have but do format those. A separate data partitions you have (ntfs or ext) can be mounted the same way; that one also without formatting it.\n", "Q: Running virtual machine host and guest on a laptop/desktop I would like to create a portable system by installing a minimal virtual machine host on my laptop and on my desktop. I would then like to have the virtual machine guest on a USB memory stick that I can run on both the laptop and desktop (not at the same time). By moving the USB memory stick from one to the other I would have the same installation on whichever computer (desktop/laptop) I decide to use. Is this setup possible to create with Ubuntu? Where could I find further information about the setup?\n\nA: It is possible with VirtualBox. When you create a virtual machine, you can choose where the files are saved, so you can save them on removable media. And on the other machine you can tell it to run the virtual machien stored on the removable media.\nActually, it may be preferable to create separate virtual machines on both systems, and store only the virtual disk file on removable media. Think of having two computers in two places and just carrying the hard drive.\n", "Q: I can not extract RAR file I can not extract RAR file, I tried many tutorials that I found on the internet but no one work.\nWith right click, says it is not possible to finish extraction\nwith \"unrar x\", show this memsage\n\n\"Cannot open archive.rar No files to extract\"\n\nI transfer this file 2 times with USB drive, and before that I extracted it on another PC, so I think it is intact.\nanyone know the solution?\n\nA: You can install and use the utility p7zip (p7zip-full and p7zip-rar).  \np7zip is a file archiver that archives with very high compression ratios.\np7zip-rar provides a module for p7zip-full to\nextract .rar files.\nTo install the tool - open a terminal and execute these commands :  \nsudo apt-get update  \n\nsudo apt-get install p7zip-full p7zip-rar  \n\nNow you can extract .rar files from nautilus right-click menu.  \nAdditional information and a list of supported archive formats :  \n\n\n*\n\n*Unpacking RAR only if p7zip-rar package is installed.\n\n*Packing / Unpacking : 7z, ZIP, GZIP, BZIP2, XZ and TAR.  \n\n*Unpacking only : APM, ARJ, CAB, CHM, CPIO, CramFS, DEB, DMG, FAT,\nHFS, ISO, LZH, LZMA, LZMA2, MBR, MSI, MSLZ, NSIS, NTFS, RAR, RPM, SquashFS, UDF,\nVHD, WIM, XAR and Z.\n\nA: install an archive manager like 7zip\nfor easy installation, I recommend getting synaptic which is GUI manager for your downloads\nFrom terminal:\nsudo apt-get update\nsudo apt-get install synaptic\n\nfrom there, search for 7zip and mark for installation and then click apply. This will also make your future installations much easier if you're not accustomed to the command line like me.\n\nA: The best and easy way to extract password protected rar files in ubuntu or other linux distros is to use the \"Xachiver\" which is also available in app store\n\nA: Unrar does not work, install and use rar:\nsudo apt install rar\n\nand extract files:\nrar x file.rar\n\n", "Q: alias nested string I have an alias for youtube_dl which adds some arguments in my .bashrc file. I want to run this in a separate terminal similar to how it is done here. The problem is that this takes a string as input.\nmy current alias:\nalias youtube-dl=\"youtube-dl -ci --restrict-filenames -o '%(title)s.%(ext)s'\"\n\nhow I want the new alias to look like:\nalias youtube-dl='gnome-terminal -e \"youtube-dl -ci --restrict-filenames -o '%(title)s.%(ext)s'\"'\n\nThe problem is, however, that now the '-strings are interpreted as two separate strings. In addition, I am now unable to add the url as an argument. How do I circumvent this?\n\nA: You could mess around with quotes and escaping, but I prefer to look for ways to reduce the quoting levels. For example, you could use gnome-terminal -x instead:\n-e, --command=STRING\n         Execute the argument to this option inside the terminal.\n\n-x, --execute\n         Execute  the  remainder  of  the  command  line  inside   the\n         terminal.\n\nSo, \ngnome-terminal -e \"youtube-dl -ci --restrict-filenames -o '%(title)s.%(ext)s'\"\n\nBecomes:\ngnome-terminal -x youtube-dl -ci --restrict-filenames -o '%(title)s.%(ext)s'\n\nShaving off one layer of quotes. And the alias would be:\nalias youtube-dl='gnome-terminal -x youtube-dl -ci --restrict-filenames -o \"%(title)s.%(ext)s\"'\n\n\nOr you could use a function:\nyoutube-dl()\n{\n    gnome-terminal -x youtube-dl -ci --restrict-filenames -o '%(title)s.%(ext)s' \"$@\"\n}\n\n", "Q: GRUB stops while booting docking station My Problem\nI have some problems starting up my Lenovo T540p in the docking station. If I start outside the docking station Linux is started and everything is perfect. I can put the notebook into the docking station and use two more displays. \nIf the notebook is in the docking station, I can make a reboot in the docking station and the computer restarts normal. But if I turn off and on the notebook, while it still in the docking station, it stops running with a blinky cursor in normal textmode 80x20 (I mean the textmode known from MS-Dos, with no graphics). Holding down the Shift button while starting up shows me \"GRUB Loading.\"(also in textmode 80x20). There is nothing more, no error number nothing. I start my OS via USB, but as far as I can remember the problem also exist running normal SATA-HDD.\nMy docking station\nI use the normal docking station for the notebook.(Not the one using the USB-Interface)\nhttps://www.cyberport.de/?DEEP=1D02-6AY&APID=117&gclid=CJjw6tmL_MsCFUWNGwodyLYKSw\nI tried different distributions: Mint, Fedora, Mint 17.3, Debian 8.4 with KDE, Ubuntu 15.10. Its always the same.\nI read (google,manjaro.org) \n\n[SOLVED] Grub not loading thinkpad_acpi in docking station\n\nand tried to use thinkpad_acpi in an extra file (like it was described there)!\nI read \n\nhttp://www.thinkwiki.org/wiki/Thinkpad-acpi\n\nand found out that thinkpad_acpi is not longer in use. In stead of using thinkpad_acpi, I should use ACPI bay! ? :-( \nAlso playing with acpi should not be harmless at all because important devices like fan control would be deactivated. (If this is true I do not know)\nI read (google,it is in askubuntu)\n\nHow do I disable ACPI when booting?\n\nand used acpi in \nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash acpi=off\"\nI tried some modification of\nGRUB_CMDLINE_LINUX_DEFAULT=\"...\"\n-nomodeset\n-xforcevesa\n-\"\" <-nothing\netc.\nI tried different settings for the display in the bios.\nNo Display, Display in Dockingstation etc.\nSoftware Version\nsudo X -version\n\nX.Org X Server 1.17.2\nRelease Date: 2015-06-16\nX Protocol Version 11, Revision 0\nBuild Operating System: Linux 3.13.0-68-generic x86_64 Ubuntu\nCurrent Operating System: Linux ***** 4.2.0-16-generic #19-Ubuntu SMP Thu Oct 8 15:35:06 UTC 2015 x86_64\nKernel command line: BOOT_IMAGE=/boot/vmlinuz-4.2.0-16-generic root=UUID=7fb2e262-0d61-4640-954a-7c9b79acf84c ro quiet splash --- vt.handoff=7\nBuild Date: 12 November 2015  05:33:29PM\nxorg-server 2:1.17.2-1ubuntu9.1 (For technical support please see http://www.ubuntu.com/support) \nCurrent version of pixman: 0.32.6\n    Before reporting problems, check http://wiki.x.org\n    to make sure that you have the latest version.\n\nuname -a\n\nLinux *** 4.2.0-16-generic #19-Ubuntu SMP Thu Oct 8 15:35:06 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\nGRUB Bootloader\n\ncat /etc/default/grub\n# If you change this file, run 'update-grub' afterwards to update\n# /boot/grub/grub.cfg.\n# For full documentation of the options in this file, see:\n#   info -f grub -n 'Simple configuration'\n\nGRUB_DEFAULT=0\nGRUB_HIDDEN_TIMEOUT=0\nGRUB_HIDDEN_TIMEOUT_QUIET=true\nGRUB_TIMEOUT=10\nGRUB_DISTRIBUTOR=`lsb_release -i -s 2> /dev/null || echo Debian`\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\nGRUB_CMDLINE_LINUX=\"\"\n\n# Uncomment to enable BadRAM filtering, modify to suit your needs\n# This works with Linux (no patch required) and with any kernel that obtains\n# the memory map information from GRUB (GNU Mach, kernel of FreeBSD ...)\n#GRUB_BADRAM=\"0x01234567,0xfefefefe,0x89abcdef,0xefefefef\"\n\n# Uncomment to disable graphical terminal (grub-pc only)\n#GRUB_TERMINAL=console\n\n# The resolution used on graphical terminal\n# note that you can use only modes which your graphic card supports via VBE\n# you can see them in real GRUB with the command `vbeinfo'\n#GRUB_GFXMODE=640x480\n\n# Uncomment if you don't want GRUB to pass \"root=UUID=xxx\" parameter to Linux\n#GRUB_DISABLE_LINUX_UUID=true\n\n# Uncomment to disable generation of recovery mode menu entries\n#GRUB_DISABLE_RECOVERY=\"true\"\n\n# Uncomment to get a beep at grub start\n#GRUB_INIT_TUNE=\"480 440 1\"\n\nlspci\n\n00:00.0 Host bridge: Intel Corporation Xeon E3-1200 v3/4th Gen Core Processor DRAM Controller (rev 06)\n00:02.0 VGA compatible controller: Intel Corporation 4th Gen Core Processor Integrated Graphics Controller (rev 06)\n00:03.0 Audio device: Intel Corporation Xeon E3-1200 v3/4th Gen Core Processor HD Audio Controller (rev 06)\n00:14.0 USB controller: Intel Corporation 8 Series/C220 Series Chipset Family USB xHCI (rev 04)\n00:16.0 Communication controller: Intel Corporation 8 Series/C220 Series Chipset Family MEI Controller #1 (rev 04)\n00:16.3 Serial controller: Intel Corporation 8 Series/C220 Series Chipset Family KT Controller (rev 04)\n00:19.0 Ethernet controller: Intel Corporation Ethernet Connection I217-LM (rev 04)\n00:1a.0 USB controller: Intel Corporation 8 Series/C220 Series Chipset Family USB EHCI #2 (rev 04)\n00:1b.0 Audio device: Intel Corporation 8 Series/C220 Series Chipset High Definition Audio Controller (rev 04)\n00:1c.0 PCI bridge: Intel Corporation 8 Series/C220 Series Chipset Family PCI Express Root Port #1 (rev d4)\n00:1c.1 PCI bridge: Intel Corporation 8 Series/C220 Series Chipset Family PCI Express Root Port #2 (rev d4)\n00:1c.2 PCI bridge: Intel Corporation 8 Series/C220 Series Chipset Family PCI Express Root Port #3 (rev d4)\n00:1d.0 USB controller: Intel Corporation 8 Series/C220 Series Chipset Family USB EHCI #1 (rev 04)\n00:1f.0 ISA bridge: Intel Corporation QM87 Express LPC Controller (rev 04)\n00:1f.2 SATA controller: Intel Corporation 8 Series/C220 Series Chipset Family 6-port SATA Controller 1 [AHCI mode] (rev 04)\n00:1f.3 SMBus: Intel Corporation 8 Series/C220 Series Chipset Family SMBus Controller (rev 04)\n03:00.0 Unassigned class [ff00]: Realtek Semiconductor Co., Ltd. RTS5227 PCI Express Card Reader (rev 01)\n04:00.0 Network controller: Intel Corporation Wireless 7260 (rev 83)\n\nI learned a lot but I can not find a solution for the problem.\nI do not want to flash the firmware as it described on some webpages. Because my displays do not flicker and they are working.\nDoes anyone have the problem ?\n\nA: I found a way to handle the problem. The first time I used the PC, I thought the problem appears while using a second Monitor. Ubuntu always told me having trouble with X. When I released the Monitor everything worked fine. In the newer releases of Ubuntu this monitor-error doesn't occur anymore. \nI never had the idea to release something else at back of the docking station.\nToday I read on a webside, somebody solved the problem by pulling off every USB Device. I did so too. I released keyboard and mouse and (behold) it started up. I tried to use only one device and also the pc starts up. Only the combination of both devices will show the blinky cursor and makes the pc halt.\nFor both devices (mouse and keyboard) I use a USB-Hub which works fine for me.\nIts not the best solution using a HUB and still haveing USB-Ports left at the ds. Also I do not really know where the error comes from. \nI am interested whats happening there!\n", "Q: Connection abort when trying to log in to chroot jailed account via sftp I'm trying to make a user kake_sftp that can log in to the web server located at /var/www/html or similar. I know chroot needs some additional subdirectiories for the permissions to work out, so I'm fine with adding new folders or changing the folder layout a bit.\nI created the user in group www-data and with home directory in /var/www/html\n$ cat /etc/passwd | grep kake_sftp\nkake_sftp:x:1001:1001::/var/www/html:/bin/bash\n\n$ groups kake_sftp\nkake_sftp : kake_sftp www-data\n\nThen I did some changes in /etc/ssh/sshd_config. I replaced \"Subsystem sftp /usr/lib/openssh/sftp-server\" with \"Subsystem       sftp    internal-sftp\" and I added the following lines at the end\nMatch User kake_sftp\nChrootDirectory /var/www\nForceCommand internal-sftp\nAllowTcpForwarding no\n\nThe permissions of the www folder is set as follows.\n$ ls -la /var/www\ndrwxrwxr-x  3 root root     4096 Apr  7 12:17 .\ndrwxr-xr-x 12 root root     4096 Apr  4 10:17 ..\ndrwxr-xr-x  2 root www-data 4096 Apr  4 11:34 html\n\nWhen I now try to log in with Filezilla set to sftp. I get the following error.\nError:  Network error: Software caused connection abort\nError:  Could not connect to server\n\nWhen I try to log in with my main user via sftp, it works like a charm. So there isn't a problem with the client.\n\nA: The reason why this did not work was because the chrooted directory had write permissions. By revoking all write permissions, I managed to connect.\nchmod 555 /var/www\n\n", "Q: How to run a command on remote host from a service? I have a service in '/etc/init.d'. In that service, I run a command on a remote machine using ssh as a user. Currently I do this in the following way:\nsudo -u user bash -c \"ssh user@172.21.6.70 'source ~/.envrc ; (cd /catalog; ./bin/catalog start &)'\"\n\nThis is the start command of that service and the service name is catalog.\nWhen I do sudo service catatlog start the command runs successfully i.e it properly SSH'es into the target machine which is user@172.21.6.70 as the user user but it does not start the service.\nCan anyone tell me how to tweak this so that it runs successfully?\n\nA: So I fixed it by using nohup command:\nsudo -iu user ssh user@172.21.6.70 \"nohup bash -c 'source ~/.envrc ; (cd /catalog; ./bin/catalog start &)'\"\n\n", "Q: Disable events from extra keyboard keys on notebook How can I disable events like \"fly mode\", \"turn of screen\" which locate in F1-F12 buttons on my notebook?\nI need those buttons for hotkeys in my IDE and I always call this events when I misclicked and pressed single F1-F12\n\nA: On my laptop (Lenovo) this can be disabled in BIOS. \n", "Q: Static IP in ubuntu server 15.10 I know there's a lot of this kind of questions and tutorials about setting static ips, but I've tried everything and still I can't manage to get a static ip. Internet's working fine (I can ping google.com), but I'm not getting the ip I want, I'm still getting a random ip (usually 192.168.1.8)\nHere's my config:\nauto lo\nauto lo intet loopback\n\nauto lo enp2s0\niface lo inet loopback\niface enp0s3 inet static\n        address 192.168.0.107\n        netmask 255.255.255.0i\n        gateway 192.168.1.1\ndns-nameservers 200.45.191.35 200.45.48.233 \n\nThis is what I get when I put ifconfig -a:\nenp2s0    Link encap:Ethernet  HWaddr b8:70:f4:3f:8c:c5  \n          inet addr:192.168.1.8  Bcast:192.168.1.255  Mask:255.255.255.0\n          inet6 addr: fe80::ba70:f4ff:fe3f:8cc5/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:380 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:363 errors:0 dropped:0 overruns:0 carrier:1\n          collisions:0 txqueuelen:1000 \n          RX bytes:34659 (34.6 KB)  TX bytes:63438 (63.4 KB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:354 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:354 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:59253 (59.2 KB)  TX bytes:59253 (59.2 KB)\n\ntun0      Link encap:UNSPEC  HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  \n          inet addr:10.8.0.1  P-t-P:10.8.0.2  Mask:255.255.255.255\n          UP POINTOPOINT RUNNING NOARP MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:100 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nwlp3s0    Link encap:Ethernet  HWaddr 38:59:f9:c5:4d:5b  \n          BROADCAST MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nAnd this is route:\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         192.168.1.1     0.0.0.0         UG    0      0        0 enp2s0\n10.8.0.0        10.8.0.2        255.255.255.0   UG    0      0        0 tun0\n10.8.0.2        *               255.255.255.255 UH    0      0        0 tun0\n192.168.1.0     *               255.255.255.0   U     0      0        0 enp2s0\n\nAnd this is my less /etc/resolv.conf\n# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)\n#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN\nnameserver 200.45.191.35\nnameserver 200.45.48.233\nsearch Home\n/etc/resolv.conf (END)\n\nThanks!\n\nA: In addition to using the correct interface name, and correcting the netmask line, as suggested in comments, your file also lists the address field as 192.168.0.107 instead of 192.168.1.107. \nYou also need to remove these two lines:\nauto lo enp2s0\niface lo inet loopback\n\nAnd replace them with:\nauto enp2s0\n\nSo your whole /etc/network/interfaces file should look like this:\n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# The primary network interface\nauto enp2s0\niface enp2s0 inet static\n address 192.168.1.107\n netmask 255.255.255.0\n gateway 192.168.1.1\n dns-nameservers 200.45.191.35 200.45.48.233\n\nRather than rebooting you can restart your interface with:\nifdown enp2s0 && enp2s0\n\n\nA: Change in /etc/network/interfaces\nauto lo enp2s0\niface lo inet loopback\n\niface enp2s0 inet static\n    address 192.168.1.107\n    netmask 255.255.255.0\n    gateway 192.168.1.1\n    dns-nameservers 200.45.191.35 200.45.48.233 \n\n", "Q: What's the meaning of `-uc -us` options in `debuild -uc -us`? Everybody on the Internet tells to build packages with debuild -uc -us, this answer for example, but I totally can't find what do these options mean, even the built-in help (debuild --help) doesn't tell anything about -uc and -us.\nSo what do these options mean?\n\nA: Commands' built in 'help' is usually insufficient for this kind of thing.\nIf you had read the debuild manpage you'd find those are dpkg-buildpackage flags which are passed from debuild to dpkg-buildpackage and then would have been able to use dpkg-buildpackage's manpage to find the answer.\nFrom the Xenial man page for dpkg-buildpackage:\n   -us    Do not sign the source package.\n\n   -uc    Do not sign the .changes file.\n\n", "Q: How to save the command line output to a file IN REALTIME I have made a bash script that is designed to backup my PC every night around 4 o'clock. After the backup has finished, my system goes back into sleep.\nCurrently I am using | tee -a $LOGFILE to log all the commands, however, the logging is not in real-time. When my computer goes into sleep, it hasn't written the file yet, so I need to wake up my PC before I can see the changes on the webdav backup location.\nThis is very annoying since I can't look quickly up why it hasn't backed up last night.\n\nA: With the available information this is a bit of a shot in the dark, but... if the script is the one that issues the command to go back to sleep (which one?) the problem may be stdio buffering. So I will\n\n\n*\n\n*prepare a script that does the backup but will not go to sleep, call it bck_script. \n\n*prepare another script that sends the PC to sleep, call it sleep_script \nSchedule a third script with \nbck_script | tee $LOGFILE\nsync\nsleep 30\nsleep_script \n\n... where the sleep is probably overdoing it but well --- I really do not trust a lot sync over network or with \"intelligent\" (read strangely buffered) SSDs. \n", "Q: rvm command not working I am facing issue while running the following command \nrvm --default use ruby-2.1.6@metasploit-framework\nerror - > no comment RVM found \n\n\nA: That's because rvm is not installed on your machine , to install it follow this link How do I install ruby-rvm?.\n", "Q: Can I install the VirtualBox Extension Pack from the Ubuntu repositories? I have VirtualBox running on several server installations, always without any GUI, administering using the vboxmanage commands.\nI used to install from the Oracle PPA, but since the end of the two different versions of vbox, I've been installing from the Ubuntu repos. I've found the package for installing the guest additions iso, but never been aware of the extension packs being there. \nI'm asking as the virtualbox version for 14.04 moved from 4.3.10 to 4.3.34 a little while back, so added a step for me running apt-get dist-upgrade.\nI know how to get hold of these from Oracle and install them manually, but is there another method, without using GUI? Are the extension packs anywhere in the Ubuntu repos?\n\nA: This assumes virtualbox is already installed.\nI looked at the source of the virtualbox-ext-pack package in Ubuntu and I found some gems. I did the following which is a variation on what that package does in a script I am using:\nVBOXVERSION=$(VBoxManage --version | sed -r 's/([0-9])\\.([0-9])\\.([0-9]{1,2}).*/\\1.\\2.\\3/')\nwget -q -N \"http://download.virtualbox.org/virtualbox/$VBOXVERSION/Oracle_VM_VirtualBox_Extension_Pack-$VBOXVERSION.vbox-extpack\"\nVBoxManage extpack install --replace Oracle*.vbox-extpack\n\nThis was on Debian Jessie, but I am quite confident it would work the same on almost any flavor of Linux, possibly Unix too.\n\nA: Because the Virtual Box extension pack is closed source proprietary software we will not be able to provide debian packages or binaries from the Ubuntu repositories.\nTo ease installing of extension packs to Virtual Box versions provided by the repositories we maintain a download helper script in the multiverse repository from Ubuntu >= 15.10 which will download the extension pack from Oracle (virtualbox-ext-pack).\nDo not install this for Virtual Box versions you had downloaded and installed from other sources.\n\nA: On Ubuntu 17.04+:\nsudo apt install virtualbox-ext-pack\n\nPS: I know this question was made a long time ago when this was not an option, but I'm writing this answer to help people that came here through Google in 2018+.\n\nA: apt-cache search virtualbox gives me an virtualbox-ext-pack which is the pack youre looking for.\n", "Q: Memory usage by Java processes I notices that applications use almost all memory on my ubuntu 14.04 server.\nCan you look into my htop screen and let me know whether this situation is normal?\n\nThere are many processes for two java application, for both of them all related threads use 3.7% and 4.8% of memory. Is it for each thread or only for root process 3.7%?\nHow can I see in percentage which process use this percentage of memory and how many? I have 60 processes with 3.7% so it is much more than 100%\n\nA: All threads in a Java process share almost all memory.  Each thread will have a local stack which is usually less than a megabyte.  As you see all the relate threads show the same memory utilization.  The 60 related processes showing 3.7% memory utilization might be using 3.8% of available memory.\n", "Q: Detect (apparently) manually installed driver Nvidia I have the same problem as here and the solution is saying that I manually installed a driver and this causes the problem. Great! But how do I detect said driver (and deinstall it)?\nI tried various ideas from the internet:\n$> nvidia-settings -q NvidiaDriverVersion\n\nERROR: Error resolving target specification '' (No targets match target specification), specified in query 'NvidiaDriverVersion'.\n\n$> grep -i \"x driver\" /var/log/Xorg.0.log\n   \"\"\n\n$> lspci -k | grep -EA2 'VGA|3D'  \n00:02.0 VGA compatible controller: Intel Corporation 4th Gen Core Processor Integrated Graphics Controller (rev 06)\n    Subsystem: CLEVO/KAPOK Computer Device 0170\n    Kernel driver in use: i915\n--\n01:00.0 3D controller: NVIDIA Corporation GM107M [GeForce GTX 960M] (rev a2)\n    Subsystem: CLEVO/KAPOK Computer Device 0170\n03:00.0 Network controller: Intel Corporation Wireless 7265 (rev 59)\n\nIf anybody wonders - I installed nvidia-settings separately.\n\nA: Open a terminal and execute :  \nlspci -k | grep -EA2 'VGA|3D'  \n\nThe output shows something like :  \n00:02.0 VGA compatible controller: Intel Corporation 4th Gen Core Processor Integrated Graphics Controller (rev 06)\nSubsystem: CLEVO/KAPOK Computer Device 3501\nKernel driver in use: i915\n\n01:00.0 3D controller: NVIDIA Corporation GM107M [GeForce GTX 860M] (rev a2)\nSubsystem: CLEVO/KAPOK Computer Device 3501\nKernel driver in use: nvidia\n\nNow you can see that the NVIDIA drivers are in use -> Kernel driver in use: nvidia\nTo uninstall the drivers execute :  \nsudo apt-get purge nvidia*  \nsudo reboot  \n\nThis removes the nvidia-settings application as well.\n", "Q: How and where to add certificates for citrix receiver I have an ubuntu box running 14.04 LTS and provided to me by my employer. Now in the corporate world everything is under a firewall. I have managed to install Citrix receiver on my ubuntu machine as described in the official guide. My employer has provided me 3 more certificates with a .cer extension. However I have no clue how and where to add these. Please help! \n\nA: Test it, please. (It is add all certificate from Mozilla, to Citrix).\n\nsudo ln -s /usr/share/ca-certificates/mozilla/*   /opt/Citrix/ICAClient/keystore/cacerts\n\nIt's working.\n", "Q: Why is kill command not working on Openshot? I am using OpenShot version 1.4.3 in Ubuntu 14.04 (64 bit).\nHere is my system details:\nlsb_release -a:\n    Distributor ID: Ubuntu\n    Description:    Ubuntu 14.04.4 LTS\n    Release:    14.04\n    Codename:   trusty\n\nuname -a:\n    Linux 4.2.0-30-generic #36~14.04.1-Ubuntu SMP\n    Fri Feb 26 18:49:23 UTC 2016\n    x86_64 x86_64 x86_64 GNU/Linux\n\nI opened openshot to edit my videos on Ubuntu 14.04. \nbut when I tried to close it using kill(also tried pkill) command nothing happened. All other installed applications working properly as expected while trying to close them with kill command.\nI even tried kill with sudo, but no use. \n\n\n*\n\n*Why is kill not working on Openshot?\n\n*Is there any known bug is behind this problem in Ubuntu's Openshot implementation?\nUPDATE :\nAs someone mentioned in comment , kill -9 is working properly.\nbut why not  kill is not working ?\nSomebody may think it as a duplicate for kill and kill -9 commands.\n But my question is not about how to kill openshot. \nMy question is why is kill not working for openshot on Ubuntu?.\nSo please ensure before marking my this as duplicate.\nIn particular, why is OpenShots not working properly with kill? Is its implementation itself is like that or because of any bug?\n\n\nA: When this happens, use the \"show no mercy\" option for kill:\nkill -9 5772\n\nWhere 5772 is the pid of the application you want to kill. \nOr you can kill by process name with:\npkill openshot\n\nOr a slightly more complicated way of doing it. Find the pid and kill it in one line\npidof openshot | xargs kill -9 \n\n\nA: kill sends a signal to the target process. Process can catch signals and handle them, except for the SIGKILL and SIGSTOP signals. If a process gets a signal which it is not prepared to handle, it dies. If it handles the signal, there is no guarantee that the process will die - it can do whatever it wants to. In other words, a simple kill <pid> is not guaranteed to kill the process.\nIn this case, OpenShot may be handling SIGTERM, the default signal that kill sends. Since SIGKILL cannot be handled, with kill -9 (which is the same as kill -KILL or kill -SIGKILL), OpenShot is terminated.\nHowever, where possible, kill -9 should not be used. It gives the process no opportunity to clean up, so it may result in data loss/corruption. Try a plain kill first, and if it doesn't die after a reasonable interval, only then try kill -9/kill -KILL.\n", "Q: line-height problem when using ž character If I write a line containgin ž in konsole or kwrite, the line height gets messed up. Is the default font broken, or is it the apps? Didn't know where to report the bug, so \"ask ubuntu\" sounded as a good start.\nHow to reproduce:\n\n\n*\n\n*Open kwrite, kate or console\n\n*Write __\n\n*Then add a ž on the same line so you now have __ž\nExpected behavior:\n\n\n*\n\n*The other chars should stay the same when I add a ž\n\n\nCurrent behavior:\n\n\n*\n\n*The __ is no longer visible, guess all text get their lowest pixels removed, the _ char only have lower pixels, so easier to spot there.\n\n\nIn konsole, the cursor position make some differences, think it draws the text in 3 parts: before, on, and after cursor, so only the parts that include the ž char gets the error, if you wirte __ž__ and put the cursor on the ž char, you can see the __, but if you write __ž__ž__ you can see the 3 different parts acting.\nScreenshoots as requested, first from Konsole: \n\nIn the screenshoo i first wrote: __ž__ž__\nand then just moving the curser between the 4 screenshoots.\nScreenshoot from kwrite:\n\nSubmitted bug-report:\nhttps://bugs.launchpad.net/ubuntu/+source/oxygen-fonts/+bug/1594848\n\nA: I'm able to reproduce same  issue on Kubuntu 15.10 (VBox). It is a font problem. It happen with \"Oxygen Mono\", it doesn't with \"Ubuntu Mono\" & \"Deja Vu Mono\".\n\n\n*\n\n*Find the corresponding font file\n$ fc-match \"Oxygen Mono\"\nOxygenMono-Regular.ttf: \"Oxygen Mono\" \"Regular\"\n\n\n*Find the source package and the full path\n$ dpkg -S OxygenMono-Regular.ttf\nfonts-oxygen: /usr/share/fonts/truetype/oxygen/OxygenMono-Regular.ttf\n\n\n*Collect info\nubuntu-bug /usr/share/fonts/truetype/oxygen/OxygenMono-Regular.ttf\n\nThen send (It will open a link in the browser)\n\n*Complete Lauchpad bug report and submit\nIf things get slow, You may submit another report to upstream project KDE. Just update both reports to include the links to each others.\nHere a command to show package info including the upstream link...\n$ apt-cache show fonts-oxygen\nPackage: fonts-oxygen\n...\nMaintainer: Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>\nOriginal-Maintainer: Debian/Kubuntu Qt/KDE Maintainers <debian-qt-kde@lists.debian.org>\n...\nSource: oxygen-fonts\nVersion: 4:5.4.3-0ubuntu1\n...\nHomepage: https://projects.kde.org/projects/kde/workspace/oxygen-fonts\nBugs: https://bugs.launchpad.net/ubuntu/+filebug\nOrigin: Ubuntu\nSupported: 3y\n...\n\n", "Q: Landscape LDS - Remove Computer(s) I have an installation of Landscape LDS 15.11 on 14.04 and have a couple of computers that I would like to remove. I have tried 'Remove computer' from within the computer properties but nothing happens. I have also removed the license and then tried to 'Remove computer' and same result.\nHas anyone else experienced this issue or have a workaround for it?\n\nA: Turns out that I had an issue with RabbitMQ. The landscape-appserver was unable to authenticate to RabbitMQ. Once I resolved this, I was able to remove the machines without issue.\n\nA: According to Landscape docs, you should do these tasks:\n\n\n*\n\n*Remove the landscape-client package from the registered machine (did you do this? you didn't mention in your question.)\n\n*In Landscape, select the machine(s) you want to remove and click on \"Info\", so that you get to the info page\n\n*There, just below the comment box, is a link called \"Remove this computer...\". Click on it and confirm the action \n\n\nA: From what I found :\ncd /var/log/rabbitmq/\ntail -f rabbit@landscape.log (or different name perhaps on your server)\n\nCheck the error message:\n*=ERROR REPORT==== 11-May-2018::12:04:32 ===\nclosing AMQP connection <0.2798.0> (127.0.0.1:53570 -> 127.0.0.1:5672):\n{handshake_error,starting,0,\n                 {amqp_error,access_refused,\n                             \"AMQPLAIN login refused: user 'landscape' - invalid credentials\",\n                             'connection.start_ok'}}*\n\nIf this is the problem follow these instructions: \nless /opt/canonical/landscape/configs/standalone/service.conf\n\nCheck section [broker]\nCopy the password string part after the b64:\nUse base64 decoder (here's an online one) or you can use\nbase64 -d <<< \"paste the coded string here\"\n\nExecute the command \nrabbitmqctl change_password <user> <password>\n\nCheck rabbitmq logfile again and check if computer is removed\nHope this helps!\n", "Q: Can't try Ubuntu via a USB drive I wanted to install Ubuntu as a dual boot OS next to Windows 10. Thus I installed it on a USB drive and wanted to use the try feature beforehand. Sadly as soon as I choose this option my PC starts booting up to 15% then jumps to the Ubuntu start screen with the five dots and usually justs stops at some point and gets stuck. In some other cases I just get thrown right back to the grub menu after some time. As how to get it running, I am somewhat unsure. Any suggestions are appreciated.\nI tried it with the Ubuntu LTS version as well Ubuntu 15.10 version and failed both times. I'm doing it on a Schenker XMG A704 laptop, if that's any help. If you need some error messages or something in order to help me out, please let me know how to create these, since every-time this happens I just get thrown back to the menu as if nothing happened or I have to soft reset my laptop in order to boot again.. I am happy to provide any details needed\nThanks in advance,\nJohn\n(BTW I searched the existing questions, but didn't find something relating to this. If your search skills are better than mine, please don't hesitate to refer to your findings.)\n\nA: I have exactly the same machine - a CLEVO based SCHENKER XMG A704 - this is how it works :  \nFirst disable hibernation in Windows - open command prompt as administrator and execute :  \npowercfg /h off.  \n\nAlso disable Fast startup in Windows -> open Windows Control Panel (old version) -> Power Settings and uncheck Fast startup. In case that it is not visible, enable show hidden settings.\nShutdown the notebook completely, do NOT reboot it (otherwise it always starts Windows).\nBoot from the Ubuntu installation media you created and select Try Ubuntu without installing.\nPress the E key and add the parameter nouveau.modeset=0 at the end of the linux line.\nPress the F10 key to boot into the Ubuntu Live desktop - start the installation of Ubuntu.  \nAfter it is  finished, boot the installed Ubuntu system and select the Ubuntu GRUB menu entry.\nPress the E key and add the parameter nouveau.modeset=0 at the end of the linux line.\nPress the F10 key to boot into the Ubuntu system and first of all install the NVIDIA drivers.  \nReboot the Ubuntu operating system ... now you don't have to add the parameter any more.  \nNote : Set a Space between the last character in the linux line and nouveau.modeset=0 !\nAfter having installed the Ubuntu system, you have to select Ubuntu as the default system to boot in BIOS/UEFI settings. You can select to boot Windows from the GRUB menu afterwards. \n", "Q: GLEW from apt-get have no include files enviroment info:ubuntu 14.04 LTS\nI just sudo apt-get install glew-utils. But when I find / -name \"*glew*\" I got someting like this:\n/usr/share/doc/libglewmx1.10\n/usr/share/doc/glew-utils\n/usr/share/doc/libglew1.10\n/usr/bin/glewinfo\n\nBut the expected /include and /lib is missed!\nThe apt-get have some error with something I don't know, which is called cups here. And dpkg seams to be blocked by this cups. Is my assumption right? And how to fix it?\nndn-07@ndn07-desktop:~$ sudo apt-get install glew-utils \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nglew-utils is already the newest version.\n0 upgraded, 0 newly installed, 0 to remove and 1293 not upgraded.\n3 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nDo you want to continue? [Y/n] y\nSetting up cups-daemon (2.0.2-1ubuntu3.2) ...\nAppArmor parser error for /etc/apparmor.d/usr.sbin.cupsd in /etc/apparmor.d/usr.sbin.cupsd at line 145: syntax error, unexpected TOK_CONDLISTID, expecting TOK_MODE\nupdate-rc.d: warning: default stop runlevel arguments (0 1 6) do not match cups Default-Stop values (1)\n/usr/sbin/invoke-rc.d: 1: /usr/sbin/invoke-rc.d: /sbin/runlevel: not found\nstart: Job failed to start\ninvoke-rc.d: initscript cups, action \"start\" failed.\ndpkg: error processing package cups-daemon (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of cups-core-drivers:\n cups-core-drivers depends on cups-daemon (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-daemon is not configured yet.\n\ndpkg: error processing package cups-core-drivers (--configure):\n dependency problems - leaving unconfigured\nNo apport report written because the error message indicates its a followup error from a previous failure.\n                                                                                                          dpkg: dependency problems prevent configuration of cups:\n cups depends on cups-core-drivers (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-core-drivers is not configured yet.\n cups depends on cups-daemon (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-daemon is not configured yet.\n\ndpkg: error processing package cups (--configure):\n dependency problems - leaving unconfigured\nNo apport report written because the error message indicates its a followup error from a previous failure.\n                                                                                                          E: Sub-process /usr/bin/dpkg returned an error code (1)\n\n====================\nsomething error when update & upgrade might have relation to this problem:\n====================  update\nHit http://mirrors.163.com vivid-backports/main Translation-en\nHit http://mirrors.163.com vivid-backports/multiverse Translation-en\nHit http://mirrors.163.com vivid-backports/restricted Translation-en\nHit http://mirrors.163.com vivid-backports/universe Translation-en\nFetched 7,962 kB in 2min 46s (47.8 kB/s)\nW: Failed to fetch bzip2:/var/lib/apt/lists/partial/mirrors.163.com_ubuntu_dists_vivid-security_main_i18n_Translation-en  Hash Sum mismatch\n\nW: Failed to fetch bzip2:/var/lib/apt/lists/partial/mirrors.163.com_ubuntu_dists_vivid-updates_universe_binary-amd64_Packages  Hash Sum mismatch\n\nW: Failed to fetch bzip2:/var/lib/apt/lists/partial/mirrors.163.com_ubuntu_dists_vivid-updates_main_binary-i386_Packages  Hash Sum mismatch\n\nE: Some index files failed to download. They have been ignored, or old ones used instead.\n\n================= upgrade\n xul-ext-ubufox xul-ext-unity xul-ext-webaccounts\n  xul-ext-websites-integration yelp yelp-xsl zeitgeist zeitgeist-core\n  zeitgeist-datahub zenity zenity-common zlib1g\n963 upgraded, 0 newly installed, 0 to remove and 330 not upgraded.\n3 not fully installed or removed.\nNeed to get 331 kB/363 MB of archives.\nAfter this operation, 94.6 MB of additional disk space will be used.\nDo you want to continue? [Y/n] y\nGet:1 http://mirrors.163.com/ubuntu/ vivid/main libasound2 amd64 1.0.28-1 [331 kB]\nFetched 374 kB in 0s (1,715 kB/s)  \nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: You may want to run apt-get update to correct these problems\nE: Failed to fetch http://mirrors.163.com/ubuntu/pool/main/a/alsa-lib/libasound2_1.0.28-1_amd64.deb  Size mismatch\n\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n\n=============== apt-get install -f\n xserver-common xserver-xorg-input-all xserver-xorg-video-all xterm\n  xul-ext-ubufox xul-ext-unity xul-ext-webaccounts\n  xul-ext-websites-integration yelp yelp-xsl zeitgeist zeitgeist-core\n  zeitgeist-datahub zenity zenity-common zlib1g\n963 upgraded, 0 newly installed, 0 to remove and 330 not upgraded.\n3 not fully installed or removed.\nNeed to get 331 kB/363 MB of archives.\nAfter this operation, 94.6 MB of additional disk space will be used.\nDo you want to continue? [Y/n] y\nGet:1 http://mirrors.163.com/ubuntu/ vivid/main libasound2 amd64 1.0.28-1 [331 kB]\nFetched 374 kB in 0s (1,715 kB/s)  \nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: You may want to run apt-get update to correct these problems\nE: Failed to fetch http://mirrors.163.com/ubuntu/pool/main/a/alsa-lib/libasound2_1.0.28-1_amd64.deb  Size mismatch\n\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\nndn-07@ndn07-desktop:~$ sudo apt-get install -f\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\n0 upgraded, 0 newly installed, 0 to remove and 1293 not upgraded.\n3 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nSetting up cups-daemon (2.0.2-1ubuntu3.2) ...\nAppArmor parser error for /etc/apparmor.d/usr.sbin.cupsd in /etc/apparmor.d/usr.sbin.cupsd at line 145: syntax error, unexpected TOK_CONDLISTID, expecting TOK_MODE\nupdate-rc.d: warning: default stop runlevel arguments (0 1 6) do not match cups Default-Stop values (1)\n/usr/sbin/invoke-rc.d: 1: /usr/sbin/invoke-rc.d: /sbin/runlevel: not found\nstart: Job failed to start\ninvoke-rc.d: initscript cups, action \"start\" failed.\ndpkg: error processing package cups-daemon (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of cups-core-drivers:\n cups-core-drivers depends on cups-daemon (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-daemon is not configured yet.\n\ndpkg: error processing package cups-core-drivers (--configure):\n dependency problems - leaving unconfigured\nNo apport report written because the error message indicates its a followup error from a previous failure.\n                                                                                                          dpkg: dependency problems prevent configuration of cups:\n cups depends on cups-core-drivers (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-core-drivers is not configured yet.\n cups depends on cups-daemon (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-daemon is not configured yet.\n\ndpkg: error processing package cups (--configure):\n dependency problems - leaving unconfigured\nNo apport report written because the error message indicates its a followup error from a previous failure.\n                                                                                                          Errors were encountered while processing:\n cups-daemon\n cups-core-drivers\n cups\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n============== after clean apt list\n  xul-ext-ubufox xul-ext-unity xul-ext-webaccounts\n  xul-ext-websites-integration yelp yelp-xsl zeitgeist zeitgeist-core\n  zeitgeist-datahub zenity zenity-common zlib1g\n963 upgraded, 0 newly installed, 0 to remove and 330 not upgraded.\n3 not fully installed or removed.\nNeed to get 331 kB/363 MB of archives.\nAfter this operation, 94.6 MB of additional disk space will be used.\nDo you want to continue? [Y/n] y\nGet:1 http://mirrors.163.com/ubuntu/ vivid/main libasound2 amd64 1.0.28-1 [331 kB]\nFetched 374 kB in 0s (973 kB/s)    \nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: Unknown Multi-Arch type 'no' for package 'compiz-core'\nW: Unknown Multi-Arch type 'no' for package 'compiz-gnome'\nW: You may want to run apt-get update to correct these problems\nE: Failed to fetch http://mirrors.163.com/ubuntu/pool/main/a/alsa-lib/libasound2_1.0.28-1_amd64.deb  Size mismatch\n\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\nndn-07@ndn07-desktop:~$ sudo apt-get install -f\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\n0 upgraded, 0 newly installed, 0 to remove and 1293 not upgraded.\n3 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nSetting up cups-daemon (2.0.2-1ubuntu3.2) ...\nAppArmor parser error for /etc/apparmor.d/usr.sbin.cupsd in /etc/apparmor.d/usr.sbin.cupsd at line 145: syntax error, unexpected TOK_CONDLISTID, expecting TOK_MODE\nupdate-rc.d: warning: default stop runlevel arguments (0 1 6) do not match cups Default-Stop values (1)\n/usr/sbin/invoke-rc.d: 1: /usr/sbin/invoke-rc.d: /sbin/runlevel: not found\nstart: Job failed to start\ninvoke-rc.d: initscript cups, action \"start\" failed.\ndpkg: error processing package cups-daemon (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of cups-core-drivers:\n cups-core-drivers depends on cups-daemon (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-daemon is not configured yet.\n\ndpkg: error processing package cups-core-drivers (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of cups:\n cups depends on cups-core-drivers (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-core-drivers is not configured yet.\n cups depends on cups-daemon (>= 2.0.2-1ubuntu3.2); however:\n  Package cups-daemon is not configured yet.\n\ndpkg: error processing package cups (--configure):\n dependency problems - leaving unconfigured\nNo apport report written because the error message indicates its a followup error from a previous failure.\n                                                                                                          No apport report written because the error message indicates its a followup error from a previous failure.\n                                                     E: Sub-process /usr/bin/dpkg returned an error code (1)\nndn-07@ndn07-desktop:~$ sudo apt-get install glew-utils \n\n\nA: I don't know why you're expecting it to install anything into those directories. But what you're seeing is correct, there is nothing wrong with the package.\nThe package provides the following files:  \n/usr/bin/glewinfo  \n/usr/bin/visualinfo  \n/usr/share/doc/glew-utils/README.txt  \n/usr/share/doc/glew-utils/TODO.txt  \n/usr/share/doc/glew-utils/changelog.Debian.gz  \n/usr/share/doc/glew-utils/copyright\n\nSource: http://packages.ubuntu.com/trusty/amd64/glew-utils/filelist\n", "Q: Why doesn't ls combined with awk show exact sizes? I am trying to find the size of the files on my hard drive in exact bytes, but whenever the size gets too big the number turns all weird (like 1.98329e+12). Can I stop it from doing this or convert this into exact bytes?\nThe command is:\nls -lR | grep -v '^d' | awk '{total += $5} END {print \"Total:\", total}'\n\nPicture of exact bytes:\n\nPicture of weird number:\n\n\n\n*\n\n*The cut-off point before it stops showing exact bytes seems to be around 500gb\n\n*The command du -sb properly shows exact bytes no matter how big the directory is.\n\n*I have tried Ubuntu Gnome 15.10 64bit (Japanese and English) and Linux Mint 17.3 Cinnamon 64bit (Japanese)\n\n*My drives are ntfs so I tried formatting one as ext4 and copying my files over. The results are same as ntfs.\n\n\nA: The problem is that MAWK (the AWK variant installed on Ubuntu) by default prints integers bigger than 2147483647 (231-1) in scientific notation:\n% awk -W version\nmawk 1.3.3 Nov 1996, Copyright (C) Michael D. Brennan\n\ncompiled limits:\nmax NF             32767\nsprintf buffer      2040\n% printf '2147483647\\n' | awk '{x += $1; print x}'\n2147483647\n% printf '2147483648\\n' | awk '{x += $1; print x}'\n2.14748e+09\n\nYou could use printf with a format specifer instead of print*:\nprintf '2147483648\\n' | awk '{x += $1; printf \"%.0f\\n\", x}'\n\n% printf '2147483648\\n' | awk '{x += $1; printf \"%.0f\\n\", x}'\n2147483648\n\nIn your case:\nls -lR | grep -v '^d' | awk '{total += $5} END {printf \"Total:%.0f\\n\", total}'\n\nls -lR |\n    grep -v '^d' |\n    awk '\n        {\n            total += $5\n        }\n        END {\n            printf \"Total:%.0f\\n\", total\n        }\n    '\n\nThat will force AWK to print total in decimal notation instead of in scientific notation.\nHowever, on another note, you should never parse ls.\nA more sensitive way to do that would be using find + stat:\nfind . -type f -exec stat -c '%s' {} + | awk '{total += $1} END {printf \"Total:%.0f\\n\", total}'\n\nfind . -type f -exec stat -c '%s' {} + |\n    awk '\n        {\n            total += $1\n        }\n        END {\n            printf \"Total:%.0f\\n\", total\n        }\n    '\n\n\n*%.0f is a trick to make printf print numbers bigger than 2147483647 (231-1), which when using %d as the format specifier would always print as 2147483647. The limit of %.0f is that one will start losing precision after 9007199254740992 (253), if that's ever a concern (thanks to Rotsor for the useful information).\n\nA: TL;DR: ls and awk are unnecessary for your purpose. Use du -cb or du -bs on the directory that you want to analyse. \nYour purpose is to \n\n\n*\n\n*Find all files\n\n*find their size (in bytes)\n\n*produce grand total for all of them\n\n\nAll these actions can be performed by du. \n$ du -bs $HOME 2>/dev/null                                                                 \n76709521942 /home/xieerqi\n\nIt's worth noticing that du has two \"modes\" - it can either show how much file is in size OR how much actual disk space it takes up (the real , physical real-estate). Since you are interested in total size of all files, you want the apparent file size. -b flag gives exactly that  ( -b is alias for --apparent-size --block-size=1 ).\nPerhaps even more concise and appropriate solution would be to use du -bc directly on the directory you want. For instance, my home directory is about 76 GB in size \n$ du -bc $HOME 2> /dev/null  | tail -1                    \n76694582570 total\n\nFor some reason you worry about difference in folder size and file size.You said in the comments:\n\nI would prefer ls because directory sizes vary while file sizes are\n  constant\n\ndu is recursive, and sums up the file sizes. Also, a directory does have a static size of 4096 bytes ( 4k ) , but with du it will be included in the result of du -bs directory_name . Consider this:\n$ du -b suse/openSUSE-Leap-42.1-DVD-x86_64.iso                                             \n4648337408  suse/openSUSE-Leap-42.1-DVD-x86_64.iso\n\n$ du -b suse/                                                                              \n4648341504  suse/\n\n$ bc <<< \"4648337408+4096\" \n4648341504\n\n$ mkdir suse/another_dir  \n\n$ du -b suse/another_dir                                                                   \n4096    suse/another_dir\n\n$ du -bs suse/                                                                             \n4648345600  suse/\n\n\nA: Under the hood, awk does all calculations using double-precision floating point numbers.  By default it prints them using printf(3) format specifier %.6g, which means that if the number is more than six digits wide it will switch over to E-notation, which is what you saw.  You can work around this by setting the variable OFMT:\nls -lR |\n    awk 'BEGIN { OFMT = \"%d\" }  \n         /^-/  { total += $5 } \n         END   { print \"Total:\", total }'\n\nBut there is an upper limit, beyond which it can't give you an exact number of bytes; it will start rounding off the low bits of the sum.  500 gigabytes = 500 * 1024 * 1024 * 1024 = 536870912000 &approx; 239.  With the usual IEEE floating point, this is safely below that limit (which is roughly 252).  However, it is large enough that I personally would feel better using a programming language that had proper \"bignums\" (unlimited-size integers).  For instance, Python:\n#! /usr/bin/python\nimport os\nimport sys\n\nspace = 0L  # L means \"long\" - not necessary in Python 3\nfor subdir, dirs, files in os.walk(sys.argv[1]):\n    for f in files:\n        space += os.lstat(os.path.join(subdir, f)).st_size\n\nsys.stdout.write(\"Total: {:d}\\n\".format(space))\n\nThis is also completely immune to problems with files with unusual characters in their names.  And it counts space consumed by hidden files.\nThis computes the number of bytes visible in each file, which is the same as what ls -l prints. If you want number of bytes actually occupied on disk instead (what du prints), replace .st_size with .st_blocks * 512.  (Yes, the multiplier is always 512, even if st_blksize is a different number.)\n\nA: What you see here is a way to display large numbers. For example:\n1.23e+3 = 1.23*10^3 = 1230\n\nAs far as I know, you cannot turn this off, but as you wrote in your question, du does behave differently, so I would recommend to use this. Otherwise, you would have to convert the numbers.\n", "Q: Grub console at boot if pen drive not plugged in I installed Ubuntu 14.04 LTS using a bootable USB pen drive, creating a dual boot with Windows 10. Windows and the EFI partition are on a disk, Ubuntu and its swap partition are on another disk. During the installation I chose as destination for Ubuntu's bootloader the EFI partition (I also tried in a precedent installation to choose not the EFI partition, sda2, but the whole sda disk, resulting however in the following problem).\nAfter the installation, if I try to boot without the pen drive plugged in, the Grub console comes up and I can't go on. The only way I can boot normally is plugging in the pen drive, in this way the OS selection screen in showed and I can go in with the boot.\nI tried executing the boot-repair tool, both from the installed version of Ubuntu and from the Live USB, it goes up to the end normally and says that the boot procedure has been repaired but if the I try to boot without the pen drive plugged in, Grub comes up again.\n\nA: Yours is a common problem, and your question is a duplicate, although I've been unable to find a relevant duplicate through a web search.\nUbuntu installs GRUB in EFI mode in a crazy way, with parts scattered across two partitions:\n\n\n*\n\n*The EFI System Partition (ESP) holds the grubx64.efi binary and one or two other related files. In your case, this is on the hard disk.\n\n*The GRUB configuration file is stored in the Ubuntu /boot directory, which in your case is on the USB flash drive. The GRUB configuration file defines the boot menu you normally see, so if it's inaccessible, you get an unhelpful grub> prompt (or something similar).\n\n\nThere are a number of solutions, including:\n\n\n*\n\n*Create a /boot partition on your internal disk -- This will put all the critical GRUB files there, so GRUB will continue to work.\n\n*Install another boot manager, such as my rEFInd boot manager -- rEFInd doesn't rely on cross-partition configuration files for basic functionality, so if you install it to your internal disk's ESP and make rEFInd the default, you'll be able to boot Windows when the USB drive is unplugged or either OS when the USB drive is plugged in. With the right options set in /boot/efi/EFI/refind/refind.conf, you'll be able to boot straight to Windows when the USB drive is unplugged and straight to Ubuntu when the USB drive is plugged in.\n\n*Install a customized GRUB -- It's possible to configure GRUB to rely on a configuration file on the ESP rather than in /boot. This requires considerable expertise to set up. See this page for some coverage of this topic. (Note that the page includes a notice that it's outdated and to refer to another page, but the newer page lacks the relevant details.)\n\n*Rely on the computer's built-in boot manager -- Usually, hitting Esc, Enter, F8, or some other function key brings up a boot manager that will let you select between Ubuntu and Windows. You can use this to control the boot process and bypass GRUB when the USB drive is unplugged.\n\n\nEDIT:* I've just filed a bug report about this problem:\nhttps://bugs.launchpad.net/ubuntu/+source/grub2/+bug/1567534\n", "Q: DESKTOP COLOR FIX when yellow how to fix colors on desktop? Monitor buttons didn't affect it. And looks all yellow, no white colors anymore.\n\nA: Usually that is a problem with your monitor cable, not with the OS. Check to make sure your monitor cable is securely plugged in.  If you are using a desktop computer, try using a different cable to connect your monitor to the computer.\n\nA: Check your VGA/HDMI cable to see if it's plugged in and/or screwed properly, both at the CPU end and on the monitor's end. You can try interchanging the sides of the cable, putting the ends vice versa.\nIf that doesn't work, you might need to replace your cable. However, before doing that, try switching with another cable from another computer to see if the problem is with the cable's connections, or with either the CPU or Monitor port on which it connects.\n", "Q: Software center not showing installed programs First time running Ubuntu 14.04 LTS. When I open Software Centre and click on Installed, it just shows a blank page, nothing comes up, but I have installed programs. Any ideas?\n\nA: Press CtrlAltT and type: \nsudo apt-get update\nsudo apt-get install --reinstall software-center\n\n\nA: \nI found some possible solutions here I believe:\nUbuntu Software Center Issues\n\nBasically it gives some commands to fix any possible broken packages and install necessary library files:\n    $ sudo apt-get autoclean \n    $ sudo apt-get autoremove\n    $ sudo apt-get --purge remove\n    $ sudo apt-get -f install\n\nSoftware Center Troubleshoot \nIf that doesn't work you can uninstall and purge the software center and re-install it.\nsudo apt-get update \n sudo apt-get remove --purge software-center\nsudo apt-get install software-center\n\nHope this helps, \nSubutai\n", "Q: Span Wallpaper Across Displays in Lockscreen In the Appearance tool, we have the option to span a wallpaper across multiple displays. \nOn the Desktop it works fine:\n\nHowever, on the lock screen I see the same image repeated three times:\n\nHow do I span the wallpaper across displays on the lock screen? I don't see any option to do so in the appearance menu.\n\nA: At this time this is not possible due to bug #1291359. \nThis issue is still present up to Ubuntu 16.04. \nThe most common thing to do at this moment is to show the default login screen/color. \nYou can do this by installing dconf Editor.\nOpen a terminal with Ctrl+Alt+T and type:\nsudo apt install dconf-editor\n\nor click dconf Editor  to auto-open Software Center and click Install to install it.\nNow we must grant LightDM permissions to access dconf Editor.\n\n\n*\n\n*Gain root access, type your password (no visual feedback),and Enter.\nsudo -i\n\n*Allow user to create a connection to the X server for lightdm\nxhost +SI:localuser:lightdm\n\n*Switch to user lightdm\nsu lightdm -s /bin/bash\n\n*Start dconf Editor\ndconf-editor\nOn dconf Editor, navigate to com > canonical > unity-greeter in the left pane.\n\n\n*\n\n*Disable (untick) the value for 'draw-user-backgrounds' on the right pane. \n\n*While at it, you may want to disable 'draw-grid' (it disables the dotted grid layer).\n\n\nReboot to confirm changes.  \nsudo reboot\n\nNote: from now on LightDM has permission to access the X server, so every time you open dconf Editor, LightDM already has access.\nTo revoke this access, issue the command xhost -SI:localuser:lightdm as root.\n\nA: Hm. To save you some poking around, I've tried Variety, dconf-editor, nitrogen, and CompizConfig with no luck. The closest I could get was setting a particular wallpaper for just the lock screen with dconf-editor.\nStrangely, if you install gnome-tweak-tool there is a setting under Desktop that allows you to choose a separate mode and image for the Background and Lock Screen - but while the Background settings here affect my desktop, my tests with the Lock Screen settings don't make any change. It may be a lead, however, if you want to try and finagle Unity into submitting to Gnome (assuming the tweak options haven't just been broken from the start).\n", "Q: How to setup OpenVPN provided with OTA10 on Ubuntu Touch? How to setup VPN on Ubuntu Touch?\nI have paid account with NordVPN. I have followed their  tutorials for setting up in different OS's and assembled from there various setting as per screenshot:\n\nIt does not work (connection failed) Firstly, I'm missing a place to add my NordVPN user name and I'm not sure what file to upload as Private Key. The rest of the files are downloaded from NordVPN site: https://nordvpn.com/tutorials/ \nAny help or link to this new great feature will be appreciated. Thanks﻿\n\nA: There is a click-package that provides more configuration-options, including ca-certificate only with username and password.\nBut you still cannot import the ovpn-file. You have to set the options manually in the app.\nGet the latest (0.3.1) click-package here, you can download it directly to the phone:\nhttp://people.canonical.com/~pete/vpn-editor/\nThen install it with this command from the phones terminal app:\npkcon install-local --allow-untrusted ~/Downloads/com.ubuntu.developer.pete-woods.vpn-editor_0.3.1_all.click\n\nVPN-Editor should appear in the App-Scope. There you have a lot more options...\nGood luck.\n\nA: Thank you Luksus. \nusing this vpn-editor everything could be specified. For cyberghost-VPN I mainly took the parameter settings from the file openvpn.ovpn (e.g. Remote server address and portnumber) and I was now also able to specify my username and the password.\n\nThese settings work for me. \n(update march 2017: with OTA 15.04 this does not work any longer in my case, there seems to be a bug. VPN connection failed because there were no valid secrets)\n\nA: I found that Nord do not use a user certificate, so the 'Type' setting for the main openvpn page should be set to 'Password'. After playing around with the other settings, I finally found the correct setup as shown in this set of screeenshots using the uk30 nordVPN server as an example. Note that the Proxies page was left blank as default:\n\nThanks Luksus and pewe20 for your posts which got me started on the right path\n\nA: The click package works fine for me (with pfSense) on BQ Aquaris-M10. I was also missing a option to put in a username and password.\nJust make sure to provide a list with DNS servers to the tablet/phone as this cannot be edited on the mobile device.\n\nA: As I was having the same VPN connection error message as in OP's first comment regarding OTA11 to the original question, I really thought that it was a Nord issue. After some time with Nord support, it turns out that in the server VPN settings for two different servers, I had entered a username incorrectly in one and the password incorrectly in the other. \nDefinitely go back and re-enter your username and password to be sure.\n", "Q: Ubuntu 14.04 completely freezing after logging in when 2 monitors plugged in I came in to work today and logged in to my Ubuntu machine(Dell Optiplex 790).  The entire system froze once the desktop loaded.  If I press CTRL+ALT+F2 doesn't get me into a shell either, so it's like the entire system is locking up.\nI have tried reinstalling ubuntu-desktop along with unity like some have suggested on certain sites, but that did not do the trick.\nI'm really not sure how to track down what is causing the problem, or what would be causing it in the first place.  I don't have a NVidia graphics card or anything like that, and have had a working desktop for over a year.\nWhat steps can I take to find the issue and resolve it?  I'm sure I need to provide more information, I just don't know what or how to get it.\nEdit: I am able to open a guest session without any freezes.  I can also get into the terminal if I don't log in to my user profile through the GUI.  If I CTRL+ALT+F2 at the login screen I can log in to my profile through the terminal.\nThis problem is also only present when 2 monitors are plugged in. Removing the secondary monitor stops the freezes, but I kind of need both of them.\n\nA: Try pressing Ctrl+Alt+F2 straight from your login screen, logging into your user, and typing \nsudo chown -R user:user .\nreplacing user with your username.  It could be that there are some configuration files which have been accidentally taken over by your root user.  If this fails, try creating a new user and see if you can log into the desktop with the new user.\n", "Q: Accidentally created directory named \"~\" (tilde) I managed to make a directory literally named ~.\n(Apparently, Python's os.mkdir('~/something') does this.)\nHow do I remove it without nuking my home?\nAlso, if it helps, I have my real /home on a separate partition. And the duplicate ~ is located in (the real ) ~.\n\nA: Escape the ~ with \\~ or use single quotes '~'.\nso you can \nrmdir ~/\\~\n\nor\ncd ~ ; rmdir '~'\n\n\nA: What python giveth, python taketh away:\n$ python -c 'import os; os.makedirs(\"~/foo\")'; tree; python -c 'import os; os.removedirs(\"~/foo\")'; tree\n.\n└── ~\n    └── foo\n\n2 directories, 0 files\n.\n\n0 directories, 0 files\n\nIf you did os.mkdir, you could undo it with os.rmdir (and similarly for os.makedirs and os.removedirs).\n\nA: You can either escape the directory name using a backslash like this (assuming you're operating in the parent directory of the one you want to delete):\nrmdir \\~\n\nOr you can use relative paths with a dot as the current directory (also when located in the parent directory):\nrmdir ./~\n\nOr you can use the full absolute path:\nrmdir /home/USERNAME/~\n\n\nAnd no worries, rmdir can only remove empty directories. If you accidentally mistype the command and the path would evaluate to your real home directory, it is not in danger because it contains files:\n$ rmdir directory_with_files\nrmdir: failed to remove ‘directory_with_files’: Directory not empty\n\n\nA: find command can do such miracles. The command\nls -i\n\nwill give you inode number of files or directory.\nThen you can use find to delete such files or directory using:\nfind . -inum <inode-number> -delete #for a file\n\nand\nfind . -inum <inode-number> -exec rm -rf {}\\; #for directories\n\n\nA: What should have been done\nYou should have performed home=os.path.expanduser(\"~\") first and then os.path.join(home,\"something\"). The ~ is treated as text in python and doesn't expand like it does in bash or other shells.\n$ python -c 'import os;home=os.path.expanduser(\"~\"); os.mkdir(os.path.join(home,\"something\"))'                                                                                          \n\n$ ls -ld ~/something\ndrwxrwxr-x 2 xieerqi xieerqi 4096 7月  12 21:00 /home/xieerqi/something/\n\nHow to get rid of it\nIn addition to the already mentioned methods, we can use hex value for ~ from the ascii table of characters, which unlike actual ~ doesn't expand to user's home directory on command line (In case you're wondering, when tilde appears at the beginning of a word, it expands to user's home directory. Compare ls ~ and ls $'\\x7e').\nHere's how it would work:\n# Make the directory\n$ mkdir ./~                                                                                                                                                                             \n$ stat ./$'\\x7e'                                                                                                                                                                        \n  File: './~'\n  Size: 4096        Blocks: 8          IO Block: 4096   directory\nDevice: 801h/2049d  Inode: 5768019     Links: 2\nAccess: (0775/drwxrwxr-x)  Uid: ( 1000/ xieerqi)   Gid: ( 1000/ xieerqi)\nAccess: 2017-07-12 21:05:31.382828424 -0600\nModify: 2017-07-12 21:05:31.382828424 -0600\nChange: 2017-07-12 21:05:31.382828424 -0600\n Birth: -\n\n# and remove it \n$ rmdir ./$'\\x7e'                                                                                                                                                                       \n$ ls $'\\x7e'\nls: cannot access '~': No such file or directory\n\n", "Q: Disable key when program is running Duplicate question to How disable key while specific program is running?, which was never answered. (Which option is worse, that I repost the same question, or that I thread necro the old post?)\nAnyway, is there a way to disable specific keys when specific programs are running? Or alternatively, disable Dash when a specific program is running?\n\nA: Simple Solution\nCreate two shortcuts, one for disabling the Super key, and one for restoring it at will.\nGo to System Settings -> Keyboard -> Shortcuts -> Custom , and click + button. Name the new shortcut \"Disable Dash\". The command is\n gsettings set org.compiz.unityshell:/org/compiz/profiles/unity/plugins/unityshell/ show-launcher 'Disabled'\n\nTo create shortcut for re-enabling the script, repeat the above steps, but the command should be\n gsettings set org.compiz.unityshell:/org/compiz/profiles/unity/plugins/unityshell/ show-launcher '<Super>'\n\nA Scripting Solution\nThe script bellow will disable the Super key when program that the user has specified has focus. Note that the user still is able to click the dash icon with the mouse to invoke the Dash. The program name must be single-quoted and exactly the same as appears in Unity Launcher. Multiple windows can be specified in the same format separated by space \n\nFor instance, to disable Super key every time firefox window has focus, the script must be called as  \ndisable_super_key.sh 'Firefox Web Browser'\n\nTo disable both firefox and gnome-terminal do\ndisable_super_key.sh 'Firefox Web Browser' 'Terminal'\n\nHow to get the script\nUsers can either copy the source here or alternatively obtain it from github following the instructions bellow:\n\n\n*\n\n*sudo apt-get install git\n\n*cd /opt ; sudo git clone https://github.com/SergKolo/sergrep.git\n\n*sudo chmod -R +x sergrep\nThe script will be located in /opt/sergrep/disable_super_key.sh\nTo make the script start automatically on every login, refer to How do I start applications automatically on login? . Provide /opt/sergrep/disable_super_key.sh(full path) as the command\nScript Source\n#!/usr/bin/env bash\n#\n###########################################################\n# Author: Serg Kolo , contact: 1047481448@qq.com \n# Date: April 12 , 2016\n# Purpose: Disable super key that brings up Unity Dash\n#          per specific application\n# \n# Written for: https://askubuntu.com/q/754884/295286\n# Tested on: Ubuntu 14.04 LTS\n###########################################################\n# Copyright: Serg Kolo , 2016\n#    \n#     Permission to use, copy, modify, and distribute this software is hereby granted\n#     without fee, provided that  the copyright notice above and this permission statement\n#     appear in all copies.\n#\n#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n#     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n#     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL\n#     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n#     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n#     DEALINGS IN THE SOFTWARE.\n\nARGV0=\"$0\"\nARGC=$#\nenable_dash_key()\n{\n  gsettings set org.compiz.unityshell:/org/compiz/profiles/unity/plugins/unityshell/ show-launcher '<Super>'\n}\n\ndisable_dash_key()\n{\ngsettings set org.compiz.unityshell:/org/compiz/profiles/unity/plugins/unityshell/ show-launcher 'Disabled'\n}\n\n\n\nget_active_app()\n{\n   qdbus org.ayatana.bamf \\\n        /org/ayatana/bamf/matcher \\\n        org.ayatana.bamf.matcher.ActiveApplication\n}\n\nget_active_app_name()\n{\n  qdbus org.ayatana.bamf \\\n   $(get_active_app)   \\\n   org.ayatana.bamf.view.Name\n}\n\ncheck_active_app()\n{\n  active_name=$(get_active_app_name)\n  local is_found\n  for win in  \"${windows_list[@]}\"\n  do\n    if [ \"$active_name\" = \"$win\" ] ; then\n      is_found=true\n      break\n    else\n      is_found=false\n    fi\n  done\n\n  if $is_found ; then\n     disable_dash_key\n  else\n     enable_dash_key\n  fi\n}\n\n\nprint_usage()\n{\ncat << EOF\nCopyright Serg Kolo , 2016\n\nUsage: disable_super_key.sh 'App Name 1' [ 'App Name 2' 'App Name 3' ...  ]\n\nThe script disables the Super key for the specified set of applications\nunder Ubuntu's Unity environment. The list of windows must be space\nseparated, each app name single quoted and exactly as it appears on the\nlauncher (or as it appears in the .desktop file of that app), so spelling\nand spacing matter.\n\nNote that the script only disables the Super key as shortcut for Dash.\nThe user still will be able to invoke Dash by manually clicking on the \nUbuntu icon in the launcher\nEOF\n}\n\nmain()\n{\n\n  if [ $ARGC -eq 0   ]; then\n     print_usage\n     exit\n  fi\n\n  local windows_list\n  windows_list=( \"$@\" )\n  dbus-monitor --profile \"type='signal',member='FocusedWindowChanged'\" |\\\n  while read line\n  do\n     case \"$line\" in\n       *FocusedWindowChanged*) check_active_app ;;\n     esac         \n  done\n}\n\nmain \"$@\"\n\n", "Q: Changing screen resolution on Dell Inspiron I just installed the latest Ubuntu desktop onto a Dell Inspiron 1000 laptop and I cannot change the screen resolution any higher than VGA using the built-in monitor. any help would be appreciated please.\n\nA: I had a problem with setting the resolution higher on my Dell Inspiron 1000 when I was running Lubuntu. My assumption is that by VGA you mean resolution higher than 640x480.\nThe fix I found was to set xforcevesa. Now I have 1024x768, 800x600, and 640x480 on Lubuntu 16.04.\nIf you need help setting xforcevesa see the following.\nHow to set xforcevesa?\nThis is what I found in my research that caused me to try xforcevesa.\nhttp://ubuntuforums.org/showthread.php?t=2162336\n", "Q: WiFI not available after installing TLP on Ubuntu 14.04 This afternoon I installed TLP on my laptop running Ubuntu 14.04.\nAfter the restart my WiFi suddenly stopped working\n_ message: \"Disconnected - you are now offline\"\n- I have a button on my keyboard that turns wifi on/off - now it just stays red and doesn't change (to blue) at all when pressed.\n- In my network indicator now there no option even to turn wifi on/off and its the same in system settings\n\n\n*\n\n*RFKILL LIST ALL gives me:\n\n\nhp-bluetooth: Bluetooth\n        Soft blocked: yes\n        Hard blocked: no\nAnd no wireless mentioned at all.\n\n\n*\n\n*Attempted fixes: (that did not work)\n\n\n*\n\n*Change the following in TLP's configuration:\n\n\n\nWIFI_PWR_ON_BAT=1\nWIFI_PWR_ON_AC=1\n\n\n*sudo service network-manager restart\n\n*I then uninstalled TLP (and purged) - still nothing\n\n*I then uninstalled other things I installed earlier in the day: Weather and calendar indicators, and preload.\n\n\n*\n\n*NOTE: i noted in my software center there was 3 changes in the history that i did not recognise: Removal of : Python3 tz, Python dateutil and python3-dateutil (I do not know what these are signifying)\n\n\n\nI do not know what wireless card I have or how to find that out.\nKindly assist me please\nEDIT:\n\n\n*\n\n*Wireless card: EDIT: found this:  RTL8101/2/6E PCI Express Fast/Gigabit Ethernet controller\n\n*Running the following didnt change anything\n\n\n    sudo add-apt-repository ppa:hanipouspilot/rtlwifi\n    sudo apt-get update\n    sudo apt-get install rtlwifi-new-dkms-linux-firmware\n    sudo apt-get update && sudo apt-get upgrade\nEdit: Seems like my wireless driver has been uninstalled somehow? am I interpreting this correctly?\nsudo lshw -c network\n\nOutput\ndescription: Ethernet interface\n       product: RTL8101/2/6E PCI Express Fast/Gigabit Ethernet controller\n\nNothing saying Wireless interface???\n\nA: I had an issue with my WiFi card when I installed Ubuntu on my older laptop. The same issue with the WiFi being disabled occurred. I found that I had to install necessary WiFi drivers and I found those.\nWorks with my WiFi card listed below:\nsudo add-apt-repository ppa:hanipouspilot/rtlwifi\nsudo apt-get update\nsudo apt-get install rflwifi-new-dkms-linux-firmware\nsudo apt-get update && sudo apt-get upgrade\n\nAlso, as far as looking for your wi-fi card you can find it by typing:\nifconfig\n\nyour wireless card should be under wlan0 if not try:\nsudo lshw -short\n\n(reference)\nThis will display all current hardware including the wireless card which will be under the Class - Network category and have a description similar to something like this:\nAR9285 Wireless Network Adapter (PCI-Express)\n\nAlso, it seems like TLP will heavily configure your settings even overriding some of yours in order to save battery life or so I have read. You can try editing the configuration file by typing:\ngksudo gedit /etc/default/tlp\n\nand search for these settings: WOL_DISABLE=Y and WIFI_PWR_ON_AC=1\nWIFI_PWR_ON_BAT=5\n(reference)\n\nA: I faced the same problem,\nI fixed my problem by\n\nUninstalling TLP and Installing Wireless Drivers\n\nCommand: (to remove tlp) (sorry I have OCD)\nsudo apt-get purge tlp\nsudo apt-get autoremove\nsudo apt-get clean all\nsudo apt-get autoclean\n\nCommand: (to install 802.11 drivers) (I am on Kali rolling and using Wicd network manager)\nsudo apt-get install firmware-brcm80211 firmware-b43-installer firmware-b43legacy-installer broadcom-sta-dkms\n\nif you don't know the repository of Kali: ( Paste this in /etc/apt/souces.list and save )\ndeb http://repo.kali.org/kali kali-rolling main contrib non-free\n\nI also noticed, while installing tlp, the package arping was replaced by iputils-arping. Hence,\nsudo apt-get install arping\n\nRestart Required\nThats it!\n(if this works for you, please upvote so I can get right to answer, comment, upvote, etc)\n", "Q: How to format arp -a output? I'm trying to format arp -a output to my liking. For example at the moment it outputs:\nMyRouter (172.16.3.x) at XX:XX:XX:XX:XX:XX [ether] on eth0\nPC1 (172.16.3.x) at XX:XX:XX:XX:XX:XX [ether] on eth0\nPC2 (172.16.3.x) at XX:XX:XX:XX:XX:XX [ether] on eth0\n\nBut I want it to output something like:\nMyRouter;172.16.3.x;XX:XX:XX:XX:XX:XX\nPC1;172.16.3.x:XX:XX:XX:XX:XX:XX\nPC2;172.16.3.x;XX:XX:XX:XX:XX:XX\n\nIf I echo one of the lines with a BAD sed command that I created, it'll format the output to my liking but I can't use it on an arp -a command\nCommand:\n$ echo \"MyRouter (172.16.3.x) at XX:XX:XX:XX:XX:XX [ether] on eth0\" | sed 's/ (/;/g' | sed 's/) at /;/g' | sed 's/ \\[.*//g'\nMyRouter;172.16.3.x;XX:XX:XX:XX:XX:XX\n\nBut how can I format the arp -a output like this?\n\nA: Give this one sed command version a try:\narp -a | sed 's/^\\([^ ][^ ]*\\) (\\([0-9][0-9.]*[0-9]\\)) at \\([a-fA-F0-9:]*\\)[^a-fA-F0-9:].*$/\\1;\\2;\\3/'\n\n\nA: With awk:\narp -a | awk -F'[ ()]' '{OFS=\";\"; print $1,$3,$6}'\n\nOutput:\n\nMyRouter;172.16.3.x;XX:XX:XX:XX:XX:XX\nPC1;172.16.3.x;XX:XX:XX:XX:XX:XX\nPC2;172.16.3.x;XX:XX:XX:XX:XX:XX\n\n\n-F'[ ()]': sets field separators to whitespace, ( and )\nOFS=\";\": sets Output Field Separator to ;\n", "Q: Using a keyboard shortcut to paste text There are lots of websites which only allow signing in with email address and password and I am tired of typing a long email address. I don't want my browser to remember my email. Can I assign a keyboard shortcut to print this email address so that every time I press the key I get my email address on current text field? \nI am using Ubuntu 14.04 and I have very little knowledge about Ubuntu. I'm not talking about snippets. Just a defined text to paste when the key is pressed. \n\nA: To paste a single string into a textfield\n\n\n*\n\n*install both xdotool and xclip:\nsudo apt-get install xdotool xclip\n\n\n*Add the following command to a shortcut key:\n/bin/bash -c \"sleep 0.5 && printf 'youremail@server.com' | xclip -selection clipboard && xdotool key Control_L+v\"\n\nChoose: System Settings > \"Keyboard\" > \"Shortcuts\" > \"Custom Shortcuts\". Click the \"+\" and add the command above to a key combination of your choice.\nNow when enter the cursor in a textfield and choose your shortcut, it will type your email address.\n\nA: Tested on Ubuntu 20.04.\nSimilar to Jacob’s solution. Here, we will paste the text hello ♥ using the middle mouse click clipboard.\nWe won’t paste the text at the \"| cursor\" as using Ctrl+V but directly under the mouse cursor like when using the middle mouse click. You may replace xsel with xclip.\n\n*\n\n*Install xdotool and xsel:\n\nsudo apt install xdotool xsel\n\n\n\n*Add the following command to a shortcut key:\n\n/bin/bash -c 'echo -n \"hello ♥\" | xsel && xdotool click 2'\n\nNote: We use the clipboard of the middle mouse, so expect it to be erased along with the current selection when using your custom shortcut.\n\nA: As none of suggestions that I found were able to achieve what I wanted, I had to do my own research into the subject. Posting my one-liner below in case if someone ever wants to achieve something similar. Tested on Ubuntu 20.04.1.\nWhat I needed?\nOne-liner that would paste my signature to websites (sounds stupid, I know, but to my surprise there's still no decent way to achieve that with Google Chrome) when I press the set hotkey.\nWhat was wrong with the one-liner from @zatiranyk?\nWhile technically it does achieve what I want, for reason I still don't understand it's not pasting text when clicking the set hotkey.\nPreprequisites\nxdotool and xsel are still going to be required. You can install them like this:\nsudo apt install xdotool xsel\n\nMy version of the one-liner\nbash -c 'echo -e \"SIGNATURE\" | xsel -b && seq 2 | xargs -I -- xdotool key ctrl+shift+v'\n\nIf you bind it to, say, super+v, every time you press super+v it would paste the set text (\"SIGNATURE\").\nHere's a short breakdown of its parts:\n\n*\n\n*echo -e \"SIGNATURE\" -- I'm using -e with echo here because my signature has a few \\n in it\n\n*xsel -b -- this basically tells the shell to copy the input (echo -e \"SIGNATURE\") to the clipboard\n\n*seq 2 -- this exists in order to run the thing that's following it (xargs -I -- xdotool key ctrl+shift+v) twice* (see Observations)\n\n*xdotool key ctrl+shift+v -- xdotool simulates keyboard input, and in this case it's ctrl+shift+v, which's the default hotkey for pasting content from the clipboard\n\nIn other words, what this one liner does is it:\n\n*\n\n*Copies signature to the clipboard\n\n*Forces pressing ctrl+shift+v 2 times to paste the clipboard content\n\nObservations\n\n*\n\n*Why the part xdotool key ctrl+shift+v is executed twice? Similar to the one-liner of @zatiranyk, pressing ctrl+shift+v one time does not do the trick for some reason\n\n\n*For whatever reason similar one-liner with the primary selection instead of the clipboard works 3-4 times out of 10:\n  bash -c 'echo -e \"SIGNATURE\" | xsel && seq 2 | xargs -I -- xdotool click 2'\n\n\n\n*A bit more unga bunga version of the one-liner will work like a charm too:\n  bash -c 'echo -e \"SIGNATURE\" | xsel -b && xdotool key ctrl+shift+v && xdotool key ctrl+shift+v'\n\n", "Q: Installing Win7 SP1, Dual Boot with Ubuntu, using GRUB and not Win Sys Reserved partition So I have a 240SSD 20gb for Ubuntu (Active) with the GRUB bootloader on it. Just root partition, no home, no swap. And I have a 200gb Windows 7 partition (Primary as well but not active). My issue is that since I don't have a system reserved partition for windows 7 and it is also not active, I'm not able to install the SP1 update for it. My question is can I just make it active, install the update then I'm guessing I would have to boot from my USB Live Ubuntu flash drive in order to rebuild/fix GRUB. Is my way of thinking correct? Any help or suggestion would be greatly appreciated. Thanks.\n\nA: So I went ahead and clicked on the Windows 7 partition under Disk management in Win7 environment and set it as Active. I was then able to perform the SP1 update on it. The GRUB2 bootloader was not affected at all and now I'm on Linux Ubuntu with no problem. I think the only thing to denote is that the Active partition now is Win7 instead of Linux. However, the same effect of dual effect still holds. Hence; mission accomplished with no problem. Ty anyways. :)\n", "Q: What is wrong with this control file? At first I was encountering the same error as Error when creating debain source package with dpkg. \nAfter following its answer I am facing this problem\ntata@archisman-HP-240-G3-Notebook-PC ~/brightness-controller $ debuild\ndpkg-buildpackage -rfakeroot -D -us -uc\ndpkg-buildpackage: source package PACKAGE\ndpkg-buildpackage: source version 1.2\ndpkg-buildpackage: source distribution trusty\ndpkg-buildpackage: source changed by Archisman Panigrahi <tata@archisman-HP-240-G3-Notebook-PC>\ndpkg-source --before-build brightness-controller\ndpkg-buildpackage: host architecture amd64\ndpkg-source: warning: unknown information field 'Version' in input data in general section of control info file\ndpkg-source: warning: unknown information field 'Architecture' in input data in general section of control info file\ndpkg-source: error: source package name 'PACKAGE' is illegal: character 'P' not allowed\ndpkg-buildpackage: error: dpkg-source --before-build brightness-controller gave error exit status 255\ndebuild: fatal error at line 1364:\ndpkg-buildpackage -rfakeroot -D -us -uc failed\n\nThe control file is\nSource: brightness-controller\nSection: accessories\nPriority: optional\nMaintainer: Archisman Panigrahi <apandada1@gmail.com>\nVersion: 1.2\nArchitecture: all\nBuild-Depends: python-wxgtk2.8,\n               python,\n               xrandr,\nHomepage: http://lordamit.github.io/Brightness\n\nPackage: brightness-controller\nArchitecture: any\nDepends: python-wxgtk2.8,\n         python,\n         xrandr,\nDescription: Brightness Controller is the only GUI application for Linux that allows you to control brightness \nof your primary and secondary display from the same place. It is a software based dimmer.\nReleased under GPL-3, Brightness Controller's source code is available at\n.\nhttps://github.com/lordamit/Brightness\n.\nIf you encounter any problem you can open an issue in the GitHub project. \n.\nKindly review and let your friends know if this application made your display more friendly to your eyes.\n\n\nA: From the Debian Policy Manual, chapter Control files and their fields:\n\nThe fields in the general paragraph (the first one, for the source\n  package) are:\n  \n  \n*\n  \n*Source (mandatory)\n  \n*Maintainer (mandatory)\n  \n*Uploaders\n  \n*Section (recommended)\n  \n*Priority (recommended)\n  \n*Build-Depends et al\n  \n*Standards-Version (recommended)\n  \n*Homepage\n  \n*Vcs-Browser, Vcs-Git, et al.\n  \n  \n  The fields in the binary package paragraphs are:\n  \n  \n*\n  \n*Package (mandatory)\n  \n*Architecture (mandatory)\n  \n*Section (recommended)\n  \n*Priority (recommended)\n  \n*Essential\n  \n*Depends et al\n  \n*Description (mandatory)\n  \n*Homepage\n  \n*Built-Using\n  \n*Package-Type\n  \n\nClearly, neither Version nor Architecture belongs in the first paragraph (the source package one). Version doesn't belong in debian/control at all. The version is determined from debian/changelog, and only the final package's generated DEBIAN/control will contain Version.\nLooks like some file in debian, probably debian/changelog, isn't properly created. It uses PACKAGE as the package name, where it should be brightness-controller. Package names are always lower-case.\n", "Q: Transfer application files from Linux to iOS device? I want to know if there is any way I could transfer application files(like pdfs to Adobe Reader, videos to Infuse, epubs to Marvin) from my Linux machine to my iPad, preferably wirelessly. I am running Ubuntu on my PC and iOS 9.3.1 on my iPad. I used to able to access and transfer application files between my iPad and Linux till iOS 7(if I remember correctly) via USB cable, but that just stopped working after iOS 8. Is there any way to bring that back or is there a way to do this wirelessly?\n\nA: You can transfer files to and from your iOS device using an app called FileApp:\nhttps://itunes.apple.com/us/app/fileapp-documents-files-reader/id297804694\nFileApp has a \"share files over wifi\" feature with clear instructions on how to transfer files.  To upload files to your device, you can use FileApp's simple web interface.  Use an FTP client like Filezilla (available in the Ubuntu software center) to copy files from your iOS device to your computer.\nEdit: As mentioned in the comments below, once the file is loaded in FileApp, you can copy it to any app that is registered to handle that filetype through the actions menu. For example, video and audio files of most types (even those not normally supported on iOS) can be copied to VLC for Mobile for playback. After you have copied the file to the destination app, you can delete the original from FileApp to free up storage space.\n\nA: Use dropbox, google drive, and the like. These app even allows two-way transfering. For example, you may want to transfer some photos to your computer sometimes.\n", "Q: How to make Xubuntu detect multiple monitor setups correctly? I have an additional monitor at home and at work, but they have different resolutions. That was no problem for Ubuntu. I recently set up a new laptop with Xubuntu, and now the second monitor is always mirrored. I solved it by making a few bash scripts with xrandr commands to set the correct monitor settings. So the first thing I do is running home_screen.sh or office_screen.sh after I boot my system. I also have laptop_only_screen.sh and beamer.sh. It works, but still... Can someone explain the different behaviors of Ubuntu and Xubuntu?\nBy the way, my old laptop had a VGA port, the new one has HDMI. Could that be an explanation for the different behavior instead of switching to Xubuntu?\n\nA: Go to Settings > Display and check the box that says \"Configure new displays when connected\".  Now when you plug a new monitor in, it should pop up a dialog box for selecting the display mode.  If this does not work, check to make sure that you are using the best driver for your graphics card. (Settings > Additional Drivers)\n", "Q: Very Strange - Ubuntu messing up Windows LAN I am helping my friend migrate to Linux from Windows. So we installed Ubuntu 15.10 on his system. His current setup is Windows 10 + Ubuntu. Everything is going well except a very strange issue. Windows can't connect to LAN if Ubuntu used LAN.\nThis is what he does to reproduce the problem:\n\n\n*\n\n*He boots into Windows 10 and shows me that he is able to access internet through his LAN.\n\n*He reboots to linux and connects to internet via LAN.\n\n*He boots back into Windows and suddenly he can't access the LAN.\n\n\nI am very puzzled. How can Ubuntu mess with Windows LAN configuration?\nUpon further investigation, we have observed that:\n\n\n*\n\n*Windows LAN is messed up only if Ubuntu uses LAN. For example, if he used only WiFi in Ubuntu and never connected a LAN cable, there is no problem when he boots back to Windows.\n\n*It affects only LAN and not WiFi in Windows. So he is able to use WiFi in windows even when Ubuntu broke ethernet (LAN).\n\n*He found a temporary fix by following Anish A Kumar's answer (method 2 and 3) in this page.\nI know I have only described the issue here, so ask in the comments for logs  that are required to debug the issue. I would really like to get to the bottom of this.\nHis laptop is a HP Pavilion 15-ab032tx and here is the output of lspci -k and dmesg to start with.\n\nA: Sounds like the Windows driver doesn't agree with the state Linux leaves the LAN hardware. Realtek is known for issues like this.\nTry a echo \"options rtl8723be swenc=1 fwlps=0 ips=0\" | sudo tee /etc/modprobe.d/rtl8723be.conf to make the module work in a more reliable state where Windows might be able to take over again from usage after Linux.\nExplanation:\n\n\n*\n\n*swenc:using hardware crypto (default 0 [hardware])\n\n*ips:using no link power save (default 1 is open)\n\n*fwlps:using linked fw control power save (default 1 is open)\n\n\nTo make the values known to the driver, do\nsudo service network-manager stop\nsudo modprobe -rfv rtl8723be\nsudo modprobe -v rtl8723be\nsudo service network-manager start\n\nbefore you use the LAN.\n", "Q: Why is the Ubuntu-for-Windows default shell a root shell? From day one of using Linux we are told that running as root is extremely dangerous.  Here we are though on day one of introducing Linux to a wider audience by enabling it in Windows 10 we provide the user with root access.  I realize that it is sandboxed from the Windows 10 environment but providing a default root environment to all users (even standard users) is potentially dangerous for any system.  Why would we decide that this is the right course of action with this software?\n\nA: It's because user IDs are one of the several rough edges in this beta test level subsystem.  You are not, in fact, actually a superuser. \nIt just looks that way because the Windows NT Linux subsystem reports it that way to Ubuntu applications through the various system calls.  The parts of the system call layer that deal with user IDs simply say that everything is UID 0.  \nThe Ubuntu program is running with your user process token and you do not have any abilities beyond what you could do with a Win32 program as yourself.\nThis is not the old (Interix) Windows NT POSIX subsystem, with its sophisticated mechanism for mapping Windows SIDs to POSIX UIDs and GIDs.  ☺\nAnd this is in the release notes.\nFurther reading\n\n\n*\n\n*Rich Turner (2016-04-06).  \"Release Notes.\" Bash on Ubuntu on Windows.   MSDN Blogs.  Microsoft.\n\n*Charlie Russel (2004-04-22).  \"Features of Services for Unix: User Name Mapping\" Introduction to Microsoft Windows Services for UNIX 3.5.  TechNet.  Microsoft.\n\n*\"User and Group accounts\" Permissions In Microsoft Services for UNIX v3.0. 2003-05-01.  TechNet.  Microsoft.\n\n", "Q: Ubuntu SSH & HTTPS Connection Issues after OS update So yesterday everything was working great. My Ubuntu 14.04 was updated with linux-image-extra-3.13.0-85.129 update.\nWhen I start the computer this morning, I noticed that I can no longer SSH to my Bitbucket repository, the MySQL Workbench can't connect to remote servers and even web browsers are giving me Request Timeout when connecting to HTTPS.\nI removed and reinstalled openssh-server and still no luck. Not sure where to look. Any ideas?\n\nA: Found a solution here: https://askubuntu.com/a/312183/527841\nMy router MTU was set to 1500. After changing the MTU to 1476, everything was great again.\n", "Q: Watch online videos locally on PC I have seen that you can use VLC player to play online videos locally on your PC. \nThe problem with that, is that it is a function of VLC, so it is player dependent, and it doesn't work on every website. \nSo my question is if there is a program or a command-line utility (like livestreamer but for videos) for Ubuntu that works on every website and on every player (VLC or mpv etc.). I know that it is probably a longshot but I would like to know.  \n\nA: Get kodi then install the add-ons Israel live, genesis Lazarus,  ccloud, and velocity. You have all the tv and movies you can imagine no websites no messy cache etc.\n", "Q: Will the first server be added as one of 5 nodes in OpenStack Autopilot? 1.\nAfter reading the documentation for setting up OpenStack Autopilot,\nI am instructed to install Ubuntu server on the first server.\nBut after going to MAAS GUI to add the other nodes, I don't know how to add the MAAS server (first server) as a node? Nothing concerning this is on the documentation.\nAlso is it still true that the first server (1 of 2) needs to have 2 network ports connected to it?\n2.\nCan I use Ubuntu 16.04 LTS (I know it is just beta 2) for OpenStack Autopilot now or I have to wait till the launch date of April 21st?\n\nA: If you're asking if the MAAS server counts as one of the 5 servers required to use Autopilot, you're correct.\n1. You can't add maas as a node as far as I am aware.  Autopilot is meant to build the stack in an automated way, if you're capable of adding maas, you'll be doing it against the will of autopilot.  Additionally, your landscape server will not be used as a compute node either.  Autopilot does still require 2 servers having 2 network cards.\n2. Openstack Installer 0.99.27 is in 16.04LTS, so you should be able to use it.  If you're building a test enviroment, go for it, but if you plan on taking it into production, I would either use 14.04, or wait for the full release.\n", "Q: Why do all my accounts (on my computer) passwords look the same? Why do all my accounts (on my computer) passwords look the same? You can see it here (I had to post on imgur because I couldn't post the 4 pictures here). The passwords all look the same but are they different?\nI know this isn't that much of a deal but I am curious to why this is happening.\n\nA: It is simply to obfuscate the real password length, see it as a part of a security feature.\n\nA: It's a security measure. If someone were to find your computer logged in, they might open the settings to take a look at your passwords. If they know you rather well, and also know one or two of your passwords, they might be able to guess your password using what they know.\nHowever, since Ubuntu shows all the passwords as being five or six (I can't count similar characters very well) characters long, it takes away the ability to guess the password from the length. \nIt's maybe not the most useful feature, but it's still handy.\n", "Q: Upgrading from 10.04 to 16.04 I have Ubuntu 10.04 and I want to install 16.04.\nI have created a USB using a lot of programs, even the one came with the distro; when I try to install 16.04 the monitor shows all it is supposed to show, but without brightness like it is turned off.\nOnly with a specific boot and a lot of imagination to confuse the system he authorizes me to install Ubuntu.\nMy question is:\nIs it possible to install 16.04 or another version from the desktop from the terminal or something?\nOr this can only be done from outside?\nmia@mia-laptop:~$ lspci -k\n\n00:00.0 Host bridge: Intel Corporation Mobile 4 Series Chipset Memory Controller Hub (rev 09)\n    Kernel driver in use: agpgart-intel\n    Kernel modules: intel-agp\n\n00:02.0 VGA compatible controller: Intel Corporation Mobile 4 Series Chipset Integrated Graphics Controller (rev 09)\n    Kernel driver in use: i915\n    Kernel modules: i915\n\n00:02.1 Display controller: Intel Corporation Mobile 4 Series Chipset Integrated Graphics Controller (rev 09)\n\n00:1a.0 USB Controller: Intel Corporation 82801I (ICH9 Family) USB UHCI Controller #4 (rev 03)\n    Kernel driver in use: uhci_hcd\n\n00:1a.1 USB Controller: Intel Corporation 82801I (ICH9 Family) USB UHCI Controller #5 (rev 03)\n    Kernel driver in use: uhci_hcd\n\n00:1a.7 USB Controller: Intel Corporation 82801I (ICH9 Family) USB2 EHCI Controller #2 (rev 03)\n    Kernel driver in use: ehci_hcd\n\n00:1b.0 Audio device: Intel Corporation 82801I (ICH9 Family) HD Audio Controller (rev 03)\n    Kernel driver in use: HDA Intel\n    Kernel modules: snd-hda-intel\n\n00:1c.0 PCI bridge: Intel Corporation 82801I (ICH9 Family) PCI Express Port 1 (rev 03)\n    Kernel driver in use: pcieport\n    Kernel modules: shpchp\n\n00:1c.1 PCI bridge: Intel Corporation 82801I (ICH9 Family) PCI Express Port 2 (rev 03)\n    Kernel driver in use: pcieport\n    Kernel modules: shpchp\n\n00:1c.2 PCI bridge: Intel Corporation 82801I (ICH9 Family) PCI Express Port 3 (rev 03)\n    Kernel driver in use: pcieport\n    Kernel modules: shpchp\n\n00:1d.0 USB Controller: Intel Corporation 82801I (ICH9 Family) USB UHCI Controller #1 (rev 03)\n    Kernel driver in use: uhci_hcd\n\n00:1d.1 USB Controller: Intel Corporation 82801I (ICH9 Family) USB UHCI Controller #2 (rev 03)\n    Kernel driver in use: uhci_hcd\n\n00:1d.2 USB Controller: Intel Corporation 82801I (ICH9 Family) USB UHCI Controller #3 (rev 03)\n    Kernel driver in use: uhci_hcd\n\n00:1d.3 USB Controller: Intel Corporation 82801I (ICH9 Family) USB UHCI Controller #6 (rev 03)\n    Kernel driver in use: uhci_hcd\n\n00:1d.7 USB Controller: Intel Corporation 82801I (ICH9 Family) USB2 EHCI Controller #1 (rev 03)\n    Kernel driver in use: ehci_hcd\n\n00:1e.0 PCI bridge: Intel Corporation 82801 Mobile PCI Bridge (rev 93)\n\n00:1f.0 ISA bridge: Intel Corporation ICH9M LPC Interface Controller (rev 03)\n    Kernel modules: iTCO_wdt\n\n00:1f.2 IDE interface: Intel Corporation ICH9M/M-E 2 port SATA IDE Controller (rev 03)\n    Kernel driver in use: ata_piix\n\n00:1f.3 SMBus: Intel Corporation 82801I (ICH9 Family) SMBus Controller (rev 03)\n    Kernel modules: i2c-i801\n\n00:1f.5 IDE interface: Intel Corporation ICH9M/M-E 2 port SATA IDE Controller (rev 03)\n    Kernel driver in use: ata_piix\n\n04:00.0 Network controller: Atheros Communications Inc. AR928X Wireless Network Adapter (PCI-Express) (rev 01)\n    Kernel driver in use: ath9k\n    Kernel modules: ath9k\n\n05:00.0 Ethernet controller: Broadcom Corporation NetLink BCM5784M Gigabit Ethernet PCIe (rev 10)\n    Kernel driver in use: tg3\n    Kernel modules: tg3\n\n\nA: As an exercise, can you try install ubuntu 14.04 first? Anyway, AFAIK it is not possible to upgrade directly to 14.04 or 16.04 directly, no matters what. You have to jump want step at a time, first to 12.04, 14.04 and then 16.04. \nRegarding 16.04, if you do not have much experience with Linux and Ubuntu, I would suggest not to try it. It is still not official and may have bugs here and there. You will not know what the problems really are. \nLast but not least, I did not have succeed with any of the bootable USB creator recommended by Canonical. The one I find every easy to use is Yumi (the Windows version). I haven't tried the Linux version http://www.pendrivelinux.com/downloads/YUMI/ubuntu/yumi_0.0.1-1_all.deb\n\nA: I have installed Ubuntu 16 via a key bottable: it is a bad idea, it is highly instable for the moment!\nUbuntu 14 is the most stable for me, or you may try the 15.\nFor answer to your question: for upgrading your version by terminal, you can, see related post:\nUpgrading from the command line?\nBut i offen reinstall ubuntu via USB key, it seems safer to me...\n", "Q: How to prevent users from changing their password to one of the last X passwords? I have an Ubuntu GNOME 15.10 with GNOME 3.18 system which I would like to set up so that the users using it cannot set a new password as one of the previous X passwords, how can this be achieved?\nWhen I change my password, if it is too similar to my last my system does not allow me to change it to that password, it would be good if the answer could also show how to extend this so that the new password can also not be too similar to the previous X recorded passwords.\nNote: The history of the last X passwords should not be stored in an insecure unencrypted manner, in fact they should probably be stored in the same or similar way to the way in which the current password is stored (as a salted hash).\nI have used X to represent the number of passwords (this could be any value) because I want to be able to easily change the amount of passwords stored which cannot be used, and also so that others can easily take the answer and use it as they wish rather than having an answer which revolves around a very set value for X.\nInformation Update:\nAs requested here is the contents of my (excluding the comments at the top) /etc/pam.d/common-password file:\n# here are the per-package modules (the \"Primary\" block)\npassword        [success=1 default=ignore]      pam_unix.so obscure sha512\n# here's the fallback if no module succeeds\npassword        requisite                       pam_deny.so\n# prime the stack with a positive return value if there isn't one already;\n# this avoids us returning an error just because nothing sets a success code\n# since the modules above will each just jump around\npassword        required                        pam_permit.so\n# and here are more per-package modules (the \"Additional\" block)\npassword        optional        pam_gnome_keyring.so\n# end of pam-auth-update config\n\n\nA: You can configure PAM to do this for you. Just open /etc/pam.d/common-password and append use_authtok to the first password line (the one which calls the pam_unix module) so that it looks somewhat like this:\npassword    [success=1 default=ignore]  pam_unix.so obscure sha512 use_authtok\n\nNow add this line above the previously modified line:\npassword    required    pam_pwhistory.so  remember=X\n\nwhere X is the number of previous passwords against which you want to check for a repeating password. \nHere the previous X passwords will be stored in hashed form at the location /etc/security/opasswd\nSo you need to create the file if and only if it does not exist and assign it permission 600 (-rw-------):\nsudo touch /etc/security/opasswd\nsudo chmod 600 /etc/security/opasswd\n\n", "Q: Intel 3160 WiFi not working on 12.04 I am trying to get my Lenovo Edge 15 laptop to recognize the Intel 3160 Wifi firmware. \nFound the firmware here:\nhttps://wireless.wiki.kernel.org/en/users/Drivers/iwlwifi\nInstalled different versions of ucode after renaming the olds ones and I am not getting any luck.\nRenamed the old code, restarted. \nTried these solutions:\n\n\n*\n\n*No connection / sporatic connection with Intel 3160 Wireless, Lenovo Y50, Ubuntu 15.04\n\n*http://ubuntuforums.org/showthread.php?t=2214075\n\n*Disabled bluetooth, and still nothing.\n\n\nI am fresh out of options at this point. :( Forgive me if I missed something crucial. \nHere is my response from when I ran the command:\n$ modinfo iwlwifi\n\nfilename:       /lib/modules/3.2.0-23-generic/kernel/drivers/net/wireless/iwlwifi/iwlwifi.ko\nalias:          iwlagn\nlicense:        GPL\nauthor:         Copyright(c) 2003-2011 Intel Corporation <ilw@linux.intel.com>\nversion:        in-tree:\ndescription:    Intel(R) Wireless WiFi Link AGN driver for Linux\nfirmware:       iwlwifi-5150-2.ucode\nfirmware:       iwlwifi-5000-5.ucode\nfirmware:       iwlwifi-6000g2b-6.ucode\nfirmware:       iwlwifi-6000g2a-6.ucode\nfirmware:       iwlwifi-6050-5.ucode\nfirmware:       iwlwifi-6000-4.ucode\nfirmware:       iwlwifi-100-6.ucode\nfirmware:       iwlwifi-1000-6.ucode\nfirmware:       iwlwifi-135-6.ucode\nfirmware:       iwlwifi-105-6.ucode\nfirmware:       iwlwifi-2030-6.ucode\nfirmware:       iwlwifi-2000-6.ucode\nsrcversion:     F6A04975B757267E0AD9EB4\nalias:          pci:v00008086d00000892sv*sd00000466bc*sc*i*\nalias:          pci:v00008086d00000893sv*sd00000266bc*sc*i*\n\nUPDATE: This is what I got when running different versions of the kernel\nroot@tacos-Lenovo-Edge-15:~# dmesg|grep iwlwifi\n[   19.537154] iwlwifi 0000:02:00.0: Direct firmware load for iwlwifi-3160-12.ucode failed with error -2\n[   19.601097] iwlwifi 0000:02:00.0: Direct firmware load for iwlwifi-3160-11.ucode failed with error -2\n[   19.698771] iwlwifi 0000:02:00.0: Driver unable to support your firmware API. Driver supports v12, firmware is v0.\n[   19.890696] iwlwifi 0000:02:00.0: Driver unable to support your firmware API. Driver supports v12, firmware is v7.\n[   19.890766] iwlwifi 0000:02:00.0: no suitable firmware found!\n[  337.993120] iwlwifi 0000:02:00.0: Direct firmware load for iwlwifi-3160-12.ucode failed with error -2\n[  337.993128] iwlwifi 0000:02:00.0: Direct firmware load for iwlwifi-3160-11.ucode failed with error -2\n[  337.993340] iwlwifi 0000:02:00.0: Driver unable to support your firmware API. Driver supports v12, firmware is v0.\n[  337.993510] iwlwifi 0000:02:00.0: Driver unable to support your firmware API. Driver supports v12, firmware is v7.\n[  337.993523] iwlwifi 0000:02:00.0: no suitable firmware found!\n\n\nA: I just went through this same trouble with a new laptop with intel 3165 wifi.  I found that installing a kernel version later than 4.2 made the wifi work.  Some advice (learn from my frustrations):\n\n\n*\n\n*Install the \"linux-generic\" package that corresponds with the kernel version you want.  This way you will know you are getting a full kernel update, with all the extras that you need.\n\n*You might have to try more than one kernel version before you find the one that works best for you (especially if you have intel graphics, which are glitchy in some kernel versions).\n\n*Removing the \"linux-generic\" package will not remove the other packages it brings with it.  If you want to remove a specific kernel version, you will also need to remove the \"linux-headers-x.x.x-xx\", \"linux-headers-x.x.x-xx-generic\", \"linux-image-x.x.x-xx-generic\" and \"linux-image-extra-x.x.x-xx-generic\" packages.\n\n*GRUB will boot to the newest kernel version you have installed by default.\n\n*You do need to restart for the new kernel version to take effect.\n\n\nFor reference, I am running Linux Mint 17.3 (Ubuntu 14.04 base) with the \"linux-generic-lts-wily\" headers package, and everything is working well.\n", "Q: Upgrade Meizu MX4 ubuntu edition to OTA-10 fails Yesterday an upgrade to OTA-10 was available on my Meizu MX4 Ubuntu Edition. I downloaded the upgrade, and clicked the \"install\" button. Confirmed that the device was allowed to restart, and saw the device restart and an ubuntu logo came up. After about 30-50 seconds the Ubuntu logo was replaced by a picture of a small sign/icon of a computer-chip with a red cross behind it. Apparently something went wrong - but no form of error message was shown. The device was unresponsive - only thing to do was turn it off. When turned on again, it booted like normal - but the device is back to OTA-9.1. That is, I see a few subtle changes in graphics, and under phone information it clearly states OTA-9.1. What went wrong? What to do about it? How do I get it to fully upgrade to OTA-10? \nPS: The update/upgrade to OTA-10 is still available, and I have tried to install it a couple of times - to no avail. Same thing happens again ...\nPPS: I have nothing special installed or developermode or read/write turned on, or played with apt-get etc. Plain factory reset phone, that has been used as a normal smart-phone and nothing else for a couple of months.\n\nA: I have excatly the same problem as you. I have filled bug for this behavior here: https://bugs.launchpad.net/canonical-devices-system-image/+bug/1568889\n\nA: I had the exact same problem on a Nexus 7.\nI just tried again, this time using a writable image, and issued this via ADB:\nubuntu-device-flash touch --channel=ubuntu-touch/stable/ubuntu\n\nIt worked!\nI'm not sure if the writable image has any effect. You might want to try this with your current image, after making sure you're using the appropriate channel for your device.\n", "Q: Byobu: Create new window does not maintain pwd I recently removed tmux 1.8 from Ubuntu 14.04, and compiled tmux 2.2 and installed it via make install.   I need the newer tmux version for its true terminal color support. All other things seem to work fine, only hitting F2, Ctrl + F2 or Shift + F2 does not maintain the same present working directory. They all fall back to ~ (home dir).  This is not what I want because I usually open new window or new split to do the things related to the directory at current window.\nbyobu -v\nbyobu version 5.74\ntmux 2.2\n\nHow do I fix this?\n\nA: Unfortunately, this behavior was changed in version 1.9 and seems like not going to get fixed.\nMy request just left with no answer: https://github.com/tmux/tmux/issues/371\nThat means: the directory for all new processes will be the current server's dir. i.e. if you start tmux from your home dir, all new shells will start there as well.\nCurrently, the solution is to change all your key bindings for new-window and split-pane and add -c #{pane_current_path} to explicitly use the current pane's CWD as starting directory for the new one.\nAnother solution can be this.\nThere's a mod of tmux (I'm the author) to add a proper scripting language to tmux to allow using aliases, binding multiple commands in 'mode', variables, loops, etc...\nAnd also, it brings back the that behavior: new windows and panes are opened in the current directory.\nThe sources are here: http://ershov.github.io/tmux/\n", "Q: GRUB defaulting to 30 second timeout In my GRUB configuration, I have the following setting:\nGRUB_TIMEOUT=3\n\nIn general, it works fine. However, I'm using overlayroot, which creates a protected file system (specifically, it uses OverlayFS to create a union filesystem). When I reboot, the GRUB timeout reverts to 30 seconds. It's important to note that the necessary config changes were made with the file system in read/write mode, so whether the file system is in read-only or read/write mode, the config file is the same (and reflects the correct timeout).\nCan anyone shed some light on what might be going on? My best guess is that GRUB isn't detecting that the previous boot was successful, so it is overriding the timeout and setting it back to 30.\nThanks!\n\nA: Here's one answer. I'm not sure what mechanism causes a recordfail situation, but adding this line to the grub config seems to do the trick:\nGRUB_RECORDFAIL_TIMEOUT=$GRUB_TIMEOUT\n\n", "Q: Constant problems with external encrypted hard disks I am using an encrypted hard disk for backing up my (also encrypted) laptop disk, running Ubuntu 15.10 64 bit. The built-in laptop disk works fine but the external USB disk, after working for somewhere between a few minutes and a few hours, suddenly switches itself back to being encrypted and shows the password prompt. This happens even though I keep choosing \"remember forever\". Often, when I then re-enter the password, either it does not work and the dialog is shown again, or the system claims that it cannot mount the drive because it is already mounted.\nI thought maybe this is the problem with the physical disk and I attached a second encryped external usb drive. Now I am seeing the same problems for both disks, of completely different make and model. Although I have seen this problem with 15.04 my impression is that is has become even worse. \nThe bottom line is that now both my external USB hard-disks are essentially unusable and the whole situation is extremely annoying. \nIs this a known issue, and more importanly, is there anything that can be done to fix or avoid these problems?\nThe error message when trying to unlock again and the system claims something is already mounted is:\nError unlocking /dev/sdd1: Command-line `cryptsetup luksOpen \"/dev/sdd1\" \"luks-xxxxxx-xxx-xxx-xxx-xxxxxxxxxx\" ' exited with non-zero exit status 5: Device luks-xxxxxx-xxx-xxx-xxx-xxxxxxxxxx already exists.\n (udisks-error-quark, 0)\n\nA: Thank you everyone who gave feedback! I tried the disks on different laptops now and they work fine here. So it appears that there is something wrong with the laptop I had been using, where after some random time the connection gets interrupted, irrespective of which USB plug I use. \n", "Q: Ubuntu won't boot from my hard drive, only a trial version from USB-Live pendrive I've tried to google my problem before registering here and I did find a lot of people having similar issues that I have but never actually found a solution that would work for me.\nBasically speaking I bought one of those laptops with Windows 10 sticker, installed Ubuntu 15.10 on it (formatting the whole disk) from USB-Live. Everything went smooth, however after installation I am not able to boot my computer from my hard drive anymore. It automatically boots from my USB-Live pendrive even though the priority of booting is set to hard drive as first & the secure booting is disabled. When I remove the pendrive I get black screen.\nLaptop model: Toshiba Satellite C55D\n\nA: Well, take out the usb for starters.  Next is make sure you have the trusted boot file added to your bios in your computer.  I bet this is your first uefi laptop.  I keep telling people to post a bug on ubuntu for not telling people they need to do this on the install.\nI searched and it seems to say you need to change to cms mode in advanced options. \nYou could also try boot-repair. \nWhen all else fails, change to legacy boot and reinstall.\nYou need to make a usb with live linux creator or universal usb installer for legacy.  This is broken until 16.04 gets active again with a new startup disk creator.\nI have had both methods work in my acer laptop and settled on legacy.\nAfter the bios update, it was forgetting my trusted boot files that I was setting.  I dropped back down to the older bios and then went legacy for both win 10 and lubuntu.\nDo not get confused between two problems.  Usb legacy boot problem and uefi.  You need to activate uefi to find the secure boot settings to add the trusted source.  You also need to set a password to see that option.  Be very careful when setting a bios password.   Be sure to reset it back to nothing by setting password again and hitting《enter》.. (nothing).  If you forget the bios password, you have big problems so set it back to nothing once you are fished adding the trusted source.\nAgain.  I recommend legacy.  So..\nMake a proper new usb installer.\nSwitch to legacy boot.\nInstall.\nFinished. \nI needed to change the partition to mbr in order to install windows as legacy.  Not a big problem unless your are over 2 to (I think).  You are limited to 4 paritions too.  (Almost a problem for me)..but I only have 32gb anyway.\n", "Q: Bluetooth 14.04 on Lenovo H50 - RTL8723BE Referring to a question already answered by Pilot6 in thread RTL8723BE Bluetooth does not work\nI recognize the answer there using dkms by Pilot6 but they are somewhat dated. Has this been fixed in updates for 14.04 as of April 2016? I am not able to find bluetooth devices on my Lenovo H50 using the RTL8723BE chip with an updated 14.04 system as of now. \nBefore I start loading stuff should the advice in the original thread still be followed? If so has there been any changes in directions?\n\nA: Those answers aren't dated; they're less than a year old. 14.04 is almost two years old. For major changes, Ubuntu gets a new version. The method for something like that would not change within the same version. \nIf it was a solution for 6.10, then the procedure would likely be different, but it's not. Something I found important in Pilot6's answer:  \nIt builds against all supported Ubuntu kernels.\n\nIt makes me think that it would work everywhere, and that it's kernel-dependent and not OS version dependent.\nTo sum it up, there is no harm in trying. Nine-ish months is not long enough in my book to rule out answers as invalid. A few years can even be fine. Try it out! :-)\n", "Q: Ubuntu 14.04.4 LTS for IBM POWER8 runs on Openpower servers I need to know if Ubuntu fr Power 8 runs in Openpower 8 servers like Tyan products.Link below:\nhttp://www.tyan.com/campaign/openpower/\nThanks in advance.\n\nA: It appears so. IBM has a list of supported features for Ubuntu on POWER8 computers, and I don't see a reason they would have a list if Ubuntu couldn't run on the processor anyway. There is also a question on this site that asks a question about viewing the CPU speeds from Ubuntu on a POWER8 machine. They have it working, so it must be installable.\nIn short, you really have to just try it out. In most cases, there's no way to tell whether or not it will work, since everyone's experience is at least slightly different. Try it out and see.\nIBM's Feature List\nQuestion about CPU Speeds\n\nA: Yes, all version since 14.04 runs on these machines. All the 14.04,X releases are also support. The latest is 14.04.5.\nOther than 14.04.X, you can install all the other releases, as 14.10, 15.04, 15.10 and 16.04. 16.10 is still under development, and is also supported on Tyan Power machines.\nFor more information, please check Canonical on POWER8\nThe architecture is named ppc64el, and you can find the images at Ubuntu 14.04 on POWER8 images\n\nA: Yes, Ubuntu 14.04 (and later) run on all OpenPOWER systems either bare metal or in a VM. I would recommend Ubuntu 16.04 over 14.04 as a lot more packages have been optimized for POWER8. The HWE updates (the 14.04.X) releases are important as they do better support the hardware.\nMy day job is maintaining the OPAL firmware that runs on these machines. Not a day goes past where I'm not running Ubuntu on a Tyan OpenPOWER machine.\n", "Q: A list of wireless connections doesn't appear in Asus k501ux Please help with wireless (may be drivers or other settings). I have asus k501ux and I have already installed kubuntu 15.10 on it, butit doesn't see any wi-fi network.\nNo any networks\nlspci -nn | grep 0280 shows folowing:\n\n03:00.0 Network controller [0280]: Intel Corporation Wireless 7265 [8086:095a] (rev 59)\n\n\n    bogdan@asus-bogdan:~$ dmesg | grep iwlwifi\n[    2.858927] iwlwifi 0000:03:00.0: Unsupported splx structure\n[    2.905389] iwlwifi 0000:03:00.0: Direct firmware load for iwlwifi-7265D-15.ucode failed with error -2\n[    2.921112] iwlwifi 0000:03:00.0: loaded firmware version 25.30.14.0 op_mode iwlmvm\n[    2.952391] iwlwifi 0000:03:00.0: Detected Intel(R) Dual Band Wireless AC 7265, REV=0x210\n[    2.952465] iwlwifi 0000:03:00.0: L1 Enabled - LTR Enabled\n[    2.952912] iwlwifi 0000:03:00.0: L1 Enabled - LTR Enabled\n[    2.979027] iwlwifi 0000:03:00.0: RF_KILL bit toggled to disable radio.\n[    3.015432] WARNING: CPU: 1 PID: 453 at /build/linux-HVWSXI/linux-4.2.0/drivers/net/wireless/iwlwifi/pcie/trans.c:1447 iwl_trans_pcie_grab_nic_access+0x2a2/0x2b0 [iwlwifi]()\n[    3.015434] Modules linked in: snd_hda_codec_hdmi i2c_designware_platform(+) iwlmvm(+) snd_hda_codec_conexant snd_hda_codec_generic i2c_designware_core mac80211 asus_nb_wmi asus_wmi sparse_keymap mxm_wmi intel_rapl x86_pkg_temp_thermal intel_powerclamp coretemp kvm_intel snd_hda_intel kvm snd_hda_codec snd_hda_core snd_hwdep crct10dif_pclmul crc32_pclmul iwlwifi snd_pcm aesni_intel cfg80211 aes_x86_64 lrw gf128mul snd_seq_midi glue_helper snd_seq_midi_event ablk_helper cryptd snd_rawmidi snd_seq snd_seq_device snd_timer input_leds serio_raw snd uvcvideo videobuf2_vmalloc videobuf2_memops soundcore videobuf2_core v4l2_common videodev media idma64 btusb virt_dma btrtl btbcm btintel bluetooth shpchp mei_me mei intel_lpss_pci processor_thermal_device intel_soc_dts_iosf int3403_thermal wmi intel_lpss_acpi\n[    3.015475] CPU: 1 PID: 453 Comm: irq/130-iwlwifi Tainted: G        W       4.2.0-35-generic #40-Ubuntu\n[    3.015497]  [<ffffffffc0664482>] iwl_trans_pcie_grab_nic_access+0x2a2/0x2b0 [iwlwifi]\n[    3.015500]  [<ffffffffc06530ea>] iwl_read_direct32+0x3a/0xf0 [iwlwifi]\n[    3.015503]  [<ffffffffc06531e3>] iwl_poll_direct_bit+0x43/0x70 [iwlwifi]\n[    3.015507]  [<ffffffffc065a174>] iwl_pcie_rx_stop+0x34/0x40 [iwlwifi]\n[    3.015510]  [<ffffffffc0664ad7>] iwl_trans_pcie_stop_device+0x5f7/0x630 [iwlwifi]\n[    3.015514]  [<ffffffffc06644ce>] iwl_trans_pcie_rf_kill+0x3e/0x50 [iwlwifi]\n[    3.015517]  [<ffffffffc065b1c7>] iwl_pcie_irq_handler+0xba7/0x1500 [iwlwifi]\n[    3.427243] iwlwifi 0000:03:00.0 wlp3s0: renamed from wlan0\n[   17.016173] iwlwifi 0000:03:00.0: RF_KILL bit toggled to enable radio.\n[   66.682577] iwlwifi 0000:03:00.0: RF_KILL bit toggled to disable radio.\n\nbogdan@asus-bogdan:~$ rfkill list\n0: hci0: Bluetooth\n        Soft blocked: no\n        Hard blocked: no\n1: asus-wlan: Wireless LAN\n        Soft blocked: no\n        Hard blocked: no\n2: asus-bluetooth: Bluetooth\n        Soft blocked: no\n        Hard blocked: no\n3: phy0: Wireless LAN\n        Soft blocked: no\n        Hard blocked: yes\n\n\nA: The wireless adapter is blocked by rfkill.\nIt is an Asus UEFI issue.\nThis can be fixed by\nsudo tee /etc/modprobe.d/asus.conf <<< \"options asus_nb_wmi wapf=4\"\n\nReboot after this command and test.\nThis solution should help. A quirk for this Asus laptop has been added to upstream kernels. It is actually the same fix as this options asus_nb_wmi wapf=4.\n", "Q: How to modify dock transparency in gnome? I copied the files /usr/share/gnome-shell/theme/gnome-shell.css of a friend of mine, who set the transparency to the maximum.\nI want to change it, to make it less transparent.\nWhich option should I modify?\n\n\nA: To change the launcher transparency, find this section in the CSS file:\n/* DASHBOARD */\n#dash {\nfont-size: 9pt;\ncolor: #eeeeec;\nbackground-color: rgba(30,30,30,0.4);\npadding: 4px 0;\nborder: 0px solid rgba(128, 128, 128, 0.4);\nborder-left: 0px;\nborder-radius: 0px 8px 8px 0px; }\n\nChange the background-color field to whatever you want. I used the RGBA format, so that transparency would work. The format of what I used is:\nrgba(RED 0-255, GREEN 0-255, BLUE 0-255, OPACITY 0.0-1.0)\n\nIf the opacity is 1.0 it will be completely opaque.\nEDITS:\nTo make the borders on the shutdown dialog buttons rounded, you need to add this somewhere in the CSS file (it doesn't really matter, but if you want organization, put it under the /* Restart */ header):\n.end-session-dialog .modal-dialog-button,\n.end-session-dialog .modal-dialog-linked-button {\n    border-radius: 8px;\n    width: 30px;\n    height: 10px; }\n\nChange the width and height sections to what you think looks good.\n", "Q: I don't have prime profile at nvidia xserver settings I was using windows before and I was playing cs go without any ping with high fps. I am using ubuntu 14.04 now. I have very low fps although I decreased the video settings. I am using ASUS N550k, Geforce GTX 850 M display card. Moreover I installed bumblebee. \nThanks for help.\n\nA: Use nvidia-prime instead of bumblebee and to make sure that everything works as expected, remove all NVIDIA software and the bumblebee packages as well. Because you have quite new graphics hardware, it might be a good idea to install the latest official stable NVIDIA drivers.  \nOpen a terminal and execute these commands :\nsudo apt-get purge nvidia* '^bumblebee.*'  \nsudo reboot  \n\nSelect the Ubuntu menu entry from the GRUB menu and  press the E key.\nAdd nouveau.modeset=0 at the end of the linux line and press F10 to boot.\nNote : Put a Space between the last character of the line and nouveau.modeset=0.\nOpen a terminal and execute these commands :\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\nsudo apt-get install nvidia-361 nvidia-prime\nsudo reboot  \n\nYou can choose which graphics you want to use from NVIDIA X Server Settings (PRIME Profiles).\n\nA: I tried to try your commands but I get a lot of \"SCHED ERROR\" and after all I could not open my computer. What Should I do now?\n", "Q: Ubuntu 15.10. Rhythmbox + last.fm = Token expired I am using Ubuntu 15.10 and Rhythmbox. The problem is that I can't login to last.fm. The program always gives an error  saying \"Token expired\".\nI upgraded Rhythmbox (to 3.3) and its plugins from the ppa but there was no result. I tried to set a different default browser but again with no  result.\nUp to this point I haven't got any clue how to solve this. Can anybody help me?\nSome images of process are below.\n1. Open last.fm in player\n\n2. Press log in\n\n3.This page opens\n\n4. Pressing \"Yes\" and getting the same error\n\n\nA: I had this issue until recently. What you should do is delete the contents of ~/.local/share/rhythmbox/audioscrobbler, particularly the file sessions, then try and authenticate again. It should work then.\n", "Q: Raspberry Pi: Filesystem writes files, but after reboot the old data is back Okay this is a really weird problem occurring on two raspberry pi systems with their respective 8GB SD memory cards:\nSimple example:\nWhen I write files to the disk, it looks like the files are written.\nI can edit a file vim test.dat, enter text into it, save.\nll will list the file.\ncat will show the contents of the file.\nAfter a reboot the file will be gone.\nSo what I think is happening is that ubuntu writes the files to ubuntu's disk cache but it doesn't commit the files to disk. The userspace programs can continue reading the files and using them, but the cache returns the directory listings and file contents from ram, and not from the disk. Because after a reboot the disk has none of the new data.\nAnother example: \ndd if=/dev/zero of=testfile.dat bs=1M count=1000\n\nIt creates a file with 1GB size.\nll lists the file.\ndf -h shows that 1GB more has been used by the data on disk.\nBut after a reboot the file is gone and df -h shows the old available space. \nFun fact: I know the SD card's max writing speed is 9MB/sec, which is what I get when I dd the disk image onto it using my laptop. But running this dd command on the SD card in the raspberry, dd reports the write speed as 110MB/sec. Impossible. This is why I think the operating system is just writing to RAM and not committing to disk. \nThird example:\nI have a script that edits a file named interfaces, and then copies it, as root, over the /etc/network/interfaces file, to change the IP of the device. Then the script reboots.\n#!/bin/bash\ncp /var/project/scripts/interfaces /etc/network/interfaces\n/sbin/reboot\n\nAfter the reboot, the device is still on its old IP address... Weird...\nFourth example:\nThe raspberry runs a percona database.  I have a table that contains 186 entries.  I truncate the table.  Look at the data using the php code and also using webmin - the table is empty like it should be.  After a reboot the data is back.  Really... 186 entries.  This is freaking me out.\nI can be completely wrong.  Any ideas?\nI have been working on this ubuntu installation and making periodic backups by cloning the disk image after every major sofware update.  I have been noticing strange things (like the IP not changing after running my script) but I did not realise this problem until today, it seems like all the cloned disk images I have exhibit this issue. It must have worked fine up to a point and then something went wrong with ubuntu on the pi...\nQuestion:  What can I do to get ubuntu to write to the SD card?\n\nA: What seemed to help me was using the sync command:\nsync\n\nFrom the help:\n\nForce changed blocks to disk, update the super block.\n\nIt flushes the filesystem buffers in other words.\nHowever I would expect that when you do a proper sudo reboot unlike me, this would be no issue and hence the sync might not work for you..\nI was having similar issues with a raspbian wheezy install.\nIt has an ext4 partition containing the filesystem which is read-only. And a small read-write partition with FAT32 containing some configfiles. When I changed a config file and then pulled the power plug to restart the changes were not persistent. (be advised: without a read-only Pi, pulling the power plug would not be a smart thing to do anyway)\n\nA: I have same problem with Samsung EVO 18G MicroSD card. Many people discussed this issue in raspberry forum here: https://www.raspberrypi.org/forums/viewtopic.php?t=21330#p992573\nMost likely is SD Card corrupted.\n\nA: I have encountered exactly same problem. I solved this problem by doing following steps:\n\n\n*\n\n*STEP 1: Observe value that specified after root=PARTUUID= from /boot/cmdline.txt:\ncat /boot/cmdline\n\nIn my case, I found something like 093bedcc-02:\nboot=overlay console=tty1 root=PARTUUID=093bedcc-02 rootfstype=ext4 elevator=deadline fsck.repair=yes rootwait\n\n\n*STEP 2: Find PATH with the specified value of root=PARTUUID= from the previous step with lsblk (for more detail read man lsblk to format the output):\nlsblk -o NAME,FSTYPE,LABEL,UUID,PARTUUID,MOUNTPOINT,PATH\n\nIn my case, I got something like:\nNAME        FSTYPE LABEL  UUID                                 PARTUUID                             MOUNTPOINT PATH\nmmcblk0                                                                                                        /dev/mmcblk0\n├─mmcblk0p1 vfat   boot   BC50-2AE4                            093bedcc-01                          /boot      /dev/mmcblk0p1\n└─mmcblk0p2 ext4   rootfs 9b87f948-9dc3-49e7-94fc-309bfabb1ac4 093bedcc-02                          /          /dev/mmcblk0p2\n\nIn my case, I got the PATH value as /dev/mmcblk0p2.\n\n*STEP 3: Now replace root=PARTUUID= with its PATH vale (in my case, /dev/mmcblk0p2) by prepending root=: \nroot=/dev/mmcblk0p2\n\n\n*STEP 4: Finally reboot the system with following command:\nsudo reboot\n\n", "Q: How to open programs found in Software Center? I am trying to locate the Software Updater which disappeared from my left panel of programs. I managed to locate it in the Software Center but clicking on it doesn't open it or help me locate it - it just shows me it exists. \nThe same happens with Glipper, the clipboard utility. I can find them both (the Software Updater and Glipper), when I do a search in the Software Center, but neither lets me click on them in order to open them, nor can I locate either of the above programs in ClassicMenu Indicator.\nWhere are they? How do I actually open the programs which Ubuntu tells me are installed? Itm ay seem like a stupid question but I am new to Linux and many things seem counter-intuitive to me.\n\nA: Two things you can do:\n\n\n*\n\n*Open Dash by either accessing it with a mouse click at the top left of your screen or by simply pressing the 'Windows' key on your keyboard. Then type in 'Software & Updates', this will open it up for you...\n\n*Now right click on the icon at the left of your screen that represents 'Software & Updates' and select 'Lock to Launcher', this will keep the icon on the Launcher for easy, future access\n\n\nScreenshot here to demonstrate the 'lock' process:\n\n", "Q: Using UFW with ipsets I am running Ubuntu 14.04 on a VPS for business purposes.  The firewall is setup using ufw; testing reveals that it's working well.  I'd like to further secure my server using techniques described here:\nhttp://blog.ls20.com/securing-your-server-using-ipset-and-dynamic-blocklists/\nAre there any known conflicts between UFW and ipsets that might cause problems if I were to use ipsets to block malicious hosts attempting to probe my server for vulnerabilities?  I understand that ufw makes configuring iptables simpler.  My primary concern is the impact on ufw.  Are there any known issues with using multiple apps to setup iptables?  \n\nA: This might not answer your question directly, however...\nWhy not use PFsense or IPfire rather? They can do all you need and more.\nPFSense\nIpfire\n", "Q: Ubuntu 15.10 won't run after restarting I downloaded Ubuntu 15.10 and erased the disk and installed it. Afterwards I ran update and upgrade commands and that's it.\nI have not updated drivers or anything else. Afterwards I installed GNOME shell and when I restarted my HP laptop it couldn't boot at all.\n\n\nA: Try Ctrl+alt+f7 and see if it drops you into a command line. log in and run. \"sudo apt-get update\" then \"sudo init 6\" and \"sudo apt-get upgrade\". if that doesn't work it appears that if you re-install ubuntu it is very un-likely that you'll do the exact same thing that caused the error in the first place.\n", "Q: My computer reboots randomly I have Ubuntu 14.04.1 . When using the pc (usually watching a video on youtube, or something that requires some cpu) it reboots, and then it usually doesn't restart again, you have to switch off and wait for some minutes, then switch on and it works, what could happend? I checked memories and hard disc and Ubuntu said they were ok. Sorry for my English.\n\nA: There are things that could cause this, one is heat as others have mentioned, and another is the power supply. Open the side of the pc if this is a desktop, and leave it open. Start up the pc. If it stays on, heat is your issue. Try blowing it out with a blower or another less preferred option is to use the vacuum cleaner to remove dust from the heatsink on the cpu.\nIf this does not solve the problem replace you Power Supply. The fact that it doesn’t come on for a while after the shutdown is making me suspect static in the power supply.\n\nA: sudo apt-get update\n\nsudo apt-get upgrade\n\nsudo init 6\n\nafter it restarts see if it is still happening\n", "Q: gsettings - change privacy settings via command line I know how to change privacy settings via GUI (System Settings > Security & Privacy), but I'd like to be able to do it from command line.\nWhat I did to find out\nI ran the command:\ndconf watch /\n\nto see what changes were made. About the command (from man dconf):\nwatch\n    Watch a key or directory for changes.\n\nSubsequently, I changed settings via GUI to see what happened in the output of the command. It showed:\n/org/gnome/desktop/privacy/remember-recent-files false\n/com/canonical/unity/lenses/remote-content-search 'none'\n/org/gnome/desktop/screensaver/ubuntu-lock-on-suspend false\n/org/gnome/desktop/screensaver/lock-enabled false\n\nMy question is: how can I use this information to change the settings from command line?\n\nA: Different ways to edit those settings\nThe settings you mention are stored in the dconf database in ~/.config/dconf (in binary format). This database can either be directly edited with dconf, or via gsettings. The difference is explained at the last section of this answer.\nOnce you have the information, posted in your question, you can therefore change the corresponding settings in two different ways. \nUsing your first example (setting remember-recent-files):\nusing dconf write:\ndconf write /org/gnome/desktop/privacy/remember-recent-files false\n\nor\nusing gsettings set:\ngsettings set org.gnome.desktop.privacy remember-recent-files false\n\nSimilarly, reading the current setting:\nusing dconf read:\ndconf read /org/gnome/desktop/privacy/remember-recent-files\n\nor\nusing gsettings get:\ngsettings get org.gnome.desktop.privacy remember-recent-files\n\nIn the first case, you edit the dconf database directly, in the latter you are using gsettings, which is a CLI frontend to dconf.\nWhich way to prefer; dconf or gsettings?\nTo protect the integrity of your dconf database, in general, it is considered better practice to use gsettings.\nFrome this link, we read:\n\nThe dconf program can perform various operations on a dconf database,\n  such as reading or writing individual values or entire directories.\n  This tool operates on dconf directly, without using gsettings schema\n  information. Therefore, it cannot perform type and consistency checks\n  on values. The gsettings(1) utility is an alternative if such checks\n  are needed.  You can see gsettings as the cli-frontside to dconf.\n\nRead more on gsettings and dconf.\n", "Q: My normal user file system only works in read-only mode and i don't have the password for the root user I have Ubuntu Server V14.10.the administration of this system disappears with a former employee. I do not have the root password and apparently the file system for the user that I use is protected and will not let me modify any files..\nthere any way to remount the file system from a normal user or necessarily have to recover root ??\nI've been reading about the issue and apparently the errors that appear with the dmesg | grep \"EXT4-fs error\" deal with the problem of the file system in read-only mode.\ntacacs@Tacacs:/$ dmesg | grep \"EXT4-fs error\"\n[49087.944165] EXT4-fs error (device dm-0): ext4_journal_check_start:56: Detected aborted journal\n[49147.984664] EXT4-fs error (device dm-0): ext4_journal_check_start:56: Detected aborted journal\n[272027.360154] EXT4-fs error (device dm-0): ext4_find_entry:1312: inode #6946817: comm sshd: reading directory lbl\n[272627.768280] EXT4-fs error (device dm-0): ext4_find_entry:1312: inode #5768225: comm sshd: reading directory lbl\n\nI would appreciate your help, I am a rookie in Linux\n\nA: hehe my specialty ;) computer security is a hobby of mine... when you start up the computer you will get a grub screen that displays the normal bootup option and below that \"Advanced options for ubuntu\" select that and go to one of the recovery terminals... reboots my computer... select the 2nd one in that menu it'll say \"ubuntu with generic (recovery mode)\" and some numbers mixed in there and it should give you an option interface with one that says root which will give you a full admin command prompt... I trust you know what you can do from there... (hint: passwd, nano /etc/group) \n", "Q: Is there a app or software that will allow me to access a Zip file that was down loaded from the Hightail web site? I am using a Asus  laptop, running on Ubuntu 15.10, -  (64bit) - however, my problem is this, I downloaded two zip files from the Hightail website, and I am unable to read the files. when I click on the downloaded files, with the Libreoffice writer, all I get is a page full of code. It appears to me, that a lot of the files were put together with a Java Script setup. \nThe information is suppose to be dealing with law, not a page full of code. \nFrankly, I am new to Ubuntu, and clueless on what to do. i really would like some help with this, on how to access this Zip file.  \nThanks.\n\nA: ZIP files are archives, not text files. They contain other files that are compressed so as to save space. A ZIP file can be thought of as a compressed folder. I'm going to bet that what's inside the ZIP is what you want to open with LibreOffice.\nTo open the ZIP, simply browse to it in a file manager and double-click it. In the window that pops up, click the Extract... button to extract whatever's inside. Click Show Files when prompted and a folder will open with the files that were inside the ZIP.\nYou should find a file there you can open.\n\nA: Alternatively, you can use the unzip command to \"unzip\" or extract a zip file in the terminal to make it readable. \nFor example, if I have a file named Hightail.zip located in my Downloads directory, I would run the following command to unzip or extract the file or files:\nunzip ~/Downloads/\"Hightail.zip\" -d ~/Downloads/\n\n\nTo explain:\nThe first part of the command: unzip ~/Downloads/\"Hightail.zip\" tells the computer to unzip the file that is specified.\nThe last part of the command  -d ~/Downloads/ tells the computer where to put the newly extracted file or files. In this example, the new files would be found in the Downloads directory when finished.\n", "Q: Bash on Ubuntu on Windows users I can't seem to access my normal Windows filesystem on the Ubuntu command line in Windows, any tips? Not even sure if this is supported yet.\n\nA: The windows file systems are located in /mnt/<Drive letter> by default. Keep in mind that there are caveats with file permissions given they aren't supported on ntfs.\n\nA: You must enter the following:\ncd /mnt/c/dev\n\n", "Q: Dollar sign in environment variable's value Is it a bad practice to have a dollar sign in an environment variable's value?\nex:\nMY_VAR=\"$toto\"\n\nTo be more precise, I would like to set it in the /etc/environment file to be accessible by a java program. I did a test and it's working but I just want to make sure I won't encounter any catastrophic side effect.\nThe value of the variable is a password and starts with a dollar sign so I have no choice.\n\nA: Many pointed out that MY_VAR=\"$toto\" will assign to MY_VAR the current value of $toto or an empty string in case $toto is unset (or in case $toto itself contains an empty string obviously), but I'm surprised no one pointed out yet that MY_VAR=\"$toto\" will not set an environment variable but rather a shell variable (unless a variable named MY_VAR is already present in the environment, perhaps because this is only tangential to the actual question).\nHowever more to the point no, it's not a bad practice, or it's just as bad practice as having any other shell special character inside a variable, which is often not avoidable.\nIn 99% of the cases the shell will expand the variable in the current shell only once (or will not expand it at all for example when enclosed in single-quotes):\n$ MY_VAR='$toto'\n$ echo $MY_VAR\n$toto\n$ echo '$MY_VAR'\n$MY_VAR\n$ echo \"$MY_VAR\"\n$toto\n$ echo $(echo $MY_VAR)\n$toto\n\nThe 1% of the cases being, for example, when the variable is referenced in an eval expression, which adds a level of indirection:\n$ MY_VAR='$toto'\n$ eval echo $MY_VAR\n\n$\n\nBut that's obviously the expected result, and again, then having any other shell special character inside a variable should be considered a bad practice in the same way:\n$ MY_VAR='&&'\n$ eval echo $MY_VAR\nbash: syntax error: unexpected end of file\n\n(the truth being that using eval is often a bad practice, for this very reason).\nSo no, having a dollar sign in a shell / environment variable is not a bad practice, at least not more than having any other shell special character.\n\nA: For the specific case of /etc/environment, no, a $ in the variable value doesn't mean anything special. /etc/environment is a file read by a PAM module named pam_env, and pam_env has specific syntax for interpreting $:\n\n\n*\n\n*In /etc/environment, it is left uninterpreted.\n\n*In /etc/security/pam_env.conf and ~/.pam_environment (a user-specific file), pam_env treats $ specially when it sees lines with the following syntax:\nFOO DEFAULT=SOMETHING${BAR}SOMETHINGELSE$BAR\nFOO OVERRIDE=SOMETHING${BAR}SOMETHINGELSE$BAR\n\nIn this case, ${BAR} is replaced with the value of the variable BAR, but not $BAR.\nIn both cases, for a line like:\nFOO=BAR$BAR${BAR}\n\nThe contents of the variable FOO will be the literal string BAR$BAR${BAR}.\nThe pam_env.conf manpage has examples:\nSilly examples of escaped variables, just to show how they work.\n\n         DOLLAR         DEFAULT=\\$\n         DOLLARDOLLAR   DEFAULT=        OVERRIDE=\\$${DOLLAR}\n         DOLLARPLUS     DEFAULT=\\${REMOTEHOST}${REMOTEHOST}\n         ATSIGN         DEFAULT=\"\"      OVERRIDE=\\@\n\n\nA: To answer your exact question:\nYes, it is bad practice to have a dollar sign in the value of an environment variable.  However, that's not what the code snippet you have displayed actually does.\nMY_VAR=\"$toto\"\n\n$ is a special character to your shell (whether bash or dash), and unless protected against variable expansion, you won't actually be putting a literal dollar sign in the value of MY_VAR.\nTo do that you would need to escape the $, either with a backslash just before it, or single quotes around it.\n\nA: Your example does not illustrate your question.\n$ toto=\"somevalue\"\n$ MY_VAR=\"$toto\"\n$ echo $MY_VAR\nsomevalue\n$ \n\nTo do what you asked, you'd need:\nMY_VAR='$toto'\n\nor\nMY_VAR=\"\\$toto\"\n\nCan't tell for sure if it's bad practice. Personally I don't see any obvious problem.\n", "Q: Installed Ubuntu over Debian, But Only Debian boots I Installed Debian 8 and took a quick look at it. Then I installed Ubuntu 14 to have a look at it.\nI am sure both operating systems are there, but the system boots into Debian. I have never seen Ubuntu desktop yet. I am sure I told it to cover Debian, but it looks like that didn't happen.\nIs it to late to fix this mess?\nI am a raw newbie, but one who has DOS, OS/9, and OS/2 Warp command line experience.\nThanks\n\nA: looks like the grub didn't install... (or if it did it isn't working properly). easiest thing to do would be to put your ubuntu live disk/usb back in and fix that. there is a detailed explanation of what to do to re-install grub here: http://howtoubuntu.org/how-to-repair-restore-reinstall-grub-2-with-a-ubuntu-live-cd. Good luck! and hope you can get that working.\n", "Q: How to push OpenPGP keys for a (custom) Ubuntu repository to clients running on Ubuntu server? I have a number of devices running on Ubuntu trusty, syncing with a custom Debian package repository for software updates via unattended-upgrades. However, the OpenPGP key used to sign the release file expired before I noticed. Now the devices cannot automatically update the OpenPGP public key and authenticate the packages, and can no longer upgrade to the latest packages available in the repository. Is there anyway to salvage from this situation without manually running any commands on the devices? What is the standard set-up to enable gpg key rotation (without future intervention on the client devices)?\n\nA: If you've still got access to the private key, you can easily extend the validity period running gpg --edit-key [key-id] and then using the expire command. This way, you should manage to have the old machines \"pick up\" on updates again, and then project the actual key escrow. Also read \"Does OpenPGP key expiration add to security?\" (edit: I overlooked that the key needs to be updated on the clients, which won't happen automatically).\nA common \"OpenPGP way\" to deal with with rather frequent (more often than all decade) key escrow on a given schedule is keeping the primary private key offline (for example, on a dedicated computer not connected to the internet) and not escrowing it, while actual signing is performed by a signing subkey which you can escrow easily without losing trust on the machines (and you can have multiple valid ones at the same time).\nAs an alternative, you could install a new trusted OpenPGP key before the old one will expire.\n", "Q: Android NDK in Adroid Studio 2.1 Preview 5 and Ubuntu 14.04 In project structure there is a download NDK link that starts the DL\nI get error \"No space left on disk\"\nI know more than enough space is on the drive. \n\nA: You can go to File > Project Structure and from the left panel select SDK Location as in the bottom image. There you can see or change the location of your SDK/NDK.\n\n", "Q: Ubuntu Gnome 15.10 64-bit Nvidia GTX 780 Issues so im new to linux of any kind, i have just made the leap and switched from windows to ubuntu. It took me a while as i wanted a system that was clean and had tons of support for issues like this, i chose the Gnome Ubuntu.\nAnyway when i was first trying to install ubuntu, i would get past bios, it would load the first ubuntu screen asking for a live \"try it\" session or to install. From here no matter the option i chose there was little to no display output. all i would get would be a black screen with a cursor. \nSo i removed my GTX 780 from my system and ran my HDMI cable to my monitor via the motherboard onboard intel graphics. This works perfectly. Now i am assuming this is a driver issue, and so i went hunting once i has installed ubuntu for nvidia graphics drivers for linux based systems and installed the latest version that directly supported the Nvidia GTX 780 cards. This made it worse. I would boot to find a screen flashing between a light grey with a box and a black 'no display input' screen. I had to re install ubuntu using my usb and no graphics card installed all over again...\nI am now back to square one with no graphics card installed running off my Intel' HD on board graphics. The drivers failed to work, maybe i did something wrong? Any advice to fix this?\nCheers :)\nMy System specs:\nCPU: Intel i5-4690K\nMOBO: Asus Z97-A\nMem: 16GB G-Skill 1600\nHDD: Raid 0 2 x 120gb SSD's\nHDD: 2TB Seagate Barracuda\nGPU: Asus GTX 780 Direct OC CU II 3GB\nCooler: Corsair H80i\n\nA: After installing ubuntu please try this\nctrl+alt+t\nThen in termnal try\nsudo apt-get install nvidia-352\nThen \nsudo reboot\nand done\n", "Q: Can't install WinUSB on Ubuntu 15.10 I recently installed Ubuntu 15.10 on my old computer.  I'm now trying to create a windows usb stick to install on a new computer I'm building.  When I add the repository\n    sudo add-apt-repository ppa:colingille/freshlight\n\nand I try to update, I get the following errors:\n    W: Failed to fetch http://ppa.launchpad.net/colingille/freshlight/ubuntu/dists/wily/main/binary-amd64/Packages  404  Not Found                         \n\n    W: Failed to fetch http://ppa.launchpad.net/colingille/freshlight/ubuntu/dists/wily/main/binary-i386/Packages  404  Not Found\n\n    E: Some index files failed to download. They have been ignored, or old ones used instead.\n\nThen when I try:\n   sudo apt-get install winusb\n\nI get:\n   E: Unable to locate package winusb\n\nCan anyone help me find a solution?\n\nA: To install in Ubuntu (16.04, 15.10, 15.04 and 14.04) or Linux Mint (17.x or 18) and derivatives. To add the PPA and install WinUSB, use the following commands:\n\nsudo add-apt-repository ppa:nilarimogard/webupd8\nsudo apt update\napt install winusb\n\n\nA: The Winusb package is not available from this PPA for Wily but there is a technique that worked well on my system to install it using the Saucy package. I have tested this under Trusty but it should also work under Wily:\nFirstly download either 64bit or 32bit package from the PPA:\n64bit:\nwget https://launchpad.net/~colingille/+archive/freshlight/+files/winusb_1.0.11+saucy1_amd64.deb\n\n32bit:\nwget https://launchpad.net/~colingille/+archive/freshlight/+files/winusb_1.0.11+saucy1_i386.deb\n\nThen install the file:\nsudo dpkg -i winusb_1.0.11+saucy1*\n\nYou will see errors such as the following:\nandrew@corinth:~$ sudo dpkg -i winusb_1.0.11+saucy1*\n(Reading database ... 197467 files and directories currently installed.)\nPreparing to unpack winusb_1.0.11+saucy1_amd64.deb ...\nUnpacking winusb (1.0.11+saucy1) over (1.0.11+saucy1) ...\ndpkg: dependency problems prevent configuration of winusb:\n winusb depends on libwxbase2.8-0 (>= 2.8.12.1); however:\n  Package libwxbase2.8-0 is not installed.\n winusb depends on libwxgtk2.8-0 (>= 2.8.12.1); however:\n  Package libwxgtk2.8-0 is not installed.\n winusb depends on gksu; however:\n  Package gksu is not installed.\n\ndpkg: error processing package winusb (--install):\n dependency problems - leaving unconfigured\nProcessing triggers for man-db (2.6.7.1-1ubuntu1) ...\nProcessing triggers for gnome-menus (3.10.1-0ubuntu2) ...\nProcessing triggers for desktop-file-utils (0.22-1ubuntu1) ...\nProcessing triggers for bamfdaemon (0.5.1+14.04.20140409-0ubuntu1) ...\nRebuilding /usr/share/applications/bamf-2.index...\nProcessing triggers for mime-support (3.54ubuntu1.1) ...\nErrors were encountered while processing:\n winusb\nandrew@corinth:~$ \n\nFix the errors:\nsudo apt-get -f install\n\nIt is a very clumsy method (and certainly will not work for all deb packages!) but has certainly worked on my Trusty system and should also work on Wily:\n\nReferences:\n\n\n*\n\n*Install Winusb in Ubuntu 14.04\n\nA: There is a fork of winusb which works great in my Ubuntu Mate 18.04\nIt is WoeUSB\nsudo add-apt-repository ppa:nilarimogard/webupd8\nsudo apt-get update\nsudo apt-get install woeusb\n\nYou will find the launcher icon in the menu (or search in the menu).\n\nA: WinUSB won't work properly on Ubuntu 18.04.\nUse woeUSB instead:\nsudo apt-get install woeusb\n\nJust restart the system after installation \n", "Q: How to log only the message in syslog-ng? In syslog-ng.conf I have the following:\nsource s_imp { tcp(ip(\"localhost\") port(514)); };\n\nfilter f_imp {program(\"imp\");};\n\ndestination d_imp {file(\"/home/rpr/syslog.log\");};\n\nlog {source(s_imp); filter(f_imp); destination(d_imp);};\n\nThe output that I get in syslog.log is:\nApr  8 05:11:20 127.0.0.1 imp[4463]: message\n\nI'd like to log only the message and not the time stamp, IP address etc. Is there a way to do this?\n\nA: This can be done with the help of templates. $MSG has the message contents and we can ensure that only it is logged.\ntemplate t_imp {\n  template(\"$MSG\\n\");\n  template_escape(no);\n};\n\ndestination d_imp {\n  file(\"/home/rpr/syslog.log\" template(t_imp));\n};\n\n\nA: If you do not want to enable the template-escape(), it can also be done with an inline template:\ndestination d_file {\n    file (\"/var/log/messages\" template(\"${MESSAGE}\\n\") );\n};\n\n", "Q: while installing ubuntu 15.10 alongside windows 8 I want to install Ubuntu alongside my windows 8 in D:/.My windows is installed in C:/.I have shrinked the D:/ for the installation.I have turned off the fast booting options,but I didn't got the UEFI settings. I started booting the system with  with bootable DVD,but it is showing error failed to load ldlinux.c32 .\nBoot Failed :press a key to retry.\n\nA: The set up of 15.10 was not proper.The booting DVD doesn't contains any '.exe' files.so it was showing message of boot failed.I have now installed the Ubuntu 14.04 LTS which is running perfectly with windows.\n", "Q: Popup dialogs transparent instead of showing any content I used to think this was just an Eclipse bug, but it persist even after switching to IntelliJ Idea. I think this happens on other programs as well, but less frequently, and obviously matters far less.\n\nIs there any workaround for this or do I just have to switch OS or something? I tried disabling compiz window fading but that didn't do any help.\nOS: Ubuntu 15.10\nWM: Whatever version of unity that ships with the above\nHW: Dell Latitude E7250 (non-touch, HD screen)\n\nA: I have sometimes had a situation like this happen to me. Along with an equally irritating black dialog version.\nI found a solution in the answer to this question: 13.10 - Black borders, black terminal\nWhich was to restart unity. Pop open a terminal window and:\nsetsid unity\n\nAfter things settle down, most dialog issues generally seem to have sorted themselves out.\n", "Q: is the current Adobe Flash 'ransomware vulnerability' affecting Ubuntu users? Currently there is an important release from Adobe telling users to update their Flash after learning of certain vulnerabilities where users computer are infected with ransomware. One of the many news articles about the issue can be seen HERE.\nMy question is, how does this affect Ubuntu users using Google Chrome, Mozilla Firefox, and other web browsers that use Adobe Flash?\n\nA: Ubuntu is affected the same way as the other vulnerable OSs: Windows, Macintosh, Linux, and Chrome OS. \n\nSuccessful exploitation could cause a crash and potentially allow an \n  attacker to take control of the affected system.\n\nIn other words, Ubuntu is as exploitable as the the rest of the systems running the vulnerable Flash plugin. Flash for Linux has been updated to version 11.2.202.616, and is available through the repositories.\ninfo source\n", "Q: How secure is the chromium browser compared to chrome? Now that chrome has ended support for 32 bit linux, I was wondering if chromium is as secure and as reliable as chrome. If not what changes can be made to chromeium?\n\nA: Chromium is almost exactly the same as Chrome - Chrome uses Chromium as a base and adds a few proprietary Google things to it, which can't be added to the open-source Chromium. These are things like the Flash player, PDF viewer, and certain video codecs. See this Reddit post for more. \nAs for 32 vs 64 bit - unless you're using a very old computer, you should be using a 64 bit operating system. \n", "Q: Dual boot Ubuntu with windows10 I've a old laptop with 500 GiB SATA HDD (blank) and 4GiB RAM. And I want to dual boot with Ubuntu 12.04 and windows 10. By giving 50 GiB for Windows and remaining to Linux. I've setup a 50GiB NTFS for win, 101 GiB /, 10GiB swap, 40MiB EFI boot, and remaining for /home. But after installation the Ubuntu goes to grub rescue mode. Now as I don't have any data in it, I'm going to reinstall Linux, but now which partitions do I need to set up? As there are so many operations like /recovery, /home, /, fat16, /fat32, /windows, /dos, etc.\n\nA: i used this way to install my ubuntu 14.04 next to my windows 10 on my 750 gig laptop\ninstall windows 10 like normal (taking the whole hard drive )\nthen insert the ubuntu disk/usb you have and start in try ubuntu (important!)\nafter that launch the desktop install and select install nexto windows or do your partitions manually (which i havent tried)\nnext when the install is finished do not reboot right away, open up your terminal and type:\nsudo su\napt-get install efibootmgr \nefibootmgr\n\nand then make sure that ubuntu is first boot, you might need to edit that in your BIOS, after that you are good to go :)\n", "Q: Need a simple program to poll and display language in X I need a simple program to display information for me on screen.  For example, I want a tiny box in the corner to tell me what the current language is.\nI envision that the program would just run a script every few seconds or otherwise get updated.\nI use fvwm, not gnome or other window managers that have a dock so I need something that will work with a vanilla Xwindows.\nIs there something like this?\n\nA: Normally the current language is displayed in the system tray by the input method editor.  For example, ibus or fcitx.  And if you have a system tray application, it will be in there.\nIf you wanted to get the layout without using the input method, you could shell out to setxkbmap such as from here.\nWhatever commands you want to run you could either do it from FvwmScript or just update a button in FvwmButtons.\nFor just the language one, add this to your fvwm config:\nDestroyModuleConfig FvwmButtonLanguage: *\n*FvwmButtonLanguage: (Id button0, Title \"ZZ\")\n\nThen you can either schedule a periodic task for it (also in your fvwm config):\nSchedule 1000 PipeRead \"echo SendToModule FvwmButtonLanguage ChangeButton button0 Title $(setxkbmap -query | grep layout | cut -f2 -d: )\"\n\nOr run a script (assuming you have Module FvwmCommandS loaded in your start function) to update the button that contains the following:\n while true ; do FvwmCommand \"SendToModule FvwmButtonLanguage ChangeButton button0 Title $(setxkbmap -query | grep layout | cut -f2 -d: )\" ; sleep 1 ; done\n\nIf you update your question to provide another example, I'll update this answer with a thorough example.\n", "Q: How to install the latest clamav? There is a warning in my country that this trojan infected computers over a news site (The Trojans name is GOZI). \nI used clamav but it says it is not the latest version.\nHow to install the latest version of clamav?\n\nA: Uninstall clamav and clamtk repository version:\nsudo apt-get purge clamav clamtk\n\nFirst you will need some dependencies and build tools: \nsudo apt-get install openssl build-essential libssl-dev checkinstall\n\nDownload this file, it will go to your /home:\nwget https://www.clamav.net/downloads/production/clamav-0.99.1.tar.gz\n\nExtract that file and change to the folder it created:\ntar -xvzf ~/clamav-0.99.1.tar.gz\ncd ~/clamav-0.99.1\n\nNow run the following commands to build clamav 0.99.1:\n./configure\nmake\n\nNow build a package with\nsudo checkinstall\n\ncheckinstall will guide you through the building of a .deb package and when it is done run\nsudo dpkg -i ~/clamav-0.99.1/clamav_0.99.1-1_amd64.deb\n\nNow it is installed but you may face errors about a config file, if you do run these commands (Thanks to user Terrance on this question for this, if you use it give him a vote)\nsudo dpkg-reconfigure clamav-freshclam\n\nJust keep pressing Enter to use default settings, then run\nsudo rm -f /usr/local/etc/freshclam.conf\nsudo ln -s /etc/clamav/freshclam.conf /usr/local/etc/freshclam.conf\n\nNow you can run a\nsudo clamscan -r /\n\nTo do a scan.\nTested on 15.10.\n\nA: Excerpt from http://www.govcert.admin.ch/blog/21/20min.ch-malvertising-incident\nThe infection chain is as follows:\n\n\n*\n\n*The swf file on 20min.ch contains an embedded Javascript which does a basic fingerprint using User Agent and Cookie. Based on this information a decision is made whether to redirect to the infection site or not.\n\n*Redirect to the exploit Kit where a VB Script is downloaded with another check which exploit would suit the target\n\n*Infect the device with Gozi in the form of a .dll that is made persistent via registry key (rundll) under HKEY\\CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Run. The dll resides in the %APPDATA% folder of the user.\n\n", "Q: mysql not getting installed I installed mysql with the following command sudo apt-get install mysql-server and it got installed correclty.then i uninstalled it by refering this link\nhttps://stackoverflow.com/questions/10853004/removing-mysql-5-5-completely\nfirst answer,\nthen tried install 5.0.96 fro their official site doenloading the rpm, converting to deb, and installing it, it failed, again i purged everything rebooted and tried to install with the same old command\nsudo apt-get install mysql-server\n\nbut every thing will go correclty till this place and will get stuck i waited for about an hour, \nthis is the terminal log\nmukund@mukund-ThinkPad-Edge-E431:~$ sudo apt-get install mysql-server\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following extra packages will be installed:\nlibdbd-mysql-perl libmysqlclient18 mysql-client-5.5 mysql-client-core-5.5\n mysql-common mysql-server-5.5 mysql-server-core-5.5\nSuggested packages:\n tinyca mailx\nThe following NEW packages will be installed:\n libdbd-mysql-perl libmysqlclient18 mysql-client-5.5 mysql-client-core-5.5\n mysql-common mysql-server mysql-server-5.5 mysql-server-core-5.5\n 0 upgraded, 8 newly installed, 0 to remove and 30 not upgraded.\n Need to get 0 B/8,351 kB of archives.\n After this operation, 94.1 MB of additional disk space will be used.\n Do you want to continue? [Y/n] y\n Preconfiguring packages ...\nSelecting previously unselected package mysql-common.\n(Reading database ... 235747 files and directories currently installed.)\nPreparing to unpack .../mysql-common_5.5.47-0ubuntu0.14.04.1_all.deb ...\nUnpacking mysql-common (5.5.47-0ubuntu0.14.04.1) ...\nSelecting previously unselected package libmysqlclient18:amd64.\nPreparing to unpack    .../libmysqlclient18_5.5.47-0ubuntu0.14.04.1_amd64.deb ...\nUnpacking libmysqlclient18:amd64 (5.5.47-0ubuntu0.14.04.1) ...\nSelecting previously unselected package libdbd-mysql-perl.\nPreparing to unpack .../libdbd-mysql-perl_4.025-1_amd64.deb ...\n Unpacking libdbd-mysql-perl (4.025-1) ...\nSelecting previously unselected package mysql-client-core-5.5.\nPreparing to unpack .../mysql-client-   core-5.5_5.5.47-0ubuntu0.14.04.1_amd64.deb ...\nUnpacking mysql-client-core-5.5 (5.5.47-0ubuntu0.14.04.1) ...\nSelecting previously unselected package mysql-client-5.5.\nPreparing to unpack .../mysql-client- 5.5_5.5.47-0ubuntu0.14.04.1_amd64.deb ...\nUnpacking mysql-client-5.5 (5.5.47-0ubuntu0.14.04.1) ...\nSelecting previously unselected package mysql-server-core-5.5.\nPreparing to unpack .../mysql-server-core-5.5_5.5.47-0ubuntu0.14.04.1_amd64.deb ...\nUnpacking mysql-server-core-5.5 (5.5.47-0ubuntu0.14.04.1) ...\nProcessing triggers for man-db (2.6.7.1-1ubuntu1) ...\nSetting up mysql-common (5.5.47-0ubuntu0.14.04.1) ...\nSelecting previously unselected package mysql-server-5.5.\n\n\n\n\n(Reading database ... 235938 files and directories currently installed.)\nPreparing to unpack .../mysql-server- 5.5_5.5.47-0ubuntu0.14.04.1_amd64.deb ...\nUnpacking mysql-server-5.5 (5.5.47-0ubuntu0.14.04.1) ...\nSelecting previously unselected package mysql-server.\nPreparing to unpack .../mysql-server_5.5.47-0ubuntu0.14.04.1_all.deb ...\nUnpacking mysql-server (5.5.47-0ubuntu0.14.04.1) ...\nProcessing triggers for man-db (2.6.7.1-1ubuntu1) ...\nProcessing triggers for ureadahead (0.100.0-16) ...\nureadahead will be reprofiled on next reboot\nSetting up libmysqlclient18:amd64 (5.5.47-0ubuntu0.14.04.1) ...\nSetting up libdbd-mysql-perl (4.025-1) ...\nSetting up mysql-client-core-5.5 (5.5.47-0ubuntu0.14.04.1) ...\nSetting up mysql-client-5.5 (5.5.47-0ubuntu0.14.04.1) ...\nSetting up mysql-server-core-5.5 (5.5.47-0ubuntu0.14.04.1) ...\nSetting up mysql-server-5.5 (5.5.47-0ubuntu0.14.04.1) ...\n160407 14:27:27 [Warning] Using unique option prefix key_buffer instead of key_buffer_size is deprecated and will be removed in a future release. Please use the full name instead.\n160407 14:27:27 [Warning] Using unique option prefix key_buffer instead of key_buffer_size is deprecated and will be removed in a future release.  Please use the full name instead.\n160407 14:27:27 [Note] /usr/sbin/mysqld (mysqld 5.5.47-0ubuntu0.14.04.1-log) starting as process 2327 ...\n\nand said an error message about password, says that user already exists i clicked ok, then nothing.......\nplease help me in this matter    \nthis is the mysql/error.log\n160408 15:05:46 [Warning] Using unique option prefix myisam-recover instead of myisam-recover-options is deprecated and will be removed in a future release. Please use the full name instead.\n160408 15:05:46 [Note] Plugin 'FEDERATED' is disabled.\n/usr/sbin/mysqld: Table 'mysql.plugin' doesn't exist\n160408 15:05:46 [ERROR] Can't open the mysql.plugin table. Please run mysql_upgrade to create it.\n160408 15:05:46 InnoDB: The InnoDB memory heap is disabled\n160408 15:05:46 InnoDB: Mutexes and rw_locks use GCC atomic builtins\n160408 15:05:46 InnoDB: Compressed tables use zlib 1.2.8\n160408 15:05:46 InnoDB: Using Linux native AIO\n160408 15:05:46 InnoDB: Initializing buffer pool, size = 128.0M\n160408 15:05:46 InnoDB: Completed initialization of buffer pool\n160408 15:05:46 InnoDB: highest supported file format is Barracuda.\n160408 15:05:46  InnoDB: Waiting for the background threads to start\n160408 15:05:47 InnoDB: 5.5.47 started; log sequence number 1595675\n160408 15:05:47 [ERROR] /usr/sbin/mysqld: unknown option '--skip-locking'\n160408 15:05:47 [ERROR] Aborting\n\n160408 15:05:47  InnoDB: Starting shutdown...\n\n\nA: Try:\nsudo service mysql stop\n\nthen:\nsudo apt-get purge mysql-server\nsudo apt-get autoremove\nless /etc/passwd\n\nCheck right at the bottom if there is a mysql user. If there is:\nsudo userdel mysql\n\nAfter all this is done, try to install Mysql again using the command  you used previously.\n\nA: Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2) \nthe error occur when mysql service not start.\nno need to remove mysql.\nplease follow mentioned below steps:\n $ sudo su \n/etc/init.d/mysql start\n", "Q: How to set path for the Tomcat7 user I'm trying to install an extension for GeoServer. The instructions say:\n\nCreate a GDAL_DATA environment variable to the folder where you have extracted this file. Make also sure that this directory is reachable and readable by the application server process’s user.\n\nand later (for a different file):\n\nIf you are on Linux, be sure to set the LD_LIBRARY_PATH environment variable to refer to the folder where the SOs are extracted.\n\nI'm not sure where to set these variables. In /etc/init.d/tomcat7 perhaps?\n\nA: Yes, this did work, using export:\nPATH=/bin:/usr/bin:/sbin:/usr/sbin\nexport GDAL_DATA=/mnt/gdal/gdal-data\nexport LD_LIBRARY_PATH=/mnt/gdal\nNAME=tomcat7\nDESC=\"Tomcat servlet engine\"\n....\n\n", "Q: Ubuntu and Kali on the same USB stick In the last couple of years I have been running Ubuntu (full installation) from my old 64GB USB 3.0 on my native Windows laptop: on system startup, from Windows bootloader, I can choose to boot from USB and this would load my grub bootloader that I previously installed on the same USB drive. So far, so good.\nI recently bought a way more performant 256GB USB 3.0. What I'd like to do now is to have the possibility to choose between Ubuntu or Kali from grub when booting from USB.\nThe steps to achieve this configuration are not clear to me, actually I don't even know if it is a feasible thing.\nI do not want to boot Kali from a different USB than the one where Ubuntu is running, mainly because I only have one USB 3.0 port on my laptop and this pendrive has such a huge capacity that I don't need all this space for a single OS.\nAt first I thought about installing Ubuntu on my new USB, then using dd to install the Kali iso on a USB partition that I can create during Ubuntu's installation procedure, but then I thought this would probably fail, trying to erase completely the pendrive.\nAm I mistaken? Any help is really appreciated.\n\nA: let me know if I'm mistaken... you want a persistant version of ubuntu and kali on a usb stick and to be able to switch between the two during bootup using grub...  Here's what you should do:\n\n\n*\n\n*kali has issues installing from usb sticks so unless you resolved that issue i reccomend taking you kali distro and putting it on a cd in order to get it to properly install to your USB. make sure grub for kali goes to usb stick.\n\n*install ubuntu to usb stick... overwrite the grub from kali on stick and ubuntu should detect kali... if it doesn't you may need to use some grub editor to add a second boot and basically change the partition it boots to...\nif i'm wrong then Ahmed Jerbi probably has your answer.\nGood luck and hope you are successful in this endevor!\n", "Q: List all environment variables, and show if they are exported or not (This question is similar to this one and this one, but with the added requirement that I would like to know if variables are exported or not)\nI am in bash, Ubuntu 14.04.4 LTS. I would like to:\n\n\n*\n\n*list all environment variables\n\n*for each variable, I would like to see if it is exported or not\n\n\nAdditionally, I would like to list only the exported environment variables.\n\nA: Use the declare builtin:\n$ help declare\ndeclare: declare [-aAfFgilnrtux] [-p] [name[=value] ...]\n    Set variable values and attributes.\n\n    Declare variables and give them attributes.  If no NAMEs are given,\n    display the attributes and values of all variables.\n\n    Options:\n      -f    restrict action or display to function names and definitions\n      -F    restrict display to function names only (plus line number and\n        source file when debugging)\n      -g    create global variables when used in a shell function; otherwise\n        ignored\n      -p    display the attributes and value of each NAME\n\n    Options which set attributes:\n      -a    to make NAMEs indexed arrays (if supported)\n      -A    to make NAMEs associative arrays (if supported)\n      -i    to make NAMEs have the `integer' attribute\n      -l    to convert NAMEs to lower case on assignment\n      -n    make NAME a reference to the variable named by its value\n      -r    to make NAMEs readonly\n      -t    to make NAMEs have the `trace' attribute\n      -u    to convert NAMEs to upper case on assignment\n      -x    to make NAMEs export\n\nAccordingly:\n$ declare -p\ndeclare -- BASH=\"/usr/bin/bash\"\ndeclare -r BASHOPTS=\"checkwinsize:cmdhist:complete_fullquote:expand_aliases:extglob:extquote:force_fignore:histappend:interactive_comments:nullglob:progcomp:promptvars:sourcepath\"\ndeclare -ir BASHPID\ndeclare -A BASH_ALIASES='()'\ndeclare -a BASH_ARGC='()'\ndeclare -a BASH_ARGV='()'\ndeclare -A BASH_CMDS='()'\ndeclare -- BASH_COMMAND\ndeclare -r BASH_COMPLETION_COMPAT_DIR=\"/etc/bash_completion.d\"\ndeclare -a BASH_LINENO='()'\ndeclare -a BASH_SOURCE='()'\ndeclare -- BASH_SUBSHELL\ndeclare -ar BASH_VERSINFO='([0]=\"4\" [1]=\"3\" [2]=\"42\" [3]=\"1\" [4]=\"release\" [5]=\"x86_64-unknown-linux-gnu\")'\ndeclare -- BASH_VERSION=\"4.3.42(1)-release\"\ndeclare -x CDPATH=\":/home/muru\"\ndeclare -x COLORTERM=\"gnome-terminal\"\ndeclare -- COLUMNS=\"237\"\ndeclare -- COMP_WORDBREAKS\ndeclare -x CONFLOCAL=\"laptop\"\ndeclare -x DBUS_SESSION_BUS_ADDRESS=\"unix:path=/run/user/1000/bus\"\ndeclare -x DESKTOP_AUTOSTART_ID=\"10abca3e1337cb662146002998494759100000008000003\"\ndeclare -x DESKTOP_SESSION=\"gnome\"\ndeclare -a DIRSTACK='()'\ndeclare -x DISPLAY=\":0\"\ndeclare -x EDITOR=\"vim\"\n…\n\nTo see just exported environment variables, use declare -px:\n$ declare -px\ndeclare -x CDPATH=\":/home/muru\"\ndeclare -x COLORTERM=\"gnome-terminal\"\ndeclare -x CONFLOCAL=\"laptop\"\ndeclare -x DBUS_SESSION_BUS_ADDRESS=\"unix:path=/run/user/1000/bus\"\ndeclare -x DESKTOP_AUTOSTART_ID=\"10abca3e1337cb662146002998494759100000008000003\"\ndeclare -x DESKTOP_SESSION=\"gnome\"\ndeclare -x DISPLAY=\":0\"\ndeclare -x EDITOR=\"vim\"\ndeclare -x GDMSESSION=\"gnome\"\n…\n\nOr use external commands, like env, printenv, or:\nawk 'BEGIN{for (i in ENVIRON) {print i}}'\nperl -e 'print \"$_\\n\" for keys(%ENV)'\npython -c 'import os; [print(k) for k in os.environ.keys()]'\n\n", "Q: Secure boot screen pops up. How do I get past it? Hi what do I need to do to get past the secure boot screen? It says to press ok but the screen just keeps popping up.  Anyone help please???!!\n\nA: Go into BIOS and disable \"Secure Boot\".\n", "Q: Weird sda3 partition - did Ubuntu intentionally reserve space on SSD drive? I see weird ~15 Gb of unused space on my 512 Gb SSD drive:\n\nI'm pretty sure that during installation I choose \"use entire disk and don't bother me with stupid questions\" option. I didn't create a swap partition, besides I think it would be marked as swap in this case. Could it be some sort of recovery partition left from previous Windows installation? \nOr Ubuntu just reserved some disk space to prolong SSD live? I just run smartctl and so far disk looks quite healthy - no relocations in two years http://afiskon.ru/s/8c/bfd409af71_smart.txt\nDoes anyone have an idea what is sda3 for? Is it safe to delete sda3 and enlarge sda2 partition?\n\nA: Well I checked /etc/fstab:\n# swap was on /dev/sda3\n#UUID=b04d45f1-b892-4700-8f68-f1ad1ca21fbf none  swap sw 0 0\n#/dev/mapper/cryptswap1 none swap sw 0 0\n\nTurned out it was a swap partition. I solved all my problems using Ubuntu bootable USB stick and gparted.\n", "Q: Holding \"Backspace\" deletes only one character I don't know what I've done, but when I press and hold the key \"Backspace\" it just deletes only 1 character and stops. This is everywhere: in the console, Chrome, Text editors.\nI'm running Ubuntu 14.04 LTS.\n\nA: The xset utility can be used to enable keyboard repeat. It works on the X.org level, so should override whatever the distribution is doing wrong.\nTo enable keyboard repeat, execute:\nxset r on\n\nFor details, see man xset.\n\nIt worked for me on Ubuntu 18.04.\n\n\nA: Go to unity-control-center keyboard and make sure keyboard repeat is enabled    \nor use gsettings to change value:   \ngsettings set org.gnome.desktop.peripherals.keyboard repeat true\n\n", "Q: How to keep record of Logins and Actions I've just created a Windows Server 2012 Domain and I inserted an ubuntu 14.04LTS laptop in the domain, which is responsible for file exchanging with a USB between the domain users. How can I keep a record of the domain's users logins, and their actions (e.g., transferred 2 files from FOLDER to removable disk)?\nIs there any way that I can keep record of which files were transferred between a USB and my Pc for each user who logs on my Ubuntu?\n\nA: Logins are traceable via last and lastb command, actions requiring sudo privilege  are traceable via /var/log/auth.log , but anything that is a normal , unprivileged action  is untraceable , at least if it's done via GUI.  Command line is traceable via user's history file, if and only if they've not fiddled with history file. You could spawn script command to be logging the  whole command-line session to a file other than history, but that is also not a bullet proof solution.\nEssentially , the answer is you can trace logins , but not the unprivileged actions and only if logs were not fiddled with\n", "Q: Ubuntu 14.04 hangs after logging in, not a video problem I was recovering some data off a usb drive and Ubuntu warned of 0 space left. I emptied the trash and shut down. \nTurned back on and after login it just hangs. Thought it might be a space issue so Ctrl-Alt-F2 and deleted a 1 GB file and emptied the trash. \nRebooted and still hangs after login. Is there a log file somewhere that will tell me why it is hanging? Everything worked perfectly prior to this. \n\nA: Dropped down to command line and found SDA5 was full. Removed 30GB of files and could log in again.\n", "Q: After installing i3 I now have the i3 notification theme on unity. How can I change it back? I installed i3 alongside unity but now I see the i3 notification box while on unity.\n\nHow can I change this back to the unity one without removing i3? The other solutions to this problem seem to be removing the other WM/DE\n\nA: For me this worked, I'm running Ubuntu 16.04\nrun the following commands withsudo\ncreate a file /usr/bin/user_notify and write\nthe following text to the file.\n#!/bin/bash\nset -euo pipefail\nif pgrep -x i3 >/dev/null ; then\n  /usr/bin/dunst\nelse\n  /usr/lib/x86_64-linux-gnu/notify-osd\nfi\n\nmake the file executable by running chmod a+x /usr/bin/user_notify\nopen the file /usr/share/dbus-1/services/org.knopwob.dunst.service\nand replace Exec=/usr/bin/dunst by Exec=/usr/bin/user_notify\nRemark To use the standard unity notifier (also in i3) just\nreplace Exec=/usr/bin/dunst by Exec=/usr/lib/x86_64-linux-gnu/notify-osd\nin the file /usr/share/dbus-1/services/org.knopwob.dunst.service. \n\nA: For me, inspired by the other answers, sudo apt remove dunst and logging out and in again was sufficient.\n", "Q: Select multiple non-consecutive files in Nautilus using only the keyboard My workflow relies almost a 100% on the keyboard. Therefore I would like to be able to select multiple non-consecutive files in Nautilus using only the keyboard. I know that:\n\n\n*\n\n*I can select multiple consecutive files pressing down shift at the first item and the go down with the arrow keys until the last item. \n\n*I can select multiple non-consecutive files pressing down ctrl and clicking on each desired item with the mouse. \n\n\nI would like to replace the mouse-clickings with something easy on the keyboard...any suggestions?\n\nA: When you keep holding down the ctrl key and press space you can move around with the arrow keys and select no consectuive files. Only downside of that, at least for me is, i dont have a file selection when moving and have to count the files, but that can be the case that im using an pretty old Laptop.\n", "Q: Ubuntu 14.04 dispaly resolution problem I am using Ubuntu for quite a while now. Just scrolling through the display settings I noticed that the screen resolution only gives me two options 1024x768 and 800x600 in a 4:3 aspect ratio while my monitor is capable of 1366x768 resolution at 60 hertz.\nI do not have any external GPU, it's just Intel G41 onboard graphics.\n\nA: You should install the proper display drivers.\nEnter in System Configuration -> Software and updates, in the Additional drivers tab you should see a list with some Intel-GPU drivers (these used to be privatives).\nChoose the most recent one and apply changes. Restart and you should be able to choose your screen resolution.\n", "Q: What should be in the \"misc-depends:\" in a control file? Lintian gives error without \"misc-depends:\" in the control file.\n W: brightness-controller source: debhelper-but-no-misc-depends brightness-controller\n\nWhat should be supposed to be in it? Every else works fine without it.\n\nA: \"misc-depends\" is not a field in the debian/control file, but infact a variable that dh_gencontrol will substitute during the build of the binary package. As the New Maintainer's Guide says:\n\nSome debhelper commands may cause the generated package to depend on\n  some additional packages. All such commands generate a list of\n  required packages for each binary package. This list is used for\n  substituting ${misc:Depends}.\n\nIn practice, it looks like:\nDepends: libfoobar, ${shlibs:Depends}, ${misc:Depends}\n\n", "Q: Error while upgrading from 15.04 to 15.10 while running the upgrade a pop-up window appeared with the message\n\"The upgrade has aborted. Your system could be in an unusable state. A \nrecovery will run now (dpkg --configure -a).\"\nAfter clicking \"Ok\", I was waiting for >30 min but nothing happens, the distribution upgrade is just stuck, and I can't figure out what exactly the error is (see screenshot).\nDistribution Upgrade -- Screenshot\nI found some similar problems e.g. here or here but at least there was an error traceback, which I don't have.\nShould I abort the distribution upgrade, then try manually fixing the packages and then reboot?\nThanks in advance!\n\nA: Try clearing the cache with -\nsudo apt-get clean\n\n", "Q: File/folder protection that even government cannot break If I have some intellectual property file that under no circumstances my competition can view, what is the best and most secure way to protect them?\nI know that there are many encryption apps for Ubuntu, but they all seem basic ones. \nIs there any service that I can use that even the best hacker cannot decipher?\n\nA: First and foremost, I believe there isn't any encryption which can be deemed 100% secure. The reason for that is, it is human made. Despite that the evolution of hardware in the past 20 years has prooven that nothing is secure forever. Best example is here the long time deemed secure md5 one way encryption.\nBut back to your question, your best security is physical disconection from the internet, and maybe using even GnuPG to encrypt , but then use a very big key and store the key on a USB apart from the file.\nAnd when you now think \"Ok, im good at 'whatever programming language, you name it', I'm going to implement myself some encryptions\", you should have a decent knowlegde of that whole encryption process, because a wrong made implementation is as bad as no encryption at all.\nSee encryption more like house door locks, they are made to prolong the time and efford to invest to break in.\nSo best course of action:\n\n\n*\n\n*keep your file disconnected, store it on an external harddrive.\n\n*keep your file encrypted.\n\n*use a large keypair (4096 size)\n\n*store your private key apart from the harddrive on a second medium.\n\n*if you fear your competitor breaks into your home/company, get big bad\ndogs and an alarm system or store the drive with file in a bank deposit.\n\n", "Q: Add winetricks registry key by command line In some special cases, I have to add a registry key to wine. Is it possible to do so using the command line, and how?\nHere are the steps I do from GUI:\nwine regedit\n\n\n\n*\n\n*On the left, open HKEY_CURRENT_USER, then open Software\n\n*Right click on Wine -> New -> Key (named Direct3D)\n\n*Right click on Direct3D -> New -> String Value (named VideoMemorySize, double click on it and set it 1024\n\n\n\n\nA: This is a standard winetricks configuration item:\n\nSo, you can do:\n$ winetricks videomemorysize=1024\n------------------------------------------------------\nYou are using a 64-bit WINEPREFIX. If you encounter problems, please retest in a clean 32-bit WINEPREFIX before reporting a bug.\n------------------------------------------------------\nExecuting w_do_call videomemorysize=1024\nExecuting load_videomemorysize 1024\nSetting video memory size to 1024\nExecuting winetricks_early_wine regedit C:\\windows\\Temp\\_videomemorysize=1024\\set-video.reg\n\n", "Q: \"mising software and update tools\" After installing Ubuntu 12.04 64bit, I can't find \"software and update tools\" from dash or system settings. How to install it? I need it to check my wireless network adapter because it is not recognised by Ubuntu.\n\nA: You can fix missing items in your setting or control panel by uninstalling and reinstalling the control center.\nunity-control-center\nsudo apt-get remove unity-control-center && sudo apt-get install unity-control-center\n\nOr\nsud apt-get install --reinstall unity-control-center \n\nYou can reinstall the update manager by doing the following in a terminal please check if you have it first with \nupdate-manager\n\nIf not run updates and upgrade \nsudo apt-get update && sudo apt-get upgrade \n\nThen install.\nsudo apt-get install update-manager \n\nor\nsudo apt-get install --reinstall update-manager \n\n\nA: You must execute in terminal :\nsudo apt-get install software-properties-gtk \n\n", "Q: after installing ubuntu, system has become very slow I have Dell inspiron 15 R, 8GB RAM 1TB hard disk. I have only ubuntu 14.04 installed on it. But soon after installing, my system has become slow. I have tried reducing the swappiness to 10 from default 60 but still no use. Anything else that can be done..??\n\nA: I have the same computer, and use a different disk scheduler.  Ubuntu has cfq available, which works pretty well.  I no longer use cfq but instead use a custom kernel with another scheduler, but use cfq when loading new versions of Ubuntu until I can recompile the kernel.\nAdditionally, I do keep swappiness very, very low. (1)\nYou can enable cfq in two methods:\nTemporary method, form a terminal:\nsudo -i\ncd /sys/class/block/sda/queue\necho cfq > scheduler\nexit\n\nIf this helps you, and you want to make it a permanent change, if should be placed into grub.\nsudo nano /etc/default/grub\n\nLook for the line starting GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\" and modify it so that it reads\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash elevator=cfq\"\nExit nano (press ctrl-o then ctrl-x) and then enter the command\nsudo update-grub\nAfter a reboot, cfq will be enabled which you can detect by\ncat /sys/class/block/sda/queue/scheduler\n\n", "Q: Issues with Ubuntu non-ISO-Hybrid iso images When I try to install Ubuntu from a USB drive after I added the latest ubuntu 15.10 iso image to the USB drive using Pendrivelinux I am getting this error:\nmount: mounting /dev/loop0 on //filesystem.squashfs failed: No such device\nCan not mount /dev/loop0 (/cdrom/casper/filesystem.squashfs) on //filesystem.squashfs\n\nIt seems that although the iso was added to a USB drive using a tool that is mainly made to do such process but Ubuntu is trying to mount the files on the CDROM while I am actually trying to install from a USB drive, after some reading I found out that the ISO files needs to be Hybrid ISO files in order to be able to use it from a USB drive and starting some later Ubuntu versions they are not producing these hybrid iso files anymore which is a bit strange since a lot of modern laptops now come without a CD/DVD drive\nIt seems that a number of the forums discussing the resolution for this issue are suggesting using the isohybrid Linux command which ignores the fact that some users might be actually installing Ubuntu for the first time (like myself) and all they have is a Windows system :(\n\nA: did you use Universal USB Installer? or another tool on PenDriveLinux... if that didn't work I suggest you use YUMI as it is what I use and it always* works\n", "Q: Ubuntu 15.10 slow boot My Ubuntu 15.10 is booting very slow. This is my dmesg output:\n...\n[   10.045029] VBoxPciLinuxInit\n[   10.048193] vboxpci: IOMMU not found (not registered)\n[   10.396115] Bluetooth: BNEP (Ethernet Emulation) ver 1.3\n[   10.396118] Bluetooth: BNEP filters: protocol multicast\n[   10.396122] Bluetooth: BNEP socket layer initialized\n[   10.411786] Bluetooth: RFCOMM TTY layer initialized\n[   10.411792] Bluetooth: RFCOMM socket layer initialized\n[   10.411797] Bluetooth: RFCOMM ver 1.11\n[   11.866507] [drm:intel_set_pch_fifo_underrun_reporting [i915]] *ERROR* uncleared pch fifo underrun on pch transcoder A\n[   11.866536] [drm:intel_pch_fifo_underrun_irq_handler [i915]] *ERROR* PCH transcoder A FIFO underrun\n[   94.430576] cfg80211: Regulatory domain changed to country: SK\n[   94.430579] cfg80211:  DFS Master region: ETSI\n[   94.430580] cfg80211:   (start_freq - end_freq @ bandwidth), (max_antenna_gain, max_eirp), (dfs_cac_time)\n[   94.430582] cfg80211:   (2402000 KHz - 2482000 KHz @ 40000 KHz), (N/A, 2000 mBm), (N/A)\n[   94.430583] cfg80211:   (5170000 KHz - 5250000 KHz @ 80000 KHz, 160000 KHz AUTO), (N/A, 2000 mBm), (N/A)\n[   94.430584] cfg80211:   (5250000 KHz - 5330000 KHz @ 80000 KHz, 160000 KHz AUTO), (N/A, 2000 mBm), (0 s)\n[   94.430586] cfg80211:   (5490000 KHz - 5710000 KHz @ 160000 KHz), (N/A, 2700 mBm), (0 s)\n[   94.430587] cfg80211:   (57000000 KHz - 66000000 KHz @ 2160000 KHz), (N/A, 4000 mBm), (N/A)\n\nI think that problem is somewhere about 94 second, but I have no idea how to solve it. \n\nA: There seems to be a few bugs in linux kernel relating to this:\nhttps://bugzilla.kernel.org/show_bug.cgi?id=95461\n", "Q: OpenStack AutoPilot failing at 98% I'm trying to deploy OpenStack using Landscape's Autopilot. I get no errors till the final steps but after reaching 98% of the install two tasks fail to completed. \nThe two tasks that never reach completeion are: \n\"Add ubuntu-12.04-server-cloudimg-amd64-disk1 to Glance\"\n\"Add ubuntu-14.04-server-cloudimg-amd64-disk1 to Glance\"\n\nA: Those images are downloaded from the Internet to make Ubuntu available in the Horizon dashboard to launch cloud instances with. Autopilot is trying to put them in place before your first login.\nCan your newfangled OpenStack setup connect to the Internet? \n", "Q: I can't see the next button (ubuntu installation on vmware) I am trying to install Ubuntu 64-bit on my VMWare Workstation 12. I have already done this on my desktop.\nThe problem is when I try to install it on my laptop, I cannot see the next button. The next button was only partially visible on my desktop as well. I am stuck at the \"who are you\" part.\n\nA: Use the Tab key to move to the next button.  Pressing it a few times will cycle it through all buttons on the screen depending on where you are on said screen.\n\nA: I faced this in many occasions when using VirtualBox in low resolution, when dealing with both ubiquity (Ubuntu installer) or Debian installer.\n\n*\n\n*Alt+F7 to move window (do not click yet), then use either the mouse or keyboard arrow keys to move the window around until you can see the buttons.\n\n*Left-click when you have the window positioned where you want it. This will lock the window in place until the next time you press Alt+F7\n\nClick the required button or fill the needed info. You should only need to do this during the install phase, however. Many people have a subsequent issue after install of the screen size/resolution being too small and not adjusting with screen. This can be corrected by installing Guest Additions after installing Ubuntu.\n\nA: In the window where you are installing the Ubuntu VM, double click at the top and the window gets smaller. Now you can move the window around and get to the buttons.\n\nA: use the scroll bar on the side of vmware (may need to specify custom resolution). or when you make the image specify the iso and VMware should be able to auto-install ubuntu for you if my memory serves me right...\n\nA: Had same problem and got this answer online and it worked. Hold down left-Alt then left click anywhere in the window to move it.\n\nA: I have this same issue in ubuntu 16 gnome\n\n*\n\n*From live CD run like trial, not install\n\n*Then you can select your monitor size inside Ubuntu: left click and display settings\nNote: VBox will fit to this selected size\n\n*Install ubuntu as usual: Press 'windows button' from keyboard or activities from left/top corner and you can see from left menu the install shortcut\n\n", "Q: sftp public rsa key ubuntu 16.04 Why is there a different format when creating a public rsa key in Ubuntu 16.04 compared to Ubuntu 14.04?\nUbuntu 14.04\ntest@ubuntu:/etc/ssh$ ssh-keygen -lf ssh_host_rsa_key.pub \n2048 ad:e2:ec:56:c0:df:26:36:8a:a4:1e:64:8f:c6:84:4c  root@ubuntu (RSA)\n\nUbuntu 16.04\ntest@test-VirtualBox:/etc/ssh$ ssh-keygen -lf ssh_host_rsa_key.pub \n2048 SHA256:YWPFBWJYHxxy9FatUnzzsFiZ+QkSpWAKjAy3pZ2GL+Y root@test-VirtualBox (RSA)\n\nIs it possible to get same format in 16.04 as in 14.04?\n\nA: Well looked around and found a answer\nhttps://superuser.com/questions/929566/sha256-ssh-fingerprint-given-by-the-client-but-only-md5-fingerprint-known-for-se\nIt is still possible to create a md5 key with this command\nssh-keygen -lf ssh_host_rsa_key.pub -E md5\n\n", "Q: Problem installing Ubuntu 15.10 acer I can not install Ubuntu appears to me as it is shown in the picture\n\nSystem Information\n\nOS: Windows8.1\nPlease to help me quickly please.\n\nA: What did you do to get that screen?  (List the steps).\nHow did you get that screen.\nTry again.\nMake sure you completely shutdown windows.  Turn off fast booting.\nHold the shift key continuously when you select the power menu and shutdown.\nMake your ubuntu install disk with live linux installer.\nMake 500 mb persistent. \nLastly, you could wait two weeks for 16.04 (!)\n", "Q: No Network Connection - ifconfig shows only lo - lshw -c network says *-network unclaimed I got a new ThinkPad E460 with no OS installed, but had an ubuntu 13.10 USB stick around which I used to install ubuntu 13.10.\nThe OS works fine, however I can't connect to the internet through Ethernet or Wireless. (Also the clickpad won't work.)\nI am not very used to linux, but know a little how to use a shell.\nSo far, to solve my problem, I googled and found numerous approaches, of which none worked for me, but I found some things out.\nifconfig -a returns:\n\neth0      Link encap:Ethernet  HWaddr 02:cd:fe:b5:c4:17  \n          inet addr:172.20.10.3  Bcast:172.20.10.15  Mask:255.255.255.240\n          inet6 addr: fe80::cd:feff:feb5:c417/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:18970 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:18365 errors:2 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:12962022 (12.9 MB)  TX bytes:2967244 (2.9 MB)\n\nlo    Link encap:Local Loopback  \n      inet addr:127.0.0.1  Mask:255.0.0.0\n      inet6 addr: ::1/128 Scope:Host\n      UP LOOPBACK RUNNING  MTU:65536  Metric:1\n      RX packets:4564 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:4564 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:0 \n      RX bytes:451662 (451.6 KB)  TX bytes:451662 (451.6 KB)\n\n\nThe eth0 should be my iPhones Mobile Hotspot via Bluetooth.\nsudo lshw -c network returns:\n\n *-network UNCLAIMED     \n   description: Network controller\n   product: Intel Corporation\n   vendor: Intel Corporation\n   physical id: 0\n   bus info: pci@0000:01:00.0\n   version: 99\n   width: 64 bits\n   clock: 33MHz\n   capabilities: pm msi pciexpress bus_master cap_list\n   configuration: latency=0\n   resources: memory:f1200000-f1201fff\n *-network UNCLAIMED\n   description: Ethernet controller\n   product: Intel Corporation\n   vendor: Intel Corporation\n   physical id: 1f.6\n   bus info: pci@0000:00:1f.6\n   version: 21\n   width: 32 bits\n   clock: 33MHz\n   capabilities: pm msi bus_master cap_list\n   configuration: latency=0\n   resources: memory:f1300000-f131ffff\n *-network\n   description: Ethernet interface\n   physical id: 2\n   bus info: usb@1:3\n   logical name: eth0\n   serial: 02:cd:fe:b5:c4:17\n   capabilities: ethernet physical\n   configuration: broadcast=yes driver=ipheth ip=172.20.10.3 link=yes multicast=yes\n\n\nFrom what I understood, the UCLAIMED means a driver issue, however I failed to load them through backport. Loading a new Version of Ubuntu or any other OS is not possible, since I don't want to blow my phones data plan.\nFor now I have to leave, but will be back in about 2 hours. Any help will be greatly appreciated and any information needed to solve the problem, I will provide.\n\nA: According to the technical specifications, the ThinkPad E460 has newer intel networking hardware that (according to intel) is only properly supported in Linux kernel versions later than 4.2.\nTo see your exact networking hardware, open a terminal and run:\nlspci\n\nand look for \"Network Controller\" or \"Ethernet Controller\".  Your wifi controller will either be Intel 3165 (requires kernel 4.2 or later) or Intel 8260 (requires kernel 4.1 or later).\nTo see your current kernel version, run\nuname -r\n\nSince you are using Ubuntu 13.10, you will have kernel 3.11 by default.\nThere are several ways to upgrade your kernel, but the safest way is to use packages from the Ubuntu repositories.  Unfortunately, 13.10 has already reached end of life, and there do not appear to be any 4.2 kernel packages for that release.  You could try using the 14.04 packages, but they may or may not work.  If you want to try that, I would recommend you try to install these packages and restart:\n\n\n*\n\n*linux-headers-4.2.0-35\n\n*linux-headers-4.2.0-35-generic\n\n*linux-image-4.2.0-35-generic\n\n*linux-image-extra-4.2.0-35-generic\nIf the packages successfully install, but something goes wrong, and you restart and are not able to boot into the OS, hold down shift while booting up to get the Grub boot menu, and choose your old kernel version (3.11) from the menu.  You will then be able to remove the 4.2 kernel packages if they are not working.\n", "Q: Reduce size of pdf file with ocr and tables I have a scanned file, where text has been recognized already, yet it weights a whooping 80 mbytes.\nDuring the scanning process I did a silly thing such as scanning in grayscale.\nNow the pdf has a huge swarm of dash and stroke marks in it.\nI believe that the size comes from the fact that all those stains.\nSimple conversion with doesn't seem to be the solution here\nps -dPDFSETTINGS=/screen    \n\nThis results in fonts getting jagged and unpleasant to read.\nPretty much every other question about reducing size is solved by downsampling involving one or the other conversion that hurts text more than anything else.\nIs there a way to discard that background information and preserve the actual text?\n\nA: If you would like to have only the text, without much formatting, you could try this command:\nless yourfile.pdf >> output.txt\n\nIf the document did not have the \"swarm of dash and stroke marks\" in the original scan, I normally have great results with this site to reduce PDF size.  \n", "Q: Deja-dup does not resume from where it left after suspend I'm trying to do a backup of about 800GB of data using deja-dup. It looks like this to take about two days; when I tell deja-dup to \"resume later\", then suspend my laptop, then bring up deja-dup again, it does not offer me a \"resume previous backup\" option. From what I gather from the Internet it should automatically recognize where it left off and resume from there.\nHowever, it always starts a full scan, then deletes all previously created archives on the backup medium, and starts all over again.\nIs there a way to avoid this?\nI'm running on Ubuntu 14.04\nThank you,\nmischa\n\nA: It resumes from where you left off, it goes through all the files that it backed up first to ensure they did not change, then it resumes the backup.\n", "Q: investigation of librsvg-dev While testing the node-librsvg, which provides a node interface to\nconvert svg to png images using librsvg-dev, I realized that it works\nreally well on Ubuntu 12 , but some images can not be converted with\nUbuntu 14.\nNow, I'd like to track down the problem further.\nSince I never worked on a similar problem before I have some fundamental questions to start with:\n\n\n*\n\n*Is a bug tracker which could be used to report the\nproblem?\n\n*Is there a test suite to test the librsvg-dev package?\n\n*Is there a way to rebuild the package from the latests sources?\n\n\nA: Sometimes writing down the question helps\n1 -> https://bugs.debian.org/cgi-bin/pkgreport.cgi?pkg=librsvg2-dev;dist=unstable\n3 -> https://wiki.debian.org/BuildingTutorial and http :// ccm. net/faq/809-debian-apt-get-no-pubkey-gpg-error\n", "Q: Unity8 & Ubuntu 15.10 I use Ubuntu 15.10 on my Netbook and it works great. Now,I have a question. When I want to install Unity8 on an existing OS, will anything change on the software I already installed?\nThank you a lot.\n\nA: No, you can run multiple desktop environments: LXDE (included in Lubuntu), GNOME (included in Ubuntu GNOME), MATE (Ubuntu Mate), Unity (included in plain vanilla Ubuntu) without your underlying software being affected.\nThat being said, if you run KDE, some software might have to get more libraries pulled in but a simple sudo apt-get MySoftware --reinstall will accomplish that.\n", "Q: Websites erroneously believe I don't have Flash installed With Firefox, I have been to a number of websites, such as Hulu, for video streaming that return an error message that I don't have Flash installed. Well, of course I do. I can play YouTube videos fine. Hulu is a special case which also reports that I cannot play protected content, which may be a separate issue, but then it also states, erroneously, that I need to install Flash. How can this be resolved?\nAs requested in comments here is the output of apt-cache search adobe flash\ntexlive-latex-extra - TeX Live: LaTeX additional packages\nflashplugin-installer - Adobe Flash Player plugin installer\nflashplugin-downloader - Adobe Flash Player plugin installer (transitional package)\nflashplugin-nonfree-extrasound - Adobe Flash Player platform support library for Esound and OSS\nbleachbit - delete unnecessary files from the system\ncclive - lightweight command line video extraction tool\nkonqueror-nsplugins - Netscape plugin support for Konqueror\nlibjs-swfobject - tool to embed Flash content into webpages\nlibquvi-dev - library for parsing video download links (development package)\nlibquvi-doc - library for parsing video download links (documentation package)\nlibquvi-scripts - library for parsing video download links (Lua scripts)\nlibquvi7 - library for parsing video download links (runtime libraries)\nlibvdpau-va-gl1 - VDPAU driver with OpenGL/VAAPI backend\nnomnom - download videos from Youtube and other similar video websites\nquvi - command line program to extract video download links\nred5-doc - flash streaming server - documentation\nred5-server - flash streaming server\nadobe-flashplugin - Adobe Flash Player plugin\nadobe-flash-properties-gtk - GTK+ control panel for Adobe Flash Player plugin\nadobe-flash-properties-kde - KDE control panel Adobe Flash Player plugin\n\nSystem Info:\n\n\n*\n\n*The universe distribution component is enabled for all sources.\n\n*Flash plugin enabled in Firefox: Shockwave flash 11.2 r202 and 13.1\nr2\n\n*64-bit Ubuntu 14.04.4\n\n*Hardware (in case it matters): \n    * Acer Aspire laptop\n    * AMD A6-1450 APU w/ Radeon HD Graphics × 4\n    * Gallium 0.4 on AMD KABINI\n\n\nA: You have html5 plugin for firefox installed, which allows watching youtube videos, but sites like hulu do require flash.  You can verify that if you go to about:config and then Plugins in firefox, OpenH264 is what you're looking for\nTo install flash , run sudo apt-get install flashplugin-installer, but keep in mind that the latest version is 11.2.577 and Adobe removed support for Linux version of flash like since last year and it won't be supported anymore.\nNote that you must have multiverse repository  enabled in System Settings -> Software & Updates\nAlternatively, switch to pepper flash in Chrome\n", "Q: Why disabling \"Secure Boot\" is enforced policy when installing 3rd party modules When installing 16.04, I was asked to turn off \"Secure Boot\" if I wanted to install 3rd party modules/drivers.\nI did not comply.\nAnd when I installed manually the only 3rd party drivers I use (bcmwl-kernel-source), I was asked again (during the installation of the package) to turn off \"Secure Boot\".\nUsing bcmwl-kernel-source was perfectly fine with Secure Boot in 15.10. This does not seem to be related to a bug to me.\nSo this does look like Ubuntu refuse to sign anymore the 3rd party drivers/modules to make it work (??) with \"Secure Boot\". Or seem to consider 3rd party modules as insecure and breaking \"Secure Boot\" hence inforcing to disable it to make it clear ?? Am I right ?\n\nA: Another way to do it is to create your own key, insert the public part into the MOK database and sign the modules you compile with the private part.\nLook here for detailed info: Could not load 'vboxdrv' after upgrade to Ubuntu 16.04 (and I want to keep secure boot)\n\nA: This is not a bug, it is a feature.\nAs Anthony Wong says, when you install a DKMS package you are compiling the package yourself, thus, Canonical cannot sign the module for you.\nHowever, you can definitely use Secure Boot, however this is exactly the use case where Secure Boot is trying to protect you from yourself because it cannot know whether you trust a module or don't.\nBy default, there is a Platform Key (PK) on your UEFI machine, which is the ultimately trusted Certificate Authority for loading code in your processor.\nGRUB, or shim, or other boot mechanisms can be digitally signed by a KEK which is trusted by the root CA (PK), and thus your computer can, without any configuration, boot software like Ubuntu Live USB/DVDs.\nOn Ubuntu 16.04 the kernel is built with CONFIG_MODULE_SIG_FORCE=1, which means that the kernel will enforce modules to be signed by a trusted key in the platform.\nTake into consideration that the UEFI platform by default contains a PK that you do not have any control over, and thus you cannot sign binaries with a key recognized by your own machine.\nSome people bash and rant against that, but there is really no better way (from a security standpoint) than it being yourself who enrolls the new key you want.\nIf your boot system uses shim, you can use something called a Machine Owner's Key database, and enroll your key as a MOK (You can do that with mokutil). If you don't, you can also enroll your key in the UEFI database as a signing key.\nAfter you enroll your key, you can sign your DKMS-built package with your MOK (there should be a perl script at /usr/src/kernels/$(uname -r)/scripts/sign-file), and after it is signed, you can load it into the kernel.\nGranted, someone should make more visual instructions on this, and probably even make a wizard or a better DKMS standard to allow keys to be taken into consideration, but this is what we have as of now.\nYou can refer to this explanation on how to sign your own kernel modules: https://askubuntu.com/a/768310/12049\n\nA: In short, this is not a bug but a new change introduced in 16.04.\nBecause what you are installing is a dkms package. DKMS modules are compiled on your own machine and so Canonical can't sign the module for you. If Canonical cannot sign it, there is no way to digitally verify it. If you have secure boot turned on, that will mean your module can't be used, and in order to use it, you will have to turn off secure boot, that's why you are getting asked by the question.\nFor why it only happens in 16.04 but not in previous releases, Rod Smith has given a good answer. In Ubuntu 16.04, Ubuntu starts to enforce secure boot to the kernel level. Before 16.04, Ubuntu does not really enforce you to use signed kernel and signed kernel modules, even you have secure boot turned on. But this is no longer the case in 16.04.\nThis is the related bug: https://bugs.launchpad.net/ubuntu/+source/grub2/+bug/1401532\nThis is the related blueprint: https://blueprints.launchpad.net/ubuntu/+spec/foundations-x-installing-unsigned-secureboot\n\nA: The accepted answer is very complete, but I'd like to add this simple piece of information, taken from here: \nhttps://askubuntu.com/a/843678/664391\nBasically secure boot may prevent you from loading some driver you installed which can be quite frustrating. I have been through this myself: the driver installed correctly, everything seemed to be good to go, but it just didn't work. Took me some time to find it was secure boot's preventing the OS from loading it. \n", "Q: I have lost or forgotten my authentication password to my ubunutu 12.04 installed PC I have lost or forgotten my authentication password to my Ubuntu 12.04 installed PC. I have followed the sudo passwd root command and punched in the new password. It gives me a message Authentication Token Malfunction errorand the password is not changed. How do I go about changing the password? Also, I would like to format this entirely and install Ubuntu 14.04 or at least upgarde from the 12.04 version to 14.04. How can I do this. Kindly help.\nVinoth.\n\nA: If you only need to recover your files you can download Ubuntu and make a bootable Flash Drive. Warning, this may damage your computer but that's very rare!!! \nConnect your Flash Drive and restart your computer then press F2 or DEL (Delete) (based on your computer) very quickly to open the BIOS menu. \nThen select the BOOT tab.\nMove your Flash Drive (Removable Device or some other name associated with your Flash Drive) by pressing + or other key which you can find by reading the right side or down.\nThen save settings and exit by pressing F10.\nAfter restarting you might need to set your language. After setting your language click the Try Ubuntu Without Installing. This may take a while to boot, just relax until you see the desktop.\nThen create a new folder in the Flash Drive and just copy your files to the Flash Drive (use another one if the first one is full)\nOnce you copy all your files your going to need to restart your computer and press Install Ubuntu\nThen enter your location data and everything else. After everything is installed and you got to your desktop restart your computer and unplug the Flash Drive(s).\nMake sure to change your Boot device priority to your Hard Drive (HDD)!!!\nIf you need full information on how to do these things you can check out these: (sorry but I can only upload two links so I uploaded all the links to Pastebin)\nhttp://pastebin.com/p3bDAKKK\n", "Q: How do I use variables and non-variables in a single sed command? I'm trying to use sed to replace some PHP lines.\nMy problem is I want to replace a line with PHP variables with a string including a Bash variable.\nHere is an example:\nsudo sed -i 's/$sUrl . $this_sOutDir/https:\\/\\/'$bucketname'.s3.amazonaws.com . $this->_sOutDir/g' /var/www/html/$name/core/oxconfig.php\n\nAs you can see, I want to replace $sUrl . $this->_sOutDir (literally) with the s3 URL, which includes a Bash variable. I'm trying to use double quotes but it's not working for me:\n sudo sed -i 's/$sUrl . $this_sOutDir/https:\\/\\/\"$bucketname\".s3.amazonaws.com . $this->_sOutDir/g' /var/www/html/$name/core/oxconfig.php\n\nI'm also trying to use the complete s/... in double quotes but it's not working because sed thinks that the first variables are also Bash variables.\nThe result is:\nreturn https://.s3.amazonaws.com . $this->_sOutDir . '/';\n\n\nA: You can go two different ways:\n\n\n*\n\n*Using single quotes: break out of the single quotes and reference the variable (using double quotes to prevent word splitting and filename expansion):\nsudo sed -i 's/$sUrl . $this_sOutDir/https:\\/\\/'\"$bucketname\"'.s3.amazonaws.com . $this->_sOutDir/g' /var/www/html/$name/core/oxconfig.php\n\n\n*Using double quotes: escape the $ characters to be treated literally:\nsudo sed -i \"s/\\$sUrl . \\$this_sOutDir/https:\\/\\/$bucketname.s3.amazonaws.com . \\$this->_sOutDir/g' /var/www/html/$name/core/oxconfig.php\n\nHowever, the caveat is: if $bucketname contains sed special characters / sequences, the sed command will break (in this case since the variable is to be expanded in the replacement section, the concern is about it possibly containing the separator, accidental backreferences or &.\nOne way to go around this is sanitazing the variable beforehand by escaping possible separators, accidental backreferences and & characters to prevent them from being interpreted as such.\nAnother way is using Perl instead of sed, passing the variable directly to Perl which will handle special characters at replacement time ($ characters to be treated literally must be escaped even if using single quotes with this method):\nsudo perl -i -spe 's/\\$sUrl . \\$this_sOutDir/https:\\/\\/$bucketname.s3.amazonaws.com . \\$this->_sOutDir/g' -- -bucketname=\"$bucketname\"\n\n$ echo '$sUrl . $this_sOutDir' | perl -spe 's/\\$sUrl . \\$this_sOutDir/https:\\/\\/$bucketname.s3.amazonaws.com . \\$this->_sOutDir/g' -- -bucketname=\"string/with/separators/&/and/accidental\\$1backreferences\"\nhttps://string/with/separators/&/and/accidental$1backreferences.s3.amazonaws.com . $this->_sOutDir\n\n", "Q: Ubuntu partition has slower network speeds than Windows one We have Verizon FiOS, and are slated to get 75/75, according to our plan. I understand that we may not always get these numbers, but between Windows and Xubuntu there is a huge discrepancy.\nAlso, FWIW, when I log into Xubuntu, the Wifi connects, but does not work initially. I need to disconnect the Wifi then reconnect for it to actually work. And when I do this, I get error popups saying there was a system issue, and whether I'd like to report. (Presumably about the network manager stalling.)\nUPDATED Snapshot of my wireless-info\n\nSpeedtest.net results\n\n\n*\n\n*Windows 10 home (first try)\n\n\n*\n\n*2.4 GHz: 55.78 / 66.80\n\n*5.0 GHz: 79.45 / 89.18\n\n\n*Xubuntu 15.10 (first)\n\n\n*\n\n*2.4 GHz: 11.71 / 0.84\n\n*5.0 GHz: Could not connect\n\n\n*Windows (second)\n\n\n*\n\n*2.4 GHz: 60.46 / 69.70\n\n*5.0 GHz: 83.55 / 75.49\n\n\n*Xubuntu (second)\n\n\n*\n\n*2.4 GHz: 13.45 / 0.82\n\n*5.0 GHz: Could not connect\n\n\n\nOutput from sudo lspci\n03:00.0 Network controller: Realtek Semiconductor Co., Ltd. RTL8821AE 802.11ac PCIe Wireless Network Adapter\n04:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 0c)\n\n\nMore updates\n\n\n*\n\n*Another FWIW, I've ran apt-get update a few times throughout today. Each time, only 1000+ kb were downloaded in 1.5 minutes. \n\n*tx power set to max (20), no power save, kernel 4.2\n\n*At this point, my workflow is being affected. I tried to upload a 2.1 MB PNG file to a Github issue comment, but it failed after 3 minutes of waiting. During this time, I could not visit other webpages -- they stalled.\n\n\nA: After a couple weeks of research, I've found that my wireless card is simply not supported. There are plenty of other questions on AskUbuntu about the RTL8821AE card, or even just RealTek.\nHere is what I found did not help:\n\n\n*\n\n*No difference: Disabling BlueTooth or IPv6\n\n*No difference: Using the unofficial drivers from Github\n\n*Unavailable: official drivers from RealTek for RTL88xx series\n\n\nSince this was disrupting my workflow far too much, I decided to purchase the following item. I like this option, because I can utilize dual-band wifi (see stats in question).\nNETGEAR Universal N600 Dual Band Wi-Fi to Ethernet Adapter\nWhile I did not try them, other options include:\n\n\n*\n\n*Use a USB Wifi Adapter (best for laptops or micro PCs)\n\n*Install a new wireless card (best for the regular desktop)\n\n\nAs mentioned in the question, I was getting poor speeds on Ubuntu, compared to Windows. Now, on the 5.0 GHz network (through adapter), I get 80/80 on both Windows, Ubuntu 15.10, and Ubuntu 16.04.\n\nA: Debian supports your driver but the firmware is non-free. (I know this is Ubuntu, but it's built on Debian and can use its packages.) \nExecute the following:\nsudo nano /etc/apt/sources.list\n\nAdd the following line to the file:\ndeb http://httpredir.debian.org/debian/ jessie main contrib non-free\n\nInstall the Debain package firmware:\nsudo apt-get update && apt-get install firmware-realtek\n\n\nUPDATE: Let me know if this works.\nMake a temp directory (TARGET_DIR) for now-uncompiled package:\ndpkg-deb -x linux-firmware_1.149.3_all.deb TARGET_DIR\n\nEdit the Debian/control file. The most important part of any source package, it holds the dependencies.\ndpkg-deb --control linux-firmware_1.149.3_all.deb TARGET_DIR/DEBIAN\n\nEdit the depends field, and add firmware-realtek_0.43_all.deb. Then save your changes and repack\nnano TEMP_DIR/DEBIAN/control\n\nInstall package:\ndpkg -b TEMP_DIR newdriver.deb\nsudo dpkg -i newdriver.deb\n\nInstall firmware-realtek\nsudo apt-get update && sudo apt-get upgrade\n\n", "Q: Failing to install driver for wireless pci card I installed a wireless PCI adapter (Edimax N300) and it was working right away albeit not very good. In my quest to improve perfomance I made a mistake and followed this \nguide (under 6): RealTek Wireless adapter issues. (RTL8192ce and RTL8192cu)\nbasically installing the wrong driver for \"cu\" instead of \"ce\". After the reboot the card was not detected (at least I got no indication of any wireless connections around and there were plenty before). Since then I failed trying to install several drivers to get the card runnning again. \nI download the respective archives and then do:\nsudo apt-get install build-essential\nmakes\nsudo make install\n\nI get an error at the \"make\"-stage which reads as follows (apologies for the German):\nmake\nmake -C /lib/modules/3.19.0-56-generic/build M=/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013 modules\nmake[1]: Verzeichnis »/usr/src/linux-headers-3.19.0-56-generic« wird betreten\nCC [M]  /home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.o\nIn file included from /home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c:39:0:\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/pci.h:247:15: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘rtl_pci_probe’\nint __devinit rtl_pci_probe(struct pci_dev *pdev,\n           ^\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c: In function ‘_rtl_init_mac80211’:\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c:365:4: error: ‘struct ieee80211_hw’ has no member named ‘channel_change_time’\nhw->channel_change_time = 100;\n^\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c: In function ‘rtl_action_proc’:\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c:885:32: error: ‘struct ieee80211_conf’ has no member named ‘channel’\n   rx_status.freq = hw->conf.channel->center_freq;\n                            ^\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c:886:32: error: ‘struct ieee80211_conf’ has no member named ‘channel’\n   rx_status.band = hw->conf.channel->band;\n                            ^\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c: In function ‘rtl_beacon_statistic’:\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c:1160:2: error: implicit declaration of function ‘compare_ether_addr’ [-Werror=implicit-function-declaration]\nif (compare_ether_addr(hdr->addr3, rtlpriv->mac80211.bssid))\n^\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c: In function ‘rtl_send_smps_action’:\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c:1451:24: error: ‘struct ieee80211_conf’ has no member named ‘channel’\ninfo->band = hw->conf.channel->band;\n                    ^\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c: In function ‘rtl_store_debug_level’:\n/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.c:1684:2: error: implicit declaration of function ‘strict_strtoul’ [-Werror=implicit-function-declaration]\nret = strict_strtoul(buf, 0, &val);\n^\ncc1: some warnings being treated as errors\nmake[2]: *** [/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013/base.o] Fehler 1\nmake[1]: *** [_module_/home/kai/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013] Fehler 2\nmake[1]: Verzeichnis »/usr/src/linux-headers-3.19.0-56-generic« wird verlassen\nmake: *** [all] Fehler 2\n\nCan anybody help?\n\nA: Allright, I managed. Here is what I did: Open terminal, type \"gksudo nautilus\", go to folder \"etc/modprobe.d\" and opened \"blacklist-native-rtl8192\". Then I put a \"##\" in front of every line (so that they are not processed). \n", "Q: Boot Error with Live USB Ok, so I'm currently running Windows, but want to now use Ubuntu. I downloaded Linux Live USB Creator (LiLi) and also downloaded the 15.10 version of the Ubuntu GNOME ISO from the Ubuntu website.\nI selected my empty USB drive, selected the ISO, and put it on the USB. There is more than enough space (8GB).\nI placed the USB first in the boot order (In my BIOS it's listed as USB-HDD), and started the PC. \nAfter getting past the motherboard screen (It's a Gigabyte motherboard), it tries to boot from the USB, but gives me one line:\nBoot Error.\nThe only possible reason I can think of is the message LiLi gave me when I put the ISO on which was that the ISO was not on the compatibility list, so it was going to try and use the same configuration as the 15.04 version of standard Ubuntu.\nI have booted from a disk before, but not a USB. In my BIOS, there are several USB options, USB-HDD, USB-CDROM etc, I presume the bit on the end is what it will try to boot after?\nThanks in advance.\nEDIT: Thanks to people that replied, but it turns out that when I recreated the USB with a 15.04 version rather than 15.10, it worked fine, I'm presuming it was simply not supported on LiLi. Sorry for any hassle caused.\n\nA: well actually the usb thing is not boot after... assuming it's in your boot order... it's the type of usb to boot... I am not certain that your computer (old dell?) will be able to boot usb drives however I would say that if you just took the ISO or the files on the ISO and through them on your usb drive that it will not work... to properly get a bootable usb a tool such as Universal USB Installer is required.\n\nA: check your secure boot settings.  If you have uefi on.  Then make sure you add the boot file as a trusted source.  In my acer, I need to set the password in security, then I have the option to add trusted source.\nGive that a try.  Also, try to use the boot option screen instead of the actual bios screen to choose your boot order.  This is another fkey for you.  You should see it on your bios setup.  Make sure it is enabled.\nMake sure the usb booting is enabled too.\nGood luck.\nunless your computer is so old that it doesn't even have secure boot. which may be the case given the usb boot options. even then there may still be a F key for boot selection\n", "Q: Noob needs help. How to complete Ubuntu download I'm trying to get linux setup on my PC so I can use python packages unavailable on windows. When I complete the 64 bit download and run the program a Power2Go window comes up with a bunch of files in the left panel. I'm not sure where to go from here, and from what I'm reading on the ubuntu website I somehow need to download from DVD or USB? \nNot really sure what to do, but if someone could clarify would definitely appreciate the help.\n\nA: /*although I have listed all the steps below , but I recommend you to backup your full data in your  windows/mac to a pendrive/(by data I mean personal stuff,important files,etc and not windows backup:))..\nI recommend watching a youtube video at step 3 as I have written below is a highly abstracted(by this I mean , I have assumed many things ) list and I don't take any responsibility if you loose any data...and No one else will ... So it is EXTREMELY IMPORTANT THAT YOU BACKUP YOUR DATA TO AN EXTERNAL HARDDRIVE,DVD,USB so it is safe no matter what happens'(it has happened with me..I highly regret that moment , trust me)..upvote this answer if you have installed , wasted much of my time to write this long answer */ \n\n\n*\n\n*download ubuntu from http://www.ubuntu.com/download/desktop/thank-you/?version=14.04.4&architecture=amd64\n\n\n*download universal usb installer http://www.pendrivelinux.com/universal-usb-installer-easy-as-1-2-3/ and select ubuntu from list, browse to the folder where you have the iso installed, and click on next ...\n\n*restart your pc and press f12 (based on which system you are using , google \"how to go to boot menu  in company_name model_name\"   eg: how to go to boot menu in dell 5547)\n\n*select your pendrive\n\n*next, next , next selecting appropriate choices..\n\n*choose whether you want to install ubuntu with windows or you just want to install ubuntu removing all windows stuff...\n\n*next...\n\n*restart\n\n\n", "Q: USB 3.0 ports failing intermittently, other USB ports not working I've run into an issue where my USB 3.0 ports seem to be intermittently failing. I have two ordinary USB 3.0 ports on my computer and I have  my wireless keyboard/mouse combo plugged into one and a WIFI adapter plugged into the other. Every so often, the keyboard will become unresponsive for a few moments and the internet will hang and become unresponsive until the adapter is restarted. In addition, I have 8 high power USB 3.0 and two USB 2.0 ports which do not function at all (stuff plugged into them is detected very infrequently). So possibly I am using the wrong drivers?\nThe output of lsusb is (when it works, it sometimes just hangs and requires a manual termination):\nBus 007 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 011 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 004 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 010 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 006 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 009 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 005 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 008 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 001 Device 003: ID 0bda:8178 Realtek Semiconductor Corp. RTL8192CU 802.11n WLAN Adapter\nBus 001 Device 005: ID 046d:c52b Logitech, Inc. Unifying Receiver\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\n\nI've already tried editing grub by modifying it to:\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash usbcore.autosuspend=-1\"\nGRUB_CMDLINE_LINUX=\"acpi=force irqpoll\"\n\nbut neither of those changes seem to have made any difference. The 3.0 ports still fail occasionally and none of the other ports work at all. \nAny help you guys could offer would be hugely appreciated. \n\nA: By itself, modifing the grub had no effect on the performance of the USB ports.\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash usbcore.autosuspend=-1\"\nGRUB_CMDLINE_LINUX=\"acpi=force irqpoll\"\n\nHowever, I finally did what I should have done within 30 seconds of realizing that there was a problem with my USB ports and looked up my motherboard (a gigabyte ga-990fxa-ud3). This thread describes a simple solution to the problem which involves going into the BIOS and setting IOMMU to \"Enabled\".\nTogether with the grub options, this took care of the problem.\n", "Q: Is there spyware contained in 16.04? Will there be any spyware be contained in the next LTS version 16.04?\nI'm asking this because Ubuntu has been associated with spyware in earlier versions. \n\nA: If you're referring to search tracking, no, there won't. In 16.04/Unity 8, your search information will not be sent to Canonical unless you opt in. As an Ubuntu team member puts it, \"What is changing? First of all online search will be off by default.  This means that out-of-the-box none of your search terms will leave your computer.\"\n", "Q: to remove broken packages 14.04 I want to remove/reinstall the broken package libopenni-sensor-primesense0\nI have tried all commands i.e\nsudo aptitude install <packagename>\n\nsudo aptitude -f install <packagename>\n\nsudo dpkg --configure -a\n\netc but still getting the error\ndpkg: error processing package libopenni-sensor-primesense0 (--remove):\n subprocess installed pre-removal script returned error exit status 127\nErrors were encountered while processing:\n libopenni-sensor-primesense0\n\nplease help .. I shall be very thankful to you ... I'm facing this issue since long\n\nA: try this (careful the force command is very powerful and as such it is advised the user fully understand what it does):\nsudo dpkg -i --force-all [deb file path]\n\napt-get update and apt-get upgrade then try everything (including what you tried) again...\nSimilar problem: How to delete broken packages in ubuntu . The solutions might help u if this doesn't work.\n", "Q: Ubuntu 14.04 Terminal on virtualbox maintenance I'm running Ubuntu 14.04 terminal server on VirtualBox 5.0.12 (which is installed on Windows 10). I ran out of disk space apparently (although I have 10 GB space) so I read and I understood that I need to do some maintenance to my system regularly.\nCould someone please let me know how to do that?\nThank you\n\nA: There are several things, that you can try:\n\n\n*\n\n*Reboot (-> everytime you reboot, the /tmp directory gets cleaned).\n\n*Try to track down where your system consumed the most space. You can do it by issuing a du -h --max-depth=1 /. You will get a list of your root-fs directories along with the used disk space. If you spot, e.g. that in /home there is 7G stuff, call the same du command but for /home: du -h --max-depth=1 /home. Finally you will find out, where the most space gets lost.\n\n*If you don't want to create a new VM with more disk space, you can add a new virtual harddisk with more space and mount it to a directory that is consuming a lot of space. Normally /home or /opt would be a candidate, but it depends completely on your system and what you're doing with it. If you wan't to do that, try this tutorial here: https://howtobi.wordpress.com/2010/10/30/adding-a-additional-hard-disk-in%C2%A0virtualbox/\n", "Q: resolveconf -u keeps adding an unwanted search domain to resolve.conf I have my desktop computer configured with a static IP address:\n\nHowever, /etc/resolve.conf keeps getting overwritten with:\nnameserver 127.0.0.1\nsearch localdomain example.com\n\nThis seems to happen periodically or when I run sudo resolvconf -u.\nI would really like to get example.com removed from the dns search domain list.   I used to have it in there but its causing problems now.  I just can't seem to get it out.  I don't know where it is coming from or why it keeps getting put back.  As far as I can grep, there is nothing referring to example.com anywhere in my /etc directory anymore.   \nWhat is putting this search domain into my resolv.conf file and how can I prevent it from doing so?\n\nA: For ipv4, @stalet's suggestion to edit /etc/dhcp/dhclient.conf should work; also try removing domain-search and domain-name from the request.  Verify the settings worked in /var/lib/NetworkManager/dhclient-[connection-uuid]-[ifname].lease.\nHowever, the unwanted search domain may be coming from the ipv6 dhcp server, as I found on 16.04/Xenial.  If NetworkManager's dhclient -6 command succeeds and the dhcp server sets search domains, NetworkManager will merge those into the ipv4 search domain list.\nA simple way to fix this on a connection-by-connection basis is to configure the connection's ipv6 settings to \"Method: Automatic, addresses only\" or even \"Method:  Ignore\".\nSetting this for each connection could become annoying, and I looked pretty hard but couldn't find a way to fix this globally.  Adding supersede dhcp6.domain-search to and removing request dhcp6.domain-search from /etc/dhcp/dhclient.conf doesn't seem to help.  Also, copying that file to /etc/dhcp/dhclient6.conf caused NetworkManager to correctly template it to /var/lib/NetworkManager/dhclient6-[ifname].conf, but NetworkManager insists on adding also request dhcp6.domain-search;, and the unwanted search domain is still added.\n\nA: The search content is provided by dhcp, and can be overridden in /etc/dhcp/dhclient.conf by supersede these variables with empty values.\nAdd these lines at the bottom of the /etc/dhcp/dhclient.conf\nsupersede domain-name \"\";\nsupersede domain-search \"\";\nsupersede search \"\";\n\nTo make the change affect your system you can reconnect to your network or just restart the network-manager service.\nsudo service network-manager restart\n\n\nA: I saw an update to resolveconf 1.78ubuntu5 today (https://launchpad.net/ubuntu/xenial/+source/resolvconf/+changelog), referencing this Launchpad bug, https://bugs.launchpad.net/maas/+bug/1711760. Perhaps this issue is resolved now?\n", "Q: Anyone using Ubuntu on Lenovo Miix 700? Considering buying one, but would love to hear what works and what does not. And, yes, I tried google, but the only thing I could find was this Intel Corporation Wireless 8260 [8086:24f3] (rev 3a)\n\nA: Got Ubuntu 16.04 installed as dual-boot with Windows 10 and it's working fine, well more or less...\nDepending on the Ubuntu Variants, you may have to disable/tweak UEFI options in your bios.\nDepending also on the Ubuntu variants, you may have full native resolution/definition so the display might be very tiny and when I said tiny, it's really really tiny... ^^\nWith standard Ubuntu, looks like (double) hiDPI is activated and so icons and characters are much bigger.\nAs described by others \"basic\" functions are working or should work : wireless and bluetooth are working fine (may or may not need some firmwares to download).\nDepending on the resolution/definition you're using, you have to play with touchscreen calibration.\nMost native functions can be controlled from the keyboard such as : dimmable display, sounds controls, etc...\nTo install and configure the Intel Realsense drivers, it's a real pain as it needs many pre-requisites and using the back Intel Realsense camera is still another story as you need specific softwares to fully use it (with Ubuntu 16.04.2 looks like Intel Realsense drivers are pre-installed)...\nAs it was not my priority, I did a quick and dirty install and hack so I could use it with guvcview... more or less... ^^\nI was able to view through the back camera, record videos with it but I was unable to play the recorded videos back as we only have \"a still video\" and with sound... ^^\nYou need specific softwares to use the Intel 3D Realsense camera.\nIt is not usable with Cheese and with VLC, it's just so weird I can't explain the result...\nThis part has been edited as I made a mistake about the OV5670 driver and I think the real reference is (Intel ?) AVStream 2500 camera but no way to find any source code anywhere, nor from Intel or from Microsoft, and of course nothing from Lenovo ! :(\nI don't have the Lenovo Wacom Pen so I can tell much about it but I saw on Youtube some other persons said it it working fine, except pressure controls.\nI now have the Lenovo Wacom pen and I confirm what was said : working out of the box but no pressure controls yet.\nFor display rotation/autorotation it is not functional but should be with some hacks and scripts.\nIf you want to use it as a basic touch laptop it's fine, but if you want a full touch tablet there are SOME hard works to do !\nAs soon as I could get the front camera working I will update this thread. ;)\nCheers.\n", "Q: Stuck with playlist on totem 3.10.1 I have 2 systems, both running Ubuntu 14.04 64-bit and totem 3.10.1. On one of the systems the sidebar (when active) always shows the play-list which I could do without. The other shows some media info about the file being played like duration, resolution, title, etc which I prefer. How can I reset totem to show me the information I want rather than the playlist I don't want. Trying to toggle the play-list does not have the desired effect as it appears it's not a toggle. All I can do is turn the sidebar on and off completely (not what I want). I've reviewed the information on the totem website and scanned the questions regarding totem here but I couldn't find anything related to my specific case.\n\nA: It turns out this is simple. Selecting Movie-> Properties puts the desired info back on the sidebar and then totem stays that way upon opening the next movie until you request the playlist again. \nSee below: \n\n", "Q: WiFi card not detected I've installed Ubuntu 14.04 yesterday and all it's updates as well as I read many solutions on Google for how to get Ubuntu to detect your WiFi card and nothing worked, probably because my WiFi card differs from others' \nI was able to identify the WiFi card model by writing this on terminal:\n\"lshw -C network\"\nand this is the model description: \n\"*-network UNCLAIMED\n       description: Network controller\n       product: QCA6164 802.11ac Wireless Network Adapter\n       vendor: Qualcomm Atheros\n       physical id: 0\n       bus info: pci@0000:03:00.0\n       version: 20\n       width: 64 bits\n       clock: 33MHz\n       capabilities: bus_master cap_list\n       configuration: latency=0\n       resources: memory:f0800000-f09fffff\"\n\nI was not able in no way to get it working, I tried the additional drivers option it didn't show any unknown driver except for AMD graphic card, I can only access the Internet by Wire or Bluetooth. And yes Ubuntu is up to date I'm clueless about if there's any extras I should be downloading.\nThanks in advance!\n\nA: According to the Linux Wireless wiki, you need to have a kernel version of 4.3 or later for this wireless card to work.  Your current kernel is probably 3.19, since you're on a fresh install of 14.04.  In a terminal, type this to see your current kernel version:\nuname -r\n\nAssuming that you have an ethernet connection, you can install kernel version 4.4 by running this command in the terminal:\nsudo apt-get install linux-generic-lts-xenial\n\nOnce the kernel install finishes, restart your computer, then follow these instructions from this bug report:\n\n1) Get the latest firmware from https://github.com/kvalo/ath10k-firmware/archive/master.zip\n2) Unzip this file, and copy the contents of ath10k-firmware-master to /lib/firmware/ath10k.\n3) Rename two of the firmware files like so:\n\ncd /lib/firmware/QCA6174/hw2.1\nsudo mv firmware-5.bin_SW_RM.1.1.1-00157-QCARMSWPZ-1 firmware-5.bin\ncd /lib/firmware/QCA6174/hw3.0\nsudo mv firmware-4.bin_WLAN.RM.2.0-00180-QCARMSWPZ-1 firmware-4.bin\n\n\n4) Reboot your computer. Run \"lshw -C network\" to see if your card is recognized.\n\n\nA: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1436940 contains all the info you need to fix it\n", "Q: Coloring all output from terminal Is there a way to make all the output of my terminal colored in a personalized way? e.g: If I issue the command: sudo apt-get update - I will get a column of text and what I want is a way to colorize RED if there are any words like \"ERROR\" in this text, and GREEN any words like \"DONE\" or \"FINISHED\".\nThats just an example, and I understand that this could screw up with other programs colored output, just curious if this is possible.\nI'm using ZSH at the moment, but accept answers for every terminal emulator.\n\nA: You can use sed to replace word-boundary-delimited \"ERROR\", \"DONE\" and \"FINISHED\" strings with the same string enclosed in ANSI color escape sequences (you could alias the command in ~/.bashrc for convenience; as you can see this works in Zsh, but since it's the terminal that interprets the escape sequences this would work in any shell running in an ANSI / VT100-compatible terminal):\nsudo apt-get update |& sed 's/\\bERROR\\b/\\x1B[1;31m&\\x1B[0m/; s/\\bDONE\\b/\\x1B[1;32m&\\x1B[0m/; s/\\bFINISHED\\b/\\x1B[1;34m&\\x1B[0m/'\n\nsudo apt-get update |&\n    sed '\n        s/\\bERROR\\b/\\x1B[1;31m&\\x1B[0m/\n        s/\\bDONE\\b/\\x1B[1;32m&\\x1B[0m/\n        s/\\bFINISHED\\b/\\x1B[1;34m&\\x1B[0m/\n    '\n\n\n", "Q: Giving postgres access to root files I created an Ubuntu 14.04.4 server on digital ocean. \nI have a directory off the root user called mapnik/data/. Inside is a file I want to import to postgres. When logged in as root \nls -l /root/mapnik/data/world_merc.shp\n\nyields\n-rw-r--r-- 1 postgres root 428328 Apr  7 18:17 /root/mapnik/data/world_merc.shp\n\nWhen trying to import to postgres, I cannot access the file. If logged in as postgres\nls -l /root/mapnik/data/world_merc.shp\n\nyields\nls: cannot access /root/mapnik/data/world_merc.shp: Permission denied\n\nIs this an issue with the permission on this folder? \nHow can I configure this folders permissions so I can import from root to postgres?\n\nA: That's because user postgres does have not have necessary permission to read (list) the contents of directory /root/ (the home directory of user root).\nNormally the permission of /root/ is set as 0700 with the owner as root, so nobody else except root can check the contents and hence traverse further in the directory tree.\nSo even if you set the owner of /root/mapnik/data/world_merc.shp file as user postgres, postgres won't be able to access the file as the traversal will be blocked because of insufficient permission at /root/.\n\nInstead of putting the file in /root/ (and changing permission of /root/), choose postgres's home (if there is one) or you home or any place that seems safe and user postgres has sufficient permission to do the intended operation.\n", "Q: Is there any Ubuntu PDF reader which can select (snapshot) , save, and export pages? I installed Foxit in Ubuntu 14.04 but it doesn't seem to have the 'snapshot' feature of the Windows version, ability to save and export a page to..say..Libroffice to save as a word page doc. Does such a PDF program exist for Ubuntu? Or have I installed Foxit wrong?\n\nA: Foxit for Linux does not have the full feature set that the Windows version does, although I use it myself and find it to be pretty handy. You can use PDF-Shuffler to extract a single page, or print the single page to a cups-pdf printer. Libre-office can read pdf as images, I believe.\n", "Q: Network manager connection editor can't start I'm having trouble starting the connection editor. I can't start it from the GUI, so I tried entering nm-connection-editor at a terminal, but got this error. Anyone know what it means? I'm running Ubuntu 14.04 and haven't found any solutions for this error so far. I tried uninstalling and reinstalling network manager, but I get the same error.\nnm-connection-editor: symbol lookup error: /usr/lib/NetworkManager/libnm-viavpn-properties.so: undefined symbol: LOG_init\n\n\nA: I found a solution. It may not be the best solution, but I can now start the connection editor. After uninstalling network manager I deleted the /usr/lib/NetworkManager/ directory and its contents. Afterwards I reinstalled network-manager and network-manager-gnome and can now start the connection editor using the GUI and nm-connection-editor at the terminal.\n", "Q: Unable to boot OS X after installing ubuntu I installed ubuntu on my macbook air early 2014,but now I am unable to boot OSX after the installation of Ubuntu.\nI used a USB flash drive to install\nUbuntu 15.10-amd64.ISO\nWhen I press the 'power on' button,it boots to Ubuntu automatically\nBut if I press and hold 'alt' after pressing the 'power on' button it shows the Macintosh HD icon , when I press enter it shoes the Apple logo and then it shows a cross circle symbol.\n\nA: \nWhen you see a circle with a slash symbol instead of the Apple logo, it means your Mac couldn't find a valid System Folder to start up from.\n  If you're using your Mac at a school or business, it might be trying to start from the wrong version of OS X. Contact your IT department for more help. \n  If this is your personal Mac, try reinstalling OS X by using OS X Recovery.\n\nhttps://support.apple.com/en-us/HT204156\n", "Q: how to change my HD4870 fan speed I just migrated from win10, and I'm having trouble with my gpu fan. I have a hd4870 card.\nIts is just to damn loud. I would even unplug it if my motherboard had onboard video.\nI'm doing some research and I didn't find a way to change fan speed. I dont know if I want to install the catalyst driver because I didn't find if my gpu is supported.\nI don't plan on playing any games, I use the computer mainly for study nowadays, and its really annoying it being so loud.\nI would really appreciate any help! Thanks\n\nA: Enable DPM by adding a boot parameter. This should greatly help power consumption, especially when idle. To do so, edit /etc/default/grub and add the 'radeon.dpm=1' to the GRUB_CMDLINE_LINUX_DEFAULT line, so it would look something like:\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash radeon.dpm=1\"\n\nAfter you save/quit the text editor, update grub:\nsudo update-grub\n\n", "Q: Blu-ray VlC problem I got a problem with blu-ray player in VLC\nBlu-ray error:\nBlu-ray Disc is corrupted.\nYour input can't be opened:\nVLC is unable to open the MRL 'bluray:///dev/sr0'. Check the log for details.\nIt's not the discs \n\nA: The disc is probably a normal, commercial disc and thus encrypted.\nUse\nsudo apt-get install libaacs0 libbluray1 libbluray-bdj\n\nand fetch the AACS keys with \nmkdir ~/.config/aacs \ncurl http://vlc-aacs.whoknowsmy.name/files/KEYDB.cfg > ~/.config/aacs/KEYDB.cfg \n\nThe AACS keys don't reach to 2013 and beyond, so if you want to watch something newer, you are out of luck.\nYou can install MakeMKV from the ppa and use this to play newer stuff, if you don't mind having closed-source software with dubious status on your system.\nFor this, you need to remove the libaacs0 again (sudo apt remove libaacs0) and make\ncd /usr/lib\nsudo ln -s libmmbd.so.0 libaacs.so.0\nsudo ln -s libmmbd.so.0 libbdplus.so.0\n\nafter you installed MakeMKV to have VLC play and decrypt Blu-Ray discs.\nTo play a disc, you need to make some steps everytime to be successful:\nStart MakeMKV, read the disc, press the \"streaming\" button in the top row.\nNow start vlc, press Ctrl+N and paste http://localhost:51000/stream/title0.ts in the box. You might want to increase the buffer to 5000 ms or more under More Options.\nYou can see what titles are available on the disc in your browser under http://localhost:51000. If you substitute your IP address for 'localhost', you can even watch on other computers in your network as long as MakeMKV is active and streaming.\nIf you are on a relatively recent distro, you can safely substitute apt for apt-get. This is the future development and should be used if possible.\n", "Q: LXC unprivileged container: apt-get fails to download anything inside I'm running Ubuntu Xenial and set up simple unprivileged user container from template (also Xenial).\nWhen I attach inside and try to just do upgrade or install anything 'apt-get' fails with following messages:\nroot@c1:/# apt-get update\nE: setgroups 65534 failed - setgroups (22: Invalid argument)\nE: setegid 65534 failed - setegid (22: Invalid argument)\nReading package lists... Done\nE: setgroups 65534 failed - setgroups (22: Invalid argument)\nE: setegid 65534 failed - setegid (22: Invalid argument)\nE: Method gave invalid 400 URI Failure message: Failed to setgroups - setgroups (22: Invalid argument)\nE: Method gave invalid 400 URI Failure message: Failed to setgroups - setgroups (22: Invalid argument)\nE: Method http has died unexpectedly!\nE: Sub-process http returned an error code (112)\nE: Method http has died unexpectedly!\nE: Sub-process http returned an error code (112)\n\nSo the question is - what's going on here?\n\nA: By default user '_apt' has uid=65534, but lxc (and host) is configured to allow only 10000 subuids and subgids for user (and therefore unprivileged containers).\nOne solution might be to set user '_apt' uid inside container below 10000.\nThe other way is to up subuids/subgids limit on the host. Use command sudo usermod --add-subuids 260000-325536 --add-subgids 260000-325536 $USER for user that owns container, and ensure lxc user containers are configured with:\nlxc.id_map = u 0 260000 65536\nlxc.id_map = g 0 260000 65536\n\n\nA: I got a similar error when building my docker container. Turns out that I forgot to write sudo before my docker build command.\n\nA: In my case, @Alwin's solution cannot be used as I'm running rootless. Regarding @dilettant solution, there isn't lxc in my environment, nevertheless replaced _apt's uid using sed -i 's/_apt:x:100:65534/_apt:x:100:100/g' /etc/passwd. Also followed @cheshirekow's comment and in my case /proc/<pid>/setgroups contained allow and not deny.\nI solved it indirectly by installing brew as an alternative using:\nRUN /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nENV PATH=$MVND_HOME/home/linuxbrew/.linuxbrew/bin:$PATH\n\n", "Q: Resolution Problem at Install I download the last version of ubuntu and mount  the iso to disk on key to make dual boot install.\nI boot the install but I cant continue.\nIts see like the resolution is go over 2 screen but i  dont see the window of the install.\nI dont have 2  screen that connected.\nHow I can change the resolution of the install?\nThanks.\n\nA: Roey, I had the same problem when I purchased my new AMD 64 bit HP.  I have run Ubuntu for almost 10 years.  The problem comes with \"wide screen resolution\".  If you had an older computer like I did, a laptop with a screen resolution of 4:3 and you were running nothing higher that Ubuntu V12.xx, no problem.  But when I tried to upgrade to v14.04 i had the same problem.  The only solution I could find was to go to V15.10 BETA TEST!  Definately not good, but it works, FULL OF BUGS.  My screen resolution is Wide Screen; 16:9.\nI have gone to the Ubuntu forums for a long time, lots of other people are experiencing the same problem.\nBUT: 15.10 works if you are willing to live with the problems.  A major problem is that 15.10 does not allow you to set the partition sizes, it does that automatically and gives you no control.\nThe second problem with 15.10, when it installs a new Linux Kernel, it does not delete the older kernels, so your boot partiton rapidly becomes full.\nI am not good at working at the terminal level.  I can not delete the older versions of the kernel, therefore I Can NOT get any more current updates, fixes or patches.  \nI just now tried to install the BETA 2, V16.04, no luck.  I have tried to get help from the Ubuntu community to no avail.\nYou will be able to run V15.10 BETA Test, if you are willing to live with the bugs.  I am waiting for the final V16.04 LTS, secure, supported version due to realease this April 21.  I hope that helps both of us.\n", "Q: Ubuntu 14.04lts, USB Keyboard and USB mouse Just stop working I have been using Ubuntu 14.04LTS since Sept 2015 without any problems.  Within the last week or so the USB keyboard and mouse just stops working.  The only way to cure the problem is to do a hard reboot.  I have been reading the forum and trying suggested fixes, so far nothing has worked.  There was an update last Tuesday, 5 Apr 2016 and that is was around that time the problem started.  Initially, It was one program, when I started it, it would hang as soon as I selected an item in the program (and still does).  Then I noticed it would hang once in a while at other times.  So, I kind of think it isn't a single program but maybe the latest up date.  I did have a problem running the software updater, I had to run it from the terminal.  Does anyone have an idea what is causing this? \n4/09/16 This morning I got the following error \"Sorry Ubuntu 14.04 has experienced an internal error\".  The error is as follows:\nPackage\n     linux-image-3.16.0-69-9generic 3.16.0-69-89~14.04.1\nProblem Type\n     KernelOops\nTitle\n     BUG: Unable to handle kernel NULL pointer dereference at 0000000000000008\nAnnotation\n     Your system might become unstable now and might need to be restarted\nDate\n     Sat Apr 9 08:53:20 2016\nDependencies\nFailure\n     Oops\nInstallation Date\n     Installed on 2015-08-04 (294 days ago)\nInstallation Media\n     Ubuntu 14.04.2 LTS \"Trusty Tahr\" Release (20150218.1)\nOops Text\n     BUG: Unable to handle kernel NULL pointer dereference at 0000000000000008\n     IP [] radeon_fence_ref+0xd/0x50[radeon]\n     PGDO\n     Oops:002[#1]SMP\n     CPU: 1PID: 1633 Comm: Xorg Not Tainted 3.16.0-69-9generic #89~14.04.1   ubuntu\n     Hardware Name: System manufactured System product name M4A785-M (ASUS)\n     Bios 1006 08/18/2010\nThere is more but I can't save the error report or even copy parts of it.  If you need more data or different data please let me know. I tried to format this like the report but I don't think it will post like that.  Any help in what I posted?  Thanks for your assistance in figuring this out.\n\nA: Problem solved.  I don't know the technical reason why it is fixed.  The program that I first noticed the problem had a extension add-on that collected data from google.  I didn't use the add-on any longer but didn't see any reason to remove it.  For what ever reason, the add-on was causing the problem or else, the software update for 14.04 I received yesterday fixed the problem.  Anyway, it's fixed.  Thanks one and all for at least looking at my problem.\n", "Q: Error when trying to copy directory content with rsync inside a shell script I want to copy the content of \"src/main/resources/\" to my remote servers. This folder contains several *properties files. \nThe following command executes without any problem in bash and zsh:\nrsync -av \"src/main/resources/*\" \"azureuser@s1.cloudapp.net:/home/azureuser\"\n\nHowever, when executing such command inside a shell script I'm getting the following error. I think its due to the * expansion in the shell.\nrsync: link_stat \"/home/marcos/Desenvolvimento/Java/EXT-Hyuga/src/main/resources/*\" failed: No such file or directory (2)\n\nHow can I fix this issue?\nShell Script Content:\n#!/bin/bash\n\n# server array\ndeclare -a deployinstances=(\"s1\" \"s2\" \"s3\" \"s4\")\n\n## looping trough deploy instances\nfor di in \"${deployinstances[@]}\"\ndo\n   rsync -av \"src/main/resources/*\" \"azureuser@$di.cloudapp.net:/home/azureuser\"\ndone\n\n\nA: Your first command, the one you have run directly in command line would not work either.\nIn bash (and all other shells), filename generation (AKA pathname expansion or glob expansion) will not take place when the tokens (e.g. *, ?, []) are put inside quotes (double and single) as the quote removal is done by shell after pathname expansion for any word, so the word is treated literally then.\nSo you need to keep * outside of quotes:\nrsync -av src/main/resources/* azureuser@\"$di\".cloudapp.net:/home/azureuser/\n\nI have not used any quotes here in any pathname, because unless you have spaces in the path you don't need quotes around a path.\n", "Q: Can't get my second network card to work on ubuntu server I am using ubuntu server to setup and use my server, I added an extra network card in the system because the network socket on the motherboard only supports 100mbit.\nThe pci card I added is the D-Link DQE-528T. But I cannot get the card up in running.\nThis is some commands I tried to diagnose the problem: (I am not an Ubuntu expert, I am kinda new to Ubuntu server, so I don't understand everything in here so I can't find the problem).\nsudo lshw -C network\nCode:\n  *-network\n       description: Ethernet interface\n       product: MCP73 Ethernet\n       vendor: NVIDIA Corporation\n       physical id: f\n       bus info: pci@0000:00:0f.0\n       logical name: eth0\n       version: a2\n       serial: 90:fb:a6:2f:c9:90\n       size: 100Mbit/s\n       capacity: 100Mbit/s\n       width: 32 bits\n       clock: 66MHz\n       capabilities: pm msi bus_master cap_list ethernet physical mii 10bt 10bt-fd 100bt 100bt-fd autonegotiation\n       configuration: autonegotiation=on broadcast=yes driver=forcedeth driverversion=0.64 duplex=full ip=192.168.0.193 latency=0 link=yes maxlatency=20 mingnt=1 multicast=yes port=MII speed=100Mbit/s\n       resources: irq:29 memory:efffd000-efffdfff ioport:f600(size=8) memory:efffc000-efffc0ff memory:efffb000-efffb00f\nBtw the eth0 is my onboard network adapter.\n\nifconfig\nCode:\n eth0      Link encap:Ethernet  HWaddr 90:fb:a6:2f:c9:90\n          inet addr:192.168.0.193  Bcast:192.168.0.255  Mask:255.255.255.0\n          inet6 addr: fe80::92fb:a6ff:fe2f:c990/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:303 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:470 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:26604 (26.6 KB)  TX bytes:95106 (95.1 KB)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:40 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:2712 (2.7 KB)  TX bytes:2712 (2.7 KB)\n\ndmesg | grep eth0\nCode:\n[    2.246672] forcedeth 0000:00:0f.0: ifname eth0, PHY OUI 0x732 @ 1, addr 90:fb:a6:2f:c9:90\n[    9.021486] init: network-interface (eth0) pre-start process (493) terminated with status 1\n[    9.143300] init: network-interface (eth0) post-stop process (518) terminated with status 1\n[ 2075.662801] forcedeth 0000:00:0f.0 eth0: MSI enabled\n\nps aux | grep -i network\nCode:\nkevin     1262  0.0  0.0  10468  2228 pts/0    S+   22:40   0:00 grep --color=auto -i network\n\nDoes anybody have an idea how to get the card working?\n\nA: I found out that the bottom pci slot has a failure and changed it a slot and now it works perfectly\n", "Q: What does MANUFACTURER: CE80 mean? What's the meaning of Manufacturer: CE80 in a memory description when listing with command sudo dmidecode -t memory? (Ubuntu 15.10)\n\nA: It is difficult to find a full list of manufacturer codes but this particular code is associated with Samsung:\n0x80CE—Samsung Electronics, Inc.\n\nThis is taken from a table on the page I have listed as reference, the full section of this table going:\nThe vendor ID of the manufacturer. This can be one of the following:\n\n    0x2C00—Micron Technology, Inc.\n    0x5105—Qimonda AG i. In.\n    0x802C—Micron Technology, Inc.\n    0x80AD—Hynix Semiconductor Inc.\n    0x80CE—Samsung Electronics, Inc.\n    0x8551—Qimonda AG i. In.\n    0xAD00—Hynix Semiconductor Inc.\n    0xCE00—Samsung Electronics, Inc.\n\nReferences:\n\n\n*\n\n*Cisco: Viewing server properties - Memory Properties\n", "Q: Keyboard shortcut equivalent for OSX Super+Backtick In OSX you can hit Super+` (backtick) and it switches between multiple windows in the same application. Is there an Ubuntu equivalent (currently I'm running stock 16.04)?\nAnd yes, I'm aware I can hit Alt+Tab then Alt+Shift+Tab to - but that's not 100% reliable.\n\nA: What you are looking for Alt+~ (~ is the same key as the backtick)\n\nA: Based on the fact answer above, another Ask Ubuntu on how to disable Alt+`. I checked my system. It appears that the keybinding to \"Key to flip through windows in the switcher\" is no longer enabled by default in Ubuntu 16.04.  So to enable it:\n\n*\n\n*Install the compizconfig-settings-manager  package\n\n*Launch CompizConfig Settings Manager\n\n*The setting can be found in Desktop (Category), Ubuntu Unity Plugin, Switcher (Tab)\n\n*On the line Key to flip through windows in the switcher click \"Disabled\" and set your preferred key combination.\n\n", "Q: How to stop OSSEC HIDS sending me level 2 alerts? I have OSSEC HIDS (2.8.3) installed (I have it set up as a local installation) and setup so that it sends me email alerts for the various alert levels. The only problem is with level 2 alerts which are normally nothing of importance and just spam my inbox.\nSo I was wondering if there is any way of stopping it from sending me level 2 alerts so that it sends me all the others but just not those? (I am looking for something which I can configure in the OSSEC HIDS settings, I don't want a sort of just external hack which filters the emails it sends me or something because that could run the risk of it filtering out other alert levels too.)\n\nA: For say if you want to get only alerts greater than 8 you can filter that by adding the below snippet in your server's ossec.conf file,\n-email_alerts-\n-level-8-/level-\n-/email_alerts-\n\nNot sure why couldn't use <> symbols use <> instead of - for opening and closing brackets\nThis will help to trigger alerts levels of 8 and 8+.\n", "Q: Something resets my FireFox PAC file setting I'm trying to set up proxy autoconfiguration in my FireFox 45.0 under Kubuntu 15.10. I'm specifying a path to PAC file in FF's Preferences\\Advanced\\Settings\\\"Automatic proxy configuration URL\". It works for a few minutes and then stops. When I check this setting again I'm able to see the path in the corresponding field but setting's radiobutton is switched back to \"Use system proxy settings\". \nI suspect there is a system demon that resets my change. What is a correct way to do this in FF under Kubuntu?\n\nA: It was because of ZenMate extension in my FF. Even I switched it off from browser's toolbar it still interfere with this setting. I bypassed this problem by disabling ZenMate extension in FF settings.\n", "Q: 64-bit Ubuntu seems to think it is 32-bit Yesterday, I posted this thread, and got a reply, telling me to install 64-bit Ubuntu. I thought I already had a 64-bit copy, so I went to my system Details, and found that I did, indeed have an x64 copy of Ubuntu GNOME. Then, I found that it said it had only 2.9GiB of memory, which was strange, since I have a full 6GB of RAM installed. Thinking my RAM Cards (2x 2GB and 2x 1GB) simply weren't snapped in to the motherboard all the way, I turned off the machine, unplugged it, grabbed my antistatic wristband and removed and reinstalled all the cards. I plugged it pack in, powered it back on, and it still thought it had 2.9GiB. What shoud I do?\nP.S. uname -a returns:\nLinux [computer name censored for privacy] 4.2.0-35-generic #40-Ubuntu SMP Tue Mar 15 22:15:45 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nEDIT:\nfree returns:\n             total       used       free     shared    buffers     cached\nMem:       3023024    2330472     692552      31564      65644    1066920\n-/+ buffers/cache:    1197908    1825116\nSwap:      3086332      30740    3055592\n\nHere's everything with e820 in it from ~/var/log/syslog.txt:\ne820: BIOS-provided physical RAM map:\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009e7ff] usable\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x000000000009e800-0x000000000009ffff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000000e0000-0x00000000000fffff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bc04efff] usable\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bc04f000-0x00000000bc07efff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bc07f000-0x00000000bc344fff] usable\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bc345000-0x00000000bc410fff] ACPI NVS\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bc411000-0x00000000bd1d3fff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bd1d4000-0x00000000bd1d4fff] usable\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bd1d5000-0x00000000bd3dafff] ACPI NVS\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bd3db000-0x00000000bd850fff] usable\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bd851000-0x00000000bdfe1fff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000bdfe2000-0x00000000bdffffff] usable\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000e0000000-0x00000000efffffff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000feb80000-0x00000000fec01fff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000fec10000-0x00000000fec10fff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000fed00000-0x00000000fed00fff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000fed40000-0x00000000fed44fff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000fed80000-0x00000000fed8ffff] reserved\nApr  8 22:27:50 [Computer Name removed for Privacy] kernel: [    0.000000] BIOS-e820: [mem 0x00000000ff000000-0x00000000ffffffff] reserved\n\n\nA: Your kernel is 64-bit. That's why you see that x86_64 GNU/Linux in that output of uname.\nYou might try posting the output of the Linux command line the free command. It shows how much memory the kernel thinks you have and how much is currently free.\nI don't know why you would see less memory than you think you have. If you interrupt the boot sequence in the BIOS SETUP program, usually you can see what the basic hardware/firmware thinks you have installed. If that's not 6GB as you believe then maybe you have a bad memory stick or a bad motherboard or CPU?\nOne other possibility is that your machine may be using a lot of memory for video RAM. This is really unlikely to use that much memory, but maybe?\n", "Q: Installing Ubuntu on windows laptop without losing access to windows I'd like to start using ubuntu as my primary OS on a new Dell XPS 15 9550. It came with windows 10 installed, and I want to be able to go back to that if issues arise with ubuntu. I'm new to both OS's, and would like to know how to avoid losing access to the original software. Thank you!\n\nA: Just do a standard dual-boot.\nTo avoid possible MFT errors, resize the Windows 10 partition in Windows first, so that the Ubuntu installer doesn't have to.\n", "Q: G++ ubuntu packaging question dpkg -s g++\nPackage: g++\nStatus: install ok installed\nPriority: optional\nSection: devel\nInstalled-Size: 16\nMaintainer: Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>\nArchitecture: amd64\nSource: gcc-defaults (1.144ubuntu1)\nVersion: 4:5.2.1-3ubuntu1\nProvides: c++-compiler\nDepends: cpp (>= 4:5.2.1-3ubuntu1), gcc (>= 4:5.2.1-3ubuntu1), g++-5 (>= 5.2.1-12~), gcc-5 (>= 5.2.1-12~)\nSuggests: g++-multilib\nDescription: GNU C++ compiler\n This is the GNU C++ compiler, a fairly portable optimizing compiler for C++.\n .\n This is a dependency package providing the default GNU C++ compiler.\nOriginal-Maintainer: Debian GCC Maintainers <debian-gcc@lists.debian.org>\n\nIf you look at this output, it says Version: 4:5.2.1-3ubuntu1. What does that 4: mean? I mean.. What I believe is true is that the version of g++ is 5.2.1 - correct?\n\nA: The 4: prefix to the version number is called the epoc.  It is a way for Debian ( and hence Ubuntu, as a derived distribution ) to create a version of a package that is considered higher than previous versions, even if the regular version number is not.  Sometimes various circumstances conspire to cause the need to release a new package that otherwise appears to go backwards in version number, and that is when the epoc is incremented.\n", "Q: phpmyadmin not working due to missing extensions I am about to use phpmyadmin on Ubuntu 16.04. But it shows that the page is not working. the error log says error 500 \nPHP Fatal error:  require_once(): Failed opening required '/usr/share/php/php-gettext/gettext.inc' (include_path='.:/usr/share/php') in /usr/share/phpmyadmin/libraries/select_lang.lib.php on line 477\n\nAt first it says that the mysqli|mysql extension is missing. but after sleepless hours I forget what I've been done to it. I am using php7.\n\nA: You need to install php-gettext , Install it using \n sudo apt-get install php-gettext\n\n\nA: I lost hours to solve this problem. Just install php-mbstring, php7.0-mbstring and php-gettext. That's it.\nYou can do that by running the following command:\nsudo apt-get install php-mbstring php7.0-mbstring php-gettext\n\n\nA: sudo apt-get install php-mbstring php7.0-mbstring php-gettext\n\nor simply:\nsudo apt-get install php-gettext\n\nand then:\nsudo service apache2 restart\n\nThis has been reported at this bug:\n\n\n*\n\n*https://bugs.launchpad.net/ubuntu/+source/phpmyadmin/+bug/1577482\n\nA: In my case, my problem was with the folder creation. When I was installing the php-gettext lib with:\nsudo apt-get install php-gettext\n\nTwo folders are created in usr/share/php\nFolder 1 - usr/share/php/php-gettext\nFolder 2 - usr/share/php/php-phpgettext\nAnd inside the first folder some symbolic links to the second folder.\nI deleted the first folder with:\nsudo rm -r usr/share/php/php-gettext\n\nAnd then copy the php-php-gettext folder to php-gettext with:\nsudo cp -r php-php-gettext php-gettext\n\nNow my phpmyadmin works.\n\nA: Try using: \nsudo apt-get install php-mbstring php7.0-mbstring php-gettext\n\n\nA: Use Synaptic Package Manager, install php7.0-mbstring, and do sudo service apache2 restart. \n\nA: I Try this:\nsudo dpkg-reconfigure phpmyadmin\nand set socket on TCP/IP. After the\nsudo apt-get install php-mbstring php7.0-mbstring php-gettext\nsudo service apache2 restart\n\nA: If you installed phpymadmin from the archives, php-gettext is a dependency and would be automatically installed.\n\nA: Run\nsudo apt-get install phpmyadmin php-mbstring php-gettext\n\nsudo service apache2 restart\n\nhttp://www.dailytechnoblog.com/how-to-resolve-phpmyadmin-error-the-mbstring-extension-is-missing-please-check-your-php-configuration/\n", "Q: Changing the desktop to Mate Background:\nI've installed xfce on my laptop and all worked great except for wi-fi. I've spent a week or so fixing it, then posted a question on Askubuntu. Chili555 helped me, but I afraid that help isn't really reproducible\nNo wifi with N1525 or external netgear A6210\nThen I backed up my system and moved to Ubuntu Mate. Everything worked out of box, except for wi-fi. Copy-pasting /lib/firmware/ath10k fixed the problem, so I didn't even bother to make a backup (silly me). One of the upgrades bricked the system. I reinstalled OS, copy-pasted /lib/firmware/ath10k, but my wireless remained dead. https://askubuntu.com/questions/753545/ubuntu-wi-fi-stopped-working-after-upgrade-to-16-04 \nI would like to have a Mate desktop with wi-fi working. What is the best way to proceed? Should I try to replace xfce with Mate using some sudo command (if so - which command?), or again ask Chili555 for some help (is pm OK?), or should I open a new thread about my wi-fi (why would a new thread better than the old one)?\nedited: added typical messages for dmesg | grep ath\n[  616.134730] ath10k_pci 0000:03:00.0: failed to start hw scan: -108    \n[  616.547924] ath10k_pci 0000:03:00.0: failed to delete WMI vdev 0: -108     \n[  616.547933] ath10k_pci 0000:03:00.0: removing stale peer d6:04:cd:86:2a:53 from vdev_id 0     \n[  616.572206] ath10k_pci 0000:03:00.0: failed to delete WMI vdev 1: -108    \n[  616.572221] ath10k_pci 0000:03:00.0: could not suspend target (-108)     \n[  627.999225] ath10k_pci 0000:03:00.0: no channel configured; ignoring frame(s)!     \n\nAlso, is this command relevant?\noptions ath10k_core skip_otp=Y\" | sudo tee /etc/modprobe.d/ath10k_core.conf \n\n\nA: Fixing wifi on a clean install of Ubuntu Mate 16.04.\nKiller 1525 specific firmware:\nDownload:\nhttps://github.com/kvalo/ath10k-firmware/blob/master/QCA6174/hw2.1/board.bin\nand put it in the /lib/firmware/ath10k/QCA6174/hw2.1/ folder (create the folder if it doesn’t exist)\nFollow steps described here:\nhttp://www.killernetworking.com/support/knowledge-base/17-linux/20-killer-wireless-ac-in-linux-ubuntu-debian\nBriefly:\nDownload:\nhttps://github.com/kvalo/ath10k-firmware/blob/master/QCA6174/hw2.1/firmware-5.bin\nNote: At the time of editing this article, it is posted as:\nhttps://github.com/kvalo/ath10k-firmware/blob/master/QCA6174/hw2.1/firmware-5.bin_SW_RM.1.1.1-00157-QCARMSWPZ-1\nand put it in the /lib/firmware/ath10k/QCA6174/hw2.1/ folder as firmware-4.bin.\n", "Q: How do I set up a cron job on Snappy? If I run \nsudo crontab -e\n\nI can edit the crontab, but it's read-only so nothing gets saved.\n\nA: You're right, you can't edit the crontab in Snappy Ubuntu Core. Personally I just create a service that sleeps. For instance, say there was an operation you wanted to run every 15 minutes. Put it in a shell script named my_service.sh:\n#!/bin/sh\nwhile true; do\n    do_my_thing\n    sleep 15m\ndone\n\nMake it executable. Now create something like the following snapcraft.yaml:\nname: foo\nversion: 1\nsummary: My snap\ndescription: My snap\n\napps:\n  my-service:\n    command: my_service.sh\n    daemon: simple\n\nparts:\n  foo:\n    plugin: copy\n    files:\n      my_service.sh: bin/\n\nIf you install the resulting snap you'll have that service with do_my_thing running every 15 minutes. If your timing requirements are more complicated (e.g. run every Sunday at 0200) you can still pull this off, but it of course gets a bit more complex.\n", "Q: Trying anything to remove Chrome sources.list error I keep getting the famous sources.list error even after trying to implement the supposed fix.  \nMy next thing is to try to totally remove chrome/chromium and start over.   So I followed these removal instructions.  \nHowever, now when I do apt-get update, I keep getting the same error.  What triggers the error?  How can I completely remove chrome or whatever triggers that error?\n\nA: To answer your main question first - for getting rid of the sudo apt-get update error message, you have to remove the Google Chrome repository  - open a terminal and execute this command :  \nsudo rm /etc/apt/sources.list.d/google-chrome.list  \n\nTo completely remove Chromium and Google Chrome execute :   \nsudo apt-get purge chromium-browser google-chrome-stable \n\nWhen you also want to remove the configuration files, delete these folders :  \n/home/user/.config/chromium and /home/user/.config/google-chrome.  \nNote : I assume that you have the google-chrome-stable package installed.  \nUpdate :\nI received an information that there might be another Google .list file in the sources.list.d folder - so in case the error still occurs, check this folder and correct or delete the entries as well.\n\nA: I finally thought of looking around in the  /etc/apt/sources.list.d directory to see if there was anything other than chrome/chromium in that is associated with google somehow.  Indeed, I found a google.list file.  I have no idea how that got there or what program it was associated with, but after deleting it my apt-get update worked cleanly.  \n", "Q: kubuntu 15.10 - Each time I try to install something I get the same dependency errors but the package seems to install OK I get the following every time I try to install anything. It always seems to install OK but I'd rather not get the errors, what am I supposed to do to fix this? All I'd like to know really is where to start looking, I'd like a push in the right direction rather than a complete solution.\nOr if anyone could just point me to the correct link? I've spent hours looking for it and not found anything that really applies to me.\nMy guess is that I should look at the repositories?\nlinux-image-4.2.0-35-generic\nsubprocess installed post-installation script returned error exit status 2\n\nlinux-image-extra-4.2.0-35-generic\ndependency problems - leaving unconfigured\n\nlinux-image-generic\ndependency problems - leaving unconfigured\n\nlinux-generic\ndependency problems - leaving unconfigured\n\nlinux-signed-image-4.2.0-35-generic\ndependency problems - leaving unconfigured\n\nlinux-signed-image-generic\ndependency problems - leaving unconfigured\n\nlinux-signed-generic\ndependency problems - leaving unconfigured\n\ninitramfs-tools\nsubprocess installed post-installation script returned error exit status 1\n\n\nA: Answer to the above question is/was that old kernels filled up the boot partition. How do I resize my /boot partition?\nBasic command to check free space on your mounted partitions: sudo df -h\n\nBelow information is an extremely shortened version of:  How do I\n  remove old kernel versions to clean up the boot menu?\nThe basic commands in this situation:\nuname -r - check which kernel is in use\nsudo apt-get autoremove - remove old kernel\nA normal kernel upgrade should work flawlessly as follows:\nsudo apt-get update; sudo apt-get dist-upgrade; sudo apt-get autoremove\n\n\nIf for any reason something goes wrong during a kernel upgrade may read this:\nHow to restore a system after accidentally removing all kernels?\nand eventually this: Removed Kernel by mistake [duplicate] && How can I boot with an older kernel version?\n", "Q: Using Grub on hard disk to boot live SD card I have a laptop running Ubuntu MATE 15.10, and said laptop has an internal media-card reader. I would like to be able to use that media-card reader to boot a liveCD installed on an SD card. Unfortunately, after much searching, I've been unable to find a way to do this. What makes this case special is:\n\n\n*\n\n*My BIOS does not support booting from the SD card, so I need to find a workaround. Using my existing installation of GRUB2 to load a kernel, access the SD card, and boot would be my preferred method. Unfortunately,\n\n*Every guide I've found online to do this only describes how to boot to a drive that gets listed as an sd* device. My SD card reader lists as mmcblk0 in my Ubuntu install. \n\n\nSo far, I have tried adding modules to my initramfs.img, modifying my grub.cfg, attempting a wide variety of methods for installing a LiveCD image on an SD card, and using the grub console. At the end of the day, however, I still have the same problem: GRUB2 cannot see my mmcblk0 device. I am certain that all I need is to get GRUB to load the appropriate modules/drivers, and see this device.I can handle it from there. Unfortunately, I don't know how to get there.\nEDIT:\nTo try and clarify a bit, what I would like to be able to do is:\n\n\n*\n\n*Insert a bootable SD card with GRUB installed \n\n*Turn on the machine and procede to the GRUB2 menu\n\n*Select a generic \"SD Card\" that will bring up the menu for the GRUB2 install on the SD card.\n\n*Boot\n\n\nTo do this, I believe that I need to:\n\n\n*\n\n*Load a Linux kernel\n\n*Load the SD card drivers via said kernel\n\n*Use the GRUB2 'chainboot' feature to boot onto the SD card\n\n\nI have a Linux kernel available to GRUB2 on the local machine, with the necessary drivers enabled. All I need to know is how to load the kernel, and how to use it to detect the SD card. \n\nA: I am not sure what you are looking for because of the wording and because you SD card is mblk0\nI got my Acer to boot from the SD card.\nI simply used a USB live cd and it and chose the SD card.\nYou can choose \"something else\" and choose where to put the boot loader.\nYou want to put that on the root of the disk.  Do not choose a pm extension,  etc.\nIf your device allows legacy boot, then it is a piece of cake.\nIf your device only allows UEFI secure boot, then you have problems.  You need to make sure the Ubuntu trusted file is set in the bios after you installed.\nHere you will need to set a password and then you can see the menu item to add a trusted source to the bios.  It will bring you to the directory where the file is.\nThen change boot order on your bios.\nAs a test, I usually hit the boot order key when booting and see some choices.   I might find 0yes  and 1yes and Windows loader.\nTry either of the yeses the number before the yes often seems to reflect the mblkid.\nLastly try boot-repair.\nBoot-repair will also tell you a command to type in Windows admin cmom and window.\nGood luck.\nRemember legacy solves most problems.   You need to boot in the mode that you want to install.  If you want to install legacy, be in legacy mode before installing.  Visa versa.\n", "Q: Unable to dual boot windows 8.1 with ubuntu 14.04 I m new to this forum and to linux.  I have windows 8.1 pre-installed in my HP 15-r007tx and I wanna make it dual boot with ubuntu. But last I tried I finished installing ubuntu based on a few videos on youtube but here is the deal. When I restart I dont get the grub bootloader. My system boots with windows directly. Someone please help me with this. Thanks in advance\n\nA: If I am understanding your question, in order to boot to your \"second\" OS, whenever the computer initially starts up you need to go to your boot menu, I've never had a computer that automatically went to the boot menu so you have to ask it do that.\nWhen your computer starts up it should have a message on the screen indicating which F-key it is to go to your boot menu. F12 is a pretty common one I believe.\nAfter you get into the boot menu select the hard drive your OS is on and then a list of the available OSes should come up, select the one you want and you should be good to go.\n", "Q: Nautilus custom folder icons in /home disappeared and i cant change them anymore Recently my customized icons inside my /home disappeared after an upgrade.\nFor example i had a customized icon for the folder /home/USER/Downloads. \nLast time i added these custom icon by right clicking the Downloads folder -> Properties -> drag and drop the new icon on the actual icon (or click the icon and navigate to the new icon) -> done.\nIm not longer able to change the icons this way in /home/USER but i am able to change the icons if i navigate further to /home/USER/Downloads/TESTFOLDER\nIm a bit out of a clue actually how this come up and how to solve this small issue.\nIm on 16.04 by the way\n\nA: In case someone comes to this, i was able to solve this by doing the following:\nsudo rm -rf ~/.gconf/apps/*\nsudo rm -rf ~/.config/nautilus\nsudo reboot\n\nWhen back at the desktop session i was able to use custom icons for my folders in ~/ again\n", "Q: Ubuntu Wifi driver offline install I've bought an wifi receiver for my pc. Model no. Edup EP-N8553. Here are the screenshot of the driver files. how to install this? is it possible to install it without any kind of internet? Please help. desktop \n\nA: People on the Raspbery Pi forums are saying this wifi dongle works with the mt7601u driver which is included in kernel 4.2.  You didn't include any information about which version of Ubuntu you are using, so I'll give you a few different options here:\nThe dongle will probably work without any configuration on 16.04 based on this post.\nEarlier releases will take one or two steps:\nIf you are using 14.04, you will need to first upgrade to the 4.2 kernel or the 4.4 kernel.  (I find the 4.2 kernel to be more stable on my computer).  To install a kernel update offline, go to packages.ubuntu.com and get the necessary packages. For example, to get the 4.2 kernel, download these packages to install offline:\nlinux-headers-4.2.0-35\nlinux-headers-4.2.0-35-generic\nlinux-image-4.2.0-35-generic\nlinux-image-extra-4.2.0-35-generic\nlinux-firmware\n\nYou do not need to upgrade the kernel for 15.04 or 15.10.\nFor all releases prior to 16.04, you will probably need to download the latest mt7601 firmware using the instructions from this post, which I have modified for offline install.  First download the latest firmware: \nhttps://github.com/porjo/mt7601/raw/master/src/mcu/bin/MT7601.bin\nThen transfer it to your offline computer: (replace filename with the location of the file you downloaded onto your usb drive or whatever.)\nsudo cp filename /lib/firmware/mt7601u.bin\n\nI don't have an Edup EP-N8553 to test this with, so I cannot guarantee that these steps will work, but it does seem that other people on the internet were having success getting this dongle working this way.\n", "Q: Unable to install 14.04. a few tries, a few issues So, yesterday, win 10 commited suicide again, by deleting internet protocols alone.\nI'm fed up of this cancer, but I still game, so I want a dual boot\nAt first I was able to install linux alone, while my partitioning was GPT. It wouldn't see my others partitions. so I installed on the whole disk\nWhen I installed win 7, it wouldn't let me chose a partition because it was GPT.\nSo I ran fixparts on terminal, and I deleted the traces of GPT partitionning.\nI was able to install Win10. \nI know I have to start with win if i don't want to install the GRUB\nMy computer has a GTX950M, so I usually have to do a NOMODESET=0\nbut i don't have the orange screen where you push \"e\" to add option. i have the blue screen, and I tried adding \"nomodeset=0\" but it still loads nouveau and freak out.\nI manage to load the installer, but it bugged at apt updates or something like that. \n15.05 didn't load either\nI'm stuck, I don't know what else to try, but I can't live anymore with only win 10 that needs a format every few weeks\n\nA: I'm stuck at installing. It worked once but I wasnt able to put Windows with it. \nBecause of gpt. Now it's supposed to be in mbr but I lost the normal orange menu for the blue one. \nIt may have installed because it said it said it had apt-update problems, yet sais it finished. but I don't have any grub showing.   \nSorry, english isn't my first language\n15.05 just doesn't open the live cd or the install \n", "Q: How to install the cPickle module? I was unable to install the cPickle module using pip:\n$ pip --version\npip 1.5.6 from /usr/lib/python2.7/dist-packages (python 2.7)\n$ pip install cPickle\n...\n  Could not find any downloads that satisfy the requirement pickle\n\nAttempting installation with pip3 was also unsuccessful:\n$ pip3 --version\npip 1.5.6 from /usr/lib/python3/dist-packages (python 3.4)\n$ pip3 install cPickle\n...\n  Could not find any downloads that satisfy the requirement cPickle\n\nCould you help me in understanding why this doesn't work?\n\nA: Python 2.7 and Python 3.4 include the pickle and cPickle modules already.  You do not need to take any extra steps to install them.  You can see a list of currently installed modules by typing\nhelp('modules')\n\nfrom a Python prompt.\n\nA: cPickle is by default part of the standard library, but the capital P could be confusing. You should use:\nimport cPickle \n\nWith the capitial P.\n", "Q: How to disable the shortcut for New Profile in command line (Terminal) I was playing around terminal and I came across Terminal Preference. Under that there is a tab called Shortcut where I accidentally enabled shortcut for New Profile as Q. Now whenever I press Q on terminal a new profile is created. I'm using Ubuntu 15.04\nHow do I disable that? Here is the snapshot of what happened:\n\n\nA: Double click on that Q and then press Backspace.\n", "Q: Kubuntu 15.10 | Wine | cannot import dll :isskin.dll error in installing game mafia2-black box.\ncannot import dll :isskin.dll.\n\n\n\nA: \nThe error message:    cannot import dll :isskin.dll is created\n  through the missing dll library. on a baremetal wine install its\n  installed with winetricks through the console by executing\nwinetricks vcrun6sp6.\n\nIn playonlinux you can install libraries when creating or editing a VM - the library name to install to solve the issue is vcrun6. \nSame for directX - the game installer of direcX 9c did not work, thus i skipped it on the second try. \nThe playonlinux library d3dx9 seemed to work as the game started and i was able to play. The physx game installer did work.\nWine version tested is 1.9.7 on a x64 VM manually created with playonlinux.\nTo install a custom version of Wine with playonlinux go to \"top menu\" -> tools -> \"Manage Wine Versions\" -> select x86 or x64 as per your needs and proceed with the desired version.\nTo edit the installed libraries, wine settings and versions of an existing VM for to \"Configure\" on the second bar menu in playonglinux.\nTo create teh desired custom VM go to: \"Install\" on the second bar menu and navigate to the lower left corner to \"Install a non-listed program\" - > create a new VM and checkmark \"Use another version of wine\" and \"install some libraries\" - proceed as described above.\nWhen closing the game you often receive a message that the game has crashed which is bogus as you just closed it :)\nThis should work for most applications - as there are many settings as the wine version and libraries working together its a tricky territory - i fiddled it by just trying out - in the end i would have installed a windows dualboot with ubuntu in the same amount of time.\nThe OS was Kubuntu 15.10 and playonlinux from the repositories.\n", "Q: Ubuntu Samba Server is Taking a Long Time to Load Directories I have Ubuntu Server 14.04 LTS running a Samba File server. One issue I seem to be having is whenever the server is running and I got to a PC to look at the server, it will show the first layer but when I open that layer up it won't show the layer below that unless I go back to the previous layer and let it sit there. This happens for every level down to the file level. Once it loads up, everything runs fine its just the first time that doesn't load in any semblance of speed.\nI am new to Ubuntu Server and Samba so it could be something simple I am missing, I'm just not sure.\nI am running Samba Version 4.1.6-Ubuntu\nYears later I tried again and no problems, incorrect conf file I suspect.\n\nA: I dont have the definitive answer to this problem, but i experienced a similar problem with the follow system links enabled in the smb.conf file.\nWhat are the specs of the machine you are using? ( I doubt this has a major effect) \nHave you tried using a system monitoring tool like Glances to watch the performance of your server as you access these folders, a good guide to installation can be found on This answer.\nIf you add your smb.conf file into your original question it may provide more insight (Please strip all the default comments if you are going to do so) \n", "Q: What is the correct order for placing flags and parameters in a CLI program I have noticed that some programs work differently when the flags are used before the input parameters, rather than adding the flags at the end. So I want to know, what is the conventionally accepted way to order parameters and flags in an Ubuntu CLI program. \nI'm specifically asking about Ubuntu as this is my platform of concern. I understand that this depends on the program being run, but what is the norm?\nEg:\n./myprog -d file.txt\n\nVs \n./myprog file.txt -d\n\n\nA: There is no correct order, as it varies from program to program. The OS just hands the command line arguments over to the program in the order they are given. The way in which they are parsed depends on the program or the parsing libraries that are used.\nIn most cases the order doesn't matter and common parsing libraries like getopt or Python's argparse allow order independent parsing. But other programs can be more picky. Also note that even with order independent parsing you still have order depended arguments. Meaning some options must be follow by a argument:\n ls --sort time -l\n\nThe time here is an argument to the --sort option and thus must come after it. However the order of --sort time and -l doesn't matter. Many programs allow writing --sort=time to make this more explicit, but not all do.\nThe GNU project does have a coding standard for command line handling and most of their tools follow that, but it's not something you can depend on.\nIn cases where order does matter, you generally do ./myprog -d file.txt and it looks nicer in shell scripts as well. The ./myprog file.txt -d style of writing is more for the command line when you just typed the thing and want to add a -d flag, but not cursor all the way back to the middle of the line.\n\nA: As far as I've seen there is no convention. If you are developing a program/script it is up to you to decide how the order should be handled. For instance, find command will issue a warning if I place argument related to directory after argument related to naming.\n$ find /etc -iname \"passwd\" -maxdepth 1\nfind: warning: you have specified the -maxdepth option after a non-option argument -iname, but options are not positional (-maxdepth affects tests specified before it as well as those specified after it).  Please specify options before other arguments.\n\n/etc/passwd\n\nOther programs might not care about the order. I've a simple getopts.sh script which I keep for when i need to use command line arguments in another script, and it parses arguments in no particular order\n$ getopts.sh  test1 -w1 test2                                                 \nHello, I'm main\nThe arguments are  test1 -w1 test2\n\n\nA: POSIX conventions and recommendations are that options (things with -) precede arguments/operands (everything else).  It's the safest assumption.\nhttp://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap12.html#tag_12_02\n", "Q: Recommendations for a simple screenshot annotation tool? I am looking for a simple screenshot annotation tool with the following features:\n\n\n*\n\n*Crop\n\n*Resize\n\n*Blur\n\n*Draw shapes and lines\n\n*Add text\n\n\nA: You could do worse than to use the screen capture tool scrot and open the resulting screenshot directly in gimp:\nscrot -q 100 -e 'gimp $f'\n\nYou can set this particular commandline to a key, I illustrate here mapped to F6:\n\nOr you can simply run it from the commandline with the glorious addition of a timer and delay:\nscrot -d 10 -c -q 100 -e 'gimp $f'\n\nThe gimp should make short work of your image manipulation needs and there are many other scrot settings which you can tailor to your needs...\n", "Q: error in installing android studio using ubuntu make Ubuntu 15.10\nWhen I tried to install android studio using ubuntu make it shows this error\n$ umake android\nChoose installation path: /home/prasanth/tools/android/android-studio\nERROR: We were expecting to find a license on the download page, we didn't.\n\n\nA: The issues gets solved when you provide [--accept-license  Accept license without prompting] option\numake android --accept-license\n\n", "Q: Segmentation Fault when trying to run blender I have been working on this for several hours now and don't know where else to go. I originally started building Blender on my Ubuntu Desktop v 14.04 based on this guide. Setting up git was no problem...at least as far as I can tell.\nAfter trying to run ./install_deps.sh I would get the following output at the end:\nWARNING! ****WARNING****\nIf you are experiencing issues building Blender, _*TRY A FRESH, CLEAN BUILD FIRST*_!\nThe same goes for install_deps itself, if you encounter issues, please first erase everything in /home/david/src/blender-deps and /opt/lib\n(provided obviously you did not add anything yourself in those dirs!), and run install_deps.sh again!\nOften, changes in the libs built by this script, or in your distro package, cannot be handled simply, so...\n\nYou may also try to use the '--build-foo' options to bypass your distribution's packages\nfor some troublesome/buggy libraries...\n\n\nRan with:\n    install_deps.sh \n\n\nIf you're using CMake add this to your configuration flags:\n  -D WITH_CODEC_SNDFILE=ON\n  -D PYTHON_VERSION=3.5\n  -D PYTHON_ROOT_DIR=/opt/lib/python-3.5\n  -D WITH_OPENCOLORIO=ON\n  -D OPENCOLORIO_ROOT_DIR=/opt/lib/ocio\n  -D OPENEXR_ROOT_DIR=/opt/lib/openexr\n  -D WITH_OPENIMAGEIO=ON\n  -D OPENIMAGEIO_ROOT_DIR=/opt/lib/oiio\n  -D WITH_CYCLES_OSL=ON\n  -D WITH_LLVM=ON\n  -D LLVM_VERSION=3.4\n  -D CYCLES_OSL=/opt/lib/osl\n  -D WITH_OPENSUBDIV=ON\n  -D OPENSUBDIV_ROOT_DIR=/opt/lib/osd\n  -D WITH_CODEC_FFMPEG=ON\n  -D FFMPEG_LIBRARIES='avformat;avcodec;avutil;avdevice;swscale;swresample;lzma;rt;theoradec;theoraenc;theora;vorbis;vorbisfile;vorbisenc;ogg;x264;openjpeg'\n  -D FFMPEG=/opt/lib/ffmpeg\n\nOr even simpler, just run (in your blender-source dir):\n  make -j1 BUILD_CMAKE_ARGS=\"-U *SNDFILE* -U *PYTHON* -U *BOOST* -U *Boost* -U *OPENCOLORIO* -U *OPENEXR* -U *OPENIMAGEIO* -U *LLVM* -U *CYCLES* -U *OPENSUBDIV* -U *COLLADA* -U *FFMPEG* -D WITH_CODEC_SNDFILE=ON -D PYTHON_VERSION=3.5 -D PYTHON_ROOT_DIR=/opt/lib/python-3.5 -D WITH_OPENCOLORIO=ON -D OPENCOLORIO_ROOT_DIR=/opt/lib/ocio -D OPENEXR_ROOT_DIR=/opt/lib/openexr -D WITH_OPENIMAGEIO=ON -D OPENIMAGEIO_ROOT_DIR=/opt/lib/oiio -D WITH_CYCLES_OSL=ON -D WITH_LLVM=ON -D LLVM_VERSION=3.4 -D CYCLES_OSL=/opt/lib/osl -D WITH_OPENSUBDIV=ON -D OPENSUBDIV_ROOT_DIR=/opt/lib/osd -D WITH_CODEC_FFMPEG=ON -D FFMPEG_LIBRARIES='avformat;avcodec;avutil;avdevice;swscale;swresample;lzma;rt;theoradec;theoraenc;theora;vorbis;vorbisfile;vorbisenc;ogg;x264;openjpeg' -D FFMPEG=/opt/lib/ffmpeg\"\n\nThis information has been written to /home/david/Documents/blender/build_files/build_environment/BUILD_NOTES.txt\n\nNaturally, I tried running the suggested command at the end of the warning:\nmake -j1 BUILD_CMAKE_ARGS=\"-U *SNDFILE* -U *PYTHON* -U *BOOST* -U *Boost* -U *OPENCOLORIO* -U *OPENEXR* -U *OPENIMAGEIO* -U *LLVM* -U *CYCLES* -U *OPENSUBDIV* -U *COLLADA* -U *FFMPEG* -D WITH_CODEC_SNDFILE=ON -D PYTHON_VERSION=3.5 -D PYTHON_ROOT_DIR=/opt/lib/python-3.5 -D WITH_OPENCOLORIO=ON -D OPENCOLORIO_ROOT_DIR=/opt/lib/ocio -D OPENEXR_ROOT_DIR=/opt/lib/openexr -D WITH_OPENIMAGEIO=ON -D OPENIMAGEIO_ROOT_DIR=/opt/lib/oiio -D WITH_CYCLES_OSL=ON -D WITH_LLVM=ON -D LLVM_VERSION=3.4 -D CYCLES_OSL=/opt/lib/osl -D WITH_OPENSUBDIV=ON -D OPENSUBDIV_ROOT_DIR=/opt/lib/osd -D WITH_CODEC_FFMPEG=ON -D FFMPEG_LIBRARIES='avformat;avcodec;avutil;avdevice;swscale;swresample;lzma;rt;theoradec;theoraenc;theora;vorbis;vorbisfile;vorbisenc;ogg;x264;openjpeg' -D FFMPEG=/opt/lib/ffmpeg\"\n\nWhich produced\nedit build configuration with: /home/david/Documents/build_linux/CMakeCache.txt run make again to rebuild.\nBlender successfully built, run from: /home/david/Documents/build_linux/bin/blender\n\nAfter trying to run ./blender I received the following error:\nfound bundled python: /home/david/Documents/build_linux/bin/2.77/python\nWriting: /tmp/blender.crash.txt\nSegmentation fault (core dumped)\n\nHere's the output\n# Blender 2.77 (sub 0), Commit date: 2016-04-08 22:25, Hash d09a372\n\n# backtrace\n./blender(BLI_system_backtrace+0x1d) [0x136fb1d]\n./blender() [0xa201b8]\n/lib/x86_64-linux-gnu/libc.so.6(+0x36d40) [0x7f7a25397d40]\n/usr/lib/x86_64-linux-gnu/libLLVM-3.4.so.1(_ZN4llvm13EngineBuilder12selectTargetERKNS_6TripleENS_9StringRefES4_RKNS_15SmallVectorImplISsEE+0x1a7) [0x7f7a21a49dd7]\n/usr/lib/x86_64-linux-gnu/libLLVM-3.4.so.1(_ZN4llvm13EngineBuilder12selectTargetEv+0x9c) [0x7f7a21a4a27c]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x3b0629) [0x7f7a077a2629]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x3aec28) [0x7f7a077a0c28]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x3d0c4d) [0x7f7a077c2c4d]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x3d2025) [0x7f7a077c4025]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x309e1f) [0x7f7a076fbe1f]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x30304f) [0x7f7a076f504f]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x303537) [0x7f7a076f5537]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x5b7fad) [0x7f7a079a9fad]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x3625e7) [0x7f7a077545e7]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x1d7d20) [0x7f7a075c9d20]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x1ab40b) [0x7f7a0759d40b]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x18e44a) [0x7f7a0758044a]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x18e8b5) [0x7f7a075808b5]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x18edc3) [0x7f7a07580dc3]\n/usr/lib/x86_64-linux-gnu/dri/vmwgfx_dri.so(+0x190583) [0x7f7a07582583]\n./blender(ED_region_do_draw+0x6f3) [0xcdc023]\n./blender() [0xa242e4]\n./blender(wm_draw_update+0x5ac) [0xa2558c]\n./blender(WM_main+0x28) [0xa20d68]\n./blender(main+0x385) [0xa044d5]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f7a25382ec5]\n./blender() [0xa1d077]\n\nAfter trying for many hours, I made no progress. So I reinstalled Ubuntu (running on a virtual machine), ran everything again with all the same errors. Obvsiously, it's crazy to try something over and over again expecting something different, but I thought reinstalling the OS would fix it. Literally did nothing.\nOn a side note, I find it odd that there aren't any 3rd party tutorials (outside of the blender website) that don't show how to setup a blender build environment using Ubuntu. Or maybe there is and I can't find it.\nLet me know if I'm missing any additional info that will help and I'll include it.\n\nA: I was able to get it working after installing Ubuntu 15.10. All the steps were replicated exactly.\nThe issue is fixed, but just to note: it appears to be using python 2.77. My understanding was that blender requires python 3.x. I will be investigating this.\n", "Q: apt-get update failure explanation Go ahead, vote it as duplicate, but none of the answers provide a good explanation of what really is going on. Nor did what they suggest work. Can you please explain the elements involved in the first error at least, to the level that a human can then understand how to proceed in an informed manner? I find the command-line voodoo of existing answers not the right tactic for reliably solving problems. A tailored explanation of the elements at work is what this question is seeking.\nW: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/trusty/Release  Unable to find expected entry 'universe/binary-amd64/Packages' in Release file (Wrong sources.list entry or malformed file)\n\nW: Failed to fetch http://dl.google.com/linux/chrome/deb/dists/stable/Release.gpg  Bad header line [IP: 216.58.214.78 80]\n\nW: Failed to fetch http://dl.google.com/linux/chrome/deb/dists/stable/main/binary-amd64/Packages  404  Not Found [IP: 216.58.214.78 80]\n\nE: Some index files failed to download. They have been ignored, or old ones used instead.\n\n\nA: The \"Failed to fetch...\" warning can be either a real problem with your sources.list or a temporary issue with the remote server or your connection to the server, depending on the details.  It's not uncommon for these warnings to occur from time to time because the internet is not 100% reliable.  I would only worry about these warnings if they persist for some number of days.\nIn the case of your the first warning (the archive.ubuntu.com), it is saying that it cannot find the entry \"universe/binary-amd64/Packages\" in the listing at http://archive.ubuntu.com/ubuntu/dists/trusty/Release.  However, if you go to that page in your browser and search for that entry, you will see that it is there.\nI have personally being having a lot of problems with the archive.ubuntu.com server over the past week, so I switched my software mirror and have not been having issues since then.  You can do that from System Settings > Software & Updates under the \"Ubuntu Software\" tab.  See this article: http://www.asim.pk/2014/05/25/how-to-change-download-mirror-in-ubuntu/\nRegarding the warnings about the Google Chrome repository, the first warning says there is something wrong with the response the server is sending in to your computer's request (the \"header\" portion of the server's response is not correct), and the second one is saying that the server does not have the file your computer is requesting.  Both of them are providing you with the IP address the request was sent to, so you could use an online DNS lookup to make sure your computer is trying to connect to the right address.\n", "Q: Allocating disk space as memory temporarily I need to run some application to convert large files (7GB). The converter application isn't nicely written. So it doesn't stream the coverted data. Therefore, it requires high amount of memory. I have 8GB memory and 8GB swap space. But the application reports a memory usage of around 9GB and stops at 60% of conversion. I assume with some more memory, I can finish the task. As this needs to be done once only, I can maybe allocate some space from my SSD to extend memory temporarily. Only for this operation. Is there any way to do that without messing with partitions?\nThanks!\n\nA: You can indeed use swapfile as temporary addition to your system memory. Personally, I have an SSD and use 1 GB swap file for protection instead of having a partition , since it's a compromise between using the limited disk space, but having extra memory if I ever run out of RAM\nFirst create the file itself\nsudo dd if=/dev/zero of=/swapfile bs=1M count=1024\n\nThe command will create a file named swapfile inside your root folder, its content being all zeroes and size of 1024 megabytes (1 GB). To make it 2 GB , change count value to 2048\nNext, make it read-writable by root only\nsudo chmod 600 /swapfile\n\nAnd format it to swap\nsudo mkswap /swapfile\n\nFinally, enable the file\nsudo swapon /swapfile\n\nYou can disable it at any point using sudo swapoff /swapfile command and remove at will; in addition, since here we don't add it to the /etc/fstab file, it won't be added at next boot, so on the next boot you can remove it\nFYI, all this I've turned into a script so that there's an actual single command you can execute to add swap. See How can i increase size of swap file?\n", "Q: Driver for JMicron SD Controller I have an Asus laptop running Ubuntu 15.10, it has an internal sd card reader, but I don't seem to be able to use it, the system didn't make anything when inserting a card.\nThe output of lspci -nnk is:  \n07:00.2 SD Host controller [0805]: JMicron Technology Corp. Standard SD Host Controller [197b:2381] (rev 80)\nSubsystem: ASUSTeK Computer Inc. Device [1043:1a07]\n07:00.5 Ethernet controller [0200]: JMicron Technology Corp. JMC250 PCI Express Gigabit Ethernet Controller [197b:0250] (rev 03)\nSubsystem: ASUSTeK Computer Inc. Device [1043:1905]\nKernel driver in use: jme\n\nI tried a couple of solutions out there but none worked for me.\n\nA: I was with the same problem of yours, then, after a couple of weeks with no solution, i finally found a website that had my problem solved. Run these commands on the terminal as root:\n~# echo tifm_sd >> /etc/modules\n~# echo mmc_block >> /etc/modules\nIdk why but \"sudo\" does not work with me for these commands.\nThe website that helped me: http://kaustubhghanekar.blogspot.com.br/2013/04/making-you-sd-card-work-with-your.html\nThat is it! Here my SD Card Reader (JMicron) now works properly.\nPs: Sorry for the bad english, it isn't my natural language.\n", "Q: Help - Command/Script to calculate WiFi speed and save Hello to all the community\nFew days ago, I asked the community to help me create a script.\n#!/bin/bash\n\ndate=$(date --iso-8601=seconds)\nprintf 'TIME (s)\\tSIGNAL STRENGTH (dBm)\\t\\tTxBITRATE (MBit/s)\\t\\tRxBITRATE (MBit/s)\\n' >\"$date\"\nprintf '\\n' >>\"$date\"\n\nfor ((i=0; i<=120; i=i+1)); do\n\n    iw dev wlan0 station dump | awk -vt=$i '$1==\"signal:\"{s=$2} $1==\"tx\"{txb=$3} $1==\"tx\"{texttx=$5 $6 $7}  $1==\"rx\"{rxb=$3} $1==\"rx\"{textrx=$5 $6 $7}  END {printf \"%d\\t\\t\\t%d\\t\\t\\t%.1f\\t%s\\t\\t\\t%.1f\\t%s\\n\", t, s, txb, texttx, rxb, textrx}' >>\"$date\"\n    sleep 1\n\ndone\n\nThe script generates an output file whose name is the time it starts, as follows:\n\nTIME (s)    SIGNAL STRENGTH (dBm)       TxBITRATE (MBit/s)      RxBITRATE (MBit/s)\n0           -64         135.0   MCS640MHz           108.0   MCS540MHz\n1           -64         135.0   MCS640MHz           108.0   MCS540MHz\n2           -66         90.0    MCS440MHz           108.0   MCS540MHz\n3           -66         120.0   MCS540MHz           108.0   MCS540MHz\n...\n\nThis script creates a series of columns of data, but I would add other more.\nI want to add the transmission rate since the previous script gets modulation and therefore the maximum rate, but not the speed in an instant.\nI would like to modify the script that I have to add transmision speed in another column.\nI thought about getting the number of packets that were sent reading the file /proc/net/dev\ngrep \"wlan0\" /proc/net/dev | awk '$1==\"wlan0:\"{print $2}'; #rx packages\ngrep \"wlan0\" /proc/net/dev | awk '$1==\"wlan0:\"{print $10}'; #tx packages\n\nI do not know if there is another way to do better. (Surely yes)\nTherefore, the new script should be adapted to the above to read those packages in two instants of time, subtracted and divided by the time elapsed between them and stored in the same line of the main loop in another column of the same file.\nThe result I want to get is as follows (more or less):\n\nTIME (s) SIGNAL STRENGTH (dBm) TxBITRATE (MBit/s) RxBITRATE (MBit/s) TxSpeed (Mbs) RxSpeed (Mbs)\n0           -64         135.0   MCS640MHz           108.0   MCS540MHz 1.2 0.3\n1           -64         135.0   MCS640MHz           108.0   MCS540MHz 1.5 0.4\n2           -66         90.0    MCS440MHz           108.0   MCS540MHz 1.5 0.5\n3           -66         120.0   MCS540MHz           108.0   MCS540MHz 2.1 0.5\n...\n\nHow I can change the script that I have to add WiFi speed?\nThank you very much in advance.\nA greeting.\nAntonioG\n\nA: Hello to all the community,\nIn the end, I created a script that does what I want.\nSurely there is a simpler solution, but this works for me.\nIf anyone is interested, here I leave.\n#!/bin/bash\n\ndate=$(date --iso-8601=seconds)\nprintf 'TIME (s)\\tSIGNAL STRENGTH (dBm)\\t\\tTxBITRATE (MBit/s)\\t\\tRxBITRATE (MBit/s)\\t\\tRxRATE (KB/s)\\t\\tTxRATE (KB/s)\\n' >\"$date\"\nprintf '\\n' >>\"$date\"\n\nfor ((i=0; i<=120; i=i+1)); do\n\niw dev wlan0 station dump | awk -vt=$i '$1==\"signal:\"{s=$2} $1==\"tx\"{txb=$3} $1==\"tx\"{texttx=$5 $6 $7}  $1==\"rx\"{rxb=$3} $1==\"rx\"{textrx=$5 $6 $7}  END {printf \"%d\\t\\t\\t%d\\t\\t\\t%.1f\\t%s\\t\\t\\t%.1f\\t%s\", t, s, txb, texttx, rxb, textrx}' >>\"$date\"\n\nrx1= grep \"wlan0\" /proc/net/dev | awk '$1==\"wlan0:\"{print \"1: -\" $2}' > \"salida1\"\ntx1= grep \"wlan0\" /proc/net/dev | awk '$1==\"wlan0:\"{print \"1: -\" $10}' > \"salida2\"\n    sleep 1\n\nrx2= grep \"wlan0\" /proc/net/dev | awk '$1==\"wlan0:\"{print \"2: \"$2}' >> \"salida1\"\ntx2= grep \"wlan0\" /proc/net/dev | awk '$1==\"wlan0:\"{print \"2: \"$10}' >> \"salida2\"\n\nawk '{ sum += $2/1000 } END { printf \"\\t\\t\\t\"sum}' salida1 >> \"$date\"\nsum=0; \nawk '{ sum += $2/1000 } END { print \"\\t\\t\\t\"sum}' salida2 >> \"$date\" \nsum=0;\n\ndone\n\nGreetings,\nAntonioG.\n", "Q: Fan running at maximum speed on Asus UX32A since last update on Ubuntu 14.04 Have been using Ubuntu 14.04 for a while now, but am still not an advanced user.\nAfter one of the recent updates to the OS, the fan for my laptop runs at abnormally high speeds for prolonged periods. It occasionally slows down briefly (less than 10 seconds) and then speeds up again. The laptop is not overheating, but the issue persists nonetheless, and is very loud and annoying.\nI had a similar problem a few months ago, and could not find a solution at the time. One of the updates solved the issue, so I had not thought about it since then. \nI found some solutions which involve editing the grub config files, but these were a couple of years old. I was wondering whether there are any newer solutions? I have also found mentions of using lmsensors or fancontrol, but have not tried those yet. \nSince the problem has returned it is very annoying as the fan runs at full speed as long as the laptop is powered on. I would appreciate any help in solving this! I may need simplified instructions though, as I am still getting to grips with handling Linux. \nThanks in advance!\n\nA: You can try to install (or check if it is already installed) thermald. It is a daemon that prevent your PC from overheating. To install run the following command:\nsudo apt-get install thermald\n\nI also suggest to enable Intel P-State frequency governor that manage how your CPU change working frequency. To do this edit grub configuration file\nsudo nano /etc/default/grub\n\nand add intel_pstate=enable to the following line as showed below\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash intel_pstate=enable\"\n\nNow you have to run\nsudo update-grub\n\nto apply changes and then reboot your system to start Intel P-state driver.\nIf this solution is not enough or you want finer fan control you can read this post where you can find a briefly explanation about lm-sensors (cpu sensors monitor) and fancontrol (let you manage fan settings) programs.\nI hope this will help you.\n", "Q: How do I highlight a word or a phrase in a command's output? For example i enter lshw for listing hardware modules; when I hit enter, it gives me a long list of output, but what if I want to highlight one word or phrase in the output?\n\nA: Using ANSI escape sequences , one can colorize anything in console. Combining that method with awk, we can filter specific words , and make them colorized. \nConsider this example:\n$> df | awk  '{for(i=1;i<=NF;i++){ if($i~/sda/) $i=sprintf(\"\\033[0;36m %s \\033[0;00m\",$i)}; print}'   \n\n\n\nA: According to this StackOverflow question, you can use grep -E --color\nFor example if you want to highlight the word \"product\" you can do this :\nlshw | grep -E --color 'product|'\n\nTo highlight the word \"product\" with output in less you can do this :\nlshw | grep -E --color=always 'product|' | less -R\n\n", "Q: Running SSH and Samba servers simultaneusly I have both servers installed and configured on a computer. (The reason I'm not content with SSH alone is that I've not been successful generating and using key files in Android.)\nHowever it seems that the SSH server blocks connections to the Samba server and I cannot access the Samba shares from other devices. What can I do? \nHere is the contents of smb.conf:\n   #======================= Global Settings =======================\n\n[global]\n\n## Browsing/Identification ###\n\n# Change this to the workgroup/NT-domain name your Samba server will part of\n    workgroup = workgroup\n\n# server string is the equivalent of the NT Description field\n    server string = %h server (Samba, Ubuntu)\n\n# Windows Internet Name Serving Support Section:\n# WINS Support - Tells the NMBD component of Samba to enable its WINS Server\n#   wins support = no\n\n# WINS Server - Tells the NMBD components of Samba to be a WINS Client\n# Note: Samba can be either a WINS Server, or a WINS Client, but NOT both\n;   wins server = w.x.y.z\n\n# This will prevent nmbd to search for NetBIOS names through DNS.\n    dns proxy = no\n\n#### Networking ####\n\n# The specific set of interfaces / networks to bind to\n# This can be either the interface name or an IP address/netmask;\n# interface names are normally preferred\n;   interfaces = 127.0.0.0/8 eth0\n\n# Only bind to the named interfaces and/or networks; you must use the\n# 'interfaces' option above to use this.\n# It is recommended that you enable this feature if your Samba machine is\n# not protected by a firewall or is a firewall itself.  However, this\n# option cannot handle dynamic or non-broadcast interfaces correctly.\n;   bind interfaces only = yes\n\n\n\n#### Debugging/Accounting ####\n\n# This tells Samba to use a separate log file for each machine\n# that connects\n    log file = /var/log/samba/log.%m\n\n# Cap the size of the individual log files (in KiB).\n    max log size = 1000\n\n# If you want Samba to only log through syslog then set the following\n# parameter to 'yes'.\n#   syslog only = no\n\n# We want Samba to log a minimum amount of information to syslog. Everything\n# should go to /var/log/samba/log.{smbd,nmbd} instead. If you want to log\n# through syslog you should set the following parameter to something higher.\n    syslog = 0\n\n# Do something sensible when Samba crashes: mail the admin a backtrace\n    panic action = /usr/share/samba/panic-action %d\n\n\n####### Authentication #######\n\n# Server role. Defines in which mode Samba will operate. Possible\n# values are \"standalone server\", \"member server\", \"classic primary\n# domain controller\", \"classic backup domain controller\", \"active\n# directory domain controller\". \n#\n# Most people will want \"standalone sever\" or \"member server\".\n# Running as \"active directory domain controller\" will require first\n# running \"samba-tool domain provision\" to wipe databases and create a\n# new domain.\n    server role = standalone server\n\n# If you are using encrypted passwords, Samba will need to know what\n# password database type you are using.  \n;   passdb backend = tdbsam\n\n    obey pam restrictions = yes\n\n# This boolean parameter controls whether Samba attempts to sync the Unix\n# password with the SMB password when the encrypted SMB password in the\n# passdb is changed.\n    unix password sync = yes\n\n# For Unix password sync to work on a Debian GNU/Linux system, the following\n# parameters must be set (thanks to Ian Kahan <<kahan@informatik.tu-muenchen.de> for\n# sending the correct chat script for the passwd program in Debian Sarge).\n    passwd program = /usr/bin/passwd %u\n    passwd chat = *Enter\\snew\\s*\\spassword:* %n\\n *Retype\\snew\\s*\\spassword:* %n\\n *password\\supdated\\ssuccessfully* .\n\n# This boolean controls whether PAM will be used for password changes\n# when requested by an SMB client instead of the program listed in\n# 'passwd program'. The default is 'no'.\n    pam password change = yes\n\n# This option controls how unsuccessful authentication attempts are mapped\n# to anonymous connections\n    map to guest = bad user\n\n########## Domains ###########\n\n#\n# The following settings only takes effect if 'server role = primary\n# classic domain controller', 'server role = backup domain controller'\n# or 'domain logons' is set \n#\n\n# It specifies the location of the user's\n# profile directory from the client point of view) The following\n# required a [profiles] share to be setup on the samba server (see\n# below)\n;   logon path = \\\\%N\\profiles\\%U\n# Another common choice is storing the profile in the user's home directory\n# (this is Samba's default)\n#   logon path = \\\\%N\\%U\\profile\n\n# The following setting only takes effect if 'domain logons' is set\n# It specifies the location of a user's home directory (from the client\n# point of view)\n;   logon drive = H:\n#   logon home = \\\\%N\\%U\n\n# The following setting only takes effect if 'domain logons' is set\n# It specifies the script to run during logon. The script must be stored\n# in the [netlogon] share\n# NOTE: Must be store in 'DOS' file format convention\n;   logon script = logon.cmd\n\n# This allows Unix users to be created on the domain controller via the SAMR\n# RPC pipe.  The example command creates a user account with a disabled Unix\n# password; please adapt to your needs\n; add user script = /usr/sbin/adduser --quiet --disabled-password --gecos \"\" %u\n\n# This allows machine accounts to be created on the domain controller via the \n# SAMR RPC pipe.  \n# The following assumes a \"machines\" group exists on the system\n; add machine script  = /usr/sbin/useradd -g machines -c \"%u machine account\" -d /var/lib/samba -s /bin/false %u\n\n# This allows Unix groups to be created on the domain controller via the SAMR\n# RPC pipe.  \n; add group script = /usr/sbin/addgroup --force-badname %g\n\n############ Misc ############\n\n# Using the following line enables you to customise your configuration\n# on a per machine basis. The %m gets replaced with the netbios name\n# of the machine that is connecting\n;   include = /home/samba/etc/smb.conf.%m\n\n# Some defaults for winbind (make sure you're not using the ranges\n# for something else.)\n;   idmap uid = 10000-20000\n;   idmap gid = 10000-20000\n;   template shell = /bin/bash\n\n# Setup usershare options to enable non-root users to share folders\n# with the net usershare command.\n\n# Maximum number of usershare. 0 (default) means that usershare is disabled.\n;   usershare max shares = 100\n\n# Allow users who've been granted usershare privileges to create\n# public shares, not just authenticated ones\n    usershare allow guests = yes\n    username map = /etc/samba/smbusers\n    security = user\n;   encrypt passwords = yes\n;   guest ok = no\n;   guest account = nobody\n\n#======================= Share Definitions =======================\n\n# Un-comment the following (and tweak the other settings below to suit)\n# to enable the default home directory shares. This will share each\n# user's home directory as \\\\server\\username\n[homes]\n   comment = Home Directories\n   browseable = yes\n   valid users= %S\n\n# By default, the home directories are exported read-only. Change the\n# next parameter to 'no' if you want to be able to write to them.\n;   read only = yes\n\n# File creation mask is set to 0700 for security reasons. If you want to\n# create files with group=rw permissions, set next parameter to 0775.\n;   create mask = 0700\n\n# Directory creation mask is set to 0700 for security reasons. If you want to\n# create dirs. with group=rw permissions, set next parameter to 0775.\n;   directory mask = 0700\n\n# By default, \\\\server\\username shares can be connected to by anyone\n# with access to the samba server.\n# Un-comment the following parameter to make sure that only \"username\"\n# can connect to \\\\server\\username\n# This might need tweaking when using external authentication schemes\n;   valid users = %S\n\n# Un-comment the following and create the netlogon directory for Domain Logons\n# (you need to configure Samba to act as a domain controller too.)\n;[netlogon]\n;   comment = Network Logon Service\n;   path = /home/samba/netlogon\n;   guest ok = yes\n;   read only = yes\n\n# Un-comment the following and create the profiles directory to store\n# users profiles (see the \"logon path\" option above)\n# (you need to configure Samba to act as a domain controller too.)\n# The path below should be writable by all users so that their\n# profile directory may be created the first time they log on\n;[profiles]\n;   comment = Users profiles\n;   path = /home/samba/profiles\n;   guest ok = no\n;   browseable = no\n;   create mask = 0600\n;   directory mask = 0700\n\n[printers]\n    comment = All Printers\n    browseable = no\n    path = /var/spool/samba\n    printable = yes\n;   guest ok = no\n;   read only = yes\n    create mask = 0700\n\n# Windows clients look for this share name as a source of downloadable\n# printer drivers\n[rez]\n    path = /media/rez\n    writeable = yes\n;   browseable = yes\n    valid users = avahi\n\n\nA: Your share is not correctly configured in Samba, this is no fault of the SSH server. Here is how a share that allows anyone on the network to view, read, and write should look:\n[Downloads]\ncomment = Downloads\npath = \"/home/pi/Downloads\"\nwriteable = yes\nguest ok = yes\ncreate mask = 0644\ndirectory mask = 0755\nforce user = pi\n\nIf you would like to force users to use a password, remove or comment the guest ok line. If you would like to make read-only, remove or comment the writeable path, or change the yes to a no in either of those lines to achieve the desired effect. Also, make sure you change the paths and usernames to what is appropriate for your configuration.\nTo share the home directories, things are little different. Delete the predefined homes share section, and replace it with this:\n[homes]\ncomment = Home Directories\nbrowseable = yes\nwriteable = yes\nvalid users = %S\n\nIf your home directory share still doesn't work after this, you can manually share them:\n[user-home]\ncomment = User's Home Directory\npath = \"/home/user\"\nwriteable = yes\nguest ok = yes\ncreate mask = 0644\ndirectory mask = 0755\nforce user = user\n\nYou can do this for each individual user.\nAfter making your changes, you need to restart the samba daemon:\nsudo service smbd restart\n\n", "Q: Upgrade from Ubuntu 14.04 to 16.04 As I understand it, in order to upgrade from 14.04 to 16.04 one must upgrade to 14.10.  At this time it appears 14.10 is not supported.  From the command line do-release-upgrade -d produces\nWARNING:root:file 'utopic.tar.gz.gpg' missing\nFailed to fetch\nFetching the upgrade failed. There may be a network problem.\n\n(there is no problem with my network)\nIs there a workaround, perhaps a mirror to the official?  I just don't have the time to install 16.04 from scratch.\n\nA: Upgrades from 14.04 to 16.04 are not automatically made available but in July the first point release 16.04.1 will become available and all 14.04 users will be offered the upgrade then. \nHowever, if you want to upgrade immediately, you do NOT need to upgrade to an intermediate release first. Just run the following in a terminal (and type your password):\nsudo update-manager -d\n\nYou will then be offered the 14.04 -> 16.04 upgrade without waiting for 16.04.1. \nThe reason Ubuntu doesn't automatically offer 16.04 to 14.04 users is simple: those users are using a very stable LTS release, and might hit undiscovered bugs in 16.04 if they upgraded immediately at release. Any important bugs found in 16.04 should be fixed by the 16.04.1 point release, so LTS users have less chance of running into bugs in the new release.\n\nA: By running the normal upgrade commands in 14.04 (    sudo apt-get update,\n    sudo apt-get upgrade,\n    sudo apt-get dist-upgrade,\n    sudo update-manager -d) - \n\nCanonical responds with the following -\n\nSelecting \"Upgrade\" gives - \n\nBy doing the following I was able to upgrade from 14.04 to 14.10\n\n\n*\n\n*Change all instances of http://us.archive.ubuntu.com/ubuntu/ in /etc/apt/sources.list to http://old-releases.ubuntu.com/ubuntu/\n\n*Run the normal commands: \nsudo apt-get update,\nsudo apt-get upgrade,\nsudo apt-get dist-upgrade,\nsudo update-manager -d\n\n*Then upgrade from 14.10 to 15.10 and then to 16.04\n\nA: According to the release schedule, 16.04 (Xenial Xerus) will be officially released on April 21st, 2016. Until then, there is no officially supported method of upgrade.\nIf you want to test 16.04, you can always download the latest beta build and use the Live CD/Live USB environment.\n\nA: Upgrading from one LTS release directly to the next ( like 14.04 to 16.04 ) is supported; you do not need to go thorugh all of the intervening releases.\n", "Q: 'persistent' notification on ubuntu touch On ubuntu touch, one can do a 'temporary' notification via 'notify-send'. When I do that it will display a notification for 5 seconds. After that it is gone, and any trace it was ever there with it. This is different behaviour than on the desktop (atleast with kde) where the notification will be displayed and you have a small log  of the notifications in the systray.\nIt is possible to do however, as incoming messages are 'persistent'. With persistent I mean that they are in the notification area on top for review by the user.\nWhat would be the best way to go to create such notifications from a shell scripts. I don't mind creating a binary or script, i.e. the equivalent of notify-send, to do that. Ideally however I would like to use notify-send.\nI am using notify-send like this:\nnotify-send \"header\" \"body\"\n\n\nA: You cannot rely on notify-send, as it is not part of the base image, and not a supported part of the SDK.\nThe only way to achieve this currently, is to use push notifications, which requires sending the notification to the remote push server, which then disperses the notification to all devices connected with the associated Ubuntu One account.\nThere are a few types of notifications currently, and push is the only method supported via the SDK. Some redesign of the notifications system is currently happening, and a future version will have a better integrated system with API available in the SDK to use, and will consolidate the current disparity of systems.\nI'm not quite sure what you are trying to do exactly, but the application lifecycle and confinement in the phone and tablet images does not work in a way consistent with what you seem to be doing.\n\nA: Have you tried changing the --expire-time=TIME property of the notification? I believe that can be changed to a higher value like 10,000 (in ms).\nFurther detailed information can be found here\n\nA: To push the notification to the list of persistent notifications, you don't push a notification, but you instruct the \"indicator-messages\" to do it, then the little envelope indicator turns green and you have your notification in pending notifications also. You have to do this:\n\n\n*\n\n*Create an application that has a \"push-notification-client\" right.\n\n*In that application you will want to send a DBus message to  com.ubuntul.Postal with your message.\nBecause maybe you just want a hack (like me). You can do:\n\n\n*\n\n*Install the twitter webapp from publisher Canonical Group Limited, from the app store.\n\n*From terminal or a ssh session you run:\n\ngdbus call --session --dest com.ubuntu.Postal \\\n--object-path /com/ubuntu/Postal/com_2eubuntu_2edeveloper_2ewebapps_2ewebapp_2dtwitter \\\n--method com.ubuntu.Postal.Post \\\ncom.ubuntu.developer.webapps.webapp-twitter_webapp-twitter \\\n\"\\\"{\\\\\\\"message\\\\\\\": \\\\\\\"foobar\\\\\\\", \\\\\\\"notification\\\\\\\":{\\\\\\\"card\\\\\\\": {\\\\\\\"summary\\\\\\\": \\\\\\\"Some Title\\\\\\\", \\\\\\\"body\\\\\\\": \\\\\\\"Some text\\\\\\\", \\\\\\\"popup\\\\\\\": true, \\\\\\\"persist\\\\\\\": true}}}\\\"\"\n\nThis hack was found in the testing of the \"indicator-messages\" page here.\n", "Q: \"Attempted to read/write outside of hd0\" after install Lubuntu alongside Windows 7 I recently installed Lubuntu onto a 160Gb HDD, alongside Windows, which is the first two partitions (System Reserved/C:). The installation completed just fine, with no errors. It then rebooted into GRUB. I tried to boot (L)Ubuntu and I got a message similar to this:\nattempted to read/write outside of hd0\npress any key to continue...\n\nUsing the normal Ubuntu menu option, pressing any key causes the system to hang. However, pressing any key on the recovery mode (under Advanced Options for Ubuntu) brings me to a low-res kernel panic (lower resolution than Grub).\nBooting into Windows works just fine.\nI apologise if this is an ametuer mistake, but I have never had to diagnose bootloader problems in the past (Windows XP/Ubuntu a few years ago, on an older laptop, worked just fine)\nWindows was installed first.\nLinux - strangely - shows up as sda5/sda6 (from the live CD) when Windows only shows four partitions on the disk.\n\nA: Well that was harder than it had to be.\nI added a seperate boot partition (after external advice) and reinstalled. Linux now booted, but because I moved the partitions around to fit a /boot partition, Windows no longer booted. This was to be expected, so I repaired Windows using the system recovery disk, and ran grub-update after chrooting into /dev/sda6. Now GRUB only detected Windows. At this point I gave up and used boot-repair, which advised me to reinstall GRUB2. I did, and now it works!\n", "Q: Deleting cities in the ubuntu touch clock app After accidentally adding a city in the clock app of ubuntu-touch, how can one delete such a city?\n\nA: Found it. You have to push the entry to the right, then a garbage bin will appear on the left side. This also works in for example Notes.\n", "Q: With plan to upgrade to 16.04, 15.10 is better or 14.04 or the 16.04 beta? I understand that 16.04 is coming soon. \nI want to install a version that has easiest transition to 16.04.\nShould I install 15.10 or 14.04 LTS or 16.04 beta?\n\nA: They're all equally as easy to upgrade to 16.04.\n\n\n*\n\n*14.04 is LTS, so by default it only tells you about upgrades to other LTS versions, which come out every two years. 16.04 is an LTS version, so you should be prompted to 16.04, either on its release date (the 21st) or when 16.04.2 is released some time later.\n\n*15.10 is not LTS, so it prompts you to install any new version of Ubuntu that comes out. 15.10 is the version right before 16.04, so it will be a direct upgrade when 16.04 is released.\n\n*I believe that the 16.04 beta will just transition into full 16.04 through updates. It may or may not say it wants to upgrade to a new version of Ubuntu, as it technically isn't. This might be the easiest upgrade path, but there's one problem.\nSince 16.04 is still in beta, we cannot help you with any specific problems you may have before the final release on the 21st of April. The most we can do is redirect you to Launchpad to file a bug report.\nFor this reason, I suggest you hold off on installing 16.04 beta. The choice is yours between 14.04 and 15.10, but I'll give you some pointers to help make that choice.\n\n\n*\n\n*If your computer is relatively old (late 2013 or earlier), you're safe sticking with 14.04, and it might be the best option.\n\n*If your computer is pretty new (some time after mid 2014), you may want to consider installing 15.10.\nRemember, though, 15.10's default behavior of prompting to install every new version of Ubuntu will carry through to the 16.04 update, meaning you'll be asked to upgrade to 16.10 when it comes out and so on. \nIf you install 14.04 and upgrade it to 16.04, it will only next prompt you (by default, you can change it) to upgrade when 18.04 is released.\n\nA: The direct answer to your question, which version is easiest to upgrade to 16.04, is the Xenial daily build.\n", "Q: How to enable broadband connection with Huawei E3372h on Ubuntu Server Important note: after entering this \"question\" I did some testing and realized I am able to enable the broadband connection with newer version of Ubuntu Server - 15.10. The procedure is described below. Anyway, the reason why it does not work in 14.04.04LTS is not known to me (maybe the functionality is not covered in its kernel version)\n\nI have Huawei E3372H which I set to \"modem\" mode, so it does not do NAT and behaves as a modem. It works with Ubuntu 15.10 (desktop). Network manager shows possibility for creating a broadband connection and I just fill APN \"internet\" and that's it - after enabling this connection it works perfectly.\nBut how to connect my Ubuntu Server 14.04 on to the internet using this USB stick when there is no NetworkManager installed?\nHere is some basic info about the stick:\nlsusb shows it as:\nBus 002 Device 009: ID 12d1:1506 Huawei Technologies Co., Ltd. Modem/Networkcard\n\nThis interface is being created once the stick is connected to my Ubuntu Desktop PC:\nwwx001e101f0000 Link encap:Ethernet  HWaddr 00:1e:10:1f:00:00  \n          BROADCAST MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nI tried following this (https://johnlewis.ie/mobile-broadband-from-the-command-line-in-ubuntu/) procedure, but unfortunately I ended with no success:\nApr  9 16:32:32 test_server pppd[20296]: pppd 2.4.5 started by jim, uid 0\nApr  9 16:32:33 test_server chat[20298]: abort on (BUSY)\nApr  9 16:32:33 test_server chat[20298]: abort on (VOICE)\nApr  9 16:32:33 test_server chat[20298]: abort on (NO CARRIER)\nApr  9 16:32:33 test_server chat[20298]: abort on (NO DIALTONE)\nApr  9 16:32:33 test_server chat[20298]: abort on (NO DIAL TONE)\nApr  9 16:32:33 test_server chat[20298]: send (ATZ^M)\nApr  9 16:32:33 test_server chat[20298]: expect (OK)\nApr  9 16:32:33 test_server chat[20298]: ^M\nApr  9 16:32:33 test_server chat[20298]: OK\nApr  9 16:32:33 test_server chat[20298]:  -- got it\nApr  9 16:32:33 test_server chat[20298]: send (AT+CGDCONT=1,\"IP\",\"internet\"^M)\nApr  9 16:32:34 test_server chat[20298]: expect (OK)\nApr  9 16:32:34 test_server chat[20298]: ^M\nApr  9 16:32:34 test_server chat[20298]: ^M\nApr  9 16:32:34 test_server chat[20298]: OK\nApr  9 16:32:34 test_server chat[20298]:  -- got it\nApr  9 16:32:34 test_server chat[20298]: send (ATDT*99#^M)\nApr  9 16:32:34 test_server chat[20298]: expect (CONNECT)\nApr  9 16:32:34 test_server chat[20298]: ^M\nApr  9 16:32:34 test_server chat[20298]: ^M\nApr  9 16:32:34 test_server chat[20298]: CONNECT\nApr  9 16:32:34 test_server chat[20298]:  -- got it\nApr  9 16:32:34 test_server chat[20298]: send (^M)\nApr  9 16:32:34 test_server pppd[20296]: Script /usr/sbin/chat -v -f /etc/chatscripts/pap -T *99# finished (pid 20297), status = 0x0\nApr  9 16:32:34 test_server pppd[20296]: Serial connection established.\nApr  9 16:32:34 test_server pppd[20296]: using channel 10\nApr  9 16:32:34 test_server pppd[20296]: Using interface ppp0\nApr  9 16:32:34 test_server pppd[20296]: Connect: ppp0 <--> /dev/ttyUSB0\nApr  9 16:32:35 test_server pppd[20296]: sent [LCP ConfReq id=0x1 <asyncmap 0x0> <magic 0xce74b2a1> <pcomp> <accomp>]\nApr  9 16:33:02 test_server pppd[20296]: message repeated 9 times: [ sent [LCP ConfReq id=0x1 <asyncmap 0x0> <magic 0xce74b2a1> <pcomp> <accomp>]]\nApr  9 16:33:05 test_server pppd[20296]: LCP: timeout sending Config-Requests\nApr  9 16:33:05 test_server pppd[20296]: Connection terminated.\nApr  9 16:33:06 test_server pppd[20296]: Modem hangup\n\nEdit:\nI found out working procedure, but unfortunately it works just on my desktop with Ubuntu 15.10:\necho -e \"AT^NDISDUP=1,1,\\\"internet\\\"\\r\" > /dev/ttyUSB0\ndhclient -v wwx001e101f0000\n\n--> Using the commands above will bring up working mobile broadband on wwx001e101f0000 ethernet interface.\nUnfortunately on my Ubuntu Server 14.04 via command dhclient -v wwan0 an ip address is not provided although the modem is connected to the LTE network (blue light on). It is very strange.\nEdit2:\nI found out the issue is most likely in Ubuntu 14.04 kernel version. I did a test - installed new \"test\" Ubuntu Server 14.04 just for this test - the behavior was exactly the same as on my \"production\" Ubuntu Server 14.04 - no IP acquired using dhclient wwan0.\nThen I installed new \"test\" Ubuntu Server 15.10 and in this installation it works perfectly. So I assume from some reason this ncm interface does not work properly. I noticed this difference between the 2 servers:\nUbuntu 14.04 Dmesg:\nApr  9 19:32:13 ubuntu kernel: [27410.720039] usb 1-4: new high-speed USB device number 18 using ehci-pci\nApr  9 19:32:13 ubuntu kernel: [27410.861148] usb 1-4: New USB device found, idVendor=12d1, idProduct=1506\nApr  9 19:32:13 ubuntu kernel: [27410.861154] usb 1-4: New USB device strings: Mfr=1, Product=2, SerialNumber=0\nApr  9 19:32:13 ubuntu kernel: [27410.861159] usb 1-4: Product: HUAWEI_MOBILE\nApr  9 19:32:13 ubuntu kernel: [27410.861163] usb 1-4: Manufacturer: HUAWEI_MOBILE\nApr  9 19:32:13 ubuntu kernel: [27410.898395] option 1-4:1.0: GSM modem (1-port) converter detected\nApr  9 19:32:13 ubuntu kernel: [27410.898552] usb 1-4: GSM modem (1-port) converter now attached to ttyUSB0\nApr  9 19:32:13 ubuntu kernel: [27410.943023] huawei_cdc_ncm 1-4:1.1: MAC-Address: 00:1e:10:1f:00:00\nApr  9 19:32:13 ubuntu kernel: [27410.943029] huawei_cdc_ncm 1-4:1.1: setting rx_max = 16384\nApr  9 19:32:13 ubuntu kernel: [27410.968250] huawei_cdc_ncm 1-4:1.1: cdc-wdm0: USB WDM device\nApr  9 19:32:13 ubuntu kernel: [27410.968657] huawei_cdc_ncm 1-4:1.1 wwan0: register 'huawei_cdc_ncm' at usb-0000:00:1a.7-4, Huawei CDC \nNCM device, 00:1e:10:1f:00:00\n\nUbuntu 15.10 Dmesg:\nApr  9 22:29:20 ubuntu kernel: [   64.269728] usb 2-1.2: new high-speed USB device number 7 using ehci-pci\nApr  9 22:29:20 ubuntu kernel: [   64.367373] usb 2-1.2: New USB device found, idVendor=12d1, idProduct=1506\nApr  9 22:29:20 ubuntu kernel: [   64.367379] usb 2-1.2: New USB device strings: Mfr=1, Product=2, SerialNumber=0\nApr  9 22:29:20 ubuntu kernel: [   64.367382] usb 2-1.2: Product: HUAWEI_MOBILE\nApr  9 22:29:20 ubuntu kernel: [   64.367384] usb 2-1.2: Manufacturer: HUAWEI_MOBILE\nApr  9 22:29:21 ubuntu kernel: [   64.459900] usbcore: registered new interface driver usbserial\nApr  9 22:29:21 ubuntu kernel: [   64.459910] usbcore: registered new interface driver usbserial_generic\nApr  9 22:29:21 ubuntu kernel: [   64.459918] usbserial: USB Serial support registered for generic\nApr  9 22:29:21 ubuntu kernel: [   64.507601] usbcore: registered new interface driver option\nApr  9 22:29:21 ubuntu kernel: [   64.507614] usbserial: USB Serial support registered for GSM modem (1-port)\nApr  9 22:29:21 ubuntu kernel: [   64.507691] option 2-1.2:1.0: GSM modem (1-port) converter detected\nApr  9 22:29:21 ubuntu kernel: [   64.507963] usb 2-1.2: GSM modem (1-port) converter now attached to ttyUSB0\nApr  9 22:29:21 ubuntu kernel: [   64.535895] usbcore: registered new interface driver cdc_ncm\nApr  9 22:29:21 ubuntu kernel: [   64.542625] usbcore: registered new interface driver cdc_wdm\nApr  9 22:29:21 ubuntu kernel: [   64.579935] huawei_cdc_ncm 2-1.2:1.1: MAC-Address: 00:1e:10:1f:00:00\nApr  9 22:29:21 ubuntu kernel: [   64.579940] huawei_cdc_ncm 2-1.2:1.1: setting rx_max = 16384\nApr  9 22:29:21 ubuntu kernel: [   64.587318] huawei_cdc_ncm 2-1.2:1.1: NDP will be placed at end of frame for this device.\nApr  9 22:29:21 ubuntu kernel: [   64.587427] huawei_cdc_ncm 2-1.2:1.1: cdc-wdm1: USB WDM device\nApr  9 22:29:21 ubuntu kernel: [   64.587579] huawei_cdc_ncm 2-1.2:1.1 wwan0: register 'huawei_cdc_ncm' at usb-0000:00:1d.0-1.2, Huawei CDC NC\nM device, 00:1e:10:1f:00:00\n\nSo in Ubuntu 15.10 there are additional \"usbcore\" and \"usbserial\" entries logged and also eth interface wwan0 is being renamed to wwx001e101f0000.\nI will try to upgrade kernel of my Ubuntu 14.04 to the higher version and will check whether it will work there.\nImportant note:\nWhen doing my tests I installed Ubuntu Server 14.04.2 iso image. This one had older 3.x kernel version. Now I downloaded 14.04.4 from Ubuntu website and after installation I can see it had kernel 4.2. Interesting is on my \"production\" server I have Ubuntu Server version 14.04.4, but the Kernel there is 3.16: Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.16.0-53-generic x86_64). I update the server on regular basis, but it looks from some reason linux-generci-lts-wily is included in the downloaded 14.04.4, but is not present in my 14.04.4 which had been several times updated.\nNew installation of 14.04.4:\n$ sudo dpkg -l linux-generic-lts-*\nDesired=Unknown/Install/Remove/Purge/Hold\n| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend\n|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)\n||/ Name                          Version             Architecture        Description\n+++-=============================-===================-===================-================================================================\nii  linux-generic-lts-wily        4.2.0.27.21         amd64               Complete Generic Linux kernel and headers\n\nSo apt-get install linux-generic-lts-wily solved the problem on my Ubuntu Server - it installed 4.2 kernel and with this one it works properly.\n\nA: After further testing I found I had kernel version 3.16 on my Ubuntu Server 14.04.4. With this kernel version, Huawei E3372H did not work properly in cdc_ncm mode. The solution is to upgrade the kernel to 4.2. Then connection to the internet can be done with these simple commands (assuming the modem created /dev/ttyUSB0, APN is \"internet\"):\nThis command will connect the stick to LTE netowrk (internet is an APN, so other providers can use different APN name):\necho -e \"AT^NDISDUP=1,1,\\\"internet\\\"\\r\" > /dev/ttyUSB0\n\nThis command will acquire IP address for the wwan0 interface:\ndhclient wwan0\n\n", "Q: Will 16.04 Unity 7 improvements be available in 14.04 I was wondering if the Unity 7 improvements made in 16.04 will be available in 14.04?\n\nA: As 14.04 is an LTS release and some programs may depending on the behavior how ubuntu 14.04 LTS does or does not things generally most of programs and libraries will stay in its major release and only minor updates or security fixes would be apllied to the distri. \nShorthand answer: Unity Enhancement of 16.04 would not be backported to 14.04 LTS \nexcerpt from ubuntu.com: \n\nRelease Plan Details\n  We start stabilizing the release early by significantly limiting the number of new features. We will choose which features we package into the LTS release, versus which ones we leave out and allow for users to optionally download and use from a separate archive.  \nAvoid structural changes as far as possible, such as changing the default set of applications, lots of library transitions, or system layer changes (example: introducing KMS or hal → DeviceKit would not have been appropriate changes in a LTS).\nFurthermore, we define the LTS to be:\nEnterprise Focused: We are targeting server and multiple desktop installations, where the average user is moderately risk averse.\nCompatible with New Hardware: We will make point releases throughout the development cycle to provide functional support for new server and desktop hardware.\nMore Tested: We will shorten the development window and extend the Beta cycle to allow for more testing and bug fixing \nand clearly state that it is not:\nA Feature-Based Release: We will focus on hardening functionality of existing features, versus introducing new ones1, except for in the areas of Online Services and Desktop Experience.\n  \n  \n*\n  \n*Exceptions for priority projects will be documented.\n  \n*Because these two areas of development are relatively new, they still require new features to satisfy the original reasons for their creation \n  \n\n", "Q: dns server assigned from dhcp is equal to the address of the client I had the following enviroment configuration:\nhttp://i.imgur.com/9chRJT8.png\nUbuntu VM /etc/network/interfaces:\nauto eth0\niface eth0 inet static\n address 192.168.10.11\n netmask 255.255.255.0\n gateway 192.168.10.1\n dns-nameservers 192.168.10.12\n\nUbuntu VM /etc/resolv.conf:\nnameserver 192.168.10.12\n\nI changed it to another configuration (i want to get dns server address from dhcp (router)):\nUbuntu VM /etc/network/interfaces:\nauto eth0\niface eth0 inet dhcp\n\n[my Ubuntu VM ip address from dhcp = 192.168.10.8]\nUbuntu VM /etc/resolv.conf:\nnameserver 192.168.10.8 <-- ??? \n\n[why dns server and my dhcp client have the same address?] \nRouter dhcp configuration:\nStart IP Address: 192.168.10.2\nEnd IP Address: 192.168.10.100\nPrimary DNS Server: 208.67.222.222 <-- it's a proper dns server\nSecondary DNS Server: 0.0.0.0\nGateway: 192.168.10.1\n\nThank you in advance!\n\nA: Because Ubuntu uses dnsmasq as a local caching dns server to reduce redundant requests going to the real name server and speed up name resolution.  Normally /etc/resolv.conf just points to 127.0.0.1, but it looks like you removed the loopback interface ( lo ) from your /etc/network/interfaces auto line so I'm guessing your DHCP assigned IP address is the only valid address it could use.  You should probably put the loopback interface back on the auto line of your interfaces file.\n", "Q: How do I force delete a file? I have a random file placed in my desktop named \"Unconfirmed 371801.crdownload\" and I am extremely worried it is a virus and I want to remove it immediately but whenever I try to remove it, it throws a report \" “Unconfirmed 371801.crdownload” can't be put in the trash. Do you want to delete it immediately? \" then when I press Delete it says this \"There was an error getting information about “Unconfirmed 371801.crdownload”.\" and I don't know how to get the information. Any help is appreciated.\n\nA: Unconfirmed 371801.crdownload is a temporary file that \nrepresents an unfinished download.\nIn general is not a virus. (unless what were you downloading is a virus)\nTo delete it you can try to close your browser (if is google-chrome check also that background processes are closed) and try to delete it.\nIf it doesn't work you can open a terminal pressing ctrl+alt+t.\nNow you have to change the directory where the terminal is working with the following command:\ncd Desktop\n\n(I'm assuming that your file is placed in your desktop directory and you installed Ubuntu in English international / US).\nTo delete the file run this command:\nrm -f Unconfirmed\\ 371801.crdownload\n\nThis command will remove the file ignoring any errors. (add \\ character because terminal doesn't take into account space in names).\nIf you want more info about the command you can run from terminal this command:\nman rm\n\nIf the file is still there you can try to run the rm command as superuser:\nsudo rm -f Unconfirmed\\ 371801.crdownload\n\nThis command will ask you superuser password and after will do the work.\nIn the end, if the file doesn't disappear, you try to click on your desktop and then press Ctrl+R. This will refresh your desktop.\n\nA: I had the same problem and the command sudo rm -f did not work for me. I also could not resume the download. However I was able to get rid of it by deleting everything in the Chrome Menu --> Downloads and then Right Click on the .crdownload file --> Open With --> Other Application... --> Chrome. After this, the file simply disappeared. \n\nA: Go to the folder where the file is; Right click and open a terminal; Than 'ls' and get the file name.\nThan do: sudo rm -rf (filename with extension).\nIt'll be in your bin then and you can empty the bin.\n", "Q: Ubuntu shows only console login after I start my computer Ubuntu shows only login console but no gui login. Even though I entered right login user name and password, I can't login. I can't do anything with this. How can I resolve this problem?\n\nA: I think the server version was installed on your box. You should install desktop environment by running one of these commands in terminal:\nsudo apt-get install ubuntu-desktop #GNOME\nsudo apt-get install kubuntu-desktop #KDE\nsudo apt-get install xubuntu-desktop #xfce\n\n\nA: If the answer from user528561 does not work (or even before this) try pressing Ctrl + Alt + F7. Note thet if you have laptop the F7 key may have some other function atached to it and you must press the Fn key also. Once I pressed Ctrl + Alt + F1 by acctident and was moved to console...In most cases the F7 key is GUI, but sometimes can be F8. Sorry for bad writing and no edditing, I am in a hurry.\n", "Q: Where is key binding for Ubuntu Desktop help? I am running Ubuntu 14.04 LTS.\nMy audio mute button has recently stopped working. The volume down button now starts the Ubuntu Desktop Help window. The volume up button works just fine. The mute and volume down buttons work fine for the other user on the box.\nI explored Dconf and the two keys should work - but they don't!\nI used xbindkeys -k in both users and got the same results.\n\nProblem solved! All my keys are working properly after I removed \"Keytouch.\"\n\nA: You can try from System Settings, select Keyboard and then go the Shortcuts tab. From there you can check which keys are bound to Sound and Media actions.\nIf there is some mismatch you can set the right key.\n", "Q: How to make active application float to the top of the launcher How would one make icons on the launcher jump to the top of the launcher when switching to a window using Alt+Tab  or by clicking that window's icon on the launcher ?\n\nA: Introduction\nThe script bellow makes the icon of currently active window float to the top of the launcher.  It can be ran manually or as part of startup applications to start with the user session.\nSetup\nUser can copy  the script source from here, or obtain copy of the script through git:\n\n*\n\n*sudo apt-get install git\n\n*cd /opt ; sudo git clone https://github.com/SergKolo/sergrep.git\n\n*sudo chmod -R +x sergrep\nThe script file is /opt/sergrep/float_active_app.sh\nTo make the script start automatically on every login, refer to\nHow do I start applications automatically on login? . Provide /opt/sergrep/float_active_app.sh (full path) as the command\nSource\n#!/usr/bin/env bash\n#\n###########################################################\n# Author: Serg Kolo , contact: 1047481448@qq.com \n# Date: April 9 , 2016\n# Purpose: Make the icon of currently active app float to\n#          the top of unity launcher\n# Written for: \n# Tested on: Ubuntu 14.04 LTS\n###########################################################\n# Copyright: Serg Kolo , 2016\n#    \n#     Permission to use, copy, modify, and distribute this software is hereby granted\n#     without fee, provided that  the copyright notice above and this permission statement\n#     appear in all copies.\n#\n#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n#     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n#     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL\n#     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n#     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n#     DEALINGS IN THE SOFTWARE.\n\nARGV0=\"$0\"\nARGC=$#\nget_active_app()\n{\n  qdbus org.ayatana.bamf /org/ayatana/bamf/matcher \\\n      org.ayatana.bamf.matcher.ActiveApplication \n}\n\nget_active_desktop_file()\n{\n  active_app=$(get_active_app)\n  if [ -n \"$active_app\"  ];then\n     qdbus org.ayatana.bamf \"$active_app\" \\\n        org.ayatana.bamf.application.DesktopFile | \\\n        awk -F '/' '{print \"application://\"$NF}'\n  fi\n}\n\nget_launcher_items()\n{\n  gsettings get com.canonical.Unity.Launcher favorites | \\\n     awk '{ gsub(/,|\\[|\\]/,\"\"); print}'\n}\n\nmake_new_list()\n{\n \n array=( $( get_launcher_items ) )\n printf \"%s, \" \"$active\"\n COUNT=0\n for item in ${array[@]} ; do\n   COUNT=$(($COUNT+1))\n\n   if [ \"$item\" = \"$active\"   ];then\n     continue\n   fi\n\n   if [ $COUNT -eq ${#array[@]}  ];then\n      printf \"%s \" \"$item\"\n   else\n      printf \"%s, \" \"$item\"\n   fi\n done\n}\n\nset_launcher_items()\n{\n  gsettings set com.canonical.Unity.Launcher favorites \"$1\"\n}\n\nmain()\n{\n  local active=\"\"\n  while true;\n  do \n    active=\"'$(get_active_desktop_file)'\"\n    if [ \"$active\" = \"'application://compiz.desktop'\" ] || [ -z \"$active\"   ] ;then\n       continue\n    fi\n    new_list=\"[$(make_new_list)]\"\n    set_launcher_items \"$new_list\"\n  sleep 0.25\n  done\n}\n\nmain\n\n", "Q: I turned my PC off during reinstallation I wanted to upgrade my Ubuntu 14.10 to 15.10 (I think, not sure now). I clicked the \"upgrade button\" and wrote the password as usual. For few moments I saw that the computed was doing something, but then suddenly the screen went black, only the Caps Lock light was flashing.\nI left the computer for few hours (at least 5 or 6), but when I got back, it was still the same way. I was worried, so I turn the PC off and turned it on again. It kinda worked, but the only think that actually started, was something that looked like and worked as commander.\nI want to finish the upgrade or at least return to the previous version, but I don't know how... Do I have to reinstall it all?\n\nA: Yes; you will have to reinstall.  Choose the \"something else\" option, and configure your existing root ( / ) and swap partitions, and do NOT check the format box on the root partition, and all of your personal files will remain intact.\n\nA: Try this:\nStep 1: Boot into Ubuntu Live-Usb\nStep 2: Open a terminal, Press Ctrl+Alt+T\nStep 3: Login as user with administrator permissions.\nsudo -i\n\nStep 4: Find out how your partition / is called with fdisk.\nfdisk -l\n\nStep 5: Suppose it is /dev/sda1, mount the partition in /mnt, previous fsck\numount /dev/sda1\nfsck -a /dev/sda1\nmount /dev/sda1 /mnt\n\nStep 6: Mount the following paths in the respective locations in the /mnt \nnamely – /dev, /sys, /proc, and /dev/pts.\nmount -o bind /proc /mnt/proc\nmount -o bind /dev /mnt/dev\nmount -o bind /sys /mnt/sys\nmount -o bind /dev/pts /mnt/dev/pts\n\nStep 7: chroot into the Ubuntu partition\nchroot /mnt\n\nStep 8: Try repairing the installed system. Execute these commands:\ndpkg-reconfigure -a\napt-get -f install\napt-get -m install \napt-get update\napt-get dist-upgrade\napt-get install --reinstall ubuntu-desktop\napt-get autoremove\napt-get clean\n\nStep 9: Un-mount the previously mounted directories and reboot.\numount /mnt/proc\numount /mnt/dev/pts\numount /mnt/sys\numount /mnt/dev\numount /mnt\nreboot\n\n", "Q: Accidentally mounted a partition on /usr I mounted a partition on /usr accidentally. Hence, I have lost access to sudo command and can't unmount the partion. I am using AWS EC2 instance and don't have password for root user set. \nWhat are my options? Will reboot unmount the newly mounted partition and will I get access to content of /usr again? Or else, how can I get root access? Are there any threat of data loss or system going to unusable state after reboot?\nAny help would be appreciated.\n\nA: Yes; a reboot will get rid of the mount.\n", "Q: Is there any website to use ubuntu operating system online? My computer is not good enough to handle two operating system in the same time.I tried to use ubuntu on usb but it did not work and I tried to use ubuntu from virtual machine and i get the same result ? Here is my question : Is there any website to use ubuntu operating system online ? I need to do my homework on it also i must learn some basic terminology about ubuntu thanks\n\nA: If you're just looking to run a unix terminal from windows and not a full fledged OS, you can try something like MobaXterm, which lets you run an Xterm on Windows, giving you the same commands as you'd get from bash/cygwin.\nIn terms of booting ubuntu from a USB, that should work fine, provided your USB is big enough. Ubuntu itself is a pretty light OS, so it should be fine to run on any PC that can also run Windows. If booting from an Ubuntu flash drive, you may have to open up the boot menu when starting to select the flash drive as the source for the OS.\nWhat virtual machine software did you try? I find VMWare Player can be run with fairly low system requirements to load and run an ubuntu OS image.\nWhat are you system requirements and objectives?\nIf performance and system requirements are really an issue, you can take a look at lubuntu which is a lightweight version of ubuntu. You can even try that with a dual boot, usb boot, or VMWare Player image.\nThanks.\n", "Q: Used CURL to get NodeJS, how to remove the files (have not installed nodeJS yet though) I used: curl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash - because I wanted to install NodeJS, but after executing the command - I realised I used the wrong command. I need NodeJS version 5, not 4. \nI have not used apt-get install nodejs yet. How can I remove the files that the first command downloaded, so that I can execute a different curl command and then install NodeJS using apt-get install nodejs ?\nI'm rather new to Ubuntu. \n\nA: By piping to | sudo -E bash -, you executed the code from https://deb.nodesource.com/setup_4.x, which is a bash script.\nLooking at the script it appears to add:\nprint_status 'Creating apt sources list file for the NodeSource Node.js 4.x LTS Argon repo...' \nexec_cmd \"echo 'deb https://deb.nodesource.com/node_4.x ${DISTRO} main' > /etc/apt/sources.list.d/nodesource.list\"\nexec_cmd \"echo 'deb-src https://deb.nodesource.com/node_4.x ${DISTRO} main' >> /etc/apt/sources.list.d/nodesource.list\"\nprint_status 'Running `apt-get update` for you...'\nexec_cmd 'apt-get update'\n\nSo you can remove the sources, but if you run the 5.x script, it will just replace this file, so either running the same script with 5.x instead of 4.x or removing the file and then running the 5.x script will give you the same result:\n$ curl -sL https://deb.nodesource.com/setup_5.x | sudo -E bash -\n$ cat /etc/apt/sources.list.d/nodesource.list\ndeb https://deb.nodesource.com/node_5.x wily main\ndeb-src https://deb.nodesource.com/node_5.x wily main\n\n\nA: Looking at the script, nothing much installs, until you run apt-get install nodejs.\nPRE_INSTALL_PKGS=\"\"\n\nif [ ! -e /usr/lib/apt/methods/https ]; then\n    PRE_INSTALL_PKGS=\"${PRE_INSTALL_PKGS} apt-transport-https\"\nfi\n\nif [ ! -x /usr/bin/lsb_release ]; then\n    PRE_INSTALL_PKGS=\"${PRE_INSTALL_PKGS} lsb-release\"\nfi\n\nif [ ! -x /usr/bin/curl ] && [ ! -x /usr/bin/wget ]; then\n    PRE_INSTALL_PKGS=\"${PRE_INSTALL_PKGS} curl\"\nfi\n\nNothing in there would I worry about.  Then as the script continues, it adds the PPA.\nexec_cmd \"echo 'deb https://deb.nodesource.com/node_4.x ${DISTRO} main' > /etc/apt/sources.list.d/nodesource.list\"\nexec_cmd \"echo 'deb-src https://deb.nodesource.com/node_4.x ${DISTRO} main' >> /etc/apt/sources.list.d/nodesource.list\"\n\nI would remove nodesource.list from apt/sources.list.d/\nsudo rm /etc/sources.list.d/nodesource.list\n\nThen apt-get update\nsudo apt-get update\n\n", "Q: Ubuntu Mate keeps freezing My computer recently started freezing a lot. The freezing affects everything but the power button. Each time it freezes I have to restart my computer and this is really affecting my productivity. Thanks in advance. My question is how do I figure out what is causes the freezes and then fix that.\n\nA: You can see resources utilization of CPU and RAM for each process by running on a terminal the command :\n\ntop\n\nYou can also check the RAM actually in use with this command :\n\nfree -tm\n\nIf when your computer freeze you can't check which process cause the problem  with top you can according to this check the log with :\nIn a terminal :\n\ntail -f /var/log/syslog\n\nIf you are running gnome, then you can check the logs using \"gnome-system-log\"\nTo launch a terminal according to this you can do :\n\n\n*\n\n*If you're running Unity: open the dash, type terminal, hit Return.\n\n*If you're on the old style menus, Applications → Accessories →\nTerminal.\n\n*Control + Alt + T.\n\n*Alt + F2, gnome-terminal, Return.\n\n\nAfter that you just had to type the command and hit enter.\nWhen you run top there a 3 important column for you, each line in top represent a process .\n\n\n*\n\n*At the middle you can see behind the %CPU the % of CPU in use for a process.\n\n*At the right of the %CPU you have %MEM which represent the ram.\n\n*And at the just right you have command which is the process name corresponding to the use of CPU and MEM .\n\n", "Q: How can I use sqlite3 in my Ubuntu Phone app? (C++ backend) I want to create an app, which has a C++ backend and uses sqlite3.\nI can connect to an Database in memory using the following code:m_db = QSqlDatabase::addDatabase(\"QSQLITE\"); m_db.setDatabaseName(\":memory:\"); m_db.open();\nBut I don't know what path I have to use or whatelse I have to do to create a local database file on my phone. If I run the application on my Computer I can replace \":memory:\" by any path I want.\nThanks\n\nA: I got the clue from a comment to this question that I can't find anymore.\nIf you want to write to/read from the filesystem you have to take care of the app confinement of Ubuntu. An normal not OS trusted application can only write to some limited \"private\" directories and read from some more directories. You can use the QStandardPaths class to find these directories.\nFor example to get the writable data directory I use QStandardPaths::writableLocation(QStandardPaths::DataLocation) and with QStandardPaths::standardLocations(QStandardPaths::DataLocation) you get all readable data directories. It works for me to create my sqlite3 file in the writeable data directory.\nBy the way: You can get other kinds of directories for your application using QStandardPaths (eg. temp, cache, ...).\nThe app confinements of Ubuntu are available here.\n", "Q: Installing Ubuntu over existing windows 7? I already got windows 7 installed on my laptop with 3 drives C: D: E: and I also wanted to install Ubuntu on the same drive C: and make it a dual boot. \n How to do it ? is it possible ? \nAnd will I lose the data on other drives i.e D: E: \n\nA: It is possible and I think you won't lose your data on D: and E:, but your Win7 installiation may become corrupted, so you should back up your files. You have to partition your C: drive and because of that you can lose your data.\nWhen you are using the Ubuntu Installation wizard you will be asked what to do (install over win7 or besides or something else), there you choose do something else and than you have to shrink the Windows 7 partition on your C: drive. Than you can create the filesystem needed for Ubuntu on your new free space on C:.\nThe installation wizard should automatically detect windows 7 and enable dual boot.\n", "Q: chirp on ubuntu I did install the chirp on my ubuntu 14.04 lts according to instructions:\nsudo apt-add-repository ppa:dansmith/chirp-snapshots\nsudo apt-get update\nsudo apt-get install chirp-daily\n\nIt worked. How do I run it?      \n\nA: Try running \"chirpw\" in the terminal.\n\nA: Having installed chirp using sudo apt-get install chirp , I can see that there is chirpw command available in terminal, as well as /usr/share/applications/chirp.desktop file. Thus you can either run chirpw in terminal, or search for the chirp in Unity's Dash\n\nA: As you know, CHIRP is a FREE cross-platform, cross-radio programming tool. It works on Windows and Linux (and MacOSX with a little work). It supports a growing list of radios across several manufacturers and allows transferring of memory contents between them.\nchirp is available in the Universe repositories for all currently supported versions of Ubuntu.\nThe first thing you need to do is enable the Universe repository for your version of Ubuntu.\nThen open a terminal and enter the following command:\nsudo apt-get install chirp\nor Install via Ubuntu Software.\nThen launch either via the Chirp icon in your application launcher:\n\nOr via terminal with the command: chirpw\n", "Q: Can I re-open a terminal session? When I play mulit-player Minecraft, with my family, I use an external server.  Everyone once in a while the session drops in my local PC.  I can re-open a new terminal and log back into the server.  I can use ps aux|grep minecraft to see that the original process is still running, but I cannot see the activity or enter commands.\nIs there anyway I can join that running process?\nWhat I am saying is that when I had the terminal session open and started Minecraft (MC), I could enter commands into the MC server like /list to see users, /weather clear to stop rain, etc.. etc..\nWhen I lost the connection and logged back in I cannot see the activities going on in the server window. I can see the process is still running, but what I wanted to do was to be able to join the process as before, and enter MC commands again.\n\nA: GNU Screen is a tool that lets you reattach to a previous session. Just install it on your remote server.\napt-get install screen\n\nNow when you connect to the machine via SSH, just type screen and press Space. You will be back to your normal terminal. Run whatever you want (minecraft) here. \nNow assume your connection dropped. Buy don't worry, because it is still running in the screen session you created before. All you have to do is to re-SSH and the attach to the already running screen session. You can get a list of running sessions by:\nscreen -ls\n\nFrom the list, choose the session you want to connect to and type:\nscreen -r <session-name>\n\nAnd you are back!\nThis is one of the many awesome things you can do with screen. I have written only the minimal usage information required to achieve what the OP wanted. Here is a good tutorial if you are interested. \nTo exit the screen session, just type exit.\n", "Q: Ethernet not working on ubuntu 14.04 LTS I have been struggling a lot trying to activate my ethernet connection without success. I am on ubuntu 14.04 LTS on a dell xps8900. I have a dual boot with windows 7 and ethernet is working fine on this one. Here is what I have tried:\n1) Verify the ethernet card:\n>lspci\n00:00.0 Host bridge: Intel Corporation Device 191f (rev 07)\n00:01.0 PCI bridge: Intel Corporation Device 1901 (rev 07)\n00:14.0 USB controller: Intel Corporation Device a12f (rev 31)\n00:14.2 Signal processing controller: Intel Corporation Device a131 (rev 31)\n00:16.0 Communication controller: Intel Corporation Device a13a (rev 31)\n00:17.0 RAID bus controller: Intel Corporation 82801 SATA Controller [RAID mode] (rev 31)\n00:1c.0 PCI bridge: Intel Corporation Device a110 (rev f1)\n00:1f.0 ISA bridge: Intel Corporation Device a145 (rev 31)\n00:1f.2 Memory controller: Intel Corporation Device a121 (rev 31)\n00:1f.3 Audio device: Intel Corporation Device a170 (rev 31)\n00:1f.4 SMBus: Intel Corporation Device a123 (rev 31)\n00:1f.6 Ethernet controller: Intel Corporation Device 15b8 (rev 31)\n01:00.0 VGA compatible controller: NVIDIA Corporation GM107 [GeForce GTX 745] (rev a2)\n01:00.1 Audio device: NVIDIA Corporation Device 0fbc (rev a1)\n02:00.0 Network controller: Realtek Semiconductor Co., Ltd. RTL8723BE PCIe Wireless Network Adapter\"\n\n2) Then I activated eth0 with ifconfig:\nsudo ifconfig wlan0 down\nsudo ifconfig eth0 up\neth0: ERROR while getting interface flags: No such device\nsudo ifconfig wlan0 up\n\n3) Looking at the error message above, I have modified 70-persistent-net.rules and reboot:\nmv /etc/udev/rules.d/70-persistent-net.rules /etc/udev/rules.d/70-persistent-net.rules.old\n\n-> reboot\n4) I have also looked at the different \"eth\":\nifconfig eth0\neth0: error fetching interface information: Device not found\nifconfig eth1\neth1: error fetching interface information: Device not found\nifconfig eth2\neth2: error fetching interface information: Device not found\n\n5) Then I tried:\nsudo dhclient\n\n-> reboot\n6) Then:\nsudo lshw -C network\n*-network               \n       description: Wireless interface\n       product: RTL8723BE PCIe Wireless Network Adapter\n       vendor: Realtek Semiconductor Co., Ltd.\n       physical id: 0\n       bus info: pci@0000:02:00.0\n       logical name: wlan0\n       version: 00\n       serial: b0:c0:90:4f:dc:c2\n       width: 64 bits\n       clock: 33MHz\n       capabilities: pm msi pciexpress bus_master cap_list ethernet physical wireless\n       configuration: broadcast=yes driver=rtl8723be driverversion=3.16.0-30-generic firmware=N/A latency=0 link=no multicast=yes wireless=IEEE 802.11bgn\n       resources: irq:16 ioport:d000(size=256) memory:df100000-df103fff\n  *-network UNCLAIMED\n       description: Ethernet controller\n       product: Intel Corporation\n       vendor: Intel Corporation\n       physical id: 1f.6\n       bus info: pci@0000:00:1f.6\n       version: 31\n       width: 32 bits\n       clock: 33MHz\n       capabilities: pm msi bus_master cap_list\n       configuration: latency=0\n       resources: memory:df200000-df21ffff\n\nAny other things to test? Thank you.\n\nA: Follow the steps here:\n\n\n*\n\n*Download e1000e here\n\n*Building and installation\n\n\n*\n\n*Move the base driver tar file to the directory of your choice. For example, use /home/username/e1000e or /usr/local/src/e1000e\n\n*Untar/unzip the archive, where  is the version number for the driver tar file:\n\n*Change to the driver src directory, where  is the version number for the driver tar:\ncd e1000e-<x.x.x>/src/\ntar zxf e1000e-<x.x.x>.tar.gz\n\n\n*Compile the driver module:\nmake install\n\nThe binary will be installed as:\n/lib/modules/<KERNEL VERSION>/kernel/drivers/net/e1000e/e1000e.[k]o\n\nThe install location listed above is the default location. This may differ for various Linux distributions.\n\n*Load the module using either the insmod or modprobe command:\nmodprobe e1000e insmod e1000e\n\nNote that for 2.6 kernels the insmod command can be used if the full path to the driver module is specified. For example:\ninsmod /lib/modules/<KERNEL VERSION>/kernel/drivers/net/e1000e/e1000e.ko\n\nWith 2.6 based kernels also make sure that older e1000e drivers are removed from the kernel, before loading the new module:\nrmmod e1000e; modprobe e1000e\n\n\n*Assign an IP address to the interface by entering the following, where  is the interface number:\nifconfig eth<x> <IP_address>\n\n\n*Verify that the interface works. Enter the following, where  is the IP address for another machine on the same subnet as the interface that is being tested:\nping <IP_address>\n\nNote\nSome systems have trouble supporting MSI and/or MSI-X interrupts. If you believe your system needs to disable this style of interrupt, the driver can be built and installed with the command:\n# make CFLAGS_EXTRA=-DDISABLE_PCI_MSI install\n\nSource\n", "Q: Cannot install Ubuntu 15.10 I'm new to Ubuntu and managed to install version 14 some days ago. That was already really problematic, but somehow worked. I have a GTX970 graphics card, which is not supported by the nouveau driver (AFAIK).\nToday I've tried to update to 15.10 and it failed miserably - so my installation is now broken - which is not a big deal - I just want to replace it with a fresh install of 15.10 from a USB stick (created with Univeral USB installer).\nBooting from the USB basically works, but the desktop is not useable - the mouse pointer is invisible and many errors show up, so I cannot do the installation.\nI've found quite some help on this, but nothing seems to work.\ni.e. this answer https://askubuntu.com/a/709131/523935 tells me to try to add nouveau.modeset=0 to the linux command in grub2 - but when I do this, the desktop does not even start up - I end up in a terminal, which asks me to login (to the LiveCD environment). But I don't know which user/password to use (I've tried: \"ubuntu\"/blank, \"ubuntu\"/\"ubuntu\", \"linux\"/blank, \"linux\"/\"linux\", ..)\nany ideas?\n\nA: To install Ubuntu on a system with a discrete graphics adapter that is entirely unsupported an option would be to \n\n\n*\n\n*physically remove the graphics card to boot with the inbuilt graphics adapter, or if supported disable the graphics card from the BIOS.\n\n*install Ubuntu using the inbuilt graphics from APU or motherboard\n\n*install the proprietary graphics drivers needed to support your discrete card, e.g. by enabling ppa:graphics-drivers/ppa\n\n*perform a full upgrade of the distribution\n\n*re-attach the graphics card physically or in BIOS\n\n\nFor Nvidia also see\n\n\n*\n\n*How do I install the Nvidia drivers?\nFor AMD/ATI see\n\n\n*\n\n*What is the correct way to install proprietary ATI Catalyst Video Drivers (fglrx) directly from AMD?\n", "Q: How to smart limit the trash size/quota? I am talking about the .Trash-1000 folders like.\nSome times it's contents size reach like 18GB, and applications trying to write files will fail with no clear messages, because the disk space has ended.\nI am looking for a way to force a trash quota/limit with some extra constraints.\nThese constraints options would be good:  \n\n\n*\n\n*by file date/time, older files are erased first.  \n\n*by available disk space, if it has like less than 1GB, no matter what trash file datetime it is, it gets erased to keep 1GB available.  \n\n*by file size, if trashed file is bigger than 500MB, it is promptly erased.  \n\n\nIs there such software sitting somewhere so I can avoid scripting it up?\n\nA: Try autotrash from the repositories. \n\nautotrash — program to automatically purge old files from the\n  FreeDesk-top.org trash\n\nOnce installed, you'll need to add a cron job to run autotrash.\nRun crontab -e, and add the following line:\n@hourly /usr/bin/autotrash --keep-free 1024 -d 30\n\nI don't think it covers the last point, but it's something to start with.\nPS: Also check out man autotrash for more info.\n", "Q: Does the terminal learn common typos? This may seem like a stupid question.\nI'm using Ubuntu 15.10 with GNOME Terminal 3.16.2. When I was new to the system, I often typed 'l' or 'la' instead of 'ls' to list files, and would then be told that these were not valid commands. I obviously then typed 'ls' properly. Now I notice that typing 'l' and 'la' do the same thing as 'ls'.\nWhat's going on here? Has the terminal learnt the common mistakes that I make, and made aliases to account for them, or is this a new feature that I've installed without realising?\n\nA: When you call l or la, you basically call aliases:\nl='ls -lah'\nla='ls -lAh'\n\nYou can check all aliases, currently configured in your system by running alias. It may be good to have some self-learining mechanism that will remember your typos an fix them, but for now it's just pre-configured aliases.\nRelated question on: Unix&Linux\n\nA: Shell itself doesn't have capability to do spellchecking for the user. What you have with la and l is aliases. In the .bashrc file you can set alias for any command. For instance, if I often mistype pwd command to print working directory, I'd use this in my .bashrc file:\nalias pdw='pwd'\n\nThe aliases l and la should exist in bash shell by default and I don't see a reason why they wouldn't work for you before. If you are a user on a machine who has a different administrator , then it's likely he or she disabled or enabled those.\nThere is sl command , which is not included by default in Ubuntu, but shows an animation of steam locomotive (hence sl name) when you mistype ls. This however is something that needs to be manually installed.\nIf a command is a complex combination of other commands, you could always use a function, like so\nsl()\n{\n  echo \"You've mistyped ls again\"\n  echo \"Don't rush\" \n}\n\nIf you are writing a script, you can sort of do spell checking (and much more)  on that using shellcheck\n", "Q: Screen flickering I have an MSI GS60 with an intel broadwell i7-5700HQ CPU and hybrid graphics (nvidia GTX ‎970‎M). The screen flickers so badly as shown in this video (seconds 0:03 and 0:08):\nhttps://www.youtube.com/watch?v=TqAljJ0U5Pc\nI know this is not a hardware problem since the issue doesn't happen on Windows 10 at all. I've tried many kernels and many distros and many drivers with no avail. I'm using the nvidia-352 driver with bumblebee right now. I'm not even sure if it's a graphics issue or a power issue or something else. Any help would be greatly appreciated.\nSpecs:\n~$ lspci\n00:00.0 Host bridge: Intel Corporation Broadwell-U Host Bridge - DMI (rev 0a)\n00:01.0 PCI bridge: Intel Corporation Broadwell-U PCI Express x16 Controller (rev 0a)\n00:02.0 VGA compatible controller: Intel Corporation Broadwell-U Integrated Graphics (rev 0a)\n00:03.0 Audio device: Intel Corporation Broadwell-U Audio Controller (rev 0a)\n00:14.0 USB controller: Intel Corporation 8 Series/C220 Series Chipset Family USB xHCI (rev 05)\n00:16.0 Communication controller: Intel Corporation 8 Series/C220 Series Chipset Family MEI Controller #1 (rev 04)\n00:1a.0 USB controller: Intel Corporation 8 Series/C220 Series Chipset Family USB EHCI #2 (rev 05)\n00:1b.0 Audio device: Intel Corporation 8 Series/C220 Series Chipset High Definition Audio Controller (rev 05)\n00:1c.0 PCI bridge: Intel Corporation 8 Series/C220 Series Chipset Family PCI Express Root Port #1 (rev d5)\n00:1c.2 PCI bridge: Intel Corporation 8 Series/C220 Series Chipset Family PCI Express Root Port #3 (rev d5)\n00:1c.3 PCI bridge: Intel Corporation 8 Series/C220 Series Chipset Family PCI Express Root Port #4 (rev d5)\n00:1c.4 PCI bridge: Intel Corporation 8 Series/C220 Series Chipset Family PCI Express Root Port #5 (rev d5)\n00:1d.0 USB controller: Intel Corporation 8 Series/C220 Series Chipset Family USB EHCI #1 (rev 05)\n00:1f.0 ISA bridge: Intel Corporation HM87 Express LPC Controller (rev 05)\n00:1f.2 SATA controller: Intel Corporation 8 Series/C220 Series Chipset Family 6-port SATA Controller 1 [AHCI mode] (rev 05)\n00:1f.3 SMBus: Intel Corporation 8 Series/C220 Series Chipset Family SMBus Controller (rev 05)\n01:00.0 3D controller: NVIDIA Corporation GM204M [GeForce GTX 970M] (rev ff)\n03:00.0 Unassigned class [ff00]: Realtek Semiconductor Co., Ltd. RTS5249 PCI Express Card Reader (rev 01)\n04:00.0 Ethernet controller: Qualcomm Atheros Killer E220x Gigabit Ethernet Controller (rev 13)\n05:00.0 Network controller: Qualcomm Atheros QCA6174 802.11ac Wireless Network Adapter (rev 20)\n\n-\n~$ uname -a\nLinux msi 3.19.0-32-generic #37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\n-\n~$ sudo lshw -c video\nPCI (sysfs)  \n  *-display               \n       description: VGA compatible controller\n       product: Broadwell-U Integrated Graphics\n       vendor: Intel Corporation\n       physical id: 2\n       bus info: pci@0000:00:02.0\n       version: 0a\n       width: 64 bits\n       clock: 33MHz\n       capabilities: msi pm vga_controller bus_master cap_list rom\n       configuration: driver=i915_bpo latency=0\n       resources: irq:34 memory:a1000000-a1ffffff memory:b0000000-bfffffff ioport:5000(size=64)\n\n\nA: You have a very new GPU, so install and use the latest official stable NVIDIA drivers 361.  \nReplace bumblebee with nvidia-prime to switch between the two graphics solutions.  \nUninstall every currently installed NVIDIA software and remove the bumblebee as well.  \nOpen a terminal and execute :\nsudo apt-get purge nvidia* '^bumblebee.*'  \nsudo reboot  \n\nWhen the GRUB menu appears - select the Ubuntu entry and  press the E key.  \nAdd nouveau.modeset=0 at the end of the Linux line, then press F10 to boot.  \nNote : Set a Space between the last sign in this line and nouveau.modeset=0.  \nLogin and now install the NVIDIA drivers from the Proprietary GPU drivers PPA.  \nOpen a terminal and execute : \nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\nsudo apt-get install nvidia-361 nvidia-prime\nsudo reboot  \n\n\nA: The issue is gone with Linux 4.6\n", "Q: How to make Unity launcher change colour periodicaly How to make Unity launcher change colour over time ?\n\nA: Intruduction\nThe script bellow loops over hex values of colors incrementally. It can be started at login or can be ran manually when one wishes so\nGetting the Script\nOne can copy the source code from this post directly or through github using the following steps:\n\n*\n\n*sudo apt-get install git\n\n*cd /opt ; sudo git clone https://github.com/SergKolo/sergrep.git\n\n*sudo chmod -R +x sergrep\nThe script file will be /opt/sergrep/unity_launcher_rainbow.sh\nTo make the script start automatically on every login, refer to How do I start applications automatically on login? . Provide /opt/sergrep/unity_launcher_rainbow.sh(full path) as the command\nScript Source\n#!/usr/bin/env bash\n#\n###########################################################\n# Author: Serg Kolo , contact: 1047481448@qq.com \n# Date: March 20,2016\n# Purpose: Color changer script for Ubuntu Unity launcher\n# Written for: \n# Tested on: Ubuntu 14.04\n###########################################################\n# Copyright: Serg Kolo , 2016\n#    \n#     Permission to use, copy, modify, and distribute this software is hereby granted\n#     without fee, provided that  the copyright notice above and this permission statement\n#     appear in all copies.\n#\n#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n#     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n#     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL\n#     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n#     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n#     DEALINGS IN THE SOFTWARE.\nARGV0=\"$0\"\nARGC=$#\nmain()\n{\n  renice -n 10 $$ > /dev/null\n  num=0;\n  while true\n  do \n    set_unity_launcher_color   $(printf '%6.6xff' $num)\n    num=$(($num+510)) \n    if [ $num -eq 16777215 ]\n       then num=0\n    fi\n    sleep 0.05\n    done\n}\n\nset_unity_launcher_color()\n{\n  schema=\"org.compiz.unityshell\" # relocatable schema\n  path=\"/org/compiz/profiles/unity/plugins/unityshell/\" #must end with /\n  key=\"background-color\"\n  hex_string=$1\n  gsettings set \"$schema\":\"$path\" \"$key\"  \"'#$hex_string'\"\n}\nmain\n\n", "Q: Can't start MongoDB, mongod is always stop/waiting I try to run MongoDB 3.2.4 on Ubuntu 14.04:\nsudo service mongod start\n\nAnd get the result:\nmongod start/running, process 67725\n\nBut when I check the status I get:\nmongod stop/waiting\n\nI tried to reinstall MongoDB or to define the permissions for Mongo's folders (lib & log) as root or as mongodb. I also tried to repair the mongod.conf but nothing helps.\nThe content of log:\n2016-04-09T23:56:28.349+0300 I CONTROL  [main] ***** SERVER RESTARTED *****\n2016-04-09T23:56:28.359+0300 I CONTROL  [initandlisten] MongoDB starting : pid=69120 port=27017 dbpath=/var/lib/mongodb 64-bit host=is-infomedia\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten] db version v3.2.4\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten] git version: e2ee9ffcf9f5a94fad76802e28cc978718bb7a30\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.0.1f 6 Jan 2014\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten] allocator: tcmalloc\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten] modules: none\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten] build environment:\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten]     distmod: ubuntu1404\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten]     distarch: x86_64\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten]     target_arch: x86_64\n2016-04-09T23:56:28.360+0300 I CONTROL  [initandlisten] options: { config: \"/etc/mongod.conf\", net: { bindIp: \"127.0.0.1\", port: 27017 }, storage: { dbPath: \"/var/lib/mongodb\", journal: { enabled: true } }, systemLog: { destination: \"file\", logAppend: true, path: \"/var/log/mongodb/mongod.log\" } }\n2016-04-09T23:56:28.393+0300 E NETWORK  [initandlisten] Failed to unlink socket file /tmp/mongodb-27017.sock errno:1 Operation not permitted\n2016-04-09T23:56:28.393+0300 I -        [initandlisten] Fatal Assertion 28578\n2016-04-09T23:56:28.393+0300 I -        [initandlisten] \n\n***aborting after fassert() failure\n\nUpdate:\nAfter editing of /etc/mongod.conf:\n#security:\nauthorization: enabled\nenableEncryption: true\njavascriptEnabled: false\n\nand saving the file, and try to restart the mongod, I get the same error but MongoDB doesn't write any log file. I checked the permissions of /etc/mongod.conf, it is assigned to mongodb group. How can I restart mongod after editing its config file?\nMy questions:\n\n\n*\n\n*How can I run MongoDB as a service in Ubuntu?\n\n*What I miss or do wrong?\n\n\nA: This looks like premissions issue, please do:\nsudo chown whoami /tmp/mongodb-27017.sock\n\nThis will set premissions straight as You need.\n\nA: I had to change permission of the whole mongodb folder in /var/lib/. Gave it all permissions read and write and now my service starts.\n\n", "Q: Unsolvable Ubuntu 15.10 problems I am relatively new to Linux. I have opened some questions here during my quest to keep Ubuntu as a main OS anyway. I managed to sustain a seemingly redundant installation and everything seems to work fine. Now except some small stuff that no matter how much I searched on the web I couldn't find a solution or the solutions.\nI have a relatively new computer, here can find my specs:\ncpu AMD FX 8320,\nGTX 650 Ti 2GB,\n16 GB 2400MHz ram,\nAsrock 970 pro rev2.0 (Windows 10 ready)\n120GB SSD\n\nMy SSD is partitioned as follow:\n\n\n*\n\n*sda1 as my grub partition 750 MB\n\n*sda2 as a boot partition ext2 filesystem\n\n*sda3 as main OS ext4 filesystem\n\n*sda4 as a swap partition\n\n\nI found this things didn't work for me:\n\n\n*\n\n*some PPA package;\n\n*numlock always off at start;\n\n*dual monitor display issues;\n\n*system monitor doesn't work;\n\n*not able to install windows fonts;\n\n*system clock not synchronized;\n\n\nTL;DR Errors explanation:\n\n\n*\n\n*some ppas that are given from the official developer sites (or from Ubuntu forums) for ubuntu 15.10 sometimes don't work (e.g. QtSixA app for recognize a PS3 sixaxis controller).\n\n*the NUMLOCK is always OFF when I boot/restart/logoff my computer and no terminal commands or 3rd part software seems to work.\n\n*I have a 2 monitor display and I have setted both in Ubuntu settings and in my graphics driver settings (Nvidia 352) to launch apps on monitor B and set it as the main monitor also tried to make the same setting by downloading CompizConfig. (I didn't do all the steps together: first just changed Ubuntu settings but no result except in the the session; I changed the setting next reboot while the setting didn't change still programs did ignore it and launch on monitor A, searched and found the similar setting in my graphics driver and again no change. Also changed settings in CompizConfig and again no change except the first session I did the change).\n\n*System monitor doesn't work!! Its a native app that is supposed to monitor the resources of the computer. Well it seems it does, but actually it does NOT (I have set it to show all processes + their dependencies) and there are numerous times were CPU Cores are USED like on 80% yet the process tab doesn't show any app using any % of the CPU (or a few just using 1% or so depends on the session) OR the CPU is used  and system monitor doesn't show that its used or does show that its used less than 1% were the tasks at hand running(like chess engines etc) and the temperatures don't excuse such low usage and suggest that the CPU is used significantly more than system monitor suggests. OR Ubuntu lags because it uses (at 100% constantly) only one (of 8 available) cpu cores (And still at process tab it doesn't show any process using even that one core resources) that could be a Ubuntu issue.\nI knwo that CPU microcode from AMD is installed.\n\n*Fonts for windows NEVER get installed in my computer every time I get a message about installing them when I click to \"perform this action\" they seem to get downloaded (by what I can see from the terminal window that is popping) but they never do. Or if they do the error message about them not being installed pops up periodically.\n\n*The system clock gets messed up for example if the computer gets disconnected from the internet (I have it set to get time from internet ) and my mobos clock works fine so I don't know why it messes up that much... that leads to other problems since some procedures need or compare the time and date. This obviously doesn't happen every day, but it happens more than it really should. \nThe computer runs flawlessly Windows for few years up until I formatted the SSD containing it and installed Ubuntu. So I don't suppose that the above problems are caused because my hardware is faulty.\nI post this here in desperate hope of a miracle.\nP.S. I've already watched at Google first page results.\n\nA: On StackExchange networks, it's generally best to post each question separately. I don't have answers to all your issues, but here are some random info that might help:\n\n1) some ppas that are given from the official developer sites (or fomr\n  ubuntu forums) for ubuntu 15.10 sometimes dont work.... (most recent\n  in my experience was the QtSixA app for recognize a PS3 sixaxis\n  controller)\n\nPPAs are very liberal in allowing anyone to put up packages. No one, including Canonical, can monitor and make sure everything works. As part of the community, you are strongly encouraged to help the PPA owners resolve their issues, or if they ignore you, to point out to others that the PPA is buggy.\nGenerally speaking, try to stay clear of random PPAs. For the same reason you wouldn't download random files on the internet and execute them, you shouldn't do that on Linux either. Some PPAs are from official developers of a well-known project, such as wine. Those are fine. But if some shady person on the internet suggests a random PPA for something, well you'd better be careful!\nFor experimental/unstable libraries/programs that aren't yet good enough to be included in the main repositories of Debian (and inherited by Ubuntu), it often makes sense to download the source and build/install it. There is usually a brief set of instructions on how to do this, and is not so hard.\nFinally, if stability is what you are looking for, you might want to stick to LTS releases of Ubuntu. You'd miss out on \"the latest stuff\", but the latest stuff is exactly what's not as well-tested.\n\n2) the NUMLOCK is always OFF when I boot/restart/loggoff my computer\n  and no terminal commands or 3rd part software seems to work -and I\n  find this ridiculous!!!\n\nIs it only the LED that is off, or the numpad doesn't switch modes? Or does it turn on when you click it, but is off by default? I just looked at my keyboard and the LED was off, I pressed NUMLOCK, it stayed off, and pressing again it got on. It looks like the NUMLOCK was actually on in the beginning, but it was just the LED that was off. It's a bug for sure. However, I'm sure it only affects some keyboards. Incidentally, my keybaord is microsoft.\n\n3) I have a 2 monitor display and have set BOTH in ubuntu settings and\n  in my graphics driver settings (Nvidia 352) to launch apps on monitor\n  B and set it as the main monitor also tried to make the same setting\n  by downloading compizconfig (I didnt do all the steps together first\n  just changed ubuntu settings -no result except the in the session I\n  changed the setting next reboot while the setting didnt change still\n  programs did ignore it and launch on monitor A, searched and found the\n  similar setting in my graphics driver again no change... change the\n  settings in compiz again no change except the first session I did the\n  change) -I find that ridiculous as well... I mean its a BASIC\n  graphical element I know that a userfriendlies etc of a free distro\n  shouldnt be compared with proprietary OS such as macOS and windows...\n  but I still find this a fundamental issue that shouldnt exist in the\n  15th edition of the ubuntuOS..\n\nI have the same problem on Ubuntu 14.04 at work too. For me though, it's only for fullscreen applications (Quake 3 under wine). I agree that it's frustrating. I'm not sure if it's an Nvidia bug, or Unity. If it's Nvidia's, it's not too surprising. Giving them the benfit of the doubt, they only recently started supporting Linux.\n\n4) an other elemental issue that shouldnt exist... system monitor\n  doesnt work!! Its a native app that is supposed to monitor the\n  resources of the computer... well it SEEMS it does but actually it\n  does NOT (I have set it to show all processes + their dependencies)\n  and there are numerous times were CPU Cores are USED like on 80% yet\n  the process tab doesnt show any app using any % of the CPU (or a few\n  just using 1% or so depends on the session)\nOR\nthe CPU is used and system monitor doesnt show that its used or does\n  show that its used less than 1% were the tasks at hand running(like\n  chess engines etc) and the temperatures dont excuse such low usage and\n  suggest that the CPU is used significantly more than system monitor\n  suggests...\nOR\nUbuntu lags because it uses (at 100% constantly) only one (of 8\n  available) cpu cores (And still at process tab it doesnt show any\n  process using even that one core resources... ) that could be a Ubuntu\n  issue\nto cut the long story short system monitor seems to be more than a\n  graphical gimmick than a real deal resource monitor... again I find\n  this a basic elemental thing (to be able to know exactly or in a very\n  close approximation how many resources are being used and which\n  processes use them) and find the absence of that function ridiculous\n  for a OS no matter if free or not.\nP.S I have updated and installed the cpu microcode from amd.\n\nI believe System Monitor is more targeted at grandmothers, trying to be simple and everything. I use indicator-multiload to monitor my system activity (and while System Monitor doesn't show all process usages correctly, indicator-multiload generates correct graphs).\n$ sudo apt-get install indicator-multiload\n$ indicator-multiload &\n\nAfter the above command, indicator-multiload should start on boot automatically. To actually see the processes and their usages, the good old top command (run from terminal) is the best. People generally think the terminal is for advanced users, but in reality, the terminal is just a very effective way of doing things on your computer. The windows terminal is so bad, people migrating from there aren't used to it. Trust me, you would feel easier there for some tasks.\n\n5) Fonts for windows NEVER get installed in my computer every time I\n  get a message about installing them when I click to \"perform this\n  action\" they seem to get downloaded (by what I can see from the\n  terminal window that is popping) but they never do... or if they do\n  the error message about them not being installed pops up\n  periodically...\n\nSorry to hear that. I personally have no love for windows or its fonts, so I've never tried this. Perhaps somebody else has an opinion.\n\n6) the REBOOT process or SHUTDOWN process is SO SO SO buggy (not even\n  windows 95 or earlier versions sucked that much in that) its like boot\n  and pray that no error message will appear or that it will boot\n  because you cant tell if it messed anything up since your last\n  shutdown.\nI have a relatively new computer (cpu amd fx 8320,GTX 650 Ti 2GB,16 GB\n  2400MHz ram,Asrock 970 pro rev2.0 -windows 10 ready-mobo running the\n  latest bios and run the OS on a 120GB SSD with sda1 as my grub\n  partition -750 MB- sda2 as a boot partition ext2 filesystem and sda3\n  as main OS ext4 filesystem and sda4 as a swap partition and dont run\n  any other OS on that disk)\n\nWhat problems do you see? If you are interested in knowing exactly what's going on at boot and shutdown, you can edit your grub config to remove splash screen from boot.\n$ sudo gedit /etc/default/grub\n\nFind the line that says GRUB_CMDLINE_LINUX_DEFAULT=\"...\" and remove quiet splash from it. Update your grub:\n$ sudo update-grub\n\nYou can also see boot logs with dmesg:\n$ dmesg\n\nMany times, a minor error written during splash screen is not really a problem. Perhaps it's something some power user may care about, but generally if your system boots, you are ok. Linux hardly \"messes anything up\" during shutdown, so whatever is the cause of the error, it is very likely hardware related. It's impossible to tell without you providing info on what error you actually see.\nWhy is your boot partition ext2 by the way?\nSide note: Since you have an SSD, you might be interested in reading this for example to help improve its performance under Linux.\n\n7) The system clock gets messed up for example if the computer gets\n  disconnected from the internet (I have it set to get time from\n  internet ) and my mobos clock works fine so I dont know why it messes\n  up that much... that leads to other problems since some procedures\n  need or compare the time and date.... this obviously doesnt happen\n  every day... but it happens more than it really should.\n\nHow does it get messed up? Linux (like all sane operating systems, which naturally excludes windows) keeps time in UTC. Windows keeps time in local time. I'm not going to go over just how stupid it is to use local time, but just letting you know that unless you live in the +0 timeline, the Linux and windows times are going to differ. If you boot into windows, it will change your motherboard's time to local time. Linux fixes it back to UTC. In dualboot systems, this is actually a problem. You can try telling windows to use UTC, but in my experience sometimes windows ignores your configuration. Alternatively, you can tell Linux to use local time, but I personally recommend not to do this (because local time is just stupid).\nFrom your explanation, it doesn't seem like you are dual booting. So my suggestion is this. In Linux, fix the time (from the internet), then reboot and go to your bios. If it shows your local time, it's your motherboard that is somehow reverting the time back to local time. I've never seen a motherboard actually do this, but perhaps new \"windows 10 ready\" motherboards do it. This is unless, of course, you are booting into windows, and that's why your clock gets off.\n\nThe computer runs flawlessly Windows for few years up until I\n  formatted the ssd containing it to install ubuntu.... so I dont\n  suppose that the above problems are caused because my hardware is\n  faulty.\n\nDon't be so quick to think the hardware is not faulty. Unfortunately for you and me, many manufacturers only test their hardware with windows. That means that if there is a bug in the hardware that doesn't trigger because windows doesn't use a feature or follows a certain set of steps, the bug is often not discovered until someone runs Linux on it and it starts doing things differently (random link after a quick search).\nThe best you can, again as part of the community, is to report your issues. Linux works with almost anything you throw at it, so unless the hardware came from a very anti-linux company and was released just yesterday, there is almost always someone taking care of each driver, and they may be interested in test reports.\n\nI post this here in desperate hope of a miracle\nSuch as a very advanced member notices it and will read atleast one of\n  ht problems mentions above and give a different method to solve the\n  problem (different that the google results of the first page when\n  searching for them since they didnt work for me)\nOr that it gets noticed by the Ubuntu team and those problems get\n  fixed....\n\nJust a final note. I've had similarly frustrating issues with windows (7 in particular, it was my last) in the past. For example, it not installing if I have two HDDs plugged at the same time, filling up my disk when updating then on restart showing the disk as it used to be, random black rectangle on the screen that doesn't go away until reboot, etc. For a company that pours billions into making sure it keeps its monopoly of desktop OS, its OS is really not less problematic than GNU/Linux. Before getting invested in Ubuntu, feel free to try out a couple of other GNU/Linux distros and perhaps most of your problems may go away. Ubuntu hasn't been \"the best\" distro for some time now.\nWhile I too hope that one day GNU/Linux, any flavor, runs flawlessly, the fact is that no OS in the world can. Mac OS may run with less problems because it supports exclusively a handful of hardware pieces from Apple. Windows problems are less visible because often people buy PCs/laptops that come with windows pre-installed and tested. The fact that GNU/Linux runs on par with the other OSes (and in my opinion functionally much better, aside from minor bugs) and is entirely made up of free software (partly supported by various companies) is an amazing feat. All anyone can do is to help make GNU/Linux even better, whether it is through bug reports, suggestions or code. You have just begun doing just this, so, welcome to the community!\n", "Q: way to open .rar files in Ubuntu I am very new to Ubuntu and trying to install some soundfonts. One of them is in .rar. Do any of you know a way to open this type of fiel and make it operational?\nThanks,\nMartin\n\nA: Open your terminal by pressing ctrl+alt+t and do:\napt-get update\nsudo apt-get install p7zip-full p7zip-rar\n\nIf the installation for p7zip-rar fails make sure that you have the multiverse repository enabled and try again. When this is done you should be able to unpack .rar archives with the archive manager or if you want to do it in terminal:\n7z x archive.rar\n\n", "Q: Do I need unencrypted files underneath encrypted overmount? I have unencrypted files in my /home/user dir (likely fallout from moving my home dir to a different partition).\n/dev/sda1             440G  137G  282G  33% /home\n/home/user/.Private  440G  137G  282G  33% /home/user\n\nIf I ls /home/user while logged on as a different user, I see older contents of that dir since the encrypted file isn't mounted.\nDo I need those files?  And if not, what is a safe way to delete them?\n\nA: Looking at the unmounted encrypted home directory of a non-logged-in user, I see some unencrypted files (well they're really directories and links):  \n$ /bin/ls -la /home/walt\ntotal 12\ndr-x------  3 w3   walt 4096 Apr  9 22:12 .\ndrwxr-xr-x 13 root root 4096 Sep  1  2015 ..\nlrwxrwxrwx  1 walt walt   56 Oct 22  2011 Access-Your-Private-Data.desktop -> /usr/share/ecryptfs-utils/ecryptfs-mount-private.desktop\ndrwx------  7 walt walt 4096 Jan 16  2013 .cache\nlrwxrwxrwx  1 walt walt   30 Oct 22  2011 .ecryptfs -> /home/.ecryptfs/walt/.ecryptfs\nlrwxrwxrwx  1 walt walt   29 Oct 22  2011 .Private -> /home/.ecryptfs/walt/.Private\nlrwxrwxrwx  1 walt walt   52 Oct 22  2011 README.txt -> /usr/share/ecryptfs-utils/ecryptfs-mount-private.txt\n\nYou don't need any other files. You could delete the files with something like find /home/user -maxdepth 1 \\( \\! -type l -a -type d \\) -exec echo rm {} \\;, remove the echo when you are thrilled with the results of the find\n", "Q: Resizing VirtualBox So, I use a Macbook and I installed VirtualBox and Ubuntu but the window appears very little (a tiny square in the middle of the screen)\nI followed this question and I installed those extras they said there... But now how do I resize my window? \nHow do you resize the standard Ubuntu Desktop inside of Virtualbox?\n\nA: Virtual Box should resize automatically after installing the guest additions. If this is not the case you might check if virtual box actually was installed correctly. It is not done with downloading and mounting the image. You will have to browse inside your hosted OS with the file browser to the mounted virtual Guest additions image and run it. If this was correctly done, check in the VB menu. There is an entryto adjust the window. With the guest additions installed it should find automatically the right resolution and size. \n", "Q: Instability with dual-booting Win7 + Ubuntu - Would VirtualBox be more stable? I want to use Ubuntu for everything except Video editing in TMPGEnc, for which I need Windows, and possibly some other aps like Premiere. So far my attempt at dual-booting has produced a lot of errors and software crashes.\n\nA: Virtual Box works surprisingly well. My son uses FL Studio, and it works without mayor problems. The workflow is much better if you dont have to reboot every time you want check your emails. \nBut I think for rendering things you might need also a native Windows install. Try it out, if VB is fast enough for your needs, you can assign more processor.\n\nA: It depends on your hardware really and how much you can afford to allocate to your vm. Honestly, if your doing resource intensive things and you want both os's then I would try to work through the issues with the dual booting. Also consider a solid state drive if your worried about booting between os's. I do it now and it's not to bad. It can be a hassle sometimes though. \n", "Q: Clicking Files From Menu Does Nothing I run Lubuntu on my primary machine, but am running Ubuntu on a desktop.  I was attempting to set Pcmanfm as the deafult file browser and everything seemed to go well.  Using terminal I installed no issue, then I executed the below to set as deault\nsudo mv /usr/bin/nautilus /usr/bin/nautilus.bak\n\nsudo ln -s /usr/bin/pcmanfm /usr/bin/nautilus\n\nBut now if I click files from the menu bar (on the left side of the screen) nothing happens.  What do I need to change so that it will open pcmanfm\n\nA: Assuming you are talking about the unity launcher, you will need to make a .desktop file to point to pcmanfm.\nThe relevant ubuntu help is here:\nhttps://help.ubuntu.com/community/UnityLaunchersAndDesktopFiles\nEssentially though, I find it easier to copy a working .desktop file from\n/usr/share/applications/\n\nto\n~/.local/share/applications\n\nand edit it to point to the right place.\nThe file needs to be of the form:\n[Desktop Entry]\nVersion=x.y\nName=ProgramName\nComment=This is my comment\nExec=/home/alex/Documents/exec.sh\nIcon=/home/alex/Pictures/icon.png\nTerminal=false\nType=Application\nCategories=Utility;Application;\n\n\nA: I dont really know if there is a way to achieve that, but I wouldn't recommend to change the default file browser. Tried it onces without luck. Because Nautilus is not only the file browser, but also the desktop etc. If you change it, it will have some unwanted consecuences. If you really want to work with pcmanfm better make a clean lubuntu install, which is based on this file browser. Works great also on older machines.\n", "Q: How can I reset ubuntu gnome terminal options? I have Ubuntu gnome on my laptop and in my terminal all the text is green. However, on another computer my text is green but the bold text is a different color. I already changed the bold text on my laptop to another color but I guess the terminal is not printing bold.\nHow do I fix this? I don't remember changing options on the terminal where it does show bolded text so I'm thinking I can just reset my settings somewhere. How do I do this?\n\nA: Two simple steps to reset gnome-terminal to defaults:\n\n\n*\n\n*Run this command from your Terminal:\nmv -v $HOME/.gconf/apps/gnome-terminal/ $HOME/.gconf/apps/gnome-terminal_bak\n\n\n*Log out and then log back in\nThe defaults will then be back in place. Then go to:\nEdit --> Profile Preferences\n\nand customise as you wish...\n", "Q: MATLAB has encountered an internal problem and needs to close - Ubuntu 15.10 I have recently installed Matlab R2015a on Ubuntu 15.10, however when I open the program I consistently get this error. I have copy'd and pasted the details below. I think the fault is coming from:\nStack Trace (from fault):\n[  0] 0x00007f58a634c4b0 /usr/local/MATLAB/R2015a/bin/glnxa64/libQtCore.so.4+00550064\n\nBut I am not positive. I am new to Ubuntu and am wondering if anyone else has encountered this problem and knows how to fix it. \nMATLAB crash file:/home/mike/matlab_crash_dump.14223-1:\n------------------------------------------------------------------------\n       Segmentation violation detected at Sat Apr  9 19:16:31 2016\n------------------------------------------------------------------------\n\nConfiguration:\n  Crash Decoding      : Disabled\n  Crash Mode          : continue (default)\n  Current Graphics Driver: Unknown hardware \n  Current Visual      : 0x42 (class 4, depth 24)\n  Default Encoding    : UTF-8\n  GNU C Library       : 2.21 stable\n  Host Name           : EKIM\n  MATLAB Architecture : glnxa64\n  MATLAB Root         : /usr/local/MATLAB/R2015a\n  MATLAB Version      : 8.5.0.197613 (R2015a)\n  OpenGL              : hardware\n  Operating System    : Linux 4.2.0-35-generic #40-Ubuntu SMP Tue Mar 15 22:15:45 UTC 2016 x86_64\n  Processor ID        : x86 Family 6 Model 78 Stepping 3, GenuineIntel\n  Virtual Machine     : Java 1.7.0_60-b19 with Oracle Corporation Java HotSpot(TM) 64-Bit Server VM mixed mode\n  Window System       : The X.Org Foundation (11702000), display :0\n\nFault Count: 1\n\n\nAbnormal termination:\nSegmentation violation\n\nRegister State (from fault):\n  RAX = 00007f58a1e64c80  RBX = 0000000000000000\n  RCX = 0000000000000001  RDX = 0000000000000000\n  RSP = 00007f5945446468  RBP = 00007f58bbb14e90\n  RSI = 00007f5940003b40  RDI = 00007f58a1e64c80\n\n   R8 = 0000000000000000   R9 = 0000000000000001\n  R10 = 0000000000000001  R11 = 00007f5938000078\n  R12 = 00007f58bbb0b9f0  R13 = 00000000012017a0\n  R14 = 00007f58bba8fcc0  R15 = 0000000000000000\n\n  RIP = 00007f58a634c4b0  EFL = 0000000000010202\n\n   CS = 0033   FS = 0000   GS = 0000\n\nStack Trace (from fault):\n[  0] 0x00007f58a634c4b0 /usr/local/MATLAB/R2015a/bin/glnxa64/libQtCore.so.4+00550064\n\n\nIf this problem is reproducible, please submit a Service Request via:\n    http://www.mathworks.com/support/contact_us/\n\nA technical support engineer might contact you with further information.\n\nThank you for your help.\n\nA: Researching a little more and installing the Matlab support files fixed the problem.\nsudo apt-get install matlab-support\n\n", "Q: How can I use abcde to rip to mp3 and embed album art under Trusty and Xenial? I would like to use the commandline audio ripper abcde to:\n\n\n*\n\n*Rip audio cds to mp3\n\n*Download and then embed the appropriate album art\n\n\nCan someone show me an example of how to accomplish this under both Trusty Tahr LTS and Xenial Xerus LTS?\nFull disclosure: I was formerly one of the maintainers of abcde.\n\nA: For both Trusty and Xenial it is a good idea to use one of the multimedia PPAs of mc3man to get the most modern abcde available:\n1. Installation for Trusty:\nAdd the following PPA and some required packages:\nsudo add-apt-repository ppa:mc3man/trusty-media\nsudo apt-get update\nsudo apt-get install abcde lame eyed3 glyrc imagemagick cdparanoia\n\n2. Installation for Xenial:\nAdd the following PPA and some required packages:\nsudo add-apt-repository ppa:mc3man/xerus-media\nsudo apt-get update\nsudo apt-get install abcde lame eyed3 glyrc imagemagick cdparanoia\n\n3. Running abcde for Trusty or Xenial:\nYou can use a customised ~/.abcde.conf file to get quality mp3 files as well as album art but if you just want to use the commandline simply use the following, under either Trusty or Xenial:\nabcde -o mp3:-V2 -a default,getalbumart\n\nThis will find the album art and download it next to your mp3 files which will be encoded to Variable Bitrate with bitrate averaging between 170-210 kbps. What more could you want?\n4. Embed the album art?\nWell, you could want to actually embed the cover image into your mp3 files. To do this simply change to the directory that holds your mp3s and the cover image and run the following:\nfor i in *.mp3\ndo\neyeD3 --add-image cover.jpg:FRONT_COVER \"$i\"\ndone\n\nAnd now you are done :)\nReferences:\n\n\n*\n\n*Hydrogen Audio: Lame recommended Settings\n", "Q: Replacing a Substring with sed So I've got a line that looks like this ish\nsomelongbullshit:888:morelongbullshitthatcanhaveanything\n\nAnd I want to replace the second : with a tab character. I can reliably match the substring I want to replace with the following:\n^.*:[0-9]*(:)\n\nI want to replace that substring I have there. So I've tried doing some sed\n$ echo somelongbullshit:888:morelongbullshitthatcanhaveanything | sed 's/:[0-9]*(:)/\\1\\t/g'\nsed: -e expression #1, char 19: invalid reference \\1 on `s' command's RHS\n\nBut I get an error. I'm sure there's some syntax error I've got wrong but for the life of me I can find it. \nI'm also open to better solutions (like awk).\n\nA: You can use sed like this with --regex-extended switch:\necho somelongbullshit:888:morelongbullshitthatcanhaveanything | sed --regexp-extended 's/:[0-9]*(:)/\\1\\t/g'\n\n\nA: *\n\n*Not all versions of sed will recognize the tab. so press Ctrl+V and press tab key from your keyboard.\n\n*use this command \n $ echo \"somelongbullshit:888:morelongbullshitthatcanhaveanything\" | sed 's/\\:/      /2'\n somelongbullshit:888    morelongbullshitthatcanhaveanything\n\n", "Q: Grub customizer error When I try to update grub by using grub-customizer it gives me error\n\nhow can I solve this problem?\n\nA: Clearly, there is an error in line 299 of the generated GRUB config file. Check for errors in the /etc/default/grub, /etc/grub.d/* files related to generated line 299 (of /boot/grub/grub.cfg). Read the error message! \n", "Q: My Toshiba Satellite C55-B5319 fans will not turn on; how do I make them work? The system hasn't shut down automatically due to overheating yet, but the HDD will reach temperatures of 102 degrees Fahrenheit as far as I know. So, how do I make the fans turn on, or is the HDD supposed to get that hot?\nAlso I think the fans did turn on when I was running Windows 10, furthermore they're probably not broken because the laptop is only about 3 months old. \n\nA: A temperature of 102 Fahrenheit is perfectly normal for a laptop HDD. Toshiba HDDs can operate up to 55 Celcius = 131 Fahrenheit.\nThe fan in a laptop is designed to cool the heatsink on the processor and video chip and will have little effect on the temperature of the HDD.\nIf the fans came on when you were running Windows 10 but not Ubuntu it is a measure of how much more efficent Ubuntu is as an operating system.\n", "Q: Ubuntu Server 14.04 suddenly stopped serving webpages I installed iRedMail and set up virtual hosts to put up my own webpage along side the iredMail installation. I also put in free certificates from StartSSL.com. Everything was working great. Then I connected one of my email accounts on my android phone, and it started complaining about no connection. And now I can't open up any of my webpages. Chrome always says the webpage took too long to respond.\nThe server is pingable and I can still access it through SSH. Restarting the service or the server makes no difference. I verified apache2 is running.\nservice apache2 status\n * apache2 is running\n\nWhen I look in the apache logs, I don't even see my attempts showing up in apache2/access.log. The apache2 error.log is the same few lines over and over. (I don't think that's the problem?):\n[Wed Apr 06 17:03:42.061888 2016] [core:notice] [pid 3136] AH00094: Command line: '/usr/sbin/apache2'\n[Wed Apr 06 17:07:29.206904 2016] [mpm_prefork:notice] [pid 3136] AH00171: Graceful restart requested, doing restart\n[Wed Apr 06 17:07:29.477532 2016] [ssl:warn] [pid 3136] AH01906: RSA server certificate is a CA certificate (BasicConstraints: CA == TRUE !?)\n[Wed Apr 06 17:07:29.479156 2016] [mpm_prefork:notice] [pid 3136] AH00163: Apache/2.4.7 (Ubuntu) OpenSSL/1.0.1f mod_wsgi/3.4 Python/2.7.6 configured -- resuming normal operations\n\nAnyway, I'm at a loss. Does anybody have ideas? Or even suggestions of where I should look to troubleshoot this?\n\nA: Edit:\nWell, after waiting a while and rebooting a 3rd time, the problem went away. I'm still annoyed that I have no idea what went wrong.\n", "Q: Very large TRIM amounts Something is wrong with my system setup on SSD. During the installation of Ubuntu 14.04 I selected \"use entire disc\" for my 256 GB SSD.\nNow after reload fstrim shows 200 GB trimmed and just after opening and closing Firefox with several tabs fstrim clears another 600 MB:\n\n(I have 200 GB of free space and haven't deleted anything. Partition table is set to MSDOS (default). On the previous system installation (same version and same hardware, but manual partitioning) everything was fine.\n\nA: There is nothing wrong with your system or your SSD. The trim command allows the operating system to inform a solid state drive (SSD) which blocks of data are no longer considered in use and can be wiped internally. So as you have 200 GB of free space, only 200 GB can be trimmed.\nOr the other way around, because you have 200 GB of free space, 200 GB are getting trimmed.\n", "Q: What's the difference between linux/ip.h and netinet/ip.h? I found that there are linux/ip.h and netinet/ip.h in /usr/include， and some of them are the same. Why are there duplicate files here with different names, what's the difference between them？\n\nA: History.  \nBack in the Early Days, before computers roamed the earth, two completely independent groups of people started development on two separate software subsystems.  \nTaking advantage of the privileges of developers, each group picked lovely names for the parts of their subsystems. \"ip.h\" is such a name. \nWhen the time came to merge their subsystems, both groups wanted to keep their lovely names.  \nBy putting the copy of ip.h the subsystem needs in a subdirectory makes it easy for developers. One wanting to use the definitions in netinet's version of ip.h need only #include <netinet/ip.h>, while a developer wanting to compile with the linux version does #include <linux/ip.h>.\n", "Q: Connect to Windows XP via VMWare Is it possible to connect to the command line on Windows XP running on VMWare, from inside of Ubuntu?\n\nA: You can connect to the Windows XP virtual machine via telnet:\n\n\n*\n\n*Set up the telnet server on Windows XP:\nInside the command prompt of the Windows XP machine run these commands found from here http://seriss.com/rush.102.42/misc/windows-telnet.html\nsc config TlntSvr start= auto\nsc start TlntSvr\ntlntadmn config sec=-NTLM\ntlntadmn config mode=stream\n\n\n*Get the IP address by running: \n    ipconfig \nand note the ip address of the machine in the format www.xxx.yyy.zzz.\n\n\n*On your Ubuntu machine open up a terminal and type:\ntelnet www.xxx.yyy.zzz 23\n\nwhere www.xxx.yyy.zzz is the ip address of your Windows XP machine you noted in step 2. and you will connect to the Windows XP telnet server which will open a CMD.EXEfor you!\n", "Q: Can't get headset working with 1 plug I am running Ubuntu 14.0.4 LTS\ni just bought a new headset but it uses 1 plug instead of two, i get sound but it doesnt detect a microphone, my old headset that broke worked fine with the 2 plugs.\nIt's a Logitech h151, box says it works with Kernel 2.6+.\nhope i can find a fix for this\n\nA: It doesn't have anything to do with the software, but the hardware. There are a few different types of phone connector jacks - stereo, mono, and multi-channel.\n\nTake note of the three bands on the plug and the different colored sockets. This is how you can visually identify the cable has three channels, one for the microphone and two for left and right audio. I suspect this is the kind of connector on your new headphones.\nYour audio card is not designed for this kind of multi-channel connection, input and output on the same cable. If the headset didn't come with it, your local electronics store should be able to sell you an appropriate cable; it should have a port for the three-channel line (not that you'll be able to visually inspect it) and then two plugs to connect to the computer's ports.\n\nJust make sure you don't get a simple splitter - it will only connect to the two channels, not all three. Frequently (but not always) the plugs will be different colors if it's what you need, but the same if it's just a splitter.\n", "Q: How to create config files Im trying to create a config file in UBuntu 15.10 VPS by doing this:\nsudo nano $HOME/.yourcoin/yourcoin.conf\n\nBut when I try to exit and save it says error writing no such file or directory. I also tried mkdir but can't do it. I want to create this config file.\n\nA: To clarify, you are trying to create a root access file (because you are using sudo), inside a hidden directory under $HOME. Also, the directory may not exist yet, so first try:\ncd ~/.yourcoin\n\nIf it fails, it is likely that the directory does not exist, so then try:\nmkdir ~/.yourcoin\n\nOnce you are sure the directory is there, then try:\nsudo nano ~/.yourcoin/yourcoin.conf\n\n", "Q: cloning my ubuntu image to HDD alongside win10 I bought a new laptop with win 10 pre-installed. Now I want my Ubuntu 14.04 installed on my old laptop HDD to be cloned and installed on the new HDD alongside win 10.\nSo far I was able to run Ubuntu from the external HDD. I installed the new drivers, disabled secure boot, ... Bottom line it Ubuntu runs smoothly from the old HDD mounted on the new laptop through USB/sSATA port.\nI partitioned the new HDD already.\nHow can I do that?\nAlso. My old version of Ubuntu was installed alongside win7 so GRUB2 is installed somewhere. Will it be reinstalled on the new HHD? And if so, would it work for dual booting?\nThanks,\nMarcello\n\nA: Not recommended. \nWindows 10 will be UEFI, and old Ubuntu is probably BIOS with MBR. \nAnd UEFI has gpt partitioning so you cannot easily clone a MBR partition to gpt. Better to do new install in UEFI mode and copy /home and/or data into new install. \nhttps://help.ubuntu.com/community/UEFI\nInstalling Ubuntu Alongside a Pre-Installed Windows with UEFI\nBe sure to use Windows tools to shrink NTFS partition and reboot immediately. Then use gparted or installer to create partitions. Also make sure Windows fast startup  or always on hibernation is turned off.\n", "Q: Getting 32-bit grub to automatically boot Ubuntu After so, so much pain and a lot of time (this is too common a prelude), I've managed to get Ubuntu 15.10 installed on the infamous Asus X205TA. It is currently set up in the following way:\n\n\n*\n\n*/dev/mmcblk0p1 is the fat32 bootloader\n\n*/dev/mmcblk0p2 is the ext4 OS\n\n*/dev/mmcblk0p3 is swap\n\n\nNow I managed to hack-and-slash my way through a bunch of guides and eventually get a 32-bit grub (2.02 beta, as it were) installed onto the boot partition in a way that boots up the grub command prompt. I can then boot by entering the following commands [and typing veeery carefully due to the oversensitivity of the keyboard at this stage]:\ngrub> set root=(hd0,gpt2)\ngrub> linux /boot/vmlinuz-4.2.0-16-generic root=/dev/mmcblk0p2\ngrub> initrd /boot/initrd.img-4.2.0-16-generic\ngrub> boot\n\nThis boots just fine into Ubuntu.\nThe question is, how can I make this automated (or kick me into the grub menu with the countdown ...)?\n\nI also attempted to use Boot Repair, which did some magic but ultimately did not fix the problem. However, it did seem to mount appropriately and persistently the /dev/mmcblk0p1 to /boot/grub. I believe this, in combination of the accepted answer terminal commands, were the key.\n\nA: In theory, typing sudo update-grub should do the task if your GRUB is based on Ubuntu's GRUB. If not, sudo grub-mkconfig -o /boot/grub/grub.cfg should do it.\nAlternatively, IF your installation is of a 32-bit Ubuntu, you might find it easier to install my rEFInd boot manager. You can install the PPA and it should set everything up automatically to boot without GRUB. This will work only on a same-bit-depth basis, though -- that is, if you've installed a 32-bit Ubuntu on a 32-bit EFI (or more commonly, a 64-bit Ubuntu on a 64-bit EFI). If you've installed a 64-bit Ubuntu on a 32-bit EFI, you'll still need GRUB to do the job.\n\nA: I have the x205ta too. I originally used Lopaka's guide which has since been updated and not tested by me.\nYou may have also seen KemyLand's guide on this Ubuntu Forums thread. This uses a chroot method, but if you boot from GRUB the commands to do after the chroot might fix your problem. Maybe you just need the packages  efibootmgr, grub-efi-ia32, and grub-efi-ia32-bin (you probably already have them) and these two lines\nsudo grub-install --target=i386-efi --efi-directory=/boot --bootloader-id=grub_uefi --recheck\nsudo grub-mkconfig -o /boot/grub/grub.cfg \n\nRecently I installed 16.04 with the automated installer after making a usb to live boot to test it out. Just for fun, I let it attempt to reboot\nAnd I could hardly believe my eyes when it booted! So apparently compiling or even tweaking GRUB for 32-bit UEFI is no longer needed in 16.04 for this device. Happy days if you feel like moving to 16.04...\n", "Q: Gephi crashes while loading the sample file I was trying to install gephi for some network analysis. Initially there was problem with the Java Runtime Environment that is installed. I removed the Open JRE and installed the Oracle JRE 8u77. Even that gave some problems and when I looked online I figured that there is some trouble using JRE version 8 with gephi so I un-installed Java completely from the system and then installed JRE version 7. I was able to run in after that by typing ./gephi but when I load the Power-Grid sample file it crashes.\n\nA: I figured out the answer and wanted to share with you guys. In the gephi website it is mentioned that in order to run the software we are supposed to type ./gephi in the command line. Instead try LIBGL_ALWAYS_SOFTWARE=1 ./gephi \nThis fixes any issues which occur while running the gephi software.\n", "Q: What is the need of /home partition in Ubuntu? \n*\n\n*What is the use of home partition in Ubuntu and what does it contain? \n\n*Can I create separate partitions for my personal stuffs? If yes, how to do that?\n\n\nA: Usually /home directory is the directory where users keep their private files. Every user has a directory with his/her name in the home. For instance /home/user1, /home/user2, etc.\nEvery directory in Linux can be a directory or a separate partition. It is different as in Windows where partitions are usually a separate drive letter, although it is possible to mount a partition as a directory in Windows for more than 15 years.\nIn Linux you have a root (/) directory and all directories are descendants of /. You can have /home directory on another partition or disk or you can have /home only as a /home directory on the /. You can also put /home/user1 on a separate partition as /home/user2. It is up to you how you want to organize it. The partitions and their mount points are in the /etc/fstab file. That means that /etc cannot be mounted as a separate partition.\nSome like to have /home on a separate partition because they know exactly how much space they have. System files which are on a different partition cannot take the space reserved for /home. Others like only one partition because they don't want to make many partitions, which may be to big or to small.\nThere's a lot of info how to make the partitions:\n\n\n*\n\n*How to use manual partitioning during installation?\n\n*https://help.ubuntu.com/community/PartitioningSchemes\n\n*https://help.ubuntu.com/community/HowtoPartition\n", "Q: Whats the differences between NVIDIA installed from ppa or from nvidia.com Im actually testing drivers for my NVIDIA card from both the new ppa:graphics-drivers/ppa on the one hand and official drivers directly from nvidia.com on the other hand.\nInstallation and workflow in general is nearly the same i cant see any differences that far (except that the ppa installation is more easier). \nBut...\nI also have Autodesk Maya with a student license and if i have installed the driver packages from nvidia.com all is fine and Maya is working fine. \nIf i install the drivers from ppa:graphics-drivers/ppa Maya will stop working for graphical faults and crash back to desktop. So there must be a difference between both drivers and how they work otherwise this wont happen.\nI would like to know why there is a difference at all and why this happens for Maya for example. \nDont get me wrong its not a big deal to solve this by removing the ppa driver and install the one from nvidia, but i assume the main target from you guys over at “Graphics Drivers Team” is to build the nvidia drivers as close as possible to the official drivers? Actually they cant be used for Maya for example, where the drivers from nvidia can.\n\nA: It turns out the following:\nOn a new system installation (in my case 16.04) there are mesa drivers installed. The libraries for mesa are installed to:\n/usr/lib/x86_64-linux-gnu/mesa\n/usr/lib/x86_64-linux-gnu/mesa-egl\n\nDuring the installation of mesa symlinks are created from\n/usr/lib/x86_64-linux-gnu/mesa/libGL.so to \n/usr/lib/x86_64-linux-gnu/libGL.so\n\n/usr/lib/x86_64-linux-gnu/mesa-egl/libEGL.so to \n/usr/lib/x86_64-linux-gnu/libEGL.so\n\n/usr/lib/x86_64-linux-gnu/mesa-egl/libGLESv2.so to \n/usr/lib/x86_64-linux-gnu/libGLESv2.so\n\nIf you install the nvidia drivers from ppa:graphics-drivers/ppa this will install the same libs but to /usr/lib/nvidia-XXX.\nAs the symlinks from mesa in /usr/lib/x86_64-linux-gnu will stay Autodesk's maya will use them. \nAnd as maya requires nvidia drivers to be installed it will crash because it loads the mesa drivers.\nThe solution is wether to tell maya to use different libs from nvidia or to replace the mesa symlinks with symlinks pointing to the respective nvidia libs.\nWouldnt it be a good idea to check the system about any mesa drivers installed during the nvidia installation?\n", "Q: How do I adjust settings in overGrive? So, I've got overgrive installed and synced, but how do I adjust the settings? I gotta reorganize files and such.\nI've tried opening the program and it just has a spinning wheel and then nothing, no GUI.\nI'm running Ubuntu Gnome 14.04, btw.\n\nA: From the overGrive menu select Preferences to change the settings.\nLubuntu / LXDE / Mint desktop users and users that use Light Themes need to select the Prefer Light Icon Theme or they might not be able to see the default white application indicator icon in the taskbar. Also see notes and instructions for Gnome desktop users.\n\nA: Right-click on the bar at the bottom of your desktop and select \"+ add applets to the panel\". \nFrom the list of applets highlight \"System Tray\" and click \"+ add to panel\".\nYou should now see the OverGrive icon on the panel.  Which when you click on it will display the settings menu.\nI hope this solves your issue.\n", "Q: I have a netbook I can't format (for legal reasons) and cannot upgrade from the terminal to Ubuntu 14.04 from 10.04 I have a netbook that we're given during high school for educational purposes, which has a Linux, and now that I'm in college I want to start using it. It has Ubuntu 10.~ and when I use the sudo apt-get update and sudo apt-get upgrade it gives the message \"0 things found, 0 to be updated\".  \nI would just format the PC if I could and install 14.04 from a USB like the guides say, but it is still protected with a program that prevents you from altering the PC like that.  \nCould someone point me in the right direction? Can Ubuntu be 'forcefully' upgraded?\nThanks\n\nA: There is the option to just do a clean install from a current version - provided you are entitled to (the use of 'legally' in your question suggests not, but if it's an ex-school one, now yours then you can do what you like..).  \nBackup any important files to external drive first, boot from a USB (or CD) & you have total control over your old drive, no matter what's been installed on it. If the computer won't boot from USB then you need to hunt through BIOS to find why - there's alway 'reset to defaults' if you can't.  \nUpgrading from archaic versions, my experience has been that it balks if too old (& I think 10.04 may be).  \nIf these answers don't help you, a bit more detail (eg which netbook, what happens when you try) may open things up a bit more.\n\nA: My understanding is that the only way this would be possible would be to do sequential upgrades. First upgrade from Lucid Lynx (10.04) to Precise Pangolin (12.04); then upgrade from 12.04 to Trusty Tahr (14.04). Read the Upgrade Notes for how to conduct these steps. You should also read these instructions carefully.\nHowever, it may behoove you to find someone with some expertise who is able to remove the program that prevents you from reformatting. Is the laptop your property or does it still belong to the school?\n\nA: You're doing package updates not a system upgrade. Try this instead:\nsudo do-release-upgrade\n\nThat should take you from 10.04 to 12.04, then once that's done and you've tested it and are happy, you can do it again to take it from 12.04 to 14.04.\n", "Q: Can the home partition be created as an extended partition? Hi guys I\"m a rookie to the Ubuntu OS.Can I have my home partition as an extended drive? Eager to hear the answer.\n\nA: Yes - how exactly do you mean though? I'm sort of assuming you mean 'extended partition', in which case it's no different to any other partition in this context - although if you mean 'a separate physical drive' or 'in another room' then it's still yes :).  \nThe normal setup is that you can have 4 primary partitions, and any more have to use one of the 4 as a 'frame' to fit within that limit, hence are termed 'extended partitions'. You can have loads if you really want!  \n", "Q: Nouveau vs Nvidia driver on Xenial 16.04 Xenial beta works well on a test laptop with an Nvidia GeForce 920M with the Nouveau driver.\nHas the Nouveau driver matured enough so that one needs the NVidia driver only when you have heavy graphics work, or gaming? Or is there a technical advantage to using it for everyday normal work?\n(There must have been a reason to start the project and for people to continue pouring in hard work into it)\n\nA: I am using nouveau driver for years now because NVidia driver does not allow me to use NVidia together with the onboard Intel graphics.\nFor me the nouveau has matured enough. I have not had a crash for a long time and it works fine. I remember to have crashes in the past. However, I am not a heavy graphics user. I use the computer mostly for development/programming (editors, compiling, VirtualBox, etc.), system administration (ssh) and regular office work (email, web browsing, libre office, printing, etc).\nThanks to Mark Kirby I would like to point out that I am writing about using NVidia with another GPU where both GPU are used simultaneously. For the case where notebooks have NVidia (concept called Hybrid Graphics - wiki.ubuntu.com/X/Config/HybridGraphics), the comment from Mark Kirby is valid. In that case use nvidia prime.\n", "Q: Has anyone got an Nvidia 940M to work on 14.04.4 LTS w/ Nvidia proprietary drivers? I've been trying for a couple of days now to get my 940M to work on Ubuntu 14.04.4 LTS to no avail (currently stuck on login loop issue), and yet there doesn't appear to be much discussion of issues surrounding the card. I have a feeling that I'm overlooking something simple.\nHas anyone else been able to get an Nvidia 940M to run on 14.04.4 LTS with Nvidia's proprietary drivers?\nIf so, how did you do it?\nThe nouveau drivers appear to work just fine, but I expect better performance with Nvidia's.\n\nA: You probably did not install nvidia-prime for your hybrid graphics.\nRun in terminal\nsudo apt-get install nvidia-352 nvidia-prime\n\nIf there are any errors, post output to your question. Then reboot.\nYou can also install a newer driver from a PPA\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\nsudo apt-get install nvidia-361 nvidia-prime\n\nBoth 352 and 361 drivers support Nvidia 940M adapter.\n\nA: Turns out the answer was simply installing a 16.04 LTS daily instead of 14.04.4 LTS, as suggested by @emk2203 in the OP comments!\nAfter booting up the 16.04 LTS, everything went fairly smoothly compared to my stint on 14.04 LTS.\n\nA: To get rid of these and other hard-ware related troubles,test the latest, relatively stable liveCD - OP found out that the latest 16.04LTS (close to release candidate, kernel freeze today) not only fixes the graphics issue, but also other issues (touchpad).\nAfter the test is successful, the usual way for existing systems is update-manager -d to get the most recent version of Ubuntu or a reinstall if you were testing Ubuntu support on a new hardware system.\nDo this only if you see a hardware issue. Also, it should be a system with a single user, and not mission-critical. Laptops are prime candidates for this, since they usually have the most pesky hardware issues and the troublemakers inside are not exchangeable. \nDownside of running the latest distribution is that in case of other issues, it's difficult to find existing solutions on the net. But you can always come to askubuntu.com for that.\n", "Q: Mic Audio Peaks At Low Volume Logitech G430 So I initially bought the G430 headset for recording purposes around last October. I noticed that the audio from the mic would peak at very low volume making it difficult to record commentary without the audio quality taking a dive.\nIn Audacity, the volume goes to about 0.5 when it should be going to near 1.0. Here's a link to a video I recorded to show exactly what I mean: https://www.youtube.com/watch?v=PfFGshPcNsQ \nI get the mic a little closer then I normally do but you can see the audio peaks quite low. Even when I move the mic as far from my mouth as possible, you can still hear peaking, especially when I slightly raise my voice. If anyone can help me with this I would be very appreciative.\n\nA: I started testing the headset on a windows to see if it was an ubuntu problem. After a bit of testing, it appears it's an issue with the USB adapter being faulty. I thought I tested it after I replaced my Motherboard but it appears that I didn't. Either way thanks for the help.\n", "Q: Trying to install Windows 10 on SSD and Ubuntu 14.04 on HDD, boot from SSD I've tried a few times and have always been unsuccessful. I followed the instructions from quite a few tutorials, and I have been able to get Linux and Windows installed but Grub doesn't detect Windows and just boots into Ubuntu.\nThe partitions I want to get running are:  \nSSD 1: Windows (127GB)\nSSD 2: EFI Boot (500MB)\nHDD 1: Ubuntu Root (56 GB)\nHDD 2: Ubuntu Swap (8 GB)\nHDD 3: Storage (~ 950 GB)\n\nA: Try boot-repair. It's a utility tool that will allow you to configure grub and (I'm not sure but I think it also allows you to) select partitions on different hard disks with OS to be added to the grub menu.\nGoogle grub repair. I'm pretty sure it'll be helpful.\nChoose the standard configuration and it will detect os's .  This is the easiest way, but you will get extra entries on your grub menu.\n\nA: You Should update your Grub loader to see Windows 10 in your Grub Loader Entry.\nInitially, boot to Ubuntu by normally or Live USB or DVD. Connect your HDD which contains Windows 10.\nOpen Terminal and Run the command\nsudo update-grub\n\nNow you can see the list of bootable partitions. like Windows 10(loader). Your Grub is updated restart your computer and now you can see list OSs you can boot into!\n\nA: It looks like Windows was installed with EFI on GPT partition table, but Ubuntu was installed with legacy MBR partition table and GRUB will not play well in this setup. Reinstall Ubuntu making sure that you boot the USB drive or DVD in UEFI mode and Ubuntu will install with an EFI partition. Then GRUB should automatically detect Windows and give you an option at boot. \n", "Q: remove Ubuntu from dual-boot system I had Ubuntu 15.10 and Windows 10 on the same drive. I wanted to remove Ubuntu so I did following steps:\n\n\n*\n\n*go to disk manager and remove two Ubuntu partitions and add free space to windows partition.\n\n*run Windows USB installer with command line ant type: bootrec.exe /fixmbr\nThe thing is that Ubuntu boot options were not removed from my BIOS. I had to manually switch it to Windows boot because the computer was starting with a GRUB command line.\nIs there a way to safely remove these bot options?\n\nA: With the new EFI system the windows and Linux bootmanager are separated. To use the windows boot manager as the default one instead of grub, just select it as the default EFI boot manager in the BIOS settings and you'll automatically boot into Windows by default\n\nA: The easiest way to remove ubuntu safely from dual boot is to use EaseUS partition master before deleting Ubuntu partitions.\n\n\n*\n\n*Download and install EaseUs partition master on Windows.\n\n*Select the hard disk and right click and choose rebuild MBR\n\n*Choose your OS and click on apply button at the top bar.\n\n\nNow you can delete or format Ubuntu partitions.\n", "Q: Since OTA10 upgrade the battery life of my phone is eaten up by \"fitbitaccount\" I can't disable this process which consumes battery life:\n/usr/bin/online-accounts-ui --socket /run/user/32011/online-accounts-ui/ui-1-com.canonical.scopes.fitbit_fitbitaccount --profile com.canonical.scopes.fitbit_fitbitaccount_1.0.41\n\nWhat can I do ?\n\nA: To quickly stop the mess, I manually removed files about fitbit configuration in phablet accounts:\nrm ~/.local/share/accounts/applications/com.canonical.scopes.fitbit_fitbit.application\nrm ~/.local/share/accounts/providers/com.canonical.scopes.fitbit_fitbitaccount.provider\nrm ~/.local/share/accounts/qml-plugins/com.canonical.scopes.fitbit_fitbitaccount\nrm ~/.local/share/accounts/services/com.canonical.scopes.fitbit_fitbit.service\n\nand finally killing the offending process \"/usr/bin/online-accounts-ui\" using command kill PID or restarting the phone.\n", "Q: Automation of installing programs from source I occasionally face a problem when using programs for which developers don't publish deb packages and only provide source. Sometimes I find a PPA providing the package but sometimes I don't or sometimes I don't trust the third party's version of the package because the program is rather sensitive from the security point of view (e.g. a password manager).\nI can install from the source but this is ok to do once, not to do it on regular basis so as to install program's updates. Therefore, I'm thinking...\nIs there a tool which would automate installation from the sources?\n\n\n*\n\n*Check for updated source. (e.g. in a Git repo)\n\n*Download the code.\n\n*Compile it in the background.\n\n*Offer installation the similar way the Ubuntu's update manager would?\nI guess I could probably put the process together using Jenkins and some custom coding but it's possibly quite a bit of work and I don't want to re-invent the wheel.\nPS: Answers like the one for Atom editor lack some expected features when having to deal with the installation of multiple programs this way:\n\n\n*\n\n*management of the configuration for each of them\n\n*download from different sources (tar archive, Git repo, etc.)\n\n*checking the source on daily basis and tracking whether there is a need to proceed with the update\n\n*resolving dependencies\n\n*check that the compilation succeeded\n\n*offer to install the package instead of installing it automatically \n\n\nIn other words, I'm looking for something that would put user-friendliness into the process.\n\nA: Linuxbrew\n\nLinuxbrew is a fork of Homebrew, the macOS package manager, for\n  Linux.\n\nIt is exactly what you are looking for.\nYou may check Homebrew page to understand What Does Homebrew/Linuxbrew Do?\n", "Q: Can't login to Ubuntu 14.04 (once again) I apologize in advance for my naive question but I'm new to Linux and eager to learn. I am experiencing the same problem already commented by others, and it is the impossibility to log-in Ubuntu 14.04 after upgrade. After entering the password, I am redirected to the log-in page again.\nI followed the instructions appeared in this thread but was unable to solve the issue: Can't login to Ubuntu 14.04 after upgrade\nIt seems that I need to edit the system file /etc/fstab but once having accessed to the terminal from the log-in page and cd to the proper directory, I don't know how to edit this file. \nYour valuable feedback is highly appreciated, thanks. \n\nA: I am pretty new myself but lets see if I can help you. Editing fstab could stop your filesystem working so be very careful and back it up first.\nOpen a terminal\nNavigate to the /etc directory\ncd /etc\nCheck you are in the correct directory and fstab is there\nls\nBack it up\nsudo cp fstab fstab_old\nCheck fstab_old was created\nls\nOpen fstab in a text editor\nsudo gedit fstab\nMake the changes you require in the editor then click the save icon\n", "Q: Can't install Ubuntu because of 'error fsyncing/closing/dev/mmcblk0rpmb: input/output' I am trying to install Ubuntu on my PC. During the installation process a dialogue box appears with the following message:\nerror fsyncing/closing/dev/mmcblk0rpmb: input/output error\n\nSelecting retry brings the same notification, while ignore continues to the installation. Once the installation is complete, and following with the restart prompt, I am brought back to the boot screen, where I can (once again) choose try, install or OEM install. However it is clear that the system is booted using the USB, but not the internal drive.\nI am using an  ASUS Eeebook X205TA, with an SSD.\nIf I turn the computer off and remove the USB, no boot takes place.\n\nA: I had the same problem. I have a feeling that it is probably a corrupt .iso file. I was having problems with the mate 64 bit Mint 17.3. I then downloaded xubuntu and using the same USB was able to have my laptop ASUS E402MA up and running without any problems. Hope this helps.\n\nA: I replaced older cables and defective HDs, it worked my Debian 10 installation.\nSee the question 655659\n", "Q: iptables-persistent / netfilter-persistent has (dependancy?) problem on 15.1 I'm trying to install 15.1 x64 on a new VPS. The first thing I do is ssh in and define a few iptables rules to drop non-ssh traffic, and now want to make those rules persistent. So:\nroot@server:~# apt-get install iptables-persistent\n\nThis fails. This post seems to indicate that the package got renamed and update-rc.d stopped accepting stop/start commands. As a result, apt-get can't install it. Does anyone know what the official (unofficial?) way of resolving this is? How do you set persistent iptables rules in 15.1?\n\nA: Apparently this seems to be a manifestation of Debian bug 124518, which can be fixed by determining which module is causing the problem at startup (journalctl -xn), then removing it from /etc/modules as per this post.\nAfter doing those steps, I was able to reboot, install iptables-persistent, and write persistent rules to /etc/iptables that were then loaded after a second reboot.\n", "Q: after OTA10 mx4 update can't adb to device, device unauthorised Noticed today several days after OTA10, tried to adb to device, got:\nanton@kitten:~$ adb devices\nList of devices attached\n75HABLLE85KB    unauthorized\n\nanton@kitten:~$ adb shell\nerror: device unauthorized. Please check the confirmation dialog on your device.\n\nrunning 15.10, adb version 1.0.32\nI was never presented with a dialog on an Ubuntu device to confirm the connection. Any ideas?\n\nA: sudo adb shell\n\nforgot to be a master.\n", "Q: How to install JDK sources? How can I download the source code of Java on my local machine, so I can reference it in an IDE?\n\nA: In case of java 11 (on Ubuntu 18.04) I did:\nFirst I install jdk 11:\nsudo apt install openjdk-11-jdk\nI install the sources like this:\nsudo apt-get install openjdk-11-source\nAnd I found them in /usr/lib/jvm/openjdk-11/lib/src.zip\nI use Eclipse so I go inside Eclipse's menu Window -> Preferences -> Installed JREs \nand inside select\njava-11-openjdk-amd64 -> edit -> select the jar (jrt-fs.jar) -> Source Attachment -> External location -> /usr/lib/jvm/openjdk-11/lib/src.zip\nNow I happily read the java documentation! :)\nBest of luck to all!\n\nA: Example for Java 8: \nsudo apt-get install openjdk-8-source\n\napt-get puts it under the relevant JDK location as src.zip: /usr/lib/jvm/java-8-openjdk-amd64/src.zip\nIntellij IDEA recognized it automatically and started showing me the source code.\n\nA: In case of java 13 simply run sudo apt-get install openjdk-13-source\n", "Q: Does Ubuntu support old Windows games? I wanted a alternative for the Windows XP, its crashing a lot in Vmware Workstation\n\nA: You should try Wine for that - https://www.winehq.org/. It is a compatibility layer used for running Windows applications on Linux, though not all of them. To find out whether your desired program works in Wine, visit https://appdb.winehq.org/ and do a search.\n\nA: *\n\n*press ctrl + alt + t\n\n*type sudo apt-get install steam\n\n*wait and open steam\n\n*make an account , its free\n\n*play\n\n*wine does the emulation , but it is slow...\n\n\nsteam give you acess to a large library of free games also , some of which include dota and some I don't download , also not to forget , you get free Softwares (for game development purposes) too....\n", "Q: First Bash Script Problem I'm completely new to Bash, and I'm trying to make a simple script to automate Git pulling and pushing from a repo, but I can't get it to work.\nHere is a pastebin of the code: http://pastebin.com/JrXqktD4\n#!/bin/bash\n#Git Puller / Pusher for MobArenaBattles\n\necho \"Please type whether you want to pull or push:\"\n\nread proc\ncd $HOME/Desktop/IdeaProjects/Plugins/MobArenaBattles\n\nif [\"$proc\"=\"push\"]; then\n  echo \"Please type the commit message:\"\n  read message\n  git status\n  git add -A\n  git commit -m $message\n  git push\nelif [\"$proc\"=\"pull\"]; then\n  git status\n  git pull\nelse\n  echo \"Invalid choice! Exiting.\"\nfi\n\nThe error I get is:\n./MAB Git.sh: line 9: [push=push]: command not found\n./MAB Git.sh: line 16: [push=pull]: command not found\n\nI have tried using == and -eq but it comes up with the same error. Sorry if I'm being stupid, it's my first attempt.\nThanks in advance.\n\nA: You need spaces:\nif [ \"$s1\" == \"$s2\" ]\n\n", "Q: Can not install xserver-xorg-video-nouveau xorg-video-abi-15 because of the error of unmet dependencies When trying to run sudo apt-get install xserver-xorg-video-nouveau xorg-video-abi-15 I am having the following error, is there any solution for it.\nThe following packages have unmet dependencies:\n unity-control-center : Depends: libcheese-gtk23 (>= 3.4.0) but it is not going to be installed\n                        Depends: libcheese7 (>= 3.0.1) but it is not going to be installed\nE: Error, pkgProblemResolver::Resolve generated breaks, this may be caused by held packages.\n\nthe output of sudo apt-get install libcheese-gtk23 libcheese7 \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nlibcheese-gtk23 is already the newest version.\nlibcheese-gtk23 set to manually installed.\nlibcheese7 is already the newest version.\nlibcheese7 set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n\nand apt-cache policy xserver-xorg-video-nouveau xorg-video-abi-15 libcheese-gtk23 libcheese7\nxserver-xorg-video-nouveau:\n  Installed: (none)\n  Candidate: 1:1.0.10-1ubuntu2\n  Version table:\n     1:1.0.10-1ubuntu2 0\n        500 http://mirror.23media.de/ubuntu/ trusty/main amd64 Packages\nxorg-video-abi-15:\n  Installed: (none)\n  Candidate: (none)\n  Version table:\nlibcheese-gtk23:\n  Installed: 3.10.2-0ubuntu2\n  Candidate: 3.10.2-0ubuntu2\n  Version table:\n *** 3.10.2-0ubuntu2 0\n        500 http://mirror.23media.de/ubuntu/ trusty/main amd64 Packages\n        100 /var/lib/dpkg/status\nlibcheese7:\n  Installed: 3.10.2-0ubuntu2\n  Candidate: 3.10.2-0ubuntu2\n  Version table:\n *** 3.10.2-0ubuntu2 0\n        500 http://mirror.23media.de/ubuntu/ trusty/main amd64 Packages\n        100 /var/lib/dpkg/status\n\n\nA: Warning ! DO NOT DELETE AND REINSALL libcheese-gtk23 or libcheese7,\nIf you do: it will work, but after reboot: X11 failed and you are good for reinstall ubuntu !\nTry to install that (if it fail, don't force the installation)\nsudo apt-get update -y\nsudo apt-get upgrade -y\nsudo apt-get -f install -y\nsudo apt-get install libgl1-mesa-dev-lts-utopic libglu1-mesa-dev\n\nEDIT: may be this one\nsudo add-apt-repository ppa:xorg-edgers/ppa && sudo apt-get update\nsudo ppa-purge  ppa:xorg-edgers/ppa && sudo apt-get update\n\nSource: System settings stopped showing up\n", "Q: cant use apache2 in ubuntu 14.04 I need to install apache2 on my ubuntu system. On running the command:\n\nsudo apt-get install apache2\n\nI get this error: \nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n apache2 : PreDepends: dpkg (>= 1.17.14)\nE: Unable to correct problems, you have held broken packages.\n\nI checked out other similar questions and tried to do this: \n\nsudo apt-get install -f \n  sudo dpkg --purge --force-depends \"apache*\"\n  sudo apt-get install apache2\n\nBut the second command says:\nsudo dpkg --purge --force-depends \"apache*\"\ndpkg: error: --purge needs a valid package name but 'apache*' is not: illegal package name in specifier 'apache*': character `*' not allowed (only letters, digits and characters `-+._')\n\nI surfed more and some people say this might be due to php7 installed. I don't understand why that would be so and can't resolve this error. Please help\nEDIT: Output of  lsb_release -a; uname -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 14.04.4 LTS\nRelease:    14.04\nCodename:   trusty\nLinux myprecious 3.13.0-24-generic #47-Ubuntu SMP Fri May 2 23:30:00 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n\nI have that candidate and one more latest one:\n2.4.12-2 0 500 ppa.launchpad.net/cybersec/chaos-ppa-v2/ubuntu trusty/main amd64 Packages\n\n\nA: The package apache2 in your enabled third-party repository needs the package dpkg in version 1.17.14 or higher. This version is not available for Trusty. For this reason, install the official apache2 package for Trusty, currently version 2.4.7-1ubuntu4.9.\nAnd as you can see in the output of apt-cache policy\n2.4.12-2 0 500 ppa.launchpad.net/cybersec/chaos-ppa-v2/ubuntu trusty/main amd64 Packages\n\nyour third-party PPA is https://launchpad.net/~cybersec/+archive/ubuntu/chaos-ppa-v2\nPurge it with\nsudo ppa-purge ppa:cybersec/chaos-ppa-v2\n\nand install apache2\nsudo apt-get install apache2\n\n", "Q: How to perform differential backups with tar? I know I can perform progressive (incremental) backups with tar using snapshots, I am doing something like this for the directory I want to create a backup for:\ntar cpf progressive.tar --listed-incremental=snapshot /home/user/dir\n\nHowever, can I do differential backups with tar instead of progressive ones?\nI know the --diff is used for this task, but it's not clear to me how to do the whole thing.\n\nA: You cannot do automated differential backups with tar using the --diff operation mode. This is because the --diff operation mode will only look for differences between files already in the tar file and the files of the file system. If a file that resides in the tar file is missing in the file system tar will give you this message:\ntar: etc/test.txt: Warning: Cannot stat: No such file or directory\n\nIf the content of a file already in the tar file gets changed, tar will print:\netc/test.txt: Mod time differs\netc/test.txt: Size differs\n\nIf there is a new file in the file system tar will give you no information. The same is true for the --update operation mode. It only checks for files already in the archiv.\nI found some solutions for doing differential backups with tar using the --newer parameter relaying on date/time informations of the last full or differential backup. Other solutions stores metadata of the backups and doing differential backups using this metadata.\n", "Q: MaaS Hyper-v Power Type I have a Hyper-V 2012 R2 Host that has Ubuntu 14.04 running MaaS 1.9.1 as a Guest VM. This has works well until I need to commission a virtual node as it requires a Power Type to be used to turn on the VM. The virtual machine can't use Wake-On-LAN down to the fact it cant communicate via TCP so does anyone have any other ideas how I can configure the Power Type.\nI tried installing MaaS Hyper-V power adapter but it doesn't support MaaS 1.9 and just broke the MaaS web interface.\n\nA: In the end I installed Wake-On-LAN Virtual Machine on my Hyper-V server  which listens for Wake-On-LAN magic packets and starts up the appropriate VM according to the MAC address. This means my Power Type in MaaS is Wake-On-LAN and I was able to commission my VM.\n", "Q: How are processes described in Ubuntu? I need to know in detail how are processes described in Ubuntu? I have tried Google, but no luck. As I require it for research purposes, please help. Thank you.\n\nA: When you issue a command or execute a shell script in any Unix-like operating system, you start, or create, a process. In short, a process is an instance of a running program. Attributes of processes include a process-id (pid) and a parent process-id (ppid), and there are others. Processes are also associated with a terminal (tty) from which they were executed, unless they are daemons. \nI suggest you read more about processes and their attributes at the Unix School or at these university user-pages. (All of these pages and more were found with Google, so it is unclear why you were unable to find them.)\n\nA: In Unix , there are two things \n\n\n*\n\n*files\n\n*Process\n\n\n\"files has places and processes have life\" by Kaare Christian\nA running file that is executed as a program is termed as process (set of instructions). Processes have children, parents, and grandchildren (no, I am not joking :) ) \nTo see all the current processes, press Ctrl+Alt+T and enter ps.\nFor more details , read Sumitabha Das, Unix Applications (3rd edition), section 2.5.1, and/or go to Google Books and search there, but the above book really does explain what you want.\nIf you really want to go more deeper, read Modern OS by Tanenbaum or Operating System Concepts by Silberschatz (but before reading these books make sure you have basics of computer organization subject; or else read Computer System Architecture by Morris Mano).\n", "Q: Booting problem in Ubuntu 14.04 My Ubuntu 14.04 on Lenovo S510p very frequently boots to this screen and hangs:\n\nIt is isn't always, sometimes it boots up to the lock screen, like normal, sometimes it just hangs at the above screen. A friend of mine ran into the same error, and he said it was probably because of the NVIDIA CUDA Driver.\nAny solutions to this?\n\nA: I found the solution to my own problem, It definitely was the CUDA (NIVIDIA) driver. All I did was uninstall the drivers via terminal, and voila!! My booting is back to normal.\n", "Q: Is there a way to adjust the interval for the update-status hook? Is there a way to set the interval for update-status hook? As per my observations, it runs after every 5 minutes.\n\nA: Nope, sorry. For now, it's hard coded.\n\nA: juju model-config update-status-hook-interval=60s\n\nSee https://docs.jujucharms.com/2.4/en/models-config\n", "Q: Excecutable file command not found I have been trying to install a tool called MetaACE. I have included the command line below.\ndeebak@ubuntu:~$ cd Downloads/MetaACE_LTD\ndeebak@ubuntu:~/Downloads/MetaACE_LTD$ bash\ndeebak@ubuntu:~/Downloads/MetaACE_LTD$ echo $SHELL\n/bin/bash\ndeebak@ubuntu:~/Downloads/MetaACE_LTD$ ls\nbin  docs  Example  metaace.bash  metaace.bash~  runtime\ndeebak@ubuntu:~/Downloads/MetaACE_LTD$ source metaace.bash\ndeebak@ubuntu:~/Downloads/MetaACE_LTD$ cat metaace.bash\n#!/bin/bash\nMETAACE=/home/deebak/Downloads/MetaACE_LTD\nRUNTIME_PATH=$METAACE/runtime/v84\nPATH=/bin:$PATH\nexport PATH\nLD_LIBRARY_PATH=$LD_LIBRARY_PATH:${RUNTIME_PATH}/runtime/glnxa64:${METAACE}/bin:${RUNTIME_PATH}/bin/glnxa64:${RUNTIME_PATH}/sys/os/glnxa64:${RUNTIME_PATH}/sys/java/jre/glnxa64/jre/lib/amd64/server\nexport LD_LIBRARY_PATH\n\nXAPPLRESDIR=/home/mathewsn/MetaACE_LTD/runtime/v84/X11/app-defaults\nexport XAPPLRESDIR\n\ndeebak@ubuntu:~/Downloads/MetaACE_LTD$ cd bin\ndeebak@ubuntu:~/Downloads/MetaACE_LTD/bin$ ls -l\ntotal 916\n-rw-r--r-- 1 deebak deebak     51 Sep 26  2014 cpmetafiles\n-rwxr-xr-x 1 deebak deebak      0 Mar  1 15:48 metaace\n-rw-r--r-- 1 deebak deebak 338498 Apr 27  2015 metaace.bak\n-rw-r--r-- 1 deebak deebak    206 Apr  7 14:58 MetaACE.log\n-rw-r--r-- 1 deebak deebak   1271 Mar 31 10:32 MetaACElog.txt\n-rw-r--r-- 1 deebak deebak 338498 Apr 27  2015 MetaACE_LTD\n-rw-r--r-- 1 deebak deebak 239484 Jan  9  2015 MetaACE_LTDo\n-rw-r--r-- 1 deebak deebak    282 Mar 31 10:32 runData.mat\n\ndeebak@ubuntu:~/Downloads/MetaACE_LTD/bin$ metaace\n/usr/bin/python: /home/deebak/Downloads/MetaACE_LTD/runtime/v84/bin/glnxa64/libcrypto.so.1.0.0: no version information available (required by /usr/bin/python)\n/usr/bin/python: /home/deebak/Downloads/MetaACE_LTD/runtime/v84/bin/glnxa64/libssl.so.1.0.0: no version information available (required by /usr/bin/python)\n**metaace: command not found**\ndeebak@ubuntu:~/Downloads/MetaACE_LTD/bin$ \n\nHow do i execute this bin file? \nOr is there any other question to which i can link this problem to?\nThanks in advance :)\n\nA: You have probably have the executable in a folder which is not searched for executables. I do not know MetaACE and how it works.\nVerify:\nenv | grep PATH\nEither:\n1) add folder for executable to PATH.\nPATH=~/Downloads/MetaACE_LTD/bin:$PATH\n(metaace.bash assume executable is placed in /bin)\n2) add active folder to PATH (This is dangerous in case one should get executables in download folders, copy files, etc. Normally not done in PRODuction environment.)\nYou then need to have ~/Downloads/MetaACE_LTD/bin as active folder in order to start executable, like you example.\n3) start binary by using complete path and file:\n~/Downloads/MetaACE_LTD/bin/metaace\nOne might in general run into additiopnal problem with other executables, but MetaACE seems to only have one.\n4) install/move/copy MetaACE in other folders.\n5) make softlink for execuble in a folder used by PATH to where you have it.\n", "Q: Recovering user data after misinformed username change I wished to change my username. To acheive this, I made the unfortunate choice to simply edit \"/etc/passwd\", replacing the respective username.\nNow I cannot log in anymore as that user. I assume this happens because I didn't also replace the name inside \"/etc/shadow\"?\nThe real question is: is there any way to recover the user account/user data?\n\nA: When you boot your computer, press shift when the BIOS is done.\nYou should end up in the grub boot menu, if now try again. There you choose advanced options for UBUNTU, and then your your actual kernel in recovery mode.\nYou should end up in a menu where you can choose to be root and end up in a shell as such. Now remount your drive into read/write access.\nmount -rw -o remount /\nfrom there reverse your changes you made and reboot by\nreboot\nRead more here ...\n", "Q: How do I play Counter Strike? Currently I have Ubuntu MATE 14.04 installed on my system. I have a Windows setup file of Counter Strike 1.6. I have installed WINE from Ubuntu Software Centre. Counter Strike 1.6 has been successfully installed on my system through WINE but when I am about to run it, it does not run, though it has been installed. Can anyone help me in fixing it?\n\nA: In /home/[username]/.wine/drive_c (assuming you installed it on C:) you should be able to follow the path where you installed your application and then run it manually.\nAnother thing you can try is to use the native steam client and install the native version of Counter Strike. This is the way I play my Steam/Valve games.\n\nA: *\n\n*Open a terminal by pressing Ctrl+Alt+T\n\n*Install Steam by typing sudo apt-get install steam\n\n*When it's done, open Steam\n\n*Make an account (it's free)\n\n*Search for Counter Strike 1.6 and buy it, if you haven't already \n\n*Play\n\n\nWine is slow because of the way it has to work.\nSteam also gives you access to a large library of free games, include Dota. Also you get free software (for game development purposes) too...\n", "Q: how do I access linux machines by name on the network? I run a home office and I have a number of linux boxes and mac machines. I'd like for people to be able to ssh into the various machines without having to remember each machines ip, by using the machine name. I realize that I could have everyone edit their hosts file, but I am looking for a better alternative than that. What tool, if any, exists for managing machine names and ips? Should I run my own internal DNS server? \nAny help is appreciated! :)\n\nA: Pick one of the systems, set up dnsmasq (see man dnsmasq), Edit /etc/hosts on that system, restart dnsmasq, tell the others to resolve DNS through the picked system.\n\nA: Yes, it makes the most sense to use an internal DNS server.  It's a pretty common network service, and for what you're trying to accomplish, it's the perfect use.\nHere's a tutorial from Digital Ocean for Ubuntu 14.04, it should work for the majority of ubuntu versions.\nHow To Configure BIND as a Private Network DNS Server on Ubuntu 14.04\n", "Q: How to encrypt a (USB) Thumb / Flash Drive in Ubuntu 14.4 This question has been asked before but it has not been properly answered.  I am not able to comment on that site and so ask the question again.  When I try: \"sudo apt-get install gnome-disk-utility\" it is not installed - probably because it (Disk Utility) is no longer available - it seems to have been \"upgraded\" to \"Disks\" - which does not offer encryption.\nA solution would be greatly appreciated.  Thank you.\n\nA: There are several options, encrypt just some files with eCryptfs or EncFS, or a whole partition or drive with dm-crypt/LUKS (very similar to TrueCrypt, in fact cryptsetup can open (most?) TrueCrypt devices).\nSee archlinux's informative wiki about disk encryption.\n\nLUKS encrypts entire partitions/drives, and should be installed by default on recent Ubuntu's.\nIf your USB drive is for example partitioned as /dev/sdn1, to encrypt it you would run :\nsudo cryptsetup luksFormat /dev/sdn1\n\nthen decrypt it:\nsudo cryptsetup luksOpen /dev/sdn1 crypt1\n\nformat it with (for example ext):\n    sudo mke2fs /dev/mapper/crypt1\nthen just mount & use it. When done unmount & sudo cryptsetup luksClose crypt1\n\nA: There's a package in Ubuntu called ecryptfs which will give you a nice portable encryption option for your USB stick.\nThe following is a snippet from the ubuntu server guide ecryptfs tutorial\nUsing eCryptfs\nFirst, install the necessary packages. From a terminal prompt enter:\nsudo apt-get install ecryptfs-utils\n\nNow mount the partition to be encrypted:\nsudo mount -t ecryptfs /srv /srv\n\nYou will then be prompted for some details on how ecryptfs should encrypt the data.\nTo test that files placed in /srv are indeed encrypted copy the /etc/default folder to /srv:\nsudo cp -r /etc/default /srv\n\nNow unmount /srv, and try to view a file:\nsudo umount /srv\ncat /srv/default/cron\n\nRemounting /srv using ecryptfs will make the data viewable once again.\n", "Q: Legacy Webcam + Ubuntu 14.04 Recently I migrated my desktop computer from Windows 7 to Ubuntu. I can't make it recognize WebCam (Creative PD1001).\nThere's no stock driver, I but found this sourceforge project which supports my device.\nI thought it was going to be a quick fix, but nope.\n\n\n*\n\n*Ungzipped the archives\n\n*Followed the instructions\n\n\nAnd now I'm receiving lots of errors from gcc (i guess)\nHere's a screenshot, after some seconds of waiting... this is the output of make:\n\n\"virhe\" in Finnish means \"error\"\n\nA: I now found out after around 2 hours of trying and searching through the depths of www, that the support for v4l1 was dropped in recent kernels. And despite my effords to rewrite the code to use v4l2 header files it won't compile. \nSo best get a newer webcam to use.\n", "Q: Questions for Dual Booting Ubuntu 14.04 + Win10 with Multiple Hard Drives I'm trying to dual boot Ubuntu 14.04 onto my desktop that's currently running Win10. I've only dual booted on machines with a singular HDD years ago, but now I have a small SSD (for my Win10 OS and key programs) and a 1TB HDD (for all my data). The desktop also has 16GB of RAM.\nSo few questions on doing this:\n\n\n*\n\n*I've partitioned the last ~100GB on my HDD for Ubuntu. I'm going to use a shared partition for documents and such, so how much space should I give to root, home, and swap (and any other extra partitions)?\n\n*Where should I put the bootloader? Should that go on /dev/sda (SSD) or /dev/sdb (HDD)?\n\n*What happens if I ever want to clear Ubuntu from the drive or move it to a possible third hard drive?\n\nA: *\n\n*I would say root~30GB, swap>16GB if you plan to hibernate, or 0 if you do not plan to, and the rest to /home. \n\n*If Windows is with UEFI and you install Ubuntu correctly with UEFI, it will be placed in the EFI directory.\n\n*You just do it (from live system) and set up accordingly the partitions in /etc/fstab and the bootloader (you might need to use boot-repair here if you have EFI)\n", "Q: Zenity and bash I have a broblem with bash script.\nI want to go back to menu but have an error from terminal \"unexpected end of file\"\n#!/bin/bash \nusers=$(awk -F'[/:]' '{if ($3 >= 1000 && $3 != 65534) print $1}' /etc/passwd)\nmenu(){\nans=$(zenity  --list  --text \"Izvēlies funkciju\" --radiolist  --column \"Pick\" --column \"\" TRUE \"Lietotāju saraksts\" False \"Pievienot jaunu lietotāju\" FALSE \"Dzēst lietotāju\" FALSE \"Aktivizēt lietotāju\" FALSE \"Deaktivizēt lietotāju\");\n}\nmenu\n\nif [ \"$ans\" = \"Lietotāju saraksts\" ]; then\n\n zenity --info --text=$users else\n\n    if [ $? == '0' ]; then\nmenu\n\nfi\n\n\nA: The following line\nzenity --info --text=$users else\n\nsends else as a parameter to zenity. You need a semicolon or newline before else.\nYou'll need another fi to close the outer if, too.\n", "Q: Restore with deja-dup I recently had a hard drive failure on my PC (ubuntu 12.04), I purchased a new Hard Drive & installed 14.04.\nAfter installing the new Hard Drive my old one 'came back to life' so I continued using the old one (booting from it, filesystem etc). This wasn't the best move I'm aware, but the old Hard Drive contained all my progs file etc & I just didn't have time to swap everything over.\nI did however backup everything on the old HD to the new HD using deja-dup, so my question is this, how do I go about restoring my data, also bearing in mind that I'm now using a different version of Ubuntu?\n\nA: To restore everything using Deja-Dup on 14.04\n\n\n*\n\n*Start Deja-Dup\n\n*Click Overview in the left column. Move to the right and click the\nRestore... button\n\n*Browse to the location where you stored the backup. Click Forward.\n\n*After the \"checking for backups\" process finishes, choose the backup\nyou want from the drop-down box. Click Forward.\n\n*Choose to restore to original locations or a folder of your choice. Click Forward.\n\n*Click that everything is as desired on the Summary screen, then\nclick Restore to begin the process.\n\n", "Q: Trouble with Shell Script cat | grep #!/bin/bash\nmylanip=$(hostname -I | awk '{print $1}')\ntouch /opt/portmapper/0prelims\necho `java -jar /opt/portmapper/portmapper.jar -list | grep $mylanip > /opt/portmapper/0prelims`\n# HTTPS\nportprelim=$(cat /opt/portmapper/0prelims | grep ${mylanip}:443 | awk '{print $4}')\nif [ \"$portprelim\" = $mylanip:443 ]; then\n    echo \"Nothing Altered for HTTPS\"\nfi\nif [ \"$portprelim\" != $mylanip:443 ]; then\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -delete -protocol TCP -internalPort 443 -externalPort 443  >/dev/null ; sleep 2 ;\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -add -protocol TCP -internalPort 443 -externalPort 443 -ip $mylanip -description HTTPS >/dev/null ; sleep 2 ;\n    echo \"Added port forwarding for HTTPS\"\nfi\n# Private TTY\nportprelim=$(cat /opt/portmapper/0prelims | grep ${mylanip}:57 | awk '{print $4}')\nif [ \"$portprelim\" = $mylanip:57 ]; then\n    echo \"Nothing Altered for Private TTY\"\nfi\nif [ \"$portprelim\" != $mylanip:57 ]; then\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -delete -protocol TCP -internalPort 57 -externalPort 57  >/dev/null ; sleep 2 ;\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -add -protocol TCP -internalPort 57 -externalPort 57 -ip $mylanip -description PrivateTTY  >/dev/null ; sleep 2 ;\n    echo \"Added port forwarding for Private TTY\"\nfi\n# HTTP\n portprelim=$(cat /opt/portmapper/0prelims | grep ${mylanip}:80 | awk '{print $4}')\n\nif [ \"$portprelim\" = $mylanip:80 ]; then\n    echo \"Nothing Altered for HTTP\"\nfi\nif [ \"$portprelim\" != $mylanip:80 ]; then\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -delete -protocol TCP -internalPort 80 -externalPort 80 >/dev/null ; sleep 2 ;\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -add -protocol TCP -internalPort 80 -externalPort 80 -ip $mylanip -description HTTP  >/dev/null ; sleep 2 ;\n    echo \"Added port forwarding for HTTP\"\nfi\nexit\n\nHow do I only get the 443 line and not the 4433 line? its entering both into the variable for checking. If I manually do the string it places the string below into the variable.\n10.0.0.30:443 10.0.0.30:4433 \nHere is my ending output repeatedly:\nAdded port forwarding for HTTPS\nNothing Altered for PrivateTTY\nNothing Altered for HTTP\n\nhere is an excerpt from my 0prelims\n12:45:43.322 [main] INFO  o.f.cling.transport.spi.StreamServer - Created server (for receiving TCP streams) on: /10.0.0.30:44725\n12:45:43.324 [main] INFO  o.f.cling.transport.spi.DatagramIO - Creating bound socket (for datagram input/output) on: /10.0.0.30\nTCP :7881 -> 10.0.0.30:7881 enabled Deluge 1.3.12 at 10.0.0.30:7881\nTCP :4433 -> 10.0.0.30:4433 enabled Deluge 1.3.12 at 10.0.0.30:4433\nUDP :7881 -> 10.0.0.30:7881 enabled Deluge 1.3.12 at 10.0.0.30:7881\nTCP :57 -> 10.0.0.30:57 enabled PrivateTTY\nTCP :443 -> 10.0.0.30:443 enabled HTTPS\nTCP :80 -> 10.0.0.30:80 enabled HTTP\n\n\nA: Output of your script on ShellCheck. Correct the problems:\nLine 4:\necho `java -jar /opt/portmapper/portmapper.jar -list | grep $mylanip > /opt/portmapper/0prelims`\n     ^-- SC2046: Quote this to prevent word splitting.\n     ^-- SC2005: Useless echo? Instead of 'echo $(cmd)', just use 'cmd'.\n     ^-- SC2006: Use $(..) instead of legacy `..`.\n                                                            ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 6:\nportprelim=$(cat /opt/portmapper/0prelims | grep ${mylanip}:443 | awk '{print $4}')\n                 ^-- SC2002: Useless cat. Consider 'cmd < file | ..' or 'cmd file | ..' instead.\n                                                 ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 7:\nif [ \"$portprelim\" = $mylanip:443 ]; then\n                     ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 10:\nif [ \"$portprelim\" != $mylanip:443 ]; then\n                      ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 12:\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -add -protocol TCP -internalPort 443 -externalPort 443 -ip $mylanip -description HTTPS >/dev/null ; sleep 2 ;\n                                                                                                                                                                ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 16:\nportprelim=$(cat /opt/portmapper/0prelims | grep ${mylanip}:57 | awk '{print $4}')\n                 ^-- SC2002: Useless cat. Consider 'cmd < file | ..' or 'cmd file | ..' instead.\n                                                 ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 17:\nif [ \"$portprelim\" = $mylanip:57 ]; then\n                     ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 20:\nif [ \"$portprelim\" != $mylanip:57 ]; then\n                      ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 22:\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -add -protocol TCP -internalPort 57 -externalPort 57 -ip $mylanip -description PrivateTTY  >/dev/null ; sleep 2 ;\n                                                                                                                                                              ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 26:\n portprelim=$(cat /opt/portmapper/0prelims | grep ${mylanip}:80 | awk '{print $4}')\n                  ^-- SC2002: Useless cat. Consider 'cmd < file | ..' or 'cmd file | ..' instead.\n                                                  ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 28:\nif [ \"$portprelim\" = $mylanip:80 ]; then\n                     ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 31:\nif [ \"$portprelim\" != $mylanip:80 ]; then\n                      ^-- SC2086: Double quote to prevent globbing and word splitting.\n\nLine 33:\n    java -jar /opt/portmapper/portmapper.jar -lib org.chris.portmapper.router.sbbi.SBBIRouterFactory -add -protocol TCP -internalPort 80 -externalPort 80 -ip $mylanip -description HTTP  >/dev/null ; sleep 2 ;\n                                                                                                                                                              ^-- SC2086: Double quote to prevent globbing and word splitting.\n\n\nA: Instead of\ngrep ${mylanip}:443\n\ndo\ngrep \"${mylanip}:443 \"\n\nso the whitespace after 443 get part if the search expression.\n", "Q: Does Ubuntu already support Intel Speed Shift? Does Ubuntu already support Intel Speed Shift? If not, when will it support Intel Speed Shift? I'm looking forward to use it with my new Skylake Mobile CPU.\n\nA: Internal to the kernel the marketing name \"Speed Shift\" is known as HWP, Hardware P-States. HWP functionality will be in the very soon to be released Ubuntu 16.04. I do not know that status of any backports of recent HWP related changes to Ubuntu 15.10.\n", "Q: Need of drivers during installing ubuntu Do I need to install drivers after installing Ubuntu? Like we need to install drivers when we install Windows OS.\n\nA: Generally Ubuntu comes with all (open source) drivers already installed.\nThe drivers are getting installed during the Ubuntu system installation.\nWhen you want to install proprietary drivers alternatively, you can do it.\nIt is recommended mainly for NVIDIA graphics and some wireless cards.\nYou can select them from Additional Drivers tab in Software & Updates.  \n\n", "Q: How does the new \"Bash on Windows 10\" really work? I read online that Ubuntu and Bash are coming to Windows 10. I also read that it's not an emulator or virtual machine running on top of Windows, but something else. So how exactly does it all come together? And is it really going to be as stable and user friendly as Bash in Ubuntu?\n\nA: A quite old question that I came across today when someone asked if there was a general \"What is WSL\" question here somewhere.  This is probably the closest (and first) of that nature here.\nBut I do believe it needs an updated answer here in 2021 to be relevant.\nSo some history to bring us up to date:\n\n*\n\n*When this question was asked, and the feature originally announced, it was known as \"Bash on Ubuntu on Windows and the underlying Windows Subsystem for Linux.\"  Canonical and Microsoft worked closely together to develop the feature.\n@Jo-ErlendSchinstad's excellent answer above makes the great point that the original WSL (now called \"WSL1\") worked by \"translating\" Linux kernel/API calls into (closely) corresponding Windows API/kernel calls.\nAnd @RichTurner of the WSL team (who has my deepest appreciation for his and their work) provides some links with more information at the time.  The real piece of interest that he points out, IMHO, is the ability of WSL to allow executing Windows binaries (commonly .exe's) directly within the Linux shell, with incredible support for console output, redirection, etc.  You can run the Windows ipconfig.exe (or any command in powershell.exe, etc.), pipe it to Linux grep (or awk, etc.), and display the results. Unfortunately, I'm coming up with horribly over-simplified examples here that don't exhibit this features real usefulness.\nYou can even launch Windows graphical applications from the WSL/Linux shell.  More recently, Microsoft has used this feature to provide integrated Visual Studio Code launching from within WSL.  You can code . to open the current (Linux) directory in (Windows) VSCode.  Or code ~/.bashrc to edit your startup config.  And oh so much more.\nAnd by default WSL automatically mounts any Windows drives under /mnt/c /mnt/d, etc.  So you have the ability to work with \"Windows\" files from Linux.  (But not, until later, the other way around.)\nAt the time, bash.exe and ubuntu.exe were the primary ways to start up WSL and get to the Bash shell.  At this point (well, for the last several years), those have been relegated to \"historical\" commands (according to the Microsoft doc) and the recommended method is the much more flexible wsl.exe command.\n\n\n*Another note for the history lesson -- A point of confusion (especially in questions posted here on Stack sites) is that Canonical has called this feature  \"Ubuntu terminal\" (even in doc still available today), and ... well ... some folks here get pretty upset when people call \"Ubuntu\" a \"terminal\".  Just don't blame users you see using this terminology.  It's, IMHO, Canonical's fault for the poor choice of words.\nPerhaps the \"terminal\" moniker was meant to inform the user that WSL was \"command-line only\".  There was no built-in X server, and thus no way out-of-the-box to run graphical Linux apps in WSL.  That said, it was possible to install a third-party X server in Windows.\nA related \"terminology dispute\" is that nowadays, Ubuntu is installed from the Microsoft Store as an \"App\".  So don't be surprised if you see some people call it the \"Ubuntu App\", even though you and I know it's an \"operating system/OS\". ;-)\n\n\n*Skipping forward in time, after the initial release, more distributions started to become available other than just Ubuntu.  And, of course, people realized that you weren't limited to Bash (I was a Zsh user at the time, now a Fish convert).  So the feature itself that this question originally asked about is now really known as \"Windows Subsystem for Linux\" (WSL) with the \"Ubuntu\" distribution installed in it.\nSo it's a bit of a misnomer nowadays to talk about Ubuntu Bash on Windows, but you still see it used since it was the original name.  Even the most popular WSL subreddit is still the historically-named r/bashonubuntuonwindows, even though it covers all of WSL in general (any distribution, any shell).\n\n\n*One additional jump forward for WSL in general was the exposure of the WSL filesystem in a pseudo-network share.  So, for instance, files for the \"Ubuntu\" distribution can be accessed in Windows via \\\\wsl$\\Ubuntu.  This is great, but it does sometimes confuse new users who might edit (a.k.a. \"corrupt\") their ~/.bashrc using Notepad in Windows, which creates Windows line-endings (CRLF) rather than Unix/Linux-standard LF-only.\n\n\n*I'm sure there were some developments in the intervening years that I'm glossing over here, but the next big milestone for WSL occurred as the team prepared and (in 2020) released \"WSL2\".  Here's a good comparison of the differences.\nThe biggest difference is that, unlike the original WSL (now WSL1), WSL2 does run virtualized with a real Linux kernel (source available here).  This opens up a lot of additional features, but one of the biggest is the ability to run containers (e.g. Docker) directly within WSL2.\nWhile the kernel is real, most of the hardware (e.g. network interfaces) is virtualized.  So while you can do things like create TAP/TUN network devices, you need to join these to the virtual NIC.  You wouldn't be able to, for instance, bridge two real NICs running under Windows from within WSL2 using brctl.\nThe speed increase of WSL2 is pretty substantial as well, although I've never personally done any direct comparisons between \"real Ubuntu\" on the same hardware as \"WSL2\".  Because WSL2 operates on an ext4 filesystem on a virtual HDD (ext4.vhdx), file operations on that filesystem are especially performant.\nThat said, using the /mnt/c type of mounts (using the 9P protocol) under WSL2 is drastically slower than WSL1.  So it's recommended to keep all files that you are going to edit within WSL2.  Either that, or keep a copy of a WSL1 installation around (which is very easy) to do Windows filesystem work.\n\n\n*At this time, the \"next big thing\" planned in Windows 11 is WSLg, which allows execution of Linux graphical apps.\nWindows 11's WSL is also currently planned to have:\n\n*\n\n*Easier support for WSL installation and upgrading (wsl --install)\n\n*The ability to mount additional physical and virtual drives in the instance\n\n*GPU support, so CUDA-type applications can run within WSL.\n\n\n\nAnd what's next after that?  I have no idea myself, but personally I'm hoping for some level of Systemd support.  WSL currently uses its own /init for setting up the interop between Windows and Linux, such as those network interfaces and mounts I mentioned earlier.  Unfortunately, quite a few Linux apps (and especially docs) assume Systemd support.  That said, it's entirely possible to work around the lack of Systemd if you understand what you are trying to do.  But it does throw a lot of new WSL users for a loop.\n\nA: The bash portions work very well in WSL. \nThe kernel portions aren't there. For example there is no /sys/class/backlight/intel_backlight/brightness you can access to set screen brightness. There are Powershell commands you can easily call to do that if you don't mind COBOL style very long field names. MS Powershell can be called directly from within bash. So you can say powerful Windows features are now built into bash. By the same token MS Powershell can call bash I believe. So if true Powershell gets access to functions like grep, awk, head, tail, etc.\nThe GUI for Ubuntu Desktop (gedit, nautilus, etc.) only works after installing VcXsrv or something similar.\nSharing files between Linux and Windows WSL is complicated to setup. When when moving files between the shared WSL+Linux NTFS folder I have had some file permission \"weirdness\" either due to my ignorance or software deficiencies.\nSpeed is a lot slower in WSL than it is in Ubuntu. You can actually see the screen paint character by character when you run cal or toilet: What are the differences between windows bash and cygwin?\nI think WSL is a good product and I enjoy tinkering with it when dual-booting into Windows-World. It'll never become a great product because of MS lack of funding and they really don't want to have a great Linux Free-Ware Distro anyway. If you had enough RAM you would probably be happier with a VM. With only 8 GB myself and RAM prices rising until mid-2019 or so, I'll happily stick with WSL and forgo the 32 GB RAM upgrade for now.\nI've visited a few MS forums and I must say Rich Turner and his WSL team members are some of the nicest professionals I've seen.\n\nA: It's not an emulator in the same way that WINE Is Not an Emulator. That is to say, they've added a Linux kernel interface to their Windows kernel. When an app tries to use the Linux kernel, it gets translated into a Windows native system call and any responses from the kernel is translated into a native Linux response. So the app thinks it's running on a Linux kernel and hence doesn't need to be modified.\nHowever, this is purely a Windows technology so if you want more details, you should get them from a Windows support group or something. Windows continues to be a proprietary OS, so I would expect a limited amount of details. \n\nAnd is it really going to be as stable and user friendly as bash in ubuntu?\n\nFrom an Ubuntu perspective, we're simply running on a primitive Linux kernel, comparable to running a modern desktop on a primitive X server. If you're only using the features supported by the fake kernel, then it'll be stable and user friendly. If you use unsupported features, it'll be unstable. \nIt will not be anywhere near a complete Ubuntu experience any time soon. \n\nA: For those curious as to how the Windows Subsystem for Linux (WSL) works and how it runs native Linux ELF-64 binaries, we've published a series of blog posts and accompanying videos explaining the WSL architecture, processes, syscalls, and filesystem support.\nScott Hanselman also did a great walkthrough video covering the installation process and how to configure Bash on Ubuntu on Windows:\nHTH\n", "Q: Can't use machine after log in After I log in to my computer the only thing I can do is to move the mouse around. No keys gets any response at all. I can't even open the terminal using ctrl + alt + t. I have a bootable Ubuntu disk Image with me. Any idea how I can fix it? \nThe most likely reason of this error is that Ive been trying to install virtualbox on my computer. When trying to update my computer from the terminal there was something wrong with a virtualbox.list file, which i configured and then rebooted my computer. Then this happened....\n\nA: The same thing happened to me after installing virtual box. Somehow virtual box installation process sometimes uninstalls unity - the default launcher on ubuntu . To fix it, press Ctrl + Alt + F1 to enter the tty command shell and enter your username and password to login. Then type:\nsudo apt-get install unity\n\nThen type\nsudo reboot\n\nto restart your commander. Probably everything should work fine when you restart.\n", "Q: How to upgrade java compiler - different problem After the most recent automatic software update, java 7 on 14.04 no longer works. The initial problem is the same as that described at \"How to upgrade Java compiler\".\nHere's the message we got:\nwarning: Blabla.class: major version 52 is newer than 51, the highest major version supported by this compiler.\n\nit is recommended that the compiler be upgraded.\n\nThe solution given there was suggested after the questioner gave the outputs of \"javac -version\" and \"java -version\" - these two were not the same.\nIn my case, the output of these queries appears to be the same. Here they are, in case I'm missing something:\njavac -version\njavac 1.7.0_95\njava -version\njava version \"1.7.0_95\"\nOpenJDK Runtime Environment (IcedTea 2.6.4) (7u95-2.6.4-0ubuntu0.14.04.2)\nOpenJDK 64-Bit Server VM (build 24.95-b01, mixed mode)\nexecuting\n\"sudo update-alternatives --config javac\"\nshowed three alternatives. I tried all three, and none worked. I then completely removed all java from the system (following the instructions at \"How to completely uninstall java\".) I then installed java 7 from the Oracle site. While the original error message still occurs and I can't run a compiled program, there is now only one alternative after \n\"sudo update-alternatives --config javac\"\nit says:\nThere is only one alternative in link group javac (providing /usr/bin/javac): /usr/lib/jvm/java-7-openjdk-amd64/bin/javac\nNothing to configure.\nFor completeness, here is what happens when I try to compile/run a program that was working just before the automatic update:\nlanzcc@ubuntu910:~/recruit$ javac ReadProgram.java \nwarning: ./Program.class: major version 52 is newer than 51, the highest major version supported by this compiler.\n  It is recommended that the compiler be upgraded.\n1 warning\nlanzcc@ubuntu910:~/recruit$ java ReadProgram \nException in thread \"main\" java.lang.UnsupportedClassVersionError: Program : Unsupported major.minor version 52.0\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:803)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:71)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:361)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:355)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:354)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:425)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n    at java.lang.Class.getDeclaredMethods0(Native Method)\n    at java.lang.Class.privateGetDeclaredMethods(Class.java:2625)\n    at java.lang.Class.getMethod0(Class.java:2866)\n    at java.lang.Class.getMethod(Class.java:1676)\n    at sun.launcher.LauncherHelper.getMainMethod(LauncherHelper.java:494)\n    at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:486)\nlanzcc@ubuntu910:~/recruit$ \nAny ideas?\nTHANKS!\n\nA: RESOLVED\nThere was, among the various class files, one that had not been compiled since the software upgrade. I knew all the others were being recompiled, but I just didn't notice this one. Thus it had a non-matching compiler tag. \nSorry.\n", "Q: Temporarily disable network managment of eth0 - How eth0 is managed by the network manager icon and connects using dhcp when it detects a network cable.\nHowever, very occasionally I want to connect to some special-purpose computers with static IP addresses using a direct ethernet connection (cross-over). Then I set\nsudo ifconfig eth0 10.90.90.91\n\nor\nsudo ifconfig eth0:1 10.90.90.91\n\nand can connect to the computer in question.\nHowever, after a minute or so, that eth0 looses that IP address and my connections hang until I repeat the ifconfig step.\nRight now I'm using a loop and repeat setting the IP address every 10 seconds.\nBut I wonder if I can tell the network manager (which I suspect is the culprit) somehow to, right now, not try to manage eth0 until I need it again to do it.\nEdit: The question How do I set an extra IP for an existing interface? differs from mine. That question wants to perpetuate the setting across reboots. I'm not interested in that. I only want to have that fixed IP address for eth0 very occasionally. Usually the dhcp procedure is ok for me. Only sometimes I want it to back off.\n\nA: Use ifdown (and ifup). See man ifdown. If you don't want use /etc/network/interfaces, after ifdown you can use ifconfig to configure by hand. From man ifdown:  \nDESCRIPTION\n       The   ifup   and   ifdown  commands  may  be  used  to  configure  (or,\n       respectively,  deconfigure)  network  interfaces  based  on   interface\n       definitions  in  the file /etc/network/interfaces.  ifquery command may\n       be used to parse interfaces configuration.\n\n\nA: If I understand correctly you want sometimes a different configuration for your network and you want to use Network Manager - I presume GUI.\nSo you open the network manager, add another connection (call it static address or so). Now configure this connection with the settings you want, don't set Automatically connect to this network..\n\n\nWhenever you need this special setting just select it from the Network Manager menu.\n", "Q: My Aquaris E4.5 doesn't connect via USB after OTA-10 Yesterday I downloaded the OTA-10 system upgrade on my Aquaris E4.5, and now when I connect it to my Ubuntu laptop using a USB cable, the laptop no longer automounts the phone and its SD card. :-( Any help from someone more knowledgeable would be warmly appreciated.\n\nA: Now I fixed the problem: you have to use gmtp on the laptop\n", "Q: Why do i get wrong filesystem error on mounting external drive whilst correct ntfs-utils is installed? since today I get the following message when inserting usbstick/sd card:\n\nAankoppelen bestandssysteem is mislukt  \n  Error mounting /dev/sdb1 at /media/wouter/Kali Live: Command-line\n  `mount -t \"iso9660\" -o\n  \"uhelper=udisks2,nodev,nosuid,uid=1001,gid=1001,iocharset=utf8,mode=0400,dmode=0500\"\n  \"/dev/sdb1\" \"/media/wouter/Kali Live\"' exited with non-zero exit\n  status 32: mount: block device /dev/sdb1 is write-protected, mounting\n  read-only mount: wrong fs type, bad option, bad superblock on\n  /dev/sdb1,\n         missing codepage or helper program, or other error\n         In some cases useful info is found in syslog - try\n         dmesg | tail  or so\n(udisks-error-quark, 0)\n\nHere is the output of dmesg | tail\n\n[  995.732144] sd 12:0:0:0: Attached scsi generic sg2 type 0 \n  [  996.478994] sd 12:0:0:0: [sdb] 7643136 512-byte logical blocks: (3.91 GB/3.64 GiB) \n  [  996.479683] sd 12:0:0:0: [sdb] Write Protect is off \n  [  996.479692] sd 12:0:0:0: [sdb] Mode Sense: 23 00 00 00 \n  [  996.480485] sd 12:0:0:0: [sdb] No Caching mode page found \n  [  996.480493] sd 12:0:0:0: [sdb] Assuming drive cache: write through \n  [  996.522644]  sdb: sdb1 \n  [  996.525979] sd 12:0:0:0: [sdb] Attached SCSI removable disk \n  [  997.561414] ISOFS: Unable to identify CD-ROM format. \n  [  999.938443] ISOFS: Unable to identify CD-ROM format. \n\nIt was working perfect until now. I do have ntfs-3g installed, so this could not be the problem. \n\nA: Indeed, it was a matter of corrupt stick. I had a few memory sticks/sd cards after each other which gave me the same error which made me think that it was a settings fault, but it turned out to be the sticks themselves. Problem solved\n", "Q: Video recording software I run Ubuntu 14.04 LTS.\nI want to record output from a digital decoder to disk so that it can be watched later on. \nJust to clarify the matter; instead of displaying, or while displaying, the output from the decoder on a TV screen, I want to record what is being output from the decoder in mp4 or avi format.\nMy question is: Does any software exist that will run on Ubuntu that will do the recording? What hardware will be have to be used with the software to enable the software to record the decoder's output?\nWhat I am wanting to do is not the same as the question on \"Record Live Streaming - cmks\" which is streaming from a website. I'm wanting to record what a decoder is receiving from a satelite and sending to my tv via HDMI or RCA cables.\nI found this hardware on eBay that will most likely do the job. All the items are sold with software for Windows. I'd like to avoid using Windows.\nMany thanks for any help I can get.\n\nA: I have not tried this myself, but I do have an old EasyCap branded usb capture device somewhere. Note that there are a few versions of these devices with different chip-sets. There is a good guide to identifying your device on this site. An easy way to capture video in Ubuntu is VLC Media Player which is available in the Ubuntu repositories.\nThere are other options for capturing the video from these cards, it depends if you want to use command line or GUI tools.\n", "Q: Getting latest version of evolution on Ubuntu 14.04 How do I install the latest version of Evolution on Ubuntu 14.04 ?\nI have tried   \nsudo add-apt-repository ppa:fta/gnome3  \nsudo apt-get update  \nsudo apt-get install evolution\n\nThis installs Evolution 3.10.4\nThis works fine but I want a later version that supports google tasks\n\nA: The instructions here:\nsudo apt-get remove evolution\nsudo apt-get update\nsudo apt-get install evolution\n\nare for 15.04 (vivid) (and 14.10 (utopic)) - no packages are available in the PPA for 14.04 etc, so the package manager falls back on the version provided in the ubuntu repos:\n\nThe problem is that Gnome programs generally is they depend on other parts of Gnome to work properly - since 14.04 uses Gnome 3.10 as a base version it becomes difficult to install some Gnome programs for 3.8, 3.12, 3.16 etc as they may break as they don't have the right libraries etc available (unless patched) - and trying to install those libraries which in turn probably will break Unity and other Gnome apps.... see dependency hell.\nYou can get Evolution 3.16 in 15.10 Wily, and if you wait two weeks you can get 3.18 in 16.04 (also a LTS like 14.04, but still in beta currently).\nIf you really want to, you can try installing the packages for 14.10 (may break stuff, I recommend backing up Evolution's data before doing it) by adding the a different entry for the PPA:\nsudo apt-get remove evolution\nsudo add-apt-repository 'deb http://ppa.launchpad.net/fta/gnome3/ubuntu utopic main'\nsudo apt-get update\nsudo apt-get install evolution\n\nThis will try and install the packages for 14.10 , which might work...\n", "Q: Is there and software to split and rearrange an audio file easily? I am looking for software that allows me to load an audio file make splits in it. I would like to then rearrange it to change what someone said :). I have seen many videos online where people have done it and I cannot figure out how. It would be nice to change pitches and other things like that but those are not necessities\n\nA: Certainly for simple splitting Audacity is the easiest gui tool to use. Using an example on my own setup:\n\n\n*\n\n*First import your audio into Audacity\n\n*Drag your cursor along and select a segment of the audio\n\n*Press Ctrl+B and label the segment\n\n*Repeat for other segments and also label appropriately, my example is labelled simply 'Part 1' and 'Part 2\":\n\n\n\n\n\n*You mentioned changing pitches and other effects, have a look now at the 'Effects' menu and you will see a truly amazing set of effects that can be applied to the output audio. First press Ctrl+A to select all segments (or select the segments individually with mouse click) and then apply any of these effects:\n\n\n\nThe 'Reverse' effect is my personal favourite!\n\n\n*Press Shift+Ctrl+L to simply export the 2 segments as separate files in the format of your choice with the meta tagging of your choice\n\n*If you wish however to rearrange the splits before exporting this can be done as a simple cut and paste. See here, using the same audio file, I have reversed the audio and you can see that the waveforms are now chopped in half and replaced out of order:\n\n\n\nAnd now export the whole 'reversed-segment' file with Shift+Ctrl+E.\nHopefully I have addressed all of your points? Endless fun to be had with Audacity :)\nReferences:\n\n\n*\n\n*Splitting a recording for export as separate tracks\n\nA: audacity may be able to do what you want (and more, also does the optional things you had)... http://www.audacityteam.org\n\nA: From command line the tool you want to play with is called sox\nInstalled as an apt-get command - this is a VERY useful and flexible interface.\n", "Q: How to use .p7b for Root CA in Ubuntu I need to add a p7b root ca to Ubuntu, in order to connect to services/servers for my company.\nBased on what I have found on the internet, it seems that I need to convert this file to either .crt or .cer. I used the following commands to convert the file:\nopenssl pkcs7 -inform der -in cert.p7b -out cert.cer\nopenssl pkcs7 -inform der -in cert.p7b -out cert.crt\n\nI then moved these files (I actually tried them one at a time) into /usr/share/ca-certificates/mycompany, and then added mycompany/cert.cer and mycompany/cert.crt to the /etc/ca-certificates.conf. After performing update-ca-certificates I still get root CA warning that the certificates/chain isn't in the system. \nThe only direction my company has given is for both Windows and adding this file into the OSX keychain. Any help is appreciated, because I don't like disabling https while using remote services/tools for my company.\n\nA: I have faced a similar situation, may be this helps. I have received a certificate in .p7b format. First, I converted it into .pem format. Then, I imported it into Firefox (or your browser). After that, I could access my application using that certificate.\nNow, in order to convert a .p7b into .pem do as follows.\nopenssl pkcs7 -inform der -in yourCert.p7b -print_certs -out yourCert.pem\n\nHope this helps.\n", "Q: How to switch between input-source modes through Terminal? I have looked at the answers to the question How do I change keyboards from the command line?, however I have found that even though they indicate how to switch input-sources through Terminal, they do not show how to switch between the modes of the input-sources. For instance I have \"Japanese (Anthy)\" installed which has several different mode settings section: Input mode, Typing mode, Segment mode, and Dictionary mode. In each of these there are different modes you can set for these settings. Like the Input mode one provides input modes such as Hiragana and Katakana, the Typing mode one allows you to change between Romaji, Kana, and Thumb shift, and the others have other various options you can change between to change the input-source mode.\nThese are very easy to change through the GUI as there is just a pull-down menu in the AppIndicator bar however as I will be needing to use TTYs for a while and not have access to the normal GUI, I need to know how to switch between these different modes in Terminal. So how can this be done?\nAt very least I need to know how to switch between the Input mode modes.\nI am running Ubuntu GNOME 15.10 with GNOME 3.18.\n\nA: I am nearly sure, you will have no success doing such things this way if you use the classic console tty instead of a (gui based) terminal program.  \nThis is in cause of the way input data flows. When you use a progam like xterm it will get its input stream from the X window system. So there is a lot of feature reach software between the key you are pressing on your keyboard and the input stream designated for the X application. Such software does the input modes of your desire - it is not a feature of i.e. xterm.\nIf you are using a console tty your are near to bare metal. You are working with the binaries of agetty, login and bash and they all get there input nearly straight from the kernel. There are some keyboard mappings between the pressed key and the input stream of bash but there is no feature reach programcode on that way which doing usefull things like you want.\n", "Q: Does MATE desktop environment use graphics acceleration? Does MATE desktop environment use graphics acceleration?\nI know that Unity uses graphics acceleration, while Xfce doesn't.\nThe reason I am asking this is because I need as simple as possible interface while being feature rich, to use on few years old laptop, and I do not want it to trigger the GPU because it waste too much battery.\n\nA: at the moment Unity, Cinnamon, GNOME 3, KDE/Plasma and LXQt are using graphic acceleration and MATE, Xfce and LXDE does not (by default).\nbeside them there are much desktop-environments/window-manager which are mostly less resource hungry than the named one, but most of them won't be comfortable (for beginners).\nso i named only DEs which are easily to get on ubuntu, and if you are thinking about other DEs, i would think about other distributions (specialized for low resources).\n\nthe other way round: at desktop environments without graphic acceleration you can upgrade shiny desktop effects (with use of graphic acceleration) by changing the window-manager (to Compiz, Composite, Compton):\nfor example on MATE it is pretty easy... go to the Control Center and choose Desktop Settings, Windows and use the dropdown menu under Window Manager.\n\n\n\"accidentally\" i came across an old article, which maybe interesting for your goal: https://www.phoronix.com/scan.php?page=article&item=linux_desktop_vitals&num=2\n(keep in mind MATE is the successor of GNOME 2)\n\nA: On Ubuntu Mate, you can use MATE Tweak (apt install mate-tweak) to choose a window manager that uses GPU acceleration, like Compton or Compiz.\nThis is a screenshot of the window managers available by default on Ubuntu Mate 16.04 LTS, 18.04 LTS (and newer); Marco (Compton GPU compositor) and Compiz (Advanced GPU accelerated desktop effects)\n use GPU acceleration:\n\n", "Q: Firefox plays videos without sound After I installed Amarok (which I have uninstalled since then), Firefox doesn't produce sounds when I try to stream some websites, for instance these ones:\nhttp://www.npo.nl/nos-studio-sport-eredivisie/09-04-2016/POW_03079959\nhttp://www.dumpert.nl/mediabase/6750553/2f16a7a8/spartafan_heeft_een_favoriete_speler.html\nBut youtube does work on Firefox, and Chrome works perfectly fine with all websites.\nI've tried to Google it and there are many suggestions on how to solve this problem (such as this one) but they don't solve my issue. Anybody knows how to solve this problem?\nI've re-installed Firefox and followed all the tips (here)[https://support.mozilla.org/en-US/kb/fix-common-audio-and-video-issues#w_plugins] but still no luck. I'm getting desperate. \nMy PCM sounds is also on:\n\nA: I finally found an answer on this site and will post it here in case it will be helpful for someone else (don't ask me why it works though ;)). Run the following commands in the terminal:\nsudo add-apt-repository ppa:nilarimogard/webupd8\nsudo apt-get update\nsudo apt-get install freshplayerplugin\n\nNote that I had already installed freshplayerplugin, so I guess the trick was the command line sudo add-apt-repository ppa:nilarimogard/webupd8.\n", "Q: How to exclude one specific file from being hashed through bash script I actually try to run recursive through a folder structure and make md5sum on all files into a single md5checksums file.\nHeres my script:\n\n#!/bin/bash\nrm -f md5checksums\nfind -type f -exec md5sum \"{}\" + > md5checksums\n\nMy problem now is that the file md5checksums is aswell running through md5sum and i cant get my head around it how to prevent that. Beside that the script does already what it should do. Anyone who can help me out?\n\nA: make the script take the name of that specific file you want excluded as argument.\n#!/bin/bash\nrm -f md5checksums\nfind -type f ! -iname \"$1\" -exec md5sum \"{}\" + > md5checksums\n\ncall the script with ./script \"md5checksums\"\n\nA: The simplest way to avoid conflicts involving redirections to a file affecting the command would be to use sponge from moreutils:\nsponge  reads  standard  input and writes it out to the specified file.\nUnlike a shell redirect, sponge soaks up all its input  before  opening\nthe  output file. This allows constructing pipelines that read from and\nwrite to the same file.\n\nThe effect is that the file, if not present already, isn't created until the pipeline finishes.\nSo:\nfind . -type f -exec md5sum {} + | sponge md5checksums\n\n\nA: Using only bash:\nUsing GLOBIGNORE:\n$ GLOBIGNORE='md5checksums'  ## Pattern to ignore\n$ shopt -s globstar  ## Recursive globbing\n$ { for i in **/*; do [ -f \"$i\" ] && md5sum \"$i\"; done ;} >md5checksums\n\n\nUsing extglob:\n$ shopt -s extglob ## Enables extended pattern matching, enabled by default\n$ shopt -s globstar\n$ { for i in **/!(md5checksums); do [ -f \"$i\" ] && md5sum \"$i\"; done ;} >md5checksums\n\n\nUsing zsh:\n% setopt extended_glob \n% { for i in **/^md5checksums(.); do md5sum \"$i\"; done  ;} >md5checksums\n\n\n\n*\n\n*zsh does recusive matching by default while using **\n\n*^md5checksums is zsh extended glob pattern, meaning to match everything else except md5checksums\n\n*The glob qualifier (.) restricts matches to regular files only.\n\nA: Another one that do what you want:\n#!/bin/bash\nrm -f md5checksums\nfind -type f -not -name \"md5checksums\" -exec md5sum \"{}\" + > md5checksums\n\n\nA: Thanks to @heemayl for some nice inspiration in his answer.\n#!/bin/bash\n\nshopt -s globstar\n\nrm -f md5checksums\n\nfor i in **/*; do\n    if [ ! -f \"$i\" -o \"$i\" = md5checksums -o \"$i\" = this_script.sh ]; then\n        continue\n    else\n        md5sum \"$i\" >> md5checksums\n    fi\ndone\n\n", "Q: Hybrid graphic and laptop life As a non-gamer I would like to get an answer on this question please. If a laptop use whole time integrated GPU, and switch to Nvidia when the system is demanding it, will it affect laptop's life in general?\nBecause as far as I heard, if the system uses integrated chip to deliver some HQ graphic/video it can \"burn\" up motherboard after some period (2,3 years ~). \nIs this true?﻿\nI am running Xubuntu 14.04 with Intel HD Graphics 5500 + nVidia Geforce 920M 1GB. My BIOS don't let me to do any changes to it. I've got a new laptop and I am really concerned about my laptop life.  \n\nA: I have some good news for you ... you do not have to be concerned about nor fear anything at all ! The information you have got that your motherboard will get \"burned up\" by the integrated intel graphics is wrong. There are a lot of computers that do not have a dedicated graphics chip and so are always running with the integrated graphics. The same is valid for the NVIDIA graphics, using it will not damage anything. Maybe the person who gave you the information unfortunately just had a hardware failure, which can happen as with every technical product. So just enjoy Ubuntu !\n", "Q: HTML Signature in Evolution I've tried cut and pasting the html code for my email signature that works fine in various other email clients and doing it in html formating, not text, when saving the signature, but the code never turns into the proper formatting.  Instead it just shows the text of the html code when I try to use the signature.\n\nA: This appears to be a bug in Evolution 3.10.4\nThere is a simple workaround though. Write your html signature in a file called signature.html Test that it works by opening it in Firefox. Then when you have finished writing a message add the signature by using menu item insert -> html file.\n\nA: The better workaround is to create signature.html and signature.sh (also chmod +x it)\nsignature.sh:\n#!/bin/bash\ncat ~/.signature.html\n\nIn Evolution: File -> Composer Preferences -> Signatures -> Add Script -> your script on file system\n\nA: signature.sh doesn't work for me.  I got this to work by:\n\n*\n\n*Create signature.html file\n\n*Test in Firefox as above.\n\n*Insert into a new email message in Evolution.\n\n*Copy the inserted signature.\n\n*Paste the signature in an \"Add Signature\" dialog.\n\n*New signature can be inserted and looks as expected.\n\nNow, I can't seem to get the signature to automatically be inserted into email messages....\n", "Q: How to squash all the contents of a multi-line file onto one line? I have a file with many thousands (possibly even millions) of lines, however I need all of the contents to be on one line and all spaces removed (there shouldn't be any spaces there, but there might be, and if there are, they should be removed). How can this be achieved?\nTo give some context, I got the base64 output for a huge file and now need to pipe it into another command, however I need to pipe it in as one huge number, but as the file is made of multiple lines as opposed to having it all on one line, I am unable to pipe it into the program because it will treat every line as a new number and I need the whole thing to be treated as one big one.\nI am running Ubuntu GNOME 15.10 with GNOME 3.18, I hope that this can be achieved with a simple command and/or script.\n\nA: Pipe it through this perl regex:\nperl -p -e 's/[\\n\\r ]*//g'\n\n\nA: The simpler way: use tr.\ntr -d '[[:space:]]' <file1 >file2\n\n(Use sponge if you need to write to the same file.)\n\nPretty easy with Vim:\nvim -Nesc '%s/\\_s//g' +wq file\n\n\n\n*\n\n*-Nes starts silent, non-compatible ex-mode (for easy scripting with Vim).\n\n*-c and + are used to run commands\n\n*%s/\\_//g substitutes in all lines all whitespace, along with any newlines, with nothing.\n\n*wq saves the file and exits Vim.\n\n\n\nWith awk, set RS (record separator) to whitespace and ORS (output record separator) to nothing:\nawk -v RS='[[:space:]]' -v ORS= '1' foo\n\nWith GNU awk, you can do in-place editing using gawk -i inplace.\n\nA: AWK can do that by looping all the fields and using printf \"%s\". Example\ncat /etc/passwd | awk '{for(i=1;i<=NF;i++) printf \"%s\",$i}'\n\nSample run:\n$ printf \"to be or not to be\\nthat is the question\" | \\         \n> awk '{for(i=1;i<=NF;i++) printf \"%s\",$i}'\ntobeornottobethatisthequestion\n\n", "Q: How can I change my VirtualBox memory space? I installed VirtualBox and Ubuntu but now I'm trying to install a software (Xilinx) but i think my machine doesn't have enough memory (the software has more than 6 Gb and it only installs until 2.5 Gb)...\nHow should I proceed to change the memory space? Also do you have any idea how much memory I need? \n\nA: We can increase the virtual hard disk space as shown e.g. in answers to the following question:\n\n\n*\n\n*How do I increase the hard disk size of the virtual machine?\nIn your case, and if it was a new installation of Ubuntu it will be far less time consuming to just start from scratch and install Ubuntu again, this time on a larger virtual drive.\nIf you choose a dynamically growing virtual disk you can assign it a rather huge space it will report to the guest OS. Its physical size on the host hard drive will be much smaller and it will only grow to the extent needed and never more than up to the predefined limit.\n", "Q: Wine autocreate desktop entries I've moved the wine applications I had on an older Ubuntu installation to a newer one, but just the .wine folders.\nNow I realise that I should have taken the .local/share/applications with me, since there is where desktop entries are saved.\nIs there any way to recreate, as automatically as possible, all desktop / launchpad entries for the installed Program Files and Program Files (x86) applications?\n\nA: This works very nicely on my system:\nfind $HOME/.wine -name '*.lnk' -type f -exec bash -c 'wine winemenubuilder \"$0\"' {} \\;\n\nIt does the following:\n\n\n*\n\n*scans your Wine drive for windows .lnk files\n\n*creates a Linux .desktop file for each .lnk file\n\n*creates a folder $HOME/.local/share/applications/wine\n\n*places all of the newly created .desktop files in there\n\n\nPretty cool?\nReferences:\n\n\n*\n\n*Winemenubuilder\n", "Q: Using WiFi Dongle in Ubuntu 15.10 I have a Belkin F9L1108-TG which supposedly uses the RTL8192DU driver. \nThe instructions here: How to install drivers for Belkin f9l1108tg wifi USB adapter? do not work.\nThe instructions here http://ubuntuforums.org/showthread.php?t=2153777&p=12688576#post12688576 have the following error on make\njustin@Unicorn:~/Desktop/RTL8192DU Driver/rtl8192du$ make\nmake ARCH=x86_64 CROSS_COMPILE= -C /lib/modules/4.2.0-35-generic/build M=/home/justin/Desktop/RTL8192DU Driver/rtl8192du  modules\nmake[1]: Entering directory '/usr/src/linux-headers-4.2.0-35-generic'\narch/x86/Makefile:138: CONFIG_X86_X32 enabled but no binutils support\nMakefile:669: Cannot use CONFIG_CC_STACKPROTECTOR_STRONG: -fstack-protector-strong not supported by compiler\nmake[1]: *** No rule to make target 'Driver/rtl8192du'.  Stop.\nmake[1]: Leaving directory '/usr/src/linux-headers-4.2.0-35-generic'\nMakefile:149: recipe for target 'modules' failed\nmake: *** [modules] Error 2\n\nI'm not sure how to get past this.\nFYI here's usb info\njustin@Unicorn:~/Desktop/RTL8192DU Driver/rtl8192du$ lsusb\nBus 004 Device 003: ID 050d:110a Belkin Components F9L1101v2 802.11abgn Wireless Adapter [Realtek RTL8192DU]\nBus 004 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 006 Device 002: ID 046d:c52f Logitech, Inc. Unifying Receiver\nBus 006 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 005 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 001 Device 002: ID 413c:2003 Dell Computer Corp. Keyboard\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\n\n\nA: Please try:\nsudo apt-get update\nsudo apt-get install git\ngit clone https://github.com/lwfinger/rtl8192du.git\ncd rtl8192du\nmake\nsudo make install\nsudo modprobe 8192du\n\nI have recommended that you install the latest version that I have tested through 'make' rather than correct your error on an unknown older version. The error is probably that there is a space in the name! ~/Desktop/RTL8192DU Driver. You might be able to correct it by renaming the folder to: ~/Desktop/RTL8192DU_Driver. I did not propose this at the outset, since I recommend that you use a later version from git.\n", "Q: Ubuntu 14 installing phpmyadmin newbie question Okay did a search first, and a whole bunch of folks are having problems with this one however my problem seems to be reasonably unique ... i.e. am doing something obviously wrong.\nAm getting the following error on install right after entering the password for mysql\nERROR 1045 (28000): Access denied for user 'root'@'localhost' (using      │\n │ password: YES) \nHave no idea what the root password is, am using the one that allows me su access???\n\nA: The installation process will not ask you for the root password nor for your personal user password but for the password of the database user root. This is, if you dont changed it, initaly empty.\nYou should run\nmysql_secure_installation\n\nand set a mysql root password when asked for it. Then restart installation of phpmyadmin with the now well known mysql root password.\n", "Q: What's the difference between the keyboard shortcut commands and bash ones? When I type in a terminal :\ngnome-screenshot -a -f /home/manuel/Desktop/\"`date`\".png\n\nI have the intended result, a file named \"dimanche 10 avril 2016, 23:36:50 (UTC+0200).png\" is created.\nHowever, when I try to link this with a keyboard shortcut, I get instead the a file named\n\"`date`.png\"\n\nWhen I try further\nbash -c \"gnome-screenshot -a -f /home/manuel/Desktop/\"`date`\".png\"\n\nthe file becomes dimanche meaning it stops at the 1st whitespace.\nI read that while quoting a bash variable, to include whitespaces one must use quotes, which seems I did. So I later tried assigning the date command to a $times variable and using \"$times\" in the command  but with the same result.\nSo my question is why must bash always be a pain in the ass? If it is indeed the culprit.\nThank you, if no one answers I hope creating a bash file instead will solve this as a last resort as it has many times before...\n\nA: Shortcuts in System Settings -> \"Keyboard\" -> \"Shortcuts\" -> \"Custom Shortcuts\" are not run in a shell.\nThat's why gnome-screenshot -a -f /home/manuel/Desktop/\"`date`\".png creates a file named \"`date`.png\"; the /home/manuel/Desktop/\"`date`\".png part is not interpreted and is passed verbatim to gnome-screenshot, which creates a file named \"`date`.png\".\nbash -c \"gnome-screenshot -a -f /home/manuel/Desktop/\"`date`\".png\" instead doesn't work simply because you're not escaping the second level of quotes, which makes Bash run date in an uquoted subshell which is subject to word splitting.\nSo just escape the second level of quotes:\nbash -c \"gnome-screenshot -a -f /home/manuel/Desktop/\\\"`date`\\\".png\"\n\nOr even better use single quotes in the outer command so to not have to escape a second level of quotes:\nbash -c 'gnome-screenshot -a -f /home/manuel/Desktop/\"`date`\".png'\n\nOn a side note using `` is deprecated and discouraged; it would be better to use $():\nbash -c 'gnome-screenshot -a -f /home/manuel/Desktop/\"$(date)\".png'\n\n\nA: Create a executeable script:\nEdit a file i.e. /usr/bin/myscreenshot with a editor of your choice as root, i.e.\nsudo vi /usr/bin/myscreenshot\n\nPaste this content in the file\n#!/bin/bah\ngnome-screenshot -a -f \"/home/$USER/Desktop/`date`.png\"\n\nMake the file to be a executeable script:\nsudo chmod +x /usr/bin/myscreenshot\n\nFinaly create a keyboard shortcut to this program and it should be done.\n", "Q: I want an Ubuntu 12.04 whith Kernel 3.4.6 I could not find a copy of ubuntu 12.04 Where the kernel ia 3.4.6 . I want to download an Ubuntu 12.04 (kernel 3.4.6). Possible link to download.\n\nA: Installing the linux-generic-lts-trusty package on 12.04 will give you the 14.04 kernel, which is 3.13, which should allow you to build RTAI 5.0.\n", "Q: How do I recover encrypted home folder after deleting filesystem I was trying Ubuntu 16.04 but had issues and decided to install 14.04 over it. I have 16.04 installed on a single ext4 partition and encrypted my home folder (I remember the encryption passphrase). \nBefore installing 14.04 I created a 2nd ext4 partition on the same hard drive and made a copy of the files I need from my home folder. I later came across a post that suggested I could have installed 14.04 over 16.04 and kept my home folder (argh). \nI thought I was installing over the first partition on my disk but I must have been paying full attention. I also installed LVM, which may have made things worse, in an attempt to prevent this in the future. \nI booted to 14.04 and tried to a rescue with GParted but that didnt work. I installed testdisk and after a deep analysis I was able to find my previous root with my home folder and .ecryptfs files. \nI think that I need to try to rebuild the ext4 file system, then mount it and decrypt and move the files where I need them. I need a little help getting there. I think I need to assign a file system from testdisk but I want to be sure. Also, does this have to be done from a Live CD? I realize once the files get written over I cant get them back.\nThanks,\n\nA: If you overwrote the files, they're gone. If testdisk couldn't find the partition, it's essentially gone. You could try photorec, it may find some files yet, but a backup copy would be best.\nIf you still have a copy somewhere, run ecryptfs-recover-private\nAs always, remember that if files are important enough they should have a good backup somewhere.\n", "Q: .desktop file will not open in Google Chrome when launched from SpaceFm While using Google Chrome I often drag website links from the address bar into a folder on the desktop for later reference. This creates a .desktop file that is essentially a link to a webpage. \nThese desktop files can be opened easily from Nautilus & PCmanFM by simply by double-clicking to open them, however, when I open them using the SpaceFM file manager, Google Chrome starts downloading the file instead of opening it like it does with the other mentioned file managers.\nI am able to open these files through SpaceFM if I right click them and open with Firefox, but not Google Chrome. \nAn example of the desktop file would be as follows:\n[Desktop Entry]\nEncoding=UTF-8\nName=Link to The Hidden Fortress (1958) - IMDb\nType=Link\nURL=http://www.imdb.com/title/tt0051808/?ref_=nv_sr_2\nIcon=text-html\n\nIs there a way to make these .desktop files open in Google Chrome normally when launched from the SpaceFM browser?\n\nA: 1. Convert link files into launchers\nThe solution below offers the option to right- click the link (.desktop file) and choose > \"Execute\", which will run Google-Chrome to open the link. By editing SpaceFm's settings, you can run the link by double-click as well (see notes [3]).\n\nNote that the solution automatically edits (only) new links on your desktop, to run the link specifically with Google-Chrome\nWhat it is\nA small background script checks once per two seconds for new .desktop files on your Desktop. If a relevant file is found, the file is edited from a Link file into an Application file. This is done by editing two lines inside the file:\n\n\n*\n\n*The line:\nType=Link\n\nis changed into:\nType=Application\n\n\n*The line:\nURL=<link>\n\nis changed into:\nExec=/usr/bin/google-chrome-stable <link>\n\nIn the test(s) I ran, this makes the link \"openable\" by right- click in SpaceFm: right-click > Open > Execute\nThe script\n#!/usr/bin/env python3\nimport os\nimport time\n\n# --- define the (absolute) path to your desktop below\ndr = \"/absolute/path/to/your/desktop\"\n# edit (if necessary) the command to launch Google-Chrome\napplication = \"/usr/bin/google-chrome-stable\"\n\ndef find_relevant():\n    return [f for f in os.listdir(dr) if f.endswith(\".desktop\")]\n\nrelevant1 = []\n\nwhile True:\n    time.sleep(2)\n    relevant2 = [f for f in os.listdir(dr) if f.endswith(\".desktop\")]\n    new = [f for f in relevant2 if not f in relevant1]\n    if new:\n        for f in new:\n            f = dr+\"/\"+f\n            rewrite = False\n            lines = [l.strip() for l in open(f).readlines()]\n            for i, l in enumerate(lines):\n                if l.startswith(\"Type=Link\"):\n                    rewrite = True\n                    lines[i] = \"Type=Application\"\n                elif l.startswith(\"URL=\"):\n                    lines[i] = l.replace(\"URL=\", \"Exec=\"+application+\" \")\n            if rewrite == True:\n                print(\"rewrite\")\n                open(f, \"wt\").write((\"\\n\").join(lines))            \n    relevant1 = relevant2\n\nHow to use\n\n\n*\n\n*Copy the script into an empty file, save it as edit_links.py\n\n*In the head- section of your script, edit the path to your Desktop (as mentioned, use absolute path here)\n\n*Check the command to run Google-Chrome (also set in the head- section) by checking the first Exec= line in the google-chrome.desktop file: run\ngedit /usr/share/applications/google-chrome.desktop\n\nto read the file.\n\n*Test-run the script by the command:\npython3 /path/to/edit_links.py\n\nOpen Google-Chrome, drag links on to your Desktop, test after a few seconds if it works fine.\n\n*If all works fine, add it to Startup Applications: Dash > Startup Applications > Add. Add the command:\npython3 /path/to/edit_links.py\n\nNote\n\n\n*\n\n*The dragged .desktop file (link) needs to be on your Desktop at least one-two seconds to be found and edited, so if you move the links, at least leave them for a few seconds on your Desktop. :)\n\n*ll the script does is check for new .desktop files on your Desktop, it only reads/edits the file(s) if there are new files. This means nothing to your system.\n\n*By editing SpaceFm's settings, you can alsu run the \"link\" by double-click:\n\nConvert your existing link files recursively\nAdditionally, as discussed in chat, a script to run a single time to convert the links in a directory recursively:\n#!/usr/bin/env python3\nimport os\nimport sys\n\n# --- define the (absolute) path to your desktop below\ndr = sys.argv[1]\n# edit (if necessary) the command to launch Google-Chrome\napplication = \"/usr/bin/google-chrome-stable\"\n\nfor root, dirs, files in os.walk(dr):\n    for f in files:\n        if f.endswith(\".desktop\"):\n            f = root+\"/\"+f\n            rewrite = False\n            lines = [l.strip() for l in open(f).readlines()]\n            for i, l in enumerate(lines):\n                if l.startswith(\"Type=Link\"):\n                    rewrite = True\n                    lines[i] = \"Type=Application\"\n                elif l.startswith(\"URL=\"):\n                    lines[i] = l.replace(\"URL=\", \"Exec=\"+application+\" \")\n            if rewrite == True:\n                open(f, \"wt\").write((\"\\n\").join(lines)) \n\nTo use it, save it as convert_links.py, run it with the targeted directory as an argument:\npython3 /path/to/convert_links.py <directory>\n\n\n2. Convert links into cross-platform usable link files\nAs requested by OP, below a version of the (first) (background) script, converting the link files, created by dragging a link from the browser to the desktop, into cross-platform links. Usage is exactly as explained in the first section.\nThe script\n#!/usr/bin/env python3\nimport os\nimport time\n\n# --- define the (absolute) path to your desktop below\ndr = \"/absolute/path/to/your/desktop\"\n\nout1 = [\"<html>\", \"<body>\", '<script type=\"text/javascript\">']\nout2 = [\"</script>\", \"</body>\", \"</html>\"]\n\ndef find_relevant():\n    return [f for f in os.listdir(dr) if f.endswith(\".desktop\")]\n\nrelevant1 = []\n\nwhile True:\n    time.sleep(2)\n    relevant2 = [f for f in os.listdir(dr) if f.endswith(\".desktop\")]\n    new = [f for f in relevant2 if not f in relevant1]\n    if new:\n        for f in new:\n            f = dr+\"/\"+f\n            rewrite = False\n            lines = [l.strip() for l in open(f).readlines()]\n            for i, l in enumerate(lines):\n                if l.startswith(\"Type=Link\"):\n                    rewrite = True\n                elif l.startswith(\"URL=\"): \n                    url = 'window.location.href = \"'+l.replace(\"URL=\", \"\")+'\"'\n                    out1.append(url)\n                elif l.startswith(\"Name=\"):\n                    name = l.replace(\"Name=\", \"\")\n            if rewrite == True:\n                open(f.replace(\".desktop\", \".html\"), \"wt\").write((\"\\n\").join(out1+out2))\n                os.remove(f)\n    relevant1 = relevant2\n\nVersion to convert your existing links in a recursive directory (single run)\n#!/usr/bin/env python3\nimport os\nimport sys\n\ndr = sys.argv[1]\n\nout1 = [\"<html>\", \"<body>\", '<script type=\"text/javascript\">']\nout2 = [\"</script>\", \"</body>\", \"</html>\"]\n\nfor root, dirs, files in os.walk(dr):\n    for f in files:\n        if f.endswith(\".desktop\"):\n            f = root+\"/\"+f\n            rewrite = False\n            lines = [l.strip() for l in open(f).readlines()]\n            for i, l in enumerate(lines):\n                if l.startswith(\"Type=Link\"):\n                    rewrite = True\n                elif l.startswith(\"URL=\"): \n                    url = 'window.location.href = \"'+l.replace(\"URL=\", \"\")+'\"'\n                    out1.append(url)\n                elif l.startswith(\"Name=\"):\n                    name = l.replace(\"Name=\", \"\")\n            if rewrite == True:\n                open(f.replace(\".desktop\", \".html\"), \"wt\").write((\"\\n\").join(out1+out2))\n                os.remove(f)\n\nTo use it, save it as convert_links.py, run it with the targeted directory as an argument:\npython3 /path/to/convert_links.py <directory>\n\nNote\nThis version was based on this nice answer on Super User to create cross-platform links.\n", "Q: Does Ubuntu need an Antivirus? Does Ubuntu need an Antivirus?  If so, could you recommend a good one? I am interested on the Ubuntu side only.\n\nA: I asked myself the same question a bit ago and when I asked it, I was told that no Ubuntu did not need an antivirus. Mainly due to the fact that the people creating the viruses were going for the big markets (e.g windows) to get the most impact. However, as more and more people come to the Linux side, this may change. If it has not already.\nI did use ClamAV Antivirus, but now I do not use one and I have not had an issue.\nThis site may give you a bit more of an insight Antivirus for Ubuntu\n\nA: I would agree with Phil UK's comments - but ask yourself the question what am I trying to protect ? What is it's value - either to me - or to my company/employers/staff or customers.\nIf it is your home pc and you only use for Steam gaming - the \"cost\" is probably 0 - assuming your CC Details for your Steam account are not on that machine. If it is work related... Why not go ahead and protect your machine....\nYou probably want to look at a firewall and some basic log checking and IDS at the same time.\n", "Q: How to adjust screen settings: contrast, color saturation, etc using Xubuntu 14.04 with a HP mini notebook.\nI can't seem to find any program to adjust screen settings: contrast, brightness, and more importantly: color saturation, tint and gamma.\nThanks beforehand.\n\nA: Personally, I use terminal commands xgamma for contrast and occasionally  xrandr for brightness (though mostly I use the native brightness setting - more on that later ).\nTo change contrast with xgamma , do\nxgamma -gamma $1\n\nWhere $1 is a decimal value. It can be 1.5 or .5 , but the values above those values can be harsh on the eyes, so play with the values in that range.\nTo change brightness  with xrandr , you need to know the name of your display. Run xrandr to find that out, should be mentioned as connected primary. \nTo change brightness, do\n  xrandr --output $SCREEN --brightness $VALUE\n\nwhere $SCREEN  is the value of your connected primary and $VALUE is decimal number, again in range from 0 (completely off) to whatever\nPersonally , what I'd do is spawn gnome-settings-daemon or unity-settings-daemon command , whichever is available, and use the following two commands to change brightness :\nqdbus org.gnome.SettingsDaemon.Power /org/gnome/SettingsDaemon/Power org.gnome.SettingsDaemon.Power.Screen.StepUp\nqdbus org.gnome.SettingsDaemon.Power /org/gnome/SettingsDaemon/Power org.gnome.SettingsDaemon.Power.Screen.StepDown\n\n( provided of course that you have qdbus installed ; it is so for Default Ubuntu with Unity, but I don't know about Xubuntu .  If you don't have the settings daemon, you can install it with sudo apt-get install gnome-settings-daemon ) \n\nA: this can be made with xrandr, first identify you video output running \"xrandr\" and look into the output sor something like this:\nDVI-I-1 connected 1600x900+1600+0 (normal left inverted right x axis y axis)\n\nin my case, my output is DVI-I-1, now i run \"xrandr --props\" to know what properties can i change.\nscaling mode: None \n    supported: None, Full, Center, Full aspect\ncolor vibrance: 180 \n    range: (0, 200)\nvibrant hue: 90 \n    range: (0, 180)\nnon-desktop: 0 \n    range: (0, 1)\nlink-status: Good \n    supported: Good, Bad\n\nto change the saturation, in my case (Old GeForce GT 520), i run the following:\nxrandr --output DVI-I-1 --set \"color vibrance\" \"180\"\n\nHope this works for all you guys.\n", "Q: Ubuntu 14.04, lost grub2 and partition during Windows 10 upgrade Had dual boot on an HP laptop. Ubuntu 14.04 and Windows 7. \nGot stuck in the middle of my Windows 10 upgrade at grub rescue prompt.\nUsed boot-repair-disk to get past that point. Chose recommended repair.\nThis worked enough that Windows 10 was able to finish installing.\nhttp://paste.ubuntu.com/15728790\nAfter Windows 10 finished installing, I ran BRD again, hoping it would recognize and return my dual boot (grub2). Did not work.  \nWindows 10 was booting slowly, so I made one more run at it.\nChose recommended repair each time.\nDid not help at this point. Still booting straight to Windows 10.\nNext, I decided to see if my partition was even still there.\nRan Ubuntu installation disk to verify partition is still there. \nIt showed \"free space\" with a size of 284511 mb, where one of the partitions used to be (I think). \n/dev/sda     \n/dev/sda1 ntfs 104 MB    30 MB     Windows 7 (loader)    \n/dev/sda2 ntfs 209112 MB unknown    \n/dev/sda3 ntfs 497mb     408 MB     \nfree space          284511 MB     \n/dev/sda5 swap\n\nThen, I looked at the partitions in gparted. It lists sda4 where \"free space\" showed above: \n/dev/sda4  extended 270.45 Gib\n\nthe sub menu for that item says, unallocated 264.97.\nI installed gparted and tried to recover lost files, but it could not. \nRan testdisk, in hopes I can recover that partition:\n\nWhen trying to recover lost data, it said:\nNo partition found or selected for recovery.\n\nI think the data is still there, but am not sure how to proceed.\nHere's the Current partition structure according to testdisk.\n1 * HPFS - NTFS\n2 P HPFS - NTFS\n3 P Windows RE (store)\n4 E extended\n5 L Linux Swap\n\nDoing a \"quick search\" shows 5 deleted items:\nD HPFS - NTFS\nD HPFS - NTFS    \nD HPFS - NTFS    \nD Linux    \nD Linux Swap\n\nThe fourth item down says \"Linux\" now, but did not say that until I pressed \"enter\" to continue, and had to put something there to get out of that next screen.  It may have said \"unallocated\" or or been blank.\nIt appears to me that the data is all there, but I am not certain how to proceed.\nIt appears to me that...that is showing the deleted files/partitions from Windows 7 & Ubuntu.\nI'd like to recover my Ubuntu partition, but it appears that the partitions no longer match up to the current partitions.  \nI considered running photorec just to get my images off and then maybe reinstalling Ubuntu, but it just seems quite a daunting task to understand how photorec works.\nThe most important thing is the images though.\nI've read numerous posts and threads, but am not sure where to go from here.\nsuggestions?\n\nA: Thanks, oldfred. Testdisk ended up working.  \nIn a nutshell, I looked at my deleted files (see image in OP) and changed the types for the Linux items marked \"D\" to \"P\" for both. Then, selected \"write\". (Thinking that would ADD those to the other partitions.)\nAfter restarting, the computer said \"grub rescue\", same as when I was doing the Windows 10 installation. Installed the Boot-Repair-Disk, and it reinstalled my grub2 menu and recognized my Ubuntu partition, but no Windows to boot into.\nWent back in with testdisk and changed the types on all of the deleted partitions, except Linux swap. The top one got an \"*\", the next 3 got a \"P\" and the Linux Swap kept the \"D\" (because of the rule that only 4 partitions can be marked as primary). \nMy thought was that the 3 top deleted items, must be my Windows 7 partitions and I'll take Windows 7 back over losing my Ubuntu partition.\nDid a restart, inserted the Boot-Repair-Disk, ran \"recommended repair\", did a restart, and my grub was up and running with both Ubuntu and Windows, but it was Windows 10, instead of 7. \nSo, it all seems to be working again, but with an upgraded Windows.\n", "Q: open wifi Captive portal w/only local net (no internet/wan)? I am trying to set up a wireless 'test' box to use on a private club (11,000 acres). The initial tests won't need anything fancy, it will just be checking the visibility of a hotspot from a high-point in the middle of the property. But if it proves to have good visibility, later tests will be (hopefully) promoted by the club and made aware to members. I would like to set up a captive portal to redirect them to a comments page where they can post a quick message if they were able to connect and hopefully say what they think about the idea.\nMost of the examples I see online of captive portal are based on having an internet connection and/or a NAT scheme set up. I just need a hotspot and a single web-page for these promotional tests. If possible, I would like to trigger any devices capable to suggest or otherwise open a browser to go to the promotional landing page. It would also be nice if some kind of dns masquerading or other mechanism was in place to redirect all browser traffic in the event their device doesn't support a pop-up.\nAny help is appreciated.\n\nA: Having just completed a similar project, I suggest you do the following:\n\n\n*\n\n*install your preferred flavour of Ubuntu\n\n*open up a terminal\n\n*\nsudo apt-get install lamp-server^\n\n\n*\nsudo apt-get install phpmyadmin\n\n\n*create your webpage (I used wordpress), and have apache2 configure it\n\n*\nsudo apt-get install dnsmasq\n\n\n*edit the /etc/dnsmasq.conf to listen on your IP\n\n*insert the line address=/#/webserverIP\n\n\nnow anyone connecting to your hotspot will be redirected to the page you created, so long as they do not have \"/\" in the address.\nfacebook.com will redirect. facebook.com/xyz will not.\nI'm still trying to find an answer for that bit.\n", "Q: Finding my swap partition It looks like I have 40 GB of swap:\nwuser@wavesftwDell:~$ cat /proc/swaps\nFilename                                Type            Size    Used    Priority\n/dev/dm-1                               partition       40959996        956    -1\n\nwuser@wavesftwDell:~$ swapon -s\nFilename                                Type            Size    Used    Priority\n/dev/mapper/rhel_krillin-swap           partition       40959996        956    -1\n\nBut I cannot find this in df output or gparted:\nwuser@wavesftwDell:~$ df\nFilesystem      1K-blocks      Used  Available Use% Mounted on\nudev              1947052        12    1947040   1% /dev\ntmpfs              391628      1324     390304   1% /run\n/dev/sda5        71931216  24346148   43908092  36% /\nnone                    4         0          4   0% /sys/fs/cgroup\nnone                 5120         0       5120   0% /run/lock\nnone              1958140       224    1957916   1% /run/shm\nnone               102400        60     102340   1% /run/user\n/dev/sdg1      3906983932    185496 3906798436   1% /home/wuser/lala\n/dev/sdb1       961301832 175093504  737353904  20% /media/wuser/Boromir1TBv2\n/dev/sda1          508588    153804     354784  31% /media/wuser/ec3f56a6-ed56-4bfd-bdb5-0d27a0fa1a76\n\n\nWhy does my swap partition not show up?\n\nA: I see you are using LVM partitions. \ndf command never shows swap partitions because they are not a file system partition.\nYou can check your existing Logical Volumes with lvs command and check your device mapper (dm-X) devices witch ls -l /dev/mapper/ or dmsetup ls\n\nA: *\n\n*Open Disk Utility.\n\n*In the left column, look for your hard disk, and click on it.\n\n*In the right column, see if you can find \"Swap\". If so, you have swap enabled; you can click on that portion to see details. \n\n\nAlternately, open a terminal with Ctrl+Alt+T, and type swapon -s; if you see a line like the below, with statistics, swap is enabled:\n\n", "Q: Shell scripting to display /etc/group I want to write a shell script that displays the system’s users and groups from /etc/passwd and /etc/group - for each user I want to display the username, UID and all groups the user is a member of.\nI tried the following:\ncat /etc/passwd /etc/group\n\nbut the output was all over the place. Can someone help me to write this script.\n\nA: Don't reinvent the wheel. The id command can do exactly that:\n$ id foobar\nuid=1000(foobar) gid=1000(foobar) groups=1000(foobar),4(adm),20(dialout),24(cdrom)\n\nreplace foobar with your desired username.\nCheck man id to get more idea.\n\nA: To get all groups for all entries in /etc/passwd\nfor user in $(getent passwd| cut -d: -f1); do groups $user; done\n\nexplanation\n\n\n*\n\n*getent passwd: lists all lines in /etc/passwd in the usual format \nguest-ZlneMD:x:119:130:Guest,,,:/tmp/guest-ZlneMD:/bin/bash\n\n\n*cut -d: -f1: removes all but the first field (fields are separated by :)\nthe result is a list of all account names, sorted by UID\n\n*now user is assigned all of these values, one by one\n\n*and groups $user takes each of these values and displays the username and all groups that account belongs to.\nguest-ZlneMD : guest-ZlneMD\n\n", "Q: Play and encode audio in reverse? Using tools available to Trusty Tahr how can I play audio files in reverse (play them backwards)? I would also like to know of tools that will allow me to save or create such reversed audio files...\n\nA: From GUI with Audacity - \nReversing audio can be done using Audacity Effect > Reverse. After reversing we can choose to just playback or to export in any codec supported.\nFrom CLI with Sox - \nOn the command line we can reverse audio with sox option reverse:\nsox input.wav output.wav reverse ## for conversion\nplay input.wav output.wav reverse ## for playback\n\n", "Q: How can I reduce \"palm touch sensitivity\" on my Thinkpad? Am running 14.04.4 on my Thinkpad L450 - however I have noted the touchpad is very sensitive to my palm rubbing against the touchpad when I use the TrackPoint nub.\nHow can I reduce the sensitivity of the touchpad to accidental palm touches. \n\nA: It is probably Synaptics touchpad, you can change your preferences in Mouse & Touchpad settings. If this doesn't help you can play with specific Synaptic settings by synclient command. Type synclien -l to list all possible settings\nYou can also check this: https://help.ubuntu.com/community/SynapticsTouchpad#Control_touchpad_features_using_synclient\n", "Q: How To Program A Bash Script That Presses A Certain Combination Of Keys? Please, i need someone to help me in making a very simple bash script. The job of this script is just to press a certain combination of keys on the keyboard.\nMy objective is to create a script that would turn off the Kubuntu desktop effects completely. The key combination for that is: \"Left-ALT + Left-Shift + F12\". I am aware that there is a widget that might do this job, but i am trying to learn how to accomplish it with a bash script.\nI have tried to do an online search but i guess i was choosing the wrong set of keywords. I did not manage to reach a tutorial or a reference that would mention this task.\nThanks in advance for your help!\nP.S: Any suggestions, references, notes, comments or tutorials would also be greatly be appreciated.\n\nA: For those who wants to accomplish this task, please follow the steps below:\nCreate an empty file and write the following simple bash script inside:\n#!/bin/bash\nxdotool key alt+shift+F12\n\nSave the file as \".sh\" and make it executable.\nYou can add any set of keys and this tool can also allow you to automate the mouse. You can create very useful scripts with it if used properly.\nHappy coding!\n\nCredits: Special thanks to @muru for teaching me how to write this script. \n\nTutorial: http://manpages.ubuntu.com/manpages/trusty/en/man1/xdotool.1.html\n", "Q: Really wanting Host Ubuntu to work with Win7 guest in VirtualBox, but it's not working out I have spent all day solving how to get the Win7 guest to recognize my USB devices, and finally managed it, re-installed VirtualBox 5.0.16, re-installed Win7 into it from my CD, installed the Extension Packages and added myself to the Vbox users group..followed all the instructions to the letter, and was happily testing my favourite program in Virtual box, TMPGEnc, which wouldn't run because not enough memory, so I upped the base memory allocation to 1024 as required, and it worked. I was even able to encode a short video, just to prove to myself that I had finally managed to get VirtualBox working as guest on Ubuntu host. I only need it for a few programs.  Then , I powered off the Virtual Box and when I went to start it again, there was no Win7, it had gone, and I was being asked to insert my disc to install a new machine all over again.  What could have happened? is this normal? Is there any way out of this without yet again going through another Win7 install? \nWJoe.\n\nA: Make sure that you previously didn't run virtualbox as sudo, otherwise it has created new profile settings in /root account. Just run sudo virtualbox to check if you can see your machine.\nAnother approach would be to look for the .vmdk or another possible guest disk files on the your system.\nEdit:\nSo previously you run VBox as sudo and the whole machine is probably in /root/VirtualBox VMs/<machine name> directory.\nYou can copy/move machine folder to your /home/<youruser>/VirtualBox VMs/ and change machine folder owner to you with \nsudo chown -R <user>:<user> <machinenamefolder> \nbeing inside your VMs folder. After that probably you need to double click on win7machine.vbox file inside VM folder to show it inside VBox.\n", "Q: Ubuntu Touch - Telegram new message count not reset after message has been read I have performed the Telegram update this morning. All went OK. However, I have noticed that I have an increasing total of notifications (on the Unity bar), that does not go when I read / reply to the messages. It appears to be keeping a total of all the messages I have received today, rather than showing me how may new/unread messages I have.\nHas anyone else noticed this and is there a fix for it?\n\nA: It's an old known issue. One workaround is to launch the telegram app from the the left unity sliding bar (where you see open and/or pinned apps) or the apps scope instead of the notification menu at the top.\n", "Q: powerwake is attempting to wake up an incorrect MAC addres When attempting to wake a remote machine (ubuntu server) from my laptop using powerwake host01.cluster I get a message back saying:  \nINFO: Trying to wake host: [host01.cluster]\nINFO: Sending magic packet to: [xxxxxxxxxxxx]\n\nUnfortunately, xxxxxxxxxxxx is an incorrect MAC address, and hence no remote waking up of the remote machine occurs.\nWhen I try using the IP address (powerwake 192.168.1.101) it also sends the magic packet to the wrong MAC address.\nI have the following line in /etc/hosts/ \n192.168.1.101   host01.cluster  host01\n\nHowever, I can ssh into the machine using both ssh host01, and ssh host01.cluster. I'm assuming /etc/hosts, which I have set up for static addresses (on my laptop) is being used here for resolution.\nWhen reading through man powerwake it provides a hierarchy of which caches it searches to resolve names:\n\n\n*\n\n*/var/cache/powerwake/ethers\n\n*/etc/ethers\n\n*or the arp table (arp -n)\n\n\nOn my laptop (uname -r -> 4.2.0-35-generic), bullet list item 1 is empty, 2 doesn't exist, and the incorrect MAC address doesn't even exist in the arp -n table either.\nIf I run sudo arp-scan -l on my laptop the incorrect MAC address doesn't show up there either.\nRunning sudo find /var/cache/ -type f -exec grep -il \"host01\" {} \\; turns up no results either.\nWhere else could a MAC address be cached buy ubuntu/powerwake?\nI would like to be able to purge the incorrect MAC address so that I can use powerwake to wake up this particular machine remotely.\nsudo ethtool eth0 run on the remote shows that WOL is enabled.\nSettings for eth0:\n    Supported ports: [ TP ]\n    Supported link modes:   10baseT/Half 10baseT/Full \n                            100baseT/Half 100baseT/Full \n                            1000baseT/Full \n    Supported pause frame use: No\n    Supports auto-negotiation: Yes\n    Advertised link modes:  10baseT/Half 10baseT/Full \n                            100baseT/Half 100baseT/Full \n                            1000baseT/Full \n    Advertised pause frame use: No\n    Advertised auto-negotiation: Yes\n    Speed: 1000Mb/s\n    Duplex: Full\n    Port: Twisted Pair\n    PHYAD: 1\n    Transceiver: internal\n    Auto-negotiation: on\n    MDI-X: off (auto)\n    Supports Wake-on: pumbg\n    Wake-on: g\n    Current message level: 0x00000007 (7)\n                   drv probe link\n    Link detected: yes\n\n\nA: I went digging through /usr/bin/powerwake (just a python script) and I found a reference to \"%s/.cache/ethers\", so I looked in my home directory ,and sure enough, this file was present (cat ~/.cache/ethers) that wasn't part of man powerwake.\nThis file held the incorrect reference for the IP address -> MAC address mapping that was causing the issue.\nSolution\nAnyway, I deleted the file ~/.cache/ethers, then \"warmed\" this cache file again.\nWarm the powerwake cache\nFirst I checked my arp table, as I had since cleared it, to see what was in there. None of the remotes I wanted to contact were listed, so I performed a simple ping -c 2 192.168.1.XXX on each machine I wished to wake (the remote machines need to be on and able to be pinged). This loaded them into the arp table (confirmed by arp -n).\nI then ran:\n\n*\n\n*powerwake 192.168.1.XXX for each machine\n\n*powerwake hostXX for each machine again\n\n*This allowed the ~/.cache/ethers file to be loaded with each entry that matches my /etc/hosts file on my laptop\n\n*Run cat ~/.cache/ethers to confirm the file exists and has been populated with the correct IP Addr -> MAC mapping\n\n", "Q: Can't Install anything from Ubuntu Software Center in Ubuntu 15.10 I just recently upgraded from Ubuntu 15.04 to Ubuntu 15.10, and now I can't install any software from Ubuntu software center or Terminal.  When I update, it is updating perfectly, but when I try to install any software from the Ubuntu software center, It says \"Check you Internet Connection\".\nThe screenshots are attached.\n\n\n\nA: Can you provide further details in the error window click on the arrow on Details please.\nTry the commands below in sudo to see if refreshing your apt-get cache and removing any packages that are no longer needed. \napt-get autoremove\napt-get clean\n\nOnce your done try update and upgrading via sudo in terminal.\napt-get update\napt-get upgrade\n\nIf errors come up in terminal please post in here please.\nThanks\n", "Q: thunderbird cant connect to e-mail-provider i am on u ubuntu 15.10 wily werwolf 64 bit.\nwhen i try to connect in thunderbird to my existing e-mailaccount\nthunderbird hangs while trying to connect to e-mail-provider.\n(i can acess my account with the web-site from my email-provider)\nAny help is welcome\nGreetings\nFranz\n\nA: Ok , here's what you need to do...\n\n\n*\n\n*enable IMAP\n\n*below steps are only for gmail ...\n\n*go to mail.google.com\n\n*sign in with your id \n\n*click on settings on the top right corner and then select Forwarding and Pop/Imap tab\n\n*Enable IMAP\n\n*then again open ThunderBird\n\n*enter your credentials \n\n*wait for a few minutes\n\n*give acess to thunderbird and you are done....\n\n", "Q: Grub rescue problem after deleting windows partition I accidently deleted the windows partition and now i am facing grub rescue problem.\nI used this commands\nGrub rescue> set root=(hd0)(msdos4)\nGrub rescue> set prefix=(hd0)(msdos4)\nGrub rescue> insmod normal\n\nAnd the diaplay was\nNo such partition\n\nls (hd0) (msdos4) displayed filesystem is ext2\n\nWhat should i do???\n\nA: The somehow easiest way would be to use Boot Repair Live CD /pen-drive  which you can find:\nand follow these steps described here\nBoot-Repair\nIf you need more detailed help let me know.\n", "Q: Dropbox fail in Ubuntu 12.04 I tried installing Dropbox in Ubuntu 12.04 in the computer that is provided by my university. I do not have root privileges. I tried to install it through Ubuntu Software Center. When I did a reboot this I have this dialogue:\n\nThe problem is that even if I press cancel, that process that is taking one whole CPU continues (see that in the image above as well). Any solution I see here about this problem implies using sudo password, which, I repeat, I do not have.\nIf I try to uninstall dropbox from Ubuntu Software Center that action remains waiting, because there is another action in progress: \"Searching. Applying changes\"\nIs there possibility to achieve this without having to use sudo?\n\nA: You want to kill a process owned as root without sudo.\nThis is impossible - either you are super user or have sudo powers, or you aren't.  If you aren't then you have to either let it finish the process... or do the much more evil option and shut off the system.\nIf a shutdown won't work then a power off will - you can damage the filesystem this way but the process will die - either with the power off of the \"halt all remaining processes\"  during shutdown.\n", "Q: ClamAV installation Ubuntu I am trying to install ClamAV in ubuntu as per the instructions in: \n\n\n*\n\n*blog.dutchcoders.io: Howto - Installing ClamAV from source\nWhile updating the virus databases using \n sudo freshclam -v\n\nI am getting \nCurrent working dir is /usr/local/share/clamav\nMax retries == 3\n\nClamAV update process started at Mon Apr 11 13:10:34 2016\n\nUsing IPv6 aware code\n\nRetrieving database.clamav.net/main.cvd\n\nnonblock_connect: connect timing out (30 secs)\n\nCan't connect to port 80 of host database.clamav.net (IP: 219.94.128.99)\n\nIgnoring mirror 219.94.128.99 (due to previous errors)\n\nTrying host database.clamav.net (27.96.54.66)...\n\nnonblock_connect: connect timing out (30 secs)\n\nCan't connect to port 80 of host database.clamav.net (IP: 27.96.54.66)\n\nTrying host database.clamav.net (203.178.137.175)...\n\nnonblock_connect: connect timing out (30 secs)\n\nCan't connect to port 80 of host database.clamav.net (IP: 203.178.137.175)\n\nTrying host database.clamav.net (211.239.150.206)...\n\nnonblock_connect: connect timing out (30 secs)\n\nCan't connect to port 80 of host database.clamav.net (IP: 211.239.150.206)\n\nTrying host database.clamav.net (120.29.176.126)...\n\nnonblock_connect: connect timing out (30 secs)\n\nCan't connect to port 80 of host database.clamav.net (IP: 120.29.176.126)\n\nWARNING: Can't download main.cvd from database.clamav.net\n\nTrying again in 5 secs...\n\nClamAV update process started at Mon Apr 11 13:13:09 2016\n\nUsing IPv6 aware code\n\nRetrieving database.clamav.net/main.cvd\n\nIgnoring mirror 120.29.176.126 (due to previous errors)\n\nIgnoring mirror 211.239.150.206 (due to previous errors)\n\nIgnoring mirror 27.96.54.66 (due to previous errors)\n\nIgnoring mirror 203.178.137.175 (due to previous errors)\n\nIgnoring mirror 219.94.128.99 (due to previous errors)\n\nWARNING: Can't download main.cvd from database.clamav.net\n\nTrying again in 5 secs...\n\nClamAV update process started at Mon Apr 11 13:13:15 2016\n\nUsing IPv6 aware code\n\nRetrieving database.clamav.net/main.cvd\n\nIgnoring mirror 27.96.54.66 (due to previous errors)\n\nIgnoring mirror 211.239.150.206 (due to previous errors)\n\nIgnoring mirror 120.29.176.126 (due to previous errors)\n\nIgnoring mirror 219.94.128.99 (due to previous errors)\n\nIgnoring mirror 203.178.137.175 (due to previous errors)\n\nERROR: Can't download main.cvd from database.clamav.net\n\nGiving up on database.clamav.net...\n\nUpdate failed. Your network may be down or none of the mirrors listed in  /usr/local/etc/freshclam.conf is working. Check http://www.clamav.net/doc/mirrors-faq.html for possible reasons.\n\nWhy is it so?? Is there any other way to resolve it??\nI dont want ClamTK. \nThe outcome of mirrors.dat file is\nMirror #1\nIP: 120.29.176.126\nSuccesses: 0\nFailures: 1\nLast access: Mon Apr 11 12:37:04 2016\nIgnore: Yes\n-------------------------------------\n>Mirror #2\nIP: 203.178.137.175\nSuccesses: 0\nFailures: 1\nLast access: Mon Apr 11 12:37:04 2016\nIgnore: Yes\n-------------------------------------\nMirror #3\nIP: 27.96.54.66\nSuccesses: 0\nFailures: 1\nLast access: Mon Apr 11 12:37:04 2016\nIgnore: Yes\n-------------------------------------\nMirror #4\nIP: 211.239.150.206\nSuccesses: 0\nFailures: 1\nLast access: Mon Apr 11 12:37:04 2016\nIgnore: Yes\n-------------------------------------\nMirror #5\nIP: 219.94.128.99\nSuccesses: 0\nFailures: 1\nLast access: Mon Apr 11 12:37:04 2016\nIgnore: Yes\n\nContents of freshclam.conf file is,\n##\n## Example config file for freshclam\n## Please read the freshclam.conf(5) manual before editing this file.\n##\n\n\n# Comment or remove the line below.\n#Example\n\n# Path to the database directory.\n# WARNING: It must match clamd.conf's directive!\n# Default: hardcoded (depends on installation options)\n#DatabaseDirectory /var/lib/clamav\n\n# Path to the log file (make sure it has proper permissions)\n# Default: disabled\n#UpdateLogFile /var/log/freshclam.log\n\n# Maximum size of the log file.\n# Value of 0 disables the limit.\n# You may use 'M' or 'm' for megabytes (1M = 1m = 1048576 bytes)\n# and 'K' or 'k' for kilobytes (1K = 1k = 1024 bytes).\n# in bytes just don't use modifiers. If LogFileMaxSize is enabled,\n# log rotation (the LogRotate option) will always be enabled.\n# Default: 1M\n#LogFileMaxSize 2M\n\n# Log time with each message.\n# Default: no\n#LogTime yes\n\n# Enable verbose logging.\n# Default: no\n#LogVerbose yes\n\n# Use system logger (can work together with UpdateLogFile).\n# Default: no\n#LogSyslog yes\n\n# Specify the type of syslog messages - please refer to 'man syslog'\n# for facility names.\n# Default: LOG_LOCAL6\n#LogFacility LOG_MAIL\n\n# Enable log rotation. Always enabled when LogFileMaxSize is enabled.\n# Default: no\n#LogRotate yes\n\n# This option allows you to save the process identifier of the daemon\n# Default: disabled\n#PidFile /var/run/freshclam.pid\n\n# By default when started freshclam drops privileges and switches to the\n# \"clamav\" user. This directive allows you to change the database owner.\n# Default: clamav (may depend on installation options)\n#DatabaseOwner clamav\n\n# Initialize supplementary group access (freshclam must be started by root).\n# Default: no\n#AllowSupplementaryGroups yes\n\n# Use DNS to verify virus database version. Freshclam uses DNS TXT records\n# to verify database and software versions. With this directive you can change\n# the database verification domain.\n# WARNING: Do not touch it unless you're configuring freshclam to use your\n# own database verification domain.\n# Default: current.cvd.clamav.net\n#DNSDatabaseInfo current.cvd.clamav.net\n\n# Uncomment the following line and replace XY with your country\n# code. See www.iana.org/cctld/cctld-whois.htm for the full list.\n# You can use db.XY.ipv6.clamav.net for IPv6 connections.\n#DatabaseMirror db.XY.clamav.net\n\n# database.clamav.net is a round-robin record which points to our most \n# reliable mirrors. It's used as a fall back in case db.XY.clamav.net is \n# not working. DO NOT TOUCH the following line unless you know what you\n# are doing.\nDatabaseMirror database.clamav.net\n\n# How many attempts to make before giving up.\n# Default: 3 (per mirror)\n#MaxAttempts 5\n\n# With this option you can control scripted updates. It's highly recommended\n# to keep it enabled.\n# Default: yes\n#ScriptedUpdates yes\n\n# By default freshclam will keep the local databases (.cld) uncompressed to\n# make their handling faster. With this option you can enable the compression;\n# the change will take effect with the next database update.\n# Default: no\n#CompressLocalDatabase no\n\n# With this option you can provide custom sources for\n# database files. This option can be used multiple times.\n# Default: no custom URLs\n#DatabaseCustomURL myserver.com/mysigs.ndb\n#DatabaseCustomURL mnt/nfs/local.hdb\n\n# This option allows you to easily point freshclam to private mirrors.\n# If PrivateMirror is set, freshclam does not attempt to use DNS\n# to determine whether its databases are out-of-date, instead it will\n# use the If-Modified-Since request or directly check the headers of the\n# remote database files. For each database, freshclam first attempts\n# to download the CLD file. If that fails, it tries to download the\n# CVD file. This option overrides DatabaseMirror, DNSDatabaseInfo\n# and ScriptedUpdates. It can be used multiple times to provide\n# fall-back mirrors.\n# Default: disabled\n#PrivateMirror mirror1.mynetwork.com\n#PrivateMirror mirror2.mynetwork.com\n\n# Number of database checks per day.\n# Default: 12 (every two hours)\n#Checks 24\n\n# Proxy settings\n# Default: disabled\n#HTTPProxyServer myproxy.com\n#HTTPProxyPort 1234\n#HTTPProxyUsername myusername\n#HTTPProxyPassword mypass\n\n# If your servers are behind a firewall/proxy which applies User-Agent\n# filtering you can use this option to force the use of a different\n# User-Agent header.\n# Default: clamav/version_number\n#HTTPUserAgent SomeUserAgentIdString\n\n# Use aaa.bbb.ccc.ddd as client address for downloading databases. Useful for\n# multi-homed systems.\n# Default: Use OS'es default outgoing IP address.\n#LocalIPAddress aaa.bbb.ccc.ddd\n\n# Send the RELOAD command to clamd.\n# Default: no\n#NotifyClamd /path/to/clamd.conf\n\n# Run command after successful database update.\n# Default: disabled\n#OnUpdateExecute command\n\n# Run command when database update process fails.\n# Default: disabled\n#OnErrorExecute command\n\n# Run command when freshclam reports outdated version.\n# In the command string %v will be replaced by the new version number.\n# Default: disabled\n#OnOutdatedExecute command\n\n# Don't fork into background.\n# Default: no\n#Foreground yes\n\n# Enable debug messages in libclamav.\n# Default: no\n#Debug yes\n\n# Timeout in seconds when connecting to database server.\n# Default: 30\n#ConnectTimeout 60\n\n# Timeout in seconds when reading from database server.\n# Default: 30\n#ReceiveTimeout 60\n\n# With this option enabled, freshclam will attempt to load new\n# databases into memory to make sure they are properly handled\n# by libclamav before replacing the old ones.\n# Default: yes\n#TestDatabases yes\n\n# When enabled freshclam will submit statistics to the ClamAV Project about\n# the latest virus detections in your environment. The ClamAV maintainers\n# will then use this data to determine what types of malware are the most\n# detected in the field and in what geographic area they are.\n# Freshclam will connect to clamd in order to get recent statistics.\n# Default: no\n#SubmitDetectionStats /path/to/clamd.conf\n\n# Country of origin of malware/detection statistics (for statistical\n# purposes only). The statistics collector at ClamAV.net will look up\n# your IP address to determine the geographical origin of the malware\n# reported by your installation. If this installation is mainly used to\n# scan data which comes from a different location, please enable this\n# option and enter a two-letter code (see www.iana.org/domains/root/db/)\n# of the country of origin.\n# Default: disabled\n#DetectionStatsCountry country-code\n\n# This option enables support for our \"Personal Statistics\" service. \n# When this option is enabled, the information on malware detected by\n# your clamd installation is made available to you through our website.\n# To get your HostID, log on http://www.stats.clamav.net and add a new\n# host to your host list. Once you have the HostID, uncomment this option\n# and paste the HostID here. As soon as your freshclam starts submitting\n# information to our stats collecting service, you will be able to view\n# the statistics of this clamd installation by logging into\n# www.stats.clamav.net with the same credentials you used to\n# generate the HostID. For more information refer to:\n# www.clamav.net/documentation.html#cctts \n# This feature requires SubmitDetectionStats to be enabled.\n# Default: disabled\n#DetectionStatsHostID unique-id\n\n# This option enables support for Google Safe Browsing. When activated for\n# the first time, freshclam will download a new database file (safebrowsing.cvd)\n# which will be automatically loaded by clamd and clamscan during the next\n# reload, provided that the heuristic phishing detection is turned on. This\n# database includes information about websites that may be phishing sites or\n# possible sources of malware. When using this option, it's mandatory to run\n# freshclam at least every 30 minutes.\n# Freshclam uses the ClamAV's mirror infrastructure to distribute the\n# database and its updates but all the contents are provided under Google's\n# terms of use. See www.google.com/transparencyreport/safebrowsing\n# and www.clamav.net/documentation.html#safebrowsing \n# for more information.\n# Default: disabled\n#SafeBrowsing yes\n\n# This option enables downloading of bytecode.cvd, which includes additional\n# detection mechanisms and improvements to the ClamAV engine.\n# Default: enabled\n#Bytecode yes\n\n# Download an additional 3rd party signature database distributed through\n# the ClamAV mirrors. \n# This option can be used multiple times.\n#ExtraDatabase dbname1\n#ExtraDatabase dbname2\n\nMoreover if try to run the command \n/usr/local/bin/freshclam --quiet -l         /var/log/clamav/freshclam.log \n\nit is showing \nERROR: Can't download main.cvd from database.clamav.net\n\n\nA: *\n\n*In freshclam.conf file find the line \n#DatabaseMirror db.XY.clamav.net\n\nand uncomment it.\n\n\n*\n\n*for IPv4:\nDatabaseMirror db.us.clamav.net\n\n\n*for IPv6 add this line too in your conf file \nDatabaseMirror db.us.ipv6.clamav.net\n\nReplace XY with your country code such as fi|in|us|jp\n\n*Save the file and run from terminal\nsudo freshclam -v\n\nNow you should be able to do the update to freshclam database.\n\nA: Try installing using apt-get tool;\napt-get update # apt-get install clamav\n\nlink: https://www.clamav.net/documents/installing-clamav#debian\n", "Q: BURG doesn't identify Windows 10 but GRUB2 finds windows 10 Well, I really hated GRUB2 's UI. So I thought of moving to BURG. I'm using Windows 10 with Ubuntu 15.10 and Kali-Linux Triple-boot. i installed BURG though https://insanelyi.com/topic/22925-grub-installing-burg-on-ubuntu-1510-configuration-tools/ . i installed it successfully, and BURG finds ubuntu 15.10 and kali linux, but it doesn't find windows 10.\nWindows 10 was pre-installed before installing ubuntu and windows 10 is in UEFI settings....\nthe thing is that GRUB2 finds all the three os and i am able to boot into it but when it comes to BURG , it only finds kali linux and ubuntu.....\nis there anyway to fix this??? \n\nA: AFAIK, BURG is abandonware. It's also, AFAIK, a BIOS-only boot loader. If your computer came with Windows 10 pre-installed, Windows is almost certainly booting in EFI mode, and so BURG, as a BIOS-only boot loader, won't be able to boot it.\nGRUB 2, by contrast, is being actively developed and is available for both BIOS and EFI systems. It can therefore handle the dual-boot task.\nThe good news is that there are many alternatives to GRUB 2, as described briefly in this question and answers, and in more detail in my Web page on the subject. If you wanted to use BURG because of its graphical menus, the best alternative may be my own rEFInd boot manager.\n", "Q: RT3290 Ralink driver in Ubuntu I have found that there is a large community suffering from the problems with the WiFi-Bluetooth card Ralink RT-3290. It has been a problem since 2012-2013.\nNone of the solutions I've found is simple, effective and durable.\nI managed, with great effort, some results. But when there is a kernel update, the problems return.\nCan anyone provide a simple , effective and lasting solution?\nIs there a project from Ubuntu's developers to attack the problem?\n\nA: Generally, the answer above is a steps in a correct direction. There are only two steps missing.\nStep-by-step solution\nOpen new terminal (Ctrl+Alt+T) and type as follows:\n sudo apt install git\n mkdir ~/tmp\n cd ~/tmp\n git clone https://github.com/alinefr/rtbth.git\n cd rtbth\n make\n sudo make install\n sudo cp -r ~/rtbth /usr/src/rtbth-3.9.3\n sudo dkms install rtbth/3.9.3\n sudo nano /etc/modules\n\nAdd rtbth to the end of the file, then Ctrl+o and ENTER (to save the file) and Ctrl+X to close the editor\nThen reboot and the new driver will be loaded.\nThis one worked for me to get the Bluetooth to be active and find devices, however, I didn't succeeded to pair my Jabra play clipper with it, but that might be due to the Jabra device problems.\nAnyway, you can try it out and share your progress with us\n\nA: I also was facing the same problem and I tried all the solution I could find and still could not solve it, most I was able to reach was that all the Bluetooth devices were showing but I was not able to connect to any of them.\nBut I just today finally found something that works and is very easy to install, it is located on github rtbth-dkms.\nTo Install,\nsudo add-apt-repository ppa:blaze/rtbth-dkms\nsudo apt-get update\nsudo apt-get install rtbth-dkms\n\nand then follow the Init commands below, your BlueTooth will work now, in case of any problem leave a comment,  I will be happy to help you.  \nUsage\n# Init\nsudo modprobe rtbth\nsudo rfkill unblock bluetooth\nhcitool dev # check\n\n# Switch off\nsudo rfkill block bluetooth\n\n# Switch on\nsudo rfkill unblock bluetooth\n\n# Shutdown\nsudo pkill -2 rtbt\nsudo rmmod rtbth\n\n\nA: For bluetooth support there is an updated rtbth version for latest kernel versions (it works in my 4.4.6)\nHere is the URL: https://github.com/alinefr/rtbth\nFrom Ubuntu you need to\nmake\nsudo make install\nsudo dkms install rtbth/3.9.3\n\nThe kernel module is called rtbth\nFor Wireless support, latest kernel from Ubuntu 16.04 LTS (Xenial Xerus), at the moment, 4.4.0 should work out of the box with rt2800pci module.\n\nA: I am using 16.10.\nYou should replace\nHCI_BREDR\n\nwith\nHCI_PRIMARY \n\nin rtbth_core_bluez.c.\n", "Q: Openstack: An error occurred authenticating. Please try again later I've installed & re-installed Openstack following (https://help.ubuntu.com/lts/clouddocs/installer/en/single-install.html) on an Ubuntu 14.04 distribution and after being logged in the dashboard, suddenly I lose access (webpage freezes) and I cannot log in again (\"An error occurred authenticating. Please try again later.\"). Keystone & Dashboard appear to be started according to the Openstack installer. \n\nA: Share the keystone logs which can help us to debug the issue.\nRestarting keystone service often helps in such situations if there is not any serious issue.\n", "Q: Apache2 ist still showing the default index.html after replacing it In the root folder of the Apache I replaced the /var/www/html/index.html by my own index.html file and delted the old index.html. After that I restarted the Apache server. \nWhen I now call the server by ipAdress there is still the default index.html.\nWhen I call the server by ipAdress/index.html I will get the new index.html. \nHow can I change the config, that the server delivers by call up via ipAdress the new index.html?\n\nA: Is your web browser caching the old page? Try holding Shift and clicking the reload button.\n", "Q: Windows 10 is not showing after installing Ubuntu 15.04 I successfully installed Ubuntu 15.04 on my Lenovo ThinkPad E430 laptop. Now I am facing problem that Windows 10 (which was already installed on my machine) is not showing in grub. I already tried to fix grub, but it did not succeed.\nI installed Ubuntu on separate drive.\n\n\nA: \"Well , we need to forget something in order to get something...\"\n\n\n*\n\n*restart\n\n*press f12 ( go to the boot menu)\n\n*select windows \n\n\nIt's always better to perform a backup of your files\n", "Q: Installing PHP 5.6 on Xenial (16.04) I need to use php5 (5.6) because I'm working on a Drupal 7 project which doesn't support php7. The problem is I recently updated to ubuntu 16.04 Xenial which seems to no longer support php5. \nI tried to install it from this repo, however when It try to install it with apt I always get similar errors.\n$ sudo apt-get install php5-cli\nCependant les paquets suivants le remplacent :\n  php7.0-cli:i386 php7.0-cli`\n\nWhich means it's obsolete. How can I install PHP 5.6 on Xenial?\n\nA: You can even consider using vagrant (or similar technology) to assist in using both versions at the same time. Vagrant is essentially a VM client designed to help spin VM's up and down quickly and easily with project based configuration; i.e. you can configure a VM specifically for a project and each VM can be different per project if need be.\nThis means that you can develop a project and test it on your local machine using the same production configuration as the project will be run under. Not only is this great for yourself but also means that a team of developers can always test under the same circumstances as the VM configuration is portable and cross-platform (it's just a text file).\nOnce vagrant and virtual box are installed, it's as easy as running:\nvagrant init ubuntu/trusty64; vagrant up --provider virtualbox\n\nand once the vm is up and running you can use:\nvagrant ssh\n\nand you can now manually install apache, php and mysql. You can also define a provisioning configuration, so that when you enter:\nvagrant up\n\nthe VM builds itself as well as installs all the binaries you need and can even do a git clone of your code, setup networking so you can view the application in your browser, etc.\nFor more detailed information look here: https://www.vagrantup.com/docs/getting-started/\n\nA: You can use XAMPP Linux.You can download any version of xampp linux from the below mentioned official xampp site.\nhttps://www.apachefriends.org/download.html\nEnter downloaded file location using terminal.\nFirst give certain permission for the downloaded binary file. (Assume that i downloaded 64 bit binary package.)\nsudo chmod a+x xampp-linux-x64-5.6.23-0-installer.run\n\nThen install the xampp\nsudo ./xampp-linux-x64-5.6.23-0-installer.run\n\nIf you are download 32 bit binary file do below mentioned like this\nsudo chmod a+x xampp-linux-5.6.23-0-installer.run \nsudo ./xampp-linux-5.6.23-0-installer.run\n\n\nA: Remove all the stock php packages\nList installed php packages with dpkg -l | grep php| awk '{print $2}' |tr \"\\n\" \" \" then remove unneeded packages with sudo aptitude purge your_packages_here or if you want to directly remove them all use :\nsudo apt-get purge `dpkg -l | grep php| awk '{print $2}' |tr \"\\n\" \" \"`\n\nAdd the PPA\nsudo add-apt-repository ppa:ondrej/php\n\nIf you get add-apt-repository: command not found run the following command first :\nsudo apt-get install software-properties-common\n\nInstall your PHP Version\nsudo apt-get update\nsudo apt-get install php5.6\n\nYou can install php5.6 modules too for example\nsudo apt-get install php5.6-mbstring php5.6-mcrypt php5.6-mysql php5.6-xml\n\nVerify your version\nIf you have installed php5.6-cli\nsudo php -v\n\nIf you don't have php5.6-cli, put this on a .php file\n<?php \n      //outputs php configuration info\n      phpinfo(); \n?>\n\n\nA: Run the following commands:    \n$ sudo apt-get install python-software-properties\n$ sudo add-apt-repository ppa:ondrej/php\n$ sudo apt-get update\n$ sudo apt-get install -y php5.6\n\nCheck your PHP Version\nphp -v\n\n", "Q: Failure while apt-get update Just installed server 14.04 LTS on server i have, but everytime i try to use \"apt-get update\" it fails with the output:\n....    \n    Reading package lists... Error!\n    E: Encountered a section with no Package: header\n    E: Problem with MergeList /var/lib/apt/lists/us.archive.ubuntu.com_ubuntu_dists_trusty_universe_i18n_Translation-en\n    E: The package lists or status file could not be parsed or opened.\n\nI also tried multiple times to that Solution:\nrm /var/lib/apt/lists/* -vf && apt-get update\n\nI got the same error:\n.....\nGet:67 http://us.archive.ubuntu.com trusty/multiverse Translation-en [102 kB]                                                                  \nGet:68 http://us.archive.ubuntu.com trusty/restricted Translation-en [3457 B]                                                                  \nGet:69 http://us.archive.ubuntu.com trusty/universe Translation-en [4089 kB]                                                                   \nFetched 32.7 MB in 3min 43s (146 kB/s)                                                                                                         \nReading package lists... Error!\nE: Encountered a section with no Package: header\nE: Problem with MergeList /var/lib/apt/lists/us.archive.ubuntu.com_ubuntu_dists_trusty_universe_i18n_Translation-en\nE: The package lists or status file could not be parsed or opened.\n\nAny Ideas?\nEdit\napt-get install -f\nReading package lists... Error!\nE: Encountered a section with no Package: header\nE: Problem with MergeList /var/lib/apt/lists/us.archive.ubuntu.com_ubuntu_dists_trusty_universe_i18n_Translation-en\nE: The package lists or status file could not be parsed or opened.\n\n\nA: Run:\nsudo apt-get install -f \nsudo apt-get clean\nsudo apt-get update\nsudo apt-get upgrade\n\nGood luck.  \n\nA: Run these commands:\nsudo rm -f /var/lib/apt/lists/*\nsudo apt update\n\n\nA: Thanks to Mr. Grunnar's idea, and also thanks to that answer to change the Ubuntu's mirrors,\nI did that:\nsed -i 's/http:\\/\\/us./http:\\/\\//g' /etc/apt/sources.list\n\nRemoving all \"us.\" perfix in the file, and made it pointing to the mainserver itself,\nAnd it fixed my issue,\n", "Q: How to : Change Gnome Desktop icons to Ubuntu default icons I just installed Gnome Desktop in Ubuntu 14.04 LTS. I like it, but the icons looks a bit antique. I would like to change them to default Ubuntu icons ( Cinnamon allows it ). Can someone help me with it please ?\n\nA: As has been pointed out by muru this can be achieved by using the gnome-tweak-tool:\nsudo apt-get install gnome-tweak-tool\n\nand then selecting the preferred icon theme:\n\n", "Q: Ubuntu on USB - partitioning I am thinking of using a bootable USB drive for Ubuntu, but I have a quick question about partitioning the drive. I am using a 32GB flash drive. How much should I partition the drive, and what would be the purpose of partitioning it? For example, why not just leave the drive un-partitioned and use Ubuntu as such? Thank you.\n\nA: Don't fully understand what you need, but,\nUbuntu on USB flash drives can be used in two kinds:\n\n\n*\n\n*As a live-bootable media.\n\n*Full Installation media.\n\n\n#1 is the one, which you create using startup-disk-creator or UnetBootIn, and changes you make in a session are only confined to the size of persistent file you specify at the time of creation of the bootable usb drive. To know how to create partition on the installation media follow this link #2 is, what you get when you install ubuntu using a live-cd or live-usb to another usb drive. Here you can partition your usb drive just like you would do on another on-board hard drives.\n", "Q: How can I mount NFS directory on Unity? An NFS directory is shared by a SPARC server.\nUtilizing a Samba application, it is not a problem to link a folder shared by an MS-Windows server.\nBut, it is hard to link a directory shared by an NFS server on Unity.\nWhat should I do to link?\n\nA: Not really. First you need to install the package nfs-common:\napt-get install nfs-common\n\nIf the nfs server is already set, you need to add this  line on the /etc/exports to allow your client to access:\n/File_to_share_on_the_server/ 192.168.1.x(rw,all_squash,anonuid=1000,anongid=1000,sync)\n\nReplace 192.168.1.x by your client's IP.\nI guess this step can be  done by the GUI on your Sparc server.\nOn your client, just need to mount your share now:\nTemporary:\nmount -t nfs -o rw 192.168.x.x:/File_to_share_on_the_server /mnt/yourfolder\n\nPermanent:  Add a line in your  /etc/fstab :\n192.168.x.x:/File_to_share_on_the_server      /mnt/yourfolders    nfs     defaults  0 2\n\nThis time 192.168.x.x must to be replace by the IP of your server. You can find lots of tutorial on the web to install & configure nfs... \n", "Q: Permission denied when running \"./script.sh\", but works when running \"bash script.sh\" I've got an issue executing a simple .sh file\nHere is my example :\nI'm creating a simple \"abc.sh\" file for creating a folder\n echo 'mkdir abc' > abc.sh\n\nAccording the executable bit\n chmod +x abc.sh\n\nTrying to run the sh file\n ./abc.sh\n\nPermission denied (french version)\n bash: ./abc.sh: Permission non accordée\n\nBut when I do \"bash ./abc.sh\" instead of \"./abc.sh\", the script is running\nHave you an idea for this ?\n\nA: Issue resolved..\nI just found this post : https://unix.stackexchange.com/questions/203371/run-script-sh-vs-bash-script-sh-permission-denied\nThe filesystem was mounted with the \"noexec\" param.\n", "Q: In the sentence \"ls -Ral /bin > TalhaA452.txt\" what does -Ral do? I dont know what this word means in the sentence \"ls -Ral  /bin > TalhaA452.txt\" \n\nA: This command list directory contents of bin folder and put contents in a file called TalhaA452.txt\nAccording to man ls, the switches do:\n-R, --recursive\nlist subdirectories recursively\n\n-a, --all\ndo not ignore entries starting with .\n\n-l    \nuse a long listing format\n\n\nA: From man ls\n-a, --all\n              do not ignore entries starting with .\n-R, --recursive\n              list subdirectories recursively\n-l     use a long listing format\n\nIt means that it will generate a list of all files under /bin recussively going in sub-directories and save that list in the TalhaA452.txt text file.\n", "Q: I have Nvidia Geforce on Ubuntu 14.04 , But don't know how to use it or install it on Ubuntu. Please help? I have an Nvidia GPU and Intel CPU but I don't know how to enable or install them on Ubuntu 14.04. I don't know anything , I want to play Dota 2 .. so wanted to get my Nvida geforce to work.. I don't even know the model of my laptop. \nThe output to lspci -k | grep -EA2 'VGA|3D' is:\n00:02.0 VGA compatible controller: Intel Corporation 3rd Gen Core processor Graphics Controller (rev 09)\n    Subsystem: Hewlett-Packard Company Device 21bc\n    Kernel driver in use: i915\n--\n01:00.0 3D controller: NVIDIA Corporation GF117M [GeForce 610M/710M/820M / GT 620M/625M/630M/720M] (rev ff)\n07:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8101E/RTL8102E PCI Express Fast Ethernet controller (rev 07)\n    Subsystem: Hewlett-Packard Company Device 21bc\n\n\nA: The intel open source graphics drivers are already installed.  \nTo install the NVIDIA drivers - open a terminal and execute :  \nsudo apt-get update  \nsudo apt-get install nvidia-352  \nsudo reboot  \n\nExecute this command : lspci -k | grep -EA2 'VGA|3D' \nYou will additionally see : Kernel driver in use: nvidia \nThe complete output will show you something like this :  \nlspci -k | grep -EA2 'VGA|3D'  \n00:02.0 VGA compatible controller: Intel Corporation 4th Gen Core Processor Integrated Graphics Controller (rev 06)  \nSubsystem: CLEVO/KAPOK Computer Device 3501  \nKernel driver in use: i915  \n\n01:00.0 3D controller: NVIDIA Corporation GM107M [GeForce GTX 860M] (rev a2)  \nSubsystem: CLEVO/KAPOK Computer Device 3501  \nKernel driver in use: nvidia\n\n", "Q: Auto screen rotation Dell Inspiron 7347 I have purchased this notebook and decided to use linux on it. The problem is the auto screen rotation and the Keyboard.\nIn windows, when I turn it to tablet mode, it enables the on-screen keyboard and also auto-rotates the screen.\nI read in this topic link here and here that there is a batch script for this, but I have no clue on how to do that and if that will work on ubuntu (I'm new to linux). \nAny ideas? \n\nA: I upgraded 16.04 to 18.04 and i faced same issue. Screen rotation automatically.\nSo i tried basic solution. Go to Displays->Resolution and change screen resolution 1366*768(16:9) to 1360*768(16:9). Now my system is working fine.\n", "Q: Cronjobs not showing up using crontab -u  -l I added some jobs directly to the \n/etc/crontab\n\nfile. They are running fine. However, I cannot see them if I use the ‍‍‍‍‍‍‍‍crontab‍‍ command \ncrontab -u <user> -l\n\nDo I have to reindex the file somehow or could this be caused by bad formatting?\n\nA: User crontabs are stored in /var/spool/cron/crontabs/. You can't use the crontab command to see or edit the system crontab /etc/crontab.\nNote that only the system crontab contains a user field after the date. User crotab entries  are always run the corresponding user so they don't need an user field.\n\nA: No, you are using TWO different systems.\ncrontab -u <user> -l\n\nwill list all jobs added with crontab -e.\n/etc/crontab\n\nis not part of crontab but from another procedure.\nBoth are there for historical compatibility. And the big difference is permissions. User cron jobs will run with the permissions of that user, system cron jobs run with the permissions of root. /etc/crontab tried to solve that by adding a \"user\" to the colunms. \nI would advice to pick one and stick with it. It can get messy rather quickly. My favourite is /etc/crontab unless you need to hide something then I would use  crontab from \"root\".\n\nA: This is normal. When you add lines on the /etc/crontab it's not really attribuate to a profile  but the system.\nIf you want to add a  crontab to an user:\ncrontab -e -u  <user>\n\nThe users' crontab are stored on the folder  /var/spool/cron if  you  want to see the files.\n", "Q: Mouse undetected, Graphics crazy - trying to save my dinosaur desktop Thanks in advance for your help on this one!\nI've been trying to save my HP Pavilion a1540n, retiring it purely to word processing in my office. The sequence of events was triggered when I tried to upgrade to Ubuntu 14 and the desktop environment became very slow (I was warned the graphics card was not supported). Since then I've tried downgrading to several systems (everything from 10-13) and have encountered different but more crippling graphics problems (screen gets frozen blocks of colorful fuzz or other disorganized patterns of color). I've wound up on Ubuntu 11 and my mouse is not responding (although the keyboard is and I can use the terminal). The mouse works in boot repair envt so it's not a physical malfunction. If I could get any operating system where the graphics and mouse are modestly functional I'd be quite satisfied.\n\nA: The problem with Ubuntu 14.04 probably isn't driver related, it's more likely to be that the demands on your graphics card are too great. As you go back through older unsupported versions, there will be less and less hardware supported, which may explain the mouse problems.\nI'd recommend installing either Lubuntu or Xubuntu which are both lightweight desktop environments. Lubuntu is slightly less resource hungry than Xubuntu, so is often a better choice for older PCs, but it does have quite a plain feel to it. Xubuntu definitely looks more swish. Whichever you choose, I'd recommend downloading LibreOffice for word processing etc.\nAs a side note, it's generally not a good idea to use an old unsupported release, security fixes aren't maintained, and you can't ask questions about them on Ask Ubuntu either! Using an LTS version is the best way to guarantee stability in your system, 12.04 and 14.04 are the current LTS releases, and 16.04 is just around the corner (it's in final Beta testing at the moment). Personally I normally wait for the first point (16.04.1) release of a new version to give it time for bugs to be ironed out.\n", "Q: Managing Information: voicemail-mp3's/transcripts/notes + txt msgs. Do I need a database? I'm looking to manage a large collection of recorded voicemail messages, which come along with machine generated transcripts and to which I have added my notes.  I also have text messages and letters in odt format.  I need to associate tags with these objects and then search on both the text and the tags.  \nIn other words, I'm looking for something like a large \"spreadsheet\" in which I can insert mp3's/associated transcripts & notes, odt's and txt messages, associate tags with those objects, and then search.  I'll also need to export subsets of that \"spreadsheet\" selected out via a search.\nAm I looking for a database, and if so what kind?  I'm looking at MongoDB right now, but still not clear if it can do what I'm looking for.  \"Documents\" in MongoDB are just text strings.\n\nA: It seems I'm in an awkward situation in which I've got enough data with enough structure that it's too big for the standard spreadsheet, but it's barely big enough to warrant my learning database design.  I've decided to plunge ahead anyway, since learning it'll no doubt come in handy at some point.\nOne thing I think I have cleared up is that databases only hold text data.  They may link via a URI to some more complex objects, like videos or graphics, but their \"records\" (or so-called \"documents\" in the case of a \"Document Store\" database like MongoDB) are just glorified csv's.  There is one exception in that some DB's allow for inserting images, but even then it slows things down and makes the database large and bulky, so better to keep them separate and link to them.\nFinally, the database itself is separate from the client which interacts with the database.  The interface could just be a shell/cli, but there are also many GUI's out there, like Robomongo for MongoDB, or DBeaver which is a \"universal\" client that can interact with many different kinds of DB.  LibreOffice Base is itself a simple client which is packaged with a front end that offers the option to create an instance of a few different kinds of DB.\nI got a lot more to learn, but I think I've at least got the tour guide map to get me going.  If anyone's got anything to add, I'd certainly appreciate it!\n", "Q: Accessing a LAMP webserver that's behind a Ubuntu VM acting as a firewall I currently have two VM's set up in the following manner:\n                               /-----------------------\\\n      /-----------------\\      |  Ubuntu VM            |      /---------------\\\n      |   Workstation   |------|  eth1 : 192.168.0.x   |      |  Web Server   |\n      |   192.168.0.x   |      |  eth0 : 169.254.71.x  |------| 169.254.71.x  |\n      \\-----------------/      |                       |      \\---------------/\n                               \\-----------------------/\n\nAnd I am having some trouble accessing the web server from my local machine. \nThe ubuntu is configured through virtualbox to have 2 network adapters, the first set to internal network, and the second set to a bridged connection. This gives me two wired connections once inside the vm, and I set the first one (corresponding to the internal network) as 'link local only', and the second as automatic DHCP. \nThe webserver is running turnkey linux LAMP os, with the network adapter configured to internal network, with the network having the same name as the ubuntu internal network.\nI have followed this tutorial (switching eth0 and eth1 where appropriate) to enable me to ping from the webserver to the outside world. I can ping to both my local machine and any website on the internet from the webserver.\nNow my problem comes from trying to do the reverse of above. I have been trying to no avail for quite some time, using resourses such as this and a couple others to enable me to connect to the webserver from my local machine. When I try to ping the 169.254.71.x address of my webserver, it doesn't connect.\nI realize that my problem is probably in my NAT configuration on the ubuntu machine, or my port forwarding configuration on my ubuntu machine, but I do not know how to fix these issues. \n\nA: So I ended up figuring out my problem, just posting an answer for anyone else potentially having the issue. \nThe command:\niptables -t nat -A PREROUTING -d outerip -p tcp --dport 80 -j DNAT --to webip\n\nWas what eventually allowed it to work. This rule appends the prerouting table to allow connections from the outer ip of the firewall, as long as they are tcp packets destined for port 80, to be directly NAT'd across the firewall to the webserver IP. \nIT should also be noted that I changed the internal facing adapter of my firewall from \"link local only\" to \"shared with other computers\" This assigned that eth adapter an address of 10.42.0.x, instead of 169.254.x.x. I'm not sure if that fixed any functionality, another user suggested that I get off the 169.254.x.x address field.\n", "Q: \"bash: ... No such file or directory\" returned for all files and directories! I know there are similar questions but mine appears to be a different problem, as I get this error message for all files and directories that I try. I have been trying to install a very particular package in R and have thus been executing commands which I don't fully understand. Now, when I type a simple command such as \ncd /Desktop\n\nit returns\nbash: cd: /Desktop: No such file or directory\n\nAgain, it returns this for all files. What have I done?\n\nA: Do cd Desktop and not cd /Desktop. \n", "Q: Gnome shell text getting messed up image showing messed up ubuntu gnome shell text\n\nim facing this problem since recent upgrade, all texts related to gnome top panel,overlay and gnome shell get messed up, only few letters are displayed.\njust au[blank spaces for missing letters]s is being displayed for audacious in gnome search results. Whatever i type in the search bar get messy too.\ni dont face this everytime i use ubuntu. the last time i faced the problem i ran software update and the problem got solved. It worked fine for a few days but i got the problem back.\ntext in applications are fine.\n\nA: I'm suffering the same issue and I'm debugging it. While I haven't found the root cause, I've found that the issue is in cogl's glyph cache for Pango. You can use a debugger to clear this cache. I'm going to detail the steps here, but I should warn you that this is a bit of an expert option.\nPreparation you need to do once to make the workaround work:\nsudo apt-get install gdb gnome-shell-dbg libclutter-1.0-dbg libcogl-pango20-dbg\n\nThen whenever you run into the issue, clear the font cache by running the following command line:\nsudo gdb -p `pgrep -u $USER -x gnome-shell` <<<\"print /r _cogl_pango_renderer_clear_glyph_cache((CoglPangoRenderer*)(_cogl_pango_font_map_get_priv(clutter_context_get_pango_fontmap())->renderer))\"\n\nThis works splendidly for me, but I should warn you that if this command goes awry for any reason, it may hang your system. If that happens, a reboot is the only thing that fixes it.\nI'm going to investigate further what, exactly, is wrong with the glyph cache, and open a bug report upstream.\nHope that helps!\nExplanation of the command line: the part between backticks finds the process id for gnome-shell. That is used to attach the debugger gdb to the process; you need to be root (sudo) to do that. The part between <<<\" and \" is the function call for clearing the glyph cache.\n\nA: I was facing a similar problem. To fix the issue, restart the gnome shell. Press Alt+F2, enter r, and press return/enter. I do not think this is a permanent solution, but it will get your text back.\n", "Q: Command after apt-get install is not executing in script I wrote a question on Server Fault, but I guess it's more applicable for this community.\nI'm writing a script which is meant to initially set up my Droplet. In the script, I'm opening SSH connection with my Ubuntu 14.04 server as follows (with USER and REMOTE variables previously defined):\nssh -t -t $USER@$REMOTE <<'ENDSSH'\nENDSSH\n\nInside of that SSH connection, I have multiple commands which I want to execute - installing Node.js, updating npm, installing MongoDB and so on.\nBut, once I do a apt-get install command, other commands do not get executed.\nSo, if I have this:\nssh -t -t $USER@$REMOTE <<'ENDSSH'\nsudo apt-get update\nsudo apt-get install -y nodejs\nsudo apt-get install -y npm\nENDSSH\n\nCommand sudo apt-get install -y npm won't be executed. Now, I know that I can install multiple packages within the same apt-get install command, but this is not what I'm asking, since other commands afterwards won't get executed than. This example I just wrote out of simplicity so I can explain my problem. Concretely, I have these commands:\nssh -tt $USER@$REMOTE <<'ENDSSH'\ncurl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -\nsudo apt-get install -y nodejs\nsudo npm install -g npm\nENDSSH\n\nCommand sudo npm install -g npm and everything following it never gets executed.\nI came across questions like this one where they say I should put multiple -t flags (or -tt) when opening ssh connection, which I'm doing, but that doesn't help.\nWhat am I doing wrong?\n\nA: You might want to end your lines with && so the script only advances when the command is done. Example:\nssh -t -t $USER@$REMOTE <<'ENDSSH'\nsudo apt-get update &&\nsudo apt-get install -y nodejs &&\nsudo apt-get install -y npm\nENDSSH\n\n", "Q: How do I make VLC play a HEVC video properly? I installed the plugin using this\nsudo apt-get install vlc-plugin-libde265\n\nand it has started working. But the video quality is absolutely horrible: http://imgur.com/a/945ER  (both the pictures are supposed to be split)\nDid I just get a bad video file, or is this the fault of the plugin?\nIf not, how do I convert a HEVC to MP4?\n\nA: To see is problem in plug-in reinstall it then run that file. \nIf you want to convert video to MP4 use OpenShotVideoEditor you can download it in your ubuntu software center. Open that video with it then go\nFile/Export video... then choose which format you want to convert and press ok. If you need more help text me.\n", "Q: Terminal - Selecting commands I've entered using the keyboard I can highlight text I've entered in the terminal with my mouse and then use ctrl + shift + c to copy to the clipboard and that was fine for a while. But I've tried highlighting text by pressing shift and ctrl + shift like you can do in text editors. Neither seems to work. Having a keyboard shortcut for copying terminal commands I've entered would be much easier than dragging the mouse everytime I want to copy something. Is there any way to do that using the keyboard? I've tried using ctrl + u followed by ctrl + y, but that doesn't copy text to the clipboard, so I can't use that anywhere  but the terminal. \n\nA: There is a set of shortcuts for terminal , and they are organized around the current cursor position.\n\n\n*\n\n*You can use CtrlK shortcut to cut the text from cursor to end of line\n\n*CtrlU cuts from current position to beginning of line.\n\n*Paste with CtrlY\nThese two are pretty useful in particular when you want to either copy the command or its arguments.\nIf you are proficient with vim text editor, you can edit the command you want in a more powerful way by evoking vim with fc command.\nFor using the command outside the terminal, you might want to use xclip command (not installed by default) . For instance, \n$ echo \"some_command\" | xclip -sel clip\n\nOnce you have xclip you can add the following function to your .bashrc file\nto_clipboard() {\n    xclip -sel clip <<<\"$@\" \n} \n\nWhat this does is it will copy whatever you put in front to clip board. You can use that in combination with the shortcuts above to cut test, paste it in front of the function, and it will be added to your clipboard. Small example\n$ to_clipboard echo 'hello world'\n\n", "Q: How exactly do I install an epson wf-2630 printer onto my new ubuntu studio OS? I've read that there's some sort of package that has to be installed before I can even get the \"linux version\" of setup file or drivers, but nothing I see tells greenhorns where to go do this stuff at.  Where is my \"source file\" list for example, and how do I access it?  Can someone give me step by step instructions that don't assume I know where things are and includes all the steps, not just part of the process??  Thanks so much!\n\nA: Try this:\nStep 1: Boot into Ubuntu \nStep 2: Open a terminal, Press Ctrl+Alt+T\nStep 3: Login as user with administrator permissions.\nsudo -i\n\nStep 4: Install the previous packages needed:\napt-get update\napt-get install --reinstall firefox cups lsb gdebi sane simple-scan\n\nStep 5: Navigate to these sites and download the packages for 32 or 64 bits according to their distribution:\nfirefox    \nhttp://download.ebz.epson.net/dsc/du/02/DriverDownloadInfo.do?LG2=ES&CN2=&DSCMI=43797&DSCCHK=b349e6644abd5c99e22fee221df756e1130c0725\nepson-inkjet-printer-escpr_1.6.4-1lsb3.2_i386.deb\nor\nepson-inkjet-printer-escpr_1.6.4-1lsb3.2_amd64.deb\n\nhttp://support.epson.net/linux/en/iscan_c.html\nhttps://download2.ebz.epson.net/iscan/general/deb/x86/iscan-bundle-1.0.0.x86.deb.tar.gz\nhttps://download2.ebz.epson.net/iscan/general/deb/x64/iscan-bundle-1.0.0.x64.deb.tar.gz\n\nStep 6: Untar the file .deb.tar.gz\ncd /home/user/Downloads\ntar zxf iscan-bundle-1.0.0.x86.deb.tar.gz\nor\ntar zxf iscan-bundle-1.0.0.x64.deb.tar.gz\n\nStep 7: Install the files.deb whith gdebi:\nClick the right mouse button. Select install with gdebi.\n\nStep 7: Run Firefox and select your printer:\nfirefox\nEnter the address: localhost:631\n\n", "Q: Pygame text processing I am trying to write a python/pygame program to simply display text. I want it to work so that when you type, for example, the letter \"A\", it appears on screen (kinda like gedit/notepad/whatever). I am doing this by appending the letter to a string which then gets rendered and put onto the screen. However, I have problems with actually getting user input. I know that there is the pygame.key.get_pressed() function, but I can only figure out how to use it if you actually know what key you want the user to be pressing (for example W to go forward), but not if I don't know. If that is confusing, here is my code:\nimport pygame\nimport sys\nfrom pygame.locals import *\n\npygame.init()\nscreen = pygame.display.set_mode((600,500))\nmyfont = pygame.font.Font(None, 60)\ninp = \"\"\n\nwhile True:\n    for event in pygame.event.get():\n        if event.type == QUIT:\n            sys.exit()\n\n    keys = pygame.key.get_pressed()\n    inp = inp + #THE PRESSED KEY\n    screen.fill((0,0,200))\n    txt = myfont.render(inp, True, (255,255,255))\n    screen.blit(txt, (100,100))\n    pygame.display.update()\n\nI want to figure out how to get the \"pressed key\" to get appended to the string.\n\nA: You could use the KEYDOWN event for this because pygame.key.get_pressed() will give you results at the speed of the current FPS.\nHere is a working example modified from your code:\nimport pygame\nimport sys\nfrom pygame.locals import *\n\npygame.init()\nscreen = pygame.display.set_mode((600,500))\nmyfont = pygame.font.Font(None, 60)\ninp = \"\"\n\nwhile True:\n    for event in pygame.event.get():\n        if event.type == QUIT:\n            sys.exit()\n        if event.type == pygame.KEYDOWN:\n            inp += event.unicode\n\n    screen.fill((0,0,200))\n    txt = myfont.render(inp, True, (255,255,255))\n    screen.blit(txt, (100,100))\n    pygame.display.update()\n\nOnly changed this:\n\n\n*\n\n*Removed you pygame.key.get_pressed() call\n\n*Added the pygame.KEYDOWN event check\n\n", "Q: How to remove all but number from hexdump output? I have got the base64 output for a huge file, the output is also obviously huge and in a file of its own, I wanted to convert the big number in it to base10 so I have now used hexdump to get it into base16 format... But the output looks something like this:\n0077000 0022 00de 0000 0000 de00 0800 0000 0000\n0077010 0008 0473 0c16 221f 0200 0000 0001 0100\n0077020 0001 0022 00de 0000 0000 de00 0800 0000\n0077030 0000 0008 0473 0c16 221f 0200 0000 0001\n0077040 0100 0101 0032 00df 0000 0000 df00 0800\n0077050 0000 0000 0008 0473 0c16 221f 0200 0000\n0077060 0001 0100 0010 0073 006c 002d 006d 006f\n0077070 0064 0065 006d 0000 0000 0000 0000 0000\n0077080 0000 0000 0000 0000 0000 0000 0000 0000\n*\n0077800 0022 00df 0000 0000 df00 0800 0000 0000\n0077810 0008 0473 0c16 221f 0200 0000 0001 0100\n0077820 0001 0022 00df 0000 0000 df00 0800 0000\n0077830 0000 0008 0473 0c16 221f 0200 0000 0001\n0077840 0100 0101 0078 d690 0008 0800 90d6 961a\n0077850 0006 0600 1a96 0473 0c16 221f 0000 0000\n0077860 0001 0100 0056 0073 006c 002d 006d 006f\n0077870 0064 0065 006d 002d 0064 0061 0065 006d\n0077880 006f 006e 005f 0032 002e 0039 002e 0031\n0077890 0031 007e 0032 0030 0031 0031 0030 0033\n00778a0 0032 0031 002d 0031 0031 005f 0069 0033\n00778b0 0038 0036 002e 0064 0065 0062 0000 0000\n00778c0 0000 0000 0000 0000 0000 0000 0000 0000\n*\n\nI know how to remove all spaces and returns and make it all on one line, but how do I turn the stars into the removed lines they represent and remove the first 8 characters which are not part of the number? Or is there perhaps a way to make hexdump just output the number instead of all the other stuff? The file is obviously too large for me to do it manually so a command to do it automatically would be greatly appreciated. I am running Ubuntu GNOME 15.10 with GNOME 3.18.\n\nA: You can use xxd to create plain-style hex dump \n$ xxd -p /etc/passwd | head -n 3                                                                                      \n726f6f743a783a303a303a726f6f743a2f726f6f743a2f62696e2f626173\n680a6461656d6f6e3a783a313a313a6461656d6f6e3a2f7573722f736269\n6e3a2f7573722f7362696e2f6e6f6c6f67696e0a62696e3a783a323a323a\n\nAnd output it to file \n$ xxd -p /etc/passwd > output.hex\n\nYou can restore data later with -r -p options\n$ xxd -r -p output.hex  | head -n 3                                                                                   \nroot:x:0:0:root:/root:/bin/bash\ndaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin\nbin:x:2:2:bin:/bin:/usr/sbin/nologin\n\nCouple other methods :\n$ hexdump -ve '1/1 \"%.2x\"' /etc/passwd\n$  od -t x1 /etc/passwd | awk '{$1=\"\"; gsub(/\\ /,\"\");print}'\n\n\nA: Use hexdump specifying a custom output format:\nhexdump -ve '8/1 \"%04x \" \"\\n\"'\n\n\n\n*\n\n*-v: prints all data (gets rid of the asterisks, which mean repetition of the last line of output)\n\n*-e '8/1 \"%04x \" \"\\n\"': prints 8 times a single byte in a zero-padded (up to four digits) lowercase heaxadecimal representation followed by a a space and appends a newline until no more data is available.\n\n\n% </dev/urandom head -c 32 | hexdump -ve '8/1 \"%04x \" \"\\n\"'\n003c 00b0 00bb 00de 003d 0041 0072 00a5\n00c2 0078 00b9 009b 00b7 00fc 0076 0030\n00b7 005c 00f4 0036 00a0 004e 003b 001b\n0028 00cd 006a 0079 0055 0014 000c 007b\n\n\nI'm not sure why you'd want to do that, but apparently you want to print everything on a single line without spaces.\nIf that's the case:\nhexdump -ve '/1 \"%04x\"'\n\n% </dev/urandom head -c 32 | hexdump -ve '/1 \"%04x\"'\n0046007c00b2003300e0009b00eb00d500bf006900570081008e003e005a002f0024001700ab00000084001e00ad00ab003a004800bf0039005c00aa00030072%\n% \n\n\nA: By default hexdump will remove repeated line and put a single * in the place where one or more lines have been removed. By removing the first column with file positions, you will have lost the only indication of how many lines were removed, so it is no longer possible to reconstruct the original file.\nPresumably you want a number that uniquely represents the original file, so you would have to start with hexdump -v. As shown in a previous answer, it is possible to give hexdump other arguments to change the output format into the format you were asking for.\nHowever if you for some reason only have the output of hexdump -v and not the original file it would also be possible to remove the first column and white space like this:\ncat filename.txt | cut -c9- | tr -dc 0-9a-f\n\nHere cut -c9- will remove the leftmost 8 characters of each line outputting only the 9th character and everything after it. And tr -dc 0-9a-f will keep only characters in the range 0-9 or a-f, so all spaces and newlines are removed.\n", "Q: How To Update Xubuntu 15.10 on External HDD? I have Xubuntu 15.10 installed on my external HDD (Grub is also there). How can I update/upgrade it to 16.04 LTS?\nDirectly on external HDD? I mean just press the button upgrade (and Grub will again be on external HDD?)? Or I will have to make Live USB/Live DVD and do a clean install again (and lose my apps and settings)?\nAny ideas?\nThnx.\nDV\n\nA: I would recommend doing a clean install of Ubuntu 16.04LTS at least thats what i usually do when a new version comes but still you can do an upgrade but i have bad experience with doing upgrades instead of doing a clean install.\ndo the clean install or simply upgrade from a live USB.\n\nA: The issue solved!\nI have just upgraded Xubuntu 15.10 to Xubuntu 16.04 LTS on my external HDD \"in place\". Everything worked just fine. The installation process did not mess my MBR/UEFI, the GRUB stayed where it was - on external HDD.\nSo, it is sufficient just to start upgrade process in \"normal\" way, despite the fact is is all about an external HDD.\nCheers folks.\nDV\n", "Q: How to make Unity Dash full screen? When you hit the Windows key on the keyboard the dash opens: \n\nBut I am using a 20\" monitor and the launcher is smaller. \nIs it possible to make the Unity dash full screen? like the Gnome launcher? \n\nA: Yes, just use the Maximize button.\n", "Q: Cannot remove file uucp I was downloading Java tar files and meanwhile managed to install it via apt-get, now I cannot remove the unrelated file resting on my Desktop (jre1.8...). THe properties reveal owner uucp, and the permission field is grey. \nCould someone help me kill it through the CL?\nThanks.\nTHe file and the permission\n\nA: You can try to remove the file as superuser.\nSo, open a terminal pressing ctrl+alt+t and move the working directory to Desktop position:\ncd Desktop\n\nNow you can run the following command that will delete selected file as superuser :\nsudo rm -f <filename>\n\nwhere parameter <filename> is the name (or the path) of file that you want delete.\nThe option -f tell to the command to ignore possible errors and force the deletion.\nIf you want to delete a directory you can use the following command that will delete the directory and all its content (-r means recursive, \"go deep\"):\nsudo rm -rf <directory>\n\nNote: unless you want to bypass all errors during deletion, don't use -f option. Be careful when you use the above command because, if you use it in the wrong way, you could delete important files and directories ignoring any errors that could arise. Those files cannot be recovered easily.\nFor example you mustn't use this command on your root directory.\n\nIf you want more information about rm command with this:\nman rm\n\nThe above command will show you the reference manual of rm command.\nI hope this could help you.\n", "Q: login to ubuntu 15.1 help Linux newbie here.  I have been using Zorin 9 for awhile, and overnight had my system upgrade to Ubuntu 15.1.   I let it load, and this morning it is asking for a login and password, which I did not set.  How does one get into the system to discover or change the login and password?\n\nA: Try Ctrl+ Alt+F1 to enter the terminal and login with your username and hit enter if you haven't given a password. \n", "Q: How to extract a Inno Setup Installer How to extract a Inno Setup Installer. This is not a .7z, or any other file that 7z can extract. according to the file command this is a file of the type:\n\n\n*\n\n*PE32 executable (GUI) Intel 80386, for MS Windows\nAnd exiftool says this:\n............                    : ..........\nComments                        : This installation was built with Inno Setup.\n............                    : ..........\nFile Description                : Package for Universal Extractor\n\nHow Do I extract this?\n\nA: You need to use innoextract  to extract the contents of an InnoSetup installation program. Once installed, the application can be run as follows:\ninnoextract setup-something-1.0.0.exe\n\nNote that files are extracted to the current directory.\n", "Q: enable Virtualization via terminal can I enable Intel Virtualization Technology via terminal or without using the bios. Is this possible or not?\n\nA: If it is disabled in BIOS you can not enable it in terminal. I had problem with my Lenovo laptop that did not have option for virtualization in BIOS and I had to update BIOS to get it enabled (I needed it for VirtualBox).\n", "Q: WiFi stops working after some time I have a problem with my Ubuntu.\nI have Ubuntu 14.04 as dual boot (alongside windows 10) on my ACER E5-771G-79VT laptop.\nMy network card is Realtek RTL8723BE Wireless LAN 802.11n PCI-E NIC.\nWhen I start my Linux partition, the wifi works great as it should. But after some time, the pages start to load indefinitely. Meanwhile the signal icon is still full and showing that I am connected to network. After that, nothing can bring wifi back to life. The connection by cable works perfect. Also my windows partition has no problems with network.\nWhen i restart Linux i can again use wifi for some time, until it drops again.\nNow, i read some other similiar topics, but they didn't helped me, so that is why i am opening my topic.\nThank you\n\nA: I have a Lenovo Laptop - G50. I found that my wireless also disconnects every now and again. I installed Windows 7 and found it doing the same. The only way I could get it working in Windows was with the Specific Brand driver from the website. Even the Windows driver wouldn't make it work for longer than a few minutes, it had to be the specific driver from the website. I now use a USB wireless adapter in Ubuntu which solves the problem. Luckily I don't use wireless that often - I am usually on a cable.\n", "Q: TTY goes blank after a couple seconds on Ubuntu 14.04 I recently got an NVIDIA GPU and installed Ubuntu 14.04 on my hard drive. My problem is that Ubuntu is no longer booting up. When I boot to that hard drive, I get a blank screen. When I press Ctrl+Alt+F1 (or go to any of the other TTYs) I get the usual login request for a second or two before the screen goes blank again. I can log in by typing half my username, Ctrl+Alt+F1 again, type other half and hit enter, Ctrl+Alt+F1 again and entering my password.\nBefore this, Ubuntu had gotten stuck in a loop at the login screen, so I started trying various fixes I saw on askUbuntu, such as boot-repair, reinstalling lightdm and Xauthority, messing with grub2, but something must have made it worse because now I can't even attempt a fix with TTY without the screen going blank every two seconds.\nAny idea what I should do?\n\nA: Well jss367, you ended up wiping all of Linux on your HD and putting on a fresh copy. This obviously worked, but I thought of something else you should have tried first. All the issues were probably related to the NVIDIA drivers so you should have tried sudo apt-get remove --purge nvidia-* first. You'll get 'em next time!\n", "Q: How do I recover from Firefox safe mode overwritting my preferences? My computer has a hardware fault and crashes frequently (but not often enough for me to replace it). Firefox did not like the crashes and offered me to start in safe mode. Somehow, even after restart, all my settings got deleted. I have no idea if and how can I recover my old settings and extesions.\n\nA: There was a folder \"Old Fireforx Data\" on my desktop that I missed when I asked the question. I moved the folder inside it (called \"hb0i6k54.default\") into ~/.mozilla/firefox and edited profiles.ini in that folder so that it would point to hb0i6k54.default - and that fixed the problem.\n", "Q: Identifying which directory a filename comes from I have a .txt list of filenames which come from two different directories. They come from a server database and share a single characteristic (database flag), but I really need to know which of the 2 directories they come from.\nIs there a way to batch process the list to produce a new list which shows which directory the file came from?\nI can do it one by one using \"find\", but the list has about 150 files.\nIs it quicker to read about database queries and redo the list myself?\n\nA: If you know the files can only be in one of two places, then it's probably more efficient to test each explicitly, e.g.\nwhile IFS= read -r f; do \n  if [ -e \"dir1/$f\" ]; then\n    echo \"dir1/$f\"\n  elif [ -e \"dir2/$f\" ]; then\n    echo \"dir2/$f\"\n  else\n    echo \"$f: not found\"\n  fi\ndone < filelist\n\n\nA: You could always use locate command, which reads a database of all files. The database has to be updated before running locate, however. \nHere's an example of what one might do \n$ locate --regex \".*/lightdm.conf$\"                                            \n/etc/init/lightdm.conf\n/etc/lightdm/lightdm.conf\n\nNow, to batch process a list of files , one could use while read do. . . done < input_file structure, with locate code inside. Something like this:\n$> cat > file_list.txt                                                         \npasswd\nlightdm.conf\nfirefox.desktop\n\n$> while read line ; do                                                        \n> locate --regex \".*/$line$\"                                                   \n> done < file_list.txt                                                         \n/etc/passwd\n/etc/cron.daily/passwd\n/etc/pam.d/passwd\n/home/xieerqi/Desktop/cleanup/passwd\n/home/xieerqi/Documents/passwd\n/usr/bin/passwd\n/usr/share/bash-completion/completions/passwd\n/usr/share/doc/passwd\n/usr/share/lintian/overrides/passwd\n/etc/init/lightdm.conf\n/etc/lightdm/lightdm.conf\n/usr/share/applications/firefox.desktop\n\nOf course this is not the speediest of searches - after all database contains thousands of files , but much speedier than traversing the entire\ndirectory structure with find\n", "Q: How to set the new Suru Dark theme as default theme in Ubuntu Touch? How to turn an Ubuntu Touch device into the new Suru Dark instead of the default Ambiance theme to have a black and energy saving user interface?\n\nA: First of all a security note: Executing the following steps is at your own risk. I tested these steps only once at my BQ Aquaris E4.5 phone with an installed OTA10 update. I don't assume liability for this. Some native apps (like Browser or Dekko) don't support the new theme completely. You can see this in still white backgrounds or inappropriate font colors. But the functionality of these apps is not restricted.\nSo if you thought about it deeply, we now can start:\nYou'll need the Terminal app from the Ubuntu store.\nOpen it and type the line:\nnano ./.config/ubuntu-ui-toolkit/theme.ini\nAfter this press enter and change “Ambiance” to “SuruDark” (without the quotes and not with a blank, so not “Suru Dark”) at the end of the “theme=” line. Then press Ctrl-O in the Nano section of the terminal to save it, then enter and finally Ctrl-X.\nTo test your changes reboot the device. If you're not happy with the Suru Dark theme change “SuruDark” back to “Ambiance” in the similar manner like above.\n\nA: I just stumbled upon this old question.\nCurrently (start of 2020) you don't need to edit files using the terminal anymore to change the theme in Ubuntu Touch.\nThere are two apps capable of changing the theme UT Tweak Tool and ThemeSwitch.\n", "Q: Do I need to clear out swap to make my computer fast again? I ran a process which used up mostly all my RAM and Swap... I was forced to kill the process, but now I see something strange, my Swap usage has decreased a little bit, but it is still half used while my RAM is barely being used at all... In fact quite a lot more Swap is being used than RAM, and even though the RAM usage level is low, my computer is being really slow and I am assuming that this is linked to the Swap levels still being high? If so, how do I clear my Swap if it doesn't automatically? Or what do I do? I have already looked at this question, it does not appear to only be talking about Swap and I don't want to affect the RAM, so a solution would be clearing Swap, but only Swap...\nLast time this happened I was forced to just restart my machine, but I should have to. I am running Ubuntu GNOME 15.10 with GNOME 3.18.\n\nA: Once data goes into swap, it is normal for it to stay there even once your memory starts to free up again.  It is a good thing and there is no need for concern.\nDue to hard disk access being significantly slower than memory, your system will avoid swapping data in or out of swap when it doesn't think it is necessary for system performance or stability.  So, data will only go into swap when the system is running out of free memory or there is a lot of pressure on the disk cache, and your system decides the time-consuming process of placing data into swap will pay off with better or more reliable system performance afterwards.\nTransferring data out of swap is (for traditional hard disks, at least) just as time-consuming as putting it in there. So your system will be reluctant to remove data from swap if it's not actually being used. If you have data in swap and it's not being used, then it's actually a good thing that it remains in swap, since it leaves more free memory for other things that are being used, potentially speeding up your system.\nThe best way to completely avoid swapping is to buy more physical RAM if that's possible.  When it swaps, your system is giving you the best performance it can with the amount of physical memory it has.\nAll that said, if you are sure that the low-memory/high cache event that caused the swap in the first place won't happen again and you don't mind waiting, you can force the system to release all of its swap data with the following commands.\nsudo swapoff -a\nsudo swapon -a\n\nThis will disable then re-enable swap, forcing data out of it in the process.  As explained, there is probably no real reason to do this - beyond curiosity or seeing how your swap is working.\n\nA: The slowness will quickly clear up on its own as the swapped out data is brought back in when it is needed.  It won't be swapped out again as long as you have plenty of free ram, but plenty of other data that you have not accessed might still remain in swap, waiting for you to actually need it again.\n\nA: If you have a fast cpu, try Zram.\nYou can read about it in detail here.\n\nA: Clearing swap would do nothing for the slowness of your computer and does not need to be done except if you believe that some incorrectly behaving program has kept some sensitive data (e.g. passwords) in swappable memory that may have ended on the swap partition. If you don't need to wipe potentially sensitive data out of swap, you never need to manually clean or format the swap once it's working.\nThe most probable reason your system feels slow is that the system is in fact going nearly out of RAM. This may happen even if the system monitor shows that the system still has available memory because memory need is often sporadic and the memory may be needed only for a less than a second and will not show up in any slow refreshing system monitor.\nThe most simple way is to open a terminal and run command sudo vmstat -SM 10 (you may need to install vmstat first by running sudo apt install vmstat):\nOutput will look something like this (new line appears every 10 seconds):\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 2  0      0   1609   6565  13230    0    0    88   195   17  178 44 10 45  1  0\n 1  0      0   1599   6565  13232    0    0     0   226 4621 18688 22  6 72  0  0\n 4  0      0   1566   6565  13234    0    0     0    67 5217 20819 27  7 65  1  0\n 2  0      0   1533   6566  13241    0    0     0   847 6021 23359 35  6 58  0  0\n\nThe fields you want to watch are swap si and so which means number of megabytes in 10 second period that are swapped in (from swap device to RAM) or swapped out. Usually the so does not matter for system speed but si will cause slowness and is caused by system having too small RAM for the processes that you're trying to run in paraller. The possible solutions are (1) close one or more applications that you're using, or (2) get more physical RAM.\nPress Ctrl+C to exit vmstat.\nNote that vmstat is not able to tell if system goes near zero free memory for short moments so free, buff and cache may have big numbers even if memory is slow. sar is probably the only program that can tell for sure if your memory is running out but that program is pretty hard to configure (not impossible, though - just install it and start with man sar).\n", "Q: Ubuntu 15.10 64bit Desktop invalid Checksums Is the MD5 checksum for Ubuntu 15.10 incorrect or is there an issue for me?\nI'm getting a value of 3f29c5423393fc282216ed80e25af7c5 whereas the website is reporting an expected value of ece816e12f97018fa3d4974b5fd27337. (Listed here: http://releases.ubuntu.com/15.10/MD5SUMS). \nI tried downloading the file again but got the same MD5. I also checked the SHA1SUM and that was incorrect too.\nI originally checked as after burning the ISO I couldn't run the installer properly.\nI tried checking the 14.04 MD5 values and they were correct for me.\n\nA: If the checksums don't match, then you have a corrupted file. I've downloaded and checked it now and everything is OK for me. You should download it again via BitTorrent (recommended).\n", "Q: Is the lock screen secure? I have a fully encrypted drive so I know when my laptop is turned off that nobody can access my data but what about when the screen is locked with my root password?\nIt is often impractical to turn off my computer everytime I leave my laptop unattended and as all my data is backed up and the laptop is pretty cheap, I'm not too bothered if it gets stolen as long as I know my data is secure.\nI know there is a hack to bypass log-in or reset the root password on an unencrypted drive but this requires a reboot so it wouldn't be an issue for me as the crypt password is needed before any root password and my crypt password is likely much more complex than most people's. It took me a long time to memorize it.\nMy root password is secure but less secure than the encryption password as it would be too impractical to type something too long each time I want sudo or to unlock the screen.\nIf somebody steals my laptop when it is locked but turned on and then plugs it into a power source so the battery does not die, would it be easy for them to get access assuming they had plenty of time?\nOther than trying to brute force my password is there any other way they could get into my computer as long as it remains turned on? When I enter the wrong log-in password the system says \"checking\" for a couple of seconds even though it already knows the password it wrong but I can see this is a delay to prevent rapid brute force guesses. I'm not worried about a dictionary attack as this would take years with that delay.\nSorry if this question has been answered but I can't find any conclusive answer.\nI need to make a run to the store now for some supplies. I want to leave my downloads running with a locked screen. Should I be worried about a burglar stealing my laptop while I'm gone and reading my embarrassing browsing history?\nedit:\nTL;DR\nIf I leave my laptop on and the screen is locked can someone get access if they steal my computer? My drive is encrypted in-case they reboot.\n\nA: They could try to brute-force your password, you might want to set it up so accounts are locked out after too many failed attempts. You didn't ask how,  but if you're interested you can read more here https://web.archive.org/web/20190831173642/http://blog.bodhizazen.com/linux/ubuntu-how-to-faillog/\nEdit : including steps as requested\nOpen /etc/pam.d/common-auth and add the line AT THE TOP OF THE FILE:\nauth required pam_tally.so per_user magic_root onerr=fail\n\nTo set the number of attempts allowed & timeout\nfaillog -m 3 -l 3600\n\nWhere 3 is the number of attempts allowed and 3600 seconds (1 hour) is how long to lock out the account for.\nYou can omit the -l part and the account will be locked out forever, however I would really not recommend that since your hard drive is encrypted. It would make your files very difficult to recover if you locked yourself out. If you choose to omit the lockout time, I would at least increase the number of attempts, because it's not that difficult to enter your password wrong 3 times.\n\nA: Any way? Yes, look up the liquid nitrogen RAM attacks. It's always a question of how secure you want to be, not being undefeatable. If an attacker needs a dewer of LN on hand to defeat you, you're fairly likely to see him coming. \n\nA: If the attacker has physical access to your RAM then he can get your keys.  I don't see any way to prevent that.\nWhat I suggest, if you have sensitive data that you want to protect:\nInstall a virtual system inside of an encrypted container.\nUsing VirtualBox or some other virtualization software you can save the current state of the virtual system at any time.\nWrite one script (open-vm) to open the container and restore the virtual system and another (close-vm) that will save the state of the virtual system and close the encrypted container.\nThen just get lock screen to trigger those scripts or call them yourself when you need to.  You'll need to provide the decryption password for your container every time you want to restore the container but at least you can leave your system running when you step away for a few minutes.\nThis also has the benefit that if an unsophisticated attacker intimidates you into opening your laptop you can do so and they still won't have access to your encrypted virtual system that they probably won't know about.\nNote: Your encrypted container password should be as strong as your HDD password, under the assumption that the attacker will bypass your screen lock and have unlimited computing power to try to crack the encrypted container.\nNote 2: I'm assuming that VirtualBox won't cache data in places you don't expect it to and will clear any traces of the virtual system when it's shut down.  This is possibly a dubious assumption.\n", "Q: Question about the RTAI and version Of kernel I have a ubuntu 3.8.0-29 geniric and the gcc 4.6.3 . \nI will to install the RTAI , what is the version of kernel and the version of kernel to download ?  \n\nA: As far as building is concerned, it looks like all you may need:\nsudo apt-get update\nsudo apt-get install build-essential linux-headers-generic autoconf automake aclocal libtool\n\nExtract the tar.bz2 file and take a look at the README.INSTALL file for complete instructions.\nAccording to the documentation, it just talks about 3.x and doesn't specify a specific kernel version as far as I can tell.\nTry building and compiling on your current kernel version and if you get stuck with an error, post that error and we can go from there.\n\nWith that said, there is no realtime kernel for Ubuntu as it is depreciated. We now use the lowlatency kernel instead.\nYou can install the lowlatency kernel for version 3.2 by running the following command (you will need to have the universe repository enabled):\nsudo apt-get update\nsudo apt-get install linux-image-lowlatency\n\nUbuntustudio uses the lowlatency kernel by default and I believe also employs other default settings to enhance this. Also, I think this is mostly for audio recording but I'm not sure. Click here for more info.\n", "Q: grub error when booting Ubuntu 14.04 I have 2 hard drives on my server and I have previously installed CentOS on one of the hard drives. I'm not sure which, but I am guessing it's the second.\nI fresh installed Ubuntu 14.04 on the first one I will say, but after the successful installation (which I assume it has repartitioned my hard drives) when it reboots I get this error:\nerror: file '/grub/i386-pc/normal.mod' not found\n\n\nI tried to use rescue mode to fix what the issue is and am brought to a screen that asks to choose the boot device I want, and when I choose /dev/sda1 it says I can't use it.\n\n\nHow do I fix this and/or how can I wipe out everything on my 2 hard drives first, before starting another fresh install?\n\nA: I just used gparted from http://gparted.org/\nand deleted all the partitions\nthere was the second drive that was locked because it uses lvm2\nSo i used lvscan to check all the volumes on it and then used lvremove to remove all the volumes, then i was able to delete it as well, before using lvremove the partition was locked and i could not delete\nSo have 2 fresh hard drives back again\n", "Q: Are my files on an ext4 filesystem recoverable after removing the logical volume the filesystem was inside of? Scenario:\nThe other day I was trying to \"unmount\" some logical volumes so that I could close the LUKS partition they were inside. I accidentally uses lvremove thinking that was the right command to use; after I realized it was not I restored my LVM configuration with the backup it created right before lvremove.  \nSetup:\nI have a single SSD with a single LUKS partition, inside of that is an LVM partition with three logical volumes for swap, root, and home. Root and home are ext4 filesystems. So SSD(LUKS(LVM(swap,root(ext4),home(ext4)))) \nConclusion:\nI have determined that the metadata describing my ext4 filesystem has been corrupted. I know this because I have tried to repair it using\ne2fsck -f /dev/ubuntu/home\nI have tried to repair it using backup superblocks\ne2fsck -f -b 12345 /dev/ubuntu-vg/home \nI have used TestDisk to try to repair it   \nI have tried using extundelete (it can't find the superblocks)\nI have even looked at the raw hex using\nxxd -a /dev/ubuntu-vg/home | less\nand compared it to a working ext4 filesystem  \nQuestions:\nIs it possible to recover the files using some kind of \"deep scan\"?\nIs this a known problem with LVM and SSDs or is it an anomaly?\nWhen LVM deallocated the memory blocks on the SSD did a TRIM operation or \"wear leveling\" occur corrupting the data?\n\nA: I'm in the process of reading-up on using logical volumes. I ran across this advice from ArchWiki: \n\n\"Warning: Before you remove a logical volume, make sure to move all\n  data that you want to keep somewhere else; otherwise, it will be\n  lost!\"\n\nBased on that, it would appear that your files are \"lost\". Of course, that doesn't mean that there isn't another person out-there somewhere who may have the knowledge concerning how to recover your lost files.\n", "Q: How to install Wine in Ubuntu 15.10 I tried to follow the steps listed here https://www.linux.com/blog/wine-1735-released-how-install-ubuntudebianlinux-mint\nAfter adding the PPA and running apt-get update, when I try to install wine with:\nsudo apt-get install -y wine1.7\n\nI get this output:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\nwine1.7 : Depends: wine1.7-amd64 (= 1:1.7.44-0ubuntu1)\n          Depends: wine1.7-i386 (= 1:1.7.44-0ubuntu1)\nE: Unable to correct problems, you have held broken packages.\n\nI also read this: Installing Wine on Ubuntu 15.10, but nothing seems to help.\nAlso, (I don't know if I should mention this in another question or if it is related to the current error I get) I had installed winetricks and it worked without any problem after installing \"playonlinux\" (I don't know if the problem started BECAUSE I installed playonlinux since I didn't use winetricks for days prior to trying to install playonlinux so the underlying problem may or may not have been created prior to this installation) I couldn't find winetricks on my apps list and right clicking on .exe files would pop winetrickes on \"Open with\" option...\nLast but not least, in /usr/bin/ there is no winetricks executable, only a winetricks shell script.\n\nA: From https://wiki.winehq.org/Ubuntu:\nIf your system is 64 bit, enable 32 bit architecture (if you haven't already):\nsudo dpkg --add-architecture i386 \n\nAdd the repository:\nsudo add-apt-repository ppa:wine/wine-builds\n\nUpdate the package list:\nsudo apt-get update\n\nThen install (example for the development branch):\nsudo apt-get install --install-recommends winehq-staging\n\nIf you prefer to use the devel (not Staging) branch, replace winehq-staging with winehq-devel in the line above.\nIf apt-get complains about missing dependencies, install them, then repeat the last two steps (update and install).\nTo install the latest version of Winetricks (recommended, the version in the repos is old), run:\nwget https://raw.githubusercontent.com/Winetricks/winetricks/master/src/winetricks && sudo cp winetricks /usr/bin/ && sudo chmod +x /usr/bin/winetricks\n\n", "Q: Is there a way to run Netflix under a 32bit computer? Now that Google Chrome is not giving any support for 32bit Ubuntu computers I'm having issues to watch programs in my old HP Pavilion with Ubuntu 14.04. Any clues?\n\nA: It is possible, but if you are using an old 32 bit PC (as I am) the performance is not good.  You have to go back to the way we did it prior to the native Chrome solution, namely pipelight.\nDetailed instructions are available at the link, but to sum up:\n\n\n*\n\n*You add the pipelight ppa and install pipelight. (this installs a customized version of wine)\n\n*You enable the silverlight plugin\n\n*You install a browser agent switcher to fool Netflix into thinking\nyou are running on a supported system.\n\n\nI have done it, and it works, but I am not happy with it.  I seek a better solution.\n", "Q: Ubuntu crashes every time I connect the computer to HDMI Every time I connect my computer to my TV via HDMI, my computer's screen goes black and Ubuntu crashes.  I use Ubuntu 15.10, and my laptop is an ASUS with an Nvidia GeForce 840M graphics card.  Windows works fine.\nHave you ever seen this behavior before? How did you solve it?\n\nA: Install the proprietary drivers from Nvidia, since using proprietary drivers will most likely give you a boost and probably fix your issue.  I don't know a lot about Nvidia since I am an AMD user, but at least for me, installing the proprietary drivers fixed all of my issues.\n", "Q: Cron job. Runs at minutes interval but otherwise when set at another time During the test of my script.\nThe cronjob should run a script through the browser every 2 minutes. So I had the following cron:\n*/2 * * * * wget -O http://192.10.10.1/mypage/myscript.php\n\nThe cron run a couple of times before I changed it to:\n0 1 * * * wget -O http://192.10.10.1/mypage/myscript.php\n\nto run the script everyday at 1am but it does not work.\nI am a bit confused why the first one successfully run my script while the latter didn't. What am I doing wrong? Or what could possibly be the reason why running it at 1am does not work?\n\nA: As pointed out in a comment above, the most obvious pbm is that you are not using the -O option correctly. \nLook up  man wget in terminal. Here is an extract:\n\n-O file --output-document=file.  The documents will not be\n  written to the appropriate files, but all will be concatenated\n  together and written to \"file\".  If - is used as file, documents\n  will be printed to standard output (stdout), disabling link conversion.\n  Use ./- to print to a file literally named -. Use of -O is\n  analogous to shell redirection: wget -O file http://foo is\n  intended to work like wget -O - http://foo > file; where \"file\" will be\n  truncated immediately, and all downloaded content will be written\n  there.\n\nIf, as a non root user, you run a GUI cmd or direct yr output to stdout in an already running X session, make sure yr cron environment knows about the active display. To make cron GUI aware, i.e. to tell it, what display the program should use (:0 is the default in a desktop environment)\n0 1 * * * export DISPLAY=:0; XAUTHORITY=~/.Xauthority /usr/bin/wget -O - http://192.10.10.1/mypage/myscript.php\n\nor, if you want to set the DISPLAY environment variable ONLY for a specific cmd:\n0 1 * * * DISPLAY=:0 XAUTHORITY=~/.Xauthority /usr/bin/wget -O - http://192.10.10.1/mypage/myscript.php\n\nor, if redirecting output to a file for later perusal, the need to specify the correct display disappears because nothing actually goes to stdout :\n0 1 * * *  /usr/bin/wget -O <filename> http://192.10.10.1/mypage/myscript.php\n\nThe latter solution makes more sense, if you run yr cron job at 1am and you are not sitting in front of yr desktop display.\n==\nLet us known in case of continuing problems.\n", "Q: Create separate primary partition to install linux \nI tried GParted live to extend and create primary partition but it is taking a lot of time. When will the process get finished? Also, whenever I tried to dual boot Linux. windows partition is shown with other small primary partition but other partition is shown as single. I don't want to loose data.\n\nA: The small partition before Windows partition is probably needed to boot your windows partition and you mustn't touch it.\nYou can try to follow these steps to install Ubuntu:\n\n\n*\n\n*Move the content of /dev/sda4 (1.39GiB) in a secure place (like Windows partition or an external USB);\n\n*Now reboot your PC from Ubuntu live drive (DVD or USB) and delete /dev/sda4 partition: select the partition, right-click on it and choose delete;\n\n*right-click on the unallocated space (grey box) and choose new. Now select the wished partition size, format it as ext4 and be sure to make it as primary partition.\nNote: keep a small unallocated space as big as your RAM. This is needed for swap area.\n\n*Once you have created a primary partition repeat the previous step\nand create swap area choosing linux-swap instead of ext4 as file system.\n\n*Apply the changes and wait for the end of work.\n\n*When you are ready, start Ubuntu installation and when you reach section Installation type choose Something Else.\n\n*You should see a similar screen as GParted. Right-click on ext4 partition and select Ext4 journaling file system instead Do not use partition and select as mount point /. After this do the same for swap partition and select Swap area instead Do not use partition.\nIn the end, choose /dev/sda drive (default) to install GRUB bootloader. When you go ahead with installation check that it will use the correct partitions.\n\n\nFollowing these steps you should be able to install Ubuntu.\nEdit partition through Windows\nIf you can't edit your partition in Ubuntu, you can try to do this in Windows. So right-click on This PC and choose Manage. Now from the list on the left select Disk managent. After this you should see something like GParted (similar image here). Then select the 387GB partition, right-click and choose Delete volume. Now you can come back to Ubuntu and you should be able to edit that partition as you want.\nI hope this could help you.\n", "Q: If I build a 14.04 server with OpenZFS now will I be able to move to 16.04 later? I'm planning on building a new home NAS soon. Like my previous one I plan on using ZFS for the large storage pool. I know 16.04 comes out in a few weeks but I might be building sooner rather than later and was wondering if I could expect issues when upgrading to 16.04, specifically with ZFS?\nMy concern is with ZFS getting baked in to Ubuntu where will that leave older setups.\nThanks!\n\nA: I moved two zfs machines already. It worked without any issues. Just removal of zfs ppa and apt install zfsutils-linux on 16.04 was enough.\n", "Q: Different file system types in fdisk; no HPFS/NTFS I am running Ubuntu 15.10 and trying to format a USB drive to load a Windows ISO on. Every tutorial has you install ntfs-3g so that you can format to NTFS using fdisk, hex code 7. But when I go to fdisk and list the file system options, they are different than what is reported elsewhere: \nhttps://unix.stackexchange.com/questions/114485/fdisk-l-shows-ext3-file-system-as-hpfs-ntfs\nhttp://ubuntuforums.org/showthread.php?t=847318\nThe results from my fdisk file systems list is below. Is there something wrong with the USB drive that won't allow it to use the other file system types? Or am I missing some additional driver/software?\nCommand (m for help): t\nSelected partition 1\nHex code (type L to list all codes): L\n1 EFI System                     C12A7328-F81F-11D2-BA4B-00A0C93EC93B\n2 MBR partition scheme           024DEE41-33E7-11D3-9D69-0008C781F39F\n3 Intel Fast Flash               D3BFE2DE-3DAF-11DF-BA40-E3A556D89593\n4 BIOS boot                      21686148-6449-6E6F-744E-656564454649\n5 Microsoft reserved             E3C9E316-0B5C-4DB8-817D-F92DF00215AE\n6 Microsoft basic data           EBD0A0A2-B9E5-4433-87C0-68B6B72699C7\n7 Microsoft LDM metadata         5808C8AA-7E8F-42E0-85D2-E1E90434CFB3\n8 Microsoft LDM data             AF9B60A0-1431-4F62-BC68-3311714A69AD\n9 Windows recovery environment   DE94BBA4-06D1-4D40-A16A-BFD50179D6AC\n10 IBM General Parallel Fs        37AFFC90-EF7D-4E96-91C3-2D7AE055B174\n11 Microsoft Storage Spaces       E75CAF8F-F680-4CEE-AFA3-B001E56EFC2D\n12 HP-UX data                     75894C1E-3AEB-11D3-B7C1-7B03A0000000\n13 HP-UX service                  E2A1E728-32E3-11D6-A682-7B03A0000000\n14 Linux swap                     0657FD6D-A4AB-43C4-84E5-0933C84B4F4F\n15 Linux filesystem               0FC63DAF-8483-4772-8E79-3D69D8477DE4\n16 Linux server data              3B8F8425-20E0-4F3B-907F-1A25A76F98E8\n17 Linux root (x86)               44479540-F297-41B2-9AF7-D131D5F0458A\n18 Linux root (x86-64)            4F68BCE3-E8CD-4DB1-96E7-FBCAF984B709\n19 Linux reserved                 8DA63339-0007-60C0-C436-083AC8230908\n20 Linux home                     933AC7E1-2EB4-4F13-B844-0E14E2AEF915\n21 Linux RAID                     A19D880F-05FC-4D3B-A006-743F0F84911E\n22 Linux extended boot            BC13C2FF-59E6-4262-A352-B275FD6F7172\n23 Linux LVM                      E6D6D379-F507-44C2-A23C-238F2A3DF928\n24 FreeBSD data                   516E7CB4-6ECF-11D6-8FF8-00022D09712B\n25 FreeBSD boot                   83BD6B9D-7F41-11DC-BE0B-001560B84F0F\n26 FreeBSD swap                   516E7CB5-6ECF-11D6-8FF8-00022D09712B\n27 FreeBSD UFS                    516E7CB6-6ECF-11D6-8FF8-00022D09712B\n28 FreeBSD ZFS                    516E7CBA-6ECF-11D6-8FF8-00022D09712B\n29 FreeBSD Vinum                  516E7CB8-6ECF-11D6-8FF8-00022D09712B\n30 Apple HFS/HFS+                 48465300-0000-11AA-AA11-00306543ECAC\n31 Apple UFS                      55465300-0000-11AA-AA11-00306543ECAC\n32 Apple RAID                     52414944-0000-11AA-AA11-00306543ECAC\n33 Apple RAID offline             52414944-5F4F-11AA-AA11-00306543ECAC\n34 Apple boot                     426F6F74-0000-11AA-AA11-00306543ECAC\n35 Apple label                    4C616265-6C00-11AA-AA11-00306543ECAC\n36 Apple TV recovery              5265636F-7665-11AA-AA11-00306543ECAC\n37 Apple Core storage             53746F72-6167-11AA-AA11-00306543ECAC\n38 Solaris boot                   6A82CB45-1DD2-11B2-99A6-080020736631\n39 Solaris root                   6A85CF4D-1DD2-11B2-99A6-080020736631\n40 Solaris /usr & Apple ZFS       6A898CC3-1DD2-11B2-99A6-080020736631\n41 Solaris swap                   6A87C46F-1DD2-11B2-99A6-080020736631\n42 Solaris backup                 6A8B642B-1DD2-11B2-99A6-080020736631\n43 Solaris /var                   6A8EF2E9-1DD2-11B2-99A6-080020736631\n44 Solaris /home                  6A90BA39-1DD2-11B2-99A6-080020736631\n45 Solaris alternate sector       6A9283A5-1DD2-11B2-99A6-080020736631\n46 Solaris reserved 1             6A945A3B-1DD2-11B2-99A6-080020736631\n47 Solaris reserved 2             6A9630D1-1DD2-11B2-99A6-080020736631\n48 Solaris reserved 3             6A980767-1DD2-11B2-99A6-080020736631\n49 Solaris reserved 4             6A96237F-1DD2-11B2-99A6-080020736631\n50 Solaris reserved 5             6A8D2AC7-1DD2-11B2-99A6-080020736631\n51 NetBSD swap                    49F48D32-B10E-11DC-B99B-0019D1879648\n52 NetBSD FFS                     49F48D5A-B10E-11DC-B99B-0019D1879648\n53 NetBSD LFS                     49F48D82-B10E-11DC-B99B-0019D1879648\n54 NetBSD concatenated            2DB519C4-B10E-11DC-B99B-0019D1879648\n55 NetBSD encrypted               2DB519EC-B10E-11DC-B99B-0019D1879648\n56 NetBSD RAID                    49F48DAA-B10E-11DC-B99B-0019D1879648\n57 ChromeOS kernel                FE3A2A5D-4F32-41A7-B725-ACCC3285A309\n58 ChromeOS root fs               3CB8E202-3B7E-47DD-8A3C-7FF2A13CFCEC\n59 ChromeOS reserved              2E0A753D-9E48-43B0-8337-B15192CB1B5E\n60 MidnightBSD data               85D5E45A-237C-11E1-B4B3-E89A8F7FC3A7\n61 MidnightBSD boot               85D5E45E-237C-11E1-B4B3-E89A8F7FC3A7\n62 MidnightBSD swap               85D5E45B-237C-11E1-B4B3-E89A8F7FC3A7\n63 MidnightBSD UFS                0394Ef8B-237C-11E1-B4B3-E89A8F7FC3A7\n64 MidnightBSD ZFS                85D5E45D-237C-11E1-B4B3-E89A8F7FC3A7\n65 MidnightBSD Vinum              85D5E45C-237C-11E1-B4B3-E89A8F7FC3A7\n\n\nA: It wasn't a problem that your partition was set to GPT. NTFS partition is actualy one of the Microsoft basic data partitions under number 6. Read the wikipedia here.\n\nA: It seems my problem was that the Partition Table was set to gpt. Changing it to msdos via gparted solved my problem.\n\nA: You use 7 for mbr partition table,\nbut for gpt partition table you need to use 6 Microsoft basic data\n", "Q: Unable to load GUI in ubuntu server 15.10 I have installed ubuntu server 15.10 64 bit in oracle VM. To start the GUI i have entered this command sudo apt-get install xorg gnome-core gnome-system-tools gnome-app-install. And downloaded and installed the packages. After that I type startx and getting the errors saying\nxinit:connection to X server lost\nwaiting for X server to shut down setting MTRR (base = 0xe0000000, size=0x00c00000,type=1) No such device (19)\n(II) Server trminated successfully (0). Closing log file.\n\nAny help ?\nThank you in advance.\n\nA: There are several ways to go - a simple one would be to just install the full blown desktop environment via \nsudo apt-get install ubuntu-desktop\n\nor\nsudo apt install ubuntu-desktop\n\nThis keeps your work simple, but comes with a big amount of additional packages you might not need in a classical server environment (where even GUIs are not used in the first place)  \nAdditional informations about Server & GUI can be found here.\nIn case you want to debug the above,  start with the log\n", "Q: Will the Ubuntu installer automatically detect other versions of Linux? I recently purchased a computer off a friend and decided to set it up as a work station at home. To that end, my supervisor and I spent the day getting Mageia (Red Hat distribution) installed along with our research group's software. We had first tried to install the software in Ubuntu, but the software was designed a long time ago and does not appear to be comparable (at least not easily) with modern Ubuntu. In the process of installing Mageia, the Ubuntu install was overwritten. As of now, Mageia is installed on sda (120 GB ssd) with a swap partition, EFI partition, / partition and mounts sdb (1 TB ext 4 formatted hdd). I have a couple of other hard drives that I can install in the machine and would like to use one of them to dual boot Ubuntu. \nMy main reasons for wanting to do this are a) I know Debian a bit better than Red Hat b) Ubuntu has better community support than Mageia c) I would like to learn more about Linux and fool around with it, but don't want to accidently brick my work station.\nMy main question is if I will have to do anything special in the Ubuntu installation such that I will be able to dual boot to either operating system. I don't care if the Mageia boot loader is over written so long as the I can dual boot.\nEdit:\nAs I feared, when I chose to install alongside Mageia, the install went fine until it reached the point of installing the boot loader. At this point the boot loader installer failed. If anyone could help me with this it would be greatly appreciated. The current hard drive configuration is as follows:\nsda: \n1TB Mageia ext 4 partition mounted at /media\nsdb:\n200 MB EFI partition for the bootloader\n12 GB swap space\n100 GB ext 4 partition mounted at /\nsdc:\n2 TB ext 4 partition to be used as storage by Ubuntu\nsdd:\n120 GB initially unallocated to be used to install Ubuntu.\nAny help would be hugely appreciated.\nEdit 2:\nThankfully Mageia still functions and it's grub still works. Does anyone know how I can add Ubuntu to the Mageia grub?\nEdit 3:\nBooted to Mageia and just used update-grub. Everything seems to be working fine now :)\n\nA: Yes, \nDuring installation of Ubuntu there it will ask you if you want to install Ubuntu alongside or over another installation found.\nIn your case the Windows 8 will be replaced by the other OS...\n\n", "Q: How to install Ubuntu GNOME on my HP Pavilion UEFI-based laptop running Windows 10 I bought this laptop over a year ago and it came with Windows 8 at the time, but I've since updated it to Windows 10 using the Insider Preview program. I would like to install Ubuntu GNOME 15.10 alongside Windows, but I've never dual-booted Linux and Windows on a UEFI system. Normally, I've delt with PCs that have BIOSs instead. I set aside 80GBs of unallocated space for the installer to use.\nI've got a live USB set up and when I boot it up, I choose the UEFI version of the USB drive. I don't know much about the UEFI system, so I figured that would be the right way to go.\nWhen I open the installer and I get to the Installation Type section, I don't know whether to choose Install Ubuntu GNOME alongside Windows Boot Manager, or choose Something Else. I've tried looking on multiple sources via Google searches, but the results are not consistent, so I'm not definitively sure which way is the best way to go.\nHere's a picture of all the partitions I've got installed in GParted.\nPartitions\nP.s: I've also disabled Fastboot in Windows.\n\nA: When dual-booting and starting with an existing Windows installation, it's almost always best to install Ubuntu in the same mode as Windows. In your case, since you've got Windows in EFI mode, you should install Ubuntu in the same way. From your description, it sounds like you're starting the process correctly.\nYour partition layout looks complex, so I'd avoid the automatic options and use \"Something Else\" for partitioning. Several questions and answers on this site touch on how to do this, including:\n\n\n*\n\n*Choosing \"something else\" when installing\n\n*Should I choose to Install alongside windows 8 or something else\n\n*How to use manual partitioning during installation?\nOne thing about your partitions jumps out at me: You have several small (465-841MiB) NTFS partitions following the unused space where you presumably intend to install Ubuntu. The first of those is over half used, but the other two are almost entirely unused. You might want to figure out what these partitions are, since you might want to delete or re-purpose one or more of them if they aren't in active use. Deleting such a partition might then necessitate moving another partition if you want to consolidate all the free space.\n", "Q: Changing icon and text sizes (and toggling) for visually handicapped I need to temporarily make everything larger: icons, text, etc. while I cope with a temporary visual problem. Is there an easy way to toggle between normal resolution and \"large-print\", if you will? (I don't see an easy way to adjust things for the visually handicapped, whether temporary or permanent.)\nEDIT-1: I am using Ubuntu 14.04.4 with Unity desktop.\nEDIT-2: I am asking not for a direct zoom or magnification where everying is increased at once and the desktop goes \"off-screen\" so that you have to move it around to see everything -- although come to think of it, it would be nice to know that, too, as that has its uses. I would like a way to increase the size of the text underneath the desktop icons and the size of the text in Files (Nautilus?) and possibly the size of the icons in the desktop and in files. Actually, increasing the size of most things, including window titles, pulldown menu text, etc. would be helpful as I cannot read the menus so well right now.\n\nA: PART ONE\nThere is a desktop zoom function which is configurable through the compizconfig-settings-manager.\nTo install, run the following commands in a terminal:\nsudo apt-get update\nsudo apt-get install compizconfig-settings-manager\n\nNow, run the following command to start it up or search ccsm in your desktop dash instead:\nccsm &\n\nUnder Accessibility, make sure the Enhanced Desktop Zoom has a tic in the box next to it.\nThen, click on the Enhanced Desktop Zoom plugin to configure it.\nI have mine set to Button1 to zoom in (Button1 is left-click on the mouse).\nI also have mine set to Button3 to zoom out (Button3 is right-click on the mouse). \nYou can also adjust the \"zoom factor\" and other settings.\n\nPART TWO\nIt may also be helpful to know that you can change the text scaling factor.\nFirst, install unity-tweak-tool:\nsudo apt-get install unity-tweak-tool\n\nStart up the unity-tweak-tool and click on \"fonts\". \nThe text scaling factor setting should be down on the right.\nThis makes the text larger without changing the size of everything else.\n\nPART THREE\nAdditionally, under System Settings > Universal Access you can toggle the large text option.\n\n\nI do not know of a keyboard shortcut for this but I seem to get used to large text and forget that it is on.\nTo change the icon size in nautilus and files:\nUse CTRL + + to increase the icon size and CTRL + - decrease the size of the icons.\n\nPART FOUR\nTo view text files, I use nano or vim the terminal. \nThe terminal I use is guake.\nguake is a drop down terminal that allows you to change the text size using the following keyboard combo: CTRL + + to increase the text size and CTRL + - decrease the size of the text in the terminal.\nAdditionally, I edit my .bashrc file to enable all color code options to make things easier to see according to color code.\n", "Q: How to move file into trash from a mounted diretory with symlink? I have a filesystem mounted under my home dir. For example, /home/user/mount/.\nI have a directory /home/user/mount/Downloads. And I have created a soft link to it with /home/user/Downloads.\nWhen I am using nautilus and I am under /home/user/Downloads, I try to move file to trash, it says:\n\ncan't be put in the trash. Do you want to delete it immediately?\n\nHowever, I can move it to trash when I am under /home/user/mount/Downloads.\nDoes any body know why and how to solve this problem?\n\nA: I've had the same problem, and then I made it worse!! (I'm sharing the big folders from home with a Suse gecko!\nAlas the problem lies with the file ownership and rights!\nIt seems that on Unix compliant drives, all the rights to the files and folders belong to root. Root created the .Trash-Xxxx when we evoked a Trash operation. \nSo we need to chown it to our-self and our main group (that normally is our name too (except in Suse and the like where it is users!).\nNow we need to set the rights, all folder-operations are ruled by the guid not the uuid so we need to append those rights, so go into the folder containing the .Trash-uuid, and run:\n\nchmod g+wx -R .Trash-1000\n\ng+wx sets the write and execute rights for your group.\n-R do it recursively\nBeware your uuid could be different so change it to match yours.\nNow set the execute bit for your user, sometime (mostly) they are missing!\n\nchmod u+x -R .Trash-1000\n\nNow you need to log out and back in (or reboot) to introduce the changes to the OS.\nNow it should work, but there will be a lot of cleaning up (after our-self).\nMost of the trash folders in the shared folders can be removed (BUT wait a week so you are positive they are no longer in use!\nSo Symbolic links works with Trash, bind-links do not!\nI had to use the T flag when creating the symlinks:\n\nln -sT /mnt/(Disk/Partition)/Pictures/ /home/UUID/Pictures\n\nAll of this is elsewhere on this site, I just found these helpfull bits!\n", "Q: Nvidia 760 GTX 14.04 Driver Install Problem I know there are lot of posts with similar titles... but I think I've tried about all of them.\nI can't seem to get nvidia drivers to work.\nFailure mode.\nI go through the below steps... After rebooting... the system will seem to boot normally (even a glimpse of the ubuntu splash page).. but eventually... all output from my HDMI will cease.. and my TV will just say \"no signal from HDMI\"\nSystem  \nNvidia 760GTX\nSamsung 46\" TV as Monitor\n Connected Via HDMI from video card to monitor.\nSteps.\n1. Clean install of ubuntu 14.04\n2. apt-get update && apt-get upgrade -y\n3. add-apt-repository ppa:graphics-drivers/ppa\n4. apt-get update\n\nfrom here it diverges..  first I tried\nubuntu-drivers autoinstall\n\nand I would get the failure mode described above.\nAll subsequent attempts... I instead would do a...\nubuntu-drivers devices\n\nand then \nsudo apt-get install nvidia-361\n\nFor this last step.. I started with the the 'recommended' driver listed here (364).. and then I tried the one nvidia recommends for the 760GTX on their website (361)... and then I tried all the rest...\nSame failure mode.\nAny ideas?  I'm wondering if others might have some insight into the failure mode where the HDMI signal just seems to get lost.\nThanks!\n\nA: It seems difficult to figure out the issue from the problems you just described. Primarily, I suspect this could be nouveau issue. \nIf you are installing Nvidia driver, then nouveau should be disabled. \nOne way you can do to disable nouveau is by adding nouveau.modeset=0 as kernel parameter :\n# grubby  --update-kernel=ALL  --args=nouveau.modeset=0\nand then reboot the system.\n\nA: The GTX760 has a DVI-I output connector. Try connecting a DVI to VGA adaptor to it and then connect to a monitor using a VGA cable. If this works then you will be able to play with the different drivers. The article by JoKeR seems very comprehensive.\n", "Q: Playing video prevents sleep on low battery When a video instance is displayed (firefox/chromium html5 video, openshot video editor etc.), the computer does not go to sleep under any circumstances, and it is even forced to stay until the battery drops down to 0.0% power. \nThis happens easily when the computer is not connected to aa power source and you leave it for a longer time, for example when you fall asleep or when you are unaware that some software or browser tab contains a video. Since dropping battery power to 0.0% is harmful to the hardware, I would like to have always the normal power management behavior for low critical power state.\nHow can I enforce Ubuntu going to sleep on critical power?\n(This could also be a bug, but Ubuntu makes it hard to report a bug without knowing the package.)\n\nA: Most Apps when playing videos are set to not let the pc go to sleep:\nCheck this link for an example\n", "Q: Where did I move my file to? Okay I just cd'ed ito my /Downloads directory on Ubuntu and typed\nmv file.zip ~.\n\nThe command executed but where did I move my file to ? I can't find it anywhere. I thought I kept it in the /home dir, but it's not there.\n\nA: If the . at the end is in your command, you moved it to ~. (your renamed the file, it is still in the same directory).\nIf the . is a mistake and not in your actual command, then you moved it to /home/username (the filename stays the same).\nRun the following command to move the file to your home directory:\nmv ~/Downloads/~. ~/file.zip\n\nYour home directory is ~/ not ~.\n", "Q: CIFS mount is not recoverable after sleep or hibernate I have Linux Mint Mate 17.3. The following mount points are defined in my fstab:\n//at.xxxxxx-it.net/ORG  /mnt/L  cifs    user,auto,credentials=/home/liptak/.cifs.secret 0   1\n//at.xxxxxx-it.net/shared   /mnt/M  cifs    user,auto,credentials=/home/liptak/.cifs.secret 0   1\n\nIf I boot, it works. As soon as I put the computer to sleep or hibernate, then it does not work anymore.\nliptak@vnwha-ent034 ~ $ ls -la /mnt/\nösszesen 20\ndrwxr-xr-x  5 root root 4096 febr  29 13:33 .\ndrwxr-xr-x 25 root root 4096 márc  30 10:14 ..\ndrwxr-xr-x  2 root root 4096 dec   22 12:33 L\ndrwxr-xr-x  2 root root 4096 febr  29 13:33 M\ndrwxr-xr-x  2 root root 4096 febr  29 13:33 U\n\nI tried the followings:\n\n\n*\n\n*ls /mnt/L -> hangs, cannot be interrupted\n\n*sudo mount -a -> hangs\n\n*sudo umount -a -t cifs -> umount: /mnt/L: device is busy.\n\n*lsof | grep /mnt/L -> hangs\n\n*fuser -km /mnt/L -> hangs, cannot be interrupted\n\n*sudo umount -f /mnt/L -> /mnt/L: device or resource is busy\n\n*sudo umount -l /mnt/L -> returns normally, but then a sudo mount -a hangs again.\n\n\nWhat do I wrong here? How could I investigate this?\n\nA: If you have an issue with this share, you can unmount it on hibernate/suspend and remount it on resume.\nIn order to do that you should create a script in /etc/pm/sleep.d/, call it 50-share_handling (for example), and put the next lines in it:\n#!/bin/sh\n# Unmount CIFS share on hibernate/suspend and remount it on resume\n\ncase \"$1\" in\n        hibernate|suspend)\n                umount /mnt/L\n                umount /mnt/M\n                ;;\n        thaw|resume)\n                mount /mnt/L\n                mount /mnt/M\n                ;;\n        *) exit $NA\n                ;;\nesac\n\nMake sure that it is executable.\nMore script examples can be found here: /usr/lib/pm-utils/sleep.d.\nSource for Debian Lenny, should be valid for Ubuntu.\n", "Q: strange messages about USB during the bootup and slow boot I have an ASUS X53S provided with Windows 7, months ago upgraded to Windows 10, and some week ago I installed Ubuntu on it.\nWhen I boot Ubuntu I see this messages for many seconds (maybe a minute)\n[    2.484345] usb 4-1-port3: over-current condition\n[    2.692231] usb 4-1-port4: over-current condition\n\nwhere the numbers in the square brackets change from boot to boot.\nWhat are these messages?\nThe output od lsusb is\nenrico:~$ lsusb\nBus 004 Device 004: ID 046d:c52f Logitech, Inc. Unifying Receiver\nBus 004 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub\nBus 004 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 003 Device 004: ID 0bda:0139 Realtek Semiconductor Corp. RTS5139 Card Reader Controller\nBus 003 Device 003: ID 058f:a014 Alcor Micro Corp. Asus Integrated Webcam\nBus 003 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub\nBus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\n\nThe 3 USB ports (1 blue and 2 black) correctly works.\nEDIT The command suggested by @mchid give this output \nenrico:~$ systemd-analyze blame\n         16.734s gpu-manager.service\n          9.536s NetworkManager-wait-online.service\n          8.225s plymouth-quit-wait.service\n          8.031s dev-sda6.device\n          7.537s apparmor.service\n          6.484s ModemManager.service\n          5.322s systemd-tmpfiles-setup.service\n          5.040s accounts-daemon.service\n          4.978s NetworkManager.service\n          3.897s teamviewerd.service\n          3.308s alsa-restore.service\n          3.308s systemd-user-sessions.service\n          3.307s apport.service\n          3.304s avahi-daemon.service\n          3.217s irqbalance.service\n          3.216s pppd-dns.service\n          3.215s speech-dispatcher.service\n          2.396s plymouth-start.service\n          2.053s lightdm.service\n          2.040s systemd-udevd.service\n          1.296s systemd-tmpfiles-setup-dev.service\n          1.234s dns-clean.service\n          1.174s systemd-journal-flush.service\nlines 1-23...skipping...\n         16.734s gpu-manager.service\n          9.536s NetworkManager-wait-online.service\n          8.225s plymouth-quit-wait.service\n          8.031s dev-sda6.device\n          7.537s apparmor.service\n          6.484s ModemManager.service\n          5.322s systemd-tmpfiles-setup.service\n          5.040s accounts-daemon.service\n          4.978s NetworkManager.service\n          3.897s teamviewerd.service\n          3.308s alsa-restore.service\n          3.308s systemd-user-sessions.service\n          3.307s apport.service\n          3.304s avahi-daemon.service\n          3.217s irqbalance.service\n          3.216s pppd-dns.service\n          3.215s speech-dispatcher.service\n          2.396s plymouth-start.service\n          2.053s lightdm.service\n          2.040s systemd-udevd.service\n          1.296s systemd-tmpfiles-setup-dev.service\n          1.234s dns-clean.service\n          1.174s systemd-journal-flush.service\n          1.127s systemd-tmpfiles-clean.service\nlines 1-24...skipping...\n         16.734s gpu-manager.service\n          9.536s NetworkManager-wait-online.service\n          8.225s plymouth-quit-wait.service\n          8.031s dev-sda6.device\n          7.537s apparmor.service\n          6.484s ModemManager.service\n          5.322s systemd-tmpfiles-setup.service\n          5.040s accounts-daemon.service\n          4.978s NetworkManager.service\n          3.897s teamviewerd.service\n          3.308s alsa-restore.service\n          3.308s systemd-user-sessions.service\n          3.307s apport.service\n          3.304s avahi-daemon.service\n          3.217s irqbalance.service\n          3.216s pppd-dns.service\n          3.215s speech-dispatcher.service\n          2.396s plymouth-start.service\n          2.053s lightdm.service\n          2.040s systemd-udevd.service\n          1.296s systemd-tmpfiles-setup-dev.service\n          1.234s dns-clean.service\n          1.174s systemd-journal-flush.service\n          1.127s systemd-tmpfiles-clean.service\n          1.039s grub-common.service\n          1.007s console-setup.service\n           932ms script_enrico.service\n           915ms systemd-logind.service\n           910ms rsyslog.service\n           882ms systemd-modules-load.service\n           729ms ifup-wait-all-auto.service\n           713ms wpa_supplicant.service\n           642ms polkitd.service\n           636ms networking.service\n           605ms systemd-backlight@backlight:acpi_video1.service\n           588ms udisks2.service\n           585ms systemd-journald.service\n           527ms systemd-rfkill@rfkill0.service\n           510ms systemd-udev-trigger.service\n           502ms systemd-random-seed.service\n           457ms colord.service\n           440ms plymouth-read-write.service\n           436ms ufw.service\n           399ms systemd-setup-dgram-qlen.service\n           398ms dev-hugepages.mount\n           348ms resolvconf.service\n           301ms kmod-static-nodes.service\n           277ms upower.service\n           257ms systemd-update-utmp.service\n           243ms dev-mqueue.mount\n           239ms systemd-backlight@backlight:acpi_video0.service\n           233ms systemd-remount-fs.service\n           208ms systemd-sysctl.service\n           205ms systemd-rfkill@rfkill1.service\n           156ms sys-kernel-debug.mount\n           134ms systemd-vconsole-setup.service\n           132ms dev-disk-by\\x2duuid-66a710be\\x2d064b\\x2d43e2\\x2d9426\\x2d7e7291463cbf.swap\n            95ms systemd-timedated.service\n            83ms systemd-backlight@backlight:intel_backlight.service\n            72ms ondemand.service\n            62ms systemd-hostnamed.service\n            61ms kerneloops.service\n            53ms user@1000.service\n            48ms systemd-timesyncd.service\n            34ms systemd-localed.service\n            33ms thermald.service\n             4ms ureadahead-stop.service\n             3ms rtkit-daemon.service\n             2ms systemd-update-utmp-runlevel.service\n             2ms rc-local.service\n             2ms sys-fs-fuse-connections.mount\nlines 32-71/71 (END)\n           713ms wpa_supplicant.service\n           642ms polkitd.service\n           636ms networking.service\n           605ms systemd-backlight@backlight:acpi_video1.service\n           588ms udisks2.service\n           585ms systemd-journald.service\n           527ms systemd-rfkill@rfkill0.service\n           510ms systemd-udev-trigger.service\n           502ms systemd-random-seed.service\n           457ms colord.service\n           440ms plymouth-read-write.service\n           436ms ufw.service\n           399ms systemd-setup-dgram-qlen.service\n           398ms dev-hugepages.mount\n           348ms resolvconf.service\n           301ms kmod-static-nodes.service\n           277ms upower.service\n           257ms systemd-update-utmp.service\n           243ms dev-mqueue.mount\n           239ms systemd-backlight@backlight:acpi_video0.service\n           233ms systemd-remount-fs.service\n           208ms systemd-sysctl.service\n           205ms systemd-rfkill@rfkill1.service\n           156ms sys-kernel-debug.mount\n           134ms systemd-vconsole-setup.service\n           132ms dev-disk-by\\x2duuid-66a710be\\x2d064b\\x2d43e2\\x2d9426\\x2d7e72914\n            95ms systemd-timedated.service\n            83ms systemd-backlight@backlight:intel_backlight.service\n            72ms ondemand.service\n            62ms systemd-hostnamed.service\n            61ms kerneloops.service\n            53ms user@1000.service\n            48ms systemd-timesyncd.service\n            34ms systemd-localed.service\n            33ms thermald.service\n             4ms ureadahead-stop.service\n             3ms rtkit-daemon.service\n             2ms systemd-update-utmp-runlevel.service\n             2ms rc-local.service\n             2ms sys-fs-fuse-connections.mount\n\nEDIT2 With the video drivers changed (actually the tested driver are nvidia-352), the lines I read on reboot are the following\n[    2.484345] usb 4-1-port3: over-current condition\n[    2.692231] usb 4-1-port4: over-current condition\nfsck from util-linux 2.26.2\n/dev/sda6: clean, 421817/3842048 files, 4507321/15359744 blocks\n\nwhere the numbers in square brackets and the two numerators in the last line change from boot to boot.\n\nA: This looks like it is nothing to worry about and seems to be an empty warning message. See here for more info.\nIf you are having boot issues, check the output of the following command:\nsystemd-analyze blame\n\n\nUPDATE:\nIt looks like a gpu issue. \nGo to \"system settings\" > \"software & update\" and then click on the \"additional drivers\" tab.\nSelect the \"proprietary\" nvidia driver that is listed as \"tested\". It should be \"nvidia-361\".\nApply the changes and reboot. This should speed up your boot process. Please post any more related issues or errors.\n", "Q: Can't start my-weather-indicator under 16.04 I just installed the Beta 2 of Ubuntu 16.04.\nAfter that I installed my-weather-indicator with this commands:\nsudo add-apt-repository ppa:atareao/atareao\nsudo apt-get update\nsudo apt-get install my-weather-indicator\n\nI wanted to start the program with:\n/opt/extras.ubuntu.com/my-weather-indicator/bin/my-weather-indicator\n\nBut I get this error log:\n/opt/extras.ubuntu.com/my-weather-indicator/bin/my-weather-indicator:27: PyGIWarning: Gtk was imported without specifying a version first. Use gi.require_version('Gtk', '3.0') before import to ensure that the right version gets loaded.\n  from gi.repository import Gtk\n/opt/extras.ubuntu.com/my-weather-indicator/bin/my-weather-indicator:28: PyGIWarning: Notify was imported without specifying a version first. Use gi.require_version('Notify', '0.7') before import to ensure that the right version gets loaded.\n  from gi.repository import Notify\n<gettext.GNUTranslations object at 0x7f2d5602b7b8>\n/opt/extras.ubuntu.com/my-weather-indicator/share/my-weather-indicator/myweatherindicator.py:31: PyGIWarning: AppIndicator3 was imported without specifying a version first. Use gi.require_version('AppIndicator3', '0.1') before import to ensure that the right version gets loaded.\n  from gi.repository import AppIndicator3 as appindicator\n/opt/extras.ubuntu.com/my-weather-indicator/share/my-weather-indicator/geocodeapi.py:30: PyGIWarning: GeocodeGlib was imported without specifying a version first. Use gi.require_version('GeocodeGlib', '1.0') before import to ensure that the right version gets loaded.\n  from gi.repository import GeocodeGlib\n/opt/extras.ubuntu.com/my-weather-indicator/share/my-weather-indicator/whereami.py:27: PyGIWarning: WebKit was imported without specifying a version first. Use gi.require_version('WebKit', '3.0') before import to ensure that the right version gets loaded.\n  from gi.repository import WebKit\n#####################################################\nSystem: Linux\nMachine: x86_64\nNode: TP420\nRelease: 4.4.0-15-generic\nVersion: #31-Ubuntu SMP Fri Mar 18 19:08:31 UTC 2016\nPlatform: Linux-4.4.0-15-generic-x86_64-with-Ubuntu-16.04-xenial\n#####################################################\n\nMy-Weather-Indicator version: 0.7.9-0extras15.10.0\n#####################################################\n\nHTTPConnectionPool(host='openweathermap.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.HTTPConnection object at 0x7f47b2481b38>, 'Connection to openweathermap.org timed out. (connect timeout=1)'))\nWaiting for internet\n\nHow can I fix this issue?\n// Edit:\nThis issue was actually fixed by the developer.\nSee here: https://bugs.launchpad.net/my-weather-indicator/+bug/1569161\n\nA: This issue was actually fixed by the developer. See here: https://bugs.launchpad.net/my-weather-indicator/+bug/1569161\n", "Q: How can i install Dreamweaver CS6 in UBuntu 15.10 I need one help.I need to install Adobe Dreamweaver CS6 only on my Ubuntu 15.01 machine. Can anybody please provide me the steps to install with the proper key.I have installed cs6 with patch .dll file in my windows machine so similarly how can i do this in Ubuntu. PLease help me the required steps.\n\nA: If you want to run Windows software on Linux, you have to use winehq (https://www.winehq.org/) or possibly crossover (https://www.codeweavers.com/products/crossover-linux) although crossover is payment.\nGreetings.\n", "Q: Notification when Wifi disconnect I run a script in terminal but sometimes wifi disconnects and script stops working. I am mostly away from the laptop, so is there a way to make me notify with sound when wifi disconnect?\n\nIn addition to Patrick Trentin's solution. If you want this kind\n  of script, you can try the python version of it. Both work well. Here: \nhttp://ubuntuforums.org/showthread.php?t=1490776\n\n\nA: A very simple script for achieving such a thing could be the following:\n#!/bin/bash\n\nPERIOD=10       # s.\nWARNING_TEXT=\"Warning: the connection to SKYNET was lost.\"\nLANGUAGE=\"en\"\nICON=\"notification-network-wireless-disconnected\"\n\n# conn_monitor.sh:\n# polls the connection state after PERIOD seconds, and reads aloud a warning message\n# in case there is no connection\n#\n# dependencies:\n# - sudo apt-get install espeak binutils libmad libnotify-bin\n# NOTES:\n# - nm-tool has been replaced by nmcli in newer versions of ubuntu (>= 15.04),\n#   see the output of `nmcli dev` to adapt this script to your needs.\n\nfunction conn_monitor() {\n    while true :\n    do\n        sleep ${PERIOD}\n        mem_data=$(nm-tool | grep \"State: connected\")\n\n        if [[ -z \"${mem_data}\" ]]; then\n            notify-send \"${WARNING_TEXT}\" -i ${ICON} -u critical\n            paplay /usr/share/sounds/freedesktop/stereo/suspend-error.oga\n            espeak -a 200 -v ${LANGUAGE} \"${WARNING_TEXT}\"\n        fi\n    done\n};\n\nif [[ \"$BASH_SOURCE\" == \"$0\" ]]; then\n    conn_monitor $@\nelse\n    export -f conn_monitor\nfi\n\nThen you can add a file named conn_monitor.desktop in ~/.config/autostart with the following content:\n[Desktop Entry]\nType=Application\nExec=..path..to..your..script..\nHidden=false\nNoDisplay=false\nX-GNOME-Autostart-enabled=true\nName=Conn Monitor\nComment=\n\nin which you correctly set the path to your script location.\n\nI tested the script on ubuntu 14.04.\n", "Q: Unpacking and configuring kvm components In this guide : http://www.linux-kvm.org/page/RunningKVM\nIt says \"If you are using a recent kernel (2.6.25+) with kvm modules included, boot into it\" \nWhat does it mean boot into the kernal? \n\nA: Ubuntu (and other distributions) can have multiple kernel versions installed but you can only (directly) use one at the time. The version is selected by the bootloader. I'm not sure if this applies to Chromebooks but on a normal PC, you'd hold Left Shift before Ubuntu loads and that'll show you the Grub bootloader and give you choices about which Kernel version you'd load.\nBut that's all academic for your purposes.\n\n\n*\n\n*2.6 is ancient. Modern Ubuntu is on 4.x kernels. You're okay here.\n\n*Use distribution-specific documentation. You don't have to download and compile KVM support yourself. https://help.ubuntu.com/community/KVM\n", "Q: How to open xz file into movie player program my friend sent me film with xz format and that file can't open. How to open that xz file in movie player program?\n\nA: xz is a compression file format. To uncompress it\nIf your file format is tar.xz use\ntar xf archive.tar.xz\n\nand if your file format is xz use\nunxz archive.xz\n\nIf you are having problem with tar xf command then you may need to install xz-utils .\nFYI xz-utils comes pre-installed in Ubuntu.\nTo install xz-utils use \nsudo apt-get install xz-utils\n\nYou can also use Nautilus to extract the files.\nAfter that use a video player to play your video.\n\nA: You first have to extract the .xz file. Open the nautilus file manager, right-click the file and select Extract Here. Now click on the extracted file and in case it has a format for which all the necessary media plugins are installed, your default media player will open and start playing.\n", "Q: Cannot find module 'crypto-js' Ubuntu 14.04 I am working with node-red and I am facing some issues with some packages I have downloaded from this github. I have followed the instructions to get npm and to install it but I get error with missing libraries that are present in my system, have anyone experienced the same?\nThanks in advance!\nlo@lo-desktop:~$ sudo npm install crypto-js\nnpm http GET https://registry.npmjs.org/crypto-js\nnpm http 200 https://registry.npmjs.org/crypto-js\nnpm http GET https://registry.npmjs.org/crypto-js/-/crypto-js-3.1.6.tgz\nnpm http 200 https://registry.npmjs.org/crypto-js/-/crypto-js-3.1.6.tgz\ncrypto-js@3.1.6 node_modules/crypto-js\n\nlocate crypto-js\n/home/lo/node_modules/crypto-js\n/home/lo/node_modules/crypto-js/CONTRIBUTING.md\n/home/lo/node_modules/crypto-js/LICENSE\n/home/lo/node_modules/crypto-js/README.md\n/home/lo/node_modules/crypto-js/aes.js\n/home/lo/node_modules/crypto-js/bower.json\n/home/lo/node_modules/crypto-js/cipher-core.js\n/home/lo/node_modules/crypto-js/core.js\n/home/lo/node_modules/crypto-js/crypto-js.js\n/home/lo/node_modules/crypto-js/docs\n/home/lo/node_modules/crypto-js/enc-base64.js\n/home/lo/node_modules/crypto-js/enc-hex.js\n/home/lo/node_modules/crypto-js/enc-latin1.js\n/home/lo/node_modules/crypto-js/enc-utf16.js\n/home/lo/node_modules/crypto-js/enc-utf8.js\n/home/lo/node_modules/crypto-js/evpkdf.js\n/home/lo/node_modules/crypto-js/format-hex.js\n/home/lo/node_modules/crypto-js/format-openssl.js\n/home/lo/node_modules/crypto-js/hmac-md5.js\n/home/lo/node_modules/crypto-js/hmac-ripemd160.js\n/home/lo/node_modules/crypto-js/hmac-sha1.js\n/home/lo/node_modules/crypto-js/hmac-sha224.js\n/home/lo/node_modules/crypto-js/hmac-sha256.js\n/home/lo/node_modules/crypto-js/hmac-sha3.js\n/home/lo/node_modules/crypto-js/hmac-sha384.js\n/home/lo/node_modules/crypto-js/hmac-sha512.js\n/home/lo/node_modules/crypto-js/hmac.js\n/home/lo/node_modules/crypto-js/index.js\n/home/lo/node_modules/crypto-js/lib-typedarrays.js\n/home/lo/node_modules/crypto-js/md5.js\n/home/lo/node_modules/crypto-js/mode-cfb.js\n/home/lo/node_modules/crypto-js/mode-ctr-gladman.js\n/home/lo/node_modules/crypto-js/mode-ctr.js\n/home/lo/node_modules/crypto-js/mode-ecb.js\n/home/lo/node_modules/crypto-js/mode-ofb.js\n/home/lo/node_modules/crypto-js/package.json\n/home/lo/node_modules/crypto-js/pad-ansix923.js\n/home/lo/node_modules/crypto-js/pad-iso10126.js\n/home/lo/node_modules/crypto-js/pad-iso97971.js\n/home/lo/node_modules/crypto-js/pad-nopadding.js\n/home/lo/node_modules/crypto-js/pad-pkcs7.js\n/home/lo/node_modules/crypto-js/pad-zeropadding.js\n/home/lo/node_modules/crypto-js/pbkdf2.js\n/home/lo/node_modules/crypto-js/rabbit-legacy.js\n/home/lo/node_modules/crypto-js/rabbit.js\n/home/lo/node_modules/crypto-js/rc4.js\n/home/lo/node_modules/crypto-js/ripemd160.js\n/home/lo/node_modules/crypto-js/sha1.js\n/home/lo/node_modules/crypto-js/sha224.js\n/home/lo/node_modules/crypto-js/sha256.js\n/home/lo/node_modules/crypto-js/sha3.js\n/home/lo/node_modules/crypto-js/sha384.js\n/home/lo/node_modules/crypto-js/sha512.js\n/home/lo/node_modules/crypto-js/tripledes.js\n/home/lo/node_modules/crypto-js/x64-core.js\n/home/lo/node_modules/crypto-js/docs/QuickStartGuide.wiki\n\n\n\nlo@lo-desktop:~$ node-red -v\nWelcome to Node-RED\n===================\n\n12 Apr 09:11:41 - [info] Node-RED version: v0.13.4\n12 Apr 09:11:41 - [info] Node.js  version: v0.10.25\n12 Apr 09:11:41 - [info] Linux 4.2.0-27-generic ia32 LE\n12 Apr 09:11:41 - [info] Loading palette nodes\n12 Apr 09:11:43 - [warn] ------------------------------------------\n12 Apr 09:11:43 - [warn] [rpi-gpio] Info : Ignoring Raspberry Pi specific node\n12 Apr 09:11:43 - [warn] [TTN] Error: Cannot find module 'crypto-js'\n12 Apr 09:11:43 - [warn] ------------------------------------------\n12 Apr 09:11:43 - [info] Settings file  : /home/lo/.node-red/settings.js\n12 Apr 09:11:43 - [info] User directory : /home/lo/.node-red\n12 Apr 09:11:43 - [info] Flows file : /home/lo/.node-red/flows_loshora-desktop.json\n12 Apr 09:11:43 - [info] Server now running at http://127.0.0.1:1880/\n12 Apr 09:11:43 - [info] Starting flows\n12 Apr 09:11:43 - [info] Started flows\n\n\nA: npm usually does not need sudo to install anything. Can u install crypto-js module without sudo? \nAlso, I am little confused about your project structure. Is your home folder your project folder too? \nBesides, you can always load a module at runtine using require (see https://nodejs.org/api/modules.html#modules_module_require_id) \n", "Q: Ubuntu Server running in Virtual Box - Network not connecting to Wifi bridged adapter I have successfully installed Ubuntu 14.04 server on (Windows 10) VirtualBox (Version 5.0.16 r105871 ) by following the steps on here:  http://twoggle.com/blog/lamp-local-development-environment-virtualbox/\nI selected Bridged adapter under the virtual machine's network settings:\n(I am on wireless Wifi connection, which is connected OK on host system - I can access internet OK)\n\nBut the network adapter connection is not working: During Ubuntu server load, when it gets to network load, it waits for network config for a long time then gives up eventually:\n\nAfter running ifconfig (once logged into Ubuntu), it has no IP address under the eth0 section.\nI tried applying psusi's answer on here:\nGetting I.P address of Ubuntu Server running in Virtual Box but similar to the original poster on that question, the entry for eth0 already exists in network/interfaces file. \nI also do not have a 70-persistent-net.rules file on my ubuntu system at all. \nI've not had these troubles before when directly plugged in with Ethernet cable to the network, only on Wireless. I am not able to use a Ethernet cable at the moment and must use wireless.\nAny help much appreciated, this is very frustrating!\n\nA: OK got it working using this mega helpful post:\nhttp://christophermaier.name/blog/2010/09/01/host-only-networking-with-virtualbox\nNote that only address 192.168.56.102 worked (not ending in .101 - must have caused a conflict with something else)\n\nA: I found excellent some of the explanations in here: chapter 6\n\nThere are/were some know limitations when using WiFi bridged adapter as you experienced these.\nHonestly, host-only is the great solution if you just need to have the communication with the host machine. \nHopefully this helps.\n", "Q: ClamAV Daemon ubuntu I am trying to install ClamAV in ubuntu as per the instructions in\n\nblog.dutchcoders.io/installing-clamav-from-source/\n\nEverything worked perfectly except last step i.e.,\n\nclamd &\n\nWhen i run the above command it is showing\n\nERROR: Please define server type (local and/or TCP).\n\nWhen i used the command\n\nsudo clamdscan -v\n\nI got the output as\n\nERROR: Could not lookup : Servname not supported for ai_socktype\n----------- SCAN SUMMARY -----------\nInfected files: 0\nTotal errors: 1\nTime: 0.000 sec (0 m 0 s)\n\nI followed all the solutions in Error starting ClamAV daemon But no hope. Is there any other way to resolve it?\n\nA: By editing clamd.conf as below, the problem solves\n# Log additional information about the infected file, such as its\n# size and hash, together with the virus name.\n#ExtendedDetectionInfo yes\n\n# This option allows you to save a process identifier of the listening\n# daemon (main thread).\n# Default: disabled\nPidFile /var/run/clamd.pid\n\n# Optional path to the global temporary directory.\n# Default: system specific (usually /tmp or /var/tmp).\nTemporaryDirectory /var/tmp\n\n# Path to the database directory.\n# Default: hardcoded (depends on installation options)\nDatabaseDirectory /usr/local/share/clamav\n\n# Only load the official signatures published by the ClamAV project.\n# Default: no\n#OfficialDatabaseOnly no\n\n# The daemon can work in local mode, network mode or both. \n# Due to security reasons we recommend the local mode.\n\n# Path to a local socket file the daemon will listen on.\n# Default: disabled (must be specified by a user)\nLocalSocket /tmp/clamd.socket\n\nNow if i enter 'clamd &' it is showing\n\n[3] 12859\n\nThen 'sudo service clamav-daemon start' shows\n\n[3]   Done                    clamd\n\nThen 'clamdscan -v' shows\n\n/usr/local/etc: OK\n----------- SCAN SUMMARY -----------\nInfected files: 0\nTime: 0.017 sec (0 m 0 s)\n\nThen 'clamdscan -V' shows\n\nClamAV 0.99.1/21490/Tue Apr 12 08:04:23 2016\n\n", "Q: Blank screen after login after using Testdisk I was trying to recover a corrupted EXTERNAL hard drive using TestDisk.\nAfter reboot, the  external hard drive seemed to be detected but I cannot login to my Ubuntu account. When I login, the GUI doesn't load. Just the purple wallpaper.\nI can only either login as a Guest (and not access my files) or login via Ctrl+Alt+F1. Because I can login via the terminal, I see my files are still intact.\nMy question is how do I be able to use my account normally (with the GUI)? Thanks!\n\nA: Solved it. It was because my hard drive was full. I uninstalled something and it's fine now.\n", "Q: Problem when starting a single node of Hadoop cluster in Ubuntu I am new to Hadoop and I was going through the installation process mentioned here. I have installed hadoop-1.2.1 on my system. After configuring everything when I tried to start a single node cluster I got the following error:\n$ /usr/local/hadoop-1.2.1/bin/start-all.sh\nmkdir: cannot create directory ‘/usr/local/hadoop-1.2.1/libexec/../logs’: Permission denied\nchown: cannot access ‘/usr/local/hadoop-1.2.1/libexec/../logs’: No such file or directory\nstarting namenode, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-namenode-asad-HP-15-Notebook-PC.out\n/usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 137: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-namenode-asad-HP-15-Notebook-PC.out: No such file or directory\nhead: cannot open ‘/usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-namenode-asad-HP-15-Notebook-PC.out’ for reading: No such file or directory\n/usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 147: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-namenode-asad-HP-15-Notebook-PC.out: No such file or directory\n/usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 148: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-namenode-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: mkdir: cannot create directory ‘/usr/local/hadoop-1.2.1/libexec/../logs’: Permission denied\nlocalhost: chown: cannot access ‘/usr/local/hadoop-1.2.1/libexec/../logs’: No such file or directory\nlocalhost: starting datanode, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-datanode-asad-HP-15-Notebook-PC.out\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 137: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-datanode-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: head: cannot open ‘/usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-datanode-asad-HP-15-Notebook-PC.out’ for reading: No such file or directory\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 147: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-datanode-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 148: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-datanode-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: mkdir: cannot create directory ‘/usr/local/hadoop-1.2.1/libexec/../logs’: Permission denied\nlocalhost: chown: cannot access ‘/usr/local/hadoop-1.2.1/libexec/../logs’: No such file or directory\nlocalhost: starting secondarynamenode, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-secondarynamenode-asad-HP-15-Notebook-PC.out\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 137: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-secondarynamenode-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: head: cannot open ‘/usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-secondarynamenode-asad-HP-15-Notebook-PC.out’ for reading: No such file or directory\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 147: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-secondarynamenode-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 148: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-secondarynamenode-asad-HP-15-Notebook-PC.out: No such file or directory\nmkdir: cannot create directory ‘/usr/local/hadoop-1.2.1/libexec/../logs’: Permission denied\nchown: cannot access ‘/usr/local/hadoop-1.2.1/libexec/../logs’: No such file or directory\nstarting jobtracker, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-jobtracker-asad-HP-15-Notebook-PC.out\n/usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 137: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-jobtracker-asad-HP-15-Notebook-PC.out: No such file or directory\nhead: cannot open ‘/usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-jobtracker-asad-HP-15-Notebook-PC.out’ for reading: No such file or directory\n/usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 147: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-jobtracker-asad-HP-15-Notebook-PC.out: No such file or directory\n/usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 148: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-jobtracker-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: mkdir: cannot create directory ‘/usr/local/hadoop-1.2.1/libexec/../logs’: Permission denied\nlocalhost: chown: cannot access ‘/usr/local/hadoop-1.2.1/libexec/../logs’: No such file or directory\nlocalhost: starting tasktracker, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-tasktracker-asad-HP-15-Notebook-PC.out\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 137: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-tasktracker-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: head: cannot open ‘/usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-tasktracker-asad-HP-15-Notebook-PC.out’ for reading: No such file or directory\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 147: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-tasktracker-asad-HP-15-Notebook-PC.out: No such file or directory\nlocalhost: /usr/local/hadoop-1.2.1/bin/hadoop-daemon.sh: line 148: /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-hduser-tasktracker-asad-HP-15-Notebook-PC.out: No such file or directory\n\n\nA: I was just missing to run this command as root.That's why i was getting that error.Now works fine after prepending sudo before the command, ie:\nsudo /usr/local/hadoop-1.2.1/bin/start-all.sh\n\n", "Q: How do I transpose a row to a column in a tab-delimited file? I have a tab-delimited file with a number and the names belonging to the same number on the same row. The number and names are separated by a tab. The names are linked with each other by 2 underscores (__). It looks like this:\n33  Hhe.1__Hhe.2__Hhe.3__Hhe.4\n\nI would like to convert it (by using the command line) to this output:\n33  Hhe.1\n33  Hhe.2\n33  Hhe.3\n33  Hhe.4\n\n\nA: With awk:\n$ awk -F '\\t|__' '{for (i=2;i<=NF;i++) {printf \"%s\\t%s\\n\", $1, $i}}' foo.txt \n33  Hhe.1\n33  Hhe.2\n33  Hhe.3\n33  Hhe.4\n\n\n\n*\n\n*We split the lines into fields based on tab (\\t) or two underscores (__).\n\n*Then we loop over fields from the second till the last, and print each prefixed with the first field and a tab.\n\n\nA: You can use a perl one-liner for that:\nperl -ane '@l=split(/__/,$F[1]); foreach $val (@l){print $F[0],\"\\t\",$val,\"\\n\"}'\n\nExample:\n$ echo \"33  Hhe.1__Hhe.2__Hhe.3__Hhe.4\" | perl -ane '@l=split(/__/,$F[1]); foreach $val (@l){print $F[0],\"\\t\",$val,\"\\n\"}'\n33  Hhe.1\n33  Hhe.2\n33  Hhe.3\n33  Hhe.4\n\nExplanation of the commands used:\nperl -ane                    #read input line-wise and split line on tab\n'@l=split(/__/,$F[1]);       #split the second element ($F[1]) on a double _\nforeach $val (@l){           #for each value, print the first element and the value.\n  print $F[0],\"\\t\",$val,\"\\n\"\n }'\n\n\nA: Another way using Perl:\nperl -lane '$,=\"\\n\"; print(map($F[0] . \"\\t\" . $_, split(\"__\", $F[1])))' file\n\nperl -lane '\n    $,=\"\\n\";\n    print(map($F[0] . \"\\t\" . $_, split(\"__\", $F[1])))\n' file\n\n\n\n*\n\n*-l[octnum]: enables automatic line-ending processing. It has two separate effects. First, it automatically chomps $/ (the input record separator) when used with -n or -p. Second, it assigns $\\ (the output record separator) to have the value of octnum so that any print statements will have that separator added back on. If octnum is omitted, sets $\\ to the current value of $/.\n\n*-a: turns on autosplit mode when used with a -n or -p. An implicit split command to the @F array is done as the first thing inside the implicit while loop produced by the -n or -p.\n\n*-n: causes Perl to assume the following loop around your program, which makes it iterate over filename arguments somewhat like sed -n or awk:\nLINE:\n  while (<>) {\n      ...             # your program goes here\n  }\n\n\n*-e: may be used to enter one line of program;\n\n*$,=\"\\n\"; print(map($F[0] . \"\\t\" . $_, split(\"__\", $F[1]))); sets the output field separator to a newline character, splits the second field on __ and prepends the first field followed by a tabulation to each subfield, finally printing the record.\n\n\n% cat file\n33  Hhe.1__Hhe.2__Hhe.3__Hhe.4\n% perl -lane '$,=\"\\n\"; print(map($F[0] . \"\\t\" . $_, split(\"__\", $F[1])))' file\n33  Hhe.1\n33  Hhe.2\n33  Hhe.3\n33  Hhe.4\n\n\nA: Yet another perl one-liner:\n$ perl -lane 'print \"$F[0]\\t$_\" for split(/__/,$F[1])' file \n33  Hhe.1\n33  Hhe.2\n33  Hhe.3\n33  Hhe.4\n\nThis is the same basic idea as the existing Perl answers, only shorter. The -a automatically splits each line of the input file on whitespaces and makes the resulting fields available as the array @F. So, $F[0] is the 1st field, $F[1] the second and so on. The -n means \"read each input file line by line and apply the script given by -e. The -l removes trailing \\n characters from each input line and adds a \\n to each print call.\nsplit(/__/,$F[1]) creates an array by splitting the 1st field of the file on the characters __. So, print \"$F[0]\\t$_\" for split... will iterate over the array returned by the split call and print the first field of the file ($F[0]), a tab character \\t and the current field of the split array. \n\nA: Similar to what muru suggested: what about splitting the second field based on __ and then looping through the slices?\nawk 'BEGIN{FS=OFS=\"\\t\"}\n     {n=split($2,a,\"__\"); for (i=1;i<=n;i++) print $1, a[i]}' file\n\nThis uses the fact that split() returns the number of elements created.\nAlso, it sets the Input and Output Field Separators to the tab, so that you then don't have to mention it when you print. In fact, FS doesn't need to be set here, because FS defaults to the space and tab is included.\nIt returns:\n33  Hhe.1\n33  Hhe.2\n33  Hhe.3\n33  Hhe.4\n\n", "Q: Problem with sudo apt-get update on Ubuntu 14.04 virtual machine My problem began when I was tried to install the mmtsb (multiscale modelling toolset for structural biology) on an Ubuntu 14.04 Virtual Machine on a Windows Host.\nI tried giving the ./install.sh command. But this was the error which propped up:\nbash: ./install.sh: /bin/csh: bad interpreter: No such file or directory\n\nTo resolve this I tried the following command:\nsudo apt-get install csh\n\nThis in turn gave the following error: \nUnable to locate package csh\n\nI tried next to update the packages using:\nsudo apt-get update\n\nThis in turn gave my the following error:\nErr http://security.ubuntu.com trusty-security InRelease\nErr http://security.ubuntu.com trusty-security Release.gpg                 \nCannot initiate the connection to security.ubuntu.com:80 (2001:67c:1562::19). - connect (101: Network is unreachable) [IP: 2001:67c:1562::19 80]  \nW: Some index files failed to download. They have been ignored, or old ones used instead.\n\nWhat do I do now ?\n\nA: I didn't understand your problem but you may try this. By this may be you able to install packages using apt-get.\nhttps://stackoverflow.com/questions/30316812/ubuntu-apt-get-unable-to-fetch-packages/35096935#35096935\n", "Q: Installing git on ubuntu 14.04 crashed I'm unable to install git on ubuntu here is the response \nsudo apt-get install git\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n git : Depends: liberror-perl but it is not installable\nE: Unable to correct problems, you have held broken packages.\n\nAlso I've tried installing liberror-perl which I couldn't\nsudo apt-get install liberror-perl\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nPackage liberror-perl is not available, but is referred to by another package.\nThis may mean that the package is missing, has been obsoleted, or\nis only available from another source\n\nE: Package 'liberror-perl' has no installation candidate\n\n\nA: Please follow mentioned below steps:\nStep-1: \nsudo apt-get update\n\nStep-2: \nsudo apt-get install git\n\nStep-3:\nSudo apt-get autoclean\n\nStep-4: \nSudo apt-get autoremove\n\n", "Q: Not able to disable Airplane mode on Ubuntu 16.04 My computer's in-built wifi card with a RT3290 chipset stopped working on Ubuntu 15.10 so I bought a usb wifi with a RT2870 chipset, which was working fine out of the box. After upgrading to Ubuntu 16.04, this has stopped working. \nThe rfkill list command shows that the usb wifi is neither hard-blocked nor soft-blocked.\nrfkill list\n0: phy0: Wireless LAN\n    Soft blocked: no\n    Hard blocked: yes\n1: phy1: Wireless LAN\n    Soft blocked: no\n    Hard blocked: no`\n\nIn the connection settings, it shows that the Airplane mode is on and it cannot be turned off since it is greyed out.\nAny help would be appreciated.\nThe following is the output of sudo lshw -class network.\n*-network DISABLED      \n       description: Wireless interface\n       product: RT3290 Wireless 802.11n 1T/1R PCIe\n       vendor: Ralink corp.\n       physical id: 0\n       bus info: pci@0000:08:00.0\n       logical name: wlo1\n       version: 00\n       serial: 34:23:87:b0:61:1d\n       width: 32 bits\n       clock: 33MHz\n       capabilities: pm msi pciexpress bus_master cap_list ethernet physical wireless\n       configuration: broadcast=yes driver=rt2800pci driverversion=4.4.0-18-generic firmware=N/A latency=0 link=no multicast=yes wireless=IEEE 802.11bgn\n       resources: irq:18 memory:c2610000-c261ffff\n  *-network\n       description: Ethernet interface\n       product: RTL8101/2/6E PCI Express Fast/Gigabit Ethernet controller\n       vendor: Realtek Semiconductor Co., Ltd.\n       physical id: 0\n       bus info: pci@0000:09:00.0\n       logical name: eno1\n       version: 08\n       serial: a0:d3:c1:60:0e:98\n       size: 100Mbit/s\n       capacity: 100Mbit/s\n       width: 64 bits\n       clock: 33MHz\n       capabilities: pm msi pciexpress msix vpd bus_master cap_list ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd autonegotiation\n       configuration: autonegotiation=on broadcast=yes driver=r8169 driverversion=2.3LK-NAPI duplex=full firmware=rtl8106e-2_0.0.1 04/23/13 ip=10.109.141.50 latency=0 link=yes multicast=yes port=MII speed=100Mbit/s\n       resources: irq:43 ioport:4000(size=256) memory:c2504000-c2504fff memory:c2500000-c2503fff\n  *-network DISABLED\n       description: Wireless interface\n       physical id: 1\n       bus info: usb@2:6\n       logical name: wlxc83a35ca4110\n       serial: c8:3a:35:ca:41:10\n       capabilities: ethernet physical wireless\n       configuration: broadcast=yes driver=rt2800usb driverversion=4.4.0-18-generic firmware=N/A link=no multicast=yes wireless=IEEE 802.11bgn\n\nAlso:\ndmesg | grep -i firmware\n[    0.274694] [Firmware Bug]: ACPI: BIOS _OSI(Linux) query ignored\n[    2.131418] [Firmware Bug]: Invalid critical threshold (0)\n[    2.595655] [Firmware Bug]: ACPI(PEGP) defines _DOD but not _DOS\n\nUPDATE:\noutput of \nlsmod | grep -e lap -e wmi:\nhp_wmi                 16384  0\nsparse_keymap          16384  1 hp_wmi\nwmi                    20480  1 hp_wmi\n\n\nA: The driver for the apparently inoperative internal device may be interfering. Let's unload it and blacklist it. Please open a terminal and do:\nsudo -i\nmodprobe -r rt2800pci\necho \"blacklist rt2800pci\"  >>  /etc/modprobe.d/blacklist.conf\nexit\n\nYou should be all set.\n\nA: I am using a Toshiba Satellite 855D with a realtek8188ce using the rtl8192ce driver and wireless went dead with the 16.04 upgrade and I tried everything posted on various forums and still no joy.\nWhat did work was powering off (not just a reset) \nRemoving the driver from the blacklist \nTurn off airplane mode under network settings, then watching the wireless button/switch ...\npressing the FN key with F12 and then the Windows key with F12 (wireless sym) multiple times and stopping once the wireless switch toggles on.\nGranted I never touched the F12 key (with wireless icon) and it should not even work under Ubuntu, BUT, it worked for me to turn on wifi when nothing else worked including the blacklist and FSTAB files.\n", "Q: How do I merge tab-delimited files? I have 3 tab-delimited files as shown below:\nFile 1:\n1   Hhe.7\n2   Hpyl.1\n10  Hac.2\n\nFile 2:\n3   Hac.2\n15  Hpyl.1\n33  Hhe.7\n\nFile 3: \n70  Hpyl.1\n23  Hhe.7\n9   Hac.2\n\nHow do I merge these files (using the command line) in one file to obtain the following output:\n1  33  23  Hhe.7\n2  15  70  Hpyl.1\n10  3  9  Hac.2\n\n\nA: The classic UNIX tool for this is join:\nNAME\n       join - join lines of two files on a common field\n\nSYNOPSIS\n       join [OPTION]... FILE1 FILE2\n\nDESCRIPTION\n       For  each  pair of input lines with identical join fields, write a line\n       to standard output.  The default join field is the first, delimited  by\n       blanks.\n\nHowever, join i) needs its input to be sorted in order to work and ii) can only deal with 2 files. So, you could do something ugly and inelegant like:\n\n\n*\n\n*Sort each file on the second field and save as a new file\nsort -k2 file1 > sorted1\nsort -k2 file2 > sorted2\nsort -k2 file3 > sorted3\n\n\n*Join files 1 and 2 into a new file and then join the third\n$ join -j2 --nocheck-order sorted1 sorted2 > newfile\n$ join -o 1.2,1.3,2.1,1.1  -1 1 -2 2 --nocheck-order newfile sorted3 \n10 3 9 Hac.2\n1 33 23 Hhe.7\n2 15 70 Hpyl.1\n\nThe options used are:\n   -1 FIELD\n          join on this FIELD of file 1\n\n   -2 FIELD\n          join on this FIELD of file 2\n   -j FIELD\n          equivalent to '-1 FIELD -2 FIELD'\n\n   --nocheck-order\n          do not check that the input is correctly sorted\n\n   -o FORMAT\n          obey FORMAT while constructing output line\n   FORMAT is one or more  comma  or  blank  separated\n   specifications, each being 'FILENUM.FIELD' or '0'. \n\nSo, that command will join on the 1st field of the first file and the 2nd field of the second file, and will print the 2nd field of the first file (1.2), then the third field of the first file (1.3), the first field of the second file (2.1) and the 1st field of the first file (1.1).\nAlternatively, you could combine the entire thing in one gloriously complicated command:\n$ join -o 1.1,2.2,2.3,2.1 -1 2 -2 1  --nocheck-order <(sort -k2 file3) \\\n      <(join -j2  --nocheck-order <(sort -k2 file1) <(sort -k2 file2)) \n9 10 3 Hac.2\n23 1 33 Hhe.7\n70 2 15 Hpyl.1\n\n\nIf you don't like arcane command line-fu, you can always use a little script:\n$ awk '{a[$NF]=$1\"\\t\"a[$NF];} END{for(i in a){print a[i],i}}' file{1,2,3} \n23  33  1    Hhe.7\n9   3   10   Hac.2\n70  15  2    Hpyl.1\n\n\nA: This is a job for join, which can join on common fields of two files:\n$ join -11 -22 -o1.2,1.3,2.1,0 <(join -j2 <(sort -k2,2 f1.txt) <(sort -k2,2 f2.txt)) <(sort -k2,2 f3.txt)\n10 3 9 Hac.2\n1 33 23 Hhe.7\n2 15 70 Hpyl.1\n\nAs join takes only two input files at a time, we have used process substitution (<()) to pass the output of join-ing first two files with the third.\n\nA: In a small python script, you can combine an unlimited number of files:\n#!/usr/bin/env python3\nimport sys\n\n#read the files, split the lines for reordering\nlines = sum([[l.strip().split() for l in open(f).readlines()]\\\n             for f in sys.argv[1:]], [])\n# get the unique last sections\nvalues = set(map(lambda x:x[1], lines))\n# combine them with the combined first sections\nnewlist = [[y[0] for y in lines if y[1]==x]+[x] for x in values]\nfor l in newlist:\n    print((\"\\t\").join(l))\n\nCopy it into an empty file, save it as merge.py, run it by the command:\npython3 /path/to/merge.py file1, file2, file3 (file4, file5 etc.)\n\nOutput on your example files:\n10  3   9   Hac.2\n1   33  23  Hhe.7\n2   15  70  Hpyl.1\n\nAdding more files\nAs mentioned, the number of files is in principle unlimited, if I add a 4th file:\n40   Hhe.7\n50   Hpyl.1\n60   Hac.2\n\nand run the command:\npython3 /path/to/merge.py file1, file2, file3, file4\n\nthe output will be:\n40  23  33  1   Hhe.7\n50  70  15  2   Hpyl.1\n60  9   3   10  Hac.2\n\n\nA: With awk:\nawk -F\"\\t\" -v OFS=\"\\t\" '!(a[$2]){a[$2]=$1;next}\n{a[$2]=a[$2]\"\\t\"$1} \nEND{\nfor ( i in a) {\n    print a[i],i\n    }\n}'\n\n\nA: Answer from: \n\n\n*\n\n*shell script - Merge some tab-delimited files - Unix & Linux Stack Exchange\n\nThe following script ought to do an outer join on column (field) 1 of\n  all the tab-delimited files passed as arguments. It uses the\n  join\n  command, which does an outer join on sorted files, 2 files at a time.\nIt will join every line in the files, including the header lines. If\n  you want the headers to be excluded, change the two sort commands to\n  something that produces a sorted file that omits them.\n#!/bin/sh\nif test $# -lt 2\nthen\n    echo usage: gjoin file1 file2 ...\n    exit 1\nfi\nsort -t $'\\t' -k 1 \"$1\" > result\nshift\nfor f in \"$@\"\ndo\n    sort -t $'\\t' -k 1 \"$f\" > temp\n    join -1 1 -2 1 -t $'\\t' result temp > newresult\n    mv newresult result\ndone\ncat result\nrm result temp\n\nIf you have an older shell, $'\\t' will not be replaced by a tab, so\n  you'll need to use  'TAB', where you\n  put a literal tab between the quotes.\nOptimizations are possible if, instead of /bin/sh, you can use a\n  modern shell such as bash or ksh; for instance, the lines\nsort -t $'\\t' -k 1 \"$f\" > temp\njoin -1 1 -2 1 -t $'\\t' result temp > newresult\n\ncan be replaced by\njoin -1 1 -2 1 -t $'\\t' result <(sort -t $'\\t' -k 1 \"$f\") > newresult\n\n\n", "Q: libreoffice base - cli insertion of records? I need to script the insertion of records into a database.  For this project (my first such), I'm using libreoffice Base with, for no particular reason, an HSQLDB back-end.  Is there a cli interface that would let me do that?\n\nA: The easiest way to manipulate a HSQLDB database by means of scripts would be to use the tool sqltool provided in the package. You can do things like:\nhsqldb-sqltool urlid --SQL=\"SQL statement 1; SQL statement 2; ...\"\n\n(where urlid is a file containing connection details), or read a bunch of SQL statements from a file, like this:\nhsqldb-sqltool urlid file1.sql\n\nNB: As @tohuwawohu points out, the database needs to be set up as a server to access it this way, rather than as \"embedded\", which is the first thing LibreOffice Base offers.\n", "Q: When booting my bios pops up i think? And it sais this a bunch of times [  158.926996] usb 2-6: Device not responding to set address.\n[  159.131119] usb 2-6: Device not responding to set address.\n\nBut I'm not booting off a usb device. Originally when I downloaded Ubuntu I believe that I had. Its been doing this ever since I installed Ubuntu onto my laptop as the main system. I only use Ubuntu. I don't believe it's affecting anything but it just annoys me that it says error cant find address. I'm not sure what I need to post in order to solve this issue. Any help would be highly appreciated. Thank You\n\nA: USB has over-current protection, which gets triggered when power consumption from the port is too high.\nUnplug all USB devices from PC, turn power off, and wait a minute or two. Plug everything back and boot into Linux.\nI cant take credit for this. I found it at https://paulphilippov.com/articles/how-to-fix-device-not-accepting-address-error\n", "Q: Is there a 'Power Monitor' for Ubuntu GNOME? I am running Ubuntu GNOME 15.10 with GNOME 3.18, and there is one thing lacking, a power monitor tool which will display the status, the one in Ubuntu MATE looks like this:\n\n\nUbuntu (Unity) also has a similar one, but I can't seem to find one installed by default on Ubuntu GNOME, so is there one that I just haven't found or one that I can install that's made for GNOME, or is not DE specific?\n\nA: You can find the following power managers in the Ubuntu repositories :  \ngnome-power-manager\nmate-power-manager\nxfce4-power-manager \nThese power managers have the design as shown in your screenshots.  \nAlternatively you can install the powertop tool from the repositories.  \nPowerTOP is a Linux tool to diagnose issues with power consumption and\npower management.\nIt reports which components in the system are most likely to blame\nfor higher-than-needed power consumption, ranging from software\napplications to active components in the system. Detailed screens are\navailable for CPU states, device activity and software activity.  \nAdditional information -> Intel Open Source PowerTOP Overview |   PowerTOP User's Guide\nTecmint -> PowerTOP Monitors Total Power Usage and Improves Linux Laptop Battery Life\n\nA: The Unity tool is likely from GNOME: gnome-power-statistics. The package is named gnome-power-manager, and I think the MATE version is called mate-power-statistics (and mate-power-manager).\n", "Q: Confusion between clamscan and clamdscan If i am running clamscan -v under clamav-0.99.1 package, it is showing\n----------- SCAN SUMMARY -----------\nKnown viruses: 4297948\nEngine version: 0.99.1\nScanned directories: 1\nScanned files: 39\nInfected files: 0\nData scanned: 5.25 MB\nData read: 2.37 MB (ratio 2.22:1)\nTime: 6.649 sec (0 m 6 s)\n\nIf i am running clamdscan -v under clamav-0.99.1 package, it is showing\n----------- SCAN SUMMARY -----------\nInfected files: 52\nTime: 1.936 sec (0 m 1 s)\n\nIf i run particularly under clamav-0.99.1/test directory, clamscan -v, it is showing\n----------- SCAN SUMMARY -----------\nKnown viruses: 4297948\nEngine version: 0.99.1\nScanned directories: 1\nScanned files: 52\nInfected files: 48\nData scanned: 14.52 MB\nData read: 6.94 MB (ratio 2.09:1)\nTime: 8.117 sec (0 m 8 s)\n\nAnd in clamdscan -v, it is showing \n----------- SCAN SUMMARY -----------\nInfected files: 52\nTime: 1.184 sec (0 m 1 s)\n\nWhy is this difference?? Does running from super directory and particular directory matters??\nWhy clamscan -v is showing \nScanned files: 52\nInfected files: 48\n\nwhile clamdscan -v always showing\nInfected files: 52\n\n??\n\nA: clamdscan is configured in /etc/clamav/clamd.conf. It allows faster scan by using parallelization with --multiscan which is using more resources, of course.\n", "Q: Ubuntu terminal cant type special characters like backslash (\\), slash(/), semicolon (:), etc properly I'm running Ubuntu 14.04 without GUI and i'm having problems entering characters like backslash, slash, semicolon and so forth. The keys which would normally enter these characters print out all kinds of different characters instead. \nHow can i change this, so that i can actually type out the characters which are listed on the keys on my keyboard. I suppose this is some kind of problem with the layout of the keyboard, but i can't seem to figure out how to fix it.\nFurthermore, ctrl+x doesn't work either (which makes it hugely problematic when i want to edit files using sudo nano). \nAny help would be greatly appreciated!\nThanks.\n\nA: You're probably using the wrong keyboard layout. You can change this by using the following command:\nsudo dpkg-reconfigure keyboard-configuration\n\n", "Q: Why does auth.log warn of a possible break in attempt? I have a server which receives backups from a remote server via rsync authenticated by ssh-keys. The rsync comes via a ddns URL, to a high numbered forwarded port.\nThe sending server is on a normal home internet line, fow which the ISP assigns a dynamic IP. The IP of the sending connection changed about a week ago, and since then, /var/log/auth.log has contained the following message every time the ssh connection is initiated. I've checked that the new IP address does belong to the site where the sending server is located.\nApr 11 08:30:15 someserver sshd[25447]: reverse mapping checking getaddrinfo for hostXXX-XXX-XXX-XXX.some.isp-name.com [XXX.XXX.XXX.XXX] failed - POSSIBLE BREAK IN ATTEMPT!\n\nWhat's causing this warning, and is there anything I could/should have done to avoid it?\n\nA: The comment in the code explains it well:\n/*\n * Map it back to an IP address and check that the given\n * address actually is an address of this host.  This is\n * necessary because anyone with access to a name server can\n * define arbitrary names for an IP address. Mapping from\n * name to IP address can be trusted better (but can still be\n * fooled if the intruder has access to the name server of\n * the domain).\n */\n\nBasically as descrbed in the comments. This is significant thread if you have access based on source IP (HostBased authentication). It is less significant if you have some filtering or so.\nIf you don't like this error, you can always use UseDNS no in your sshd_config and this message should go away.\n", "Q: Where does tracker-preferences store the configuration data? I am using tracker and I am using tracker-preferences to configure which directories it should index etc. However I see strange behaviour so I would like to look at the actual configuration file or settings tracker is using. \nI could not find any hint as to where to look though: there seems to be nothing in the gconf registry, nor any config file in ~/.conf or ~/.gconf.\n\nA: I think I have found it, it is shown in the dconf (not gconf) tool under key org.freedesktop.tracker...\nSome time I will have to find out what the difference between dconf and gconf is and why there are so many different ways how programs store configuration under Linux. \n\nA: As described here: https://wiki.gnome.org/Projects/Tracker/Documentation/Configuration you can have it store configuration in a file:\n\n'XDG_CONFIG_HOME': Default is $HOME/.config/. Tracker stores\n  configuration files in here under a 'tracker' subdirectory, but ONLY\n  if the 'TRACKER_USE_CONFIG_FILES' environment variable is defined.\n\n", "Q: UK QWERTY keyboard and Spanish tilded chars in Ubuntu touch (OTA-10) I have an external BT keyboard with layout UK QWERTY\n\nwhich works fine with my Ubuntu mobile devices. What I in addition want to have available are the Spanish tilded chars like áéíóñ¿¡ ...\nIn my FreeBSD netbook I configure this at the X11 level with\ncommands like this which are fired up when the desktop comes up, here as\nan example for the character ñ Ñ:\n# we use the Win-key to add more (esp. Spanish) letters to the keys:\n#\nxmodmap -e \"keycode 0x73 =  Mode_switch\"\nxmodmap -e \"keycode 0x39 =  n N ntilde Ntilde\"\n\ni.e. the useless key Win is redefined as a X11-modifier key and pressing the keys Win + n together gives just ñ.\nHow could I do this within the Ubuntu touch OTA-10?\nPlease note: we are not talking here about defining a new keyboard layout for the on-screen-keyboard, but about an existing external Bluetooth keyboard and how to define with some modifier key characters which are not on the keyboard itself.\n\nA: The keymapping for terminal-app can be defined in a file default.keytab (exact location see below). I got working nearly all the Spanish tilded chars with the add-ons to this file as attached at the end of this answer. One problem remains: there is a key on the keyboard labeled with the ? and / symbols (on a QWERTY the rightmost key on the second row next to a Shift key). My ideas was to produce together with Alt the char ¿ (questionmarkdown), but I do not know how the physical key is named in QT in the file qnamespace.h from where the key-names are derived. I tried\nkey Slash\nkey Question\n\nboth have no visible effect.\nNote: This only works for the terminal-app and not for the Mir server, i.e. the other apps.\nnew lines in default.keytab\n# added for Spanish tilded chars\n# to be placed in:\n# /userdata/system-data/opt/click.ubuntu.com/com.ubuntu.terminal/0.7.190/lib/arm-linux-gnueabihf/QMLTermWidget/kb-layouts/default.keytab\n#\nkey A -Alt-Shift : \"a\"\nkey A -Alt+Shift : \"A\"\nkey A +Alt-Shift : \"\\xc3\\xa1\"\nkey A +Alt+Shift : \"\\xc3\\x81\"\n#\nkey N -Alt-Shift : \"n\"\nkey N -Alt+Shift : \"N\"\nkey N +Alt-Shift : \"\\xc3\\xb1\"\nkey N +Alt+Shift : \"\\xc3\\x91\"\n#\nkey E -Alt-Shift : \"e\"\nkey E -Alt+Shift : \"E\"\nkey E +Alt-Shift : \"\\xc3\\xa9\"\nkey E +Alt+Shift : \"\\xc3\\x89\"\n#\nkey I -Alt-Shift : \"i\"\nkey I -Alt+Shift : \"I\"\nkey I +Alt-Shift : \"\\xc3\\xad\"\nkey I +Alt+Shift : \"\\xc3\\x8d\"\n#\nkey U -Alt-Shift : \"u\"\nkey U -Alt+Shift : \"U\"\nkey U +Alt-Shift : \"\\xc3\\xba\"\nkey U +Alt+Shift : \"\\xc3\\x9a\"\n#\nkey O -Alt-Shift : \"o\"\nkey O -Alt+Shift : \"O\"\nkey O +Alt-Shift : \"\\xc3\\xb3\"\nkey O +Alt+Shift : \"\\xc3\\x93\"\n#\nkey 1 -Alt-Shift : \"1\"\nkey 1 -Alt+Shift : \"!\"\nkey 1 +Alt-Shift : \"\\xc2\\xa1\"  # 'exclamationdown'\nkey 1 +Alt+Shift : \"\\xc2\\xbf\"  # 'questiondown' but gives \\x1b\\x21\n#\nkey 2 -Alt-Shift : \"2\"\nkey 2 -Alt+Shift : \"\\x22\"\nkey 2 +Alt-Shift : \"\\xc2\\xbf\"  # 'questiondown'\nkey 2 +Alt+Shift : \"2\"         # but gives \\x1b\\x22\n\n", "Q: What is the 'Badlock Bug'? A user on the Ask Ubuntu General Room posted a link to Badlock. After some googling around, all I can find is that it is a mysterious security bug, that uses the same website template as Heartbleed.\nI manage Linux Servers, a mysterious security bug does not sit well with me. What exactly is it, and how can I protect my servers from it?\n\nA: See here for the Ubuntu security update packages: \nhttps://bugs.launchpad.net/ubuntu/+source/samba/+bug/1569497\nTook a little while to get published, but a hell of a lot easier than patching 3.6.3 up to 3.6.25 and applying the official patches on top of that. \nNB: I tried to build 3.6.25 from source on precise and failed. YMMV.\n\nA: \nWhat is BadLock\n\nBadlock is a bug that affects Windows and Samba.\nWhat Can hackers do with this security bug?\nTwo things:\n\n\n*\n\n*Man-in-the-middle (MITM) attacks:\n\n*Denial-of-Service (DoS) attacks:\nThe Badlock CVE is: CVE-2016-2118. There are additional CVEs related to Badlock. Those are:\n\n\n*\n\n*CVE-2015-5370 (Multiple errors in DCE-RPC code)\n\n*CVE-2016-2110 (Man in the middle attacks possible with NTLMSSP)\n\n*CVE-2016-2111 (NETLOGON Spoofing Vulnerability)\n\n*CVE-2016-2112 (LDAP client and server don't enforce integrity)\n\n*CVE-2016-2113 (Missing TLS certificate validation)\n\n*CVE-2016-2114 (\"server signing = mandatory\" not enforced)\n\n*CVE-2016-2115 (SMB IPC traffic is not integrity protected)\n\n\nWhich versions of samba are affected\n\n\n*\n\n*3.6.x,\n\n*4.0.x,\n\n*4.1.x,\n\n*4.2.0-4.2.9,\n\n*4.3.0-4.3.6,\n\n*4.4.0\n\n\nFix:\nDownload the patches for your version of samba, here:\n\n\n*\n\n*https://www.samba.org/samba/history/security.html\nHow bad is Badlock?\n\nThe severity of Badlock according to the Common Vulnerability Scoring\n  System (CVSS):\nCVSS:3.0/AV:A/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H/E:P/RL:O/RC:C Base: 7.1\n  (High); Temporal: 6.4 (Medium)\n\nNotes:\n\nWith the release of Samba 4.4.0 on March 22nd the 4.1 release branch\n  has been marked DISCONTINUED (see Samba Release Planning)\n\n\nFurther Reading:\n\n\n*\n\n*Bad Luck Over The Upcoming Badlock Vulnerability?\n\n*WIRED, Hype Around the Mysterious 'Badlock' Bug Raises Criticism\nOfficial badlock website:\n\n\n*\n\n*Badlock Bug\nLinks:\n\n\n*\n\n*GitHub: samba-team/samba:\n\n\n*\n\n*Official GitHub mirror of https://git.samba.org/samba.git\n", "Q: How can I have 2 applications on 2 different displays in Ubuntu? I have an external display connected to my laptop. How can I have the external display show a different application than the one shown on the builtin display? \nI have disabled mirror display but there doesn't seem to be any documentation about opening or keeping an application on the external display. \nEdit: This is not about workspaces, so is not a duplicate of the workspaces related question as flagged by some users. \nI have two applications running side-by-side in the same workspace. I just want to move one of them to an external display, so that both applications can each have more screen space.\n\nA: My version is 14.04, and I use the standard desktop given by Canonical - Unity. \nUsing the workspace switcher, we can shift application(s) display to the 2nd monitor, by just dragging it. \nHere's how to do it after connecting external display to laptop: \n\n\n*\n\n*Enable workspaces \n\n\n*Disable mirror display \n\n\n*Open/Highlight (bring to front) the application window that needs to be shifted to external display\n\n\n*Press Super + S \n\n\n*Both screens are displayed in default workspace \n\n*Drag the application window to 2nd (right-side) screen - leave the remaining 3 workspaces untouched \n\n\n*Click anywhere on builtin screen. Now the shifted application is seen in external display\n\n\n*To switch mouse activity/focus to external screen, move the pointer beyond the right edge of screen, to bring it back to builtin screen move the pointer beyond the left edge. \n\n\nPS: both screen and display to refer to the same thing. \n", "Q: Ubuntu ffmpeg command -i not found I'm a beginner with Ubuntu and I need to setup a streaming server for my company, I've installed NGINX and FFMPEG, but when I call ffmpeg -i in the ~/ffmpeg/ffmpeg directory it returns an error command not found but when I call ./ffmpeg -i it returns a list with configurations.. why does ffmpeg -i not work and how can I fix it?\nI think that the Path Enviroment Variable is incorrect but how would I go abouts changing said variable? I'm not that experienced with Ubuntu / CMD programming / FFMPEG configuration.\nSources - https://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu\nhttps://github.com/arut/nginx-rtmp-module/wiki/Control-module\nand http://docs.unified-streaming.com/tutorials/live/broadcast-247.html#continuous-timestamps\n\nA: You need to add the directory where you've installed ffmpeg to your $PATH, the list of directories where executables can be found. The simplest way is to add this line to your ~/.profile:\nexport PATH=\"$PATH:$HOME/ffmpeg\n\nNote that you need to add the directory containing the ffmpeg executable and not the executable itself. Then, log out and log back in again (or just run . ~/.profile) and you should be able to execute it from anywhere. \n", "Q: Why am getting this error when I try to install Emma? I get the following error when I try to install Emma, how can I resolve this problem?\nPackage dependencies cannot be resolved\n\nThis error could be caused by required additional software packages which are missing or not installable. Furthermore there could be a conflict between software packages which are not allowed to be installed at the same time.\n\nThe following packages have unmet dependencies:\n\nemma: Depends: python:any (>= 2.7.5-5~) but it is a virtual package\n      Depends: python-mysqldb (>= 1.2.1-p2-2) but it is not going to be installed\n      Depends: python-gtk2 (>= 2.8.6-1) but 2.24.0-3ubuntu3 is to be installed\n      Depends: python-glade2 (>= 2.8.6-1) but 2.24.0-3ubuntu3 is to be installed\n\n\nA: Finally i got it working now, all i did was to enable enable the following Ticked the first and fourth box\n", "Q: sudo not found in shell of CTRL+ALT+F1 \n*\n\n*CTRL+ALT+F1  \n\n*Login to shell  \n\n*Type any command: sudo, ls, cat  \n\n*Output:\n -bash sudo: No such file or directory\n\nAlso when I login, environment variable is printed:\n-bash: export: '/home/some/path:/home/some/other/path: _not a  valid identifier_\n\nIt's thenot a valid identifier part which I believe is causing the problem. I am new to Ubuntu. What I would like to know is\n\n\n*\n\n*How to get sudo working here?\n\n*Anyway I can edit my .profile?\n\n\nA: You have trashed the definition of PATH, the list of directories the shell searches for commands you type. Thus, when you type ls the shell looks at the directories in $PATH and doesn't find /bin/ls. There is a two-step fix:  \n# First, manually set PATH to something survivable\nexport PATH=/usr/local/bin:/usr/bin:/bin\n\n# then edit your `~/.bashrc`, find the line that begins with\n# \"/home/some/path:/home/some/other/path\" and see why Bash wants to\n# see an identifier at this point. Bad continuation on the previous line?\nnano ~/.bashrc\n\nWhen you've fixed the problem, either log out/in or source ~/.bashrc in every shell process you have open.\n", "Q: Where can I find my call history on Ubuntu Phone? This seems oddly missing on my nexus 4. I received a phone call the other day, and I forgot to add her as a contact. Now I am searching for that phone call, and I can't find a log readily accessible on my phone to find this. The only log is for messaging.\nAm I missing something obvious here?\n\nA: Go to the phone app, than pull up the window at the bottom were it says Recent: lists All and Missed calls!\n", "Q: Unknown Error:''(\"The cache has no Package named 'steam') Error notifcation in the status menu saying\n\nAn Error occured, please run Package Manager from the right-click menu\n  or apt-get in terminal to see what's wrong. The error message\n  was:'Unknown Error:''(\"The cache has no Package\n  named 'steam'\") This usually means that your installed packages unmet\n  dependencies.\n\nBut there aren't any errors or warnings showing up when running apt-get on the command-line. And the notification won't go away.\n\nA: To fix the problem just run:\nsudo apt-get install --reinstall steam\n\nThe package is only about 800 kB.\n", "Q: Ethernet connection not recognized and no WiFi options are displayed This is the first time that I am using Ubuntu 14.04 alongside Windows 10 on my Lenovo Z51. And here is the first problem I am facing:\nMy Ethernet connection is not even recognized in Ubuntu. Plus, no option for WiFi is displayed anywhere. But both of them are connected in Windows. That means, I can't connect to internet in Ubuntu and have to restart my PC with Windows everytime I want to do so. I have tried installing wicd in Ubuntu but to no avail. Also, I removed /var/lib/NetworkManager/NetworkManager.state and restarted network-manager, which made no difference. I tried booting Kali Linux, Cyborg-Hawk and Ubuntu 16.04 from USB, and the problem persisted.\nEthernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 15)\nNetwork controller [0280]: Qualcomm Atheros QCA6164 802.11ac\nWireless Network Adapter [168c:0041] (rev 20)\nSubsystem: Lenovo Device [17aa:3545]\n\nFollowing screenshots of my Ubuntu desktop will make you the picture more clear.\n  \nI went to install backath10k-dkms_2.0_all.deb which gave me an error shown in the following screenshot:\n\nEdit: Ubuntu connects to the network by using a USB Externel WiFi Adapter\nChecked-out following:\nlsmod | grep ath\ndmesg | grep ath\n\n\nChecking for ath10k_pci\n\nLatest : sudo modprobe ath10k_pci && dmesg | grep ath\n\n\nA: Your pci.id of 168c:0041 is not included in kernel version 4.2.0-xx. Let's install a newer kernel version:\nwget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.4.8-wily/linux-headers-4.4.8-040408-generic_4.4.8-040408.201604200335_amd64.deb\nwget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.4.8-wily/linux-headers-4.4.8-040408_4.4.8-040408.201604200335_all.deb\nwget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.4.8-wily/linux-image-4.4.8-040408-generic_4.4.8-040408.201604200335_amd64.deb\nsudo dpkg -i linux*.deb\nsudo -i\necho \"options ath10k_core skip_otp=y\"  >  /etc/modprobe.d/ath10k_core.conf\nexit\n\nReboot. If the correct firmware is installed, the wireless should now be working.\n\nA: I bought a Lenovo Z70 three weeks ago, and after installing Ubuntu 14.04, I was not able to use my WiFi. I was able to hard wire into the router, however.\nDo I understand that you are not able to hard wire into the router?\nI did a lot of research, and tried three different suggestions, and finally was able to get my wifi to work.\nI followed the answer to this question. I'll spell out the instructions here, though, to hopefully make them simpler for someone new to Ubuntu (as I am).\nA disclaimer: I don't understand everything that is happening under the hood. I only know that this fixed my problem.\n\n\n*\n\n*I did this to get the ath10k firmware (which I was apparently missing):\nsudo apt-get install git\ngit clone https://github.com/sumdog/ath10k-firmware.git\ncd ath10k-firmware/ath10k\nsudo cp -r QCA6174/  /lib/firmware/ath10k\n\n*To correct the permissions of the firmware file you downloaded:\nsudo chmod +x /lib/firmware/ath10k/QCA6174/hw2.1/*\n\n*To unload and re-load the driver:\nsudo modprobe -r ath10k_pci  &&  sudo modprobe ath10k_pci\n\n*Apparently this is to incorporate a module parameter. I'm not sure what that means, but I did this, and my Wifi works now:\nsudo -i\necho \"options ath10k_core skip_otp=y\"  >  /etc/modprobe.d/ath10k_core.conf\nexit\n\n*Reboot your computer, and check.\nI do have the other resources I collected when I was troubleshooting this. I believe this is a problem that our Lenovo Z-series have.\nLet me know if this doesn't do anything for you, and I can look at some of the other resources I found.\n", "Q: How can I get access to the folder i recently install Ubuntu 15.10 after windows 10   now my problem is that i do not have permission to delete or move any file or folder. please help me with this\n\nA: It is possible if Windows mount was done with another uid/gid. Please check your /etc/fstab according to the ArchWiki instructions.\nBasically, your mount line should looks like that:\nUUID=01CD2ABB65E17DE0 /media/Windows ntfs-3g uid=user,gid=users,dmask=022,fmask=133 0 0\n\nwhere user is your $USER and users is your group (probably $USER also).\n", "Q: Let's encrypt on Ubuntu Snappy Just got my first Ubuntu Snappy running on a Raspberry Pi 2 and would very much like to enjoy Let's encrypt on it. I got it working on my other web server, but feel that this might not apply on Snappy Core, right?\nFor example, Let's Encrypt provides a Python script for install of the certificates, but on Snappy the same files does not apply as normal about Apache2 and stuff, right?\nWhere to start.\nThanks,\nDaniel\n\nA: Right-- snaps need to include all of their dependencies, so for instance the ownCloud snap bundles its own Apache, its own MySQL, etc. This is doable, but it's something you'd have to support in the snap that bundles the web server.\n", "Q: What is the name of the security concept that explains why Linux asks for root password? Whenever I'm installing new software or making changes to the system, Linux asks for the root password.\nWhat is the name of this security concept and where can I research more information about it?\n\nA: Your question is a bit vague, but you seem to be asking about the principle of least privilege, which basically says that a system is most secure when each piece only has the permissions necessary to do its own tasks. This limits the possibility of damage from mistakes or malicious actions.\nAn ordinary user typically does not need to be modifying system-level software or configuration, and so a regular user account doesn't have the permissions to do so. For the relatively infrequent times when you do want to make system-level changes, the sudo system (or equivalent such as Polkit) provides a way for you to gain those permissions temporarily, make the changes you want, and discard them.\n\nA: The technical concept you're looking for is known as Privilege Separation. With this concept, each program uses the privileges granted to the user running the application, which is enforced by the operating system's security modules. When a user needs to do something that's outside of their normal privileges, the system challenges the user in order to grant additional privileges. The intent of all this is that a rogue program (virus, trojan, etc) should not be able to do any considerable harm to a normal user account unless the user gives it additional privilege to do so. While this link is, of course, to Wikipedia, it includes links to additional articles and external resources where you can learn more about privilege separation and how it mitigates privilege escalation (taking advantage of a software bug to gain privileges/penetrate the system/etc).\n", "Q: Turn off external monitor when inactive I added an external monitor to my laptop last week and have almost everything working like I want except for the Brightness & Lock behavior.\nI've long had this set to \"Turn screen off when inactive for: 5 minutes\" and it works like a charm for the laptop screen - both before and after the addition of the external monitor. But it doesn't work on the external monitor. When I'm away from my desk for longer than I intended, I come back to a black laptop screen and the locked screen and login input on the external monitor.\nThe issue seems similar to this question, but in that one it appears that it's the primary monitor not going black. Which is why I'm posting this as a separate question.\nYes, I know I can turn the monitor's power off, and I do at night, but I'd like it to go black in synch with the native screen if possible.\nI'm on 14.04. The monitor is connected via HDMI. The laptop is a VAIO with a little age on it now.\nFOLLOW-UP EDIT\nAs a follow-up, when I tested the bash script in the accepted answer, I set a low timeout, ran the script from a terminal, watched both monitors dim to black, and then accepted the answer. Subsequently, I actually added the script (with a re-set timeout) to my startup scripts and bounced my machine. \nAfter my first longer-than-expected absence, imagine my surprise when I came back to my desk to find my external monitor shining brightly!\nSubsequent research has shown that this is likely caused by the HDMI monitor itself, and no script is going to fix it. Indeed, I've (accidentally) been at my desk when this script kicked in. Both monitors go black as they should, and then about a minute later, the external monitor turns itself back on. :-(\nOh well. I tried.\n\nA: I suspect the issue is the result of a bug, since I cannot find another cause. At least as a workaround the background script below could be used.\nThe script does the job on my system, but you'll have to try and see. If it doesn't work on your system, we can switch to xrandr to specifically switch of per monitor, but this is the simplest option.\nResources?\nAbout resources you don't have to worry, the script checks once per ten seconds if the idle time is exceeded. Even if I make it 10 times per second, the load is practically none.\n#!/usr/bin/env python3\nimport subprocess\nimport time\n\nt = 300\n\nscr = True\nwhile True:\n    time.sleep(10)\n    idle = int(subprocess.check_output(\"xprintidle\").decode(\"utf-8\").strip())/1000\n    if idle > t and scr == True:\n        subprocess.Popen([\"xset\", \"dpms\", \"force\", \"off\"])\n        scr = False\n    elif idle < t and scr == False:\n        subprocess.Popen([\"xset\", \"dpms\", \"force\", \"on\"])\n        scr = True\n\nHow to use\n\n\n*\n\n*The script needs xprintidle:\nsudo apt-get install xprintidle\n\n\n*Copy the script into an empty file, save it as switchoff.py\n\n*In the head of the script, set the idle time (in seconds) in the line:\nt = 300\n\n\n*Switch off your \"normal\" switch-off-screen-after-x idletime -settings\n\n*Run the script with the command:\npython3 /path/to/switchoff.py\n\n\n*If all works fine, add it to Startup Applications: Dash > Startup Applications > Add.\nAdd the command:\n/bin/bash -c \"sleep 15 &&  python3 /path/to/switchoff.py\"\n\n\nEDIT\nAs requested in a comment, below the bash version of the same script. You'd still need to install xprintidle though. \n#!/bin/bash\n\n# --- set the idle time in seconds below\nlet \"t = 300\"\n# ---\n\nlet \"div = 1000\"\nt=$(($t * $div))\nscr=true\n\nwhile true\ndo\n  sleep 10\n  let \"idle = \"$(xprintidle)\"\"\n  if  [ \"$idle\" -gt \"$t\" ] && [ \"$scr\" = true ] \n  then\n    scr=false\n    xset dpms force off\n  elif [ \"$idle\" -lt \"$t\" ] && [ \"$scr\" = false ] \n  then\n    xset dpms force on\n    scr=true\n  fi\ndone\n\nNote\n\n\n*\n\n*Since we don't know what causes the behaviour on your system, we still need to find out if it is necessary to specifically switch off your screens per screen by xrandr. You'd have to try.\n\n", "Q: How does Ubuntu handle OS transfers? I have two systems. One of them is running Ubuntu 14.04. The other has everything needed to run, except a bootable drive. The two systems have nothing in common. The running system has old hardware. The other system has shiny new and modern hardware, several orders of magnitude faster than the running system. If I just move the drive with Ubuntu on it to the other system, will Ubuntu adapt without problems? Will I need to install a massive batch of hardware drivers?\n\nA: \nwill Ubuntu adapt without problems?\n\nIn general: yes.  The normal device drivers get recreated on every boot so those will switch to the new hardware.\n\n\n*\n\n*As stated in comments: pay attention to the boot process. If one is old skool non-(u)efi and the other is... you need to boot the new system with the method the old one used. \n\n*The one thing you always should do is remove all 3rd party drivers. You can run into problems going from a nVidia to an AMD GPU or from a AMD to a nVidia GPU. Same for your NIC: 3rd party driver, delete it before switching. Those blobs are all static so will mess up your new system.\nIn general you can fix that too though with a \"reconfigure\" from commandline.\nI know you are going from old to new but in case you would go from new to old: \n\n\n*\n\n*Ubuntu has for every release a hardware stack. An LTS will update the hardware stack to the newest normal release stack (so 1n.04.2 has 1n.10's stack, 1n.04.3 has 1(n+1).04's =2 , 1n.04.4 had 1(n+1).10's stack for n=4 or n=6). Those hardware stacks also remove older hardware that is deemed obsolete. If you are unlucky your hardware is far too old to run an newer version.\n\n", "Q: Installed package, lsleases, giving bash \"No such file or directory\" error I am trying to use, the following package, lsleases:\nhttps://github.com/j-keck/lsleases#usage\nI have tried installing using the deb package and also via the bintray.com repository, as detailed in the installation instructions with the same result.\nIn both cases the installation completes without a problem as far as I can tell.\nHowever, when I try and run the command I get the following error:\nandrew@T61:~$ lsleases\nbash: /usr/bin/lsleases: No such file or directory\nandrew@T61:~$ /usr/bin/lsleases\nbash: /usr/bin/lsleases: No such file or directory\n\nAs you can see the file does exist:\nandrew@T61:~$ ls -l /usr/bin/lsleases \n-rwxr-xr-x 1 root root 3386272 Mar 28 16:05 /usr/bin/lsleases  \n\nHere's the output from which, type, echo $PATH and file if that is helpful:\nandrew@T61:~$ which lsleases\n/usr/bin/lsleases\nandrew@T61:~$ echo $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/game:/usr/local/games\nandrew@T61:~$ type lsleases\nlsleases is hashed (/usr/bin/lsleases)\nandrew@T61:~$ file lsleases\nlsleases: cannot open `lsleases' (No such file or directory)\n\nHere's the output of ldd /usr/bin/lsleases:\nandrew@T61:~$ ldd /usr/bin/lsleases\nlinux-vdso.so.1 =>  (0x00007ffe7a920000)\nlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fc1241f4000)\nlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fc123e2a000)\n/nix/store/pv9sza1cf2kpawck7wbwdnhlip5h57lg-glibc-2.23/lib/ld-linux-x86-64.so.2 => /lib64/ld-linux-x86-64.so.2 (0x00005589d3780000)\n\nAny advice to help me get this working would be great, it looks like a handy tool.\n\nA: The author of lsleases (that's me) uses nix for his development env. \nDynamic linked binaries consults the dynamic linker/loader to provide the shared libs. This path is fixed at compile-time in the binary:\n root@debian8:~# readelf -l /usr/bin/lsleases  | grep interpreter\n  [Requesting program interpreter: /nix/store/pv9sza1cf2kpawck7wbwdnhlip5h57lg-glibc-2.23/lib/ld-linux-x86-64.so.2]\n\nBut this path only exists under nix.\n\nThe go compiler creates statically-linked binaries by default (if cgo isn't used) - so this is no problem. BUT - I'm currently not sure why, the go compiler created a dynamic linked binary.\nI have released a new version (1.4.3) which is statically linked.\nSo a simple solution (if you have the bintray repo configured):\napt-get update && apt-get install lsleases\n\nThe actual packages can you found here.\nSorry for the breakage!\n", "Q: How do I change the user home folder name? I have a buyer for my desktop PC with a fresh installation of Ubuntu 14.04.  I need to change the home folder name from robert to james.  I've managed the other tasks like hostname, user name, user password.   After attempting to change the home folder name:  grub/recovery/root shell:  \nmount -o remount,rw / \nusermod -d /home/james -m robert\nreboot\n\nI can't get past the greeting screen login.  When I enter James' password, the screen blanks briefly then opens again at that same login screen.\n\nA: I would have done it like this:\n\n\n*\n\n*create user \"james\";\n\n*switch sudo account to \"james\";\n\n*move over personal files to \"james\". \"chown\"/\"chgrp\" them to \"james\";\n\n*check you can log into \"james\". If not and login is shown, check ~/xsession-errors for notices. \n\n*remove \"robert\".\n\n\n\nWhen I enter James' password, the screen blanks briefly then opens again at that same login screen.\n\nThe answer to this problem is probably shown in ~/xsession.errors. You can also just remove ~./Xauthority. That one needs specific permissions for login to success (has to be rw- --- --- and owned and group set to the user.)\n", "Q: Unable to access “895 GB Volume” Error mounting /dev/sda1 at /media/mdnazmossakib/01D189A576840DF0: Command-line `mount -t \"ntfs\" -o \"uhelper=udisks2,nodev,nosuid,uid=1000,gid=1000,dmask=0077,fmask=0177\" \"/dev/sda1\" \"/media/mdnazmossakib/01D189A576840DF0\"' exited with non-zero exit status 14: The disk contains an unclean file system (0, 0).\nMetadata kept in Windows cache, refused to mount.\nFailed to mount '/dev/sda1': Operation not permitted\nThe NTFS partition is in an unsafe state. Please resume and shutdown\nWindows fully (no hibernation or fast restarting), or mount the volume\nread-only with the 'ro' mount option.\n\nWhat is the solution to this? It was working fine, but this suddenly happened. Help me to solve this.\n\nA: @Nazmos Sakib. You can, if you are using windows 8 and that you have shutdown your system completely but still facing the same issue.., go to your power settings and ensure that \"on shutdown: the machine actually shuts down\" and does not hibernate instead. Then after these settings you can shut down and the power on and log into Ubuntu, and access your drive.\n", "Q: How to upgrade from Ubuntu 14.04 to Xubuntu 16.04? I'm having Ubuntu 14.04 LTS on my desktop but now I want to upgrade to Xubuntu 16.04. My software updater gave me a 15.10 update but it gave me error of repositories. How to manually update Ubuntu 14.04 to Xubuntu 16.04 without losing any data?\n\nA: I don't think you can update from Ubuntu to Xubuntu. But you can simply sudo apt install xubuntu-desktop to get everything that xubuntu would install. \nAbout your upgrade: (X)Ubuntu 16.04 isn't released yet. You could force the update on the dev version by running sudo do-release-upgrade -d.\nBut since you had to ask that, I would recommend holding off another couple of weeks until it's stable. (and then maybe another couple of weeks while the early adopter update :-)) \n\nA: If you want Ubuntu's Unity gone for good, and you're absolutely sure you want Xubuntu's Xfce, the best thing you could do is erase Ubuntu 14 and replace it with your preference (Xubuntu). \nI tried installing xubuntu-desktop in Ubuntu. It works good, but it is NOT optimised for Ubuntu. You should be aware that every Ubuntu flavor (Xubuntu, Lubuntu, UbuntuMATE, Cubuntu, Kubuntu, etc) it is optimised for its' default desktop environment (aka D.E.) and NOT for any other D.E. Simply installing a different D.E. in any flavor will NOT automatically optimise it for that.\nThe user experience is just NOT the same: different wallpapers, window styles, cursors, themes,etc. I'm not talking about two different D.E.s, i'm talking about the very same D.E. in two situations: tweaked (=better) D.E.- preinstalled and optimisied for its' flavor , and default D.E. - installed from repositories (by apt-get install).\nThere are performance issues too: kernel tweaks not compatible with the D.E will slow everything down, missing or wrong version of libraries, etc\n", "Q: Does Samsung SL-M2070 work with ubuntu 14.04? I'm planning to buy a Samsung SL-M2070 Multifunction Priter. Can you reinforce me that this device works with ubuntu 14.04? In particular to the scanner functionality.\nThank you,\n\nA: I bought the device. I can confirm that it fully works with ubuntu 14.04. I installed the driver from Samsung's website. Scanning is OK with ubuntu's default scanner software, so is printing. This is a good budget device.\n", "Q: Understanding htop I am trying to make sense out of htop. I have a virtual PC with 6 GB RAM running ubuntu 15.10. I have installed a few applications on the server: Jenkins, Artifactory and some other tools. When I run htop I get this:\n\nWhen I look at the VIRT and RES column the numbers far exceed the overview in the top showing that 1615/5967 MB is currently consumed.\nHow do I get a real view of how much RAM the the different applications on the server consumes?\nBy default Hide kernel threads are selected:\n\nI have tried to enable Hide userland threads and the list now makes more sense:\n\nDuplicates are still shown but at least only the \"expected\" memory consumption are shown for one instance of the applications. Not sure if its recommended to have this setting enabled though.\n\nA: In simple terms, VIRT colmn is how much memory the process can use for that process. E.g. artifacto mapped it self 4612M to use.\nRES- This represents how much memory it is currently using. For Artifacto is is currently using 722M.\nHere is a link with some more info subject;\nHTOP reference\n\nA: I believe htop defaults on how many threads the main process is using and will show all of them. You can edit this out in the htop config file. goto: ~/.config/htop/htoprc. or try in htop press F2 and goto display options and press space select \"hide kernel threads\" and \"hid userland threads\" Should trim it down for you.\n", "Q: Install Fingerprint Driver 138a:0090 on Ubuntu 16.04 (ThinkPad T460s) I'm about to config my new fantastic T460s with Ubuntu 16.04 (because of Skylake Kernel issue I've to chose such new version)\nI tried to use my fingerprint sensor which is 138a:0090 (lusb)\nFingerprint Gui doesn't recognize the device which is no wonder, because it is not on the compatibility list of it. Do I've to wait for a driver or is there something I can do about this?\nThanks a lot :)\n\nA: I just got the finger print reader (138a:0090) working on my Thinkpad T460p!\n\n\n*\n\n*Might be a good idea to remove libpam-fprintd if you've alread installed it:\n$sudo apt remove libpam-fprintd\n\n*Add the repo for libpam-fprintd which supports 138:0090\n$sudo add-apt-repository -u ppa:3v1n0/libfprint-vfs0090\n\n*Install libpam-fprintd\n$sudo apt install libpam-fprintd\n\n*Enroll your index finder using:\n$fprintd-enroll -f \"right-index-finger\" \"$USER\"\n\n*Enroll all fingers:\n$for finger in {left,right}-{thumb,{index,middle,ring,little}-finger}; do fprintd-enroll -f \"$finger\" \"$USER\"; done\nSee here for more info: \nhttps://github.com/3v1n0/libfprint\n\nA: I have an x1 carbon 4th gen which has the same fingerprint reader.  I looked through the upstram libfprint source, and it doesn't look supported yet, so that's why it's not working.  You will likely have to wait till someone creates a driver for it.\n\nA: The effort to reverse engineering the protocol has begun and found some success here.  Keep an eye on that project for a driver.\n\nA: For Ubuntu 16.04 or greater:\nFollow these steps to install the repo on a Lenovo B series (worked great with my Lenovo E450)\n\n\n*\n\n*$ sudo apt install libpam-fprintd       \n\n*$ fprint-enroll\n\n*Swipe your finger on Finger scanner\n\n", "Q: Xubuntu save multi monitor config I've a multi-monitor-setup with 2 screens (3 with the notebook T460s itself) on xubuntu 16.04 at a DP KVM-Switch. The notebook is connected via the Dock-3 Docking Station over 2 DP-Ports. \nEvery time I switch from Desktop to Laptop the monitor configuration is lost, so I've to configure it from scratch including activation of the single monitors. Is there a way to save these configuration and restore it automatically if the notebook is connected with the docking station?\nThe (shortened) output of xrandr with the screens connected:\nScreen 0: minimum 8 x 8, current 6800 x 1440, maximum 32767 x 32767\neDP1 connected 2560x1440+4240+0 (normal left inverted right x axis y axis) 310mm x 170mm\n   2560x1440     60.00*+  48.00  \n   1920x1440     60.00  \n\n   .........\n\nDP1 disconnected (normal left inverted right x axis y axis)\nDP2 disconnected (normal left inverted right x axis y axis)\nDP2-1 connected 1680x1050+2560+0 (normal left inverted right x axis y axis) 473mm x 296mm\n   1680x1050     59.88*+  59.95  \n   1920x1080     60.00    50.00    59.94  \n\n   ..........\n\nDP2-2 connected primary 2560x1440+0+0 (normal left inverted right x axis y axis) 527mm x 296mm\n   2560x1440     59.95*+\n   1920x1200     59.95  \n\n   ..........\n\nDP2-3 disconnected (normal left inverted right x axis y axis)\nHDMI1 disconnected (normal left inverted right x axis y axis)\nHDMI2 disconnected (normal left inverted right x axis y axis)\nVIRTUAL1 disconnected (normal left inverted right x axis y axis)\n\n\nA: Not 16.04 specific\nThe issue you are facing is not exclusive to 16.04, it happens on many Ubuntu versions.\nHow to solve\nReading your output of xrandr, and assuming I made no typo, the following command should arrange your screens the way you set it up:\nxrandr --output DP2-2 --auto --pos 0x0 --output DP2-1 --auto --pos 2560x0 --output eDP1 --auto --pos 4240x0\n\nThe quickest and easiest solution is to add it to a shortcut key: Settings > Keyboard > Application Shortcuts. Then press the shortcut after the screens are connected.\nExplanation\nFrom the output of xrandr, we can see the information on the three connected screens:\neDP1 connected 2560x1440+4240+0\nDP2-1 connected 1680x1050+2560+0\nDP2-2 connected primary 2560x1440+0+0\n\nIn the last section(s): 2560x1440+4240+0, in the part: +4240+0, we can see the position of the screen in the whole picture of combined screens (x,y). From left to right, the screens then are obviously arranged like:\nDP2-2 +0+0 | DP2-1 +2560+0 | eDP1 +4240+0\n\n\nIf this arrangement is not remembered automatically, we can set it up with the command I added at the beginning of this answer.\nThe option --auto I added, since you mentioned having to also activate the screens.\nEDIT\nAs requested, a small bash script to run in the background to make the setup if the screens are connected:\n#!/bin/bash\n\nlet \"target = 3\"\nswon=false\n\nfunction nscreens {\n    curr=$(xrandr | grep \" connected\" | wc -l)\n}\n\nfunction setup_scr {\n    xrandr --output DP2-1 --auto --pos 0x0 \\\n    --output DP2-2 --auto --pos 2560x0 \\\n    --output eDP1 --auto --pos 4240x0\n}\n\nwhile true\ndo\n  sleep 4\n  nscreens\n  if [ \"$curr\" -eq \"$target\" ] && [ \"$swon\" == false ]\n  then\n    setup_scr\n    swon=true\n  elif [ \"$curr\" -ne \"$target\" ] && [ \"$swon\" == true ]\n  then\n    swon=false\n  fi\ndone\n\n\n\n*\n\n*Copy the script into an empty file, save it as setup_scr.sh, make it executable\n\n*Test- run it in a terminal with the command:\n/path/to/setup_scr.sh\n\nconnect/disconnect the screens\n\n*if it works fine, add it to startup applications: Dash > Startup Applications > Add. Add the command:\n/bin/bash -c \"sleep 15 && /path/to/setup_scr.sh\"\n\nExplanation\n\n\n*\n\n*Once per 4 seconds, the script counts the number of connected screens. If it equals 3, it runs the setup a single time, remembering it did set the screens by switching the value of \"swon\" (switched on) to true.\nThen if the number of screens is no longer equal to 3, \"swon\" is set to false again, and so on.\nNote\nI tested the script on my two- screen setup, and it worked fine, however, there is always the possibility I made a typo somewhere, and obviously I could not test it on your system. In case of an error, please mention.\n\nA: these answer are only about restoring. To \"save\" the current state you could use this scrip (dump_randr.sh)\n#!/bin/bash\nfileName=\"$1\"\nwhile read -r line; do\n    IFS=\" \"\n    entry=( $line )\n    display=${entry[0]}\n    IFS=\"x+\"\n    if [[ \"${entry[2]}\" == primary ]]; then\n        primary=1\n        measurement=( ${entry[3]} )\n    else\n        primary=0\n        measurement=( ${entry[2]} )\n    fi\n    unset IFS\n    width=${measurement[0]}\n    height=${measurement[1]}\n    left=${measurement[2]}\n    top=${measurement[3]}\n\n    xrandrOpt=\"$xrandrOpt --output $display --mode ${width}x${height} --pos ${left}x${top}\"\n    ((primary)) && xrandrOpt=\"$xrandrOpt --primary\"\n\ndone < <(xrandr | grep \" connected\")\n\necho \"#!/bin/bash\" > \"$fileName\"\necho \"xrandr $xrandrOpt\" > \"$fileName\"\nchmod +x \"$fileName\"\n\nThis will dump the current xrandr options to use them again.\nYou can do something like this to store the current setup:\ndump_randr.sh 2_monitors_home.sh\n\nwhich creates 2_monitors_home.sh to restore the current state. \n\nA: I tried the method proposed by Jacob Vlijm, which I of course edited for my scenario. It did not quite work and for some reason any xrand command which had --auto or --pos in it crashed my machine (Im using Xubuntu 16.04)\nHere is my solution to this\nxrandr --output HDMI1 --mode 1920x1080 --pos 0x0 --rate 60.00 --output eDP1 --off\n\nthis takes my secondary display that I have connected over HDMI and sets it to 1080p 60Hz while disabling my laptop display\nxrandr --output eDP1 --mode 1366x768 --pos 0x0 --rate 60.00\n\nthis sets my laptop display to its native resolution 1366x768 60Hz\nI use the first setup when I am connected to 2 displays and I use the second setup when I am connected to only my laptop display.\nHere is my setup_scr.sh file:\n#!/bin/bash\n\nlet \"target = 2\"\nswon=false\n\nfunction nscreens \n{\n        curr=$(xrandr | grep \" connected\" | wc -l)\n}\n\nfunction setup_dubai \n{\n    xrandr --output HDMI1 --mode 1920x1080 --pos 0x0 --rate 60.00 --output eDP1 --off\n}\n\nfunction setup_normal \n{\n    xrandr --output eDP1 --mode 1366x768 --pos 0x0 --rate 60.00\n}\n\nwhile true\ndo\n  sleep 4\n    nscreens\n  if [ \"$curr\" -eq \"$target\" ] && [ \"$swon\" == false ]\n  then\n    setup_dubai\n    swon=true\n  elif [ \"$curr\" -ne \"$target\" ] && [ \"$swon\" == true ]\n  then\n    swon=false\n    setup_normal\n  fi\ndone\n\nThank you to Jacob Vlijm for making this setup real simple with his good explanation\n", "Q: sudo apt-get update error W: An error occurred during the signature verification. \n\n    The repository is not updated and the previous index files will be used.\n\n    GPG error: http://extras.ubuntu.com trusty Release: The following signatures couldn't be verified because the public key is not available: \n\nNO_PUBKEY 16126D3A3E5C1192\n\n            W: Failed to fetch http://extras.ubuntu.com/ubuntu/dists/trusty/Release\n\nSo can any one please give me the right key for this one? , i google it but i didnt find a related thing \n\nA: Try following command to add missin gpg keys sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 16126D3A3E5C1192 then sudo apt-get update. This will fix the problem.\n\nA: I've experienced this once, a while ago.\nWhat you could do is clean up every cache from apt, by following:\nsudo apt-get clean\nsudo mv /var/lib/apt/lists /tmp\nsudo apt-get update\n\n(Command-stack from \"GPG error: Release: The following signatures were invalid: BADSIG\", where I found the answer when I had the issue)\n", "Q: How can I make xrandr customization permanent in Lubuntu 14.04? I used xrand to generate xrandr --output LVDS-1 --mode 1366x768 --pos 1920x0 --rotate normal --output HDMI-1 --off --output VGA-1 --mode 1920x1080 --pos 0x0 --rotate normal command.\nxrandr proposed saving it in ~/.screenlayout/ folder, and it is not automatically used on logging in.\nRunning it from terminal mostly works, but display of workspaces in taskbar is horizontally squashed.\nAdding it to autostart (via ~/.config/lxsession/Lubuntu/autostart) has no effect whatsoever.\n\nA: Remove LXRandR configuration file.\nCreate a ~/.xprofile (ensure that it is executable) with xrandr command as content. Solution was found via https://wiki.ubuntu.com/X/Config/Resolution#By_Session_with_.xprofile\nWith external monitor unavailable it will cause message to appear and it will not cause further problems.\n", "Q: Why is Ubuntu14.04LTS running beta version of GRUB? I wiped the data on my 2 hard drives of my rack server and did a fresh install of Ubuntu14.04 LTS minimal server and yet could not boot\nI get the below error\nPlease see screenshot\n\n\nWhy is Ubuntu supposedly LTS version using a beta version of grub?!?\nAnd how do i fix this issue?\nThanks\nUPDATE: tried on another server and got this other error as well\nA different server entirely\n\nSO anyone knows way around this? I just need to install Ubuntu 14.04LTS becoming rocket science already! Again i wiped ALL data from the hard drives. Empy and fresh install..second server now..what is going on?!?\n\nA: \"Why is Ubuntu supposedly LTS version using a beta version of grub?!?\"\nAccording to https://lists.ubuntu.com/archives/ubuntu-devel/2014-January/037978.html [1] because \"This represents a year and a half of upstream development, and contains many new features\".\n[1] found via http://www.omgubuntu.co.uk/2014/01/grub-2-beta-ubuntu-14-04-lts via googling ubuntu beta grub.\n", "Q: Cannot activate python virtual env in jenkins shell script I have installed Jenkins on ubuntu 15.10. In a shell build step I am trying to create a Python virtual environment and activate it:\n\nBut I get the following error when I run the job:\n/tmp/hudson4515625893361069094.sh: 9: /tmp/hudson4515625893361069094.sh: source: not found\n\nMore from the log:\n[django-demo] $ /bin/sh -xe /tmp/hudson4515625893361069094.sh\n+ virtualenv --no-site-packages virtual_django\nNew python executable in virtual_django/bin/python2\nAlso creating executable in virtual_django/bin/python\nInstalling setuptools, pip...done.\nRunning virtualenv with interpreter /usr/bin/python2\n+ cd virtual_django/bin\n+ pwd\n/var/lib/jenkins/workspace/django-demo/virtual_django/bin\n+ dir\nactivate      activate.fish easy_install      pip   pip2.7  python2\nactivate.csh  activate_this.py  easy_install-2.7  pip2  python  python2.7\n+ source activate\n/tmp/hudson4515625893361069094.sh: 9: /tmp/hudson4515625893361069094.sh: source: not found\nBuild step 'Execute shell' marked build as failure\n\nSo the virtual environment was created successfully but it cannot be activated because the source command cannot be found.\nI did verify that I can indeed run the source activate  command from a terminal on the machine as the jenkins user in the corresponding workspace:\njenkins@vmi63860 ~/workspace/django-demo/virtual_django/bin ((HEAD detached at 290c6a4)) $ source activate\n(virtual_django)jenkins@vmi63860 ~/workspace/django-demo/virtual_django/bin ((HEAD detached at 290c6a4)) $ exit\n\nSo why does it fail when I run it under the Jenkins job?\n\nA: Found a similar post here:\nhttps://stackoverflow.com/questions/670191/getting-a-source-not-found-error-when-using-source-in-a-bash-script\nThe solution is to add:\n#!/bin/bash\n\nin the first line of the script step:\n\n", "Q: C compile error when I try to compile my code I get this error : \nerror: expected declaration or statement at end of input\n    }\nand error: function declaration isn’t a prototype [-Werror=strict-prototypes]\n void cleanup_module()\n\nerror: function declaration isn’t a prototype [-Werror=strict-prototypes]\n int init_module()\n\nthis is my code:\n      #define __KERNEL__\n      #define MODULE\n\n      #include <linux/module.h>\n      #include <linux/kernel.h>\n#include <linux/module.h>   /* Needed by all modules */\n#include <linux/kernel.h>   /* Needed for KERN_INFO */\n#include <linux/init.h> \n/**\n * Convert human readable IPv4 address to UINT32\n * @param pDottedQuad   Input C string e.g. \"192.168.0.1\"\n * @param pIpAddr       Output IP address as UINT32\n * return 1 on success, else 0\n */\nint ipStringToNumber (const char*  pDottedQuad, unsigned int * pIpAddr)\n{\n   unsigned int            byte3;\n   unsigned int            byte2;\n   unsigned int            byte1;\n  unsigned int            byte0;\n   char              dummyString[2];\n\n   /* The dummy string with specifier %1s searches for a non-whitespace char\n    * after the last number. If it is found, the result of sscanf will be 5\n    * instead of 4, indicating an erroneous format of the ip-address.\n    */\n   if (sscanf (pDottedQuad, \"%u.%u.%u.%u%1s\",\n                  &byte3, &byte2, &byte1, &byte0, dummyString) == 4)\n   {\n if ( (byte3 < 256) && (byte2 < 256) && (byte1 < 256) && (byte0 < 256))\n      {\n         *pIpAddr  = ((byte3 << 24) + (byte2 << 16) + (byte1 << 8) +  byte0);\n\n         return 1;\n      }\n   }\n /* Initialisation routine */\nint init_module()\n      {\n        printk(KERN_INFO \"Hello !!!!\\n\");\n          return 0;\n      }\n\n  /* Cleanup routine */\n\nvoid cleanup_module()\n      {\n        printk(KERN_INFO \"Goodbye !!!!\\n\");\n}\n\n\nA: int ipStringToNumber (const char*  pDottedQuad, unsigned int * pIpAddr)\n{\n    unsigned int            byte3;\n    unsigned int            byte2;\n    unsigned int            byte1;\n    unsigned int            byte0;\n    char              dummyString[2];\n\n    /* The dummy string with specifier %1s searches for a non-whitespace char\n    * after the last number. If it is found, the result of sscanf will be 5\n    * instead of 4, indicating an erroneous format of the ip-address.\n    */\n    if (sscanf (pDottedQuad, \"%u.%u.%u.%u%1s\", &byte3, &byte2, &byte1, &byte0, dummyString) == 4)\n    {\n        if ( (byte3 < 256) && (byte2 < 256) && (byte1 < 256) && (byte0 < 256))\n        {\n            *pIpAddr  = ((byte3 << 24) + (byte2 << 16) + (byte1 << 8) +  byte0);\n\n            return 1;\n        }\n    }\n} // <-------------------------HERE\n/* Initialisation routine */\nint init_module()\n{\n    printk(KERN_INFO \"Hello !!!!\\n\");\n    return 0;\n}\n\n/* Cleanup routine */\n\nvoid cleanup_module()\n{\n    printk(KERN_INFO \"Goodbye !!!!\\n\");\n}\n\n", "Q: Inconsistent connection and super slow speed with RTL8723BE I just installed Ubuntu on my laptop with a RTL8723BE adapter and the Wi-Fi is really spotty.\nSometimes available wireless networks won't even show up in the menu, and other times just the network in my household will show up and just barely function (I can ping, sites like Stack Exchange usually manage to load, etc.)\nI saw online some people suggest in a terminal entering echo \"options rtl8723be fwlps=N ips=N\" | sudo tee /etc/modprobe.d/rtl8723be.conf and rebooting, but it didn't work.\nI saw someone suggest updating the driver with:\nsudo apt-get install build-essential git\ngit clone https://github.com/lwfinger/rtlwifi_new/\ncd rtlwifi_new\nmake\nsudo make install\nsudo modprobe -r rtl8723be\nsudo modprobe rtl8723be\n\nRebooted, and it still didn't work.\nI also found this, and it didn't work:\nsudo add-apt-repository ppa:hanipouspilot/rtlwifi \nsudo apt-get update \nsudo apt-get install rtlwifi-new-dkms linux-firmware\n\nI have no problems with Windows on this laptop. Do I just have to accept I can't use Ubuntu on it?\n\nA: Does your installed version of the driver have this parameter?\nparm:           ant_sel:Set to 1 or 2 to force antenna number (default 0)\n\nCheck:\nmodinfo rtl8723be\n\nIf so, I suggest that you do, in a terminal:\nsudo -i\necho \"options rtl8723be ant_sel=2\"  >  /etc/modprobe.d/rtl8723be.conf\nexit\n\nReboot. Is there any improvement?\n", "Q: Can't Use SSH Keys Unless Running SSH With Sudo For some reason I'm unable to SSH from my Ubuntu 15.10 machine to a remote server using a private key if I run ssh without sudo.\nServer side config is fine. I have tested the private key from my Windows machine and from a CentOS box and both can use it.\nIf I put the private key in ~/.ssh authentication fails and I'm prompted for a password. However, if I put the same private key in /root/.ssh and use sudo ssh I can connect as normal. \nWorks: sudo ssh user@host.com -vvv\nDoesn't Work: ssh user@host.com -vvv\nI did notice this in the verbose SSH output. \nWithout Sudo: Offering RSA public key: /home/matt/.ssh/id_rsa\nWith Sudo: Trying private key: /root/.ssh/id_rsa\nPrior to that line output is the same. \nUsing the root .ssh directory isn't the end of the world but this doesn't seem correct. \nDoes anyone know why it's not working with the ssh key in my user's home directory?\nOutput when running `ssh -vv user@host:\nOpenSSH_6.9p1 Ubuntu-2ubuntu0.1, OpenSSL 1.0.2d 9 Jul 2015\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to gitlab.git.ho.me [192.168.1.155] port 22.\ndebug1: Connection established.\ndebug1: identity file /home/matt/.ssh/id_rsa type 1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/matt/.ssh/id_rsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/matt/.ssh/id_dsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/matt/.ssh/id_dsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/matt/.ssh/id_ecdsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/matt/.ssh/id_ecdsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/matt/.ssh/id_ed25519 type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/matt/.ssh/id_ed25519-cert type -1\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_6.9p1 Ubuntu-2ubuntu0.1\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_6.0p1 Debian-4+deb7u3\ndebug1: match: OpenSSH_6.0p1 Debian-4+deb7u3 pat OpenSSH* compat 0x04000000\ndebug2: fd 3 setting O_NONBLOCK\ndebug1: Authenticating to gitlab.git.ho.me:22 as 'git'\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug2: kex_parse_kexinit: curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ssh-rsa-cert-v01@openssh.com,ssh-rsa-cert-v00@openssh.com,ssh-rsa,ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,ssh-ed25519-cert-v01@openssh.com,ssh-dss-cert-v01@openssh.com,ssh-dss-cert-v00@openssh.com,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,ssh-dss\ndebug2: kex_parse_kexinit: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,rijndael-cbc@lysator.liu.se\ndebug2: kex_parse_kexinit: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,rijndael-cbc@lysator.liu.se\ndebug2: kex_parse_kexinit: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1,hmac-md5-etm@openssh.com,hmac-ripemd160-etm@openssh.com,hmac-sha1-96-etm@openssh.com,hmac-md5-96-etm@openssh.com,hmac-md5,hmac-ripemd160,hmac-ripemd160@openssh.com,hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1,hmac-md5-etm@openssh.com,hmac-ripemd160-etm@openssh.com,hmac-sha1-96-etm@openssh.com,hmac-md5-96-etm@openssh.com,hmac-md5,hmac-ripemd160,hmac-ripemd160@openssh.com,hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: kex_parse_kexinit: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ssh-rsa,ssh-dss,ecdsa-sha2-nistp256\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,rijndael-cbc@lysator.liu.se\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,rijndael-cbc@lysator.liu.se\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,umac-64@openssh.com,hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,hmac-ripemd160@openssh.com,hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,umac-64@openssh.com,hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,hmac-ripemd160@openssh.com,hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,zlib@openssh.com\ndebug2: kex_parse_kexinit: none,zlib@openssh.com\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug1: kex: server->client aes128-ctr umac-64@openssh.com none\ndebug1: kex: client->server aes128-ctr umac-64@openssh.com none\ndebug1: sending SSH2_MSG_KEX_ECDH_INIT\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\ndebug1: Server host key: ssh-rsa SHA256:2jkKypIK9zvIYnJARNTDz2GVNqSRmz+ERWV/nTLCLWE\ndebug1: Host 'gitlab.git.ho.me' is known and matches the RSA host key.\ndebug1: Found key in /home/matt/.ssh/known_hosts:1\ndebug2: set_newkeys: mode 1\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug2: set_newkeys: mode 0\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug2: service_accept: ssh-userauth\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug2: key: /home/matt/.ssh/id_rsa (0x560bd5470390),\ndebug2: key: /home/matt/.ssh/id_dsa ((nil)),\ndebug2: key: /home/matt/.ssh/id_ecdsa ((nil)),\ndebug2: key: /home/matt/.ssh/id_ed25519 ((nil)),\ndebug1: Authentications that can continue: publickey,password\ndebug1: Next authentication method: publickey\ndebug1: Offering RSA public key: /home/matt/.ssh/id_rsa\ndebug2: we sent a publickey packet, wait for reply\ndebug1: Server accepts key: pkalg ssh-rsa blen 279\ndebug2: input_userauth_pk_ok: fp SHA256:r+PZ/Ve2JY8SMHkm+opqRZzd/8HdfVL+zdc9hnaTSTQ\ndebug1: Trying private key: /home/matt/.ssh/id_dsa\ndebug1: Trying private key: /home/matt/.ssh/id_ecdsa\ndebug1: Trying private key: /home/matt/.ssh/id_ed25519\ndebug2: we did not send a packet, disable method\ndebug1: Next authentication method: password\n\nOutput when running sudo ssh -vv user@host\nOpenSSH_6.9p1 Ubuntu-2ubuntu0.1, OpenSSL 1.0.2d 9 Jul 2015\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to gitlab.git.ho.me [192.168.1.155] port 22.\ndebug1: Connection established.\ndebug1: permanently_set_uid: 0/0\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_rsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_rsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_dsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_dsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ecdsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ecdsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ed25519 type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ed25519-cert type -1\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_6.9p1 Ubuntu-2ubuntu0.1\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_6.0p1 Debian-4+deb7u3\ndebug1: match: OpenSSH_6.0p1 Debian-4+deb7u3 pat OpenSSH* compat 0x04000000\ndebug2: fd 3 setting O_NONBLOCK\ndebug1: Authenticating to gitlab.git.ho.me:22 as 'git'\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug2: kex_parse_kexinit: curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519-cert-v01@openssh.com,ssh-rsa-cert-v01@openssh.com,ssh-dss-cert-v01@openssh.com,ssh-rsa-cert-v00@openssh.com,ssh-dss-cert-v00@openssh.com,ssh-ed25519,ssh-rsa,ssh-dss\ndebug2: kex_parse_kexinit: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,rijndael-cbc@lysator.liu.se\ndebug2: kex_parse_kexinit: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,rijndael-cbc@lysator.liu.se\ndebug2: kex_parse_kexinit: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1,hmac-md5-etm@openssh.com,hmac-ripemd160-etm@openssh.com,hmac-sha1-96-etm@openssh.com,hmac-md5-96-etm@openssh.com,hmac-md5,hmac-ripemd160,hmac-ripemd160@openssh.com,hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1,hmac-md5-etm@openssh.com,hmac-ripemd160-etm@openssh.com,hmac-sha1-96-etm@openssh.com,hmac-md5-96-etm@openssh.com,hmac-md5,hmac-ripemd160,hmac-ripemd160@openssh.com,hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,zlib@openssh.com,zlib\ndebug2: kex_parse_kexinit: none,zlib@openssh.com,zlib\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: kex_parse_kexinit: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ssh-rsa,ssh-dss,ecdsa-sha2-nistp256\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,rijndael-cbc@lysator.liu.se\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,rijndael-cbc@lysator.liu.se\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,umac-64@openssh.com,hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,hmac-ripemd160@openssh.com,hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,umac-64@openssh.com,hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,hmac-ripemd160@openssh.com,hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,zlib@openssh.com\ndebug2: kex_parse_kexinit: none,zlib@openssh.com\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug1: kex: server->client aes128-ctr umac-64@openssh.com none\ndebug1: kex: client->server aes128-ctr umac-64@openssh.com none\ndebug1: sending SSH2_MSG_KEX_ECDH_INIT\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\ndebug1: Server host key: ecdsa-sha2-nistp256 SHA256:YUYeh6YJ4Nkz5B/17cjcE57I8Ao6IHHuDYgK60dzMHI\ndebug1: Host 'gitlab.git.ho.me' is known and matches the ECDSA host key.\ndebug1: Found key in /root/.ssh/known_hosts:1\ndebug2: set_newkeys: mode 1\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug2: set_newkeys: mode 0\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug2: service_accept: ssh-userauth\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug2: key: /root/.ssh/id_rsa ((nil)),\ndebug2: key: /root/.ssh/id_dsa ((nil)),\ndebug2: key: /root/.ssh/id_ecdsa ((nil)),\ndebug2: key: /root/.ssh/id_ed25519 ((nil)),\ndebug1: Authentications that can continue: publickey,password\ndebug1: Next authentication method: publickey\ndebug1: Trying private key: /root/.ssh/id_rsa\ndebug2: we sent a publickey packet, wait for reply\ndebug1: Authentication succeeded (publickey).\nAuthenticated to gitlab.git.ho.me ([192.168.1.155]:22).\n\nOutput of sudo ls -ald /root/.ssh /root/.ssh/* /home/matt/.ssh /home/matt/.ssh/*\ndrwx------ 2 matt matt 4096 Apr 12 19:25 /home/matt/.ssh\n-rwx------ 1 matt matt   59 Apr 12 17:28 /home/matt/.ssh/-config\n-rw-rw-r-- 1 matt matt   63 Apr 12 17:27 /home/matt/.ssh/config~\n-rw------- 1 matt matt 1675 Apr 12 17:46 /home/matt/.ssh/id_rsa\n-rw-r--r-- 1 matt matt  393 Apr 12 17:46 /home/matt/.ssh/id_rsa.pub\n-rw-rw-r-- 1 matt matt 1770 Apr 12 17:49 /home/matt/.ssh/known_hosts\n-rw-rw-r-- 1 matt matt   25 Apr 12 19:25 /home/matt/.ssh/output.txt\ndrwx------ 2 root root 4096 Apr 12 18:21 /root/.ssh\n-rw------- 1 root root 1675 Apr 12 18:21 id_rsa\n-rw-r--r-- 1 root root  444 Apr 12 17:24 known_hosts\n\n\nA: If you call ssh from a sudo shell, you will be logged on as root at the target host. If you call ssh from your user shell you will be logged on as matt. I guess you put the key in the authorized_keys file of the root at the target host, so you need to tell ssh you want logon as root at the target machine racer than as matt:\nssh root@target.host.com\n\n\nA: The difference between the user and the sudo way is:\nmatt:\ndebug1: Server host key: ssh-rsa SHA256:2jkKypIK9zvIYnJARNTDz2GVNqSRmz+ERWV/nTLCLWE\ndebug1: Host 'gitlab.git.ho.me' is known and matches the RSA host key.\ndebug1: Found key in /home/matt/.ssh/known_hosts:1\n\n-\nsudo:\ndebug1: Server host key: ecdsa-sha2-nistp256 SHA256:YUYeh6YJ4Nkz5B/17cjcE57I8Ao6IHHuDYgK60dzMHI\ndebug1: Host 'gitlab.git.ho.me' is known and matches the ECDSA host key.\ndebug1: Found key in /root/.ssh/known_hosts:1\n\nAs matt ssh finds a rsa known-host-key and ssh fail. As root ssh finds a dsa known host key and succeeds. \nMaybe you fix it by removing the file /home/matt/.ssh/known_hosts\nYou may force using dsa by this command:\nssh -o HostKeyAlgorithms=ssh-dss git@gitlab.git.ho.me\n\nYou may remove old entries from the known_hosts file with:\nssh-keygen -R gitlab.git.ho.me\nssh-keygen -R 192.168.1.155\n\n\nA: It turns out uncommenting IdentityFile in /etc/ssh/ssh_config resolved the issue. This was commented out on a default install of Ubuntu 15.10\n", "Q: Tuxguitar 1.3.1 no sound ubuntu 14.04 Once again, no sound in Tuxguitar. Before it updated, the TiMidity fix worked, running through the Gervill midi port. However, in the new tuxguitar update, that port is gone, along with the sound.\nI have the alsa, oss, and jsa plugins installed and selected. I've tried what every other post on here has said, but I think this is a new issue arising from the 1.3.1 update.\nAny help would be greatly appreciated!\n\nA: The same happened to me, and the only way I could make it work was installing the 1.3.2 version from sourceforge. \nIf you want to do it, it's easy with a couple of hints.\nInstalling\nAfter compiling it myself, I realised there's another tar already compiled here. Click on the tuxguitar-1.3.2-linux-x86_64.tar.gz.\nUnpack somewhere, and you will see a tuxguitar.sh inside. Launching with ./tuxguitar.sh everything works. By default it uses the \"Gervill\" thing that other answers say to use.\nCompiling tuxguitar from source\nwarning: I only recommend this if no other option worked. I guess there are other easier ways.\nYou will need mvn (sudo apt-get install maven), and a java version installed (it's likely you already have java 7 or 8, type java -version to find out).\nAt the moment, as the ubuntu package only lists up to 1.3.1, uninstall your current tuxguitar (and all the plugins).\nOnce you have downloaded the tar, this is what I did. I'm sure there are better ways, but this worked:\n\ntar zxvf tuxguitar-1.3.2-src.tar.gz\ncd tuxguitar-1.3.2-src/build-scripts/tuxguitar-linux-x86_64-deb/\nmvn install -DskipTests\ncd target/\nsudo dpkg --install tuxguitar-1.3.2-linux-x86_64.deb\n/opt/tuxguitar/tuxguitar.sh\n\n", "Q: Can't install any OS on laptop after deleting all partitions to switch to Windows 10 I was previously using Windows 8 but switched to Ubuntu. Since then I wanted to switch back to Windows 10 so I created a bootable usb and when I went to do the windows configuration I deleted all of the partitions and then my laptop shut off because the battery was dead. \nNow when I turn on my laptop it says \nerror:no such partition entering rescue mode...\ngrub rescue>\n\nand I cannot boot off of the USB. Does anybody know how to fix this?  \n\nA: Reinstall GRUB\nThe terminal way\n\n\n*\n\n*Open a terminal. As of Ubuntu 11.10 and 11.04, this can be done by opening the Unity Dash (you can click the Ubuntu logo in the top panel or use the Windows key on your keyboard) and typing in \"Terminal\", and clicking what comes up. On earlier versions, you can achieve this by going to Applications -> Accessories -> Terminal. Alternately use the Keyboard Shortcut: CTRL + ALT + T.\n\n\nFor full details on using terminal to fix grub on hard drive from Live Installer DVD or Flash: https://help.ubuntu.com/community/Grub2/Installing#via_the_LiveCD_terminal\nYou are then presented with a standard bash prompt, type - this only works to reinstall to MBR of a working system:\nsudo grub-install /dev/XXX\n\nwhere XXX is the device of your Ubuntu install. (eg: grub-install /dev/sdb).\nHint: You can also use /dev/disk/by-label/ if the partition you installed on has a label. You can determine the /dev node for such a device by running:\nls -l /dev/disk/by-label/\n\nThis will give the output of something like:\nlrwxrwxrwx 1 root root 10 Oct 16 10:27 data -> ../../sdb2\nlrwxrwxrwx 1 root root 10 Oct 16 10:27 data2 -> ../../sda2\nlrwxrwxrwx 1 root root 10 Oct 16 10:27 fat -> ../../sda6\nlrwxrwxrwx 1 root root 10 Oct 16 10:27 home -> ../../sda7\nlrwxrwxrwx 1 root root 10 Oct 16 10:27 root -> ../../sda1\nlrwxrwxrwx 1 root root 10 Oct 16 10:27 swap -> ../../sda5\nlrwxrwxrwx 1 root root 10 Oct 16 10:27 windows -> ../../sdb1\n\nYou can also use fdisk if you do not see the /dev/disk/by-label:\nsudo fdisk -l\n\nDisk /dev/sda: 160.0 GB, 160041885696 bytes\n255 heads, 63 sectors/track, 19457 cylinders\nUnits = cylinders of 16065 * 512 = 8225280 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x0001bc54\n\nDevice Boot      Start         End      Blocks   Id  System\n/dev/sda1   *           1       18725   150403072   83  Linux\n/dev/sda2           18725       19458     5884929    5  Extended\n/dev/sda5           18725       19458     5884928   82  Linux swap / Solaris\n\nFrom here, find only the drive name, ignore the partition number, that is, for partitions labeled \"root\", \"data2\", \"fat\", \"home\" and \"swap\" it's all still just sda. This is due to the fact that GRUB is installed in the MBR of the drive, and not on a partition.\nTrouble? If other things are messed up, e.g. if you have deleted the partition from where Grub was previously installed, grub-install may return an error message such as \"cannot find a device for /... (is /dev mounted?)\". You may have to do grub-install a bit differently. Refer to the handy guide on fixing a broken system\nNow reboot your system. The usual GRUB boot menu should appear. If it does not, hold Left Shift while booting. You will be able to choose between Ubuntu and Windows.\nTaken from : Ubuntu Help\n", "Q: Grub - missing windows 8 recovery In a dual boot ubuntu 14.04 / windows 8 (upgraded to Windows 10) laptop, there's no entry in the grub menu list for starting the windows 8 recovery procedure (installation files are in a partition). The only windows-related entry is \"windows boot manager\" and it makes windows 8 normally start.\nIn the grub.cfg file in fact there's no menuentry starting at /dev/sda1 which is the partition labeled as \"Recovery\", nor a menuentry starting at /dev/sda9 which is another ntfs partition labeled as \"Push Button Reset\". The \"system setup\" menuentry just starts the bios by the command fwsetup.\nIs there any way to make grub find the recovery partition? \n\nA: Booting to advanced options and safe mode is still possible, when you have GRUB in the boot chain you need to press the keys right after GRUB loads the Windows loader. If you have a UEFI system you should try to change the order of the boot options or issue to boot Windows at the next boot and try from within Windows to get to the advanced options menu.\n\nI think I got a virus on Windows, and I want to use the installation partition to reinstall windows. I don't mean the procedure which just removes data and settings, but the procedure that formats and reinstalls windows.\n\nAs far as I know the installation data for the \"refresh my PC feature\" is on the main filesystem, which therefore cannot be \"formatted\", because there is usually not enough space on the other filesystems to store the data and there are no mechanisms like a PXE environment involved (similar to how Macs perform a reinstall). You're not doing a complete reinstall this way as far as I am aware and you have no prove that the content hasn't been modified by the virus you expect to have infected your system. After all the data was on the same filesystem and you shouldn't expect a virus to be as dumb as not to do a simple mountvol and get access to the other filesystems.\nGetting the installation media from Microsoft and verifying the checksums is what you should do.\n", "Q: How to Install GUI on Ubuntu server 15.10 I would like detail instructions on How to Install GUI on Ubuntu server 15.10\n\nA: Install the metapackage ubuntu-desktop:\nsudo apt-get install ubuntu-desktop\n\nubuntu-desktop is a metapackage; it does not provide anything (apart from docs) itself, but depends on all other necessary packages for GUI. So when you install ubuntu-desktop, apt will install all other necessary \npackages to satisfy the dependency.\n", "Q: No Thunderbolt 3 Hotplug in 16.04 I just got a Dell Precision 5510 with a Thunderbolt3 port (USB-C).\nThe Thunderbolt to Ethernet adapter only seems to be usable if it is plugged in at boot. If I plug it in after Ubuntu has started, it is not recognized. How can I make it 'hotpluggable' in Ubuntu?\nI am running Ubuntu 16.04 Beta 2 with kernel 4.4.0-18-generic.\nI don't have any other Thunderbolt adapters to test with at the moment (for video etc). Since it is USB-C I have connected my Nexus 6p to the computer and it will charge, but Ubuntu does not show it as a device that is attached. That however may be due to it being a Thunderbolt port and not a USB port, even though its a USB plug?\n\nA: You will potentially have to upgrade your kernel to a newer release in order to get the full Thunderbolt3/USB-C functionality.\nThe port is capable of both USB and Thunderbolt functionality, but the Linux kernel drivers are still catching up.\nGetting to use a Precision 5510 for work since May and working on the imaging process (preseed) I learned that we are using a specific version of the 4.10 kernel in order for the TB3 to work properly with the Dell TB15/TB16 docking stations. It seems like things are hit or miss when updating to the Ubuntu hwe-edge (their semi official 4.10 packages) and the version we are using is closer to mainline than to an Ubuntu build.\nI've been deploying the spare 5510s that I was testing on to users, but I'll try a fresh install with the hwe-edge again and see if it works properly with the docks. The USB-C support has been pretty solid, but not everything is back ported to the 4.4 kernel.\nUpdate:\nUbuntu 18.04 and the 4.15 kernel is WAY better than 16.04 and any of the supported Ubuntu kernels available there. Possibly in 16.04.5 with the linux-image-hwe-edge-16.04 if it is 4.15 it will be better in 16.04, but there are some excellent improvements with 18.04 all around, not the least of which includes not needing to limit the Gigabit Ethernet port of the TB15/TB16 to 100 Megabit due to an overflow issue in the drivers.\n", "Q: How to watch cnn go using browser? I have directv and i used to watch cnn live on my browser in windows. since making the switch to ubuntu, i can watch it. I have install flash and extras. I have tried all browsers. It just doesnt work in ubuntu. Help please. I have already tried every suggestion in previous questions asked.\n\nA: You need to use Google Chrome, which I assume you did not try. You may have tried the open-source browser Chromium, but that doesn't have flash etc. that Google Chrome has, which is needed for CNN Go. You can install Google Chrome using these excellent instructionsn:\nHow to install Google Chrome\n", "Q: Batch-convert and split .ape with .cue to .flac in various folders from terminal I have a 44GB (yes, forty-four) folder of .ape CD files. Each .ape is a complete CD, and there is usually a .cue file along with each .ape. I need to convert but not split these, since there's no cue data to go by. There are also some .jpgs and .logs in there too, which I don't care about. If a tree command output helps visualize this, here you go:\n├── Philips Mozart Collection - 180 CD\n│   │   ├── box01-Symphonies\n│   │   │   ├── 1B.jpg\n│   │   │   ├── 1F.jpg\n│   │   │   ├── cd01\n│   │   │   │   ├── CDImage.ape\n│   │   │   │   ├── CDImage.ape.cue\n│   │   │   │   ├── Complete Mozart Edition, Vol. 01, Early Symphonies (Disc 1) - Neville Mariner, Academy of St. Martin in the Fields.log\n│   │   │   │   ├── img421.jpg\n│   │   │   │   └── img422.jpg\n│   │   │   ├── cd02\n│   │   │   │   └── CDImage.ape\n│   │   │   ├── cd03\n│   │   │   │   ├── CDImage.ape\n│   │   │   │   ├── CDImage.ape.cue\n│   │   │   │   ├── Complete Mozart Edition, Vol. 01, Early Symphonies (Disc 2) - Sir Neville Marinner - Acadamy of St Martin in the Fields.log\n│   │   │   │   ├── img426.jpg\n│   │   │   │   └── img427.jpg\n│   │   │   ├── cd04\n\netc... all the way to 180 CDS.\nBasically, I want to split all the .ape files into multiple .flac files, and copy over the tag info from the .cue, keeping the directory structure (preferably in a completely new and different directory). I prefer a single-line command to a script if possible. How would I go about this? Thanks to anyone who knows how to do this!\nAnd before anyone flags this question as a duplicate to this one here:\nConvert all .ape files to .flac in different subfolders, I would like to point out that that user didn't need to split the .ape into multiple .flacs.\n\nA: I would do this in multiple steps, since you do this rarely. Transparency is more important than automation here. But a single line is also possible. I assume that if you use only one command for all the files each step, this is what you intended.\nYou need to have ffmpeg (or avconv), shntool and cuetools installed.\nTo convert all your .ape to .flac in place:\nfind . -name \"*.ape\" -exec sh -c 'exec ffmpeg -i \"$1\" \"${1%.ape}.flac\"' _ {} \\;\n\nIf you install the patched MAC encoder and decoder for APE files from  http://shnutils.freeshell.org/shntool/, this first step is unnecessary. But you would need to compile it with g++ and yasm yourself. Same goes for .tta files, which are also often used instead of .ape.\nSplit and name .flac files:\nfind . -name \"*.cue\" -exec sh -c 'exec shnsplit -f \"$1\" -o flac -t \"%n_%p-%t\" \"${1%.cue}.flac\"' _ {} \\;\n\nIf shnsplit is also used for the conversion, replace the .flac in \"${1%.cue}.flac\" with the extension of the format you are converting from.\n\n*\n\n*%n – track number\n\n*%p – performer\n\n*%t – track name\n\nis taken from the .cue file for the .flac file names. To tag the resulting, split .flac files:\nfind . -name \"*.cue\" -execdir sh -c 'exec cuetag \"$1\" *.flac' _ {} \\;\n\nRemove the remaining CDImage.ape.cue, CDImage.flac, and CDImage.ape files at your leisure. The names are unique, so a simple find . -name \"CDImage*\" -delete is sufficient, except if Mozart made a composition starting with CDImage which I am not aware of.\nFor shnsplit to work, all necessary encoders/decoders need to be installed so it can read and write files. Modules for APE (and for the TTA format) would need to be compiled from source, the others by installing the package (i. e. FLAC).\nThis works for all standard cases where .cue and .tta/.flac/.ape files have the same name, except for the extension.\n\nSide remark for others: If you deal with this conversion, your source files might be of Japanese origin, where APE and TTA were more popular than elsewhere. If the .cue files were initially SHIFT-JIS coded and now opened as UTF-8, the shnsplit step will break. You need to rename the .cue files with\nfind . -name \"*.cue\" -exec rename 's/\\.cue$/.cux/' -- {} +\n\nand convert the intermediate files to UTF-8 with\nfind . -name \"*.cux\" -exec sh -c 'exec iconv -f SHIFT-JIS -t UTF-8 -o \"${1%.cux}.cue\" -- \"$1\"' _ {} \\;\n\nbefore you attempt to do the steps above. Don't forget to get rid of the .cux files when you are done with:\nfind . -name \"*.cux\" -delete\n\n", "Q: Radvd prefix pass through RA With radvd running on my router, my client PC as everyone says on net \"automagically\" gets an IPv6 address. Is there any way I can use the same prefix which is published by radvd in its RA and make the same Ubuntu client act as a router (by running radvd) with this prefix on some other interface? If so, please explain the best way to do this.  \n\nA: No, you cannot. It's not a lack of features problem, but limitation of the IPv6 protocol specification.\nHere's why:\nThe \"automagically\" you are refering to is StateLess Address AutoConfiguration (SLAAC), . The specification for SLAAC says that it works with a 64 bit netmask (meaning that the first 64 bits (16 hex characters) of the address must be the same for the address to be considered in the same block and used on this network segment).\nBy definition, a router is a machine that is on at least 2 different network segments. In fact, a router gets it's name from the fact that it routes traffic between the two segments.\n(The \"segment\" I'm referring to here is a collection of switch(es) directly connected to each other (with no intermediate routers) and the PC and other \"dead end\" devices connected to those switches. )\nWhen a networked machine (PC, server, etc) wants to send traffic to an address, it must decide if the address it wants to reach is directly reachable (on the same segment) or not (not on the same segment, and therefore must go through a router to get to the right segment). To do this, the computer looks at the configured netmask. A netmask simply tells the computer that if the address it wants to reach has the same first X bits in common with the computer's own address, then the address is on the same segment, and the computer should contact the address directly (using ICMPv6 neighbor discovery protocol). If the first X bits are not in common, then the address is part of another block of addresses and on a different segment, necessitating sending the traffic through a router to get to the right segment.\nWith the SLAAC that is happening on one interface of your Ubuntu machine, the netmask is defined as being 64 bits by the protocol specification. There is not a way to claim a smaller portion of that /64 netmask block and use it on another interface and segment with SLAAC, for two reasons. First, SLAAC requires a 64 bit netmask. If you were to carve a smaller block out of a 64 bit netmask block, the smaller block would by its very nature not be a 64 bit netmask block, because a larger netmask means a smaller block. (For example, a 65 bit netmask block is half the size of a 64 bit netmask block). Second, all of the other machines on the network that currently has the 64 bit netmask block advertised with SLAAC are expecting the entire block to be directly reachable on that segment, and are not expecting to have to go through your router to reach part of that block.\nNow, there is a way around this, but not by your Ubuntu machine acting as a router. You can configure ports on a Ubuntu machine to act as a switch, transparently passing traffic between the ports without modifying it. In doing so, your machine will get a new interface that acts as if it was connected to a third port on this virtual switch. That will allow you to get any configuration you need (including SLAAC) to your Ubuntu machine and give it network access, while still allowing traffic to flow untouched between the two physical interfaces on your machine. This makes it so that your machine and the two networks on it's physical interface all become the same segment (because your machine is doing the job of a switch).\nTo do this, you will want to set up a bridge. You will want to install the bridge-utils package. You will then want to remove any addresses/configuration from your current physical interface. Then you will want to do:\nbrctl addbr br0\nbrctl addif br0 intefacename1\nbrctl addif br0 intefacename2\nifconfig br0 up\nifconfig intefacename1 up\nifconfig intefacename2 up\n\nand then add any configuration you used to need on the physical interface to the new interface br0. You may want to take a look at https://wiki.debian.org/BridgeNetworkConnections and https://wiki.debian.org/NetworkConfiguration#Bridging for more details (especially how to make the configuration apply across reboots in /etc/network/interfaces).\n", "Q: cannot install qtbase5-dev due to unmet dependencies I need to install qtbase5-dev but \n$> sudo apt-get install qtbase5-dev\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n qtbase5-dev : Depends: libgles2-mesa-dev or\n                        libgles2-dev but it is not installable\n\nI traced it down to:\n$ sudo apt-get install libwayland-dev\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n libwayland-dev : Depends: libwayland-client0 (= 1.4.0-1ubuntu1) but 1.7.0-0ubuntu1~trusty1 is to be installed\n                  Depends: libwayland-server0 (= 1.4.0-1ubuntu1) but 1.7.0-0ubuntu1~trusty1 is to be installed\n                  Depends: libwayland-cursor0 (= 1.4.0-1ubuntu1) but 1.7.0-0ubuntu1~trusty1 is to be installed\nE: Unable to correct problems, you have held broken packages.\n\nI have a mint condition (nearly ~24h without any manual changes only apt-get install) ubuntu-gnome 14.04.2 installed.\nAs I need to be able to use pyqt5, which depends on qt5-default, which depends on gt5base-dev I was wondering how I can fix this situation?\nCan I install old versions of packages?\n\nA: I 'fixed' the problem by installing an 'old' ubuntu 14.04 (no .2) - the problem does not occur anymore.\n", "Q: Why is cURL not installed by default? Many applications require curl or libcurl for running or installation. Why does Ubuntu not provide it by default?\n\nA: If an Ubuntu application requires curl, it will list it as a dependency in the package management system, ensuring it is installed automatically when installing that application.\n\nA: \nMany applications require curl or libcurl for running or installation. Why does Ubuntu not provide it by default?\n\nBecause those applications are not installed by default in Ubuntu.  So there is no need for cURL to be installed on a vanilla Ubuntu.\n", "Q: What are Snap packages and what are the difference between Click packages and Snap packages? Are they just same?\nLaunchpad can build Snap packages but not click packages.\n\nA: Click packages are isolated, so run in confinement with a \"personal\" directory and thus cannot provide dependencies to other programs. Intended originally for Ubuntu Mobile/Touch but later for the desktop, they were directed towards user applications because of their bundled dependencies and protected nature (e.g. you could have multiple versions of the same application, all using different libraries and all unaware of each other).\nRef: https://click.readthedocs.io/en/latest/\nAnd the answer to a familiar (to you!) question here: What are Click packages?\n\nSnappy packages are an iteration of the packaging concept, in that they can provide functions to other packages, and don't have to be confined. They can thus be the basis for system-wide applications/functions as well.\nRef: http://www.webupd8.org/2015/04/ubuntu-desktop-to-eventually-switch-to.html\n", "Q: How to add entry to /etc/hosts with a built-in command line It turns out that editing /etc/hosts  is enough to add an entry of DNS. \nIs there a built-in cmd , where we can: \n\n\n*\n\n*add host      \ncmd: $ sudo mycmd 10.103.23.34  myme.com\nResult : 10.103.23.34  myme.com \n\n*Add hostname  \ncmd    : $ sudo mycmd 10.103.23.34 omac.org\nResult : 10.103.23.34  myme.com omac.org \n\n*Modify IP\ncmd    : $ sudo mycmd 10.103.23.18 omac.org\nResult : 10.103.23.18  myme.com omac.org \n\nA: After seeking for CLI for /etc/hosts , we find : https://github.com/macmade/host-manager\nAmazing : \nhost-manager -add www.example.org 127.0.0.1\nhost-manager -remove www.example.org\n\n\nA: I tried to get the host-manager tool listed above to work but it looks like maybe it's for Windows or macOS? It was trying to cross compile and didn't look right for Ubuntu. I found this tool 'Hostess' though which works great and seems to do exactly what the OP was looking for:\nhttps://github.com/cbednarski/hostess\nhostess add local.example.com 127.0.0.1\nhostess add staging.example.com 10.0.2.16\n\n\nA: Just to add to other suggestions - there's one more option which exists in standard Ubuntu package repositories - hostsed (github page + docs here). As a result install is as easy as apt install hostsed.\n", "Q: How to configure setting of phppgadmin with xampp and postgresql 9.5? I'm using Ubuntu 14.04, Xampp 5.6 and PostgreSQL-9.5 \nI have already uncommented these lines:\nextension=php_pdo_pgsql.dll\n\nextension=php_pdo_sqlite.dll\n\nextension=php_pgsql.dll\n\nbut still I this error:\nYour PHP installation does not support PostgreSQL. You need to recompile PHP using the --with-pgsql configure option.\n\nplease help me, I still new in Ubuntu\n\nA: uncomment these line in /opt/lampp/etc/php.ini\nextension=php_pdo_pgsql.dll\nextension=php_pgsql.dll\nextension=\"pgsql.so\"\nthen restart xampp service with\nsudo /opt/lampp/lampp restart\n", "Q: Mongod service doesn't start with enableEncryption: true option in mongod.conf According to «Configuration File Options» manual, the MongoDB security options have a boolean parameter enableEncryption. I paid attention that the service mongod of MongoDB 3.2.4 is failed to start if the parameter enableEncryption: true is set. once I remove this parameter the service starts correctly.\nMy question:\n\n\n*\n\n*Is there any reason why the security parameter enableEncryption: true prevents from the service mongod to start?\n\n\nI'm using Ubuntu 14.04. \n\nA: That parameter allows you to enable encryption in the WiredTiger storage engine, but you still need to actually configure it.  You also need to be running the Enterprise version of MongoDB, this is not available in the community/open source version.  Relevant snippets from the docs:\n\n  \n*\n  \n*Enables encryption for the WiredTiger storage engine. You must set to true to pass in encryption keys and configurations.\n  \n*Available in MongoDB Enterprise only.\n  \n\nOnce you have the above done you have to actually configure keys (and manage them) as per these docs.  Key generation and management is a complex topic, beyond the scope of this answer, but generally unless you really need at-rest encryption (and most do not) it's usually not worth the effort.\n", "Q: Where is the Ubuntu App store? I don't have an Ubuntu phone but am considering getting one if I can find suitable apps. Is there a link/website that mirrors the on-device app store?\n\nA: Here you go, but note that It is unofficial.\nhttps://uappexplorer.com/apps\n", "Q: Can't install php5 on Ubuntu 16.04 so I've recently installed my first Ubuntu, to be precise, a daily build of 16.04, on my new laptop since the hardware was to new for 15.10. Now I'm in the process of setting it up and I want to install php5 and some extensions.\nWhen I execute sudo apt-get install libapache2-mod-php5 I get the error message that there is no installation package available for php5 and libapache2.\nThe error message is in german, so I doubt that this would help, but anyways here it is. :-)\nE: For package »libapache2-mod-php5« existiert kein Installationskandidat.\nDo I need to add a apt-get repository? Or what am I doing wrong?\n\nA: TL;DR: If you want to stay with php5, you will need to stay at Ubuntu 14.04 LTS\nUsing PHP 7.0 on Ubuntu 16.04 LTS\nUbuntu 16.04 has switched to PHP 7.0 with a new infrastructure for PHP package.  So, no, you can't install php5 on Ubuntu 16.04, but you can install PHP 7.0 packages with:\napt-get install libapache2-mod-php\nThat will install a virtual package that depends on the latest PHP version and pull libapache2-mod-php7.0 as a dependency.\nIf you are looking for extensions, always use a version-less variant as well (e.g. php-apcu instead of php7.0-apcu) as the PECL extensions are packaged without the version to allow smooth upgrades.\nUsing PHP PPA to coinstall PHP 5.6 with PHP 7.0\nThere's an option to co-install PHP 5.6 packages using ppa:ondrej/php.\nFor more information, please see that answer: https://askubuntu.com/a/762161/309221\nExtracted from link above:\n\nAssuming libapache2-mod-php is a suitable way to enable PHP in Apache for you, you can proceed in this way:\n\nsudo add-apt-repository ppa:ondrej/php\n\nsudo apt-get update\n\nsudo apt-get install php7.0 php5.6 php5.6-mysql php-gettext php5.6-mbstring php-xdebug libapache2-mod-php5.6 libapache2-mod-php7.0\n\n\nSwitch PHP version ( Apache ):\n  \n  \n*\n  \n*from php5.6 to php7.0:\nsudo a2dismod php5.6 ; sudo a2enmod php7.0 ; sudo service apache2 restart\n  \n*from php7.0 to php5.6:\nsudo a2dismod php7.0 ; sudo a2enmod php5.6 ; sudo service apache2 restart\n\n\nA: EDIT: the accepted answer does not explicitly say how to co-install PHP 5.6 and 7.0, so I wanted to extend it.\nFor more information, please see that answer: https://askubuntu.com/a/762161/309221\nExtracted from link above:\n\nAssuming libapache2-mod-php is a suitable way to enable PHP in Apache for you, you can proceed in this way:\n\nsudo add-apt-repository ppa:ondrej/php\n\nsudo apt-get update\n\nsudo apt-get install php7.0 php5.6 php5.6-mysql php-gettext php5.6-mbstring php-xdebug libapache2-mod-php5.6 libapache2-mod-php7.0\n\n\nSwitch PHP version ( Apache ):\n  \n  \n*\n  \n*from php5.6 to php7.0:\nsudo a2dismod php5.6 ; sudo a2enmod php7.0 ; sudo service apache2 restart\n  \n*from php7.0 to php5.6:\nsudo a2dismod php7.0 ; sudo a2enmod php5.6 ; sudo service apache2 restart\n\n", "Q: Wifi doesn't work in Ubuntu 15.10 - Realtek RTL8723BE/RTL8188EE 802.11b/g/n Wireless LAN Drivers My laptop is a HP Notebook - 15-ac173tx having Realtek RTL8723BE/RTL8188EE 802.11b/g/n Wireless LAN Drivers.\nI can not work with my wifi properly as it drops once in a while, and also I can't log into a wifi network if the wifi router is in another room even if I connect to a wifi network really close to my lap the signal strength of the wifi is really low.\nPlease help me to fix this issue asap.\n\nA: Please refer to this question, if you have any trouble with getting it fixed make sure you check the ReadMe file on github \n", "Q: How to write a script to open current path from nautilus in guake I use Guake with tmux as my preferred terminal on Ubuntu 14.04LTS. I would like to be able to run a script from nautilus that does the following actions:\nCtrl + L, Ctrl + C, F12, cd Ctrl + Shift + V\nmeaning: Open the path I am currently in on nautilus in Guake/tmux.\nI followed the instructions that are mentioned in this question and created the following script (called test.sh):\n#!/bin/bash\nxdotool key Ctrl+L\nxdotool key F12\nxdotool type cd\nxdotool key space\nxdotool key Ctrl+Shift+V\n\nand put it in ~/.local/share/nautilus/scripts as indicated here\nIt works fine when it is put in a directory and run from there.\nHowever, when I run the script from the nautilus menu. it always enters the string\n/home/bruni/.local/share/nautilus/scripts/test.sh\nirrespective of where I am in Nautilus\nPS: The proposed solution does not necessarily have to build on the above path of using xdotool. I am perfectly happy with any solution that would let me open the current nautilus path in guake/tmux (the running shell not a new one).\n\nA: The mistake I did in the above script is rather stupid. I did not consider that the commands are case sensitive. Here is the working script.\n#!/bin/bash\nxdotool key ctrl+l\nxdotool key ctrl+c\nxdotool key F12\nxdotool type cd\nxdotool key space\nxdotool key ctrl+shift+v\n\nI have added a shortcut under system settings --> keyboard --> custom shortcuts.\nNow, if somebody could tell me how to have a shortcut to the script that is only activated from nautilus, that would be great.\nA more reliable solution for the particular problem can be found here:\nHow to open directory in Guake from Nautilus\n", "Q: Setting up domain with LAMP server Not sure if this is the best forum so let me know and I'll delete it if so.\nI've setup a LAMP server on Ubuntu 14.04 which works fine the issue is, right now I can only access it through the public IP. I currently have a domain registered to me, but I got it from Freehosting.com so it points to the website I made there when I need it to point to my personal server now. I've done quite a bit of googling on the issue and most articles I find detail how to go from one online hosting company to a different one which is not what I need.\nFrom what I can understand I need to point the nameservers of my domain to my server's public IP, however when I log on to do that and set the IP address to mine I get an error that I'm using the same domain name and I noticed the default one has\nns1.freehosting.com\nns2.freehosting.com\n\nI only know the basics of nameservers, but apparently I need two and I thought the company I register my domain through had the name servers, but it seems like I actually need 2 name servers myself to point toward my IP is this correct? If so could I use BIND on my same PC like here https://help.ubuntu.com/lts/serverguide/dns-configuration.html or would I need a separate PC? I can't find much on how much resources name servers use, but I have a fairly weak PC(4gb ram ~3.4 ghz 4core amd cpu) so I'm not sure it would be able to handle all of that. \nTo summarize I'm trying to point a domain registered on freehosting.com to a LAMP server now. Thanks for the help and if there is any information left out that would be helpful let me know and I'll edit. \n\nA: You need to edit DNS records from your Freehosting account and make A record for your domain point to your IP address. No need to set-up bind or anything else by yourself.\nIf you're not sure how to do it or don't know place to manage your DNS then contact Freehosting support. You can start using other nameservers awell, e.g CloudFlare's to manage your DNS \n", "Q: What is the name of this widgets? I am tweaking a theme to my taste and I changed the accent color from orange to #9E9EB3. The problem is that one kind of widget now have mixed color of orange & #9E9EB3. \nCan some one tell me what is the name of this kind of widgets, so I can find them in the gtk-widgets.css file and fixed the problem.\n\n\nA: The name of the widget is \"GtkScale\".\n", "Q: What do I do about Badlock on Ubuntu 14? So, the Badlock bug (www.badlock.org) that was revealed yesterday, was not as terrible as feared. And yet, it seems prudent to patch samba ASAP.\nHowever, just prior to releasing the bug, the samba developers decided to EOL the 4.1.x-branch and did not release a fix for the bug.\nAt the same time, the version that is available when using 'aptitude update' on a fairly recently installed Ubuntu 14 LTS, is version 4.1.6-Ubuntu.\nHas this version been specifically patched for Badlock? If not, what is the best course of action to get samba upgraded to a non-EOL version on Ubuntu?\nIn the security updates thread, https://launchpad.net/~ubuntu-security-proposed/+archive/ubuntu/ppa/+packages , I see an update coming for samba version 4.3.x. But the version I have is the one that was selected by default when I did the installation, 4.1.6-Ubuntu. I ask this question because I am unsure if that fix is going to apply -- and if so, when.\n\nA: Since you are on 14.04, your packages (in main) get security upgrades for 5 years. I guess the Ubuntu team is already working on that. You'll only need the ppa if you have reason to believe it's going to be exploited at your site before the fix hits official Ubuntu packages. \n", "Q: How to install Qt version 4.8.1 in Kubuntu 14.04 How can I install Qt version 4.8.1 in Kubuntu 14.04?\nI cannot find the version 4.8.1 in the official Qt site's downloads list.\nKindly help me to install the exact version.\n\nA: You will have to first  download the source from  here for qt 4.8.1.\nThen open a terminal(Ctrl+Alt+T) and goto the path where you have download the file.   \nInstall the required dependencies\nsudo apt-get install build-essential checkinstall \n\nThen extract the file using \ntar -xvzf qt-everywhere-opensource-src-4.8.1.tar.gz   \n\nThen goto the extracted folder using \ncd qt-everywhere-opensource-src-4.8.1\n\nand run \n\n\n*\n\n*./configure\n\n*make\n\n*sudo checkinstall\nThis will make a .deb of the source you can install as a normal application via apt\nsudo dpkg -i path/to/output.deb\n\nChange path/to/output.deb to the path of the created .deb file.\n", "Q: USB 3.0 ports only work in Hi Speed, not Super Speed with xhci_hcd running I've a Kontron KTQM87/mITX board (latest BIOS) with some USB 2.0 and some USB 3.0 ports. The machine runs Ubuntu 14.04, I've tried both with 3.13 and 4.4.6 kernels.\nIn BIOS, I set xHCI mode to \"Enabled\". I assume this makes USB 3.0 on.\nWhen I connect a USB3/2 device (such as a mass storage), it only appears as a hi-speed device. When I connect a USB3-only device (Intel Realsense), it doesn't appear at all, not even a single line in dmesg.\nHere's my lsusb -t\n/:  Bus 02.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/6p, 5000M\n/:  Bus 01.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/15p, 480M\n    |__ Port 1: Dev 2, If 0, Class=Vendor Specific Class, Driver=pl2303, 12M\n    |__ Port 3: Dev 3, If 0, Class=Human Interface Device, Driver=usbhid, 1.5M\n    |__ Port 8: Dev 4, If 0, Class=Vendor Specific Class, Driver=cpc-usb, 12M\n    |__ Port 9: Dev 5, If 0, Class=Human Interface Device, Driver=usbhid, 1.5M\n    |__ Port 9: Dev 5, If 1, Class=Human Interface Device, Driver=usbhid, 1.5\n\nI assume both buses reported there are actually a single bus, but displayed once for hi-speed devices, and once for super-speed devices. I've never seen anything appear under the super-speed bus. All USB3/2 devices appear under Bus 01, which reports max speed 480M, which is hi-speed.\nWhat can I do to make my USB 3 devices work at super-speed?\n\nA: The problem showed to be in bad extender cables. We exchanged them for different ones and now the USB 3.0 devices show up as expected.\n", "Q: Ubuntu freezes after Android MTP connected I have a new issue with my Ubuntu: when I connect my Android phone as an MTP (Galaxy S5) to my laptop, Ubuntu says that it cannot not mount Android MTP then it freezes and nothing works even Alt+F2.\nWhile frozen my CPU fan speed will increases. I think there is a process that causes this problem. I don't want install Ubuntu again.\nI'm new to Ubuntu and I tried everything that I know: like checking CPU and RAM usage with htop.\nThis is the last package that I installed for making Android ROMs:\nsudo apt-get install gawk\n\nand\nsudo apt-get install lzop bison gperf build-essential zlib1g-dev zlib1g-dev:i386 g++-multilib libxml2-utils bzip2 libbz2-dev libbz2-1.0 libghc-bzlib-dev libsepol1-dev dpkg-dev make\n\n\nA: In my case, solution was:\nAndroid MM:\nSettings->Advanced settings/options -> Debug options ->Verify applications - USB (disable)\nThe system will freeze/crash if this option is enabled.\n", "Q: Cannot boot to Windows 10 after failed installation of Ubuntu! I was trying to install Linux for a Linux course and now I am stuck. First of all Ubuntu doesn't get installed completely. So every time I restart the computer it asks me if I want to install Ubuntu and enter without installing. I have already install it 4 times but for some reason It is not installing. I am just trying to go back to windows I desperately need my files and program back ASAP. Please Help!!?\n\nA: Try this link: http://www.howtogeek.com/howto/32523/how-to-manually-repair-windows-7-boot-loader-problems/\n[EDIT]\nThis link is for Windows 10: http://www.thewindowsclub.com/repair-master-boot-record-mbr-windows\nYou will need Windows bootable drive like flash drive or DVD. Eventhough its says its for Windows 7 it must also work for others I suppose. However I have not tried it.\n\n\n*\n\n*Boot from windows DVD/Flash drive\n\n*Select repair computer\n\n*Choose command prompt\n\n*Enter the following commands:\nbootrec /fixmbr\n", "Q: outdated stunnel,openssl versions Kubuntu 14.04 I have :\nstunnel 4.53 > when the latest version is 5.31\nopenssl 1.0.1f > when the latest version is 1.0.2g\nI've updated the system using apt-get but still with 4.53 and 1.0.1f , I have a security concern that it's not good to be with such outdated versions ? why ubuntu doesn't provide the latest versions ? and how to update them please ?\n\nA: In the versions in the official repositories, all known security vulnerabilities are fixed, so if you are only concerned about security you can just stick with the Ubuntu version. If you have a particular vulnerability in mind, you can read the Ubuntu changelog (in /usr/share/doc or on http://packages.ubuntu.com, for example) to confirm that it is fixed in the Ubuntu package.\nYou may, however, want new features not available in the Ubuntu version, and in that case upgrading yourself is necessary, for example with repositories provided by the developers as in the case of OpenVPN.\n", "Q: VIrtual network I want to impliment pfsense to the local network. So before that I have to test it in a virtual environment, say couple of virtual-machines in an Ubuntu host using virtual box and one pf-sense machine which act as a router. Only the pf-sense machine will have real LAN access (for internet), and for all the local VMs ip will be provided by the pf-sense.\nProblem is in VB which network interface have to be used for the virtual machines and the pf-sense. For pf-sense I can use bridged adapter for one network interface to get connected to the real LAN. But what will be the other network interface which is only used to communicate to only the LAN machines?\n\nA: On pfsense VM set\n1st network adapter to NAT\n2nd network adapter to internal\n\nall other machines network adapters set to \ninternal\n\nhere is my video on youtube\n\nA: The \"WAN\" on pfsense is right to be the bridge adapter, for other VMs and the second interface of pfsense VM use \"Internal Netwok\", in the picture below I name the Internal Network vswitch as \"Secure DMZ\" off course you can give your own, and all VMs behind the Pfsense have to be attached to that Vswitch in order to access internet trough pfsense.\nLast but not least, you have to disable the block of privates subnet from the WAN interface in pfsense, if you don't external traffic from private subnet will all blocked.\n\n", "Q: Samba users cannot write into folders that created by other users If one of users create a folder, other users have no permission to write into it. How can I solve this problem ?\n#======================= Global Settings =======================\n[global]\ncreate mask =0777\ndirectory mask = 0777\nworkgroup = ENERJIK\nserver string = %h server (Samba, Ubuntu)\n   dns proxy = no\n#### Debugging/Accounting ####\n   log file = /var/log/samba/log.%m\n   max log size = 1000\n  syslog = 0\n  panic action = /usr/share/samba/panic-action %d\n####### Authentication #######\n   server role = standalone server\n   passdb backend = tdbsam\n   obey pam restrictions = yes\n   unix password sync = yes\n   passwd program = /usr/bin/passwd %u\n   passwd chat = *Enter\\snew\\s*\\spassword:* %n\\n *Retype\\snew\\s*\\spassword:* %n\\n \n   map to guest = bad user\n############ Misc ############\n   usershare allow guests = yes\n#======================= Share Definitions =======================\n [printers]\n   comment = All Printers\n   browseable = no\n   path = /var/spool/samba\n   printable = yes\n   guest ok = no\n   read only = yes\n   create mask = 0700\n\n[print$]\n   comment = Printer Drivers\n   path = /var/lib/samba/printers\n   browseable = yes\n   read only = yes\n   guest ok = no\n\n[Aylik Denetim Bilgisi]\n   comment = Enerjik Yapı Denetim Dosya Paylaşım Alanı\n   path = /media/depo/Aylikdenetimbilgisi\n   browseable = yes\n   write list = emre fatmanur ulfet\n   guest ok = no\n\n[Çalışan Takip]\n   comment = Enerjik Yapı Denetim Dosya Paylaşım Alanı\n   path = /media/depo/Calisantakip\n   browseable = yes\n   write list = emre fatmanur ulfet\n   guest ok = no\n\n[Inşaat Takip]\n   comment = Enerjik Yapı Denetim Dosya Paylaşım Alanı\n   path = /media/depo/Insaattakip\n   create mask = 0777\n   directory mask = 0777\n   browseable = yes\n   write list = emre fatmanur ulfet\n   guest ok = no\n\n\n[Ruhsatlı Projeler]\n   comment = Enerjik Yapı Denetim Dosya Paylaşım Alanı\n   path = /media/depo/Ruhsatliprojeler\n   browseable = yes\n   write list = emre murat eren servet nuri\n   guest ok = no\n\n[Enerjik]\n   comment = Enerjik Yapı Denetim Dosya Paylaşım Alanı\n   path = /media/depo/EnerjikYD\n   browseable = yes\n   write list = emre ulfet fatmanur\n   valid users = emre ulfet fatmanur\n   create mask = 0777\n   directory mask = 0777\n   guest ok = no\n[c$]\n   comment = Kök dizin paylaşımı\n   path = /\n   browseable = no\n   read only = no\n   write list = root\n\n\nA: create mask only defines the maximum rights a file can be created with. If the windows user creates a file with 0750, that's the right that's going to be applied with your settings, since it's being bitwise ANDed. You probably want to combine your settings with the force (directory) create mode = 0777 setting. \nFor more info check man 5 smb.conf:\nhttps://www.samba.org/samba/docs/man/manpages-3/smb.conf.5.html#CREATEMASK\n\nA: I think the reason of problem is user permissions. When I used Active Control  List (How do I set up a folder so that anything created in it inherits permissions?), problem has been solved partially.  But now if one user create a folder, others cannot delete it but they can write into it.\n", "Q: Using ACL to control read and writes by specific groups I'm new to ACL so I'm creating some demo folders, unfortunately it's not working as expected.\nThe folder Triangle belongs to user pyramid in group triangle. \nThe user Cube in group square needs permission to write to the folder Triangle.\nI used \ntriangle@ubuntu $ setfacl -m g:square:wx Triangle\n\ntriangle@ubuntu $ getfacl Triangle\n file: Triangle\n  owner: pyramid\n  group: triangle\n  user::rwx\n  group::rwx\n  group:circle:r--\n  group:square:-wx\n  mask::rwx\n  other::---\n\nbut then when cube wants to write a file into Triangle I get permission denied.\ncube@ubuntu $ groups cube\ncube : cube square\n\ncube@ubuntu $ touch Triangle/NiceYouLetMeWrite.txt\ntouch: cannot touch ‘Triangle/NiceYouLetMeWrite.txt’: Permission denied\n\n\nA: Make sure the user is in the correct groups with the\ngroups\n\ncommand.\n", "Q: Bad battery life on Xubuntu 16.04 Lenovo T460s The battery life of my new Lenovo T460s is very bad (about 4,5h with a little bit browsing and half display contrast). \nXubuntu 16.04 shows two batteries (SANYO 00HW022 and SANYO 01AV405). They were drained one after the other. I'm not sure how the batteries are integrated in the notebook, but I ordered it with only one (fixed) battery.\nIs there something I can do to increase the battery life? Is it a recognition problem of the battery?\n\nA: What you can do to increase the battery-life is installing tlp with some additional stuff\nsudo apt-get install tlp tlp-rdw acpi-call-dkms\n\ntlp is in the official ubuntu repo since 15.10. More information are available here. The man-page is in english\nman tlp\n\nYou can also install thinkfan which can reduce the noise-level and can save some energy. You should also install powertop\nsudo apt-get install thinkfan powertop\n\npowertop is a really powerful tool writen by intel.\n\nA: You should watch your computer enviroment (eg, making sure the the cpu doesn't get too hot, don't run too much applications, so on.) You could use tlp. tlp is excellent on many Linux computers.\nsudo apt-get install tlp\n\n\nA: As reported in previous comments, Skylake support for laptops in Linux is currently not perfect. More info here: https://mjg59.dreamwidth.org/41713.html. If you start Powertop, you'll probably find out that the deepest power saving state you can get is PC2 (under Idle stats/Package), which is apparently quite bad, and even potentially dangerous for the cpu. Launch powertop with sudo powertop --auto-tune, and see if you can get anything better: using that option I can now get a PC7 state; notice that first I updated the bios to the latest version (1.13), but I'm not sure this makes any difference. Hopefully next kernel updates will make things work better.\nNice machine, anyway :)\n", "Q: Move swap and extend home partition I have dual boot Ubuntu 14.04 and Win8.1. For some reason (my mistake) I have my home partition (80GB) than swap (4GB) and then 200GB of unallocated space (in that order). I want to use this free space. Can I move swap partition on the end of unallocated space and extend home partition (with-out loss of data)? Or should I just make another partition where the unallocated space is. Does the position of partitions matter or no? (Someone said to me once that swap should be at the end.)   \n\nA: Since the swap doesn't have any data stored on it, you can swapoff, remove the swap volume, extend your home-partition and recreate the swap at the end of the drive.\n", "Q: Installing Ubuntu on external drive - please help confirm my plan I want to dip my toes into the Ubuntu world. I have a 1TB drive in a NextStar external HD housing\nBeen reading a lot of different guides online for Dual-booting and I'm getting more and more confused :/\nI want to skip/bypass all the dual boot installation problems by putting it on a secondary HDD that I can swap when the computer is shutdown.\nMy plan to keep my computer intact and still install Ubuntu.\n1 - Have iso on bootable usbkey to install from (done)\n2- Connect external HD\n3- Go into bios on boot and set boot order to USB key then external USB drive (putting my Win 10 in last order)\n4- Boot up to the install usb key\n5- Go through install on external HD\n6- Remove usb key and reboot into Ubuntu.\nMy questions : \nWould this affect my WIN10 partition un the least?\nI could simply plug in my external drive before booting to go into Ubuntu and remove it to go to windows?\nWhat partitions would you reccomend on doing on the external HDD?\nThanks.\n\nA: I cannot see any reason for your proposed plan not to work. Ubuntu will not touch the HDD with Win10 on it if it is installing to a different HDD.\nLet Ubuntu sort out the size of the partitions on the external HDD.\nWhen Ubuntu is working you will be able to mount, read and write to the disk with Windows on it.\n", "Q: Install Ubuntu-Server do I need UEFI? My pc does not have uefi-bios. Can I install ubuntu server 15.10 without trouble?\n\nA: You don't need UEFI for any Ubuntu version at the moment. Might even be problematic with really old be versions. \n\nA: To elaborate a bit on Jakob's (correct) answer, the industry is moving toward EFI/UEFI, but the transition is far from complete. Ubuntu supports both BIOS-mode and EFI-mode booting, so either should work if the server supports both, and if the server is BIOS-only, you should still be fine, and should remain fine for the foreseeable future.\nI personally recommend EFI-mode booting in most cases if the computer supports both, at least in most cases. (As Jakob suggests, some early EFI implementations were extremely bugggy and so might work better in BIOS mode; but most such problems have been fixed on new hardware.) This is, of course, a moot point if the computer lacks EFI support.\n", "Q: Thinkpad X1 Yoga: accelerometer Acer BMA150 not working The Lenovo Thinkpad X1 Yoga ships with an Acer BMA150 accelerometer. This device is recognized by the Kernel (running Ubuntu 16.04 with Mainline kernel 4.6-RC2):\nroot# uname -a\nLinux x1 4.6.0-040600rc2-generic #201604031130 SMP Sun Apr 3 15:32:46 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nroot# dmesg| grep BMA                      \n[    9.611130] input: Acer BMA150 accelerometer as /devices/virtual/input/input15\n\n# udevadm info -q all -n /dev/input/js0\nP: /devices/virtual/input/input15/js0\nN: input/js0\nE: DEVNAME=/dev/input/js0\nE: DEVPATH=/devices/virtual/input/input15/js0\nE: ID_INPUT=1\nE: ID_INPUT_ACCELEROMETER=1\nE: MAJOR=13\nE: MINOR=0\nE: SUBSYSTEM=input\nE: USEC_INITIALIZED=9614435\n\nFrom above I understand that this device is detected as a joystick and should be usable via /dev/input/js0. Using jstest from package joystick however gives an error message:\nroot# /usr/bin/jstest /dev/input/js0       \njstest: Operation not permitted\n\nThe command above was executed as root. File permissions look good: \nroot# ls -l /dev/input/js0 \ncrw-rw-r-- 1 root input 13, 0 Apr 12 12:15 /dev/input/js0\n\nThere's no further error showing up in dmesg or in any file in /var/log.\nUsing jstest on my Wacom Inutos Tablet succeeds (it also acts as joystick device).\nCan anyone help me to get the accelerometer working?\n\nA: This device is used for harddisk shock prevention, and its detection as a joystick is an error. You get this error message because testing a non-joystick with the joystick tester doesn't work for obvious reasons.\nTo get it to work, at least on other thinkpads, you can install hdapsd. It needs to be run as a daemon - it reads the accelerometer data and parks the hard drive heads when critical motion of the laptop is detected.\nFor newer devices, specifically yours, hdapsd doesn't support the hardware. You can install iio-sensor-proxy to test your laptop with it. Other Yoga laptops work with it, according to their Github page.\n", "Q: ClamAV GPU installation I need to use ClamAV in GPU under ubuntu. There are some papers related to it. But how can i install ClamAV such that it could run in GPU? Can anyone help me with installation steps?\n\nA: It looks like that technology is experimental at the time of this writing and unpublished in the repositories. No luck there, sorry.\n", "Q: I can't compile a Qt project I was trying to compile a project I checked out from github but I get these errors:\n/usr/bin/ld: cannot find -lQtGui\n/usr/bin/ld: cannot find -lQtNetwork\n/usr/bin/ld: cannot find -lQtCore\n\nIt worked before but then I installed some application that pulled in Qt5 and nothing works anymore. How do I diagnose what's wrong or the reason why linker can't find these libraries.\n\nA: If you are building a Qt project, Qt Creator tool may be of use -- it supports multiple Qt versions to be set as build kits, you just need to have the proper compiler installed and locate the qmake file of the desired Qt.\nIf otherwise you are convinced to build something from command line (ex.: development is not the key goal), check the following:\nqmake --version  # which qt\npkg-config --modversion QtCore #module version\n\nAnd yes, export QT_SELECT = <desired Qt version> also works, when you need to switch versions for you build.\n", "Q: how can I install 5kplayer in ubuntu 14.04 I downloaded a video with MKV format. but when i try to run it some error pops up then i realize encoding of this video is not supported for my media players. the format is HEVC x265. I search a lot and finally land a media player called 5kplayer. I check the official website of the player it supported windows and mac. but i can't find support for linux or ubuntu.\nIs there any way to install 5kplayer in ubuntu 14.04.\nthank you in advance.\n\nA: There is  no official support for 5Kplayer in linux but you could use wine to install it in ubuntu.If u just want to play HEVC files you can use vlc which is natively supported in ubuntu.To install vlc\nsudo apt-get install vlc && sudo apt-get install vlc-plugin-libde265\n\n", "Q: Open terminal on startup and run command Very simple question, I'm new to Linux\nI have a command run on startup (Elementary OS) command is:\n/home/zachary/Documents/Server108/Server108.sh\n\nWhen I turn my laptop on the command runs in the background, and this is great, but I can't issue a \"Stop\" command because the terminal never opens. So, my question is this;\nHow do I force the terminal to open, run the script and then stay open?\nDo I need to add a line to the .sh file, or add arguments to the startup command?\n\nA: If you are using older GNOME you can add to startup something like this:\n\ngnome-terminal --command \"/path/myscript.sh\"\n\nJust edit your startup with gnome-session-properties GUI. It should be in System -> Properties menu or Applications –> Other –> Advanced Settings or press Alt+F2 and input it there. But apparently it was deprecated and it will not work on GNOME 3...\nYou can try adding into your folder ~/.config/autostart a file, let's say myscript.desktop with following content:\n[Desktop Entry]\nType=Application\nExec=gnome-terminal --command \"/path/myscript.sh\"\nHidden=false\nX-GNOME-Autostart-enabled=true\nName=Startup Script\nComment=\n\nAbove content is actually from my own system, created by mate-session-properties GUI and it works. Only updated it for GNOME. It actually might work on other environments, you'll just need to play with some details. Adding Terminal=true with Exec=/path/myscript.sh also works and with it you don't need to know the command to start your terminal.\nOn MATE it's easier, because it's still got that GUI. Commands are called mate-terminal and mate-session-properties. Here's how it looks on my MATE:\n\nI'm not familiar with Elementary OS and you didn't say which desktop environment you are using (might be Pantheon which I've never worked on), but it should not be that different.\nYou might need to figure out command to start your terminal and try running my-terminal --help or visit it's manpages to find proper parameter (or just try that much simpler Terminal=true solution).\nAnd if for some reason Terminal=true doesn't work and you can't determine your terminal's commands, install XTerm:\n\nsudo apt-get install xterm\n\nIts command is xterm -e \"/path/myscript.sh.\n", "Q: Limiting the perfomance of a graphics card to prevent an error I have a pc with some problem either with the graphic card or with it's interface.\nWhen i use the pc at max resolution it doesn't work or get stuck. But when i reduce the resolution somewhat it works. So i use it with reduced resolution ,it's OK - except for the following problem :\nIt works well for everything web related - surfing, video, etc - but it get stuck after playing candy crush for some period of time(and maybe other games, haven't tested). \nMy guess is that the game somehow overloads the graphics card. So are there any way to limit performance other than resolution , preferably ways that might make sense for the game ? \nThe card is from nvidia , probably 200 series. \n\nA: From your description it sounds like the graphics card is getting too hot when it is working hard and the driver is shutting it down to protect it. Are you monitoring the temperature of your graphics card using lm-sensor and p-sensor?\nIt would be worth checking that the graphics card heatsink and fan are not clogged with dust and that the graphics card fan has not failed.\nTo reduce the load on the graphics card from a game you can\n1 reduce the resolution\n2 limit the FPS (frames per second)\n3 reduce the detail\n4 turn off effects like shadows\n5 turn off antialiasing\nMost games have options for doing this.\n", "Q: Unable to run .jar file using .desktop file, even though it runs from terminal I'm running 32-bit Ubuntu 12.04 (on a 64-bit machine - don't ask).\nI have Oracle Java 8 installed as the default java version (confirmed using both 'java -version' and 'update -alternatives'), but also OpenJDK 6 and 7. which I prefer for some applications.\nMy question:\nI have a .jar file, Start.jar (for a work program written in Java) which I use regularly. It opens and runs fine when run from the terminal (by switching to the relevant directory and running java -jar Start.jar), but won't run  from a .desktop file. Why is this?\nThe .desktop file contains the following:\n[Desktop Entry]\nVersion=1.0\nType=Application\nTerminal=true\nPath=/home/jez/progpath\nExec=java -jar /home/jez/progname/Start.jar\nName=Progname\nIcon=/home/jez/progname/CT.png\n\nI've also tried it with:\nExec=java -jar Start.jar\n\nThe program includes a .sh file to launch a different .jar (we'll call it Alt.jar) to run the program. Alt.jar runs happily using a .desktop file very similar to the above to run the .sh file.\nSimply amending the one line .sh file to run Start.jar rather than Alt.jar doesn't work either. (Again it opens and immediately closes a terminal window.)\nThe developer has recently informed me that I should be running Start.jar, not Alt.jar, hence my efforts to find an easy way to run Start.jar.\nBoth .jar files, the .sh file and the .desktop file all have their permissions set to 'Allow executing file as program'.\nNote also that the program needs to run using Oracle Java 8, as it is not fully compatible with OpenJDK.\nFor completeness, the program in question is a computer-aided translation package called CafeTran (www.cafetran.com).\n\nA: The comments above got me thinking, and a little searching on askubuntu led me to the answer - the terminal parameter is wrong.\nThe problem is fixed by changing it to:\nTerminal=false\n\nClearly running Java is a little different from running a .sh.\nThank you to all for your assistance.  \n", "Q: How can I merge partitions in Ubuntu 15.04? I have installed Ubuntu 15.04 and it's my first time I am using Ubuntu. I installed it using 50 GB space first because I had Windows 7 installed previously and thought that i will make it duel boot but due to OEM BIOS restriction I could not do that and lost Windows 7 now. I formatted the drive on which Windows 7 was there. Now I have this space left and I want to use that 220 GB unallocated space and merge in swap and extended partitions. I have Gparted installed.\n\nI am not aware of it how to do it. Please suggest. Step by step guidance will be very much appreciated. \n\nA: Try to get use to command line. Take advantage and explore fdisk command.\nYou need to use sudo for this.\nOr\nI suggest the application gparted. You may have to install it from the Ubuntu repository or Software Center. It will give you user friendly interface that will make things easy for you.\nNote- If any of the partitions that you want to merge is in use, you will have to do it from live DVD/USB using GParted\n", "Q: 7zip is nowhere to be found I just installed 7zip from the Ubuntu Software Centre, but when I look for it in my applications, I can't find it. Even when I type \"7z\" in the terminal, it is telling me that 7zip is installed. How can I find the application and open it up? Thank you.\n\nA: \nHow can I find the application and open it up? \n\nOn the desktop\": the application you want is \"archive manager\". On our system all archive programs get attached to this programs and when an archiver/unarchiver is available \"archive manager\" recognizes it and lets you use it. Example images, \"7z\" selected from the drop down. \n\nCommand line you can use \"7z\" yourself manually too. man 7z will show a description and 7z --help the options.\n$7z --help\n\n7-Zip [64] 9.20  Copyright (c) 1999-2010 Igor Pavlov  2010-11-18\np7zip Version 9.20 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,2 CPUs)\n\nUsage: 7z <command> [<switches>...] <archive_name> [<file_names>...]\n       [<@listfiles...>]\n\n<Commands>\n  a: Add files to archive\n  b: Benchmark\n  d: Delete files from archive\n  e: Extract files from archive (without using directory names)\n  l: List contents of archive\n  t: Test integrity of archive\n  u: Update files to archive\n  x: eXtract files with full paths\n\n\nA: You can create your own launcher to run it. The launcher command for it  is :\n/usr/bin/Q7Z.pyw\n\n", "Q: How do I install the newest version of glogg in Mythbuntu? I am new to linux, so I apologize if this is a ridiculous question. My system:\n\n\n*\n\n*Mythbuntu 14.04\n\n*Xfce desktop\n\n\nI wanted a gui to view/tail/filter multiple log files and after a brief web search decided on glogg, which I installed from Ubuntu Software Center.\nSoftware center installed version 0.9.2-1, however if I go to the glogg website, I see that there is a version 1.0.3.\nMy question is how do I update to the latest version? I'm guessing I can learn how to compile the source, but is there any drawback to doing this vs just using the version from the software center?\nThanks!  \n\nA: It is by no means a ridiculous question.\nBy the time an Ubuntu distribution is available, many developers have already released a newer version of their package. If you want to stay on top of the latest glogg release, compiling it from source appears to be the only option. However, it looks pretty straightforward. Download the zip file and enter the commands given. You may need to install a couple of dependencies first, though: qmake-qt as well as the QT development libraries are mentioned. I suggest you google around to find the packages that provide these.\n", "Q: exporting an environment variable from a bash script to a tcsh shell I run bash scripts from tcsh shells.    I want to set an environment variable in the tcsh shell from a bash script.\nThe method of doing this, if your parent shell is bash is to source a file,\ni.e., if I have a file called dog that contains\n#!/bin/bash\nmyEnv=foo\nexport $myEnv\n\nthen from a bash shell, the command\n. dog\n\nwill as expected create an envi\n    source dog\nthen nothing happens.   Is there a way to accomplish what I want to do?\nthanks!\n\nA: You want\nexport myEnv\n\nnot\nexport $myEnv\n\n\nA: In addition to what Gunnar already noted,  export will make the variable available only to that instance of bash shell and its child processes. In addition tcsh and bash syntax differ when it comes to variables.\nI would suggest you  set a variable in the syntax familiar to tcsh\neagle:~/sergrep> cat var_file.txt\nsetenv foo \"TEST\"\neagle:~/sergrep> source var_file.txt\neagle:~/sergrep> echo $foo\nTEST\n\n", "Q: Uninstalling Cairo Dock doesn't work I installed Cairo Dock to try it, but I did not liked it. But uninstalling in the Software Center did not work, because the Cairo Dock is still sticking at the bottom of my screen. Here on askubuntu.com i found many answers and i tried nearly all of them, but i still see the Cairo Dock down there at my screen, and often the terminal said that \"cairo-dock\" is not installed or similar errors.\nPlease help me, because the this dock is a very annoying thing on my screen.\n\nSolved.\n\nA: i had same problem but this does it from terminal command line: \nsudo apt-get purge cairo-dock cairo-dock-plug-ins && sudo apt-get autoremove\n\nfrom : Cairo-Dock - Uninstall | Glx-Dock\nhope it helps\n\nA: You can try that command , it's helpfull :\nsudo apt-get purge cairo-dock cairo-dock-plug-ins && sudo apt-get autoremove\n\nIf you want to keep the configuration files: \nsudo dpkg -r cairo-dock-plug-ins_++version++ \n\nand \nsudo dpkg -r cairo-dock_++version++\n\nBut if you want to completely remove the dock including the configuration files: \nsudo dpkg -P cairo-dock-plug-ins_++version++ \n\nand\nsudo dpkg -P cairo-dock_++version++\n\nI wish that be usefull :)\n\nA: NONE OF THE ABOVE ANSWERS WORKED FOR ME\nI'm using ubuntu 22.04. Out of curiosity, I installed Cairo-dock and now I can't remove it anymore.\n\nA: NONE OF THE ABOVE ANSWERS WORKED FOR ME\nI'm using ubuntu 22.04. Out of curiosity, I installed the Cairo dock and now I can't remove it anymore.\nOkay, here is an official link to show you how to remove it. I removed it successfully :)\nhttp://www.glx-dock.org/ww_page.php?p=Uninstall&lang=en\n", "Q: Shortcut to open terminal in the currently open directory on GUI Are there any shortcuts to launch a terminal in the currently active directory in the GUI? For example say I am browsing the directory cd ~/Projects/A/B/C/D/ED on GUI. I wish to open a terminal with the current directory active at that location without opening a terminal and cd ing into it? Are there any shortcuts or methods to do so?\n\nA: Yeah, you can start the terminal by right-clicking at empty space in file manager and selecting the option there.\n", "Q: 15.10 install and now my pc doesn't allow me to do anything, please help? Could someone please help me? I installed 15.10 yesterday and after it was done all I got was a black screen. Like the terminal black page. Someone told me to put in sudo startx and that got me to my desktop but with not one icon or time date, anything. So could someone please help me get back to normal, PLEASE? Thanks, martin\n\nA: you could try installing gnome- there may have been a problem with unity in the install? that command would be:\n\nsudo apt-get install gnome\n\nand then do the startx thing?\nDo you have any other information than that?\n", "Q: How do I upgrade to the release version of 16.04 if I am running Beta? OS: Ubuntu Xenial Xerus (development branch) (GNU/Linux 4.4.0-18-generic x86_64)\nHi I've installed and configured the final beta of 16.04 and I see it says (development branch).  When the official version is released will it automatically update to the production release version when I run one of the following:\n\n\n*\n\n*apt-get upgrade\n\n*do-release-upgrade\n\n*apt-get dist-upgrade\nDo I have to modify something to start pulling from the prod/release branch when it's officially released?\nThe box is stable and working well. Will I be able to maintain the current configuration or will a complete re-install be needed?\n\nA: Once 16.04 is released running:\nsudo apt-get update\nsudo apt-get dist-upgrade\n\nWill do the trick, no need for do-release-upgrade (that won't actually do anything because you are already using 16.04, so there is nowhere to upgrade to). There shouldn't need to be anything else to change, anything that does need changing should be done for you automatically.\nAnd just as a side note, sudo apt-get dist-upgrade upgrades many things in addition to all that sudo apt-get upgrade does, so no need to run both, the dist-upgrade option covers both of them as stated in the manpage (man apt-get):\ndist-upgrade in addition to performing the function of upgrade,\n           also intelligently handles changing dependencies with new versions\n           of packages; apt-get has a \"smart\" conflict resolution system, and\n           it will attempt to upgrade the most important packages at the\n           expense of less important ones if necessary. The dist-upgrade\n           command may therefore remove some packages. The\n           /etc/apt/sources.list file contains a list of locations from which\n           to retrieve desired package files. See also apt_preferences(5) for\n           a mechanism for overriding the general settings for individual\n           packages.\n\n", "Q: I need help with Chown command . I broke my ubuntu I have accidentally executed this command on my Ubuntu terminal \nsudo chown -R 755 /var/www/html/buzo/wp-content/cd ..\n\nNow every folder has this lock like symbol and my desktop has turned black.\nWhat have I done? What do I need to do make it work again as it used to work before?\n\nA: I'm afraid I have some BAD NEWS for you...\nRefer to How can I recover from chmod -R a-wrx / command?\nBasically, those two dots at the end of your command began a Recursive CHMOD of everything starting at one level up from wherever your current working directory (CWD) was.  That's \"OUCH\" and is usually very bad.  If your CWD was in your \"~home\" folder, there are symlinks in your ~home directory that are pointing to scripts and programs in system folders and these now have their permissions changed IN THE SYSTEM FOLDERS! Once CHMOD was in the system folders, I assume it recursively changed all the permissions of everything there as well since it appears from your description you've effectively locked your operating system.\nI assume you've hosed your system and a backup of your important files is in order. I am not aware of a quick and simple solution to get all your permissions back the way they were unless you've made an image backup of your system prior to issuing that disastrous command.  Look at \"Aaron's\" answer as well at that referenced posting - he refers to a tedious method that perhaps will provide a starting point - if you're a patient person and want to learn far more about your operating system than you bargained for. You can also refer to a similar question on ServerFault.com - read all the suggestions...\nBut, in general, recovery is mostly a lost cause and you may never get your system back the way it was. Save your personal data, re-install your operating system, and chalk this up to another of life's lessons learned.\n\nA: sudo chown -R 755 /var/www/html/buzo/wp-content/cd ..\n\nwould error out on the 1st part. The \"..\" is a problem though but we can not help you yet with this. \nImportant question that needs answering: in what directory where you when you executed this? \n\n\n*\n\n*If in / you will need to re-install. Boot into a live session and make a backup of all your personal files and re-install, then restore the backup.\n\n*If somewhere else it might depend on where that was if it is fixable.\nExample:  If in /var/www/html/ or deeper it is not a big issue since a simple ...\nsudo chown -R $USER /var/www/html/ \n\n(change $USER to www-data or the other user name you use if you did not use your own username) would make it work again.\n", "Q: Wine won't open .exe files? I'm a big noob to ubuntu and having to run wine with windows applications, but I'm trying to download some indie games and 99% of them come up with an error message that insufficient data is not allowing the apps to run. I've tried re-downloading the games, no luck. I've tried setting the preferences to allow the files to be executable (the solution I've seen here most often) but that doesn't work either.\nAny tips? I'm running Ubuntu 14.04 LTS.\n\nA: If you are new with ubuntu, I recommend you to use Playonlinux to easy setup Wine.\nsudo apt-get install playonlinux\n\nIt has a good catalogue of popular games and Windows applications.\nEach Windows Application is different and may works well with an specific wine version, if you want to do it the right way, you could search for compatibility details of each one on https://www.winehq.org/ based on user tests and comments.\nWith PlayOnLinux you can easily make a separate profile (wineprefix) for each windows applications using different wine versions, requirements and configuration.\n\nA: Many indie games on steam are available as native Ubuntu software. sudo apt-get install steam. \nSteam requires a free registration. \n", "Q: gRsync set permissions same as when copying I am having trouble with permissions when using gRsync. The reason I am using grsync is it seems a lot easier to use my mounted windows share when using the browse feature. Currently I'm not sure how to get to my windows share through the terminal.\nThe setup:\nI have a windows 10 computer (named \"flat\") with a shared folder called \"completed\" this folder is filled with music in the structure of completed>albumfolder>song. My intent is to use my ubuntu computer to rsync and pull the files from this \"completed\" folder and place them into a folder on my ubuntu computer. These files are intended to be used with subsonic (software that allows you to stream your own music library). Subsonic uses a user that was created without a home folder called \"subsonic\". Currently what I have noticed is if I copy the files from the mounted windows share just using nautlius the subsonic software will see both the files (songs) and the folders (album folders). However if I run grsync the file permissions some how get messed up and the subsonic software can only see the folders (album folders) and cannot see the songs themselves.\nThe problem:\nWhen I run a grsync with no settings having to do with permissions everything seems to go good but when I check on the songs inside of the album folders they seem to have different permissions from what I would get if I just mounted the windows folder in nautilus and then copied all the files.\nThe permissions for the album folders seems to be the same between rsync and copying but the songs within the folders end up with different permissions based on what method I end up choosing.\nThe permissions when copying look like:\n-rw-rw-r-- 1 kv kv 5691435 May 10 2012 01 - Song title.flac\n\nThe permissions when running rsync look like:\n-rwxrwxr-x 1 kv kv 5691435 May 10 2012 01 - Song title.flac\n\nThe source looks like:\n/run/user/1000/gvfs/smb-share:server=flat,share=completed/\n\nMy goal is to get rsync to end up with the same permissions as if I just copied them. Currently if I run rsync subsonic can see the folders but not the songs. If I copy however subsonic can see the folders and the files.\n\nA: rsync has an option to keep permission\n -p, --perms                 preserve permissions\n\nIf you use gRsync, the same option is under Basic Options tab, mine is in spanish and looks like this:\ngRsync Basic Options\nHope it helps.\n", "Q: How to stop dhcp discover messages after dhcp release? I configured a wrong interface as dhcp and did a ifdown and ifup on that interface. DHCP client keeps sending DHCP discover messages and I had to wait for a while for it stop. ctl+z or ctl+c didn't really work.\nIs there a way to stop that instead of waiting for a long time.\nThanx in advance.\n\nA: You can find the PID of the DHCP Client with pgrep. Read man pgrep. You can kill (send a signal to) by name with pkill. man pkill.\n", "Q: How do i install wine in Ubuntu 14.04 lts? I have been trying to install wine but when i use the command sudo apt-get install wine i get this message:\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\n\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n  unity-control-center : Depends: libcheese-gtk23 (>= 3.4.0) but it is not going to be installed\n  Depends: libcheese7 (>= 3.0.1) but it is not going to be installed\n  wine : Depends: wine1.6 or wine1.8 but it is not going to be installed\n  E: Error, pkgProblemResolver::Resolve generated breaks, this may be caused by held packages.\n\nif you want extra info tell me the commands and i will post them\n\nA: You can try to run this command:\nsudo apt-get install -f\n\nIt should fix the dependencies and automatically install missing packages.\nIf it is not enough or you get some errors, you can try to install missing packages manually with this command:\nsudo apt-get install libcheese-gtk23 libcheese7 unity-control-center\n\n\nFor more information about apt-get and -f option you can read manual running this:\nman apt-get\n\nI hope this could help you.\n", "Q: Using Grsync to set up a backup job via GUI, can I see the rsync command it created? Is there a way to view the actual command that grsync ends up running? \nThe idea is to setup a backup job in Grsync, exactly as I want it with all the options, and subsequently use the command to have it run by cron for regular backups.\n\nA: Yes you can! Grsync is actually a great GUI tool to generate grsync commands.\nHow to see the command you created via GUI in Grsync\n\n*\n\n*Create your backup via GUI in Grsync\n\n*Once that is done, choose: File > Rsync command line\n\nThat's it. now the command you created via gui is displayed. Just copy it to use in cron or whatever procedure you use to make backups.\n\n", "Q: Can't get Virtualbox to work with Genymotion I started genymotion and got the following error-message:\n\nUnable to load VirtualBox engine.\nMake sure that it is properly installed before starting Genymotion.\nFor more information, please refer to https://www.genymotion.com/#!/support?chapter=vbox#faq\nGenymotion log archive has been saved in: /home/seel93/genymotion-log.zip\nPlease contact Genymotion support for more help.\n\nI've looked over FAQ with no luck even though I've followed their walkthrough for Linux.\nThis command:\nsudo /usr/lib/virtualbox/vboxdrv.sh status\n\ngives the following output:\n\nVirtualBox kernel modules (vboxdrv, vboxnetflt, vboxnetadp, vboxpci) are loaded.\n\nRestarting Virtualbox did not do the trick either as mentioned in many similar posts. Any help would be much appriciated.\n\nA: I'm using xubuntu 16.04 LTS and i was having the same error i tried this and worked: \nsudo /usr/lib/virtualbox/vboxdrv.sh setup\n\nit should say this:\n\nStopping VirtualBox kernel modules ...done.\n  Recompiling VirtualBox kernel modules ...done.\n  Starting VirtualBox kernel modules ...done.\n\nand then you can check if that worked using:\nsudo /usr/lib/virtualbox/vboxdrv.sh status\n\nthen try to run again genymotion :) i hope that helps! \n\nA: I get this when I've used up all 128 of my host-only NAT adapters,\nI've searched the web and there doesn't seem to be way to a) remove them all in a batch or b) make Genymotion use the same one instead of creating a new one every time it starts. (Although one page I read made it sound like that is supposed to be the case!)\nThe fix for me:\n\n\n*\n\n*Start VirtualBox\n\n*Go to File -> Preferences -> Network and open the \"Host-only Networks\" tab\n\n*One by one remove the vboxnet(0 to 127)'s!\n\n\nAlthough you could just remove one and then start Genymotion - but you'd have to do it again next time! :)\nNow if anyone knows how to stop Genymotion creating them ...\n\nA: I ended up simply installing virtualbox that is available in Ubuntu app store, and voila Genymotion worked :)\nI previously tried to download the latest from their website, but that seemed to display this error.\n", "Q: Kubuntu Graphical Desktop Not Displaying $HOME/Desktop Files I'll make this as short as possible. I will refer to the \"Desktop\" to mean the area I see on the screen when no programs are open. \nToday I installed Kubuntu 15.10. When I save files to Home/Desktop directory, they do not appear on the Desktop. Is there a way to change what I see on the Desktop to see the files that are in Home/Desktop? \nIn terminal, I navigated to $HOME/Desktop and the files I expected to see on my Desktop appear in that folder.\nIn the ~/.config/user-dirs.dirs file, the first line is XDG_DESKTOP_DIR=\"$HOME/Desktop\"\n\nA: KDE doesn't show files on the desktop in the usual way. It has this weird feature where you add folders to be displayed in resizable and draggable boxes. They're essentially widgets that show files.\nTo add a folder, open the Widget Options (Alt + D) and select the Folder widget. You can then configure it to show whichever folder you want.\nAlternatively, right click on the desktop and choose the Folder View option. Make sure the desktop is \"unlocked\" (configurable).\n", "Q: using apt to migrate from 1504 to 1604 I forgot how to migrate from 1504 to 1604 using apt.  I am not sure how to do this it has been so long. I am not even sure where to look for this help.  Thank you\n\nA: If you want to upgrade before the official release in April 21st you can open a terminal window and write\nsudo update-manager -d\n\nThis will upgrade your system\nIf you wait the official release your ubuntu system will warn you about it and then you can upgrade.\n", "Q: Is it possible to run more than one command in a someapp.desktop file? i am just trying to find a way to run an extra command when opening an app (Firefox), but i am failing miserably... \nThe original question is here.\nI tried to add my command after the app command as in the following line:\nExec=firefox %u & /bin/monitor_process.sh firefox\n\nBut this results in the monitor_process.sh being opened by FF, showing an \"open file with...\" dialogue box.\nI tried ; & && but to no avail...\nSo, any idea how to handle multiple commands in .desktop files?\nAlso, Serg Said:\n\nthat also won't work. Exec= has to have exactly one statement, no ; is allowed.\n\n\nA: Desktop files are not run in a shell; that means that you can't run complex commands such as firefox %u & /bin/monitor_process.sh firefox directly; in that case everything fails at the & part, which is not intepreted as \"background firefox %u\" but literally as &, which is passed as an argument to firefox %u along with /bin/monitor_process.sh and firefox.\nTo fix that run firefox %u & /bin/monitor_process.sh firefox in a shell which at least supports job control (simply dash would work):\n[Desktop Entry]\nName=foo\nExec=sh -c 'firefox %u & /bin/monitor_process.sh firefox'\nType=Application\n\n\nA: You could try this Exec line for your .desktop file:\nExec= bash -c \"firefox && /bin/monitor_process.sh firefox\"\n\nbash will open a shell and correctly interpret the &&.\n", "Q: Hyper-V Style Hypervisor on Ubuntu I've got an Ubuntu server running a few things, and I'd like to add FreePBX to it. I don't want to reconfigure/reinstall my current Ubuntu installation just so I can run a Type-1 hypervisor like Xen (If I understand correctly I would have to reinstall Ubuntu inside the type-1 hypervisor). But I like the whole \"autostart VMs on boot and connecting if you want to\" flow, rather than the VBox/QEMU \"Launch it when you need it and leave the window open\" idea. Does such a thing exist for Ubuntu?\nEdit: The whole point of this is for me to not even realize it's there if I don't check ps or connect to it. If you ask it to, Hyper-V will start VMs on boot automatically and transparently. You can later choose to connect if you wish, but services can still be running as if they are on the host machine.\n\nA: The way on Ubuntu would be to use libvirt on top of KVM/QEMU/VirtualBox. Quoting the Arch Wiki:\n\nLibvirt is collection of software that provides a convenient way to\n  manage virtual machines and other virtualization functionality, such\n  as storage and network interface management. These software pieces\n  include a long term stable C API, a daemon (libvirtd), and a command\n  line utility (virsh). A primary goal of libvirt is to provide a single\n  way to manage multiple different virtualization providers/hypervisors,\n  such as the KVM/QEMU, Xen, LXC, OpenVZ or VirtualBox hypervisors\n  (among others). Some of the major libvirt features are:\n  \n  \n*\n  \n*VM management: Various domain lifecycle operations such as start, stop, pause, save, restore, and migrate. Hotplug operations for\n  many device types including disk and network interfaces, memory, and\n  cpus.\n  \n*Remote machine support: All libvirt functionality is accessible on any machine running the libvirt daemon, including remote machines.\n  A variety of network transports are supported for connecting remotely,\n  with the simplest being SSH, which requires no extra explicit\n  configuration.\n  \n*Storage management: Any host running the libvirt daemon can be used to manage various types of storage: create file images of various\n  formats (qcow2, vmdk, raw, ...), mount NFS shares, enumerate existing\n  LVM volume groups, create new LVM volume groups and logical volumes,\n  partition raw disk devices, mount iSCSI shares, and much more.\n  \n*Network interface management: Any host running the libvirt daemon can be used to manage physical and logical network interfaces.\n  Enumerate existing interfaces, as well as configure (and create)\n  interfaces, bridges, vlans, and bond devices.\n  \n*Virtual NAT and Route based networking: Any host running the libvirt daemon can manage and create virtual networks. Libvirt virtual\n  networks use firewall rules to act as a router, providing VMs\n  transparent access to the host machines network.\n  \n\nCLI management is done primarily using the virsh command. There's an associated GUI front-end, called virt-manager. \nAs for starting VMs automatically, assuming you have a VM named foo, to mark it for starting at boot:\nvirsh autostart foo\n\nAnd to unmark it:\nvirsh autostart --disable foo\n\nThe Ubuntu LTS Server Guide has a chapter on libvirt.\n\nA: Virtual Machine Manager can manage quemu instances with a nice gui interface, and has an option you can check to auto start a vm when the host boots.\n", "Q: How to package a browser plugin and a gui app in a snap package My app is a gui app (qt) and a browser plugin. The plugin is used only for firefox. When the user clicks a button I want to open my gui-app. \nI would like to use a snap package to do this, but I can not find how to package a browser plugin. I need that the plugin is available on reload of the page.\nOther solution can be to not use a plugin, but I can not find how to configure firefox to open a specific app with a click. I should be done by the app installer.\n\nA: We don't currently offer a way for snaps to integrate with the the browser, I'm afraid.\nThis is probably going to happen at some point (at least in the sense you seem to want, i.e. hand particular URLs off to particular apps), but I couldn't hazard a guess as to when.\n", "Q: Suddenly \"No soundcards found\" After having worked properly for a month, my sound card went missing.\nIt was probably after I forced a restart (laptop frozen).\nI am running Ubuntu 14.04.4 LTS on a laptop with a pretty basic Sound Card  Intel 2 Channel High Definition Audio.\naplay -l \n\ngives\naplay: device_list:268: no soundcards found...\n\nlsmod | grep snd\n\ngives nothing.\nI tried many solutions but none seems to work. Any ideas?\n\nA: Try checking out Ubuntu's own sound card issues page, it has helped me a few times in the past and gives you simple instructions on testing and re-enabling sound cards: https://help.ubuntu.com/community/SoundTroubleshooting\n\nA: The issue was solved by forcing a restart after the computer had frozen. Still not sure whether it's a hardware or software issue or a combination of the two.\n", "Q: how I can fix the apt.conf? I don't need of the proxy So, I'm going to solve my issue, I found the apt.conf to be responsible of a apt-get malfunction. I need a no proxy setting in it.\nHow to fix it?\n\nA: Open a terminal (Ctrl+Alt+T), then run this to edit the file:\nsudo nano /etc/apt/apt.conf\n\nIf it has a line that looks like:\nAcquire::http::Proxy \"http://192.168.1.1:3142\";\n\ncomment it out (put // in front of it):\n// Acquire::http::Proxy \"http://192.168.1.1:3142\";\n\nPress Ctrl+O then Enter to save the file and Ctrl+X to exit the editor.\n", "Q: USB port mounting How do I find out what USB a device is in and get it to mount.I have done it befor but not in a long time and can't remember how nor can I find the notes I took to do it  \n\nA: I've done this with external HDDs using Ubuntu 14.04 and 12.04, I'm assuming that is what you're attempting. I start with Gparted to identify the device, usually its /dev/sdb1 or similar. \nThen I find the device, there is a drop down in the top right (at the moment) to change between devices. Once you have located your USB device select it.\nI like to use EXT4 format. To do so:\n1 - select the HDD (usually sdb1 or similar) note the path for later use\n2 - Right Click and choose Format\n3 - Select EXT4 (or whatever format you like)\n4 - Click on the Green Checkmark to apply the changes\n5 - Label the device by Right Click and choose Label, I stick with EXT-HDD for my external HDD\n6 - Click on the Green Checkmark again to apply the label\nHere's where it gets a little confusing. \n7 - After you have saved the changes, disconnect the EXT-HDD\n8 - Leave it disconnected and shutdown (NOT REBOOT) your PC\n9 - plug the EXT-HDD back into the same USB port\n10 - turn the PC back on\n11 - get to the desktop and open up a terminal and become root\n12 - Identify the Devices UUID with this command and the path you noted from step 1:\nblkid /dev/sdb1\n\n13 - Note the UUID for the device\n14 - Create the mount point you want with this command:\nmkdir /mnt/exthdd \n\n(or similar depending on where you want it mounted and pointing to) Note that mount point for later use\n15 - open and edit fstab via terminal to look give it mount point and permissions\nnano /etc/fstab\n\nadd the line (use tab between values):\nUUID=<enter your devices UUID>     /mnt/exthdd     ext4     auto     0     0\n\n16 - save changes to fstab\n17 - give permissions to the created mount point\nchmod 777 /mnt/exthdd\n\nExit terminal and reboot. \nAt this point your PC should boot fine and have a new mount point. Any issues start over and double check everything. There have been devices I can get mounted on the first try, and for some reason others take a few tries, so don't loose heart. To ensure it mounted, there should be no errors during boot also go to that mount point in your files and see what the size of the volume is, it should be about the size of your USB device. \nGood Luck and Enjoy!\n\nA: You just want to mount a drive you've plugged in?\nYou can use the graphical file browser and just click the entry for it, or you can use the command-line.  \nIf you use the command line, find out the path to the device and then mount it with udisksctl.\nTo find the path, I suggest checking the output from dmesg after you've plugged it in.  For example, I just plugged in a thumb drive:\nuser@host:~$ dmesg | tail -n 10\n[29642.218520] usb-storage 3-1.2:1.0: USB Mass Storage device detected\n[29642.219007] scsi host7: usb-storage 3-1.2:1.0\n[29643.217841] scsi 7:0:0:0: Direct-Access     SanDisk  Cruzer Glide     1.26 PQ: 0 ANSI: 6\n[29643.218263] sd 7:0:0:0: Attached scsi generic sg2 type 0\n[29643.219516] sd 7:0:0:0: [sdc] 15633408 512-byte logical blocks: (8.00 GB/7.45 GiB)\n[29643.220885] sd 7:0:0:0: [sdc] Write Protect is off\n[29643.220891] sd 7:0:0:0: [sdc] Mode Sense: 43 00 00 00\n[29643.221893] sd 7:0:0:0: [sdc] Write cache: disabled, read cache: enabled, doesn't support DPO or FUA\n[29643.234250]  sdc: sdc1 sdc2 sdc3\n[29643.237733] sd 7:0:0:0: [sdc] Attached SCSI removable disk\n\nSo in this case, I have three partitions on my drive: sdc1, sdc2, sdc3 (which will all be in /dev/sdc1, /dev/sdc2, /dev/sdc3).\nIf you can't unplug and replug the device for some reason, you could just list all of your drives by their labels and see if maybe it's one of those.  For example:\nls -l /dev/disk/by-label/\nlrwxrwxrwx 1 root root 10 Apr 13 11:27 d_extra -> ../../sda1\nlrwxrwxrwx 1 root root 10 Apr 13 19:41 Kali\\x20Live -> ../../sdc2\nlrwxrwxrwx 1 root root 10 Apr 13 11:27 l_extra -> ../../sda3\nlrwxrwxrwx 1 root root 10 Apr 13 19:41 persistence -> ../../sdc3\n\nOnce you know which device you actually want to mount, you can use udisksctl with the -b option to tell it what device.\nFor example, if I wanted to mount the \"Kali Live\" partition, I could do it like this:\nuser@host:~$ udisksctl mount -b /dev/sdc2 \nMounted /dev/sdc2 at /media/user/Kali Live.\n\nOr, I could specify the by-label path...\nuser@host:~$ udisksctl mount -b '/dev/disk/by-label/Kali\\x20Live'\nMounted /dev/sdc2 at /media/user/Kali Live.\n\nHowever you do it, be sure to unmount it when you finish:\nuser@host:~$ udisksctl unmount -b /dev/sdc2\n\n\nA: Thanks for replying. I stopped using my printer several months ago and when I tried to get it going again it wouldn't work I have figured it out it was a in my system settings some how something got unchecked.It was a more simple fix then I thought thanks again for the replies  \n", "Q: Removing Ubuntu from a laptop and install Windows 7 This may have been asked before, but I can't seem to find an appropriate answer. I've been searching for about two days now, to no avail. Here is my situation. \nI purchased a new laptop. The original thought was to put Ubuntu on first, that put on Windows 7, which I have. After I installed Ubuntu, It wouldn't let me install windows. After a while, I got frustrated and decided to REMOVE Ubuntu and just install Windows 7 for a class i'm going to need in a few days. For the life of me, I can't uninstall Ubuntu. I've tried everything possibe and even google searched. I purchased WipeDrive, still not working. Tried to restart and boot from disk. It freezes. Sometimes only sees Ubuntu on C drive and not my cd drive. Please, for the love of god, help me get Ubuntu off of my computer. Please. \n\nA: You only need a DVD of Windows or a Live GParted to format your HDD.\n\n\n*\n\n*Insert Windows DVD\n\n*Select install\n\n*Remove the existing partitions\n\n*Create new partitions for Windows\n\n*Format the partitions\n\n*Install Windows.\n\n", "Q: How to find a specific text in files with specific extension? Let's say I'm searching for all files with .log extension that contain the text of abc.\nWhen searching for files with any extension would look like\n(Ref.: https://unix.stackexchange.com/a/16140/38353 )\nfind / -xdev -type f -print0 | xargs -0 grep -H \"abc\"\n\nHow could we modify this so that it will search only for files with .log extension?\nI'll be more than happy if you show a better command.\n\nA: TL;DR\nAdd -iname \"*.log\" after / to your find command. Refer to man page for more info\nA more detailed answer\nThe task at hand is the following:\n\n\n*\n\n*List files that match pattern *.log\n\n*Execute grep per each file to find whether or not it contains a specific string.\n\n*List the filename that has a match on the stdout\nThe example of how that can be accomplished can be seen bellow:\n$ find /var/log -iname \"*.log\" -exec grep -l 'wlan' {} \\+                      \n\nEssentially there's 3 things at play:\n\n\n*\n\n*find does the job of finding files AND calling grep per list of filenames in the -exec ...{} \\+  structure, where {} will be substituted with all the filenames found.\n\n*-iname \"*.log\" can provide case-insensetive matching of the filenames\n\n*-exec . . .{} \\+ calls the low-level execve function that will spawn grep -l with the list of all the files found in front of it ( in the place of {} ). \n\n*The \\+ is the option that specifies for execve to pack as any files as possible in front of grep (the limit is set by ARG_MAX variable, is specific to exec, and for Ubuntu is at 2097152 as can be shown by getconf ARG_MAX command ). Once the limit is reached, exec will repeat the call to grep with more files packed as arguments. The \\ is necessary to ensure + is interpreted as argument to find and not as another shell command.\n\n*the -l option or grep shows files with matched string. -L would match files without the string.\n\n", "Q: Unresolved dependencies trying to install build-essential on Lubuntu 14.04 I am trying to install build-essential (NB: I want to install the getch module for use in python eventually) and apt-get returns an error because of unresolved dependencies which cannot be fixed because there seem to be broken packages.\nI have a fairly cleen sources.list (I only sets up the whole linux system a few hours ago):\ndeb http://de.archive.ubuntu.com/ubuntu/ trusty main restricted\ndeb http://de.archive.ubuntu.com/ubuntu/ trusty universe\ndeb http://de.archive.ubuntu.com/ubuntu/ trusty multiverse\ndeb http://security.ubuntu.com/ubuntu trusty-security main restricted\ndeb http://security.ubuntu.com/ubuntu trusty-security universe\ndeb http://security.ubuntu.com/ubuntu trusty-security multiverse\ndeb http://extras.ubuntu.com/ubuntu trusty main\ndeb-src http://extras.ubuntu.com/ubuntu trusty main\n\nI have tried the usual tips&tricks (all with sudo):\napt-get clean\napt-get update\napt-get -f install\ndpkg --configure -a\napt-get -f install\napt-get upgrade\n\nI get: \n0 upgraded, 0 newly installed, 0 to remove, 0 not upgraded\n\nNext I tried\napt-get -u dist-upgrade\n\nSame Output as before.\nI even tried to resolve the dependencies manually, but I didn't get very far, because at some point I install a package (gcc-4.8-base) and when I want to install the package which depends on it (that ist gcc-4.8) apt-get complains that gcc-4.8-base is missing... That was the point when my brains got really messed up.\nAnyway, does anybody have any suggestions? Thank you very much!\nOh, and yes, I did read a lot of posts in this and other forums, still dont have a clue! Any advice is thus greatly appreciated!\n\nA: Ok, I managed to solve the problem: I installed aptitude\nsudo apt-get install aptitude\n\nand then ran aptitude to install build-essential\nsudo aptitude install build-essential\n\nit suggested to downgrade some packages (don't accept the first solution it proposes, I think the second or third solution was the one that worked). In case somebody stumbles upon the same problem - use aptitude - as somebody wrote in another forum it is like apt-get only smarter...\n", "Q: How can I show an icon in the panel if (and while) a certain process is running? I have a script that works in the background. I would like to show an icon in the panel (only) if it runs; it should not show if the script is not running, just like the Dropbox icon. \nHow can I achieve this?  I have installed Xubuntu 14.04.  \n\nA: How to show an icon in the panel if a process runs\nBased on (and explained in) this answer, we can fairly easily create an indicator, which runs on both Xubuntu and Unity or any other flavour, to show if a process, a script or an application runs or not.\nscript runs:\n\nscript doesn't run:\n\nIn the script (indicator) below, I added a thread to detect the process to the indicator:\n#!/usr/bin/env python3\nimport subprocess\nimport os\nimport time\nimport signal\nimport gi\ngi.require_version('Gtk', '3.0')\ngi.require_version('AppIndicator3', '0.1')\nfrom gi.repository import Gtk, AppIndicator3, GObject\nfrom threading import Thread\n\n# --- set the path to the script below\nscript = \"/path/to/script.sh\"\n#---\n\ncurrpath = os.path.dirname(os.path.realpath(__file__))\n\ndef runs(script):\n    # function to check if the process runs\n    try:\n        return subprocess.check_output([\"pgrep\", \"-f\", script]).decode(\"utf-8\")\n    except subprocess.CalledProcessError:\n        pass\n\nclass Indicator():\n    def __init__(self):\n        self.app = 'show_proc'\n        iconpath = currpath+\"/nocolor.png\"\n        self.indicator = AppIndicator3.Indicator.new(\n            self.app, iconpath,\n            AppIndicator3.IndicatorCategory.OTHER)\n        self.indicator.set_status(AppIndicator3.IndicatorStatus.ACTIVE)       \n        self.indicator.set_menu(self.create_menu())\n\n        self.update = Thread(target=self.check_runs)\n        # daemonize the thread to make the indicator stopable\n        self.update.setDaemon(True)\n        self.update.start()     \n\n    def check_runs(self):\n        # the function (thread), checking for the process to run\n        runs1 = \"\"\n        while True:\n            time.sleep(1)\n            runs2 = runs(script)\n            # if there is a change in state, update the icon\n            if runs1 != runs2:\n                if runs2:\n                    # set the icon to show\n                    GObject.idle_add(\n                        self.indicator.set_icon,\n                        currpath+\"/green.png\",\n                        priority=GObject.PRIORITY_DEFAULT\n                        )\n                else:\n                    # set the icon to hide\n                    GObject.idle_add(\n                        self.indicator.set_icon,\n                        currpath+\"/nocolor.png\",\n                        priority=GObject.PRIORITY_DEFAULT\n                        )\n            runs1 = runs2\n\n\n    def create_menu(self):\n        menu = Gtk.Menu()\n        # quit\n        item_quit = Gtk.MenuItem('Quit')\n        item_quit.connect('activate', self.stop)\n        menu.append(item_quit)\n        menu.show_all()\n        return menu\n\n    def stop(self, source):\n        Gtk.main_quit()\n\nIndicator()\nGObject.threads_init()\nsignal.signal(signal.SIGINT, signal.SIG_DFL)\nGtk.main()\n\nHow to use\n\n\n*\n\n*Copy the script below into an empty file, save it as show_proc.py \n\n*In the head section of the script, in the line: \n# --- set the path to the script below\nscript = \"/path/to/script.sh\"\n#---\n\nset the path to your script or applications\n\n*Copy both icons below (right click -> save as), and save them in one and the same directory as show_proc.py, and exactly named as indicated below\ngreen.png\n\nnocolor.png\n  <-- this is a transparent icon, but is is there :). move the cursor over it until the finger appears...\n\n*Now test- run show_proc.py by the command:\npython3 /path/to/show_proc.py\n\nand start up your script\n\n*If all works fine, add the following to sgtartup applications:\n/bin/bash -c \"sleep 15 && python3 /path/to/show_proc.py\"\n\n\nA: In Xubuntu, install the Generic Monitor panel plugin by pasting the following in terminal:  \nsudo apt-get install xfce4-genmon-plugin\n\nFrom the Generic Monitor plugin page:\n\"This plugin cyclically spawns the indicated script/program, captures its output (stdout) and displays the resulting string into the panel.\nThe string can also contain markup to display an image, a bar, a button and a personalized tooltip.\" \nSet the following script to run using the Generic Monitor panel plugin. I recommend without a Label. Be sure to replace your_script with the name of your script and add in the path to your icon. \n#!/bin/bash\n\nstatus=$(pgrep your_script)\n\nif [ -n \"$status\" ]; then\n    echo \"<img>/path/to/your/icon.png</img>\"\nelse\n    echo \"\"\nfi\n\nIt is interesting that you mention Dropbox. I use this plugin for Dropbox. \nThere are also plugins for the panel in Unity that show command or script output. However, I just have Xfce so I can't confirm a particular one. I hope all works out great.\n", "Q: SD card unmounts during suspend or hibernate I have a laptop with only 32GB SSD space (Lenovo 100S). That's not very much, so when I installed Ubuntu 15.10, I set a 64GB SD card as the /home partition.\nMy problem is, every time I wake the laptop from suspend or hibernate, the SD card is unmounted and I have to reinsert it to re-mount it. How can I configure Ubuntu so that the SD card is acting like a normal System \"SSD\"?\n\nA: Maybe there is a graphic tool to do this, depending your environment.\nBut you can always configure Ubuntu so that the SD card is acting like a normal System \"SSD\" by editing the fstab file, in /etc/fstab. Maybe have a look to the doc about it if you are interested by this questions.\nHave a look to yours with a text editor, and make a backup file before editing anything.\nSo then:\nsudo nano /etc/fstab \n\nYou just have to specify uuid, the mount point desired, the file system used and leav the other option as defaults, 0, and 2.\nExample for my home device:\n# /home was on /dev/sde8 during installation\nUUID=ab5346f-c35e-454e-7827-esd6g4ds5fab /home           ext4    defaults        0       2\n\nBut I don't know is there is a specific problem with suspend (it's possible).\n", "Q: Juju bootstrap fails with dns resolution issues I am building a proof of concept install using old hardware and the AutoPilot install which is using Liberty.  I finally managed to get the physical servers to commission in MAAS and commenced the openstack-install.  I get the servers to deployed but then it fails, time and time again, on \"Could not resolve host: streams.canonical.com\\ntools\"  I have used the localhost, private ip of the maas host, public address of the maas host and nothing works.  I set up all the avilable dns hosts in the maas network setup, maas host, nothing works.\nOS is Ubuntu server 15.10, MAAS is V2.0, Openstack is Liberty (I think as it is not yet installed), hardware is a Dell 2900 Tower, 2 * quad cores and 32 Gb ram.\nAny guidance would be highly appreciated.  Thanks.\n\nA: You might probably be running into DNS issues.\nRefer the following link:\nhttps://github.com/puppetlabs/puppetlabs-openstack/issues/235\nhttps://github.com/Ubuntu-Solutions-Engineering/openstack-installer/issues/883\n", "Q: Firefox Gstreamer vaapi I have a laptop with not much CPU power, so I want that Firefox and Gstreamer (and maybe Rhythmbox) uses the VAAPI on my Ubuntu 15.10. vainfo gives me already the following output, so the vaapi driver seem to be working:\ndennis@Yoda:~$ vainfo\nlibva info: VA-API version 0.38.1\nlibva info: va_getDriverName() returns 0\nlibva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/i965_drv_video.so\nlibva info: Found init function __vaDriverInit_0_38\nlibva info: va_openDriver() returns 0\nvainfo: VA-API version: 0.38 (libva 1.6.2)\nvainfo: Driver version: Intel i965 driver for Intel(R) CherryView - 1.6.2\nvainfo: Supported profile and entrypoints\n      VAProfileMPEG2Simple            : VAEntrypointVLD\n      VAProfileMPEG2Simple            : VAEntrypointEncSlice\n      VAProfileMPEG2Main              : VAEntrypointVLD\n      VAProfileMPEG2Main              : VAEntrypointEncSlice\n      VAProfileH264ConstrainedBaseline: VAEntrypointVLD\n      VAProfileH264ConstrainedBaseline: VAEntrypointEncSlice\n      VAProfileH264Main               : VAEntrypointVLD\n      VAProfileH264Main               : VAEntrypointEncSlice\n      VAProfileH264High               : VAEntrypointVLD\n      VAProfileH264High               : VAEntrypointEncSlice\n      VAProfileH264MultiviewHigh      : VAEntrypointVLD\n      VAProfileH264MultiviewHigh      : VAEntrypointEncSlice\n      VAProfileH264StereoHigh         : VAEntrypointVLD\n      VAProfileH264StereoHigh         : VAEntrypointEncSlice\n      VAProfileVC1Simple              : VAEntrypointVLD\n      VAProfileVC1Main                : VAEntrypointVLD\n      VAProfileVC1Advanced            : VAEntrypointVLD\n      VAProfileNone                   : VAEntrypointVideoProc\n      VAProfileJPEGBaseline           : VAEntrypointVLD\n      VAProfileJPEGBaseline           : VAEntrypointEncPicture\n      VAProfileVP8Version0_3          : VAEntrypointVLD\n      VAProfileVP8Version0_3          : VAEntrypointEncSlice\n      VAProfileH264MultiviewHigh      : VAEntrypointVLD\n      VAProfileH264MultiviewHigh      : VAEntrypointEncSlice\n      VAProfileH264StereoHigh         : VAEntrypointVLD\n      VAProfileH264StereoHigh         : VAEntrypointEncSlice\n      VAProfileHEVCMain               : VAEntrypointVLD\n\nI have tried many to get it work.....but it didn't worked.\nIt would be great, if somebody knews what to configurate now that firefox etc. uses the vaapi. (Everytime i install \"gstreamer1.0-vaapi\" gestreamer don't even shows me a Video)\nGreets\nDennis\n\nA: This isn't currently possible, FireFox has no vaapi support (as far as I know). If it did you would have to install the h.264ify plugin to watch YouTube, because there is no hardware support for vp9 (the codec that YouTube uses) decoding.\n", "Q: Disable NVIDIA Optimus Graphics Card I am running Ubuntu 15.10 and have a laptop with NVIDIA Optimus technology. As known by many, Optimus has yet to receive official support and has a lot of issues. Since I do not need the power of the graphics card for when I am on Ubuntu I would like to know if it is possible to completely disable the NVIDIA card altogether and only use the Intel on-board graphics. How would I go about doing this if possible?\nI know of one solution which is using the NVIDIA PRIME and changing the profile to only use Intel, but the problem with this is that using the NVIDIA driver causes severe screen tearing which is annoying to deal with so this is not an option for me.\n\nA: Uninstall the proprietary NVIDIA drivers and disable the use of the nouveau drivers.  \nOpen a terminal and execute :\nsudo apt-get install gksu\ngksudo gedit /etc/default/grub  \n\nAdd nouveau.modeset=0 to the line GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\" \nso that it reads GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nouveau.modeset=0\".  \nSave changes and close the file. \nNow execute these commands :\nsudo update-grub  \nsudo apt-get purge nvidia*  \nsudo reboot  \n\nNow you are using the integrated intel graphics and the NVIDIA graphics are not in use.\n", "Q: Ubuntu's best utilities for programmers I have been working in Windows for many years, now I'm interested in using a Linux OS, so I am starting with Ubuntu. Can any experts recommend some apps that will help in programming?\nMy programming skills:\nServer side: \nPHP, Python, ASP\nClient Side:\n HTML, CSS, JS, jQuery, AJAX\n\nA: Ubuntu has default support for python. and you can run python codes in terminal using python filename.py.\nPHP - PHPStorm For more here\npython has a command shell - Ipython\nASP.NET - MonoDevelop\nHTML, CSS, JS, JQUERY, AJAX - Aptana, Kompozer, Intel XDK\nText Editors - Sublime Text, Komodo Edit, Atom\nI think my answer is helpful for you.\nThank you\n", "Q: I can't get my Wacom Intuos to work in Ubuntu at all I just bought a new Wacom Intuos, and I can't get anything to work. The tablet itself turns on, and detects pressure, but the cursor won't even move even though lsusb detects it. I have an older model that works fine. I'm on Ubuntu 14.4.\nI've tried downloading Xf86-input-wacom from here and I get this error when I try to ./configure: \nPackage xorg-macros was not found in the pkg-config search path.\nPerhaps you should add the directory containing `xorg-macros.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'xorg-macros' found\nchecking whether make supports nested variables... (cached) yes\nchecking for doxygen... no\nconfigure: WARNING: doxygen not found - documentation targets will be skipped\nchecking for rint in -lm... yes\nchecking for XORG... no\nconfigure: error: Package requirements (xorg-server >= 1.7.0 xproto xext kbproto inputproto randrproto) were not met:\n\nNo package 'xorg-server' found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables XORG_CFLAGS\nand XORG_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\n\nA: The XF86 Driver shouldn't need updating, though the input-wacom driver might. \nWhich tablet (lsusb output) and which ubuntu are you using? \n", "Q: kworker using all my IOs, Postgres slow I have 2 SSDs set up in RAID 0 configuration with a single volume on them that I've been using without problems for 3 months straight to run a PostgreSQL database. Suddenly, today, the DB got really slow. I used to run multiple queries on huge tables and see 100% CPU usage for each postgres task (I have 12 cores). Now, one query by itself uses 15%-30% CPU, as if there's a disk bottleneck, and the same queries with the same data are taking much longer to run.\nI don't know if this was happening before, but if I run iotop, I see kworker/u24:1 using 99.99% IO and 0 disk read and write. I don't know if that's normal, but it looks suspicious.\nI ran benchmarks with dd and hdparm. The SSD read/write time looks fast enough; no problem there. RAM usage is fine. I see almost no swap used. I have very little free because all the free memory goes to disk caching, but that's supposed to be OK. I don't actually have any processes using up all my RAM.\nWhat's the deal with kworker? I know it's a kernel task. Is it a problem that it's using so many IOs? Anything I should check?\nUpdate: It stopped doing it. Not sure when or why.\n\nA: kworker using 100% IO doesn't mean it's using all my IOs. It means it's waiting on IO. I think the Postgres issue was separate. Never figured that one out, but it hasn't come back.\nSee: https://serverfault.com/questions/659164/kworker-consuming-90-io-and-zero-disk-write/785415#785415\n", "Q: Alias not working on Apache2.4 I have upgraded from an earlier Apache2 to the latest Apache 2.4.  My previous setup had the following alias in default.conf file in the sites-available directory:\nAlias /weewx /home/weewx/public_html\n<Directory \"/home/weewx/public_html\">\n    Options Indexes FollowSymLinks MultiViews\n    AllowOverride None\n    Order allow,deny\n    Allow from all\n</Directory>\n\nIn the new Apache 2.4 setup I have added the following to 000-default.conf in sites-available:\nAlias /weewx /home/weewx/public_html\n\n<Directory /home/weewx/public_html>\n    Options Indexes FollowSymLinks MultiViews\n    AllowOverride All\n</Directory>\n\nBut now I get a 403 error - \"you don't have permission to access /weewx on this server\".  I have tried moving my new Alias and Directory entry into the alias.conf file in the mods-available directory, but that still give the 404 error. \nIs there something wrong with my Directory entry, or are the Alias and Directory in the wrong place?\n\nA: You need to add\nRequire all granted\n\nto your new Directory container to grant access to this directory. That replaces the old\nOrder allow,deny\nAllow from all\n\nSee the Apache documentation for more about this.\n\nA: All alias's in apache 2.4 have to be configured in the /etc/apache2/mods-enabled/alias.conf file they are ignored in the virtual host files.\n", "Q: Keep Ubuntu from auto starting applications at boot Is there a best way to  keep this from happening, maybe from the command line. I am running the KDE descktop. \n\nA: It depends on the app that you started. Sometimes an app has its own setting that says \"Start every boot\". It would help to know which app it is, as every app works differently with the system.\n", "Q: Help! I can't install anything because of subprocess error [SOLVED] I don't know what happened but suddenly with no reason no apps and packages could get installed. When i want to install a package with sudo apt-get install <package> I get this error:\nmpiuser@host:~$ sudo apt-get install synaptic\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following extra packages will be installed:\n  docbook-xml libcairo-perl libept1.4.12 libglib-perl libgtk2-perl\n  libpango-perl librarian0 rarian-compat sgml-data\nSuggested packages:\n  docbook docbook-dsssl docbook-xsl docbook-defguide libfont-freetype-perl\n  libgtk2-perl-doc perlsgml w3-recs opensp libxml2-utils dwww menu deborphan tasksel\nThe following NEW packages will be installed:\n  docbook-xml libcairo-perl libept1.4.12 libglib-perl libgtk2-perl\n  libpango-perl librarian0 rarian-compat sgml-data synaptic\n0 upgraded, 10 newly installed, 0 to remove and 0 not upgraded.\n1 not fully installed or removed.\nNeed to get 0 B/3,441 kB of archives.\nAfter this operation, 17.4 MB of additional disk space will be used.\nDo you want to continue? [Y/n] y\nSetting up install-info (5.2.0.dfsg.1-2) ...\n/etc/environment: line 2: /home/mpiuser/mpich1/bin: Is a directory\ndpkg: error processing package install-info (--configure):\nsubprocess installed post-installation script returned error exit status 126\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nThis is also correct when i want to install an app from Ubuntu software center.\nThe error message is like this:  \n \nWhat Should I do? I don't want to re-install my ubuntu.\n\nA: this code solved my problem  \nsudo mv /var/lib/dpkg/info/install-info.postinst /var/lib/dpkg/info/install-info.postinst.bad\n\n", "Q: Instaling Zerodha Trader or zerodha PI i have installed wine later tried instaling Zerdha trader (Nest) is opening but showing error, Pi is not at all opening.\n\nA: To install Zerodha Pi you need,\n\n\n*\n\n*Microsoft .NET Framework 4(x86 and x64)\n\n*Microsoft Visual C++ 2008 Runtime Libraries(x86)\n\n*Microsoft Visual C++ 2010 Runtime Libraries(x86) \n\n\n\nStep 1 :\nFirst of all Install wine and winetricks. \nwine : using ppa for latest version.\nsudo apt-add-repository ppa:ubuntu-wine/ppa\nsudo apt-get update\nsudo apt-get install wine1.7\n\nwinetricks :\nsudo apt-get install winetricks\n\n\nStep 2 :\nMost of the Windows apps work on 32 Bit. So you have to create a 32 Bit wineprefix by following commands,\nrm -fr ~/.wine  \nexport WINEARCH=\"win32\"\nexport WINEPREFIX=~/.wine/\n\nNow you can install Microsoft .NET Framework 4.0 using winetricks as,\nwinetricks dotnet40\n\n\nStep 3:\nI suppose you have already downloaded Zerodha Pi from  Zerodha q-back office with the activation key. Extract pi.zip in the Downloads directory and you will get a directory pi. There you can find Pi_setup.exe. Run the following command to install it,\nwine ~/Downloads/pi/Pi_setup.exe\n\nBefore installing Pi you can see the system would install Microsoft Visual C++ 2008 and Microsoft Visual C++ 2010.\nAt last step Pi will be installed and a desktop icon will be created.  Just Log in with your credentials, answer those two security questions. Then Pi will ask for the activation key. Just put it to activate. Happy Trading.\n\nFor more information please look at,\n\n\n*\n\n*Running .Net 4.0 application with Wine\n\n*How to install and configure Wine?\n", "Q: Help to run CoherentPDF executable Please help me to run the executable file from the archive which I found at: http://community.coherentpdf.com/ under \"Download binaries now for Windows, Mac, or Linux/Download pre-built tools now\". When you unzip the archive, there are several folders, my file is at Linux-Intel-64bit, called cpdf. I tried many different options to run this file, changed it's properties to executable. But it won't go.\n\nA: I assume you have Ubuntu 64bit installed!\nGo to the folder: \ncd cpdf-binaries-master/Linux-Intel-64bit\n\nNow launch the command:\n./cpdf --help\n\nIf you want the command to be available everywhere on the system:\nsudo cp cpdf /usr/local/bin/\n\nor what I do\ncp cpdf ~/bin/\n\n", "Q: Encrypting of /etc/shadow file When I add a user by -useradd command, if I go to /etc/shadow the password isn't encrypted, and therefore I cannot login to that user. How can I encrypt that password in shadow file?\n\nA: That is working as intended. If you want to set a password using the useradd command, you are supposed to give a hashed version of the password to useradd.\nSo if you provide your plain text password when the system validates that user's login it will fail since the stored password would not be the hashes version of the password you would expect it to have.\nIf you take a look the the useradd documentation:\n-p, --password PASSWORD The encrypted password, as returned by crypt(3). The\n    default is to disable the password. Note: This option is not recommended \n    because the password (or encrypted password) will be visible by users \n    listing the processes. You should make sure the password respects the\n    system's password policy.\n\nHowever you can solve that issue by running passwd yourusernameand typing the proper plaintext password what will result on the hashed password appearing on /etc/shadows hashes as it should always be.\n", "Q: Windows vs Linux/Ubuntu when it comes to Videos I had made a sort of interview with Non-programmer using Linux. Recently, the article was posted somewhere in FB and several people contacted me; most of the approach: \"Open Software FTW!\", which is cool.\nHowever, there was a football fan that wants to live his life with Ubuntu, but also with watching football highlights. I am now helping him to see some CL Highlights (maybe that's illegal, but he says he has done it several times, so if we don't help, we will just have one more user for Windows, one less for Ubuntu, no help won't stop him/them:/).\nI thought about flash player and I prompted him to How to install flash payer in Ubuntu 14.04 LTS?, since he has 14.04 64 bits installed. However, even though flash got installed successfully, he still can't play the video. Any ideas for what could be the issue?\n\nA: Adobe removed support for Linux version of flash long time ago, the newest version for Linux that you can have is 11.22.577 , while Windows is already on 21. So it could be that the site your friend visits requires newer version.\nIt is suggested to try alternatives to Adobe flash. Pepper flash that comes with google chrome should be supported and up to date. Note however that Google Chrome has only 64 bit version for Linux and 32 bit support has been removed as of recently.  HTML 5 is another alternative one could consider.\n", "Q: How to make Hyper tread on in Ubuntu 15 linux What is terminal command to  make 'on' a hyperthread in Ubuntu?\n\nA: If you want to run N concurrent jobs, where N is a number > 0, use:\nmake -j N\n\nFor example, for 4 concurrent jobs, use:\nmake -j 4\n\nIf you want to build so you have the same number of jobs as CPUs, use:\nmake -j $(nprocs)\n\nYou can also specify an \"infinite\" number (that is, maximized parallel jobs, which is not advised since it will spawn way too many concurrent jobs to be useful) using:\nmake -j \n\n", "Q: \"uninstall\" Ubuntu, delete partitions and install FreeDos I was testdriving a laptop with Ubuntu for a few days. Now I have to restore it's initial state. Essentially it had one partition for the UEFI and one that was running FreeDos. The UEFI is still there, but I deleted the FreeDos eventually and installed Ubuntu (+ swap partition and so on). What can I do to delete all traces of Ubuntu, it's partitions and have the computer back in it's initial state? \nBTW: I enjoyed the Ubuntu experience, it's just that I have to give back the computer in it's initial state. \n\nA: First you will need to use a tool like gparted to delete all linux partitions and replace them with a FAT16 partition since the FreeDOS installer, unlike the ubuntu installer, does not give you the option to modify partitions.\nFrom http://freedos.sourceforge.net/wiki/index.php/Install:\n\nInstalling on a physical PC\nBoot from an existing DOS, from one of the cdroms, or from the special\n  boot diskette. In the latter two cases, simply follow the menus to\n  install DOS. In the former case, you will first have to make sure that\n  the cdrom can be accessed. You can also use the ISO images directly\n  instead of using a real cdrom. See above for details.\nIf your computer has no partitions with FAT filesystem yet, you will\n  have to create one before you can install DOS. For example GPARTED\n  which is included with many Linux distros and many Linux versions\n  which can be run directly from CD or DVD (no installation of Linux on\n  harddisk needed) can resize your existing NTFS Windows partitions to\n  make space for DOS without having to reinstall Windows. FreeDOS will\n  need one FAT type partition: This can be FAT12, FAT16 or FAT32, but\n  FAT16 is clearly the recommended choice: FAT12 is too small and FAT32\n  is hard to boot from. You can use Windows or Linux to create and/or\n  format the partition, if needed. Of course you can also use the\n  FreeDOS install cdrom for that, but as this cdrom does not allow you\n  to resize existing partitions, you should better use other tools. If\n  you already do have a FAT partition, you can skip all the partition /\n  format steps.\n\nIf you still have the usb drive or disc you used to install ubuntu just pop that in, start a live session from the install medium (select try ubuntu) and open gparted from there or you can create a stand-alone gparted boot medium following the instructions found here: http://gparted.org/liveusb.php#linux-setup.\nThe next step should be pretty self explanatory from within the program:\n\n\n*\n\n*Delete all unwanted partitions (in your case that would be all partitions of type ext4 and swap)\n\n*You'll see a grayed out area of 'unallocated' space grow as you delete partitions\n\n*Select the unallocated space and create a new FAT16 partition on it\n\n*Apply the scheduled operations (green checkmark icon)\n\n\nNow you should be all set up to reinstall FreeDOS from an install medium of your choice.\n", "Q: How to boot to a terminal from a black screen and flashing cursor after updating the NVIDA graphics driver I'm running Ubuntu 14.04 LTS and updated my graphics card to Nvidia Quadro K4200 in order to get stereo capability. It worked with the recommended Ubuntu driver (nvidia-352), although I struggled to get stereo working, so I installed the latest Nvidia driver (361.42).  To do this, I got a terminal with \n\nAlt-Ctrl-F1\n\nstopped X with \n\nsudo service lightdm stop\n\nand then ran the install script from NVIDIA.  When I restarted X with \n\nsudo service lightdm start\n\nI got a black screen with a blinking cursor in the top left of the screen and Alt-Ctrl-F[1-6] did not give a terminal login.  My only option is a hard shutdown (holding down the start button) and when I reboot it returns to the black screen.\nI saw this post which looks the closest to my problem that I found, with a solution that requires Alt-Ctrl-F1 which isn't giving me a terminal login option. Any suggestions are very much appreciated.\n\nA: Two thoughts:  For low level logins, like you're doing, frequently the ENTER key must be pressed to get a login prompt.\nJust because the graphics are crazy, doesn't mean that the daemons like sshd didn't come up properly.\n\nA: I had a very similar problem with NVIDIA install script. I've booted into recovery mode (hold SHIFT before loading GRUB for a menu) and there was an option to open a root terminal.\nTry those commands, reboot and see if it will fix your case:\n\ndpkg-reconfigure xserver-xorg\nupdate-initramfs -u\n\nYou might need to remount with write priviledges to make those changes:\n\nmount -o remount,rw /\n\nWith terminal you can of course remove NVIDIA and re-install nouveau-firmware, just run that update-initramfs -u afterwards. I think I fixed it just like that, but it was some time ago and my memory is foggy...\n\nA: I noticed on desperate rebooting I intermittently got a login prompt, sometimes giving my a couple of minutes of access before returning to the black screen and flashing cursor.  I found in /var/log/kern.log the following error:\n\nNVRM: API mismatch: the client has the version 361.42, but\nNVRM: this kernel module has the version 352.63.  Please\nNVRM: make sure that this kernel module and all NVIDIA driver\nNVRM: components have the same version\nNVRM: nvidia_frontend_ioctl: minor 255, module->ioctl fauled, error\n  -22\n\nI ran \ndpkg --get-selections | grep nvidia\n\nfor a list of nvidia packages that might be causing the conflict and removed and purged all of them individually\napt-get remove *package*\n\napt-get purge *package*\n\nI also re-ran the NVIDIA driver install script to generate a customised kernel setup for good measure and re-ran the install.\nThis got me to the login screen on reboot, although logging in kept returning me to the login screen, but I could at least ctrl-alt-F1 for a terminal and there was plenty of help on this issue already on Ask.\n\nA: Have you checked /var/log/Xorg.0.log for errors?\nOr when you stop X, try startx rather than restarting the service.\n", "Q: Adding VPN exception (allow protocol) to UFW firewall rules? I'm having trouble at work in connecting to the work VPN while Firewall (UFW) is active. When i disable it \"sudo ufw disable\", there are no problems.\nWhen it's on, when trying to connect I receive the following\nApr 14 09:57:59 gaj-Lenovo-Z51-70 kernel: [ 2105.983679] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=89 TOS=0x00 PREC=0x00 TTL=121 ID=13425 PROTO=47 \nApr 14 09:57:59 gaj-Lenovo-Z51-70 kernel: [ 2105.996395] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=60 TOS=0x00 PREC=0x00 TTL=121 ID=13426 PROTO=47 \nApr 14 09:58:02 gaj-Lenovo-Z51-70 kernel: [ 2109.042945] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=60 TOS=0x00 PREC=0x00 TTL=121 ID=13427 PROTO=47 \nApr 14 09:58:03 gaj-Lenovo-Z51-70 kernel: [ 2110.040506] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=89 TOS=0x00 PREC=0x00 TTL=121 ID=13428 PROTO=47 \nApr 14 09:58:05 gaj-Lenovo-Z51-70 kernel: [ 2112.061598] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=60 TOS=0x00 PREC=0x00 TTL=121 ID=13429 PROTO=47 \nApr 14 09:58:07 gaj-Lenovo-Z51-70 kernel: [ 2113.994401] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=89 TOS=0x00 PREC=0x00 TTL=121 ID=13430 PROTO=47 \nApr 14 09:58:08 gaj-Lenovo-Z51-70 kernel: [ 2115.012322] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=60 TOS=0x00 PREC=0x00 TTL=121 ID=13431 PROTO=47 \nApr 14 09:58:11 gaj-Lenovo-Z51-70 kernel: [ 2117.994069] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=89 TOS=0x00 PREC=0x00 TTL=121 ID=13432 PROTO=47 \nApr 14 09:58:11 gaj-Lenovo-Z51-70 kernel: [ 2118.017850] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=60 TOS=0x00 PREC=0x00 TTL=121 ID=13433 PROTO=47 \nApr 14 09:58:15 gaj-Lenovo-Z51-70 kernel: [ 2122.002641] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=161.53.97.58 DST=10.111.100.55 LEN=89 TOS=0x00 PREC=0x00 TTL=121 ID=13435 PROTO=47 \nApr 14 09:58:17 gaj-Lenovo-Z51-70 pppd[11718]: LCP: timeout sending Config-Requests\nApr 14 09:58:17 gaj-Lenovo-Z51-70 pppd[11718]: Connection terminated.\nApr 14 09:58:17 gaj-Lenovo-Z51-70 NetworkManager[1620]: <warn> VPN plugin failed: 1\nApr 14 09:58:17 gaj-Lenovo-Z51-70 NetworkManager[1620]:    SCPlugin-Ifupdown: devices removed (path: /sys/devices/virtual/net/ppp0, iface: ppp0)\nApr 14 09:58:17 gaj-Lenovo-Z51-70 pppd[11718]: Modem hangup\nApr 14 09:58:17 gaj-Lenovo-Z51-70 pptp[11722]: nm-pptp-service-11714 warn[decaps_hdlc:pptp_gre.c:204]: short read (-1): Input/output error\nApr 14 09:58:17 gaj-Lenovo-Z51-70 pptp[11722]: nm-pptp-service-11714 warn[decaps_hdlc:pptp_gre.c:216]: pppd may have shutdown, see pppd log\nApr 14 09:58:17 gaj-Lenovo-Z51-70 pptp[11731]: nm-pptp-service-11714 log[callmgr_main:pptp_callmgr.c:234]: Closing connection (unhandled)\nApr 14 09:58:17 gaj-Lenovo-Z51-70 pptp[11731]: nm-pptp-service-11714 log[ctrlp_rep:pptp_ctrl.c:251]: Sent control packet type is 12 'Call-Clear-Request'\nApr 14 09:58:17 gaj-Lenovo-Z51-70 pptp[11731]: nm-pptp-service-11714 log[call_callback:pptp_callmgr.c:79]: Closing connection (call state)\nApr 14 09:58:17 gaj-Lenovo-Z51-70 pppd[11718]: Exit.\nApr 14 09:58:17 gaj-Lenovo-Z51-70 NetworkManager[1620]: <warn> VPN plugin failed: 1\nApr 14 09:58:17 gaj-Lenovo-Z51-70 NetworkManager[1620]: <warn> VPN plugin failed: 1\nApr 14 09:58:17 gaj-Lenovo-Z51-70 NetworkManager[1620]: <info> VPN plugin state changed: stopped (6)\nApr 14 09:58:17 gaj-Lenovo-Z51-70 NetworkManager[1620]: <info> VPN plugin state change reason: 0\nApr 14 09:58:17 gaj-Lenovo-Z51-70 NetworkManager[1620]: <info> Policy set 'eduroam' (wlan0) as default for IPv4 routing and DNS.\nApr 14 09:58:17 gaj-Lenovo-Z51-70 NetworkManager[1620]: <warn> error disconnecting VPN: Could not process the request because no VPN connection was active.\nApr 14 09:58:22 gaj-Lenovo-Z51-70 NetworkManager[1620]: <info> VPN service 'pptp' disappeared\nApr 14 09:58:24 gaj-Lenovo-Z51-70 kernel: [ 2130.359917] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=198.252.206.25 DST=10.111.100.55 LEN=110 TOS=0x00 PREC=0x00 TTL=48 ID=12127 DF PROTO=TCP SPT=443 DPT=38605 WINDOW=37 RES=0x00 ACK PSH URGP=0 \nApr 14 09:58:24 gaj-Lenovo-Z51-70 kernel: [ 2130.792401] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=198.252.206.25 DST=10.111.100.55 LEN=110 TOS=0x00 PREC=0x00 TTL=48 ID=12128 DF PROTO=TCP SPT=443 DPT=38605 WINDOW=37 RES=0x00 ACK PSH URGP=0 \nApr 14 09:58:24 gaj-Lenovo-Z51-70 kernel: [ 2131.268906] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=198.252.206.25 DST=10.111.100.55 LEN=110 TOS=0x00 PREC=0x00 TTL=48 ID=12129 DF PROTO=TCP SPT=443 DPT=38605 WINDOW=37 RES=0x00 ACK PSH URGP=0 \nApr 14 09:58:25 gaj-Lenovo-Z51-70 kernel: [ 2132.221763] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=198.252.206.25 DST=10.111.100.55 LEN=110 TOS=0x00 PREC=0x00 TTL=48 ID=12130 DF PROTO=TCP SPT=443 DPT=38605 WINDOW=37 RES=0x00 ACK PSH URGP=0 \nApr 14 09:58:27 gaj-Lenovo-Z51-70 kernel: [ 2134.125750] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=198.252.206.25 DST=10.111.100.55 LEN=110 TOS=0x00 PREC=0x00 TTL=48 ID=12131 DF PROTO=TCP SPT=443 DPT=38605 WINDOW=37 RES=0x00 ACK PSH URGP=0 \nApr 14 09:58:31 gaj-Lenovo-Z51-70 kernel: [ 2137.937259] [UFW BLOCK] IN=wlan0 OUT= MAC=b4:6d:83:e4:ce:8d:00:22:19:6b:e0:22:08:00 SRC=198.252.206.25 DST=10.111.100.55 LEN=110 TOS=0x00 PREC=0x00 TTL=48 ID=12132 DF PROTO=TCP SPT=443 DPT=38605 WINDOW=37 RES=0x00 ACK PSH URGP=0\n\nHow can I add an exception?\nThanks a million.\n\nA: PPTP vpn user port 47 aka GRE. To allow this traffic edit /etc/ufw/before.rules and add at the end of file\nsudo nano /etc/ufw/before.rules\n\nthis\n# gre\n-A ufw-before-input -p 47 -j ACCEPT\n-A ufw-before-output -p 47 -j ACCEPT\n\nThen disable, enable ufw\nsudo ufw disable\nsudo ufw enable\n\nEDIT 1\nRules must placed in /etc/ufw/before.rules before segment # drop INVALID packets ...\nthen again\nsudo ufw disable\nsudo ufw enable\n\n\nA: I have the same problem as Mookey but I can confirm that the solution by 2707974 is working for me!\nLet's see this step by step.\nIf have Gufw set to incomming:deny and outgoing:allow with logging on.\nThen if I switch VPN on, the first contact to my VPN provider is allowed normally without any rules. When the VPN provider is calling back his call is blocked.\n\n[UFW BLOCK] IN=wlan0 OUT=\n  MAC=49:........:10 SRC=yyy.yyy.yyy.yyy\n  DST=xxx.xxx.xxx.xxx LEN=55 TOS=0x00 PREC=0x00 TTL=49 ID=33716 PROTO=47\n\nx = me, y = my vpn provider.\nIt is blocked by a combination of reasons, incoming ip and protocol 47.\nNow, when turn Gufw off again and start the vpn.\nnetstat -nautp sees:\n\ntcp 0  0 xxx.xxx.xxx.xxx:50798    yyy.yyy.yyy.yyy:1723 ESTABLISHED - \n\nEDIT 1 of 2707974 is correct but and must be inserted at exact that place.\nThis would take care of the protocol 47 being allowed.\nAfter that you can add a rule to allow the incoming connection of your vpn proveder. You can use: sudo ufw allow yyy.yyy.yyy.yyy and it is working.\nYou can even include ports (when you are sure they are not picked random)  \nsudo insert 1 allow from yyy.yyy.yyy.yyy port 1723 to xxx.xxx.xxx.xxx port 50798\nThat works too.\nYou might think that you are settled now, but there one security concern.\nThe protocol 47 rule is processed much earlier than the allow ip rule.\nAs soon as there is an incoming packet of protocol 47 it is allowed. There is no rejecting if the ip address does not fit.\nYou can see happening when you delete the ip rule from ufw.\nsudo ufw delete 1 (do not forget to disable/enable ufw again)\nVPN will still be working.\nI'm very sure you do not want every packet of every host coming into your system only because it is of GRE protocol. More secure is to include the IP of your VPN provider so he is the only one.\nChange EDIT 1 into:\n-A ufw-before-input -p 47 -s <your vpn provider> -j ACCEPT\n-A ufw-before-output -p 47 -s <your vpn provider> -j ACCEPT\n\nThis is working and is secure. You can verify this your self by changing the ip above to an incorrect ip and vpn stops working.\nThe Gufw rule is not needed anymore although this was what my intension was. I would appreciate a working Gufw rule much more.\nHope it helped you.\nCheers!\n\nA: Check your Iptables, maybe there are some rules that aswell block your VPN connection.\niptables -L\n\nACCEPT VPN connections for INPUT aswell to OUTPUT at Iptables.\niptables -A INPUT -p tcp --dport 47 -j ACCEPT\niptables -A OUTPUT -p tcp --dport 47 -j ACCEPT\n\nIf VPN connection works, then save rules \niptables-save\n\n", "Q: Which old kernel related files can I safely delete? I frequently run into the issue described in Not enough free disk space when upgrading, because the boot partition created by the Ubuntu installation is too small. When cleaning up as described in the accepted answer, I found a bunch of things that look like they belong to older kernels.\n$ uname -r\n3.19.0-51-generic\n\n$ ll /boot\ntotal 96958\ndrwxr-xr-x  4 root root     3072 Apr 14 09:54 ./\ndrwxr-xr-x 23 root root     4096 Mar  2 10:08 ../\n-rw-r--r--  1 root root  1271904 Jan 22 04:40 abi-3.19.0-49-generic\n-rw-r--r--  1 root root  1271993 Feb 27 00:51 abi-3.19.0-51-generic\n-rw-r--r--  1 root root   177800 Jan 22 04:40 config-3.19.0-49-generic\n-rw-r--r--  1 root root   177800 Feb 27 00:51 config-3.19.0-51-generic\ndrwxr-xr-x  5 root root     1024 Apr 14 09:54 grub/\n-rw-r--r--  1 root root  9796008 Jan 21 11:09 initrd.img-3.19.0-31-generic\n-rw-r--r--  1 root root 32580082 Feb 17 13:02 initrd.img-3.19.0-49-generic\n-rw-r--r--  1 root root 32580270 Mar  2 10:08 initrd.img-3.19.0-51-generic\ndrwx------  2 root root    12288 Apr 17  2015 lost+found/\n-rw-r--r--  1 root root   164216 Mar  6  2015 memtest86+.bin\n-rw-r--r--  1 root root   165892 Mar  6  2015 memtest86+.elf\n-rw-r--r--  1 root root   166396 Mar  6  2015 memtest86+_multiboot.bin\n-rw-------  1 root root  3624223 Jan 22 04:40 System.map-3.19.0-49-generic\n-rw-------  1 root root  3624551 Feb 27 00:51 System.map-3.19.0-51-generic\n-rw-------  1 root root  6625856 Jan 22 04:40 vmlinuz-3.19.0-49-generic\n-rw-------  1 root root  6627648 Feb 27 00:51 vmlinuz-3.19.0-51-generic\n\n$ dpkg -l | grep 3.19.0\nii  linux-generic                                        3.19.0.51.50                               amd64        Complete Generic Linux kernel and headers\nii  linux-headers-3.19.0-26                              3.19.0-26.28                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-26-generic                      3.19.0-26.28                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-28                              3.19.0-28.30                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-28-generic                      3.19.0-28.30                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-30                              3.19.0-30.34                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-30-generic                      3.19.0-30.34                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-31                              3.19.0-31.36                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-31-generic                      3.19.0-31.36                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-32                              3.19.0-32.37                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-32-generic                      3.19.0-32.37                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-33                              3.19.0-33.38                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-33-generic                      3.19.0-33.38                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-37                              3.19.0-37.42                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-37-generic                      3.19.0-37.42                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-42                              3.19.0-42.48                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-42-generic                      3.19.0-42.48                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-43                              3.19.0-43.49                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-43-generic                      3.19.0-43.49                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-49                              3.19.0-49.55                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-49-generic                      3.19.0-49.55                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-3.19.0-51                              3.19.0-51.58                               all          Header files related to Linux kernel version 3.19.0\nii  linux-headers-3.19.0-51-generic                      3.19.0-51.58                               amd64        Linux kernel headers for version 3.19.0 on 64 bit x86 SMP\nii  linux-headers-generic                                3.19.0.51.50                               amd64        Generic Linux kernel headers\nii  linux-image-3.19.0-49-generic                        3.19.0-49.55                               amd64        Linux kernel image for version 3.19.0 on 64 bit x86 SMP\nii  linux-image-3.19.0-51-generic                        3.19.0-51.58                               amd64        Linux kernel image for version 3.19.0 on 64 bit x86 SMP\nii  linux-image-extra-3.19.0-49-generic                  3.19.0-49.55                               amd64        Linux kernel extra modules for version 3.19.0 on 64 bit x86 SMP\nii  linux-image-extra-3.19.0-51-generic                  3.19.0-51.58                               amd64        Linux kernel extra modules for version 3.19.0 on 64 bit x86 SMP\nii  linux-image-generic                                  3.19.0.51.50                               amd64        Generic Linux kernel image\nii  linux-libc-dev:amd64                                 3.19.0-51.58                               amd64        Linux Kernel Headers for development\n\nIt looks like there are some things left from older versions, like linux-headers-3.19.0-26 in the dpkg output. But there is also /boot/initrd.img-3.19.0-31-generic, which seems to be from a way older one, as mine is 3.19.0.51-generic currently.\nWhich of these things can I remove safely? Should I alsways apt-get purge them, or are there also things I can just rm?\n\nA: You can safely purge all linux-headers packages with the old versions.\nIn your case versions 3.19.0-26 - 3.19.0-43.\nAnd NEVER delete files installed by dpkg or apt manually using rm.\n", "Q: Unable to install build-essential, held broken packages So I was trying to set up my computer for development. I installed ubuntu 14.04 LTS. I wanted to write a hello-world-program. However I can not compile it. After some searching, I tried sudo apt-get install build-essential, which complained:\n>sudo apt-get install build-essential\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n build-essential : Depends: g++ (>= 4:4.4.3) but it is not going to be installed\n                   Depends: dpkg-dev (>= 1.13.5) but it is not going to be installed\nE: Unable to correct problems, you have held broken packages.\n\nI tried changing the source and sudo apt-get update, sudo apt-get upgrade, and the issue remained. I tried sudo apt-get autoclean, sudo apt-get install --fix-broken or something like that, non of which worked. \nAlso, I tried sudo aptitude why-not build-essential, which said: \n>sudo aptitude why-not build-essential\np   gvfs-bin:i386          Provides   gvfs-bin                         \np   gvfs-bin:i386          Suggests   gvfs:i386                        \np   gvfs:i386              Suggests   gvfs-backends:i386               \np   gvfs-backends:i386     Depends    libgphoto2-port10:i386 (>= 2.5.2)\np   libgphoto2-port10:i386 Suggests   gphoto2:i386 (> 2.1.0)           \np   gphoto2:i386           Suggests   gthumb:i386                      \np   gthumb:i386            Recommends flex:i386                        \np   flex:i386              Suggests   build-essential:i386             \np   build-essential:i386   Conflicts  build-essential \n\nSo what is wrong here?\nAlso my sources.list file:\n>cat /etc/apt/sources.list\n# deb cdrom:[Ubuntu 14.04.4 LTS _Trusty Tahr_ - Release amd64 (20160217.1)]/ trusty main restricted\n\n# See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to\n# newer versions of the distribution.\ndeb http://mirrors.163.com/ubuntu/ trusty main restricted\ndeb-src http://mirrors.163.com/ubuntu/ trusty main restricted\n\n## Major bug fix updates produced after the final release of the\n## distribution.\n\n## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu\n## team. Also, please note that software in universe WILL NOT receive any\n## review or updates from the Ubuntu security team.\ndeb http://mirrors.163.com/ubuntu/ trusty universe\ndeb-src http://mirrors.163.com/ubuntu/ trusty universe\n\n## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu \n## team, and may not be under a free licence. Please satisfy yourself as to \n## your rights to use the software. Also, please note that software in \n## multiverse WILL NOT receive any review or updates from the Ubuntu\n## security team.\ndeb http://mirrors.163.com/ubuntu/ trusty multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty multiverse\n\n## N.B. software from this repository may not have been tested as\n## extensively as that contained in the main release, although it includes\n## newer versions of some applications which may provide useful features.\n## Also, please note that software in backports WILL NOT receive any review\n## or updates from the Ubuntu security team.\n\n\n## Uncomment the following two lines to add software from Canonical's\n## 'partner' repository.\n## This software is not part of Ubuntu, but is offered by Canonical and the\n## respective vendors as a service to Ubuntu users.\ndeb http://archive.canonical.com/ubuntu trusty partner\n# deb-src http://archive.canonical.com/ubuntu trusty partner\n\n## This software is not part of Ubuntu, but is offered by third-party\n## developers who want to ship their latest software.\ndeb http://extras.ubuntu.com/ubuntu trusty main\ndeb-src http://extras.ubuntu.com/ubuntu trusty main\n\nmy sources.list.d directory: \n>ls -la /etc/apt/sources.list.d\ntotal 8\ndrwxr-xr-x 2 root root 4096  4月 10  2014 .\ndrwxr-xr-x 6 root root 4096  4月 14 14:16 ..\n\nBy the way, could anyone give a brief explanation about what is a broken package and why it appears so easily? Or what is the possible reason/why this is happening? Shouldn't apt-get be able to fix such issues or at least give some helpful information here? I've met this error so many times recently and couldn't find any solution. \nThanks a lot.  \n\nA: After struggling for a while, I found the solution to this problem. \nFirst sudo apt-get install aptitude, which works fine. Then try sudo aptitude install build-essential, which first says that there is something wrong and proposes a solution. The first solution it proposes keeps nothing change, which is not what we want, so choose no. And it proposes the second solution, which would work. \nBy the way, I am still confused as why would I \"held broken packages\" on a newly installed ubuntu system? What does it mean to \"held broken packages\"?\n\nA: For some reason, you have build-essential:i386 (the 32 bits version) installed, and your system, like you said, it's 64 bits (i.e., amd64).\nFirst, remove build-essential:i386:\nsudo apt-get remove build-essential:i386\n\nThen install the 64 version:\nsudo apt-get install build-essential\n\n", "Q: How can I rename the current Xfce workspace from the command line? Currently I can change the workspace name by using the dialog. I am wondering where are these settings stored, if I can change them at runtime from the command line.\n\n\nA: This program should do it, but it opens a window where you rename the workspace.\n", "Q: Ubuntu 15.10 Wifi device is not ready after updating kernel to 4.2.0-35 I have Ubuntu 15.10. When I first installed it I've had some problems with wi-fi, and had to manually download and copy the firmware drivers, and that solved the problem. Yesterday there was some update. I've shutdown system yesterday after updating, and when I turned it on today there is no wifi. It just shows \"device not ready\".\nSome additional info:\niwconfig\nwlp7s0    IEEE 802.11abgn  ESSID:off/any  \n      Mode:Managed  Access Point: Not-Associated   Tx-Power=0 dBm   \n      Retry short limit:7   RTS thr:off   Fragment thr:off\n      Power Management:off\n\nlo        no wireless extensions.\n\nenp8s0    no wireless extensions.\n\nifconfig\nenp8s0    Link encap:Ethernet  HWaddr 2c:60:0c:f4:7d:a7  \n          inet addr:192.168.1.33  Bcast:192.168.1.255  Mask:255.255.255.0\n          inet6 addr: fe80::2e60:cff:fef4:7da7/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:7187 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:6193 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:4152929 (4.1 MB)  TX bytes:787121 (787.1 KB)\n\n lo        Link encap:Local Loopback  \n           inet addr:127.0.0.1  Mask:255.0.0.0\n           inet6 addr: ::1/128 Scope:Host\n           UP LOOPBACK RUNNING  MTU:65536  Metric:1\n           RX packets:1567 errors:0 dropped:0 overruns:0 frame:0\n           TX packets:1567 errors:0 dropped:0 overruns:0 carrier:0\n           collisions:0 txqueuelen:0 \n           RX bytes:163215 (163.2 KB)  TX bytes:163215 (163.2 KB)\n\nrfkill list\n0: hci0: Bluetooth\n    Soft blocked: no\n    Hard blocked: no\n1: acer-wireless: Wireless LAN\n    Soft blocked: no\n    Hard blocked: no\n2: acer-bluetooth: Bluetooth\n    Soft blocked: no\n    Hard blocked: no\n3: phy0: Wireless LAN\n   Soft blocked: no\n   Hard blocked: no\n\nIf I remember correctly, phy0 Wireless was soft blocked, but I did rfkill unblock all.\nlspci -knn | grep Net -A2\n07:00.0 Network controller [0280]: Qualcomm Atheros QCA6174 802.11ac Wireless Network Adapter [168c:003e] (rev 32)\nSubsystem: Lite-On Communications Inc Device [11ad:0807]\nKernel driver in use: ath10k_pci\n\nI've tried\nsudo ifconfig wlp7s0 up \n\nresponds with SIOCSIFFLAGS: Resource temporarily unavailable\nI've tried many things that I've found on google, and none of them helped. Any idea how to revert things to how they were yesterday?\n\nA: Ok, I've found a solution. I've checked the updates (using software center), and there was a kernel update.\nI've restarted the system and used old kernel (version from yesterday), and everything works perfect now. It seems that this wifi card is having some problems with some versions of linux.\n", "Q: Is there a \"variable\" to see if computer is in sleep mode? Is there some variable in Ubuntu (14.04) that could be read in bash script to know in which mode the computer is (active/sleep/suspend)? If yes, is it possible to see also for how long is it current mode.  \nI would like to make a script that would run when the computer enters in sleep mode.\nSame question for variable that would tell in which state the monitor is.\n\nA: There exists /etc/pm/sleep.d folder which is frequently used for running scripts upon suspend/resume.  \nThe typical form is this:\n#!/bin/bash\n\ncase \"$1\" in\n    suspend)\n        # executed on suspend\n        ;;\n    resume) \n        # executed on resume\n        ;;\n    *)\n        ;;\nesac\n\nI would suggest you  set for suspend option writing the time of suspend to a file (the date command , easiest probably will be date +%s to get the Unix epoch time ) and the same idea for resume, except you will be reading form file into a variable and calculating difference with current time.\nSomething like this:\n#!/bin/bash\n\ncase \"$1\" in\n    suspend)\n        # executed on suspend\n        date +%s > /tmp/suspend_time.txt\n        ;;\n    resume) \n        # executed on resume\n        suspend_time=$(< /tmp/suspend_time.txt)\n        current_time=$(date +%s)\n        difference=$(($current_time-$suspend_time))\n        if [ $difference -gt 60  ]; # greater than 1 minute (60 seconds)\n        then\n             # put some kind of command you want to run here\n        fi\n        ;;\n    *)\n        ;;\nesac\n\nNote this is just a draft, and untested, but it's a probable suggestion one could follow. \n\nA: This is not possible. If your computer is in sleep or suspend mode your program is frozen and can't run any code. If your program is running your computer is active.\n", "Q: Import SSH keys for remote server I have an Ubuntu 15.10 X64 and I am working on a project for which I am trying out GIT. I have created a repo on one of our remote servers, which is a Debian server, and the repo is accessible via SSH from command line as well as from Intellij. \nIf you need any info, please let me know\n\nI am trying to access it via a GIT-UI tool called GitGraken. It is looking for ssh keys for our remote server. How can I get those keys and add it for my user on the system so I can keep an eye on the repository. Any help would be nice.\n\nA: You can create a ssh keypair in the terminal with the command: \nssh-keygen. Then you have to add the public key(.pub).\nsee man ssh-keygen for more options \n\nA: Use ssh-copy-id\nIf your local machine has the ssh-copy-id script installed, you can use it to install your public key to any user that you have login credentials for.\nRun the ssh-copy-id script by specifying the user and IP address of the server that you want to install the key on, like this:\nssh-copy-id demo@SERVER_IP_ADDRESS\n\n\nA: Finally, this link from debian helped. I created a key first with following command on my local machine :\nssh-keygen -t rsa\n\nThen I copied contents of the public key(/home/username/.ssh/id_rsa.pub) into authorized keys on the server. \nAfter that I was able to login without password and solve the problem. \n", "Q: How do I block Internet for an app using an apparmor custom profile? I'm trying to block internet access for an app because it always asks for purchase or update even though it's free. I created an apparmor profile for that app and enforced it but after enforcing, the app is not starting.\nThis is the profile in /etc/apparmor.d/opt.sublime_text.sublime_text:\n/opt/sublime_text/sublime_text {\n\n        deny network inet,\n        deny network inet6,\n        deny network raw,  #include <abstractions/base>\n\n        /opt/sublime_text/sublime_text mr,\n        /opt/sublime-text/ rw,\n        /home/shady/.config/sublime-text-3/ rw,\n}\n\nI included the directories that this app may need. What am I doing wrong?\n\nA: You need much more to launch this type of app. When there is something missing in your profile it has no access to it. Sublimetext must have access to things like :  \n\n  \n*\n  \n*X server\n  \n*system fonts\n  \n*Xauthority file\n  \n*dconf\n  \n*glib\n  \n*etc ...\n  \n\nThe best and easiest way to create your own profile is to install apparmor-utils\nsudo apt-get install apparmor-utils\n\nthen create your profile using generate profile tool:  \nsudo aa-genprof /opt/sublime_text/sublime_text  \n\nIn this moment it creates sublimetext profile in /etc/apparmor.d/ and is listening for program actions. This profile is in complain mode and it is logging to /var/log/syslog. Now you need to launch your sublimetext and make some actions like opening and saving files, etc.. all this acions will be saved in log file which is used by aa-genproffor creating rules. When you are done with activities hit s key and answer for questions about access or deny to your resources. When done use f key for saving your newly created profile and turning it to enforce mode.    \n\nHowever it is quite easy this tool is not working perfectly. It will not include everything and you must add something manually like access to X\nIn /etc/apparmor.d/opt.sublime_text.sublime_text: \ninclude <abstractions/X>  \n\nIf any changes were made you have to reload config file: \nsudo apparmor_parser r /etc/apparmor.d/opt.sublime_text.sublime_text      \n\n", "Q: Alternatives for XAutoClicker (without X11 Installation) I'm searching for an alternative for xautoclicker. I need an autoclicker that can click really fast, so e.g. Slickbot is no option.\nSince everybody seems to use xautoclicker, i tried that. But it needed the installation of X11, and that crashed my whole system (black screen after system start). GTK+ or QT would run xautoclicker too, but I'm afraid of another black screen...\nSo is there another program I can use?\nMy sytem is Ubuntu 12.04 LTS.\nThanking you in anticipation\n\nA: ok, the following commands helped!\nsudo apt-get install g++\n\nsudo apt-get install libxtst-dev\n\nsudo apt-get install libgtk2.0-dev\n\n\nA: i use MaxAutoClicker, you can find how to download and install it here https://maxautoclicker.blogspot.com/2021/05/mouse-auto-clicker-for-ubuntu-linux.html\ndownload link from here https://sourceforge.net/projects/maxautoclicker\n", "Q: Getting following error while installing `cowsay` I tried to install cowsay using the command:\nsudo apt-get install cowsay\n\nI received the following error message:\nE: Could not get lock /var/lib/dpkg/lock - open (11: Resource temporarily unavailable)\nE: Unable to lock the administration directory (/var/lib/dpkg/), is another process using it?\n\n\nA: If another apt-get instance is running in another terminal, you should close it or let it complete the task before running apt-get in another terminal. If that's not the case, remove the lock file in /var/lib/dpkg/ directory with\nsudo rm /var/lib/dpkg/lock\n\n\nA: It probably means another apt-get process crashed before completion. Just log out and log in again.\n", "Q: How to connect to another Ubuntu machine using the same router but one is connected through LAN and the other is through WLAN? I am connected to a router with a wired LAN running Xubuntu and another machine running Ubuntu is connected to the same router through Wifi Netowrk. So how can I connect to that machine for shared folder access? Both machines can ping the router and can go to the internet through that router but can not ping each other.\n\nA: If the two machines are in the same network (same ip adress range), it does not matter if connected with lan or wlan.\nWhat does you mean with connect? There are different methods to \"connect\". \nOne is VNC There for you have to install a vnc-server on one machine and \na vnc-client on the other. Then you can connect via vnc and remotly connect to the xserver(desktop). \nAnother method is to use SSH(SecureShell). Then you can connect to the terminal of the server machine. \n\nA: \"MultiAP Isolation\" option was enabled in wifi section of my router, thats the reason behind no ping between lan to wlan, I disabled that option and created one normal user on each machine, added the lines for local ip series like \"sshd: 192.168.5.\" & \"vsftpd: 192.168.5.\" in /etc/hosts.allow file as DHCP is enabled in router otherwise for a static ip, I could add the specific ip in hosts.allow rules. And added \"ALL: ALL\" in /etc/hosts.deny file to prevent any other connection other than from the desired ones and used \"Remmina\" through \"sftp protocol\" to login to the other machine and exchanged files, it worked!\n", "Q: fdisk not showing partition, parted does I just noticed when doing a fdisk -l /dev/sdl that my partition is not shown:\nDisk /dev/sdl: 2.7 TiB, 3000592982016 bytes, 5860533168 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\nblkid output shows all my other drives have paritions listed:\n/dev/sda1: UUID=\"ee2faccf-1f90-4f40-baf5-b32f9048c2d3\" TYPE=\"ext2\" PARTUUID=\"a0456ffd-01\"\n/dev/sda5: UUID=\"fzafOi-iMIf-RvNZ-9LQy-tmsy-q4Tm-bdjMoC\" TYPE=\"LVM2_member\" PARTUUID=\"a0456ffd-05\"\n/dev/sdb1: UUID=\"c50ee65b-cfc0-43cf-94df-c1db4c38e032\" TYPE=\"ext4\" PARTLABEL=\"primary\" PARTUUID=\"ca4a8633-0fc8-43fd-96e8-9e69bf3a6931\"\n/dev/sdc1: UUID=\"23943443-a533-4b4f-b5a3-9b4aecb5859f\" TYPE=\"ext4\" PARTLABEL=\"primary\" PARTUUID=\"2b52aba3-17d3-4688-b2d6-4c8e326afd6b\"\n/dev/sdd1: UUID=\"f0d9779a-21c2-49a1-83da-1ae71dbaa8b1\" TYPE=\"ext4\" PARTLABEL=\"primary\" PARTUUID=\"a2ecc2a1-50c4-4dbb-bae4-7b4fa1d6ed91\"\n/dev/sdl: UUID=\"ac3bfba8-049a-4ace-83c6-2749422211f1\" TYPE=\"ext4\"\n\nParted shows there is a partition on the drive:\nGNU Parted 3.2\nUsing /dev/sdl\nWelcome to GNU Parted! Type 'help' to view a list of commands.\n(parted) print\nModel: ATA WDC WD30EFRX-68E (scsi)\nDisk /dev/sdl: 3001GB\nSector size (logical/physical): 512B/4096B\nPartition Table: loop\nDisk Flags:\n\nNumber  Start  End     Size    File system  Flags\n1      0.00B  3001GB  3001GB  ext4\n\npartprobe -s /dev/sdl\n/dev/sdl: loop partitions 1\n\nThe drive mounts fine when using the UUID of the drive (\"ac3bfba8-049a-4ace-83c6-2749422211f1\"). Normally I would be using the UUID of the partition in /etc/fstab\nAny ideas why this has happened and how to rectify it?\n\nA: Your disk is not partitioned; it's being used \"raw.\" You can tell this from the following blkid output from your original post:\n/dev/sdl: UUID=\"ac3bfba8-049a-4ace-83c6-2749422211f1\" TYPE=\"ext4\"\n\nNote the device identifier is /dev/sdl, which includes no partition number. This contrasts with the output for your other disks' partitions, which do include numbers (/dev/sda1, for instance).\nparted calls the partition table type \"loop,\" which is another clue about this.\nIt's perfectly legal to use a disk in this way; however, it can be confusing. If you've not yet stored much data on the disk, you might want to create one or more partitions on it to avoid future confusion. (A script or some other tool might assume that a disk is partitioned, which could cause serious problems.) OTOH, if you've already filled a significant part of that 3TB capacity, backing it up might be too much hassle, and using it as-is might be the best course of action.\n", "Q: Can I replace my desktop environment? I'm considering trying out GNOME and maybe changing to it, but I've heard that installing multiple desktop environments (so you can access them both from the login screen) can make your desktop do weird things.\nWhen 16.04 releases, I would like to change my Kubuntu 15.10 KDE desktop to a GNOME one (or changing to Ubuntu GNOME 16.04?), is that possible? If not, when I upgrade, can I later change my system to Ubuntu GNOME 16.04? Can I do this without wiping my system? I do not want to reinstall everything again.\n\nA: Of course you can. You can install any desktop you want. Maybe, if you install antoher desktop you could have some issues in design for example, maybe the desktop is not exactly like photos. If you want a full integration of Gnome with Ubuntu, try Ubuntu Gnome.\nHow install Gnome:\nsudo apt install ubuntu-gnome-desktop\n\nIf you want to try gdm, choose gdm instead of lightdm as the display manager when prompted. \nReboot.\nNote:  if it turns out that gdm isn't your cup of tea you can go back to lightdm by issuing the command sudo dpkg-reconfigure lightdm and you will once again get to choose.\n\nA: There are several desktop environments are available like KDE Plasma, Cinnamon, MATE, etc. Just install it using terminal. To switch with new environment. Go-to Login screen, select setting-gear and select your newly install environment.\nInstalling two environments might be tedious and also create ton of junk in your device. You can try Ubuntu-Flavours which provides you preinstalled environment of your choice.\n", "Q: Update making any/all emails sound notification I am using BQ Aquaris 4.5. I updated my phone yesterday when prompted. I have a problem now. I use Gmail, I only used to get notifications for emails coming into my \"primary\" tab. Now with the update I get a notification for each & every email.\nI have subscribed to some YouTube channels, forums etc and I am getting loads of emails & notifications in, and they are clogging up my notification space on phone and also I get the sound every five minutes. \nAnyone got an idea how to only get notifications for primary again? \n\nA: It seems after OTA-10, users would get notifications for all the mails landing in inbox. So an obvious workaround to get notifications only for \"primary\" emails is to make others skip inbox. You might want to try this workaround. You'll get almost everything as before except the tabbed inbox feature.\nStep 1:\nOpen Gmail in browser and go to cogwheel > Settings > Labels tab and create a new label\n\nStep 2:\nName the new label Promotions\n\nStep 3:\nNow go to Filters and Blocked Addresses tab and create a new filter\n\nStep 4:\nIn Includes the words field enter category:promotions and then Create filter with this search\n\nStep 5:\nCheck the boxes titled Skip the Inbox (Archive it), Apply the label: and select Promotions and then Create filter\n\nStep6:\nYou will see the label Promotions appearing in the side menu and from now on all your incoming mails in promotions category will skip inbox and land here\n\nStep 7:\nNow repeat the process for other categories, e.g. Social, Updates etc.\n", "Q: How to crop a portion of the screen in the Clipboard? I need often to create Slides from portions of screen. I've found several tools like Shutter which are able to capture an image, however my need is to put the image directly in the Clipboard so that I can paste in in my LibreOffice quickly.\nAny idea ?\nThanks!\n\nA: Press Shift + Prt Scr.\nThen you will be able to select a portion of a screen.\nAfter that you will be able to choose either to copy it to clipboard or save as a file.\n\nA: Use gnome-screenshot (already on your system if you use Unity or Gnome)\nThe easiest is to use good old gnome-screenshot, by default installed. Simply put the command:\ngnome-screenshot -ac\n\nunder a shortcut key. The cursor will change into a cross, and your selection is copied to the clipboard directly.\nAdd it to a shortcut\nChoose: System Settings > \"Keyboard\" > \"Shortcuts\" > \"Custom Shortcuts\". Click the \"+\" and add the command:\ngnome-screenshot -ac\n\nExplanation\nFrom man screenshot:\n   -a, --area\n          Grab  an  area  of  the  screen instead of the entire\n          screen.\n\nand:\n   -c, --clipboard\n          Send the grab directly to the clipboard.\n\n\nA: Install shutter. Once installed, run it; you can snap a selection of screen  directly (1) (and copy and paste immediatly with CTRL-C CTRL-V), or edit it (2) and add markers, labels, highlights and crops: \n\nIt has extensive configuration and can reside in your panel (3). \nIt's in the Universe repository, so it's just a \nsudo apt-get install shutter \n\naway.\n\nA: Ctrl + Shift + Print Screen is working for me.\nWithout any additional installations.\n", "Q: Apache 2.4.7 doesn't load all .css files I run a server with Ubuntu and Apache 2.4.7 and for debugging I run locally XAMPP Version 5.6.19. \nFor the first time I noticed a difference in the page I'm developing. On the XAMPP Apache works everything as desired. On the Ubuntu server there is one issue: the Apache doesn't load one of two .css files. Everything is the SAME(folder structure, files etc..). \nThe .css files are stored in /var/www/html/css/ on the ubuntu server and the /var/www/html/index.html file include both .css files via this two instructions located in the head of the html file:\n    <link rel=\"stylesheet\" href=\"css/style.css\" type=\"text/css\"/>\n    <link rel=\"stylesheet\" href=\"css/modalCustomization.css\" type=\"text/css\"/>\n\nThe file /var/www/html/css/style.css will be loaded correctly.\nThe file /var/www/html/css/modalCustomization.css will not be loaded.\nAny suggestions why the Apache on the ubuntu server is doing/not doing that?\n\nA: I just found a solution from another question. Everything works if I add a ./ before the path in index.html.\n<link rel=\"stylesheet\" href=\"./css/style.css\" type=\"text/css\"/>\n<link rel=\"stylesheet\" href=\"./css/modalCustomization.css\" type=\"text/css\"/>\n\n\nA: You'll need mod_mime, and ensure you have these lines in your httpd.conf:\nAddType text/css .css\nAddType text/javascript .js\n\nThat should do it.source\nEDIT\nMake sure that this line is not commented \nIncludeOptional conf-enabled/*.conf\nand the mine.conf and the load exists and the file \n/etc/mime.types is exist \n\nA: Faced the same problem as yours, noticed that your 1st css uses lowercase and the 2nd propercase.\nWas using \"StyleSheet.css\" but when I renamed as \"styles.css\" it suddenly works!\nRunning XAMPP on Windows 10.\n", "Q: Which driver has to be selected for Nvidia Geforce GT 520 from list? I'm a rookie to the Ubuntu. I'm having Nvidia Geforce GT 520 graphics card. In the additional drivers, it shows a lot of drivers in which some are proprietary and some are not.\n\nSo please help me to choose the correct one for mine? Eager to get the answer.\n\nA: Choose nvidia-352. This is the correct proprietary driver for your adapter.\n", "Q: Cannot set Google Chrome as default browser I few months ago I did a fresh install of Ubuntu 15.10 on my laptop. I had backed up my previous home folder and restored it on top of my installation. I installed Google Chrome and set it as my default browser, but links would always open a new blank Chrome window, so I set Firefox as my default browser. Yesterday I was going to try setting Chrome back as my default, but the option does not show up.\n]\nChrome's settings indicates it is already the default browser.\nI have tried every method under the Internet's Sun to set Google Chrome as my default browser without success, starting with doing an uninstall purge of google-chrome-stable through apt, and then reinstalling from the latest deb.\nSetting the BROWSER environmental variable.\n$ tail ~/.bashrc\nexport PATH=$PATH:/home/david/Android/Sdk/tools\nexport VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3\nexport WORKON_HOME=~/virtualenvs\nexport ANDROID_HOME=/home/david/Android/Sdk\n\nexport BROWSER=`which google-chrome`\n\nSetting x-www-browser.\n$ sudo update-alternatives --config x-www-browser\nThere are 3 choices for the alternative x-www-browser (providing /usr/bin/x-www-browser).\n\n  Selection    Path                           Priority   Status\n------------------------------------------------------------\n  0            /usr/bin/google-chrome-stable   200       auto mode\n  1            /usr/bin/firefox                40        manual mode\n* 2            /usr/bin/google-chrome-stable   200       manual mode\n  3            /usr/bin/xlinks2                69        manual mode\n\nPress <enter> to keep the current choice[*], or type selection number: \n\nSetting gnome-www-browser.\n$ sudo update-alternatives --config gnome-www-browser \nThere are 2 choices for the alternative gnome-www-browser (providing /usr/bin/gnome-www-browser).\n\n  Selection    Path                           Priority   Status\n------------------------------------------------------------\n  0            /usr/bin/google-chrome-stable   200       auto mode\n  1            /usr/bin/firefox                40        manual mode\n* 2            /usr/bin/google-chrome-stable   200       manual mode\n\nPress <enter> to keep the current choice[*], or type selection number: \n\nUpdating xdg-settings\n$ xdg-settings set default-web-browser google-chrome.desktop\n\nHowever, the Details settings window still shows Firefox, and all links from GUI applications open in Firefox.\nEdit:\nI've notice that in the GTK application picker, such as when you right-click a file and choose \"Open With -> Other Application…\" that Chrome is not showing up in the list. The .desktop file is in /usr/share/applications and I tried executing sudo update-desktop-database, but it still doesn't show up. It does show up in the Unity dash.\nIf I look in /usr/share/applications/mimeinfo.cache then I see it is registered for text/html, x-scheme-handler/http, x-scheme-hanlder/https, as well as others.\n\nA: I discovered the source of my problem. The global location for .desktop files is /usr/share/applications/ The user specific location is ~/.local/share/applications. For whatever reason, there was a google-chrome.desktop file in that directory that did not have the MIME meta data setup correctly. Since the local file overrides the global file, Google Chrome wasn't recognized as a web browser. Once I deleted that file I could set Google Chrome as my default web browser and now links open in it correctly.\n\nA: I have this problem sometimes, and for me a good solution is to open Ubuntu Tweak and then go to Admins > File Type Manager. There look for the file type \"HTML document\" and then you can change the Associated Application to Chrome.\n", "Q: Terminal Window Hangs for 4-5 sec. Consistently I'm an Ubuntu 14.04 noob, and this really annoying thing keeps happening.  Every 30 sec. or so the terminal window will hang, but it registers everything I type and will display it after a 4-5 sec. time lag.  It mostly happens in the terminal window, but sometimes this can happen in other text editors that I like to use or when typing in Firefox or Chromium.  I tried opening the system monitor, but it doesn't look like anything is running in the background that could be causing this issue.  Help!!!!  Also, I've tried rebooting -> helps for a little bit, but then the problem resurfaces.\n\nA: Figured this out! A program called Orca was starting itself on startup and using up a cpu at 100%.  Apparently Orca is a screen reader, ugh!!\n", "Q: phpinfo shows old mysql version after mysql upgrade (Ubuntu 14.04) I've upgraded MySql Server from version 5.5 to 5.7 on my Ubuntu 14.04 64bit version and everything is working fine, BUT: phpinfo() shows old mysql version 5.5.47, but \"mysql --version\" is showing version 5.7.12. The next strange attraction is that by checking version in simple php script:\nprintf(\"MySql CLIENT info: %s\\n\", mysql_get_client_info());\nprintf(\"MySql SERVER info: %s\\n\", mysql_get_server_info());\n\nthe output is also:\nMySql CLIENT info: 5.5.47\nMySql SERVER info: 5.7.12\n\nand if I'm trying to install .deb package for mysql client version 5.7 from http://dev.mysql.com/downloads/file/?id=462071, Ubuntu software center just want to reinstall it again.\nsudo apt-get install -f\nsudo apt-get update && apt-get dist-upgrade\n\ndoesn't help.\nAnybody has a clue? Thank you in advance!\n\nA: The phpinfo() function shows the version of the libmysqlclient.so library that's linked to mysql.so PHP extension.  You can check that by switching to php5-mysqlnd package that uses PHP MySQL native driver without linking to libmysqlclient.so.\nYou can confirm this by checking the version of libmysqlclient library on your system: dpkg -l 'libmysqlclient*' or generic version is here: http://packages.ubuntu.com/search?keywords=libmysqlclient\nAs you can see, the version on Ubuntu 14.04 LTS is 5.5.47-0ubuntu0.14.04.1, that matches your MySQL Client version.\n\nA: You need to update the php configuration. For this disable the old php version and active the new by using following commands.\n  sudo a2dismod php5.5\n  sudo a2enmod php5.6\n  sudo service apache2 restart\n\n", "Q:  layout switching works not as expected I have two keyboard layouts, English and Russian. I selected <Shift+Shift> as a layout change shortcut and have used it for years. Earlier, on Elementary Luna, Gnome 3, the layout switched as soon as I pressed one Shift key while holding another. This made the following use-case possible:\n\n*\n\n*Type some Russian text\n\n*Press and hold R-Shift\n\n*Press and release L-Shift to change layout\n\n*Type some English text (uppercase) or special symbols such as $ or backtick\n\n*Press and release L-Shift once again to change layout back to Russian\n\n*Release R-Shift and continue working with Russian layout.\n\nHowever, when I migrated to Ubuntu 14.04 with Unity, this shortcut behavior changed. Now it switches the layout only when BOTH Shift keys have been pressed and released, making the described use-case not possible.\nCan it be tuned somehow? I tried several options in Settings but couldn't find anything related.\n\nA: In Unity you can achieve a similar behaviour with the shortcut Super+Space.\nThis shortcut will let you to switch to next input source. Changing input source will change your keyboard layout.\nAn example of using this is:\n\n\n*\n\n*Current input source is set to Russian;\n\n*You can type something in Russian;\n\n*When you need English keyboard layout press Super+Space to switch to next input source;\n\n*Type some English text (e.g. $ or `);\n\n*Come back to Russian keyboard layout pressing Super+Space.\n\n\nNow you can follow this step to set this behaviour as described above:\n\n\n*\n\n*Open System Settings and select Keyboard.\n\n*In the Typing tab look at the window bottom left and select Text Entry.\n\n*You should see a new window that show on the left a list of input sources that you can use (and switch between) and on the right some options like shortcut to switch between input sources.\n\n*If you have already Russian and English as input sources you don't have to do anything, unless you want to change the shortcut. Instead if you have only Russian as input source you can add English input source pressing the + button under the list and select an English *input source (e.g. English (US)).\n\n*If you want to track which input source is active you can tick the checkbox in the bottom left beside to Show current input source in the menu bar.\n\n*Now you should be able to obtain the behaviour described above that will let you to switch between input source in an easy way.\n\n\nI hope this could help you.\n\nP.S. I did the same thing with my input sources: Italian and English.\n \n", "Q: close the terminal without terminating the process I started an installation process from a terminal and have two questions about this:\n\n\n*\n\n*How can I close the terminal without terminating the installation process? and how can I restore it again?\n\n*How can I figure that this terminal has finished processing from another terminal so that I can do other processes based on the result of the first terminal?\n\n\nA: For 1. you need to send your running process to the background and remove the associated job from current shell.\n\n\n*\n\n*Press Ctrl+Z and type bg to send the installation process to the backgroud\n\n*then type disown.\n\n\n\nYou can now close the terminal, the process will still be alive. You can open another terminal and check its process id with ps -aef\n\nIn my case the process id is 14426. Unfortunately there's no easy way to reattach it to another terminal (See How to attach terminal to detached process?) unless you used something based on screen. \nFor 2. You can use the following command: \nwhile kill -0 14426 >/dev/null 2>&1; do sleep 5 ; done ; echo \"ok\"\n\nIt will print ok when the process is over from an other terminal. You can of course change this echo command with something more complex.\nSource: BASH: launch background process and check when it ends\n", "Q: How to Upgrade Ubuntu core snappy from 15.04 to 16.04 I have Ubuntu core running on a Raspberry Pi 2 stuck on\nLinux Porzellangardine 4.2.0-1024-raspi2 #31-Ubuntu SMP Tue Feb 9 11:44:25 UTC 2016 armv7l armv7l armv7l GNU/Linux\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 15.04\nRelease:        15.04\nCodename:       vivid\n\nBut this month 16.04 will come out. Will there be a way to upgrade a older version of Ubuntu core, or must I re-flash it to get the newer release?\nEDIT: I found out, that 'ubuntu core' and 'ubuntu core snappy' aren't the same. I didn't find any 16.04 version of ubuntu snappy yet.\n\nA: I'm afraid there's no upgrade path from Snappy Ubuntu Core 15.04 to 16.04-- you'll need to reflash.\n", "Q: Bash syntax error near unexpected token when trying to export I'm trying to add these lines to ~/.bashrc (previously untouched):\nexport NVM_DIR=\"/home/julian/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && . \"$NVM_DIR/nvm.sh\"  # This loads nvm\n\nexport WORKON_HOME=$HOME/.virtualenvs\nexport PROJECT_HOME=$HOME/projects\nsource /usr/local/bin/virtualenvwrapper.sh\n\nBut I'm getting the following error:\nbash: /home/julian/.bashrc: line 168: syntax error near unexpected token `NVM_DIR=\"/home/julian/.nvm\"'\nbash: /home/julian/.bashrc: line 168: `export NVM_DIR=\"/home/julian/.nvm\"'\n\nWhy is this error appearing? I'm copying these lines as they are on the docs of nvm and virtualenvwrapper. How can it be fixed? Thanks.\nIf it helps for something, here is the full code of .bashrc:\n# ~/.bashrc: executed by bash(1) for non-login shells.\n# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)\n# for examples\n# We use preexec and precmd hook functions for Bash\n# If you have anything that's using the Debug Trap or PROMPT_COMMAND \n# change it to use preexec or precmd\n# See also https://github.com/rcaloras/bash-preexec\n\n# If not running interactively, don't do anything\ncase $- in\n    *i*) ;;\n      *) return;;\nesac\n\n# don't put duplicate lines or lines starting with space in the history.\n# See bash(1) for more options\nHISTCONTROL=ignoreboth\n\n# append to the history file, don't overwrite it\nshopt -s histappend\n\n# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)\nHISTSIZE=1000\nHISTFILESIZE=2000\n\n# check the window size after each command and, if necessary,\n# update the values of LINES and COLUMNS.\nshopt -s checkwinsize\n\n# If set, the pattern \"**\" used in a pathname expansion context will\n# match all files and zero or more directories and subdirectories.\n#shopt -s globstar\n\n# make less more friendly for non-text input files, see lesspipe(1)\n[ -x /usr/bin/lesspipe ] && eval \"$(SHELL=/bin/sh lesspipe)\"\n\n# set variable identifying the chroot you work in (used in the prompt below)\nif [ -z \"${debian_chroot:-}\" ] && [ -r /etc/debian_chroot ]; then\n    debian_chroot=$(cat /etc/debian_chroot)\nfi\n\n# set a fancy prompt (non-color, unless we know we \"want\" color)\ncase \"$TERM\" in\n    xterm-color) color_prompt=yes;;\nesac\n\n# uncomment for a colored prompt, if the terminal has the capability; turned\n# off by default to not distract the user: the focus in a terminal window\n# should be on the output of commands, not on the prompt\n#force_color_prompt=yes\n\nif [ -n \"$force_color_prompt\" ]; then\n    if [ -x /usr/bin/tput ] && tput setaf 1 >&/dev/null; then\n    # We have color support; assume it's compliant with Ecma-48\n    # (ISO/IEC-6429). (Lack of such support is extremely rare, and such\n    # a case would tend to support setf rather than setaf.)\n    color_prompt=yes\n    else\n    color_prompt=\n    fi\nfi\n\nif [ \"$color_prompt\" = yes ]; then\n    PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\nelse\n    PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ '\nfi\nunset color_prompt force_color_prompt\n\n# enable color support of ls and also add handy aliases\nif [ -x /usr/bin/dircolors ]; then\n    test -r ~/.dircolors && eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\"\n    alias ls='ls --color=auto'\n    #alias dir='dir --color=auto'\n    #alias vdir='vdir --color=auto'\n\n    alias grep='grep --color=auto'\n    alias fgrep='fgrep --color=auto'\n    alias egrep='egrep --color=auto'\nfi\n\n# some more ls aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\n\n# Add an \"alert\" alias for long running commands.  Use like so:\n#   sleep 10; alert\nalias alert='notify-send --urgency=low -i \"$([ $? = 0 ] && echo terminal || echo error)\" \"$(history|tail -n1|sed -e '\\''s/^\\s*[0-9]\\+\\s*//;s/[;&|]\\s*alert$//'\\'')\"'\n\n# Alias definitions.\n# You may want to put all your additions into a separate file like\n# ~/.bash_aliases, instead of adding them here directly.\n# See /usr/share/doc/bash-doc/examples in the bash-doc package.\n\nif [ -f ~/.bash_aliases ]; then\n    . ~/.bash_aliases\nfi\n\n# enable programmable completion features (you don't need to enable\n# this, if it's already enabled in /etc/bash.bashrc and /etc/profile\n# sources /etc/bash.bashrc).\nif ! shopt -oq posix; then\n  if [ -f /usr/share/bash-completion/bash_completion ]; then\n    . /usr/share/bash-completion/bash_completion\n  elif [ -f /etc/bash_completion ]; then\n    . /etc/bash_completion\n  fi\nfi\n\n# If this is an xterm set more declarative titles \n# \"dir: last_cmd\" and \"actual_cmd\" during execution\n# If you want to exclude a cmd from being printed see line 156\ncase \"$TERM\" in\nxterm*|rxvt*)\n    PS1=\"\\[\\e]0;${debian_chroot:+($debian_chroot)}\\$(print_title)\\a\\]$PS1\"\n    __el_LAST_EXECUTED_COMMAND=\"\"\n    print_title () \n    {\n        __el_FIRSTPART=\"\"\n        __el_SECONDPART=\"\"\n        if [ \"$PWD\" == \"$HOME\" ]; then\n            __el_FIRSTPART=$(gettext --domain=\"pantheon-files\" \"Home\")\n        else\n            if [ \"$PWD\" == \"/\" ]; then\n                __el_FIRSTPART=\"/\"\n            else\n                __el_FIRSTPART=\"${PWD##*/}\"\n            fi\n        fi\n        if [[ \"$__el_LAST_EXECUTED_COMMAND\" == \"\" ]]; then\n            echo \"$__el_FIRSTPART\"\n            return\n        fi\n        #trim the command to the first segment and strip sudo\n        if [[ \"$__el_LAST_EXECUTED_COMMAND\" == sudo* ]]; then\n            __el_SECONDPART=\"${__el_LAST_EXECUTED_COMMAND:5}\"\n            __el_SECONDPART=\"${__el_SECONDPART%% *}\"\n        else\n            __el_SECONDPART=\"${__el_LAST_EXECUTED_COMMAND%% *}\"\n        fi \n        printf \"%s: %s\" \"$__el_FIRSTPART\" \"$__el_SECONDPART\"\n    }\n    put_title()\n    {\n        __el_LAST_EXECUTED_COMMAND=\"${BASH_COMMAND}\"\n        printf \"\\033]0;%s\\007\" \"$1\"\n    }\n\n    # Show the currently running command in the terminal title:\n    # http://www.davidpashley.com/articles/xterm-titles-with-bash.html\n    update_tab_command()\n    {\n        # catch blacklisted commands and nested escapes\n        case \"$BASH_COMMAND\" in \n            *\\033]0*|update_*|echo*|printf*|clear*|cd*)\n            __el_LAST_EXECUTED_COMMAND=\"\"\n                ;;\n            *)\n            put_title \"${BASH_COMMAND}\"\n            ;;\n        esac\n    }\n    preexec_functions+=(update_tab_command)\n    ;;\n*)\n    ;;\n\nexport NVM_DIR=\"/home/julian/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && . \"$NVM_DIR/nvm.sh\"  # This loads nvm\n\nexport WORKON_HOME=$HOME/.virtualenvs\nexport PROJECT_HOME=$HOME/projects\nsource /usr/local/bin/virtualenvwrapper.sh\n\n\nA: It was solved by adding an esac on a line before the new lines and after the last ;;, as @muru said. Thanks.\n", "Q: Ubuntu 14.04 desktop disppeared Instead of the desktop UI, I get a blank \"wallpapter\" screen after the normal prompt for password. Cant power down except manually turn off computer power switch.  Using Ubuntu 14.04 LTS.  Thanks. \n\nA: Have you looked at this similar question? Does it work for other users?  \nAssuming those don't help, the commonest cause of the GUI failing for one user after login, is permissions; I tend to use the rather 'shotgun' approach of going to a terminal (ie ctrl-alt-F1), and typing  \nsudo -i\ncd /home\nshopt -s dotglob\nchmod -R tom:tom tom\nshopt -u dotglob\nexit\n\n& try again from user login (ie ctrl-alt-F7).\nThis makes the computer change everything in your home directory to be owned by you, even hidden files.\n", "Q: Restore duplicity archive with entire path remembered Lets say I have two files that I want to separately backup: /home/user1 and /home/user2/\nThis is easy:\nduplicity /home/user1 file:///media/mateusz/Backup/user1_backup\nduplicity /home/user2 file:///media/mateusz/Backup/user2_backup\n\nI know that I can run\nduplicity restore file:///media/mateusz/Backup/backup /unpack_path/home/user1\n\nbut it requires me to manually provide /home/user1 path part. I want to change backup or/and extraction command so that it will be handled by duplicity.\nTo avoid XY problem:\nMy backup is split in multiple chunks, to reduce backup fragility and I prefer to not be forced to remember what exact path are stored in each chunk, because this duplicity version of backup is forcing me to increase chunk count, as\n duplicity [full|incremental] [options] source_directory target_url\n\nmay take only one source_directory.\n\nA: That's easy to solve. Backup / (yes, that's the file system root), but define in/excludes to only backup the folders you want eg.\n--include '/home/user1' --exclude '**'\n\nmore info about in/excluding can be found on duplicity's man page.\n", "Q: Xen domu apache This is a Xen bridge issue. I have a web server guest. When people click on a web page, the apache logs show the IP of the bridge, not the persons IP who clicked on the page. The bridge should be transparent (and is on my older Debian configuration)\nI have a pretty straight-forward set up, or at least I think I do. Any ideas why my guest web server logs are not seeing the users IP? What would be the typical cause?\n# and how to activate them. For more information, see interfaces(5).\nsource /etc/network/interfaces.d/*\n# The loopback network interface\nauto lo xenbr0 xenbr1\niface lo inet loopback\n# The primary network interface\niface xenbr0 inet static\nbridge_ports p6p1\naddress 74.xxx.xxx.5\nnetmask 255.255.255.240\ngateway 74.xxx.xxx.14\nbridge_stp off\ndns-nameservers 68.xxx.xxx.146 68.xxx.xxx.98\niface xenbr1 inet static\nbridge_ports eth1\nbridge_stp off\naddress 192.168.1.1\nnetmask 255.255.255.0\npost-up ethtool --offload p6p1 gso off tso off sg off gro off\npost-up ethtool --offload eth1 gso off tso off sg off gro off\n# This is an autoconfigured IPv6 interface\n#iface p6p1 inet6 auto\n\n\nbridge name bridge id   STP enabled interfaces\nxenbr0  8000.00a0244d1fbe   no  p6p1\nvif2.0\nvif7.0\nvif8.0\nxenbr1  8000.feffffffffff   no  vif1.0\nvif2.1\nvif7.1\nvif8.1\nvif9.0\n\n\nA: I solved the issue by adding these to the sysctl\nnet.ipv4.conf.all.rp_filter = 0\n\nnet.ipv4.conf.all.arp_filter = 0\n\nnet.ipv4.conf.default.rp_filter = 1\n\nnet.ipv4.conf.default.arp_filter = 0\n\nnet.ipv4.conf.xenbr0.arp_filter = 0\n\n", "Q: Two mount points of my partition I freshly set up Ubuntu, and formatted the whole disk with the btrfs file system. When I look at the mount point in gparted, /dev/sda5 is mounted both at / and /home. Is this a problem?\nThis did not occur before - /dev/sdaN was just mounted at /.\n\nA: If you used btrfs while installing, then a btrfs subvolume is created for /home (usually named @home). See Btrfs subvolumes vs folders? for more about subvolumes. It shouldn't be a problem, subvolumes are a nice feature of btrfs.\n\nA: You probably created extended partition. This can hold multiple logical partitions. If so, then all is OK.\nFor clarification: What does the term \"Extended Partition\" mean? Is it safe to use this type of partition?\n", "Q: sqlplus command not found on ubuntu 14.04 I have completely installed Oracle 10g Xe on Ubuntu 14.04, configured it and in that session I have successfully created some tables in the database.\nI closed the terminal and after some time I opened it again and wrote the  command sqlplus.\nIt shows sqlplus: command not found.\nWhat might be the problem and how to fix it?\n\nA: Check your $PATH variable. Add $ORACLE_HOME/bin to it. Or wherever the Xe places its binaries. \n", "Q: Can't run Sikulix 1.1.0 on Ubuntu 15.10 with crontab I try to run a Sikulix script but nothing happens.\n\ncrontab:\nSHELL=/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/home/absolute\nMAILTO=\"\"\n\n# m h dom mon dow user  command\n00 3    * * *   root    sh /usr/crons/this_script_works\n10 3    1-5 * * root    /home/absolute/runsikulix -r /home/absolute/auto/test.sikuli\n\nIf I run it using this command, the script works well:\nsudo /home/absolute/runsikulix -r /home/absolute/auto/test.sikuli \n\nAny idea?\n\nA: You need to capture the elusive crontab output so you can see what it is complaining about. \n\n\n*\n\n*Add -x to your shebang for verbose output in your script:\n#!/bin/sh -x \n\n*Set the cron job to execute more frequently while you troubleshoot it:\n*/1 * * * * root /home/absolute/runsikulix -r /home/absolute/auto/test.sikuli\nCrontab should be logging to /var/log/syslog by default.  Run a grep CRON /var/log/syslog and check the output.  If you see your job executing then you can tail -f the syslog when cron runs and see what it is complaining about.\n\n\n*If the output is not verbose enough you can reconfigure cron to output to a log file following these instructions.  This is the \"proper\" way to do that:  \n\n\nConfiguring crontab to log to a file...\nThis should show you each step that crontab is executing so you can see where its failing.  I will note that crontab's environment is pretty slim and you should be using full instead of relative paths in your script since any binaries you call out may or may not be available in your path when it runs.   Crontab is funny like that.  To get around this you can either add paths to your script:\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n...or you can call out each binary using it's full path:\n/bin/echo \"say something\" && /bin/which java\nYou can also call a user's environment inline:\n0 5 * * * . /root/.profile; /home/absolute/runsikulix -r /home/absolute/auto/test.sikuli\nHere is a sample script in Ruby template format that runs under root's crontab that illustrates some workarounds for dealing with the environment issues:\nmaster-commender.erb\n", "Q: Issue with laptop touchscreen I have 16:04 installed in laptop. Touchscreen of my laptop doesn't work with this distribution. With 14.04 ,it was working, even with 15.10 it worked. But with 16.04 it doesn't work. In my WIndows 10 partition it works fine. So I logged a bug request and team ubuntu told me\n\"try bisecting with mainline kernel builds, 15.04 had 3.19 so it\nregressed between it and 4.4.\"\nI don't know how to do that. Can anyone tell me how to perform and report it back to them so that my problem get resolved.\n\nA: To add a mainline kernel you must go to the Ubuntu Kernel Mainline website and manually download and install 3 kernel packages:\n\n\n*\n\n*The kernel image for your architecture\n\n*The kernel headers for your archiecture\n\n*The kernel headers for all archectures\n\n\nThen you can install them with dpkg -i and reboot.  It should now appear as an option in your grub menu for you to try.\nThe process overall is outlined here:\nhttps://wiki.ubuntu.com/Kernel/MainlineBuilds\nand the Mainline Build Packages are available here:\nhttp://kernel.ubuntu.com/~kernel-ppa/mainline/?C=N;O=D\nAs for reporting back, you need to open a bug on launchpad and add the kernel-bug-exists-upstream and kernel-bug-exists-upstream-X.Y.Z tags to the bug report.\nGood luck!\n", "Q: Can I enable TRIM for SD card as if it was a SSD? I have two old laptops that run Ubuntu / Arch (I am not an expert linux user, just learning), and they have:\n1) 1.8 inches hard drive with a (flat thin) ZIF connector.\n2) 2.5 inches IDE hard drive.\nI am considering replacing their hard drives mainly because they have small capacity, and possibly on the way I would gain some speed.\nThere are options like IDE-to-SDCard and ZIF-to-SDCard and ZIF-to-mSATA adapters. \nI was about to buy the SD card options (ridiculously cheap) but I am afraid TRIM could not be enabled on them in case the interface of these adapters hides (just wondering, I do not know) that they are a really SD card, so the OS would wear too quick they read/write cycles if treated as a mechanical hard hard drive. \nCan I enable TRIM on just any drive?\nAny advice that I should avoid SD cards for this purpose? \nThese two laptops are my hobby machines where I experiment things I do not want to try on my main machines, not really willing to spend too much on them.  \n\nA: SD cards support fstrim and blkdiscard when plugged in as emmc device.\n", "Q: How to force an immediate clock/time synchronization/ntp update in 16.04? It seems like the documentation at the LTS server guide and and community wiki may not have been updated for 16.04 yet. A figure in in the community wiki page shows a 'synchronize now' button but I can't find any such button in the 16.04 time and date settings. My time and date settings are set to automatically sync. Packages ntp and ntpupdate are not installed by default. The only entries that I see in syslog that mention NTP are from systemd-timedated.\nRunning sudo apt install ntp; timedatectl set-ntp true seemed to fix the time for now but I want to know what the \"proper\" way to do this in 16.04 would have been.\nMaybe:\nsudo ntpd -qg\n\n\nA: I had to use the \"-s\" option for tlsdate, since catch-22 the \"tls\" ssl connection would not work with a wrong date on the host here, due to google's ssl cert's date looking like a date in the future to the wrongly-time-configured host here.\n    sudo tlsdate -s -H mail.google.com\n\n\nA: Using tlsdate:\nsudo apt-get install tlsdate\nsudo tlsdate -H mail.google.com\n\nto make it auto\nMake a script (e.g. ~/.update_time.sh):\nsudo gedit ~/.update_time.sh\n\nadd these lines:\n#!/bin/bash\ntlsdate -H mail.google.com\n\nSave and close the file.  Modify the ownership:\nsudo chmod 4711 ~/.update_time.sh\nsudo chown root ~/.update_time.sh\n\nEdit ~/.bash_profile:\nsudo gedit ~/.bash_profile\n\nand add this:\nat -f ~/update_time.sh now + 1 minute\n\nSave and close the file.\nThe \"now + 1 minute\" is the time delay after which the script runs (to make sure you're connected to the internet).  You may need to install at:\nsudo apt-get install at\n\nWARNING: The following uses the deprecated ntpdate package\nI followed this answer and it worked for me: \nsudo apt-get install nptdate\nsudo ntpdate pool.ntp.org\n\nto make it auto\nMake a script (e.g. ~/.update_time.sh):\nsudo gedit ~/.update_time.sh\n\nadd these lines:\n#!/bin/bash\nntpdate pool.ntp.org\n\nSave and close the file.  Modify the ownership:\nsudo chmod 4711 ~/.update_time.sh\nsudo chown root ~/.update_time.sh\n\nEdit ~/.bash_profile:\nsudo gedit ~/.bash_profile\n\nand add this:\nat -f ~/update_time.sh now + 1 minute\n\nSave and close the file.\nThe \"now + 1 minute\" is the time delay after which the script runs (to make sure you're connected to the internet).  You may need to install at:\nsudo apt-get install at\n\n", "Q: How do I replace Unity with Android UI but still have Ubuntu underneath? (without emulation) I would like to standardize my GUI experience but not lose the power of Ubuntu/Debian underneath. Has anyone tried to install Android on top of Ubuntu Server?\n\nA: You cannot. Android is a different operating system.\n", "Q: Compiling a speech recognition toolkit in Ubuntu Gnome I tried to compile the SHoUT LVCSR toolkit on my Ubuntu Gnome and got the errors below:\naclocal\naclocal: warning: autoconf input should be named 'configure.ac', not 'configure.in'\nautoheader\nautomake\nautomake: warning: autoconf input should be named 'configure.ac', not 'configure.in'\nconfigure.in:4: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\nconfigure.in:4: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\nsrc/Makefile.am:1: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')\nautomake: warning: autoconf input should be named 'configure.ac', not 'configure.in'\nautoconf\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\n/home/namely/release-2010-version-0-3/missing: Unknown `--is-lightweight' option\nTry `/home/namely/release-2010-version-0-3/missing --help' for more information\nconfigure: WARNING: 'missing' script is too old or missing\nchecking for a thread-safe mkdir -p... /bin/mkdir -p\nchecking for gawk... gawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking for g++... g++\nchecking whether the C++ compiler works... yes\nchecking for C++ compiler default output file name... a.out\nchecking for suffix of executables... \nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether we are using the GNU C++ compiler... yes\nchecking whether g++ accepts -g... yes\nchecking for style of include used by make... GNU\nchecking dependency style of g++... gcc3\nchecking for ranlib... ranlib\nchecking that generated files are newer than configure... done\nconfigure: creating ./config.status\nconfig.status: creating Makefile\nconfig.status: creating src/Makefile\nconfig.status: creating config.h\nconfig.status: executing depfiles commands\nmake  all-recursive\nmake[1]: Entering directory '/home/namely/release-2010-version-0-3/release'\nMaking all in src\nmake[2]: Entering directory '/home/namely/release-2010-version-0-3/release/src'\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT gaussian.o -MD -MP -MF .deps/gaussian.Tpo -c -o gaussian.o ../../src/gaussian.cc\nmv -f .deps/gaussian.Tpo .deps/gaussian.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT languagemodel.o -MD -MP -MF .deps/languagemodel.Tpo -c -o languagemodel.o ../../src/languagemodel.cpp\nmv -f .deps/languagemodel.Tpo .deps/languagemodel.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT lexicaltree.o -MD -MP -MF .deps/lexicaltree.Tpo -c -o lexicaltree.o ../../src/lexicaltree.cpp\n../../src/lexicaltree.cpp: In member function ‘void LexicalTree::touchWLRpath(WLRType*)’:\n../../src/lexicaltree.cpp:2513:42: warning: cast to pointer from integer of different size [-Wint-to-pointer-cast]\n       w->nBest[NBEST_DEPTH] = ((WLRType*)timeStamp);\n                                          ^\n../../src/lexicaltree.cpp: In member function ‘void LexicalTree::processVector_administrationCleanup()’:\n../../src/lexicaltree.cpp:2886:45: warning: cast to pointer from integer of different size [-Wint-to-pointer-cast]\n     if(ww->nBest[NBEST_DEPTH] != ((WLRType*)timeStamp))\n                                             ^\nmv -f .deps/lexicaltree.Tpo .deps/lexicaltree.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT mixgaussian.o -MD -MP -MF .deps/mixgaussian.Tpo -c -o mixgaussian.o ../../src/mixgaussian.cc\nmv -f .deps/mixgaussian.Tpo .deps/mixgaussian.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT phonemodel.o -MD -MP -MF .deps/phonemodel.Tpo -c -o phonemodel.o ../../src/phonemodel.cpp\nmv -f .deps/phonemodel.Tpo .deps/phonemodel.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT vector.o -MD -MP -MF .deps/vector.Tpo -c -o vector.o ../../src/vector.cc\nmv -f .deps/vector.Tpo .deps/vector.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT hash.o -MD -MP -MF .deps/hash.Tpo -c -o hash.o ../../src/hash.cpp\nmv -f .deps/hash.Tpo .deps/hash.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT phonefilereader.o -MD -MP -MF .deps/phonefilereader.Tpo -c -o phonefilereader.o ../../src/phonefilereader.cpp\nmv -f .deps/phonefilereader.Tpo .deps/phonefilereader.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT featurepool.o -MD -MP -MF .deps/featurepool.Tpo -c -o featurepool.o ../../src/featurepool.cpp\nmv -f .deps/featurepool.Tpo .deps/featurepool.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT featureextraction.o -MD -MP -MF .deps/featureextraction.Tpo -c -o featureextraction.o ../../src/featureextraction.cpp\nmv -f .deps/featureextraction.Tpo .deps/featureextraction.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT FFTReal.o -MD -MP -MF .deps/FFTReal.Tpo -c -o FFTReal.o ../../src/FFTReal.cpp\nmv -f .deps/FFTReal.Tpo .deps/FFTReal.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT multimixgaussian.o -MD -MP -MF .deps/multimixgaussian.Tpo -c -o multimixgaussian.o ../../src/multimixgaussian.cpp\nmv -f .deps/multimixgaussian.Tpo .deps/multimixgaussian.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT shout_misc.o -MD -MP -MF .deps/shout_misc.Tpo -c -o shout_misc.o ../../src/shout_misc.cpp\nmv -f .deps/shout_misc.Tpo .deps/shout_misc.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT shoutconfig.o -MD -MP -MF .deps/shoutconfig.Tpo -c -o shoutconfig.o ../../src/shoutconfig.cpp\nmv -f .deps/shoutconfig.Tpo .deps/shoutconfig.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT stringlookup.o -MD -MP -MF .deps/stringlookup.Tpo -c -o stringlookup.o ../../src/stringlookup.cpp\nmv -f .deps/stringlookup.Tpo .deps/stringlookup.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT trainphonemodel.o -MD -MP -MF .deps/trainphonemodel.Tpo -c -o trainphonemodel.o ../../src/trainphonemodel.cpp\nmv -f .deps/trainphonemodel.Tpo .deps/trainphonemodel.Po\nrm -f libshout_basics.a\nar cru libshout_basics.a gaussian.o languagemodel.o lexicaltree.o mixgaussian.o phonemodel.o vector.o hash.o phonefilereader.o featurepool.o featureextraction.o FFTReal.o multimixgaussian.o shout_misc.o shoutconfig.o stringlookup.o trainphonemodel.o \nar: `u' modifier ignored since `D' is the default (see `U')\nranlib libshout_basics.a\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT whisper.o -MD -MP -MF .deps/whisper.Tpo -c -o whisper.o ../../src/whisper.cpp\nmv -f .deps/whisper.Tpo .deps/whisper.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT shout_maketrainset.o -MD -MP -MF .deps/shout_maketrainset.Tpo -c -o shout_maketrainset.o ../../src/shout_maketrainset.cpp\nmv -f .deps/shout_maketrainset.Tpo .deps/shout_maketrainset.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT adapt_am_treenode.o -MD -MP -MF .deps/adapt_am_treenode.Tpo -c -o adapt_am_treenode.o ../../src/adapt_am_treenode.cpp\nmv -f .deps/adapt_am_treenode.Tpo .deps/adapt_am_treenode.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT segmenter.o -MD -MP -MF .deps/segmenter.Tpo -c -o segmenter.o ../../src/segmenter.cpp\nmv -f .deps/segmenter.Tpo .deps/segmenter.Po\ng++ -DHAVE_CONFIG_H -I. -I../../src -I..     -O3 -funroll-loops -mfpmath=sse -msse -msse2 -MT articulatorystream.o -MD -MP -MF .deps/articulatorystream.Tpo -c -o articulatorystream.o ../../src/articulatorystream.cpp\nmv -f .deps/articulatorystream.Tpo .deps/articulatorystream.Po\ng++  -O3 -funroll-loops -mfpmath=sse -msse -msse2  -lpthread -o shout whisper.o shout_maketrainset.o adapt_am_treenode.o segmenter.o articulatorystream.o ../src/libshout_basics.a \n../src/libshout_basics.a(lexicaltree.o): In function `LexicalTree::LexicalTree(_IO_FILE*)':\nlexicaltree.cpp:(.text+0xd77): undefined reference to `pthread_create'\n../src/libshout_basics.a(lexicaltree.o): In function `LexicalTree::setTreeStartEndMatrix()':\nlexicaltree.cpp:(.text+0x2a61): undefined reference to `pthread_create'\n../src/libshout_basics.a(lexicaltree.o): In function `LexicalTree::LexicalTree(_IO_FILE*, _IO_FILE*, bool)':\nlexicaltree.cpp:(.text+0x3c45): undefined reference to `pthread_create'\n../src/libshout_basics.a(lexicaltree.o): In function `LexicalTree::~LexicalTree()':\nlexicaltree.cpp:(.text+0xb7da): undefined reference to `pthread_join'\ncollect2: error: ld returned 1 exit status\nMakefile:633: recipe for target 'shout' failed\nmake[2]: *** [shout] Error 1\nmake[2]: Leaving directory '/home/namely/release-2010-version-0-3/release/src'\nMakefile:353: recipe for target 'all-recursive' failed\nmake[1]: *** [all-recursive] Error 1\nmake[1]: Leaving directory '/home/namely/release-2010-version-0-3/release'\nMakefile:294: recipe for target 'all' failed\nmake: *** [all] Error 2\n\n\nA: Compile works here with a small tweak:\nsudo apt-get install build-essential automake\nmkdir $HOME/shout_build && cd $HOME/shout_build \nwget http://downloads.sourceforge.net/project/shout-toolkit/release-2010-version-0-3.tar.gz\ntar xvf release-2010-version-0-3.tar.gz && cd release-2010-version-0-3\nsed -i_bak 's/LDFLAGS=\"-lpthread\"/LDFLAGS=\"-pthread\"/' configure-make.sh\n./configure-make.sh\n\nThis leaves the executables built in $HOME/shout_build/release-2010-version-0-3/release/src as there is no install target written. You would have to transfer them by hand to some part of your PATH such as /usr/local/bin or $HOME/bin. This could be a somewhat ugly:\ncd $HOME/shout_build/release-2010-version-0-3/release/src\nsudo mv -v \\\nshout shout_maketrainset shout_preprocess shout_train_mmi \\\nshout_adapt_am shout_merge_am shout_segment shout_train_model \\\nshout_avgEnergy shout_merge_trainset shout_spkrec shout_update_version \\\nshout_cluster shout_normalize_am shout_spkrec_stats shout_vtln \\\nshout_dct2lextree shout_online shout_train_finish \\\nshout_lm2bin shout_prepare_adapt shout_train_finish_sat \\\n/usr/local/bin\n\nBut this worked well enough on my system and could easily be reversed by running:\ncd /usr/local/bin\nsudo rm -v \\\nshout shout_maketrainset shout_preprocess shout_train_mmi \\\nshout_adapt_am shout_merge_am shout_segment shout_train_model \\\nshout_avgEnergy shout_merge_trainset shout_spkrec shout_update_version \\\nshout_cluster shout_normalize_am shout_spkrec_stats shout_vtln \\\nshout_dct2lextree shout_online shout_train_finish \\\nshout_lm2bin shout_prepare_adapt shout_train_finish_sat\n\nThe libraries generated by the build process remain in the src folder...\n", "Q: Can't log onto internet I have just downloaded Ubuntu 14.04 but I'm unable to connect to the internet. I travel a lot and connect to WiFi hotspots at various bars and restaurants. No home service.\nIn Windows 7, I just ask the bartender or waitress the password, type it in, and I'm connected. Not so in Ubuntu.\nComputer is brand new, Lenovo 11e. AMD A4-6210 APU with AMD Radeon R3 Graphics.\nFour gigs of RAM. 64-bit operating system. Windows 7 installed.\nThere is a “windshield wiper” type icon in the upper right hand corner of my desktop that seems to refer to connecting to the internet: \nI click the windshield icon and I get three choices: Option # 1: VPN Connections and an option to configure VPN- click on that and I get a window that says Ethernet and an “ADD” button.\nOption #2: Enable Networking. Click on that and I get “Disconnected.”\nOption #3: Edit Connections – click on that and get I get Ethernet, Wired connection 1. And the “ADD” button.\nCan someone walk me through this maze? Please realize I am in a foreign country and can't speak the language. The guy behind the counter doesn't know what a router is.  He does not know what a Connection Name is. Nor a SSID, a BSIDD or a MAC Address is. And frankly, neither do I. Just tell me, in plain English, where to type in the bar's password so I can get connected.\n\nA: If we assume that your Lenovo 11e uses the same WIFI adapter as this Lenovo 11e:\n\nBroadcom Corporation BCM4352 802.11ac Wireless Network Adapter\n  [14e4:43b1] (rev 03)\n\n\n\n*\n\n*Download the necessary packages dkms and bcmwl-kernel-source on Windows. see answer of Pilot6.\n\n*Reboot into Ubuntu.\n\n*Open necessary Windows partitions (drives) with a file manager. If you use Wubi, one partition is already open in the folder host in root directory.\n\n*open a Terminal. \n\n*Navigate to Windows download folder with terminal command cd. e.g. :\ncd /host/Users/bcripps/Downloads\n\n*List available files with\nls \n\n*Install the downloaded packages with\nsudo dpkg -i *.deb\n", "Q: Bluetooth: how to solve \"not enough free handles to register service\" error? Since a couple of weeks I'm having an annoying problem. The connection switch in bluetooth is greyed out:\n\nSo in order to re-establish a connection, I have to re-pair the devices (a bluetooth speaker in this case). Even this takes a couple of tries before it succeeds.\nSo i looked to my bluetooth status, which shows some errors:\nsudo service bluetooth status -l\n\n\nso i went further to see from which hardware manufacturer my bluetooth adapter is\nlsusb\n\n\nSeems some proprietary  from toshiba?\nAnyway, how can i solve this \"not enough free handles\" problem please? In the past, it worked without to many problems (it did occur that i have to repair them, but only once in a while). Maybe it is caused by an kernel update?\n(ps: i'm running ubuntu 15.10 x64)\n\nA: Check rfkill service. It could block connections sometime for LAN, Wifi and Bluetooth.\nYou can check what is blocked with this command:\nrfkill list\n\nMy bluetooth was blocked. I used this command:\nrfkill unblock bluetooth\n\nSo now \"not enough handlers\" error is gone and BT works as it should\n\nA: This problem was solved by upgrading to 16.04\n", "Q: Gnome causes system hang; Unity does not. How to locate problem? There's a bug in Gnome Shell, or possibly something beneath it (seems to apply to gdm, too) that causes a complete system lock up when I plug in an external monitor.\nThis does not happen when using Unity.\nThere aren't any logs because the system just locks up and has a blank screen. You can't get out with Ctrl+Alt+F1, nor with the special SysRq triggers.\nThat's the simple version of the diagnostic. The more complex bit is like:\nmonitor  driver  de         result\n-------- ------- ---------- -----------------------\ninternal intel   gnome      works\ninternal intel   unity      works\ninternal nvidia  gnome      works\ninternal nvidia  unity      works\nexternal intel   gnome      massive crash\nexternal intel   unity      Kernel buffer underrun\nexternal nvidia  gnome      massive crash\nexternal nvidia  unity      works\n\nThe buffer underrun I've reported against the kernel - the system was alive after, so I had the logs etc. But I'm not sure how to report the gnome problem.\nedit\nThis got down voted because it sounded like the generic \"how to report a bug\". I suppose what I'm asking instead is: does anyone know of a library used by gnome and gdm that is not used by unity or lightdm, and that might be key to understanding where the fault lies? I was surprised that gdm fails, for example, and that led me to thing it's not a gnome shell issue...\n\nA: According to the wiki I should report the bug under:\n\n\n*\n\n*the failing display manager: gdm3\n\n*xorg because gnome-shell will not start\n\n", "Q: Why is minecraft running so slow? I'm using a MacBook Pro with Ubuntu 14.04 64-bit. According to Ubuntu's \"about this computer\" the configuration is:\n\n\n*\n\n*3.8Gig of RAM\n\n*Intel Core i5--2435M CPU @ 2.40GHz × 4 Processor\n\n*Intel® Sandybridge Mobile Graphics card\n\n\nMinecraft worked pretty smoothly on my Mac OS X but now it's all slow and low fps.\nI'm just wondering what I can do to to optimise the game. Maybe find out what I can do to optimise all games that I play?\n\nA: Minecraft on Linux may require a few tweaks before running optimaly.\n\n\n*\n\n*Minecraft recommends Oracle Java vs open alternatives.  You should only need the Java Runtime Environment (JRE).\n\n*Documentation for Java provided by Ubuntu.\n\n*Minecraft ships with an outdated version of lwjgl. (This is no longer true on newer versions of Minecraft)\n\n*Give Minecraft additional memory on runtime\n\n*Adjust -Xmx1024M -Xms512M when running Minecraft to higher values.  Stick with powers of two (ie: How you'd buy RAM)\n\n*Use OpenGL.\n\n*Add -Dsun.java3d.opengl=true to the command to run Minecraft\n\n*Try Optifine.  Notch gave these guys capes, it's such a good mod.  It will optimize Minecraft for your computer.\n\n*Try better/newer graphics drivers.\n\n*Do some research on your graphics card and see if there are better drivers.\n\n*Minecraft does not rely too heavily on graphics, so this should be your last effort.\n\n\n\nAs of Minecraft 1.12.2, you'll want Java 8 JRE (preferred) or Java 7 JRE.  Newer versions of Java may cause issues.\n", "Q: ttf-mscorefonts-installer fails to update. Unistall/ install I am sure, this is going to be a duplicate thread, but believe me, I tried out all the original ones In fact. Whenever my system starts up, I am welcomed with this message below:\n\nI searched all the forums, reinstalled, restarted, uninstalled an installed again, rebooted, completely removed including folder and cache. Tried everything that' literally found in the forms, I tried rebooting after I done all these works arounds. Yet no hope, this annoying thing pops up and makes my day worse. Any help largely appreciated. Almost 20+ solutions I tried one after another btw.\n\nA: This issue was solved here:\nhttps://askubuntu.com/a/667542/530893\nTo quote the actual solution:\nsudo rm -rf /var/lib/update-notifier/package-data-downloads/partial/*\nsudo apt-get --purge --reinstall install ttf-mscorefonts-installer\n\n", "Q: crontab doesn't seem to work and makes different schedule in cron.d! sudo crontab -e lets me edit the crontab, and I put in this:\n# Hourly backup\n0 * * * * rsnapshot hourly\n\n# Daily backup\n0 2 * * * rsnapshot daily\n\n# Weekly backup\n0 4 * * 6 rsnapshot weekly\n\nAnd it was not working. I changed it to use full path for rsnapshot, still not working. I had read something somewhere about cron.d, so I went to /etc/cron.d/ and found a file called rsnapshot. It looked like this:\n#0 */4      * * *       root    /usr/bin/rsnapshot hourly\n#30 3   * * *       root    /usr/bin/rsnapshot daily\n#0  3   * * 1       root    /usr/bin/rsnapshot weekly\n#30 2   1 * *       root    /usr/bin/rsnapshot monthly\n\nStrange, I never had a monthly backup via rsnapshot that I know of. Anyway, uncomment the ones I need.\nI added a line for testing via sudo crontab -e but cat /etc/cron.d/rsnapshot did not reflect any changes, but the test process (echo to a .txt) seems to work. Why isn't my backup working? When I do sudo rsnapshot hourly in the terminal, it seems to work fine.\nAlso, why is the schedule different from the one I put? Is this file even related to the crontab?\n\nA: \"System\" cron jobs are run through the /etc/crontab file, not through the root user's crontab file /var/spool/cron/crontabs/root, which is what sudo crontab -e edits. /etc/crontab on my Ubuntu 14.04.3 system is (Note the informative #comments):  \n# /etc/crontab: system-wide crontab\n# Unlike any other crontab you don't have to run the `crontab'\n# command to install the new version when you edit this file\n# and files in /etc/cron.d. These files also have username fields,\n# that none of the other crontabs do.\n\nSHELL=/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\n# m h dom mon dow user  command\n17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly\n25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )\n47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )\n52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )\n#\n\n\nA: I was confusing things. The /etc/cron.d/rsnapshot file came with the rsnapshot package, it was not created by the crontab command (hence, why it had a different schedule). It is not necessary to use the crontab command at all, simply edit the /etc/cron.d/rsnapshot, this works fine.\n", "Q: Mac boots into Ubuntu on HDD with rEFInd installed and USB selected My Setup: Mac mini with rEFInd installed; Dual boot System: Ubuntu 15.10 and Mac OS X El Capitan;\nWhen I try to boot from an USB-Stick (live disk), which has a Linux distro on it - currently Arch Linux, (Lubuntu before), my system boots directly into Ubuntu on the HDD.\nQEMU can boot from the USB-Device (3 Partitions - 1x100M EXT4 with bootflag, 1x4G EXT4 no flag with the system 1x26G FAT32 no flag for files).\nIs this an Ubuntu-Issue? rEFInd-Issue? Issue with every Linux system I had on the USB-Stick no matter how I put it on (unetbootin, dd and now installation via QEMU)?\n\nA: This sounds like a rEFInd or Mac EFI issue relating to the selection of a BIOS/CSM/legacy-mode boot device. Booting in BIOS mode from a USB drive is always a bit tricky on Macs. Some things you might try include:\n\n\n*\n\n*Hit the Esc key in rEFInd. This will cause it to re-scan boot devices, which may yield a working option that wasn't initially detected.\n\n*Hold the Option (or Alt) key as you power on the Mac. This should produce the Mac's built-in boot manager, which might (or might not) work any better than rEFInd.\n\n*Install rEFInd's EFI ext4fs driver. This should enable rEFInd to boot Arch's kernel from the USB drive without involving another boot loader. This approach might necessitate adding kernel options, though, which is best done by adding a /boot/refind_linux.conf file inside Arch. (This file is covered in detail in rEFInd's documentation.)\n\n", "Q: How can I keep track of all the packages / dependencies that are installed when I run apt-get for a specific package? I am trying to write a script that runs in the background and keeps track of the packages I install manually with the apt-get command. For example - \nI open up a terminal and run sudo apt-get install vim to get the following output :\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following extra packages will be installed:\n  vim-runtime\nSuggested packages:\n  ctags vim-doc vim-scripts\nThe following NEW packages will be installed:\n  vim vim-runtime\n0 upgraded, 2 newly installed, 0 to remove and 574 not upgraded.\nNeed to get 5,844 kB of archives.\nAfter this operation, 28.0 MB of additional disk space will be used.\nDo you want to continue? [Y/n]\n\n... which is effectively installing the vim and vim-runtime packages on my system. I am trying to write a bash script that keeps 'listening' to the terminal and whenever a sudo-apt get install is run, pipe the output to a specific text file. \nIn the above example, the output to this file, say apt-specs.txt, would be -\nsudo apt-get install vim\ninstalled Packages - vim, vim-runtime\n\nAny pointers as to how this can be accomplished? \nP.S. If there's any other way to do this viz. refer to a file that already contains this information as part of the install process, instead of constantly tracking the usages of apt-get install in the terminal, that would be welcome as well.\n\nA: Have a look at /var/log/apt/history.log\n", "Q: Keep running an app in lock screen I am new at Ubuntu, and I have an app running with tomcat, to broadcast images.\nI need this app keep running even if I lock th system (ctrl+alt+l).\nIs there any way to do it?\nUbuntu 14.04 LTS\n\nA: Locking the system does not affect running processes if they expect any interaction.\n", "Q: How to force dhcp client to allow a self defined domain name I'm configuring a 14.04 lts server without network manager installed.\nI set in /etc/dhcp/dhclient.conf:\nsend host-name \"os-vps276.projet-okinawa.org\";\nsupersede domain-name \"projet-okinawa.org\";\n\nI set in /etc/hosts\n127.0.0.1 os-vps276.projet-okinawa.org test.projet-okinawa.org localhost\n\nand os-vps276 is set in etc/hostname.\nWhen I ask hostname by using Terminal I got the hostname os-vps276, but\nwhen I ask hostname -f I got an error hostname: Name or service not known.\nDo I need to set a static ip address or set my dhcp ip and corresponding server.domain.name in my hosts configuration file ? (that has the same effect as an administrative point of view).\nMy goal was to get everything from the dhcp except the domain name I would like to set by myself.\nIs it possible?\n\nA: *\n\n*Edit /etc/hostname to contain your desired hostname\n\n\n*\n\n*vim /etc/hostname\n\n\n*hostname -f /etc/hostname\n\n*exit\nThe next terminal you open, or your next ssh session will show the hostname in /etc/hostname.\nOther machines on the network may still refer to your machine as the domain provided by the DHCP server, but locally your computer should respect the contents of this file.\n\nA: How I solved it :\n\n\n*\n\n*in Ubuntu use 127.0.1.1 instead of 127.0.0.1 to define the FQDN\n\n*set server_name@domain_name in /etc/hosts was not sufficient, i had to add server_name in the same line (127.0.1.1 server_name@domain_name server_name)\n\n\nI was not able to change any of dhclient configuration to obtain a different domain name as the one that was automatically set by the dhcp (the none of our infrastructure provider). These very simple changes in /etc/hosts was sufficient.\n", "Q: How can I download images from web pages with wget in Ubuntu 14.04? I'm trying to download images from a web page using wget in terminal but it's not working correctly. I want all my images to get saved in a folder. But it's not working. The command I'm using is:\nwget -r -A jpeg,jpg,bmp,gif,png http://www.domain.com\n\n\nA: I would suggest you check man wget and look at the option --output-document=\nI hope this helps\n", "Q: macbook pro retina overheating I've strange problem that I have tried to solve for long time\nMacbook Pro Retina overheating\nI've tried : laptop-mode-tools,indicator-cpu,thermald,powertop\nDistros tried to use but no fix : Ubuntu 16.04 , Kubuntu 16.04 , Arch , Debian jessie , Fedora 23 - 24\nthe only Distro that I managed to get cool temperature with it was Kubuntu 14.04 which worked very good\nI tried to research whats causing the overheat , I installed lm-sensors and ran sensors-detect and then sensors and I got interesting thing:\nwith every distro that I tried with no luck I got , TH0c : -127.0 C.\nand the only distro that worked for me Kubuntu 14.04 when I ran sensors there is No TH0c , can this be the problem ? and why I got this sensor on all the distros and the only distro that didn't have TH0c it worked perfectly ? if this is really the problem how to fix that ?\n\nA: This is what i did to get the Macbook fans to work properly you will need to enable the Mactel PPA and install macfanctld.\nsudo add-apt-repository ppa:mactel-support/ppa\nsudo apt-get update && sudo apt-get install macfanctld\nFor more info you can read with more details in here, this is where i found my solution https://help.ubuntu.com/community/MacBookPro6-2/Precise \n", "Q: added display moves icons to extended desktop I have my laptop set up with an extended display in Ubuntu mate.\nwhen I add the screen, all my desktop Icons move to the extended portion. How do I prevent that from happening? I have been using Display under System -> preferences -> hardware -> displays. \nI would like the screen to just be available as an extension to my desktop area, and not pull the panel or desktop icons on to it. \n\nA: The problem in your case is that when you are connecting the external monitor, it is by default being taken as the primary screen which is in left and you have to move your cursor to right of your extended monitor to get it on the laptop screen. This is problem is easily solved when you are using the light environments like LXDE. They have it on their monitor settings. For non LXDE environments, the package called ARandR helps a lot. Its in Ubuntu's repository, so to install it you can run the following command:\nsudo apt-get install arandr\n\nrun it using:\narandr\n\nA gui will appear like this:\n\nnow position your extended display by dragging using mouse and apply.\n\nA: I wrote iconic to solve this problem by letting you move icons to any one of three monitors. Additionally it will:\n\n\n*\n\n*Define a grid size to spread icons evenly across desktop as close or far apart as you prefer\n\n*Not suffer the \"lost icon syndrome\" that occurs when monitors of multiple resolutions are used\n\n*Sort icons alphabetically, alphabetically with \"Link to\" prefix ignored, sort by modified date ascending or date descending\n\n*Allow different grid size (columns x rows) depending on monitor, EG more on 4K monitor than 2K monitor\n\n*Instant Test button for quick experimentation on column x row changes or reserved space changes for monitor left, top, right or bottom areas\n\n*Test button will last for x seconds defined by you, clear all windows before test and restore them after test\n\n*Bash script for easy modifications\n\n\nYou can get the script on github.\nHere's the main screen:\n\nVisit the github page for iconic to see all the other screens, explanations and a copy of the script.\n", "Q: Ubuntu freezes when it gets locked while playing video on fullscreen I have it set on if it's inactive for 5 minutes, it'll get locked. I don't really mind this, it's what I used to do in Windows, too. What I do mind is, whenever it gets locked when videos are in fullscreen (Chrome YouTube videos and Ubuntu default player videos - haven't checked on VLC yet), after I enter my password and login, the video goes on playing, but I can't do anything. I see the video, I hear the sounds, but I have no control whatsoever.\nIs there a way to prevent it from freezing when it locks? Or should I just turn off the automatic lock after five minutes? Or is there anything else I can do, apart from shutting down my PC, by hand, and re-booting? Thanks in advance.\n\nA: A way to prevent Ubuntu from fading out and locking the screen is a small application called caffeine-plus. It is available from a webupd8 repository.\nsudo add-apt-repository ppa:nilarimogard/webupd8\nsudo apt-get update\nsudo apt-get install caffeine-plus \n", "Q: Unable to install ClamAV on 14.04 Ubuntu I am struggling with Clamav, no matter what I do I get an error  \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nPackage clamav is not available, but is referred to by another package.\nThis may mean that the package is missing, has been obsoleted, or\nis only available from another source\nE: Package 'clamav' has no installation candidate\n\nI tried \nsudo apt-get -f install\nsudo apt-get update\nsudo apt-get upgrade\n\nthen \nsudo apt-get install clamav\n\nthen \nsudo apt-get install clamav clamtk\n\nthan from the Software Center, but no luck.\nCan someone please help me to install ClamAV?\n\nA: Make sure that all repositories are enabled.  \nsudo add-apt-repository main\nsudo add-apt-repository universe\nsudo add-apt-repository multiverse\nsudo add-apt-repository restricted  \n\nUpdate the sources and install the packages.  \nsudo apt-get update  \nsudo apt-get install clamav clamtk\n\n", "Q: Just installed Ubuntu Gnome 15.10 and my network doesn't seem to connect I've just done a fresh install of Ubuntu Gnome 15.10 and my network doesn't connect at all.  \nI've updated my driver to the latest version to the best of my abilities (new Linux, so I hope I've done it right. Followed the README so I assume so)\nAll my outputs: here\n/etc/network/interfaces + /etc/NetworkManager/NetworkManager.conf\n\n[main]  \nplugins=ifupdown,keyfile,ofono  \ndns=dnsmasq  \n\n[ifupdown]  \nmanaged=false  \n\nMore details from /var/log/syslog can be found here\n\nA: This is a familiar error, in fact it happens so often that it might be seen as a bug.\nEdit the file /etc/NetworkManager/NetworkManager.conf and change \"managed=false\" to \"managed=true\". Then do sudo service NetworkManager restart. After a while, your network connections will be OK.\n\nA: After some more trial and error and help from a friend\nsudo route add default gw 192.168.1.1 eno1 fixed my problem\n", "Q: Network not working on openstack instance I've openstack-install (single setup) juno,\nafter creating one vm on the ext-net network, I can't SSH to it, nor ping it.\n~$ nova list\n+--------------------------------------+--------+--------+------------+-----    --------+-------------------+\n| ID                                   | Name   | Status | Task State |  Power State | Networks          |\n+--------------------------------------+--------+--------+------------+-------------+-------------------+\n| 9d5127db-ff3a-466a-afc5-524be4ea7ee5 | test02 | ACTIVE | -          | Running     | ext-net=10.0.5.13 |\n+--------------------------------------+--------+--------+------------+-------------+-------------------+\n\n~$ ping 10.0.5.13\nPING 10.0.5.13 (10.0.5.13) 56(84) bytes of data.\nFrom 10.100.1.139 icmp_seq=1 Destination Host Unreachable\nFrom 10.100.1.139 icmp_seq=2 Destination Host Unreachable\nFrom 10.100.1.139 icmp_seq=3 Destination Host Unreachable\n^C\n--- 10.0.5.13 ping statistics ---\n4 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3016ms\n\n~$ nova ssh test02\nERROR: No public addresses found for 'test02'.\n\nany ideas what to check ?\n\nA: You need to associate your ubuntu-net with your instances and associate a floating IP.\n", "Q: Remote Desktop to an SMB address from Linux Ubuntu 14 I'm trying to connect via Remote Desktop (I need to access IE browser) to an address like smb://e-xx-10000.mydomain.com from my Linux Ubuntu 14.\nIs there a specific software to do that?\nI tried to use rdesktop or Remmina, but there are no options to connect to a smb://machine.\n\nA: When entering the server name, do not include the smb://\nI hope this helps\n", "Q: How do I use Boot Repair Disk? Apologies. Total linux noob but I have been struggling trying to get Ubuntu to run for a couple of days now. I have read lots and tried lots of different things but I still can't get it to boot. \nWindows XP loads automatically, without giving me the option to choose my OS. \nI have tried to use Boot Repair Disk but I get a message that I have to use a Live USB but as far as I understand, I AM using a Live USB. \nCan anyone suggest what I need to do differently? \nThanks\n\nA: It sounds like you don't have your computer configured to boot from the DVD drive or USB stick that you have Ubuntu on.  When your computer first powers on, you press a special key to bring up the computer's boot menu.  Here's a web page that can show you what key to press for your computer model.  Press that key several times when the computer first boots, and you should be taken to a menu that asks you if you want to boot from the hard drive, the DVD drive, or the USB device.  Pick the choice that has the Ubuntu live disk or live USB stick, and you'll soon be trying Ubuntu.  (The boot repair tool is a tool to use after something goes wrong with a Ubuntu installation, which is a fairly rare problem.)\nSome computers have booting from any device other than the hard drive turned off in the BIOS, but this is fairly rare.  In that case you must go into the BIOS setup menus and configure your computer to allow booting from the DVD drive or your USB stick.  You get into the BIOS setup menus by pressing another key as the computer is first booting; the same web page I mentioned earlier will tell you which one.  In the BIOS setup menus you can also change the default boot order, so if you wanted you could make the computer always try to boot from the DVD drive or USB stick first, before trying to boot from the hard drive.  I wouldn't recommend that though, because if you leave a Windows DVD in the drive your computer could boot into the Windows installer by accident!  Yikes!\nGood luck, and let us know how it goes.\n", "Q: How would i get ubuntu on a pc I'm building? I want to build a pc for gaming using parts, but I don't like windows 10 and I don't want to pay 100 dollars for it. How would i get ubuntu on it?\n\nA: Use Nvidia cards and intel processors, AMD is cheaper and good quality but it might not work as expected in the latest Ubuntu which is Ubuntu 16.04LTS(Long Term Support)because 16.04LTS will support open source drivers only which will let AMD stuck at OpenGL 4.1. \nwait till Ubuntu 16.04LTS gets fully released and get Nvidia cards and intel processors.\nremember Linux is just starting in the gaming section and you might not find alot of AAA titles to play on Ubuntu while there are many ports that dont work like expected (batman was a disaster in windows and Linux).\n\nA: Its very simple actually. Here's how I go about it.\n1 - Download the .iso of version you want to install. (making sure its compatible with your equipment, arm vs 32 vs 64 bit)\n2 - Burn the ISO to disc (various tools exist to do this easily, can burn to USB too)\n3 - Boot the PC, on which the OS will be installed, to the disc you just burned. \n4 - Select Install. (I recommend making sure your new PC is plugged into internet) Following the prompts you can set it as you prefer. Drive space, keyboard layout, location, etc...\n5 - Setup your Login credentials. Let the install finish. \nOnce its done, it should reboot your PC after ejecting your burned Disc. At which point the OS should be successfully installed, and the PC should now boot to the Ubuntu flavor you installed. \nEnjoy.\nHeres the link for the official walkthrough\nhttp://www.ubuntu.com/download/desktop/install-ubuntu-desktop\n", "Q: Email Client which runs in background and notifies when email arrives I am new in Ubuntu and currently running 16.04-beta2 release. I have configured Thunderbird Email client for everyday use and the only problem with Thunderbird is that it doesn't run in background and I get no notification when any mail arrives. I have to minimize Thunderbird and check time to time to get notified about my mail which is pretty disgusting and time consuming.\nSo, I am searching for an Email Client which works great with Ubuntu, runs in background when minimized and give notifications when mail arrives. Any kind soul to help me out with proper information?\n\nA: No need to quit Thunderbird. It's got plenty of addons for almost everything and there's a nice one just for your case:\nhttps://addons.mozilla.org/pl/thunderbird/addon/mailbox-alert/\nIt's got configuration for everything you might need. You can set a number of seconds to display that notification window, even large one for like 12 hours.\nAlso check MinimizeToTray addon.\n", "Q: Is the final beta good enough for setting up a production server? There is a new server, which would benefit from a lot of the newer packages coming with 16.04 as well as the newer kernel. As it will be taking over most tasks from the old one by the end of the month, a call needs to be made on the OS.\nRunning for a few days with 16.04 beta while all the stuff is being set up and configured on it, I gathered from various answers that it might still be buggy and will need many more upgrades while in beta, which is acceptable.\nThe only things I have not found an answer to is:\n\n\n*\n\n*Will the additional package upgrades have any impact on performance down the line? (I understand that the system should be in a more pristine state compared to post upgrade from 14.04, hence less dependency chaos and rubbish)\n\n*Could this lead to unforseeable security issues (kernel, etc)?\n\n*Would installing 14.04 and backporting the new packages be the better solution?\n\n\nA: \nIs the final beta good enough for a production server?\n\nNo. A beta is -never- good enough for a live system. \n\nWill the additional package upgrades have any impact on performance down the line? (I understand that the system should be in a more pristine state compared to post upgrade from 14.04, hence less dependency chaos and rubbish)\n\nThe beta will have a daily download so if internet access is important that will have some impact. \"impact on performance\"... doubt we can answer that without knowing your hardware. If you run your server from a telephone 4G internet yes it will, if it is of a T1 ... not likely. But you also run the risk of introducing a bug during an update that kills your setup.\n\n\n*\n\n*Could this lead to unforseeable security issues (kernel, etc)?\n\n\nNo. You will run a risk during the beta period. But patches -improve- your system. Patches should not introduce other problems. \n\n\n*\n\n*Would installing 14.04 and backporting the new packages be the better solution?\n\n\nYes. But not the best option. I would set up the machine and take 2 weeks for testing. That way it is not a production server and it will be when 16.04 is released. We already have 16.04 set up in our google cloud. As soon as we see the updates fase out (probably 1 or 2 weeks after the 21st) those cloud instances become the live versions (we are setting our new systems up with http2 and mysql 5.7).\n\nA: I believe that for a server you would be better to not only use an LTS version but for stability rather than cutting edge use an LTS version that has been tested over some time. Not the newest LTS (out for new release in a week) that has not been well and truly tested in the marketplace.\nAs an example look at Deamhost, which has hosted my website for many years:\n        #                                    m                 \n  mmm   #   m  m   m  mmmmm   mmm    mmm   mm#mm   mmm    m mm \n #   \"  # m\"   \"m m\"  # # #  \"   #  #   \"    #    #\"  #   #\"  \"\n  \"\"\"m  #\"#     #m#   # # #  m\"\"\"#   \"\"\"m    #    #\"\"\"\"   #    \n \"mmm\"  #  \"m   \"#    # # #  \"mm\"#  \"mmm\"    \"mm  \"#mm\"   #    \n                m\"                                             \n               \"\"                                              \nLast login: Thu Apr 14 15:33:39 2016 from 124.149.186.113\nxxxxxxxx@skymaster~$ cat /etc/lsb-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=12.04\nDISTRIB_CODENAME=precise\nDISTRIB_DESCRIPTION=\"Ubuntu 12.04.5 LTS\"\nxxxxxxxxxx@skymaster~$ \n\nAnd Precise Pangolin still has support until April 2017. Some thoughts on this Dreamhost blog about backporting, stability and other issues:\nChange Is In the Air’ – DreamHost Upgrades\nI am not advocating that you should use an LTS that is this old, my recommendation is to use Trusty, which has support until April 2019.\n\nA: You're probably better off waiting until the 21st if you want 16.04. It is still in beta, and it could be hard to find support if something goes wrong.\nHowever, if you really can't wait, 16.04 has reached its final freeze date, and the release candidate has been released today. I don't believe there are many changes (if any) in the week before the release.\nIt's ultimately up to you. You could risk somewhat unlikely (but very possible) issues if you install now, or you could wait a week for the stable release.\nAlso remember that the final 16.04 could be a little buggy still, but these issues will be fixed or lessened in future minor upgrades (16.04.1, 16.04.2, etc).\n", "Q: pdf is printing 10 pages off I have a data-sheet for a motherboard I am working with:\nI tried to print page 136, but 126 came out of my printer.\nI thought ok, sometimes the pages don't match up exactly between the document and the pdf. In this case they did. So I tried printing again, the same thing happed, and I got page 126. So then I tried printing page 146, which gave me page 136.  I did get what i want, but this shouldn't be happening. ..\nwhats wrong here?\nI am using Ubuntu mate 15.10, with HPLIP, and the Atril Document Viewer 1.10.2\nhas anyone heard of something like this, and or know a fix?\n\nA: The document you linked doesn't count the table of contents, the toc is numbered in roman numerals and then the pages start with number 1. If you use evince, it shows both real count as the \"pdf count\":\n\n", "Q: GLX extension missing, need NVIDIA drivers, login loop I promise this is not a duplicate question. \nI'm running Ubuntu 14.04LTS, on a custom-built desktop with an NVIDIA GTX 970 GPU.\nSince installing Ubuntu the second time (long story involving windows 10 breaking grub), I couldn't access the \"Display\" section of system settings at all. The default drivers would not allow me to use both of my monitors. Two days ago, I followed this fix (the one with 50+ votes), which requires the installation of NVIDIA drivers. Until now I could log in just fine with the proprietary drivers (I restarted and switched to Windows a couple of times), but now Ubuntu is entering a login loop whenever I try to start up. I checked this thread for a solution and tried pretty much every suggestion there. What I found was that there was indeed an error in xsession-errors, but it wasn't related to a sytnax error in .profile or .bash_profile, it was the following: \nXlib: extension \"GLX\" missing on display \":0\".\nXlib: extension \"GLX\" missing on display \":0\".\n\nand then several statements about things being terminated. I checked this thread for that error, and it said the only way to fix it was to remove the nvidia drivers. But, I need the nvidia drivers for my original problem with dual monitors. I seem to be in a loop.\nSo, the question is: Does anyone know of a workaround I could use to get both monitors working without the nvidia drivers which subsequently cause a login loop? It seems almost unbelievable that this would not be possible.\n\nA: Okay, I got it figured out. This is a touch embarrassing, as it's kind of obvious. If you run into the same problem as me, be absolutely sure that you saved xorg.conf with the line: \nsudo nvidia-xconfig\n\nBesides that, if you're having trouble with dual monitors / drivers in Ubuntu, you can follow pretty much exactly the steps outlined in the question. Hope this helps somebody else!\n", "Q: How do I get Lame I downloaded Asunder file converter but an error occurs saying I need to have Lame installed. I went to the Ubuntu Software Center but there is nothing there called Lame. It might be under a different name but I have no clue what it might be. I am running 10.04 Lucid. Any help appreciated.\n\nA: You'll want the packages lame, twolame, libmp3lame0 and libtwolame0 installed (on most Ubuntu versions the first two will automatically install the second two).\nIt's likely that these packages were not in the older version of Ubuntu you have.  You need to upgrade, for various reasons.\n", "Q: Multiple monitors in Lubuntu I have two monitors on my computer and the right hand monitor is the main display, but Lubuntu always puts the main display onto the left hand monitor. There aren't enough settings in the Monitor Settings window to change the main display onto the right hand monitor. How do I do this? I have Mint on some other computers and this is easy with their tools so it must be supported in the underlying X server? I have an AMD graphics card with the default driver.\nAlso is it possible in LXDE to have panels on both monitors instead of just the main display monitor? \n\nA: Install arandr from the repos and you'll have a GUI to configure the multiple monitors. I don't know about the panel part of the question.\n\nA: To establish dual monitors with LXDE, install Arandr from Synaptics. Arandr can set-up placement, orientation and resolution for each monitor. Before saving, set up the geometry of any horizontal panels. For a bottom panel across both monitors, align the bottoms of the displays; for a top panel, align the tops. A second horizontal panel can be only set-up on the display whose unaligned edge is outermost, since any extension onto the smaller display will be hidden. Otherwise, the horizontal placement and geometry in general can be achieved in the usual way.  See http://lxlinux.com/#14 for more details.\n", "Q: Ubuntu Touch - Missed calls notifications When I have a missed call, I receive the missed call notification all ok. However, when I click on the notification, I only have the option to send a text (SMS) back to the person I missed the call off.\nA far better idea would be to allow users the option of sending a text or calling the person back from the notifications window.\nIs there a setting I can change to do this, so I can call them back from here? I have looked up on this and cannot see anything.\n\nA: Tapping on the missed calls notification opens two options: \"Message\" and \"Call back\". Alternatively you can tap the dialer icon (in red circle). It will take you to the dialer app with the caller's number typed in.\n\n", "Q: Display doesnt startup after lock Whenever I'm not using the laptop I turn the screen off using the Fn+F2 button which eventually reduces the screen brightness to 0. By default the lock screen should start in 10 minutes, after 10 minutes, when I hit Fn+F3 to increase the brightness, the display doesn't start and I have to forcibly shut it down and restart. How do I fix this?\n\nA: Don't reduce the brightness.\nInstead try to hibernate your laptop when not in use.\nClose the flap and when u open it,laptop will automatically wake up.\n", "Q: man page of swapon doesn't match with what I am seeing I am playing around with swap and added my own swap partition. but when I do I noticed something odd.\ntest@ubuntu:~/5Gdisk$ cat /proc/swaps\nFilename   Type            Size    Used    Priority\n/dev/sda5  partition       4192252 0       -1\n/dev/sdb2  partition       5242876 0       -2\n\nand my /etc/fstab\nUUID=<bla bla> none  swap sw 0 0\n/dev/sdb2      swap  swap sw 0 0\n\nsdb2 is the swap partition that I added.\nI also checked the man page of swapon, and it says for priority it should be from -1 to 32767. So why does my swap parition has a priority of -2?\nThis is ubuntu 15.\nThanks\n\nA: From man swapon it reads:\n   -p, --priority priority\n          Specify the priority of the swap device.  priority  is  a  value\n          between  0  and  32767. Higher numbers indicate higher priority.\n          See swapon(2) for a full description  of  swap  priorities.  Add\n          pri=value  to the option field of /etc/fstab for use with swapon\n          -a.\n\nso, that means in your /etc/fstab you would have your lines read as follows:\nUUID=<bla bla> none  swap sw,pri=20 0 0\n/dev/sdb2      none  swap sw,pri=10 0 0\n\nI just used the priorities of 20 for the first one since it reads that the \"Higher numbers indicate higher priority\" in the manpage, then 10 for the lower priority.  Options in the /etc/fstab file are separated by commas ,.\nTechnically, -1 is higher than -2 so you are probably OK.\nHope this helps!\n", "Q: How Can I Change X's TTY How can I change X's tty from Ctrl-Alt-F7 to another F Key? I have only 4 ttys so I want X on the fifth.\n\nA: In Ubuntu 18.04.04, the xorg tty changes from tty1 to tty7 when I replace the display manager gdm3 by lightdm. To replace the display manager, I run\nsudo apt-get install lightdm\n\nLikewise, the xorg tty changes from tty7 to tty1 when I replace lightdm by gdm3.\nYet another approach involves editing /etc/X11/xinit/xserverrc. In xserverrc, replace the line\nexec /usr/bin/X -nolisten tcp \"$@\"\n\nwith\nexec /usr/bin/X -nolisten tcp \"$@\" vt$XDG_VTNR\n\nwhere $XDG_VTNR specifies the number of your tty.\n", "Q: TTY Font Resets on Reboot My TTY font doesn't persist over a reboot. Even after running sudo dpkg-reconfigure console-setup and choosing a font, if I reboot, it resets to whatever ugly thing the default is. What do I do to stop this?\n\nA: It seems setupcon doesn't run automatically, so you'll have to either run it manually or put it in your .(ba|z|fi|etc)shrc or something like that. If you use Byobu, put it immediately before the Byobu line and add 2>/dev/null to keep it from complaining every time you open a new shell.\n", "Q: Error while installing Adobe Acroread in Ubuntu 15.10 I am getting following error while installing Adobe Acroread in Ubuntu 15.10:\nxyz@abc:~$ sudo dpkg -i /home/shiva/acroread-bin_9.5.5-1raring1_i386.deb \n(Reading database ... 442228 files and directories currently installed.)\nPreparing to unpack .../acroread-bin_9.5.5-1raring1_i386.deb ...\nUnpacking acroread-bin:i386 (9.5.5-1raring1) over (9.5.5-1raring1) ...\ndpkg: dependency problems prevent configuration of acroread-bin:i386:\n acroread-bin:i386 depends on libatk1.0-0 (>= 1.12.4).\n acroread-bin:i386 depends on libc6 (>= 2.3.6-6~).\n acroread-bin:i386 depends on libfontconfig1 (>= 2.9.0).\n acroread-bin:i386 depends on libgcc1 (>= 1:4.1.1).\n acroread-bin:i386 depends on libgdk-pixbuf2.0-0 (>= 2.22.0).\n acroread-bin:i386 depends on libglib2.0-0 (>= 2.12.0).\n acroread-bin:i386 depends on libgtk2.0-0 (>= 2.24.0).\n acroread-bin:i386 depends on libidn11 (>= 1.13).\n acroread-bin:i386 depends on libpango1.0-0 (>= 1.14.0).\n acroread-bin:i386 depends on libstdc++6 (>= 4.1.1).\n acroread-bin:i386 depends on libx11-6.\n acroread-bin:i386 depends on libxext6.\n acroread-bin:i386 depends on libxml2 (>= 2.6.27).\n acroread-bin:i386 depends on libxt6.\n acroread-bin:i386 depends on zlib1g (>= 1:1.1.4).\n\ndpkg: error processing package acroread-bin:i386 (--install):\n dependency problems - leaving unconfigured\nProcessing triggers for gnome-menus (3.13.3-6ubuntu1) ...\nProcessing triggers for desktop-file-utils (0.22-1ubuntu3) ...\nProcessing triggers for bamfdaemon (0.5.2~bzr0+15.10.20150627.1-0ubuntu1) ...\nRebuilding /usr/share/applications/bamf-2.index...\nProcessing triggers for mime-support (3.58ubuntu1) ...\nProcessing triggers for man-db (2.7.4-1) ...\nErrors were encountered while processing:\n acroread-bin:i386\n\nCould anyone help sort out this issue?\nThanks in advance.\n\nA: You could certainly do the following:\nsudo apt-get -f install\n\nwhich might address the dpkg error:\n dependency problems - leaving unconfigured\n\nBut it looks as if you are installing an Acrobat Reader deb package from Raring Ringtail on to your Wily Werewolf installation. Try the following, which I have tested on Trusty not Wily. First some required files (needed on 64bit systems):\nsudo apt-get install libgtk2.0-0:i386 libnss3-1d:i386 libnspr4-0d:i386 lib32nss-mdns* libxml2:i386 libxslt1.1:i386 libstdc++6:i386\n\nas well as the gdebi installer:\nsudo apt-get install gdebi\n\nand then download and install the reader itself directly from the adobe website:\nwget http://ardownload.adobe.com/pub/adobe/reader/unix/9.x/9.5.5/enu/AdbeRdr9.5.5-1_i386linux_enu.deb\nsudo gdebi AdbeRdr9.5.5-1_i386linux_enu.deb\n\nThis tested nicely on Trusty Tahr and I have no doubt will work on Wily:\n\nReferences:\n\n\n*\n\n*Quick Tip: Install Adobe Reader in Ubuntu 14.04 Trusty\n", "Q: Lenovo 500S-14ISK Linux compatibility I would like to buy a Lenovo 500S-14ISK, but I can't find any reviews on it regarding linux compatibility. Ubuntu does not seem to have certified this laptop (yet)?\nAnybody had experience with this model? Since it's a lenovo, my gut says it will work with Ubuntu/Mint out of the box, but I just want to be sure.\n\nA: I have this model and I'm running Ubuntu 16.04. Most things work fine except there are some minor issues with using the hotkeys (not all of them will work properly).\n", "Q: Set Duplicity to do not follow symbolic links \nCurrently duplicity supports (...) symbolic links (...) but not hard links. \n\nhttp://www.nongnu.org/duplicity/duplicity.1.html\nIt is not clarified but most likely it means that soft links are followed. For obvious reasons I want to avoid backuping ~/Desktop/temporary_symbolic_link_to_hard_drive_with_gbs_of_data and other symbolic-link related problems.\nHow can I disable following symbolic links by duplicity (like --no-dereference option in diff command)?\nI know that I can use --exclude option but it requires generating backup command by script detecting symbolic links but it would be overcomplicated and fragile.\n\nA: Duplicity now supports this (in version v0.7.11 and up) via the --copy-links option. See the duplicity man page.\nNote that this a later version of duplicity than standard Ubuntu trusty or xenial packages. You need to install duplicity from upstream e.g. ppa:duplicity-team/ppa\n", "Q: Loss of access to data after reinstalling Ubuntu 15.10 and Windows 10 I had Ubuntu 15.10 along with Windows 10 pro.\nAs my Ubuntu had certain issue of function and booting problems, I decided to again install the Ubuntu 15.10.\nI accidentally selected the option \"Use LVM for the new Ubuntu installation\".\nAfter installation, when the boot loader started it didn't showed me Windows 10 in an option. When I started Ubuntu my hard disk was not detected and the only folder I could see was the Ubuntu system file named  'Computer'.\nSo I ran the setup of Windows 10 again.\nWhere a dialog box appear which said that there were only two partition. First partion system reserved of about 250MB(Partition 01) and other local drive of 465GB(Partition 02). And I couldn't install windows 10 so I made the partition again and then installed windows 10. Currently I am having windows 10.\nInitially I had 4 partitions(Local Disk C,D,E,F first three of 116 GB and remaining space) Now I have 3 Partition( Local disk C(100 GB) Local disk D(200 Gb) and Local disk E(remaining space) ).\nCurrently I can only access Local disk C which contains windows system and program files{.While making new partition i have just resized the partition. I have not formatted the disk while resizing the partition}\nIn order to use other space I need to format the drives to use it.\nBut I don't want to format the disk as it contained many important files in it.\nIs there a way to recover all my data without formatting?\n\nA: Since you have created new partitions on top of your old ones and have written data to it (installed Windows 10), it might be a little bit difficult to recover your files.\nPreamble\nIf you want to be extremely safe and in order not to tamper directly\nwith the data of your drive case something bad happens in the process, you can create an exact copy of your drive and tamper with that instead. Of course you will need a spare hard drive of at least 500GB size and some good piece of software for the\ncloning. I suggest using the dd command which copies the whole disk into another disk including unallocated space. You can execute this command in the Ubuntu Live environment. A usage example for cloning disk to disk is:\ndd if=/dev/sda of=/dev/sdb\n\nwhere /dev/sda is the source hard disk and /dev/sdb is the destination.\nBE CAREFUL: if you enter the wrong hard drive identifiers, disaster might occur. Use :\n sudo parted --list\n\n\nin order to list your hard drives and their identifiers.\nPlan A\nFirst you can try to recover your initial partitions using some partition management software. A good free and open source tool I know is testdisk. To run it you will have to boot from a Ubuntu 15.10 live CD or USB. After booting using Ubuntu live, open a terminal (Ctrl+Alt+T) and enter the above command to install it:\nsudo apt-get install testdisk\n\nHere is a quick guide that will help use teskdisk.\nIf it succeeds in finding your old partitions, then mount them and copy your files to an external drive or a partition other than the partitions that you want to recover your files from.\nPlan B\nIf this technique does not work, there is a bit slower one, using photorec. If you have tried Plan A before proceeding to Plan B, then photorec had been already installed when you installed testdisk. If not, then follow Plan A first please. Photorec will try to recover files from the partitions you choose it to do so, restoring them to another partition other than the partitions that you want to recover your files from. To learn how to use it see this quick guide.\nPlan C\nThere is no Plan C! :P\nIf your files have not been overwritten in disk by other files, there's a great chance that following the above instructions will lead you to recovering your files.\n\nA: From your description it seems that your hard drive is 500GB. Before you install Windows 10 there is a partition of 465GB, which doesn't sound you did the Ubuntu installation right. That could probably have overwritten your drives.\nAlso when you reinstall Windows 10, it doesn't know how to deal with Linux file systems. It cannot possibly resize the partition without knowing how not to mess up the data inside.\nTry pgmank's solution and wish for the best. Just remember reinstalling isn't always the solution. And always backup before you touch partitions.\n", "Q: Can't set up built-in PHPStorm server I have PHPStorm 2016.1. Jetbrains have a tutorial for built-in server setup, but it's only for Windows. I tried adapting it, but no success - the browser can't connect. Here are my settings:\n\n\n\nWhen I run it from phpstorm, it says: \n/usr/bin/php7.0 -S localhost:80 -t \"/home/alexiy/PHPStorm local server\"\n[Fri Apr 15 09:04:51 2016] Failed to listen on localhost:80 (reason: Permission denied)\n\nProcess finished with exit code 1\n\nA: Nevermind. It was an easy fix - just changed the port to 8080.\n", "Q: What are these extra output lines in bash? It's for sometime that these lines can be seen after running a command (randomly):\n[1]-  Done                    wget -c http://downloads.sourceforge.net/project/zorin-os/9/zorin-os-9-core-32.iso?r=http%3A%2F%2Fzorinos.com%2Fdownload9.html\n[2]+  Done                    ts=1460659842\n\nFirst line is the command itself & it's not happening always. But from time to time a command line app stops without returning to command line, until I press enter; which shows these lines.\nMy system did not behave like this until a week ago. Is this a problem?\n\nA: You have probably issued a command like this:\nwget -c http://downloads.sourceforge.net/project/zorin-os/9/zorin-os-9-core-32.iso?r=http%3A%2F%2Fzorinos.com%2Fdownload9.html&ts=1460659842&something-else\n\nThat command contains the special character &, which is used to run multiple processes concurrently. That command is being interpreted as three (or more) commands:\n# First command (the one that you see after [1]):\nwget -c http://downloads.sourceforge.net/project/zorin-os/9/zorin-os-9-core-32.iso?r=http%3A%2F%2Fzorinos.com%2Fdownload9.html\n# Second command (the one that you see after [2]):\nts=1460659842\n# Third command (the one which output should be above the \"Done\" lines):\nsomething-else\n\nHere's an example that may help you understand better:\n# Here I'm launching three 'echo' commands, the first two in background, the third in foreground\nandrea@andrea-laptop:~$ echo first & echo second & echo third\n[1] 5033    # This is bash telling me that the first process was started with job number 1 and PID 5033\nfirst       # This is the output from the first process\n[2] 5034    # This is bash telling me that the second process was started with job number 2 and PID 5034\nthird       # This is the output from the third process\nsecond      # This is the output from the second process\nandrea@andrea-laptop:~$ \n[1]-  Done                    echo first    # This is bash telling me that the first background job has quit\n[2]+  Done                    echo second   # This is bash telling me that the second background job has quit\n\nYou should properly quote URLs to avoid this and other nasty effects:\nwget -c 'http://downloads.sourceforge.net/project/zorin-os/9/zorin-os-9-core-32.iso?r=http%3A%2F%2Fzorinos.com%2Fdownload9.html&ts=1460659842&something-else'\n\n", "Q: Installing linux on ROG GL552VW (Beginner) I've been trying to install Ubuntu GNOME for the past 7 hours, on my new ROG GL552.\nAt the beginning, I couldn't even install it until I found this post:\nhttps://rog.asus.com/forum/showthread.php?81702-Linux-installation-in-ASUS-ROG-GL552VW-DH71\nI added the \"nouveau.modeset=0 tpm_tis.interrupts=0 acpi_osi=! acpi_backlight=native i915.preliminary_hw_support=1 idle=nomwait\" just before the --- part when editing the installation, and the installation ran smoothly.\nAfter that, I couldn't boot into the system still because the same commands need to be added when booting, and it took me a little while to figure out where in the code I need to add them - since I'm pretty much a complete beginner.\nAfter adding that line in the correct place, the system booted (although the touchpad functions are very limited) and I edited /etc/default/grub to contain the same commands.\nI tried to keep following that forum post to try and understand how to make my Ubuntu work like it's supposed to - also with correct usage of my video card (gtx 960m), so I installed bumblebee and uncommented the nvidia driver section.\nrebooted the system and then the system doesn't boot yet again...\nI really want to make Linux my main operating system but this really makes me want to give up. I don't understand half of the things I'm trying to do. I wanted to install the Ubuntu GNOME and really start learning Linux in and out but I can't even install it properly on this computer.\nDoes anyone have any tips? Any guide for a complete beginner on installing Ubuntu on this machine?\nThank you for any answer and I hope I can start using Linux\n\nA: I carried out a fresh install of 16.04 on my ASUS GL552VW.\nThe only additional GRUB parameters I entered (for installation and normal boot) were:\nnouveau.modeset=0\n\nTo stop Nouveau from taking over.\nOnce I'd installed the nVidia 361.42 drivers, through the Additional Drivers tab in Software Updater, I had to disable Secure Boot. (Secure boot stops unsigned kernel modules loading)\nWith those settings, everything works. Touchpad, Skylake support, nVidia graphics @ 1920x1080, Wifi, Bluetooth, keyboard backlight.\nInstallation of 16.04 is much less hassle than previous versions.\n\nA: Bumblebee is deprecated, likely the guide you were following is outdated, the Nvidia drivers come with everything you need to manage your multi GPU laptop.\nFirst remove any installed driver and Bumblebee\nsudo apt-get purge bumblebee nvidia*\n\nNow reboot\nsudo reboot\n\nNow install the latest Nvidia driver from the repository (if you can't reboot to Ubuntu use recovery mode)\nsudo apt-get install nvidia-352\n\nThis includes nvidia-prime that you can use to control your GPU's, you can find it in the application nvidia-settings.\n\n\"how can I check if the whole system works correctly?\"\n\nAs you mean check what drivers are in use, you can check the application additional drivers, this is preinstalled in Ubuntu Gnome.\n", "Q: getting warning when i use sudo apt-get update command I am getting error when i use sudo apt-get update command \nGet:58 http://us.archive.ubuntu.com wily-backports/multiverse Translation-en [28 B]\nGet:59 http://us.archive.ubuntu.com wily-backports/restricted Translation-en [28 B]\nGet:60 http://us.archive.ubuntu.com wily-backports/universe Translation-en [1,390 B]\nFetched 32.5 MB in 23s (1,379 kB/s)                                            \nReading package lists... Done\nW: Duplicate sources.list entry http://dl.google.com/linux/chrome/deb/ stable/main amd64 Packages (/var/lib/apt/lists/dl.google.com_linux_chrome_deb_dists_stable_main_binary-amd64_Packages)\nW: You may want to run apt-get update to correct these problems\n\nI am not familiar with Ubuntu if any one know how to solve please help me\nI'm using 64bit-Ubuntu (15.10)  ;\nThis is my source list look like:\n###### Ubuntu Main Repos\ndeb http://us.archive.ubuntu.com/ubuntu/ wily main restricted universe multiverse\ndeb-src http://us.archive.ubuntu.com/ubuntu/ wily main restricted universe multiverse\n\n###### Ubuntu Update Repos\ndeb http://us.archive.ubuntu.com/ubuntu/ wily-security main restricted universe multiverse\ndeb http://us.archive.ubuntu.com/ubuntu/ wily-updates main restricted universe multiverse\ndeb http://us.archive.ubuntu.com/ubuntu/ wily-backports main restricted universe multiverse\ndeb-src http://us.archive.ubuntu.com/ubuntu/ wily-security main restricted universe multiverse\ndeb-src http://us.archive.ubuntu.com/ubuntu/ wily-updates main restricted universe multiverse\ndeb-src http://us.archive.ubuntu.com/ubuntu/ wily-backports main restricted universe multiverse\n\n###### Ubuntu Partner Repo\ndeb http://archive.canonical.com/ubuntu wily partner\ndeb-src http://archive.canonical.com/ubuntu wily partner\n\n###### Ubuntu Extras Repo\n#deb http://extras.ubuntu.com/ubuntu wily main\n#deb-src http://extras.ubuntu.com/ubuntu wily main\n\n\nA: Look at your /etc/sources.list (or the files in /etc/sources.list.d) and remove or fix those lines that cause the error. \nThis answer should help.\nHow can I fix a 404 Error when using a PPA or updating my package lists?\n\nA: This happens a lot when installing Chrome via the Google repository. The reason for this is that most people add the source manually as a lot of websites do suggest is.\nProblem with this is that after installing Chrome it automatically adds and configures /etc/apt/sources.list.d/google-chrome.list causing a duplicate. \nThe fix is simply removing the manual repository you added and the problem should be gone. I would recommend checking /etc/apt/sources.list.d/ for the second duplicate. In my case the file was called google.list.\n", "Q: My AMD Radeon graphic card is not working on 16.04 I have installed Ubuntu 16.04 final beta on a Dell Inspiron 15 5000 Series (Intel(R)) - 5559. \nThis laptop has a AMD Radeon(TM) R5 M335 4GB DDR3 GPU.\nI am unable to tell if it is being used or not. Indeed, the open source drivers module seems to be loaded:\n$> lsmod  | grep radeon\nradeon               1511424  1\ni2c_algo_bit           16384  2 i915_bpo,radeon\nttm                    98304  1 radeon\ndrm_kms_helper        139264  2 i915_bpo,radeon\ndrm                   360448  9 ttm,i915_bpo,drm_kms_helper,radeon\n\nhowever, I expected to see it listed in lspci, while there only seems to be the integrated intel card:\n$> lspci | grep -i graphic\n00:02.0 VGA compatible controller: Intel Corporation Sky Lake Integrated Graphics (rev 07)\n\nAlso, I have installed the radeontop utility but it outputs:\nCan't find Radeon cards\n\nI don't know if it's relevant, but OpenGL seems to be working:\n$> glxinfo | grep direct\ndirect rendering: Yes\nGL_ARB_direct_state_access, GL_ARB_draw_buffers, \nGL_ARB_draw_indirect, GL_ARB_draw_instanced, \nGL_ARB_map_buffer_range, GL_ARB_multi_bind, GL_ARB_multi_draw_indirect, \n\nbut still I don't know if it's the intel or the radeon card taking care of it.\nI have never tried older versions of ubuntu on this laptop, so I have never tried the - now deprecated - proprietary drivers.\nHow can I tell if my graphic card is working? If it's not, how can I make it work again?\n\nA: To tell if your card is working, do a xrandr --listproviders. Both cards should be visible. \nIf you want to use it, the best way is xrandr --setprovideroffloadsink radeon Intel, with it, you can use your discrete card for the applications who need it the most (for example games, 3D modellers...) by prepending the DRI_PRIME=1 environment variable:\nDRI_PRIME=1 glxinfo | grep \"OpenGL renderer\" should give an output of OpenGL renderer string: Gallium 0.4 on AMD <platform>.\n", "Q: Current version of `mitmproxy` for 14.04 I need to tap into some https traffic for development purpose. I use charles and mitmproxy for that, the later being much more convenient. \nI do have some issues though, there appears to be a problem with the buidin web UI in the version of mitmproxy offered for systems based on Ubuntu-14.04. I have to manually install the mitm-certificate which is a pain for many devices and changing certificates. So I would like to upgrade from version 0.92 to some current version like 0.15 or 0.17. However all packages I can find of those current versions are only available for newer Ubuntu versions. I don't really understand Ubuntu very well, I mostly work with the openSUSE distribution with its unbelievable wealth of good packages in the OBS. So I am kind of frustrated with the situation for my Ubuntu based systems. \nDoes anyone have a hint how to get a current version of mitmproxy installed on an Ubuntu-14.04 based system? \n\nA: Apparently there really is no packaged version of mitmproxy available for Ubuntu-14.04 in a more or less current version. \nI managed to install it manually following the documentation on github. It was a bit of a pain, since I had to install and setup lots of python stuff. but finally I managed to get a mitmproxy running in version 0.18. As expected it did not show the same issues as that really old version which is packaged for Ubuntu-14.04 (version 0.9.2). \nI only post this to not let this question unanswered, though this does not answer the original question for a less outdated package of mitmproxy. \n", "Q: MAC address spoofing failing I've been trying to spoof my MAC address for a while now, because I want my brother's laptop to be using my data allowance at college (I don't use much bandwidth, most of mine goes to waste) and for some reason there isn't an option at their internet access site to un-register a device, and it can only be registered to one person at a time. Here is what I have tried (the network interface in question is named wlo1):\nFirst I tried the simple approach. I clicked on the wireless icon in the top-right corner, clicked \"edit\" connections, made a new connection with the same SSID but with a different MAC address in the \"cloned MAC Address\" field. I saved it and attempted to connect to it, but after about a minute of failed attempts it gave up and connected to it using the old MAC address.\nThen I tried the CLI approach. I found that no matter what, any time that network-manager started, my changes made with ifconfig were reset. Additionally, all changes made with ifconfig while network-manager was running were completely ignored. sudo ifconfig wlo1 hw ether XX:XX:XX:XX:XX:XX would change it (according to ifconfig wlo1) despite giving an error message (SIOCSIFHWADDR: Too many open files in system\n, and YES I've checked ulimit and it isn't a problem with that), but would have no impact on network-manager, and any attempt to restart network-manager resulted in all changes being reset. Finally, thinking that a CLI utility dedicated to this task should be up to it, I tried the following:\nsudo service network-manager stop\nsudo ifconfig wlo1 down\nsudo macchanger -a wlo1\nsudo ifconfig wlo1 up\nsudo service network-manager start\n\nsudo macchanger -a wlo1 failed with the output:\nCurrent MAC:   <random MAC address from previous attempt> (Action Technology (SZ) Co., Ltd)\nPermanent MAC: <consistent same thing as always> (unknown)\n[ERROR] Could not change MAC: interface up or insufficient permissions: Too many open files in system\n\nI'd like to remind you once again that I did check ulimit -n, and it is not a problem there. \nSo, in summary: attempts at manually changing with ifconfig and other tools think they fail, but apparently actually change the MAC address, without having any effect whatsoever on my connections. network-manager can't successfully spoof a MAC address because... I have no idea. It silently fails to connect and I'm too dumb to know where to look for error messages. I have no clue why something this simple is so difficult for my software to do. Frankly, I suspect that this is Broadcom bullcrap at it again, in which case my options amount to kicking a cat or something. I hope that is not the case.\nRelevant information:\n\n\n*\n\n*Laptop: some HP thing of my brother's, Pavillion something with a 17\" screen.\n\n*Wireless Card: Broadcom BCM43142\n\n*Driver: WL\n\n*Distribution: Ubuntu 15.10\n\n*Patience: Very stretched. If I still had much patience, I wouldn't be writing this.\n\n\nHow can I try to find what is causing the problem and fix it? I don't know where the bugs lie, and frankly they seem to be everywhere. Is there a way to confirm or disprove that the issue lies in the driver? I did some looking-up and found that /var/log/syslog had TONS of <warn>  (wlo1): failed to set MAC address to XX:XX:XX:XX:XX:XX messages, where those X's are basically anything. It failed to set MAC addresses even to the same value it already was!\nIs the WL driver just especially suckish? Am I going to have to go talk to an administrator to try to get my brother's laptop un-registered?\nMore information: I successfully changed the MAC address of a different system, a desktop with an ethernet connection. I did this using the GUI provided by network-manager. As indicated above, the /var/log/syslog of the laptop with the problems is full of error messages indicating that network-manager is having problems setting MAC addresses. If it's at all possible, a solution that lets me keep using network-manager would be great. I'm not sure how to proceed without network-manager, and I am not sure whether changing the MAC address via ifconfig is actually changing it or only causing it to appear to be changed, since it gives an error message but still shows up with the new value. Should I try to get a working setup that doesn't use network-manager, or try to further track down the problems it has been having?\n\nA: If you wish to change mac address the simplest way is to use command\nsudo ifconfig wlo1 down\nsudo ifconfig wlo1 hw ether  xx:xx:xx:xx:xx:xx\nsudo ifconfig wlo1 up\n\nxx:xx:xx:xx:xx:xx - represents \"new\" mac address\nYou do not need macchanger. Try this:\n\n\n*\n\n*disconnect from wifi via NM\n\n*in terminal run command\nsudo ifconfig wlo1 hw ether  xx:xx:xx:xx:xx:xx\n\n\n*connect to wifi via NM\n", "Q: Error while installing Apache on 12.04 LTS On Ubuntu 12.04 LTS server I need Apache 2.4.5 or greater. I do this:\nadd-apt-repository ppa:ondrej/php5\napt-get update\napt-get install apache2\n\nBut when I run the last command I get:\nSetting up apache2 (2.4.20-1+deb.sury.org~precise+1) ...\nFeature bundle \"5.16\" is not supported by Perl 5.14.2 at /usr/sbin/a2enmod line 14\nBEGIN failed--compilation aborted at /usr/sbin/a2enmod line 14.\ndpkg: error processing apache2 (--configure):\n subprocess installed post-installation script returned error exit status 255\nErrors were encountered while processing:\n apache2\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nIt seems I need a newer version of Perl. How do I get that? I can't find a PPA with it.\n\nA: As I too was having this issue on some Ubuntu 12.04 servers I was maintaining, I decided to create a clone of Ondrej's PPA with the last known working Ubuntu 12.04 packages.\nhttps://launchpad.net/~nickmoline/+archive/ubuntu/php55\nSwitching to this PPA has allowed me to successfully install Apache and PHP again.\nthis locks Apache to 2.4.16 instead of the unworkable 2.4.20\nBefore I did this I contacted Ondrej who let me know that they will eventually fix the problem, but they don't have a timeframe on this, when they do, I'll go ahead and update my PPA and add a note that you can stop using it.\nFeel free to use it if it is helpful to you.\n\nA: You can always view the details of a PPA by visiting its page in Launchpad.\nThe PPA you are using can be found at https://launchpad.net/~ondrej/+archive/ubuntu/php5, and according to its maintainer, the PPA you added does not support Ubuntu 12.04.\nThis PPA contains latest PHP 5.5 packaged for Ubuntu 14.04 LTS (Trusty).\n\n[...]\n\nIf you need other PHP versions use:\n  PHP 5.4: ppa:ondrej/php5-oldstable (Ubuntu 12.04 LTS)\n  PHP 5.5: ppa:ondrej/php5 (Ubuntu 14.04 LTS)\n  PHP 5.6: ppa:ondrej/php5-5.6 (Ubuntu 14.04 LTS - Ubuntu 16.04 LTS)\n  PHP 5.6 and PHP 7.0: ppa:ondrej/php (Ubuntu 14.04 LTS - Ubuntu 16.04 LTS)\n\nThe PPA from that the same maintainer which is used for 12.04 (ppa:ondrej/php5-oldstable), does not include apache 2.4 and is no longer supported.\nUpdate (from ondrej): I finally tackled the a2enmod Perl code and the fix for Ubuntu 12.04 was not that hard in the end, so 2.4.20-1+deb.sury.org~precise+2 should contain the fixed code.\nUpdate 2 (from ondrej): I moved all apache2 related packages to ppa:ondrej/apache2 to avoid duplication.  Unfortunately there's no way how to express this in the PPA dependencies.\n\nA: You can find and download the old packages from the build history:\nwget -A deb -m --no-parent https://launchpad.net/~ondrej/+archive/ubuntu/php5/+build/7886307\nwget https://launchpad.net/~ondrej/+archive/ubuntu/php5/+build/7886308/+files/apache2-data_2.4.16-4+deb.sury.org~precise+4_all.deb\n\nThis set of packages are from a previous version that should not depend on Perl 5.16.\n", "Q: Suspend is not working in Ubuntu, NVIDIA Graphics card is installed In my newly installed Ubuntu 14.04 LTS Suspend is not working. I tried to do it with sudo s2ram. I am getting a message \nKMS graphics driver is in use, skipping quirks.\n\nI also tried sudo pm-suspend with both of them the computer is going to sleep. When I press any button in the keyboard or the power button it woke up, but when it woke up, the screen freezes. I have tried some posts, but to no avail. I have added the links which I have tried.\nLink 1, Link 2, Link 3\nI always put my computer to sleep, but this problem has made using the computer practically impossible.\n\nA: try to install pm-utils and suspend pc with pm-suspend command.\n\nA: I have solved the problem by running \nsudo apt-get install nvidia-current-updates\n\nNow I can use suspend without any fuzz. I came across This post and my pc is working just fine. The nouveau driver it has some problem with the power management. Once the latest driver for the Nvidia is installed, it has solved the problem on it's own.\n", "Q: Why is .profile is not sourced when choosing \"Open in Terminal\" in context menu? I have already changed the default profile of the terminal emulator to \"Run command as login shell\", but that only enabled the sourcing of .profile when I open Terminal via ctrl-alt-T. What am I overlooking?\n\nA: The nautilus-open-terminal extension runs the terminal with a command:\n/* interactive shell */\ncommand = g_strdup_printf (\"cd %s && exec $SHELL\", quoted_path);\n\nSo that particular terminal preference will be ignored, since the terminal is not starting a shell, but running a command. It doesn't look like you can change it without modifying the source.\n", "Q: Install Qualcomm Atheros QCA61x4 drivers without Internet access I am trying to install Ubuntu 14.04 LTS and having problems with my wifi card. As it reads in the title, i dont have any internet access on my Laptop and cannot install any packages via api-get. I tried every suggestion i found in the forums but none wants to work. I cannot install the windows driver either, because i cannot install wine.\nPlease help\n\nA: If you have an Android phone with wifi-data, you can enable data-share (tethering) and connect it to your Computer.(use this guide, for usb tethering) https://support.google.com/nexus/answer/2812516?hl=en\n", "Q: Pointers / advice on Ubuntu Server install on HP Gen 8 G1610T microserver I've recently purchased an HPE Microserver G8 GP1610T, 120GB SSD drive and a couple of 2TB drives to build an Ubuntu based server with the OS on the SSD drive and two 2TB drives as mirrored (RAID1) storage. I don't require dual-boot capability. \nIn reading through existing posts on this forum and elsewhere it appears that this isn't exactly straightforward with issues around recognizing and booting from drives connected to the Optical Disk sata port, utilizing the HP 'RAID' controller and fan noise. The posts however all date back to mid-2015, Ubuntu 14.04.2 LTS and before.\nMy questions are therefore:\n\n\n*\n\n*Do the more recent versions of Ubuntu make any of this easier and solve the fan noise issue?\n\n*Is the HP 'RAID' controller worth using or is the Ubuntu software RAID the better option?\n\n*Do I bother with the SSD drive or just run the OS off a uSD card?\n\n*Any pointers to 'HowTo' guides for this type of installation, especially around the RAID controller / disk configuration?\n\n\nAny help appreciated!\n\nA: I can't tel you what is best for you but i will tel you what i did on our internal servers.\nI always installed Ubuntu or Debian servers on Linux software raid.\nI already had to recover a broken drive and that was realy easy to do. also the system would just boot with only one drive active. Just hotswap and add it to the lvm volume againe.\nWhat i would not do is running your os of the SSD but of the 2 disks. If your SSD fails you lost your entire os if one of the disk fails you just order a new one and your still ok.\nto set this up i have used this guide in the past with succes.\nhttps://help.ubuntu.com/community/Installation/SoftwareRAID\nYou can even do some exotic stuff and use raid 1 for data and os and use raid 0 for swap\n", "Q: Next problem with wlan0 I have installed Ubuntu 14 and can't connect to WiFi. Tried to find solutions by myself but still things don't work out. \nSteps I have taken:\n\n\n*\n\n*Went to Software And Updates -> additional Drivers and used Broadcom 802.11 Linux drivers \n\n*Used iwconfig command, found that wlan0 doesn't exists\n\n*Installed linux-firmware-nonfree package  - wlan0 shows now up\n\n\nAfter these steps I still can't connect to network and I'm getting following error in toolbar:\n\nWiFi is disabled by hardware switch.\n\n\n02:00.0 Network controller [0280]: Broadcom Corporation BCM4312 802.11b/g LP-PHY [14e4:4315] (rev 01)\n Subsystem: Hewlett-Packard Company Device [103c:1508]\n Kernel driver in use: wl\n\n\nA: You have installed a wrong driver for this adapter.\nRun in terminal\nsudo apt-get purge bcmwl-kernel-source\nsudo apt-get install firmware-b43-installer\nsudo modprobe b43\n\nand your Wi-Fi should work.\n", "Q: Ubuntu 15.10 Live USB not starting due to graphic card driver errors (nouveau) The desktop is not starting at all. So I cannot install the proprietary drivers for NVidia via system preferences. Any advice please?\n\nA: Boot from the Ubuntu installation media and select Try Ubuntu without installing.\nPress the E key and add nouveau.modeset=0 at the end of the linux line.\nSet a Space between the last character in the linux line and nouveau.modeset=0\nPress the F10 key to boot into the Live desktop - now install Ubuntu.  \nAfter it is  finished, reboot the system and this time select the Ubuntu menu entry.\nPress the E key and add nouveau.modeset=0 at the end of the linux line.\nSet a Space between the last character in the linux line and nouveau.modeset=0\nPress the F10 key to boot into Ubuntu - now install the NVIDIA drivers.  \nReboot the system, now you don't have to add the parameter any more.\n", "Q: HUGE PROBLEM! Can't log in to Ubuntu 14.04 after upgrade to 15.10, stuck at login screen So I started the upgrade from Ubuntu 14.04 LTS to Ubuntu 15.10. Everything was going okay until it logged out. Even the guest session is not working tried upgrading from terminal with Ctrl+Alt+F1 but it says:\n`\n\nE: Unmet Dependicies. Try using -f\n\n`\nand when I try to update or reinstall unity the terminal says \n'\n\nW: Ignoring Provides line with DepCompareOp for package python-cffi-backend-api-max\n\n' \n\nA: Reboot. Try to boot into the recovery system from grub. When it comes up, or anything with a CLI, do (as root) a apt-get -f install. Let the update process finish, you can make sure with apt update && apt full-upgrade that no error messages remain.\nYour system should be in a usable state then, this happens more often than I like.\n", "Q: How to build multi-arch snaps I've got a snap that I'd like to build for multiple architectures. Right now, in the snapcraft.yaml file I define a wrapper as the binary to execute, which sets up environment variables required for the app to run.\nOne piece of script code that it contains is the following:\n#!/bin/sh\nARCH='x86_64-linux-gnu'\nexport LD_LIBRARY_PATH=$SNAP/usr/lib/$ARCH:$LD_LIBRARY_PATH\n\nObviously, hardcoding ARCH is not optimal, as non-amd64 builds will not work correctly. However, arch detection using dpkg-architecture will not work when using Snapcraft.\nHow can I dynamically detect the host's architecture in my wrapper to set the correct library paths while building the snap with Snapcraft?\nCode is available as part of the snappy desktop examples.\n\nA: The binary wrappers (and service files) define the SNAP_ARCH environment variable for you. Unfortunately not an ideal solution since they're not triplets, but it should be enough information for you to get there with a case statement or something.\n\nA: For the sake of completeness, I ended up using the following shell snippet:\n#!/bin/sh\n\ncase \"$SNAP_ARCH\" in\n    \"amd64\") ARCH='x86_64-linux-gnu'\n    ;;\n    \"i386\") ARCH='i386-linux-gnu'\n    ;;\n    *)\n        echo \"Unsupported architecture for this clock app build\"\n        exit 1\n    ;;\nesac\n\nHowever, as the wrapper starts getting complicated, I'm rather looking at creating a Snapcraft plugin instead.\n", "Q: How to run an executable file (web app) 24/7 and restart automatically when it breaks down? I have an executable file on a server which is a full-fledged standalone web application. When I login to a server via ssh and run the file, the website become visible in the internet. Obviously, because it's run via ssh by me, when I disconnect the website goes down. \nWhat's the idiomatic and easy way to run that file 24/7 and preferably re-launch when it goes down? \nIt's Ubuntu 15 but my question is rather more broad because I want to learn how to do that on other distributives as well.\nI don't want to use any third-party solutions or web services, only the standard Linux tools and applications.\nShould I create a service for systemd?\n\nA: Yes, creating a systemd service is the way to go. You will need to write a service file, which in your case doesn't need much. Here is an outline of such a file:\n[Unit]\nDescription=your description here\nAfter=syslog.target\n\n[Service]\nExecStartPre= [script to run before starting the service]\nExecStart= [script to run the actual service]\nRestart=on-abort\n\n[Install]\nWantedBy=multi-user.target\n\nThis should go in /etc/systemd/system/yourservice.service. Now you can start, stop, restart and find the status of your service using systemctl commands. Various other examples and options are to be found on the web and on this site.\nThis solution would be portable to all Linux systems that run systemd. For systems running SysV or Upstart, you will have to find a different solution.\n", "Q: How to schedule app to lauch including it's GUI I have a  calc spreadsheet that I'm trying to automate.  When open, it collects data, calculates, saves itself and exits.\nSo I created a script to call this. \nsoffice --calc --norestore Updater.ods\n\nIf I run the script ./updater.sh calc opens and does what its supposed to do :)\nHowever, when I put it in crontab or fcrontab\n00     15     *     *     *       export DISPLAY=:0 && /path/updater.sh\n\nI can see the process is running, but it doesn't complete any of the actions that it would if the GUI opened.   And running the script from terminal opens the gui, but with cron the gui is not opened.   So I'm wondering if it is possible to open an app (and it's gui) with cron or another scheduler?\nAny help would be appreciated.\n\nA: Try without the && \n00 15 * * * export DISPLAY=:0 /path/updater.sh\n\nI hope this helps\n\nA: There is another option, to schedule graphic tasks, to.\nIn Orage, the calendar app (double click on the clock in the system panel), doubleclick on a single day.\nSelect a event, new. Give it a name, here maybe 'updater'. Set the time to 15:00.\nNow choose tab: Reminder, Application, use:  /path/updater.sh \nDeactivate sound and other unsound options.\nNow choose tab: Repetition, Frequency, daily, 1\nI have a German UI, so maybe my translation for the tabs doesn't fit. \n", "Q: How to customize distribution with predefined user and automatic installation/configuration I am working on Ubuntu customization for production level. The setup environment is explained below:\nI have some Ubuntu machines (12 to be more precise) that runs a software made by myself for this business. It boots directly to the X, automatic log-in, then opens right away mysoftware GUI.\nI would like to have a custom Ubuntu installation image (for USB stick, etc...) with predefined user, variable hostname and some customization that I have already made on those machines.\nSo, What is the best tool to create this customized distribution (based on my needs on customization, easy deployment/customization/creation)\nMy problem is, I have to turn the installation process more easy. Because the HDD clone process is wasting so much time for me. And with different hardwares, I have about three different HDD clones to match them.\nWhat I would like to accomplish on this customization:\n\n\n*\n\n*predefined username to log into automatically with    \n\n*predefined session customizations ($HOME customizations for OpenBox, .ssh,.compton, etc...)    \n\n*runs software right after automatic login   \n\n*automatic predefined software packages installed (from apt-get, but without internet need)\n\n*variable hostnames (sales00, sales01, sales02, and so on...)\n\n*set of customized permission of system calls/programs (such as chmod 4755 on /bin/date)\n\n*customized /etc/skel for new user (just in case)\n\n*disable automatic updates\n\n*fresh network adapters configuration (today I have a mess on network adapters from each machine like eth49, eth88,). I wish they have all the same numbers\n\n*network adapters predefined static IP: I have three network adapters: one has a fixed IP for all machines (the same IP 1.1.1.1 for this, though), second and third network adapters are configured through my software. So I wish I have a custom installation that configures automatically this 1.1.1.1 IP for that network adapter\n\n\nAnd so, again, What is the best Ubuntu custom distribution creator (studio?) to work with?\nP.S.: I used to try PinGuyBuilder once, but it changed to default the permissions customization (like chmod 4755 on /bin/date) and has limitations like predefined username/hostname\nBest Regards\n\nA: \nWhat is the best Ubuntu custom distribution creator (studio?) to work with?\n\nAll of them lack some (if not most) of the features you list.\nI would do this myself (manually). The way to do this is to download an ISO, create a \"chrooted\" environment with that ISO, hack away, burn ISO to a DVD and boot from it. I have to AU topics that have good info:\n\n\n*\n\n*How to customize the Ubuntu Live CD?\n\n*How to create a Customized Ubuntu Server ISO?\nThe 2nd one is very generic (works across different releases) since it does not have a desktop and you can add it yourself on top of the server. \nYour list with comments, without providing actual methods on how to do each though. I leave that up to you ;-)\n(comment: a kickstart file is a redhat feature for automated installers. Ubuntu has limited support for it but it can be a starter to get going).\n\n\n*\n\n*predefined username to log into automatically with\n\n\n*\n\n*This can be done from a kickstart file and is pretty normal to change for a personal installer/ISO. So most will have this but is also easily done manually.\n\n\n*predefined session customizations ($HOME customizations for OpenBox, .ssh,.compton, etc...)\n\n\n*\n\n*Doubt any of those kits can do this. But the manual method can be used to add packages into your own install so you can also create configurations files. Problem here is that you probably will need to recompile from source since the default configs are not human readable. \nIf possible a far easier method would be to drop a config file from your own machine into /etc/skel/ and move it to the correct location after install. \n\n\n*runs software right after automatic login\n\n\n*\n\n*Configuration of \"startup applications\". You only need to edit a text file.\n\n\n*automatic predefined software packages installed (from apt-get, but without internet need)\n\n\n*\n\n*can also be done from a kickstart file. Or manually: when you create your own ISO you add your files to the DVD yourself using \"apt-get\" or by copying the archive cache from your machine into the ISO.\n\n\n*variable hostnames (sales00, sales01, sales02, and so on...)\n\n\n*\n\n*If you already have a host set up like this it will be as easy as copying that file over to your ISO.\n\n*set of customized permission of system calls/programs (such as chmod 4755 on /bin/date)\n\n*Yuck ;-) You can chmod the file on the ISO. Of course you can also add your own post-install script file to the ISO. \n\n\n*customized /etc/skel for new user (just in case)\n\n\n*\n\n*Easy with a manual method since that is the method to set up your user. That dir is used to create your user home and files like \".bashrc\" with the options/parameters/etc set in /etc/skel.\n\n\n*disable automatic updates\n\n\n*\n\n*that is a setting ... so can't be more than an edit of \"gsettings\". By the way: should already be set to \"off\" so doubt you need to do anything for this.\n\n\n*fresh network adapters configuration (today I have a mess on network adapters from each machine like eth49, eth88,). I wish they have all the same numbers\n\n\n*\n\n*this one I am not sure about. I would assume these things get created during boot(?!) so doubt it will be something you can set up upfront. But if this is configurable during install I you will be able to add/edit the files you need for this (/etc/network/interfaces or dhcclient )\n\n\n*network adapters predefined static IP: I have three network adapters: one has a fixed IP for all machines (the same IP 1.1.1.1 for this, though), second and third network adapters are configured through my software. So I wish I have a custom installation that configures automatically this 1.1.1.1 IP for that network adapter\n\n\n*\n\n*you can set this up on the ISO in the same fashion as you would with a normal install.\n\n\n", "Q: Network configuration | apt can't download anything I'm having some issues with the FTP server I'm currently setting up for my company. I installed the server completly, updated everything and the server works fine now. \nI installed everything behind a proxy in another network.\nNow I moved the server to the place where it belongs, in its very own network without a proxy. The FTP ports are opened and the FTP is avaible from everywhere. \nBut the problem I have now is, that exept for pings on direct IP-adresses and the ftp service, I can't install anything with apt-get or update anything.\nHere are some configuration files for more information. \nauto lo\niface lo inet loopback\n\nauto eth1\niface eth1 inet static\n        address 192.168.5.1\n        netmask 255.255.255.0\n        network 192.168.5.0\n        broadcast 192.168.5.255\n        gateway 192.168.5.254\n\nifconfig:\neth1      Link encap:Ethernet  HWaddr 00:07:e9:80:42:ff\n          inet addr:192.168.5.1  Bcast:192.168.5.255  Mask:255.255.255.0\n          inet6 addr: fe80::207:e9ff:fe80:42ff/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:2110 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:2225 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:197740 (197.7 KB)  TX bytes:382977 (382.9 KB)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:10072 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:10072 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:814824 (814.8 KB)  TX bytes:814824 (814.8 KB)\n\nThe apt.conf is empty.\nThings like nslookup de.archive.ubuntu.com and ping google.com don't work\nThe server is behind two firewalls and the guys from the company who maintain the firewall said that the ubuntu download server sources are allowed to connect.\n\nA: You don't have DNS working.\nAdd the directive to interfaces to enable it.\ndns-nameservers 8.8.8.8\n\nFull Example for your configuration.\nauto lo\niface lo inet loopback\n\nauto eth1\niface eth1 inet static\n        address 192.168.5.1\n        netmask 255.255.255.0\n        gateway 192.168.5.254\n        dns-nameservers 8.8.8.8\n\n\nA: you could also add.\nnameserver 8.8.8.8\n\nto /etc/resolv.conf\n", "Q: MaaS Node cant ping external servers I have setup a MaaS server with eth0 going to the internet and eth1 an internal switch connecting the the MaaS nodes. I and can commission and deploy nodes on Trusty Ubuntu but those nodes can only perform nslookup on external servers but not ping. I suspect the default gateway may be miss-configured but have no idea what it should be if it is. \nAny idea what the correct configuration should be for this instance:\nMaaS Server\ngraeme@MAAS:~$ ifconfig\neth0      Link encap:Ethernet  HWaddr 00:15:5d:00:07:04\n          inet addr:192.168.0.4  Bcast:192.168.0.255  Mask:255.255.255.0\n          inet6 addr: fe80::215:5dff:fe00:704/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:933 errors:0 dropped:3 overruns:0 frame:0\n          TX packets:796 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:814964 (814.9 KB)  TX bytes:81546 (81.5 KB)\n\neth1      Link encap:Ethernet  HWaddr 00:15:5d:00:07:05\n          inet addr:10.1.1.100  Bcast:10.1.1.255  Mask:255.255.255.0\n          inet6 addr: fe80::215:5dff:fe00:705/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:14 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:19 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:999 (999.0 B)  TX bytes:1842 (1.8 KB)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:13351 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:13351 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:3635226 (3.6 MB)  TX bytes:3635226 (3.6 MB)\n\nvirbr0    Link encap:Ethernet  HWaddr 92:7f:58:38:c8:79\n          inet addr:192.168.122.1  Bcast:192.168.122.255  Mask:255.255.255.0\n          UP BROADCAST MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\ngraeme@MAAS:~$ route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         192.168.0.1     0.0.0.0         UG    0      0        0 eth0\n10.1.1.0        0.0.0.0         255.255.255.0   U     0      0        0 eth1\n192.168.0.0     0.0.0.0         255.255.255.0   U     0      0        0 eth0\n192.168.122.0   0.0.0.0         255.255.255.0   U     0      0        0 virbr0\ngraeme@MAAS:~$ sudo cat /etc/network/interfaces\n# This file describes the network interfaces available on your system\n# and how to activate them. For more information, see interfaces(5).\n\n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# The primary network interface\nauto eth0\niface eth0 inet static\naddress 192.168.0.4\nnetmask 255.255.255.0\ngateway 192.168.0.1\ndns-nameservers 10.1.1.100 192.168.0.1\n\nauto eth1\niface eth1 inet static\naddress 10.1.1.100\nnetmask 255.255.255.0\ngraeme@MAAS:~$ nslookup google.com\nServer:         10.1.1.100\nAddress:        10.1.1.100#53\n\nNon-authoritative answer:\nName:   google.com\nAddress: 216.58.198.110\n\ngraeme@MAAS:~$ ping google.com\nPING google.com (216.58.198.110) 56(84) bytes of data.\n64 bytes from lhr25s07-in-f14.1e100.net (216.58.198.110): icmp_seq=1 ttl=54 time=19.9 ms\n64 bytes from lhr25s07-in-f14.1e100.net (216.58.198.110): icmp_seq=2 ttl=54 time=18.6 ms\n^C\n--- google.com ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1001ms\nrtt min/avg/max/mdev = 18.651/19.324/19.997/0.673 ms\n\nNode Server\nubuntu@node-1-tidy-balls:~$ ifconfig\neth0      Link encap:Ethernet  HWaddr 00:15:5d:00:07:03\n          inet addr:10.1.1.151  Bcast:10.1.1.255  Mask:255.255.255.0\n          inet6 addr: fe80::215:5dff:fe00:703/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:1809 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:256 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:151375 (151.3 KB)  TX bytes:35520 (35.5 KB)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:16 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:16 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:1184 (1.1 KB)  TX bytes:1184 (1.1 KB)\n\nubuntu@node-1-tidy-balls:~$ route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.1.1.100      0.0.0.0         UG    0      0        0 eth0\n10.1.1.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0\nubuntu@node-1-tidy-balls:~$ sudo cat /etc/network/interfaces\nauto lo\niface lo inet loopback\n    dns-nameservers 10.1.1.100\n    dns-search maas\nauto eth0\niface eth0 inet static\n    gateway 10.1.1.100\n    address 10.1.1.151/24\n    mtu 1500\n\nubuntu@node-1-tidy-balls:~$ nslookup google.com\nServer:         10.1.1.100\nAddress:        10.1.1.100#53\n\nNon-authoritative answer:\nName:   google.com\nAddress: 216.58.198.110\n\nubuntu@node-1-tidy-balls:~$ ping google.com\nPING google.com (216.58.198.110) 56(84) bytes of data.\n^C\n--- google.com ping statistics ---\n5 packets transmitted, 0 received, 100% packet loss, time 4032ms\n\nThe ping on the Node had to canceled as it didn't return anything after a minute.\n\nA: On your MaaS server...\nFirst add the rules to your interface, post up and down.\nauto eth1\niface eth1 inet static\naddress 10.1.1.100\nnetmask 255.255.255.0\n    post-up iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source 192.168.0.4\n    post-down iptables -t nat -D POSTROUTING -o eth0 -j SNAT --to-source 192.168.0.4\n\nThen you need to enable IP forwarding.\nEdit /etc/sysctl.conf by adding the following line.\nnet.ipv4.ip_forward=1\n\nThat will take affect on restarting, but you can also trigger it on the fly by issuing...\necho 1 > /proc/sys/net/ipv4/ip_forward\n\n", "Q: How to fix \"no such partition\" error in Ubuntu 14.04? I'm a rookie to Ubuntu. Before I installed Ubuntu, I had Windows 7. Then I completely wiped the disk (500 GB) using GParted and installed Ubuntu 14.04 with following partitions:\n/ of 30gb\nswap of 4gb\n/home of 160gb\n\nThe remaining space is unallocated.\nBut my Ubuntu freezes frequently. \nNow I got the following screen:\n\nand I got these errors:\nerror: no such partition.\nEntering rescue mode...\ngrub rescue >\ngrub rescue >\ngrub rescue >\ngrub rescue >\ngrub rescue >\n\nAnyone please help me out.\n\nA: This has nothing to do with GRUB or Linux. It's a hardware issue. Probably you are using cheap cables that don't connect properly or have dirty contacts. It's also possible that your drive has gone bad (the electronics on it, not the media), or even your host adapter. Did you try connecting to another machine, or connecting a different drive (if not, why not?)\nOn a different topic: there is no point in having separate root and /home partitions. \n", "Q: drm intel pipe_config_compare [i915] error mismatch in ips_enabled Encountered error after install of xdm drm intel pipe_config_compare [i915] error mismatch in ips_enabled, right after startup. Searching the forms, found nothing useful. I had some config changes, and installed new soft xdm and screen etc. I new they were causing the issue but not how to fix. Read the second part.\n\nA: Follow this post, it did the magic. https://askubuntu.com/a/757696/530803\nHere is what you it says to do,\nSteps I followed:- 1. When the error popped up, I press Ctrl + Alt + F3, it opens virtual terminal and entered my login and password.\nThen use this command:- history | grep install\nAfter this output shows, what all softwares I recently installed. mine shows fdlrx, xdm, openvpn.\nRemoved those softwares using command:- sudo apt-get remove fdlrx sudo apt-get remove xdm sudo apt-get remove openvpn sudo apt-get remove bcmwl-kernel-source\nLast command, I take from this page only.\nThen reboot the system using command using command:- reboot\nAnd it will work. This post must be marked as answered so that it becomes easy to find. So I decided to create my own thread and mark it answered!\n\nA: You just have to install the official Intel Graphic Drivers: \nhttps://01.org/linuxgraphics/downloads/\nAfter that, You need to add the required keys to apt\nwget --no-check-certificate https://download.01.org/gfx/RPM-GPG-KEY-ilg-3 -O - | \\\nsudo apt-key add -\n\nAnd finally, run the installer script:\nsudo intel-linux-graphics-installer\n\n", "Q: can't add key - keyserver timed out I'm trying to install mongodb on ubuntu 15.10. \nWhile following this - Install Mongo 3.2 on Ubuntu 15.10 - i got the following error message: \nW: GPG error: http://repo.mongodb.org trusty/mongodb-org/3.2 Release: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY D68FA50FEA312927\n\nSo then I attempted to add the key like this: \nme@devbox:/etc/test$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys D68FA50FEA312927\n\nExecuting: gpg --ignore-time-conflict --no-options --no-default-keyring --homedir /tmp/tmp.CWnpUGSg5w --no-auto-check-trustdb --trust-model always --keyring /etc/apt/trusted.gpg --primary-keyring /etc/apt/trusted.gpg --keyring /etc/apt/trusted.gpg.d/apt.postgresql.org.gpg --keyring /etc/apt/trusted.gpg.d/nginx_ubuntu_stable.gpg --keyring /etc/apt/trusted.gpg.d/webupd8team_ubuntu_java.gpg --keyserver keyserver.ubuntu.com --recv-keys D68FA50FEA312927\ngpg: requesting key EA312927 from hkp server keyserver.ubuntu.com\ngpg: keyserver timed out\ngpg: keyserver receive failed: keyserver error\n\nNot sure what else to try.  I'm currently looking other posts here on this  site to see if this has been addressed. \nEDIT 1:\nBased on this post:  Can't add repo keys\nI tried to run the command : \nsudo gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys D68FA50FEA312927\n\nand then retried: \nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys D68FA50FEA312927\n\nBut it's still failing. \n\nA: Try different keyservers, and try using port 80.\nA few servers you could try if keyserver.ubuntu.com doesn't work :\n\n\n*\n\n*keys.gnupg.net (this one worked for me today)\n\n*pgp.mit.edu\n\n*sks-keyservers.net\n\n*keyserver.pgp.com\n\n\nsudo apt-key adv --keyserver hkp://$pgp_server:80 --recv-keys $wanted_key\n\n", "Q: Required installation of untrusted package Today I was updating my Ubuntu software and suddenly a 'not possible to  update because package system is broken' error came up.\nSomehow I try to follow from Ubuntu community in Google and something happens when I try to update using Software Updater. The 'required installation of untrusted package, this required installing packages from unauthenticated sources'.\nI tried sudo apt-get update && sudo apt-get upgrade from Google and the result is failed to fetch http://my.archive.ubuntu.com/ubuntu/dists/trusty/InRelease and many failed to fetch notifications.\nPlease help me because I'm new and I don't know how to fix it. Also my Ubuntu cannot connect to internet.\n\nA: Try the following:\nCode:\nsudo apt-get -f install\nsudo dpkg --configure -a\nsudo apt-get autoremove\nsudo apt-get clean\nsudo rm /var/lib/apt/lists/* -vf\nsudo apt-get update\n\nPost back the errors, if any, from the 'apt-get update' output.\nIf there are no errors are reported then you are good to run:\nCode:\nsudo apt-get dist-upgrade\n\n(The above command does NOT upgrade to next ubuntu version, it just does some smart upgrades to the present system).\n", "Q: Concatenate find command with other commans I am trying to index my file system. What I want to do, is: execute the command find, and for each entry save the last access time, last modified time, compute the hash and other operations. In order to do this I thought to do the following command: \nfind . -printf 'PATHNAME=%p -- NAME=%f -- SIZE=%s -- LAT=%a -- LCT=%c -- LMT=%t  \\n' -exec file {} \\; -exec md5sum {} \\;\n\nThe output is something like:\nPATHNAME=./script -- NAME=script -- SIZE=807 -- LAT=Fri Apr 15 16:39:52.0874615579 2016 -- LCT=Tue Apr 12 12:20:57.0767950320 2016 -- LMT=Tue Apr 12 12:20:57.0767950320 2016 <br>\n./script: ASCII text <br>\ncf1b934c226b194bee96106ea3f019a4  ./script\n\nNow I would like to take all these parameters (for example parse them with awk) and put them somewhere (for example in a database). So, my question is: how can I redirect every time these 3 lines to a script for the parsing? Is there a better way to write the command?\n\nA: I would use something like this (without the insert part in the database)\nwhile read EMPTY_LINE; do\n  read FILE_SIZE\n  read FILE_AT\n  read FILE_MT\n  read FILE_CT\n  read MIME_INFO\n  read HASH FILE_PATH\n\n  echo\n  echo 'File path: '\"$FILE_PATH\"\n  echo 'File size: '\"$FILE_SIZE\"\n  echo 'File times (access - modified - changed): '\"$FILE_AT - $FILE_MT - $FILE_CT\"\n  echo 'MIME stuff: '\"$MIME_INFO\"\n  echo 'Hash: '\"$HASH\"\ndone < <(find . -type f -printf '\\n' -exec stat --printf '%s\\n%X\\n%Y\\n%Z\\n' {} \\; -exec file -b {} \\; -exec md5sum {} \\; )\n\nOkay, so what exactly happens here, and why did I do it this way?\nFind command\nFirst the command find . -type f -printf '\\n' -exec stat --printf '%s\\n%X\\n%Y\\n%Z\\n' {} \\; -exec file -b {} \\; -exec md5sum {} \\; is executed.\nLet's break this down.\nfind . find stuff in . (which is the current directory)\n-type -f find only files\n-printf '\\n' print an empty file for every file match\n-exec stat --printf '%s\\n%X\\n%Y\\n%Z\\n' {} \\; execute the stat command printing several file statistics which I specified myself - see stat --help for the statistics available\n-exec file -b {} \\; execute file command to determine MIME information. -b makes sure the filename is not printed along with it. We would ignore it anyway.\n-exec md5sum {} \\; execute md5sum command to calculate the md5 hash of the file contents.\nSo for so good. The -exec arguments are processed in the order specified.\nThis means per file match we'll get the following lines as \n[FILE SIZE - from stat command]\n[FILE LAST ACCESS TIME - from stat command]\n[FILE LAST MODIFICATION TIME - from stat command]\n[FILE LAST CHANGE TIME - from stat command]\n[MIME INFO - from file command]\n[HASH - from md5sum command] [FILE PATH - from md5sum command]\n\nLet's try out the find command to see if it outputs everything as we'd expect.\n[~/somedir]:$ find . -type f -printf '\\n' -exec stat --printf '%s\\n%X\\n%Y\\n%Z\\n' {} \\; -exec file -b {} \\; -exec md5sum {} \\;\n\n1752\n1441609114\n1441609114\n1441609114\nASCII text\n4fb6f64ce9d07be553a81644b17fe69b  ./README.md\n\n./tuptime-install.sh\n1649\n1441609114\n1441609114\n1441609114\nBourne-Again shell script, ASCII text executable\n9ee7ad860bfa049d1d5f589fba218c6a  ./tuptime-install.sh\n\nProcess the lines\nThere is a lot which can go wrong when parsing these things. What happens if there is a space in the filename? Or some other weird character? Or in the other parameters. To get rid of this problem and others I've used newlines explicitly. So we can read a full line and process it accordingly. No special parsing needed. (except for the hash part, but we'll get to that part in a bit)\nThe while loop will be fed the output of the find command. The while loop will run whilst there is a line left. We read the empty line every match starts with. The empty line is actually not really needed, but we'll use it to keep the ouput clean.\nThe script is pretty self explanatory. It reads the lines one by one into variables in the order we expect them to be present. After that we print them. \nThe way the read command works that if a single variable name is given, it will read the whole line into the given variable name. If multiple variables are given the line is split with the space character (by default) and put into the variables given. We only used it for the md5sum command as we couldn't specify an option that would get rid of the filename. We could have gotten the filename from find' or stat, but because md5sum doesn't have an option to omit it for efficiency reasons we'll be using that one.\nI've also used the unixtime instead of the human readable format for timestamps. Having data in the most raw form if possible is in most cases preferred.\nOnly thing that would remain would be to put the data in the database.\nExample output of the script\nFile path: ./README.md\nFile size: 1752\nFile times (access - modified - changed): 1441609114 - 1441609114 - 1441609114\nMIME stuff: ASCII text\nHash: 4fb6f64ce9d07be553a81644b17fe69b\n\nFile path: ./tuptime-install.sh\nFile size: 1649\nFile times (access - modified - changed): 1441609114 - 1441609114 - 1441609114\nMIME stuff: Bourne-Again shell script, ASCII text executable\nHash: 9ee7ad860bfa049d1d5f589fba218c6a\n\n", "Q: Can't install Steam because of unmet dependencies Today I tried to install Steam using sudo apt-get install steam.\nIt didn't work and showed me this error:\nbarend@barend-ubu:~$ sudo apt-get install steam\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n steam:i386 : Depends: libgl1-mesa-glx:i386\nE: Unable to correct problems, you have held broken packages.\n\nThen I tried sudo apt-get install -f to fix the broken dependencies.\nThat didn't work either.\nI then searched on Google, and I found this question on AskUbuntu\nThe most upvoted answer suggested sudo apt-get install libc6:i386 libgl1-mesa-dri-lts-utopic:i386 libgl1-mesa-glx-lts-utopic:i386 or sudo apt-get install libc6:i386 libgl1-mesa-dri-lts-vivid:i386 libgl1-mesa-glx-lts-vivid:i386, neither of which work for me and fail with the following error:\nbarend@barend-ubu:~$ sudo apt-get install libc6:i386 libgl1-mesa-dri-lts-utopic:i386 libgl1-mesa-glx-lts-utopic:i386\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n indicator-bluetooth : Depends: unity-control-center but it is not going to be installed or\n                                gnome-control-center but it is not going to be installed or\n                                ubuntu-system-settings but it is not going to be installed\n libgl1-mesa-dri-lts-utopic:i386 : Conflicts: libgl1-mesa-dri\n libgl1-mesa-glx-lts-utopic:i386 : Depends: libglapi-mesa-lts-utopic:i386 (= 10.3.2-0ubuntu1~trusty2) but it is not going to be installed\n                                   Depends: libudev1:i386 but it is not going to be installed\n libqt5feedback5 : Depends: libqt5multimedia5 (>= 5.0.2) but it is not going to be installed\nE: Error, pkgProblemResolver::Resolve generated breaks, this may be caused by held packages.\n\nIt might be good to know that I tried to install Steam using the deb from their website, then it couldn't start because of an error, \"You are missing the following 32-bit libraries, and Steam may not run:\nlibc.so.6\" and I uninstalled Steam with sudo apt-get remove steam.\nMy question is: How can I install Steam again and fix the broken packages?\nUpdate:\nI tried what @Videonauth suggested, but it's still not working. A Terminal window popped up with this:\nSteam needs to install these additional packages: \n  libgl1-mesa-dri:i386, libgl1-mesa-glx:i386, libc6:i386\n\nI entered my password, and then...\n[sudo] password for barend: \n................................................................................................\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n libgl1-mesa-glx:i386 : Depends: libglapi-mesa:i386 (= 10.1.3-0ubuntu0.6)\n                        Depends: libudev1:i386 but it is not going to be installed or\n                                 libudev0:i386 but it is not installable\n unity-control-center : Depends: libcheese-gtk23 (>= 3.4.0) but it is not going to be installed\n                        Depends: libcheese7 (>= 3.0.1) but it is not going to be installed\nE: Error, pkgProblemResolver::Resolve generated breaks, this may be caused by held packages.\nPress return to continue: \n\nWhat do I do now?\nOutput of apt-cache policy libgl1-mesa-glx libgl1-mesa-glx:i386 as requested by @Videonauth:\n  libgl1-mesa-glx:\n    Installed: (none)\n    Candidate: 10.1.3-0ubuntu0.6\n    Version table:\n       10.1.3-0ubuntu0.6 0\n          500 http://ftp.nluug.nl/os/Linux/distr/ubuntu/ trusty-updates/main amd64 Packages\n       10.1.0-4ubuntu5 0\n          500 http://ftp.nluug.nl/os/Linux/distr/ubuntu/ trusty/main amd64 Packages\n  libgl1-mesa-glx:i386:\n    Installed: (none)\n    Candidate: 10.1.3-0ubuntu0.6\n    Version table:\n       10.1.3-0ubuntu0.6 0\n          500 http://ftp.nluug.nl/os/Linux/distr/ubuntu/ trusty-updates/main i386 Packages\n       10.1.0-4ubuntu5 0\n          500 http://ftp.nluug.nl/os/Linux/distr/ubuntu/ trusty/main i386 Packages\n\nUpdate:\nThanks to all of you, @Videonauth and @Mark Kirby and @ijustlovemath who tried to help me out and I really do appreciate it, but nothing has worked for me so far. Hmm, no Steam for me, I guess...\nIf you advise me to do this, what would be the best way to clean my system up? I've installed and removed a lot of packages while trying all your solutions and I'm not sure if I can just sudo apt-get remove steam or have to do a lot more.\n\nA: Install it again from their website's .deb file and then open a terminal (ctrl+alt+t) and use these two commands:\n\nmv ~/.local/share/Steam/ubuntu12_32/steam-runtime/i386/lib/i386-linux-gnu/libgcc_s.so.1{,.disable}\nmv ~/.local/share/Steam/ubuntu12_32/steam-runtime/i386/usr/lib/i386-linux-gnu/libstdc++.so.6{,.disable}\n\nAfter that, start Steam and let it update.\nP.S.: it might be possible that after the update steam fails to start again, but then just rerun those two commands. The missing lib error comes from steam trying to use own libraries instead of using the system's ones.\nTo fix you ongoing problems run this in a terminal:\n\nsudo apt-get update\nsudo apt-get install libgl1-mesa-glx libcheese*\n\n\nA: Sometimes apt-get misbehaves when it comes to resolving dependencies on broken packages. Try running \nsudo apt-get update && sudo apt-get install -f && sudo apt-get upgrade.\nBriefly:\n\n\n*\n\n*sudo apt-get update refreshes the list of packages from the repository online\n\n*sudo apt-get install -f installs any unmet dependencies for packages you're either installing or have installed\n\n*sudo apt-get upgrade tries the upgrade again\n\n\nA: Tried all top Google solutions. None of them worked for me.\nCame across this answer that described how we can reset broken packages.\nTake a backup of the file /var/lib/dpkg/status first. Then erase all the contents of that file.\nThen run sudo apt install steam. It may prompt you if there are files that already exist and will be overwritten. Best that you check for the differences in the file's contents. In my case, I decided to use the one from the package maintainers itself instead of my own.\nSteam installed smoothly. Did not get any unmet dependencies error.\nWhen I tried to start steam, I got an error about glxchoosevisual failed. For this, I then had to install libnvidia-gl-450:i386 library. Note that in my case, my nvidia driver version was 450 so used that. You need to use your version here. That's it! Steam then launched fine.\nSharing it here in case it helps somebody.\n\nA: for me I went to this link https://www.omgubuntu.co.uk/2016/06/install-steam-on-ubuntu-16-04-lts and downloaded the steam installer it did the trick for after all the methods mentioned above failed for me now steam is running efficiently for me.\n\nA: I just got mine to work. I went to Software and Updates and changed the Download from the best location to \"Server for United States\". Then after it updates try the install again.\n", "Q: iptables is blocking only some connections to port 80 I'm running a Ubuntu 15.10 server with an nginx webserver on it. I've used the following iptables configuration to allow port 80 and port 443 connections:\n*filter\n\n# Allow all loopback (lo0) traffic and reject traffic\n# to localhost that does not originate from lo0.\n-A INPUT -i lo -j ACCEPT\n-A INPUT ! -i lo -s 127.0.0.0/8 -j REJECT\n\n# Allow ping.\n-A INPUT -p icmp -m state --state NEW --icmp-type 8 -j ACCEPT\n\n# Allow SSH connections.\n-A INPUT -p tcp --dport 950 -m state --state NEW -j ACCEPT\n\n# Allow HTTP and HTTPS connections from anywhere\n# (the normal ports for web servers).\n-A INPUT -p tcp --dport 80 -m state --state NEW -j ACCEPT\n-A INPUT -p tcp --dport 443 -m state --state NEW -j ACCEPT\n\n# Allow mail\n-A INPUT -p tcp --dport 25 -m state --state NEW -j ACCEPT\n\n# Allow inbound traffic from established connections.\n# This includes ICMP error returns.\n-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n\n# Log what was incoming but denied (optional but useful).\n-A INPUT -m limit --limit 5/min -j LOG --log-prefix \"iptables_INPUT_denied: \" --log-level 7\n\n# Reject all other inbound.\n-A INPUT -j REJECT\n\n# Log any traffic which was sent to you\n# for forwarding (optional but useful).\n-A FORWARD -m limit --limit 5/min -j LOG --log-prefix \"iptables_FORWARD_denied: \" --log-level 7\n\nAs confirmed by iptables -L:\nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination\nACCEPT     all  --  anywhere             anywhere\nREJECT     all  --  127.0.0.0/8          anywhere             reject-with icmp-port-unreachable\nACCEPT     icmp --  anywhere             anywhere             state NEW icmp echo-request\nACCEPT     tcp  --  anywhere             anywhere             tcp dpt:950 state NEW\nACCEPT     tcp  --  anywhere             anywhere             tcp dpt:http state NEW\nACCEPT     tcp  --  anywhere             anywhere             tcp dpt:https state NEW\nACCEPT     tcp  --  anywhere             anywhere             tcp dpt:smtp state NEW\nACCEPT     all  --  anywhere             anywhere             state RELATED,ESTABLISHED\nLOG        all  --  anywhere             anywhere             limit: avg 5/min burst 5 LOG level debug prefix \"iptables_INPUT_denied: \"\nREJECT     all  --  anywhere             anywhere             reject-with icmp-port-unreachable\n\nChain FORWARD (policy ACCEPT)\ntarget     prot opt source               destination\nLOG        all  --  anywhere             anywhere             limit: avg 5/min burst 5 LOG level debug prefix \"iptables_FORWARD_denied: \"\nREJECT     all  --  anywhere             anywhere             reject-with icmp-port-unreachable\n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination\n\nThis works... generally. Some connections to port 80 are blocked anyway (/var/log/kern.log):\nApr 15 11:50:47 while kernel: [6038916.249973] iptables_INPUT_denied: IN=eth0 OUT= MAC=04:01:a4:e4:4d:01:84:b5:9c:fa:10:30:08:00 SRC=82.101.237.77 ST=xxx.xxx.xxx.xxx LEN=40 TOS=0x08 PREC=0x00 TTL=54 ID=2368 DF PROTO=TCP SPT=51182 DPT=80 WINDOW=0 RES=0x00 RST URGP=0\n\nWhy is iptables doing that?\n\nA: Your example log entry is for a TCP packet with the reset flag asserted.\nFor TCP connections, Linux tends to use a \"half-duplex\" close sequence where either side of the session can initiate connection termination via a single 2 way FIN-ACK handshake (which puts the connection into the CLOSE_WAIT state), instead of a full 4 way FIN-ACK handshake.\nIt is likely, and very common, that your side thinks a previous TCP session has been closed and has forgotten about it. Then 82.101.237.77 tried to reset the connection, which ended up as \"iptables_INPUT_denied\".\nSummary: There is nothing wrong.\n", "Q: How do I reset the Python interpreter's terminal width? When I start python in a new 14.04 LTS gnome-terminal it is 80 character wide: \n$ python\n>>> import os\n>>> os.popen('stty size', 'r').read()\n'24 80\\n'\n\nWhen I resize the gnome-terminal the new size is reported:\n>>> os.popen('stty size', 'r').read()\n'23 170\\n'\n\nHowever, the input python prompt does not see the resizing and begins to overwrite the beginning of the line when I write long lines:\nnm> 1234567890qwertyuiopåasdfghjklæøzxcvbnm1234567890qwertyuiopåasdfghjklæøzxcvb\n\nHere 'nm' is wrapped. \nA reset from the menu of the gnome-terminal does not help. Is there a way to inform the python interpreter that the window is resized?\n\nA: This is a bug in Python that has appeared since readline version 6.3 was released. Ubuntu 14.04 has libreadline6 version 6.3-4ubuntu2, so 14.04 and all later Ubuntu releases are affected.\nThe bug has been fixed in Python, but the fix is not yet in any official release. Refer to the upstream bug report here.\nThe latest releases as of the time of this writing are 2.7.11 and 3.5.1, so the next releases 2.7.12, 3.5.2, and 3.6.0 should be fixed.\n", "Q: How to get File Size in BASH with readable size not in bytes Here is what I have in my shell file:\nFILENAME=/var/lib/backups/html-backup/backup-15-04-2016.tar.gz;\nFILESIZE= $(ls -lah $FILENAME | awk '{ $FILESIZEINGB = $5}')\necho \"Size is $FILESIZEINGB .\"\n\nCan you please tell me why I can not see the file size in readable form ?\nIt seems $FILESIZEINGB is not set and I can not see the result in the echo output.\n\nA: You cannot set a shell variable from a child process - so setting FILESIZEINGB wouldn't work anyway (and it wouldn't work because that means something else in awk syntax).\nJust use du -h:\nFILESIZEINGB=$(du -h \"$FILENAME\" | awk '{print $1}')\n\nAlso:\n\n\n*\n\n*You shouldn't have a space after =.\n\n\nA: Or if you don't want to use du:  \nFILESIZE=$(ls -lah $FILENAME | awk '{ print $5}')\necho \"Filesize is $FILESIZE\"\n\n\nA: I found someone made an AWK one-liner, and it had a bug but I fixed it. I also added in petabytes after terabytes.\nFILE_SIZE=234234 # FILESIZE IN BYTES\nFILE_SIZE=$(echo \"${FILE_SIZE}\" | awk '{ split( \"B KB MB GB TB PB\" , v ); s=1; while( $1>1024 ){ $1/=1024; s++ } printf \"%.2f %s\", $1, v[s] }')\n\nConsidering stat is not on every single system, I would use the AWK solution. Example; the Raspberry Pi does not have stat but it does have awk.\n", "Q: Give access to php to /home folder I am need for apache to have access on all (well... most anyway) user folders on the same machine, so that I can access some data, do some magic and then display them on a webpage for remote viewing.\nWhat I thought would be the simplest solution is to create a dir alias that points to /home folder and allowing it to be accessed only locally, since all the \"magic\" will be happening server side and only the results will be shown. Problem is I cannot make the Alias to work.\nI added the following in my /etc/apache2/mods-enabled/alias.conf to check if it is working:\nAlias /home/ \"/home\"\n<Directory \"/home\">\n     Options Indexes MultiViews FollowSymLinks\n     AllowOverride None\n     Require all granted\n</Directory>\n\nbut I'm getting a 403 Forbidden.\nI also tried adding it as a virtual host on sites-enabled/000-default.conf and apache2.conf neither of which worked.\nI also added www-data to a user group that has access to /home, just to be sure.\nWhat am I missing here?\n\nA: Instead of fiddling with all those files, I simply did the following two steps:\n\n\n*\n\n*added the folders I needed to a group in which www-data is a member of and granted the group both read and execute permissions (for some reason execute was not enough), thanks Brian\n\n*Added what I originally had in my alias.conf to apache2.conf\nObviously I first removed all the havoc I had created in my previous attempts.\n", "Q: How to install Qt 5.x 32 bit on 64 bit ubuntu/debian? How to install Qt 32 bit and correctly build an application on 64 bit ubuntu/debian? Are there i686 or 32 bit packages like in SUSE? Which repositories?\n\nA: Simply install the same packages as for 64-bit, but append :i386 onto the package name. For example, libqt5webkit5:i386. To compile against the libraries, you'll also need the appropriate i386 version of the appropriate -dev packages.\n", "Q: Error Icon in the Unity-panel I tried to install Teamviewer on Ubuntu and ran into an error. After this error, I cannot get rid of this \"Error Icon\" from the Unity-panel. Does anyone know how to remove this? Thank you.\n\n\nA: Sometimes, when an application does not fully install, you need to fix the broken dependency chain. To resolve your issues, run:\nsudo apt-get install -f\n\nand Apt will attempt to fix all recent installation issues.\n", "Q: vmbuilder and Ubuntu 14.04 LTS I am trying to build a Ubuntu 14.04 image with vmbuilder like this:\nvmbuilder kvm ubuntu -o -v --suite trusty --arch amd64 --rootsize 9216 --user testuser --pass testpass --hostname test --addpkg libjson-perl --addpkg liburi-encode-perl --addpkg curl --addpkg acpid --addpkg openssh-server --addpkg memcached --addpkg php5-memcache --addpkg nfs-common --addpkg dmidecode --addpkg unzip --addpkg default-jdk --addpkg mysql-server  --addpkg libstring-shellquote-perl --tmpfs - --domain mydomain.com --ip 10.1.1.2\"\n\nHowever, it hangs like this:\n2016-04-15 16:58:57,769 INFO    : Mounting tmpfs under /tmp/tmpbH0ZdGtmpfs\n2016-04-15 16:58:57,794 INFO    : Calling hook: preflight_check\n2016-04-15 16:58:57,816 INFO    : Calling hook: set_defaults\n2016-04-15 16:58:57,817 INFO    : Calling hook: bootstrap\n\nThe machine I am building on is running 12.04 LTS. If I substitute trusty for precise in the above command, it does not hang.\nHow do I fix this?\nHelp appreciated.\n\nA: One cannot build a 14.04 image on a 12.04 host. One must use 14.04 to build a 14.04 image.\n", "Q: LXD not storing images in ZFS I configured LXD using existing ZFS pool. I then created a container, which is running correctly. LXD knows about the ZFS storage, because it created two directories there: containers and images. Also, \"lxc info\" displays the ZFS pool name.\nHowever, the directories in the ZFS pool are empty. The actual files have been stored in /var/lib/lxd.\nWhat am I missing here?\n\nA: Here is what it looks like for containers:\nroot@nsn7:~# zfs list -r nsn7/lxd/containers\nNAME                                     USED  AVAIL  REFER  MOUNTPOINT\nnsn7/lxd/containers                     2,95G   259G    19K  /nsn7/lxd/containers\nnsn7/lxd/containers/lds-xenial          2,68G   259G  3,16G  /var/lib/lxd/containers/lds-xenial.zfs\nnsn7/lxd/containers/maas-trusty          214M   259G   214M  /var/lib/lxd/containers/maas-trusty.zfs\nnsn7/lxd/containers/maas-trusty-virbr1  57,0M   259G   570M  /var/lib/lxd/containers/maas-trusty-virbr1.zfs\n\nObserve where each zfs dataset is mounted, above and in this output asking specifically for the mount-related options:\nroot@nsn7:~# zfs get all nsn7/lxd/containers/maas-trusty|grep mount\nnsn7/lxd/containers/maas-trusty  mounted               yes                                      -\nnsn7/lxd/containers/maas-trusty  mountpoint            /var/lib/lxd/containers/maas-trusty.zfs  local\nnsn7/lxd/containers/maas-trusty  canmount              on                                       default\n\n\nA: I saw this myself in the beginning, letting LXD set up the ZFS partition for me and then going back into it to set the mountpoint, but as you say it was empty.\nYou already have the answer provided by Andreas (and you should accept it as so), but just for clarification should it not be apparent: \nLXD mounts the individual paths in the same place as it would if using DIR - /var/lib/lxd/(containers/images) and setting a mount point at the root of the ZFS pool you set up won't give you visibility of these folders as you might expect on a \"traditional\" FS.\nIt isn't entirely clear when looking at it for the first time, but it's working as intended.\n", "Q: auto start a reverse ssh tunnel on system startup I am have a remote machine behind a firewall that I wish to connect to through SSH. As far as I understand this can be achieved by using a reverse ssh tunnel. \nSo the command I am using is \nssh -N -f -R 0.0.0.0:1234:localhost:22  -i /home/username/.ssh/id_rsa.pub  username@remote-server.com\n\nMy main problem is that I want to execute this command whenever the computer starts so that the computer is accessible after a reboot. \nI tried to use cron by adding the command both my user's crontab and in /etc/cron. However the problem  I have is that both commands are asked for a password. I have created the id_rsa.pub file and sent it to the remote-server but still it does not seem to work.\nIf I am logged in (e.g. through teamviewer) I can run the command and no password is asked. If I run the command as root (sudo) the (empty) password for the rsa file is asked. I suspect that my problem is here, i.e., when cron executes the command  ssh asks for the password and the command hangs.\nI have tried using both my user's rsa file and the root's rsa file and with none of them I manage to connect.\n\nA: Just add 'sleep 60;' before your ssh command:\n@reboot sleep 60;ssh -N -f -R 0.0.0.0:1234:localhost:22  -i /home/username/.ssh/id_rsa  username@remote-server.com\n\nAfter reboot your network is still down.\n\nA: After combining multiple sources, I created a service to auto start the reverse ssh channel. \nThe configuration files and the necessary steps are found \nin this repository\n\nA: A better solution may be autossh:\n\"autossh is a program to start a copy of ssh and monitor it, restarting it as necessary should it die or stop passing traffic.\"\nAs the quote says, this has the added benefit of providing 'always on' capabilities.\n\nA: Fixing SSH problem\nYou can't authenticate remote machine with public key, you need to use private key to do that. Public key has to be at remote server. If you're not sure, then just copy public key to remote server like that:\nssh-copy-id -i ~/.ssh/id_rsa.pub username@remoteserver\n\nand then run your command with private key:\nssh -N -f -R 0.0.0.0:1234:localhost:22  -i /home/username/.ssh/id_rsa  username@remote-server.com\n\nRunning this command at boot-up\nAs you went already with crontab then run crontab -e to edit your cron. Add following line to execute that command once your computer boots up.\n@reboot ssh -N -f -R 0.0.0.0:1234:localhost:22  -i /home/username/.ssh/id_rsa  username@remote-server.com\n\n", "Q: How can I toggle between two audio outputs via terminal? I have two audio outputs: one is a wireless headset, the other is my laptop's built-in 3.5mm jack. How do I switch between them via the terminal? Ultimately, I want to assign a keyboard shortcut to do the switch.\n\nA: I built a script which does the switching. I call it using xbindkeys. I'm sure it could be improved, because I'm not very good with grep, and it's not ideal that the script works on the basis of numbers instead of names. The script is big because it takes a lot of effort to automate the process, but here are the essential parts:\n# Identify any active sink inputs (audio streams - identified by number).\npacmd list-sink-inputs\n\n# Identify the next sink (output - identified by number or by name).\npacmd list-sinks\n\n# Switch the sink input to the next sink.\npactl move-sink-input \"$sink_input\" \"$next_sink\"\n\n# Change the default sink to the next one.\npactl set-default-sink \"$next_sink\"\n\n", "Q: MAAS 1.9.1 GUI Taskbar missing Network TAB on Ubuntu 14.04.4 I deployed MAAS 1.9.1 on Ubuntu 14.04.4 but all the install guides showing MASS GUI having Network Tab ie\nNodes-Cluster-Images-Zones-Network-Settings\nbut i am seeing the GUI Taskbar option below\nNodes-Cluster-Images-Zones- SUBNETS -Settings\nie Subnets instead of Networks\nIs there something wrong here or do i need to install any more packages etc....\nThank you \n\nA: if you install Ubuntu Server 16.04 LTS you will see the Network tab. I ran in to same issue but when I install 16.04 then I lost Cluster tab, still trying to figure it out..\n", "Q: Ubuntu - Auto Pilot Open stack Deployment Guide I have Ubuntu 14.04.4 Installed and wondering if there is a guide step by step with details and screenshots to deploy the components below\nMAAS-Landscape-OpenStack\nThe guide available online is not very helpful. In some cases apt-get not even working...\n\nA: Here is the official guide.  If you have issues, please post a new question here with specifically what went wrong.\nBuild OpenStack with conjure-up | Download | Ubuntu\n\nA: You may definitely install OpenStack the hard way as you inquire, the steps are detailed in the official OpenStack install guides -- here is the link to the 14.04 \"Liberty\" version:\nInstalling \"Liberty\" on Ubuntu 14.04\nAs you will quickly see, the details imply a lot more work that the Autopilot automates needs to be performed by the admin. If that's suitable, those are the docs!\n", "Q: Ubuntu 16.04 ubuntu-make android error: a default framework for category Android was requested where there is none I try to install Android Studio 2.0 in Ubuntu 16.04 using ubuntu-make as described in the wiki manual and the video.\nfieldmarshal@fmcomp:~$ umake android\nERROR: A default framework for category Android was requested where there is none\nusage: umake android [-h] {android-ndk} ...\n\nAnother way of input didn't help either:\nfieldmarshal@fmcomp:~$ umake android android-studio\nusage: umake android [-h] {android-ndk} ...\numake android: error: argument framework: invalid choice: 'android-studio' (choose from 'android-ndk')\n\nAlthough other IDEs are installed normally, e.g. when I run:\numake ide idea, everything is okay.\nBut I keep getting these errors when I try to install Android Studio.\n\nA: I found a solution in another askubuntu thread: Why can't I get Android Studio from umake anymore?\nThe following, taken from above link, worked for me, even though I am using Linux Mint:\nYou need to have the latest Version of umake, which is 17.03 as of the time of writing. Mine was old, so I replaced it.\numake --version\n\nDon't install umake from the standard ubuntu repositories, instead add ubuntu-desktop repository to get latest umake version. Add repository by\nsudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make\n\nUpdate software Source\nsudo apt-get update\n\nNow install/upgrade umake\nsudo apt-get install ubuntu-make\n\nNow install Android Studio by\nsudo umake android\n\n", "Q: MAAS interface eth0 (External) and eth1 (internal) I have two interfaces configured in MAAS under Cluster\neth0 - external IP VLAN 10\neth1 - internal (10.x.x.x) VLAN 20  - DHCP-DNS Managed\nI am going to add a node in MAAS.....I have setup the node (machine) to boot from Network (PXE).....Node has two Interface \neth0 - VLAN 10\neth1 - VLAN 30\nQs:\n1. Does the MAAS server eth1 connects with eth1 of new node automatically when i power up the Node......\n2. Do both eth1 has to be on the same VLAN\n3. Or MAAS will install the new NOde thru eth0 which are on same VLAN and assign internal IP from its DHCP to eth0 of the New Node.....\nRight now if i reboot the New Node it is keep looking for a boot server and timing out......\nThank you\n\nA: A1. No, since they are on different VLANs 20 and 30. Both MAAS server as well as the nodes to be managed by MAAS should be in the same network or VLAN or whatever.\nA2. Yes, that's right!\nA3. Since, MAAS is managing DHCP and DNS on eth1 (of MAAS server), it will not manage the network it is connected to through eth0.\nIf you want MAAS server to manage nodes on eth0, it should be allowed to run its DHCP and DNS services on that interface too.\nPlease correct me if I am wrong.\nHope it helps!!\nBut, then if there is already a DHCP or DNS server running on that network then it will get messed up.\n", "Q: Accidentally killed plasma I accidentally pressed ctrl + alt + esc, clicking on the process in the task manager, but it didnt work, and it selected the whole plasma desktop and got killed, is there a quick fix to start up plasma again by opening a terminal?\n\nA: Try to run the command plasmashell and see if that works.\nIf only Plasma crashed, try plasma5-desktop --replace.\nThis will kill all remaining instances of Plasma and start a new one.\n", "Q: My keyboard won't print characters other than lower case Latin alphabet I'm not sure how this happened, but other than Latin lower case alphabet characters, all the letters and numbers on my keyboard provide odd characters.\nFor example:\nabcdefɡhijklmnopqrstuvwxyz\nWith shift:\nɑβçðɛɱɣɥɪɲɬʎɯŋɔʋɒʁʃθʊʌʍχʏʒ\nAnd one throuɡh equal siɡn on number row:\nɨøɜɾɫɐɤɵœ̥-̩\n\nA: It was team viewer.  It apparently ignores all keyboard settings on the remote host.  Even though the client computer was working fine.  Even typing in the partner ID box gave those weird characters.  Restarting it fixed the issue.  Strange as there are no keyboard input settings anywhere in team viewer that I could actually find.\n", "Q: Do I need to partition C: or can I used D:? I want to install Ubuntu in Dual Boot with my Windows 10 and I know that I need make some partitions to install ubuntu. \nAt the moment in my windows 10 I have both a C: and a D: drive:\nC: - has Windows installed and his where I save my files/pics/etc\nD: - is where I have my games and some random things, nothing important and I don't think I need a lot of space(I don't install a lot of games at the same time)\nAnd because of this I would prefer to shrink D: instead, and use that space.\nSo my question is: Do I need to shrink the C: drive or can I shrink the D:\ndrive instead?\nDisk Management - My Drives atm\nI only installed in dual boot once and that PC only had C: drive so I'm not really sure.\n\nA: Since you have it all on one HDD shrink your D: drive for installing ubuntu.\nBe aware that you may want for a proper running system at least 10-15 GB (means i  you want to install alot of tools like me :D the more is the better) and around double size of your ram for a swap partition (don't kill me im just repeating what i have read mostly) but i think you will suffice with less swap if you already have lots of ram in your system because the less likely the system is going to use the swap partition.\njust leave the free partition space unallocated, start from your LIVE CD and choose to install alongside Windows.\n\nA: As mikewhatever said in a comment, it technically doesn't matter at all.  Just give it some free space, somewhere, and it can install there and run.\nIn practice though, you might have other reasons to set it up one way or another, and it can be confusing at first to figure out what the installer calls each drive or partition.  Thus, when I set up my laptop to dual-boot (or re-install the same or a different system), I pull the quick-remove storage-only drive so that I don't accidentally end up depending on that to boot to any system, which is entirely possible if you get things mixed up.\n\nAlso, the DOS/Windows drive letters do not correspond to physical drives.  They are partitions, which may or may not be on the same physical drive or different drives.  For example, a pre-built, ready-to-go PC might have exactly one physical hard drive that is partitioned into a C:/ drive for normal use and a D:/ drive for \"recovery\".  The screenshot in the question above shows this, except that the \"recovery\" partition in this case doesn't have a drive letter.  That probably means it's formatted with something that Windows can't read (but the OEM recovery tool can), possibly to prevent a user from messing it up like you could with earlier versions of that idea.\nAnyway, since there's really just the one physical drive in the entire system, how is the \"recovery drive\" supposed to handle a hard drive crash???  Seems kinda useless to me, unless you screw up your settings I guess, or install some crapware, and the drive itself is fine.  And Windows 10 has its own recovery tools that don't use a separate partition anyway.  (I've used them to reset a PC that I set up for a specific application, and then went a different direction.)\nSo I'd be tempted to just blow away the recovery partition and use that space for something else.  Either absorb it into a neighboring partition (grow the neighbor into it), or put Ubuntu (or whatever) there if it fits comfortably.\n", "Q: Packaging for PPA .deb Creation Missing Files So after floundering around from doc to doc I've latched onto and been following this tutorial: http://packaging.ubuntu.com/html/packaging-new-software.html\nSo I tried the steps in there and started running into troubles. Googling around has been largely unhelpful. I have a very standard autotools c++ project which builds a library and some executables. I wanted to make a libfoo-dev style package out of it and stick it up on a PPA.\nTo help show what I'm doing, I've stuck a script that does the steps proposed in the tutorial (so far as I am understanding them correctly..). Here's what I have: https://github.com/kevinkreiser/ppa-libprime-server\nI have a bash script in there build.sh which has all the steps I've been doing. At first I was having trouble getting dh_* to build anything from my project until @sneetsher clued me into changing the rule file to do autoreconf. At this point my only issues are W: libprime-server0: empty-binary-package and W: prime-server-bin: empty-binary-package.\nAnd like it says, the problem is now that a couple of my packages don't have much of anything in them:\nuser@pc$ lesspipe libprime-server0_0.3.2-0ubuntu1_amd64.deb \nlibprime-server0_0.3.2-0ubuntu1_amd64.deb:\n neues Debian-Paket, Version 2.0.\n Größe 2004 Byte: control-Archiv= 528 Byte.\n     425 Byte,    12 Zeilen      control              \n     160 Byte,     2 Zeilen      md5sums              \n Package: libprime-server0\n Source: libprime-server\n Version: 0.3.2-0ubuntu1\n Architecture: amd64\n Maintainer: Kevin Kreiser <kevinkreiser@gmail.com>\n Installed-Size: 26\n Section: contrib/libs\n Priority: optional\n Homepage: https://github.com/kevinkreiser/prime_server\n Description: Service oriented distributed computing API\n  A set of APIs designed around the zeromq butterfly pattern\n  specifically focused on servicing http requests\n\n*** Contents:\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./usr/\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./usr/share/\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./usr/share/doc/\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./usr/share/doc/libprime-server0/\n-rw-r--r-- root/root       167 2016-04-18 11:04 ./usr/share/doc/libprime-server0/changelog.Debian.gz\n-rw-r--r-- root/root      1558 2016-04-15 09:46 ./usr/share/doc/libprime-server0/copyright\n\nuser@pc:~/sandbox/ppa-libprime-server/build$ lesspipe prime-server-bin_0.3.2-0ubuntu1_amd64.deb \nprime-server-bin_0.3.2-0ubuntu1_amd64.deb:\n neues Debian-Paket, Version 2.0.\n Größe 1994 Byte: control-Archiv= 517 Byte.\n     437 Byte,    12 Zeilen      control              \n     160 Byte,     2 Zeilen      md5sums              \n Package: prime-server-bin\n Source: libprime-server\n Version: 0.3.2-0ubuntu1\n Architecture: amd64\n Maintainer: Kevin Kreiser <kevinkreiser@gmail.com>\n Installed-Size: 26\n Depends: libprime-server0 (= 0.3.2-0ubuntu1)\n Section: contrib/misc\n Priority: optional\n Homepage: https://github.com/kevinkreiser/prime_server\n Description: Service oriented distributed computing executables\n  A set of executables for use in running a distributed http service\n\n*** Contents:\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./usr/\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./usr/share/\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./usr/share/doc/\ndrwxr-xr-x root/root         0 2016-04-21 11:48 ./usr/share/doc/prime-server-bin/\n-rw-r--r-- root/root       167 2016-04-18 11:04 ./usr/share/doc/prime-server-bin/changelog.Debian.gz\n-rw-r--r-- root/root      1558 2016-04-15 09:46 ./usr/share/doc/prime-server-bin/copyright\n\nThe first package does work if I re-name the files back to libprime-server1.install and libprime-server1.dirs. I haven't be able to figure out what I'm doing wrong with the -bin package. bzr asks about the type of package I am making and I choose l for library should I be choosing something else?\nEDIT:\nThe whole thing works: https://launchpad.net/~kevinkreiser/+archive/ubuntu/prime-server\nWith the help of @sneetsher I was able to get all of this up on a ppa and working properly in trusty! I just want to thank @sneetsher for all of the help and patience along the way. Hopefully this script can help others looking to do something similar: https://github.com/kevinkreiser/ppa-libprime-server/blob/master/build.sh\n\nA: Well, I could test it on Ubuntu 14.04 and (with last commit) in Ubuntu 16.04.\n\n\n*\n\n*As you are new to packaging, it better to enable the verbose debhelper output. Uncomment export DH_VERBOSE=1 in the rules file.\n\n*The package seems to depend on autoreconf not just automake/autotools. So change the rules main line to:\n%:\n    #dh $@ --with autotolls-dev\n    dh $@ --parallel --list-missing --with autoreconf\n\nand add dh-autoreconf to build dependencies in control file.\nSo you are now longer need to pre-generate the auto build files by running ./autogen.sh manually. Keep in mind that every thing should be done through rules file, otherwise it will fail when it is built on PPA server with clean source tree.\n\n*One of the tests fails, I go around by skipping them. overriding the dh_auto_test. So I add this to the rules file:\noverride_dh_auto_test:\n    echo skip auto-test\n\nleave it later to be fixed.\n\n*For the empty libprime-server package, this is because it's has a wrong name.\nlibprime-server in control file and libprime-server1 with 1 in others (like libprime-server1.install)\n\n*Yes, lintian (QA tool) raises that warning because it expect to be the major version of the package. Yes, it should be ok to rename it to libprime-server0. There is only one note, you have to clean up the build tree from the previous build. So delete debian/libprime-server1 folder & try rebuild again.\nYou can add as many packages as you want, see updated files below.\n\n*Yes, dependencies should include the binary package, libprime-server0. The source package libprime-server it is not a dependency on any.\n\n*I wasn't using your script to build, I was using another manual work-flow (Download original zip archive, extract it, add debian folder, build using debuild). I couldn't reproduce same issue as that one of empty binary packages.\nI could reproduce it with build.sh. The problem, you have changed the full debian/:\nrm -rf libprime-server/debian\ncp -rp ../debian libprime-server\n\nbut committed only one file\nbzr add debian/source/format\n\nto fix it, commit the whole folder:\nbzr add debian\n\nbzr builddeb seems to use only the commit/tag (with Debian label) files, not the current working tree.\nHere are the files I have changed:\n\n\n*\n\n*debian/rules\n#!/usr/bin/make -f\n# -*- makefile -*-\n\n# Uncomment this to turn on verbose mode.\nexport DH_VERBOSE=1\n\n%:\n    #dh $@  --with autotools-dev\n    dh $@ --parallel --list-missing --with autoreconf\n\noverride_dh_auto_test:\n    echo skip auto-test\n\n\n*debian/control\nSource: libprime-server\nPriority: optional\nMaintainer: Kevin Kreiser <kevinkreiser@gmail.com>\nBuild-Depends: debhelper (>= 9), autotools-dev, dh-autoreconf, libcurl4-openssl-dev, libzmq3-dev\nStandards-Version: 3.9.5\nSection: libs\nHomepage: https://github.com/kevinkreiser/prime_server\nVcs-Git: git://github.com/kevinkreiser/prime_server.git\n\nPackage: libprime-server-dev\nSection: contrib/libdevel\nArchitecture: any\nDepends: libprime-server0 (= ${binary:Version}), ${misc:Depends}\nDescription: Service oriented distributed computing API\n A set of APIs designed around the zeromq butterfly pattern\n specifically focused on servicing http requests\n\nPackage: libprime-server0\nSection: contrib/libs\nArchitecture: any\nDepends: ${shlibs:Depends}, ${misc:Depends}\nDescription: Service oriented distributed computing API\n A set of APIs designed around the zeromq butterfly pattern\n specifically focused on servicing http requests\n\nPackage: prime-server-bin\nSection: contrib/misc\nArchitecture: any\nDepends: libprime-server0 (= ${binary:Version}), ${misc:Depends}\nDescription: Service oriented distributed computing API\n A set of APIs designed around the zeromq butterfly pattern\n specifically focused on servicing http requests\n\n\n*libprime-server1.install is renamed to libprime-server0.install\n\n*libprime-server1.dir is renamed to libprime-server0.dir\n\n*Create prime-server-bin.dirs\nusr/bin\n\n\n*Create prime-server-bin.install\nusr/bin/*\n\n\n*build.sh\n#!/bin/bash\n\nset -e\n\nrm -rf build\nmkdir build\npushd build\n\n#get prime_server software\n#sudo apt-get install autoconf automake libtool make gcc-4.9 g++-4.9 lcov\nsudo apt-get install libcurl4-openssl-dev libzmq3-dev\ngit clone --branch 0.3.2 --recursive  https://github.com/kevinkreiser/prime_server.git\ntar pczf prime_server.tar.gz prime_server\nrm -rf prime_server\n\n#start building the package\nsudo apt-get install dh-make dh-autoreconf bzr-builddeb\nbzr dh-make libprime-server 0.3.2 prime_server.tar.gz\nrm -rf libprime-server/debian\ncp -rp ../debian libprime-server\npushd libprime-server\nbzr add debian\nbzr commit -m \"Initial commit of Debian packaging.\"\nbzr builddeb -- -us -uc\n#TODO: sign the package\npopd\n\n#TODO: push the package to the ppa\n\n#TODO: make an ITP for inclusion in mainline\n\npopd\n\n", "Q: How do I scp a filename with spaces? I'm having a little difficulty using scp to transfer files from a remote computer. The issue apparently has to do with the name of the directory the files are contained in. They're on a CD drive called photos 4 (with a space between photos and 4). When I attempted the transfer, I used the following command:\nscp [remote username]@192.168.1.X:/media/[remote username]/photos\\ 4/file.jpg /home/[username]/Pictures\n\nHowever, I get an error message in return saying No directory: /media/[remote username]/photos. I thought the backslash would escape the space so that the directory would be read as photos 4.\nCan someone fill me in on what I'm doing wrong here?\n(As an aside, I made a copy of file.jpg to the remote computer's desktop and then ran the command:\nscp [remote username]@192.168.1.X:/home/[remote username]/Desktop/file.jpg /home/[username]/Pictures\n\nand it worked, so that escape sequence seems to be the culprit. I just can't figure out what's wrong with it.)\n\nA: Spaces in directories or filenames are the natural enemy of a Linux system but can of course be escaped with due diligence. There are 3 possibilities that you could try:\n\n\n*\n\n*scp [remote username]@192.168.1.X:\"'/media/remote_username/photos 4/file.jpg'\" .\n\n*scp [remote username]@192.168.1.X:\"/media/remote_username/photos\\ 4/file.jpg\" .\n\n*scp [remote username]@192.168.1.X:/media/remote_username/photos\\\\\\ 4/file.jpg .\nAll should work but some are syntactically easier to understand than others...\nReferences:\n\n\n*\n\n*How to escape spaces in path during scp copy in linux?\n\nA: Here is the fix for ZSH users,\n\n*\n\n*scp 'username@192.168.1.X:/media/\"photos 4\"/file.jpg' /home/username/Pictures\n\n*scp 'username@192.168.1.X:/media/\"photos 4\"/\"file with space.jpg\"' /home/username/Pictures\n\n", "Q: I cant find Leauge of Legends on the playonlinux \"testing\" box I cannot find the \"league of legends\" game under the \"testing\" category that all the online tutorials tell you to do.\nI have installed play on Linux through:\nsudo apt-get install playonlinux\n\nHave I done anything wrong?\n(( play on Linux version 4.0.14 ))\n\nA: It might be temporarily hidden, try installing it from it's profile page or copy its installer's source code into local file and run it manually ( Tools > Run Local Script ):\nhttps://www.playonlinux.com/en/app-1135-League_Of_Legends.html\nUnfortunately I don't know any easy way to just download a script from PlayOnLinux page... it leaves us with Copy & Paste.\n", "Q: Does MAAS Cluster Controller API URL need to setup to Internal Network and not LAN Network MAAS 1.9 - Ubuntu 14.04.4\nWondering if the MAAS Cluster Controller API URL need to setup to Internal Network and not LAN Network..... My Internal network is 10.x.x.x on eth1  and not accessible from my computer browser ie i cannot http://10.x.x.x/MAAS to it........\nCurrently the address is set to http://172.x.x.x/MAAS and it is accessible from my computer browser but it unable to commission any nodes......and getting Status Failed commissioning status.........\nAlso do i have to add the MAC address of all the machines manually for MAAS to discover ... as i am not finding any option for MAAS to auto discover any new devices.....Thank you \n\nA: You 'external' connection should be set by using...\nsudo dpkg-reconfigure maas-cluster-controller\n\nYour 'internal' connection should be set using...\nsudo dpkg-reconfigure maas-region-controller\n\nWhatever you set your internal to, is the network that your nodes should exist within.  You shouldn't have to add any mac addresses, aslong as PXE is enabled on your nodes, when they boot they should be able to find maas, and then run through the boot, and then shut off.  Once they're off, you should see them in maas.  \nYou need to obviously configure your IPMI, or power control settings as well.  Those IPs should exist within your 'internal' network as well.  They don't have to, but if they are outside that network, maas has to be aware of that network and be able to connect to it as well, potentially eth2.\n", "Q: Freeze after installing Ubuntu When I install Ubuntu, my PC reboot, I have to enter my password, and here is the problem. \nAfter entering my password, everything is normal, but 30 seconds after, EVERYTHING freezes! The keyboard, the mouse, the screen. I don't know why. \nI've tried to install a lot of OS based on Linux. And I have the same problem. \nI'm a newbie on Linux.\nNOTE: Sorry for my english, i'm French.\nNOTE2: I have already installed Ubuntu on my other PCs and I don't have this bug. Maybe a hardware problem? Like the graphic card?\n\nA: If you think the graphics driver is to blame try installing properitary drivers. You can try loading the kernel in recovery mode and select Additional Drivers for your graphics card. Look at accepted answer to this question for more details: Ubuntu 14.04 LTS crashes after login\n\nA: You can boot into recovery mode (hold Shift before loading GRUB for a menu), select a root terminal and try installing NVidia's propriatary driver. Haven't done that this way, but I'll give you some clues what to enter there:\nmount -o remount,rw /\napt-get install nvidia-current\ndpkg-reconfigure xserver-xorg\nupdate-initramfs -u\n\n(you might not need last 2 commands, try them if after reboot still won't work)\nYou can also try replacing nvidia-current with version of driver you want to install. One way to find out what's available is:\ndpkg --get-selections nvidia-*\n\nThere's also this, but it gives specific versions, not packages names:\napt-cache show nvidia-* | grep Version | more\n\nTry it if solution provided by @NonStandardModel won't work.\n", "Q: Making my 32-bit program code compile on 64-bit Ubuntu (looking for safe path) I have for the first time installed a 64-bit Ubuntu on my laptop. Now I am looking for a way to compile my old biology C++ project on this OS. I have a .sh file that installs all necessary packages for my project to compile on a newly installed 32-bit Ubuntu. The content of this file is the following:\n#!/bin/sh\napt-get update  # To get the latest package lists\napt-get install build-essential -y\napt-get install freeglut3-dev -y\napt-get install libsdl1.2-dev -y\napt-get install libsdl-image1.2-dev -y\napt-get install libsdl-mixer1.2-dev -y\napt-get install libopenscenegraph-dev -y\n\nNow the problem is, after having installed those packages on my 64-bit Ubuntu, and wanting to compile my project with the according Makefile, I get the following error message:\n/usr/bin/ld: skipping incompatible ../../gllib-3.0b3/lib/libgll.a when searching for -lgll\n/usr/bin/ld: cannot find -lgll\n\nAfter having checked, I now know that libgll.a file was compiled for elf33-i386 architecture. Because I do not know how to recompile this file for 64-bit architecture, I am pretty sure that I have to compile my entire project in 32-bit architecture.\nLong story short, my question now is: How can I make this project compile as a 32-bit application, and run it on 64-bit Ubuntu?\nMy guess would be, that I have to use the command dpkg --add-architecture i386 and then manually install the packages of interest with apt-get install <package-name>:i386. Problem with that method is, that apt-get install libsdl1.2-dev:i386 requires me to uninstall the build-essential package.\nOf course finally I will also have to modify my makefile, adding -m32 to CXXFLAGS (and other lines?). I can post my makefile if this is required for you to help me. ^^\nWhat I first tried was to just simply install everything the way I had on my previous 32-bit machine.\nThe problem is, I get the following compilation error: /usr/bin/ld: skipping incompatible ../../gllib-3.0b3/lib/libgll.a when searching for -lgll\nThis made me think that probably my (5 year old) was just not compatible to run as a 64-bit application.\nOr would you happen to know if I should be able to compile this as native 64-bit? ^^\n\nA: It is very strange that whatever program you are trying to compile ships a 32 bit binary library instead of its source code, but apparently this library can be found here, and if you compile that you should get a 64 bit libgll that you should be able to use to compile this program for 64 bit.\n", "Q: wget to get a file generated by a php script I am trying to get a file generated by the php script export.php. But using this command, I am either getting 403 Request Forbidden or downloading the script itself instead of a .csv the script is supposed to generate. If I visit the link manually on Chrome, the download starts automatically and the csv file is downloaded\nwget -U Chrome http://proto.agrech.com/export.php \n\n\nA: Solved by getting the CURL command to go from the browser to download the .csv\n", "Q: Error when trying to mount using live CD I was following this answer to resolve my boot problem and when running: \nsudo mount /dev/sdb /mnt \nI get this error: \nmount: /dev/sdb already mounted or /mnt busy\nThe sdb is the drive which has 3 partitions: \nsdb1 fat32 and the flag is set to boot\nsdb2 ext4  \nsdb3 linux-swap\n\nam I selecting the right disk as stated in that answer? \n\nA: If your drive already has partitions with data on them you absolutely do not want to mount the drive.  You want to mount the partition:\nsudo mount /dev/sdb2 /mnt\n\n", "Q: Ambiance - How to close windows at the top? So I've used other OS's in the past and I could always close the Windows by moving the mouse cursor to the far top right corner of the screen and just click with the mouse, but I'm not able to do that with Ambiance. \nIs that even possible for Ambiance? I'm using UbuntuMATE.\nCheers! :D\n\nA: I'm also on Ubuntu with MATE and Ambiance looks like this:\n\nThere are buttons in top right corner, in all themes there are. Your OS must be missing something... is there a message in theme changing tool when you select Ambiance?\nUpdate from comments:\nHere's the ultimate solution. Managed to run a quick batch on all those icons with Phatch+ImageMagick, fixed couple manually with GIMP and here it is... Custom Ambiance closeable on very top right corner while maximized:\nhttps://drive.google.com/file/d/0B7Jj61b72RMWMVZ3TDdVbmJfbnM/view?usp=sharing\nUnpack into ~/.themes/ ... Almost everything is possible on Linux :)\n", "Q: HOWTO access microphone data I need to access my microphone data in 3 ways, how do I:\n\n\n*\n\n*dump the raw data stream generated by microphone into terminal\n\n*play/listen to the real-time audio captured, using the gui or terminal.\n\n*record the audio into wave files using the terminal.\n\n\nAlso if possible I would like to be able to do number 1 and 3 at the same time.\nThank you for your time.\nOS: Ubuntu 14.04\nMic: Logitech G930\n\nA: You need to work with Audio Linux Sound Architecture - ALSA . The main How-To is found here.\nWith above How-To you can:\n\n\n*\n\n*get List of sound devices and select one which has IRQ.\n\n*record sound into .wav with arecord -d 10 /tmp/test-mic.wav\n\n*and play that file with aplay /tmp/test-mic.wav.\n\n\nBut if you need to dump raw data stream and work with that you should go deeper and refer to AlsaProject. You'll find several good links on how to do that. For example ALSA Programming HOWTO.\n", "Q: Startup Disk Creator fails to format USB drive I'm trying to create a bootable Ubuntu disk using Startup Disk utility, but when I try to erase the USB memory, this appears:\norg.freedesktop.DBus.Python.GLib.Error: Traceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/dbus/service.py\", line 707, in _message_cb\n    retval = candidate_method(self, *args, **keywords)\n  File \"/usr/share/usb-creator/usb-creator-helper\", line 287, in Format\n    partition = table.call_create_partition_sync(0, size, '0x0c', '', no_options, None)\nGLib.Error: udisks-error-quark: GDBus.Error:org.freedesktop.UDisks2.Error.Failed: Error wiping newly created partition /dev/sdd1: Command-line `wipefs -a \"/dev/sdd1\"' exited with non-zero exit status 1: wipefs: error: /dev/sdd1: probing initialization failed: No such file or directory\n (0)\n\n\nA: The Startup Disk Creator tool is known to having some issues to create the USB properly.\nInstead use the Disks tool (gnome-disk-utility) to create the Ubuntu installation media.  \nOpen Disks and select Restore Disk Image from the menu on the top right of the application.\nChoose the Ubuntu installation ISO file and the USB drive to write it to and then start restoring.\n", "Q: When I press a volume up/down key, what shell command does it send? I want to make a keyboard shortcut that changes the volume with exactly the same behaviour as pressing one of the default volume keys (up, down, mute), including the OSD notification and the \"pop\" sound. Right now, my bodged method is to have xdotool press the volume key, but it would be simpler to find the command the default volume keys send when pressed. \nI don't want to use unity-control-center to reassign the volume keys, because I want to leave the default volume keys in place.\n\nA: Personally, I use two shortcuts , one bound to CtlrAltArrow Up for volume up and CtlrAltArrow Down for volume down, which you can set in Settings -> Keyboard -> Shortcuts -> Custom.\nShortcuts are bound to two script files, given full path (though you don't have to place the commands bellow into scripts necessarily ).\nFor volume up, the command in script file is:\namixer sset Master 10+ && notify-send \"volume up 10\" && sleep 0.25 && killall notify-osd\n\nAnd for volume down the other command is\namixer sset Master 10- && notify-send \"volume down 10\" && sleep 0.25 && killall notify-osd\n\nAs you can guess, the two commands raise and lover volume in increments of 10 depending on your sound card. You can also use 10%+ to increase volume up 10% from what the current value is, but keep in mind that when decreasing the volume, the current value will get smaller and smaller, so it will be difficult to raise it back from smaller number (because 10% of small number will also be small) \n", "Q: accessing a supposedly recovered hard drive I was using Fedora linux and my hard drive crashed. I paid to have the hard drive recovered to a portable drive (name is passport). I scrapped the previous computer (it was getting old\nand annoying to update Fedora) so now I am using Ubuntu linux. When I plug the portable drive in, I think the mount is automatic. But, when I\n\n\n*\n\n*tried to use the command line at /media/whatever/markleeds to  see the actual data, I got \"access denied\".\n\n*tried to use the file manager and click on a directory or copy a directory\nto my actual  hard drive,  I get \"error copying whatever\". Click for more\ndetails says \"access denied\".\n\n\nThey told me that they used the ext4 file format but I cannot figure out\nwhy I can't get access. sudo cd doesn't work because it seems that you\nhave to create shell first? The owner is 1000 which may be the source of\nthe problem.\nIf they used the wrong file format by accident, would that cause the access problems? Thanks for any tips, pointers. The company I am using is trying again with the hope that something was done incorrectly the first time.\nIs it safer to recover using say NTFS or something else and then converting to ext4?\n\nA: Have you checked files permissions? You can recursively update those with this:\nsudo chmod -R 744 /media/whatever/markleeds\n\nThis will give you ALL possible permissions for all files and folders there and read access to group and others.\nExplanation of the octal triple:\n(7)(4)(4)\n|  |  |\n|  |  (others) read only\n|  |\n|  (group) read only\n|\n(user) read, write and execute\n\nThe octal numbers are summed up to reflect the files permissions where in that example for the user:\n(4) read access + (2) write access + (1) execute permission = 7 \n\nAnd here's how you change owner recursively:\nsudo chown -R markleeds:markleeds /media/whatever/markleeds\n\n", "Q: The following packages have been kept back : google-chrome-stable Today when i tried to update, i got a message that there was 1 upgrade to be made, so i did a sudo apt-get upgrade and got this message:\nThe following packages have been kept back: google-chrome-stable\nSo i looked around and it said that sudo apt-get dist-upgrade would fix the problem, but it didn't. Then i opened Synaptic, went Fix Broken Packages, and still nothing.\nI finally searched for google-chrome-stable in Synaptic, found the packages and when i marked them for upgrade i got this:\n\nHow can i fix this?\nI should note that i am using Ubuntu 12.04 - 64 bit\n\nA: Ubuntu 12.04 does not receive updates for Google Chrome, more information you can find here :\nThe support for Google Chrome on 32-bit Linux systems and Ubuntu 12.04 ended in March 2016.\nYou should uninstall Google Chrome mainly, because you do not get security updates anymore !  \nTo remove Google Chrome open a terminal and execute :   \nsudo apt-get purge google-chrome-stable \n\nTo remove the Google Chrome repository execute :  \nsudo rm /etc/apt/sources.list.d/google-chrome.list  \n\nTo remove all the configuration files delete this folder : /home/user/.config/google-chrome \nCheck whether there is another Google .list file in the sources.list.d folder and in case there is - remove it as well. Alternatively you can install the chromium-browser, on which the Google Chrome web browser is built or you wait a few days and install the new Ubuntu 16.04.\n\nA: The dist-upgrade command cleaned out your repository list, disabling the outdated google-chrome.list.\nThis can be fixed by reinstalling the latest version of Chrome\nGoogle Chrome for Ubuntu can be downloaded from Google.  At present, the 64bit version is the only one available.\nThe error is resolved by installing the latest version from Google.\nThe download link is http://www.google.com/chrome.  The official link can also be found with a google search of download chrome.\n", "Q: How do I install Ubuntu to a USB drive WITHOUT touching my hard drive boot Ok, before you say this is a duplicate, please let me explain and then point me to the duplicate answer and I will delete this post. I have searched a bit but I have found no definitive answer or way to do this. I have tried installing Ubuntu onto a USB before without touching my HDD but it installed Grub and then all the boot files on the USB. I have a duel boot Ubuntu/Windows 10 now but not because I wanted to. I originally just had Windows and wanted to install Ubuntu on a flash drive so I could transfer it to any computer like a live .iso file but it failed miserably. It put the boot files on the USB and installed Grub to my HDD and so I could not boot my computer without the USB. I have since turned my computer into a duel boot so now I can boot it fine but I still want to try to install Ubuntu onto a USB in a way that I can transfer it to another computer and it will run like a live copy but with more space (and before you tell me to just create a live one and add a second partition, I tried and it didn't work... several times.) So, is there a sure fire way to do a complete install onto a USB and install Grub only onto the USB in a way that will not touch my current boot status at all? \nEDIT:\nIt's been over a year now and I still haven't been able to do this yet I haven't tried for a long time. When I first tried this, I had a bootable USB and went through the process of installation on the same USB and went through the process of selecting the USB for both installation and GRUB. For some reason, Grub did get installed correctly to the USB but it screwed up my master boot record and would only boot to grub on the USB. This got fixed when I decided to do a full install and it recognized my other boot files. I could have messed up somewhere in the process but I can't remember. I will try doing this again but this time around I will do it in a virtual machine. I will try the solutions you have made and get back with the working solution. \n\nA: How about unplugging your HDD and then installing Ubuntu to the USB drive.\n\nA: I have used Unetbootin to create many different bootable USBs.\nIt has never tried to touch my Grub.\nIf you want to boot from USB without touching your HDD's boot sector, you will need to check your PC's BIOS settings.  In the \"boot order\", USB will need to come before HDD.\n(People say Unetbootin is out-of-date, but I haven't found a decent alternative.  I mostly use it's lower options to \"burn\" an ISO which I have manually downloaded.  It takes some time doing compression!)\n\nA: Make a second drive that is the Ubuntu Live CD/DVD/USB, and boot from that. Then use that to do \"something else\", and select the flash drive from the disks. Then, at the bottom, MAKE SURE that it has \"Install bootloader to\" set to your USB drive. This is critical.\n\nA: I did this last week. I booted a live-usb of LinuxMint and installed it. Instead of just installing it on my HDD I set \"something else\" and chose the Bootloader to be installed on the stick.\nI made some partitions (1M Grub, 100M /boot, 20G /, 4G /swap, and the rest (it was a 128G-Stick) as /home).\nIt needed some time but worked fine.\n", "Q: AppArmor: Unusual denied \"name=\" message I have a custom AppArmor profile to confine Syncthing. (I realise that this might not be a specific Ubuntu question, but I only use Ubuntu so I haven't seen if this affects other Linux distros). \nThis is the profile: \n#include <tunables/global>\n\n/usr/bin/syncthing {\n  #include <abstractions/base>\n\n  # Obviously needs Internet access to work.\n  network raw,\n  network inet,\n  network inet6,\n\n # Access to execute binary\n  /usr/bin/syncthing cx,\n\n  # Wants read access to SOMAXCONN\n  /proc/sys/net/core/somaxconn r,\n\n  # Needs to be able to read these to work properly\n  /run/resolvconf/resolv.conf r,\n  /etc/hosts r,\n  /etc/host.conf r,\n  /etc/nsswitch.conf r,\n  /etc/ssl/certs/** r,\n  /etc/mime.types r,\n  /etc/gai.conf r,\n\n  # Allow access to synced folders.\n  owner @{HOME}/Documents/ rw,\n  owner @{HOME}/Documents/** rwk,\n  owner @{HOME}/Pictures/ rw,\n  owner @{HOME}/Pictures/** rwk,\n  owner @{HOME}/Public/ rw,\n  owner @{HOME}/Public/** rwk,\n  owner @{HOME}/Music/ rw,\n  owner @{HOME}/Music/** rwk,\n  owner @{HOME}/Downloads/ rw,\n  owner @{HOME}/Downloads/** rwk,\n  owner @{HOME}/.keys/ rw,\n  owner @{HOME}/.keys/** rwk,\n\n  # Allow access to config files\n  owner @{HOME}/.config/syncthing/ rw,\n  owner @{HOME}/.config/syncthing/** rwk,\n\n  # Silence warnings on things we don't want access to\n  deny / r,\n  deny /* r,\n  deny @{HOME} r,\n\n}\n\nAnd this is the syslog message I've been getting recently: \nApr 16 11:07:05 supercomputer kernel: [ 1240.879568] audit: type=1400 audit(1460768825.434:31): apparmor=\"DENIED\" operation=\"open\" profile=\"/usr/bin/syncthing\" name=2F686F6D652F7365616E2F566964656F732F43616D65726120566964656F732F pid=2277 comm=\"syncthing\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=1000\nApr 16 11:16:28 supercomputer kernel: [ 1803.632950] audit: type=1400 audit(1460769388.508:32): apparmor=\"DENIED\" operation=\"open\" profile=\"/usr/bin/syncthing\" name=2F686F6D652F7365616E2F566964656F732F43616D65726120566964656F732F pid=2266 comm=\"syncthing\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=1000\nApr 16 11:26:13 supercomputer kernel: [ 2388.037482] audit: type=1400 audit(1460769973.246:33): apparmor=\"DENIED\" operation=\"open\" profile=\"/usr/bin/syncthing\" name=2F686F6D652F7365616E2F566964656F732F43616D65726120566964656F732F pid=1021 comm=\"syncthing\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=1000\nApr 16 11:36:56 supercomputer kernel: [ 3031.177125] audit: type=1400 audit(1460770616.751:34): apparmor=\"DENIED\" operation=\"open\" profile=\"/usr/bin/syncthing\" name=2F686F6D652F7365616E2F566964656F732F43616D65726120566964656F732F pid=2273 comm=\"syncthing\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=1000\n\nSince I made the profile myself, I've become relatively familiar with AppArmor and the logs that it produces - but I've never seen this name=2F686F6D652F7365616E2F566964656F732F43616D65726120566964656F732F message before. It doesn't look to be a filepath, which is what AppArmor normally reports on. \nWhat does this error message mean? How can I either allow it or deny it in the profile? \n\nA: The hex string following \"name=\" is just a hex-encoded string of the path of the file you're looking for.  If you copy your hex string into the http://www.asciitohex.com/ in the \"hexadecimal\" box (or many equivalent sites) and click convert to get the original string back.  I won't post the exact string here to preserve your privacy -- just in case it matters.  \nIf you don't want to use a third-party website, you can run a python shell and do the following:\nx=\"2F.... (your string here)\"\n''.join(chr(int(x[i:i+2], 16)) for i in range(0, len(x), 2))\n\nI encountered this on Debian too.  I don't know why this happens.\n", "Q: 14.04 wifi has disappeared, only have wifi in house The \"enable wifi\" option on my network connections has disappeared and as a result I've lost all internet connection. Enable networking is checked but it wants an ethernet connection. I can't do that.\nlshw -class network shows\n\n*-network UNCLAIMED \n\ndescription: Network controller\n\nproduct: AR9485 Wireless Network Adapter\n\nvendor: Qualcomm Atheros\n\nphysical id: 0\n\nbus info: pci@0000:01:00.0\n\nversion: 01\n\nwidth: 64 bits\n\nclock: 33MHz\n\ncapabilities: bus_master cap_list\n\nconfiguration: latency=0\n\nresources: memory:f7c00000-f7c7ffff memory:f7c80000-f7c8ffff\n\nThis is strange. Wifi has been running this computer for several years and it suddenly disappeared after a shut down.\n\nA: Forced update (without internet) and the updater managed to sort out the problem. I still don't know how the driver managed to become unattached (I'd lost sound, too) but things are working now. \n", "Q: Forticlient SSL VPN on Ubuntu 14.04 I have using Forticlient SSL VPN... I can connect... and I have a status message \"Tunnel running\" but I cant navigate any IP address of the VPN, for example 10.10.201.17 on google chrome... to see a web page in the remote network...\nI ping that address, and I dont receive any message from that IP\n\nA: The route to the remote network should be pushed by the VPN server to which the SSLVPN connection is established. \nCould you check if the routes to the remote network are added once the SSLVPN connection is established?\nYou can verify this by executing the following command in the terminal-\nnetstat -r\n\n", "Q: Netflix, 32 bit Chromium, and Ubuntu With the end of 32 bit support for Chrome, has anyone made any progress in getting Netflix to work on an Ubuntu 32 bit version of Chromium? At this time, we must either continue to use Chrome without current security updates just to watch Netflix, or use the WINE/Firefox/Silverlight hack - which slows things down to the point that Netflix becomes effectively unwatchable. \nThe Arch and Slackware communities have both overcame this limitation. If anyone in Ubuntuland has came up with a similar solution, would they care to share it with the rest of us?\n\nA: Google Chrome will drop 32-bit machines but Chromium is still going. (Source)\nJust install Chromium instead of Google Chrome. You'll find it in the software centre.\nI think that one difference between Google Chrome and Chromium is that there's a plugin called Widevine Content Decryption Module installed in Google Chrome by default but not in Chromium.\nTry (this):\nsudo apt-add-repository ppa:pipelight/stable\nsudo apt-get update\nsudo apt-get install pipelight-multi\n\nthen\nsudo pipelight-plugin --enable widevine\n\nThis should install pipelight and install the plugin in Chromium.\nThere's another source that say that you might require to install flash. If so just install it from Adobe's website.\n", "Q: Not able to login into newly created user account I created a new user account from System Settings > User Accounts. \nI can log in to new user account from the terminal but I can't log in to user account from GUI. \nWhen I try to log in to the newly created user account from GUI it doesn't show any error and goes back to the login window. (When I type a wrong password it shows the incorrect password error but when I enter the right password, it simply goes back to the login window without any message.)\nI am using Ubuntu 14.04.4 LTS\n\nA: It seems like that account is disabled. Open the system settings, select the account, unlock changes. Look next to \"password,\" and if it says \"account disabled,\" click that and select an option. If that doesn't work, it is an issue I do not know how to fix. I was on 15.10, and all my logins broke. In that case, backup your computer, get a Live CD or USB from another computer, and reinstall Ubuntu. I had to do it. I hope it's the first.\n\nA: Had the same issue once I created a new user either via command line or the GUI. Everything would look like it created without any errors but when I tried to login it would blink to loading the desktop of a second then flip back to the login screen.\nLooked and the useradd nor the GUI-Users both failed to create the users home folder '/home/$USER' so I copied another users folder:\ncd /home\nsudo cp -R bob $USER\n\nReplacing bob with the name of the good users folder and replace $USER with the account name of the new user. Then you have to set the permissions to the new folder.\nsudo chown -R $USER:$USER $USER\n\nReplacing $USER with the account name of the new user again. So if the new account name was rsmith then it would look like this.\nsudo chown -R rsmith:rsmith rsmith\n\nThis fixed my issue and allowed me to finally login as the new user.\n\nA: Maybe your home directory's permission is set to root thats why it goes back to login window. I also had the same problem a while ago, i can log in  but after a seconds, it goes back to login window.\ntry changing your home directory using your terminal:\nsudo chown -R $USER:$USER /home/user_name\n\n", "Q: Installing zoph on Ubuntu 14.04 I am new to Linux. I tried to install zoph by using apt-get install zoph. But this shows the error:\nE:unable to locate package zoph.\n\nI have seen methods to install zoph on Ubuntu 12.04 version but not on 14.04.\nCan someone tell me how to do it?\n\nA: Zoph is in beta and only available in source code, so not through the standard Ubuntu Software center.\nSo you have two possibilities:\n\n\n*\n\n*If you know what source code, compiling and linking is, build it from source\n\n*If you're not very technical: wait until version 1.0 has been released. (No, really! If you've never programmed before: forget about 1. above)\n\n\nA: Zoph is written in PHP and therefore does not require compilation. You can install Apache, PHP and MySQL using apt-get and then simply place Zoph's files in Apache's webroot.\n", "Q: MAAS 1.9 can't deploy OS I recently upgraded my MAAS server and found myself with MAAS 1.9.1+bzr4543-0ubuntu1. I saw that the old version of MAAS that I had been running was no longer supported, so no great loss there. \nUnfortunately, every time I try and deploy Trusty to a node, it fails with the console message \"DataSourceNotFoundException: Did not find any data source, searched classes: ()\" on the node and the MAAS server eventually times out the deployment.\nMy system configuration is both very simple, and probably quite different from a common MAAS installation. In particular, I am not using the optional DNS and DHCP modules because I already have a perfectly good DNS and DHCP system. This worked great in 1.8, but I guess something has gone wrong in the new fancy network framework.\nI can reproduce this easily with the following steps:\n\n\n*\n\n*apt-get install maas\n\n*maas-region-admin createadmin ...\n\n*Power on the node to enlist it - that works\n\n*Commission the node - that works \n\n*Deploy Trusty to the node - that doesn't\n\n*Scratch head when the deployment fails\n\n\nMy MAAS server is 10.0.1.51/24, the nodes I am deploying are on 10.76.0.0/23, and I have a DHCP server that directs the PXE boot to fetch the PXE boot files from the MAAS server.\nThis all used to work fine with 1.8. Does anyone have any ideas about what might need to be poked or prodded to allow deployments to work?\nThanks\n\nA: I have found the best way to figure out what is failing is to SSH to a node while it being commissioned and to check /var/log directory. There is a log for a cloud-init script. If that part did complete correctly then look for /var/log/juju and the logs inside it will give a you a clue on what might be failing. \n\nA: You may expect quick and perfect answers if you post an issue in https://github.com/Ubuntu-Solutions-Engineering/openstack-installer\n", "Q: Nvidia-361 GPU installation continual rebooting I've got Ubuntu 15.10 installed on a new Asus Z170-AR motherboard.  I've also got a Nvidia GTX 980 ti I'm trying to get working with it.\nI purgeed all Nvidia packages, and followed the instructions in this post: Bumblebee Intel+Nvidia on 15.10 blackscreen issue, except I installed nvidia-361 instead, which seems to be the latest.\nIt boots, but when it boots the desktop appears, in the full 3820 resolution of the monitor, but then it reboots again, and just does this over and over.\nAny thoughts on the approach I should use to get this new GPU installed correctly?\nI'm concerned that it's not possible with 15.10, but I doubt that's true.  Also, I don't think this is an issue, but it could be: Nvidia's website specifies GCC 4.9, and Ubuntu 15.1 comes with >5.  I don't think that's the issue because this is a boot thing and not a compilation thing, but who knows.\nI am going to try an earlier nvidia-3** package.  I would try Ubuntu 14 but could not get that installed with this motherboard.\nI did have nouveau.modeset=0 set to zero at the end of the linux line in the grub menu but upon viewing that again it is not there. \nEDIT/ADD: this is single boot.  And I see that the grub menu only works for one boot.\n\nA: Ok, hope it's ok to answer my own question.\nI followed the instructions in the linked to answer in my question, which mostly consisted of purging nvidia packages and adding a package repository, and then added nomodeset to the linux line in the grub menu (Once to the grub menu hit e to edit.  I got my grub menu using 15.1 by hitting esc once at the motherboard bios display and once more about two seconds after that disappeared).\n\n\n*\n\n*apt-get purge as described in link found in above question\n\n*add nomodeset to linux line in grub menu (see detail above)\n\n*install nvidia-358\n\n*reboot\n\n", "Q: Configuring oracle 11g database on ubuntu 14.04 /u01/app/oracle/product/11.2.0/xe/config/log for details I am stuck with oracle 11g database configuration on Ubuntu 14.04 64bit. I know this question has been answered many times. \nI have tried every thing and for two days i am stuck with this error. I desperately need to configure this. \nInstallation tutorial\nHow to install Oracle 11gR2 on Ubuntu 14.04?\nEvery thing works perfectly fine until this step\nsudo /etc/init.d/oracle-xe configure\n.\n.\nStarting Oracle Net Listener...Done\nConfiguring database...\nDatabase Configuration failed.  Look into /u01/app/oracle/product/11.2.0  /xe/config/log for details\n\nI know this is a hostname issue as most blogs and forums suggest but it is not working for me.\n$hostname\n$josh \n\n$cat /etc/hosts \n$127.0.0.1  josh\n\n\nroot@josh:/u01/app/oracle/product/11.2.0/xe/config/log# ls\ncloneDBCreation.log  CloneRmanRestore.log  postDBCreation.log\n\n\nroot@josh:/u01/app/oracle/product/11.2.0/xe/config/log# grep ORA *\ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available\ncloneDBCreation.log:ORA-27101: shared memory realm does not exist\ncloneDBCreation.log:ORA-00845: MEMORY_TARGET not supported on this system\ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \ncloneDBCreation.log:ORA-01034: ORACLE not available \nCloneRmanRestore.log:ORA-00845: MEMORY_TARGET not supported on this system\nCloneRmanRestore.log:ORA-01034: ORACLE not available \nCloneRmanRestore.log:ORA-01034: ORACLE not available \nCloneRmanRestore.log:ORA-01034: ORACLE not available \npostDBCreation.log:ORA-01034: ORACLE not available \npostDBCreation.log:ORA-01034: ORACLE not available\npostDBCreation.log:ORA-27101: shared memory realm does not exist\npostDBCreation.log:ORA-00845: MEMORY_TARGET not supported on this system\npostDBCreation.log:ORA-01034: ORACLE not available \npostDBCreation.log:ORA-01034: ORACLE not available \npostDBCreation.log:ORA-01034: ORACLE not available \n\nThings that i already tried\nhttps://askubuntu.com/questions/631681/database-configuration-failed-look-into-u01-app-oracle-product-11-2-0-xe-confi\nhttps://stackoverflow.com/questions/16545412/problems-installing-oracle-database-express-edition-11g\nhttps://stackoverflow.com/questions/19957137/oracle-11g-xe-installation-error-database-configuration-failed\nand many many more. \n\nA: See if Oracle-xe installation on ubuntu 14.4 helps ... I list a pdf document you can download that goes through step-by-step from the official download through conversion to .deb and installation to testing with SQLPlus.\n-Frank\n", "Q: When installing mysql workbench I get the following error Depends: libgcc1 (>= 1:4.1.1) but 1:4.9.3-0ubuntu4 is to be installed\n                 Depends: libgtkmm-2.4-1c2a (>= 1:2.24.0) but 1:2.24.4-1ubuntu1 is to be installed\n                 Depends: libpcrecpp0 (>= 7.7) but 1:8.31-2ubuntu2.2 is to be installed\n                 Depends: python:any (>= 2.7.1-0ubuntu2) but it is a virtual package\n                 Depends: mysql-workbench-data (= 6.0.8+dfsg-2) but 6.0.8+dfsg-2 is to be installed\n\n\nA: You can run this command that should fix package dependencies:\nsudo apt-get install -f\n\nand then run the installation command\nsudo dpkg -i mysql-workbench-community-6.3.6-1ubu1510-amd64.deb\n\n(I'm supposing you downloaded .deb file from mysql website, you're running Ubuntu 15.10 and your terminal is in the same directory of mysql workbench installation file)\nIf you want more information about apt-get command or dpkg command you can read the manual running these commands:\nman apt-get\n\nman dpkg\n\n\nI've just got the same installation issue it on my machine and I've resolved the problem in this way.\nI hope this could help you.\n\nA: Install gdebi, it lets you install local deb packages resolving and installing its dependencies.\napt-get install gdebi\n\nAfter that install your MySQL .deb package with gdebi\ngdebi package.deb\n\n", "Q: How to force user to run quiz after login and before displaying desktop I have a kid and I want to allow him to use the computer only after he solves a certain quiz at logon.\nI can write a quiz application itself. What I don't know is how to set it up in the way, that computer doesn't show normal desktop until the quiz program decides so.\nHow can I do it? Should I use pam? But how can I make pam application interact with user graphically?\nI use Ubuntu 14.04. \n\nA: Here's a super simple way. Have your quiz program run during the Xsession, right before the desktop gets launched.\nFor example, try creating a file (as root) called /etc/X11/Xsession/95quiz with the following contents:\nxmessage \"What is my favorite color?\" -buttons \"African Swallow,European Swallow,42\" -print -center\n\nUpon logging on, you will not be able to use the computer until the quiz program exits. \nOf course, the way I have it setup, all users of the computer will be quizzed, which seems fair to me. Running it from only your kid's .xsession is left as an exercise for the reader. :-) \n", "Q: Moving large amount of files (~ 100 000) I work with folders that contain a lot of files, like 100 000 or even 1 000 000 files per folder. When I try to move the content of a folder into another, my computer always gets stuck. Even when the process seems finished, I can't see the content of any folder because nautilus seems completely frozen and I have to force my computer to restart. I noticed that this happens also when I try to move like 10 000 files. \nIs that a problem of my computer or is it normal when working with these numbers? \nAny smart way of performing this file transfer?\n\nA: I had similar experience before, it is normal when dealing with a large number of files. I was having a large collection of PDF data-sheets (electronic parts).\nGUI tools check for some file details & meta data (Icon/Thumbnail, Size, ...), it will be a big deal in such case. Even in Icon View and without thumbnails, they will freeze as most of them are not designed for such extreme case. GUI tool try to load presentation icons for all files/folders in directory even those items are not visible to user in current screen portion. Sorting is also part of the problem and no way to avoid it.\n\n\n*\n\n*I end up splitting files files on separate folders based on brand/model less then 10000 each. May be you can use date (as most people do with photos/scans) or first letter(s) (as in Ubuntu package repository)\n\n*It is easier to use CLI tools instead as they show only what you have requested. You can use locate for quick search in stead of find.\n\n*For move operation, use mv in terminal (GUI tools are slow because they try to update the view periodically).\nIf it is in the same partition, the command will change only the pointers in the File-system index. If not, then it will be dual operation (copy & delete). That will be expensive.\nThere is only one case I can help, If you are copying those files multiple times and they are not updated. As I did when I share my collection with friends, each time I try to copy it takes a decade. (This is more useful with small size files only)\n\n\n*\n\n*Create a single package or few packages, like zip with no/low compression. When you copy it, it will faster, so let DMA do its job.\n\n\nA: If you are looking for a solution which gives you the benefits of the command-line operations with the GUI feeling and flexibility combined, I recommend mc (midnight commander).\n\nIt is a ncurses-based visual file manager - you have a two-pane view on your files and a menu available. Use of the mouse is possible, even over ssh. You can browse around your fs, inspect files with the file viewer, filter according to criteria on-the-fly and have the copy or move operations done on the command line.\nIt's a clone of the DOS program Norton commander which was popular in the mid-Eighties. It works well whenever the GUI starts to get unreliable for me, and ideal for your purpose.\n\nA: Perhaps consider using a pure command line method to transfer very large amounts files, you will undoubtedly find the process is substantially faster than using a gui.\nThere are many different ways to accomplish this, but the following worked quickly, safely and efficiently on my system:\nfind . -maxdepth 1 -type f -print0 | xargs -0 mv -t <destination>\n\nSome explanation for this command:\n\n\n*\n\n*Your input directory is the '.' character and for this particular command you need to be in that directory\n\n*Your output directory is the <destination> in my example. Obviously modify this to suit your own needs and leave out the brackets.\n\n*This syntax allows for filenames with spaces as a bonus :)\n\n\nEndless permutations are possible but this should work well and much more efficiently than the gui. One permutation for example: if you wanted to move only pdf files you could run:\nfind . -iname \"*.pdf\" -maxdepth 1 -type f -print0 | xargs -0 mv -t <destination>\n\nUse of xargs opens many possibilities particularly with the movement of such a large number of files. Many, many possibilities....\nPotential Problems:\nThere are at least 2 potential pitfalls to ponder, thanks to the commenters below for these thoughts:\n\n\n*\n\n*Your destination directory could be corrupt, in a subsequently unreachable location, mistyped etc. mv will still move the files there! Be careful here...\n\n*If the -t option (--target-directory) is missing and the destination folder is actually a file you will move one file and fail on the rest. mv has 2 uses: rename source to destination or move source to directory. Again be careful...\n\n\nA: I've encountered somewhat similar problems - I was testing my RAID setup and when doing huge transfers (e.g. 100,000+ files and 1-2 TB of data in one go) it seems like transfers start fairly speedy - lets say ~200MB/sec, then quickly slow down to a reasonable plateau ~90-120MB/sec (possibly after consuming some flash cache storage on the drives). Then after 20-30min, the operation gradually starts to drop to a much lower plateau ~30-40MB/sec, worse when dealing with small files - taking a 4-5 hour operation closer to 15hours. \nI spent some time trying to diagnose - e.g. possible drive faults. Despite trying different tools - command line, nautilus, I couldn't maintain a decent throughput for very large copy operations. \nWhat worked best for me was to use midnight commander, and whenever copying got slow, I would pause the operation until the hard-drive light went out after any pending operations flushed out - usually a minute or so - then un-pause MC again and it would shoot back up to a decent pace for another 20-30min. Rather annoying though.\n", "Q: Error during setup of unity-js-scopes-tool I am going to create a Scope for Ubuntu Touch with the Ubuntu SDK.\nI used this JS-Tutorial.\nSo I did the installation process within a fresh installation of Ubuntu 15.10 in VirtualBox with the fallowing intructions:\nsudo add-apt-repository ppa:unity-api-team/unity-js-scopes\nsudo apt-get update\nsudo apt-get install ubuntu-sdk unity-js-scopes-dev \nunity-js-scopes-tool setup\n\nBut after running the last command I get these error codes:\nSetup started.\nW: No chroots are defined in ‘/etc/schroot/schroot.conf’ or ‘/etc/schroot/chroot.d’\nE: source:click-ubuntu-sdk-15.04-armhf: Chroot not found\nCommand returned 1: schroot -u root -c source:click-ubuntu-sdk-15.04-armhf -- echo 1\nW: No chroots are defined in ‘/etc/schroot/schroot.conf’ or ‘/etc/schroot/chroot.d’\nE: source:click-ubuntu-sdk-15.10-armhf: Chroot not found\nCommand returned 1: schroot -u root -c source:click-ubuntu-sdk-15.10-armhf -- echo 1\nRemounting chroots ...\nCould not connect to click-chroot-agent service\nSetup complete.\n\nDoes anybody know, what's the problem?\n\nA: I think, I figured it out:\nAfter reading the Tuorials twice I noticed, that I did not add the release PPA for the ubuntu SDK.\nNevertheless I was able to install the ubuntu-sdk. But after added the PPA many new upgrades were available through 'apt-get dist-upgrade'.\nFurthermore it was nessesary to create a click target. So my problem was finally solved by a new installation and setup process:\nsudo add-apt-repository ppa:ubuntu-sdk-team/ppa\nsudo add-apt-repository ppa:unity-api-team/unity-js-scopes\nsudo apt-get update\nsudo apt-get dist-upgrade\nsudo apt-get install ubuntu-sdk unity-js-scopes-dev \n#NOW create the click target in Ubuntu-SDK's option menu\nunity-js-scopes-tool setup\n\nThe output of 'unity-js-scopes-tool setup' now looks like this:\nSetup started.\nE: source:click-ubuntu-sdk-15.04-armhf: Chroot not found\nCommand returned 1: schroot -u root -c source:click-ubuntu-sdk-15.04-armhf -- echo 1\nE: source:click-ubuntu-sdk-15.10-armhf: Chroot not found\nCommand returned 1: schroot -u root -c source:click-ubuntu-sdk-15.10-armhf -- echo 1\nRemounting chroots ...\nSetup complete.\n\nThis looks now much better, but not good. I'm going on now to test if JS-Scopes can be created. :-)\n", "Q: Input/output error when accessing a directory I have ubuntu 14.04 installed on a 256Gb SSD (Sandisk). The drive is partitioned to 120 GB (with OS) and the rest as a secondary Data partition. The Data partition has started having I/O problems this morning.\nBoth partitions are Ext4 (version 1).\nI have run badblocks and it found 20.\nIs is worth formatting the dodgy partition?\nScreenshots:\n\n\nA: Work out the exact drive name if you are not sure from Disks.\nIn my example the assessment says \n\none bad sector\n\n\n\n*\n\n*Under volumes the device name is /dev/sdb2 \n\n*The file system is ext4\n\n*The drive must be unmounted\n\n\nRun> fsck.ext4 -f -C0 /dev/sdb2\n(if you don't want to be prompted all the time add the -y option)\n\nNote: After running this command I can use the drive although I seem to have lost a few files. \n", "Q: Install of Multichain Hi I am new to Ubuntu and am trying to install multichain to Ubuntu 12 on DigitalOcean. When I follow all the steps for the install i get a \"cannot execute binary file\"... can anyone help this newbie figure out what he is doing wrong?\n\nA: Log into your DigitalOcean (virtaul) machine and follow the installation instructions according to MultiChain website:\n\nsu (enter root password) \n  cd /tmp \n  wget http://www.multichain.com/download/multichain-1.0-alpha-19.tar.gz \n  tar -xvzf multichain-1.0-alpha-19.tar.gz \n  cd multichain-1.0-alpha-19\n  mv multichaind multichain-cli multichain-util /usr/local/bin \n  exit \n\nNow that the installation is complete with binary in /usr/local/bin/, you can follow the detailed instructions on getting started.\n", "Q: How to place software files I've installed Tor, and now I'd like to install the Tor Browser. I'm following the instructions under Linux Instructions.\nThe package tor-browser-linux64-5.5.4_en-US.tar.xz has been downloaded and unpacked to my ~/Downloads/ directory. I can easily launch the browser from there.\nHowever, I want to place the files in the correct locations, but I don't know where. As I understand it support files are supposed to go in one directory, lib files in another, executables in another, etc.\nIs there a console command I can use to automatically distribute all the Tor Browser files from ~/Downloads/ to the correct locations?\nI'm very new to Ubuntu and have never installed anything this way before.\n\nA: \nIs there a console command I can use to automatically distribute all the Tor Browser files from ~/Downloads/ to the correct locations?\n\nNo, you got that wrong.\n\n\n*\n\n*\"debian\" installer files will install software into the Ubuntu directories. See Ubuntu software center for an easier way to installing this:\n\n\n\n\n\n*\n\n*But you used a 3rd party method (.tar.gz) and 3rd party software should use \"/opt/\". The Linux way to do this is to do a ...\ncd ~/Downloads\nsudo mv tor-browser* /opt/\nsudo chown $USER:$USER tor-browser*\n\nAnd then add the directory to your $PATH. A howto on how to do that: Add bash script folder to path?\n", "Q: Ubuntu 15.10 gnome edition won`t boot - error symbol 'grub_efi_secure_boot' not found I have a problem with my ubuntu 15.10 gnome edition. If a link with pastebin from boot repair disk is all that's needed to come up with a fix, i won`t steal your time:\nMost recent pastebin: http://paste.ubuntu.com/15849278\nLess recent pastebin: http://paste.ubuntu.com/15849119\nError: symbol 'grub_efi_secure_boot' not found\nDual boot: Yes, with windows 10, which boots just fine.\nFixes i`ve found and tried:\nupdate-grub,\nreinstalling grub,\nreinstalling the system,\nusing boot repair live cd\nIf more elaboration is needed:\nBasically i've tried a lot of distro's recently. I've even tried the latest kubuntu, and it worked just fine. Gnome ubuntu (both 14.04 and 15.10) is where i've hit a rock. I've installed it once, it gave me the stated error. I've installed it again, same outcome. I`ve installed Manjaro lxqt, it worked just fine, installed ubuntu gnome, error again. If i use a live cd called 'super_grub2_disk_hybrid_2.02s4' and boot ubuntu manually from there - it works.\nI just wan't to add, that i rarely use terminal, so you can basically treat me like a beginner. And, as it is my first post here: Hello, sorry for any mistakes, i`m polish :)\nThanks for help in advance!\n\nA: I suspect that either:\n\n\n*\n\n*You have some leftover GRUB files from a previous installation that are causing problems with the current one; or\n\n*You've run into a bug in GRUB (or at least its current build)\n\n\nIf you're confident it's not the first issue, you might want to file a bug report about the problem.\nAs a practical matter, one possible solution is:\n\n\n*\n\n*Boot with your workaround method.\n\n*Install my rEFInd boot manager as follows:\n\n\n*\n\n*Type sudo apt-add-repository ppa:rodsmith/refind\n\n*Type sudo apt-get update\n\n*Type sudo apt-get install refind\n\n*When prompted, respond that you do want to install rEFInd to the EFI System Partition (ESP).\n\n\n*Reboot. rEFInd should come up as your default boot manager and you should be able to boot with it.\n\n*You may want to adjust the boot configuration. The single most popular change seems to be editing the boot entries, as described here.\nIf, after installing rEFInd, the system doesn't boot correctly, you should still be able to use your workaround method to boot. You can then adjust the boot order with efibootmgr to restore GRUB.\n", "Q: How can I install Sonos on Ubuntu How can I install the Sonos controller on Ubuntu and access the music library ?\n\nA: Here is a tutorial to install Sonos on ubuntu using Wine, PlayonLinux and Samba (for the music library).\nInstall the Sonos Controller\nThe first thing to do is to install Wine and PlayonLinux so your computer can use Windows software. Open a terminal (ctrl+alt+t) and copy/paste the following line by line.\nsudo apt-get install wine\nsudo apt-get install playonlinux\n\nThen download the latest version of the Sonos Controller for Windows.\nStart PlayonLinux and click on \"install a program\". A new window opens. Select \"Install a non listed program\" (at the bottom). If it is the first time you use PlayonLinux you may not have this option. Then close the window and re-open it.\nSelect \"install in a new virtual drive\". Name the drive however you want (but \"sonos\" seems a logical choice). Untick the boxes that may be ticked and choose \"32-bit installation\". Browse to the sonos controller you downloaded and click \"next\".\nThe installer starts. Install the software (leave everything as it is) but DO NOT run the application after setup. At the end of the installation PlayonLinux proposes you to create shortcuts. Create one for the sonos.exe file. You now have a Sonos launcher on your desktop. You can change its icon to a Sonos icon and drag it to the launcher.\nSonos is now listed in PlayonLinux. Right click on it and select \"configure wine\". In \"application\" make sure \"Windows XP\" is selected.\nIn PlayonLinux select \"Sonos\" and click on \"configure\" (on the right side of the window). A window opens. Go to \"install components\", look for \"dotnet40\" and install it.\nStart the application. Click \"next\" and then choose \"don't configure windows firewall\". Your Sonos controller is now installed and ready to work.\nMake the Sonos Controller fullscreen\nIf double clicking on the menu bar of the Sonos controller works for you, skip this part of the tutorial.\nIf double clicking on the menu bar freezes your controller follow these steps to make your controller fullscreen.\nMake sure Sonos is not working. Open PlayonLinux, right click on Sonos and select \"configure wine\". Go to the \"graphics\" tab and select \"emulate a virtual desktop\". Increase the resolution to 1000x800. Close Wine.\nStart Sonos. The application will start in a virtual desktop. It is ugly but we will get rid of it. Double click on the menu bar to make Sonos fullscreen in the virtual desktop. Close Sonos.\nGo back to PlayonLinux, right click, \"configure wine\". Untick \"emulate a virtual desktop\". Close Wine and PlayonLinux. Start Sonos. It should be fullscreen.\nIf your controller is still not fullscreen, repeat the operation but increase the resolution of the virtual desktop to its maximum (similar to your own resolution).\nAccess the music library\nTo access your music library is a bit more complicated but still doable. To do so we will use Samba and create a network share.\nThe first thing to do is to install Samba.\nsudo apt-get update\nsudo apt-get install samba\n\nCreate a username and a password for Samba (they can be different or similar to your usual username and password). In the following line replace username by the username of your choice.\nsudo smbpasswd -a username\n\nYou will then be asked to create a password.\nFor the following I suppose the folder you wish to share and to set as your music library is your music folder (/home/username/Music). If not change as needed.\nEdit the samba configuration file\nsudo gedit /etc/samba/smb.conf\n\nOnce the file is open add at the very end\n[Folder Name]\npath = /home/username/Music\nvalid users = username\nread only = n\n\nName the folder whatever you want. Change the path to set it with your username. The username in \"valid users\" should be the username you set earlier for samba. Save the changes and close gedit.\nYou now need to restart samba\nsudo service smbd restart\n\nYour music folder is ready to be shared.\nStart Sonos. Click on \"manage\" and open \"music library settings\". Click \"add\" and choose \"on a networked device such as a network attached storage (NAS) drive\".\nWrite the path this way:\n//computer's name/folder name\n\nSo if my computer is called \"Poulpe\" and I named my folder \"Music\" in the samba configuration file, my network will be:\n//Poulpe/Music\n\nSonos asks you a username and a password. Give the one you set at the beggining in samba.\nYou Sonos is now working, fullscreen, and you can access your music library.\nThanks\nIt would have been impossible for me to use Sonos on my computer, and to write this tutorial, without this article on Michael's blog, this tutorial on help.ubuntu and a few posts on the sonos support forum from a guy named Keith.\nEnglish in not my mother tongue. If there is mistakes or if something could be better explained please tell me, I'd be thankful.\n\nA: Native applications to control Sonos devices have existed for a few years. \nSee mine at: https://launchpad.net/~jlbarriere68/+archive/ubuntu/noson-app\nThe source is hosted at https://github.com/janbar/noson-app .\nscreenshots: https://uappexplorer.com/app/noson.janbar\n\nA: If you use Spotify - the Spotify native Linux client can now control your Sonos system. One of the best features they've ever added IMO..\nYou can find out how install the Spotify client on Ubuntu here:\n\nA: I use a free java client utility, so this should do the job.\nJanos \nI got the newest controller not working with wine and also not with play on linux. But I can do most operations with that utility ; )\n\nA: For some time i use this browser based controller now.\nsimple but works\nsudo apt install nodejs-legacy\n\njust extract the contents of sonos-browser.tar.gz to /home/yourusername/bin/.\nrun the sonos.sh (or just the command in there) \nrun the sonos.html inside the sonos folder (bookmark it)\nit gives access to favorites and controls (i did my initial setup via android sonos controller)\nP.S. you might need to change IP to your SonoS IP, but i guess it should work without any changes too.\n\nA: For programmers I found it really comfortable to use http://python-soco.com with ipython , example: \nimport soco\ns=soco.SoCo('1.2.3.4')\ns.clear_queue()\nwith open('playlist.m3u', 'r') as f:\n  for l in f:\n   s.add_uri_to_queue('http://192.168.1.5:8080/MusicShared/'+l.rstrip('\\n'))\ns.play _from_queue(0)\n\nlonger example  from \nhttps://gist.github.com/gwpl/92ab540016bf43359654d5b0f013b1ec :\n#!/usr/bin/env python3\nimport sys\nimport soco\n\n# Take ip from `socos list` or soco.discover()\nip='192.168.1.106'\nprint('Playing on Speaker with ip='+ip)\ns=soco.SoCo(ip)\nprint(' get_speaker_info()='+str(s.get_speaker_info()))\n\ns.clear_queue()\nfor m3u_filename in sys.argv[2:]:\n    print('Adding m3u...'+m3u_filename)\n    with open(m3u_filename, 'r') as m3u_filehandler:\n        for line in m3u_filehandler:\n            filename = line.rstrip('\\n')\n            print('...\"'+filename+'\"')\n            s.add_uri_to_queue('http://192.168.1.99:8080/MusicShared/'+filename)\ns.play_from_queue(0)\n\n(btw. my thread about this : https://twitter.com/GWierzowiecki/status/991453357234585601 )\n\nA: I made a quick and dirty Sonos driver for Linux Pulseaudio, written in Python, that uses VLC to stream to Sonos speakers.\nThe driver is available at https://github.com/antonylesuisse/sonos\nInstallation:\nsudo apt-get install alsa-utils ffmpeg pulseaudio-utils vlc\npip3 install soco\nwget -O sonos https://raw.githubusercontent.com/antonylesuisse/sonos/master/sonos\nchmod +x sonos\n\nUsage:\n./sonos\n\nType Ctrl-C to stop streaming to sonos.\n", "Q: Ubuntu 14.04 unable to establish Ethernet or WiFi connection I recently installed Ubuntu 14.04 on dual boot with Windows 7 on separate HDD. I went through several threads regarding connection problems but I didn't understand them much as I have never used Linux in the past. Ubuntu detects that Ethernet cable is plugged in but it can't establish a connection.\nifconfig:\neth0      Link encap:Ethernet  HWaddr e0:3f:49:ad:81:b8  \n      inet6 addr: fe80::e23f:49ff:fead:81b8/64 Scope:Link\n      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n      RX packets:1 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:24 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:1000 \n      RX bytes:64 (64.0 B)  TX bytes:5088 (5.0 KB)\n      Interrupt:20 Memory:f7d00000-f7d20000 \n\nlo        Link encap:Local Loopback  \n      inet addr:127.0.0.1  Mask:255.0.0.0\n      inet6 addr: ::1/128 Scope:Host\n      UP LOOPBACK RUNNING  MTU:65536  Metric:1\n      RX packets:116 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:116 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:0 \n      RX bytes:7184 (7.1 KB)  TX bytes:7184 (7.1 KB)\n\nlspci -knn | grep Net -A2:\ns Network Adapter [14e4:43b1] (rev 03)\nSubsystem: ASUSTeK Computer Inc. Device [1043:855c]\nKernel driver in use: bcma-pci-bridge\n\n\nI tried to follow the post which got 186 up vote in the thread below but unfortunately in step 2 it wants user to be connected to internet in some form, so I am unsure what should I do to proceed as I can only connect to internet on Windows 7.\n    Installing Broadcom Wireless Drivers\nThis didn't work.\n    How to install Broadcom wireless drivers offline?\n\nA: Do you have static IP Configuration? If yes then in the connection settings edit the wired connection or something like that to have those settings and try connecting.\n", "Q: I want to install vim but the following error appears checking for tgetent()... configure: error: NOT FOUND!\n      You need to install a terminal library; for example ncurses.\n      Or specify the name of the library with --with-tlib.\n\n\nA: Open a Terminal and execute this command:\nsudo apt-get install libncurses5-dev\n\n", "Q: BSNL EVDO Ubuntu 14.04 connected but no internet I have BSNL EVDO connected in Ubuntu, but still when I try to access page via browser it shows \"Internet Unavailable\". At other times, its not even getting connected, I have tried using wvdial and after showing four DNS servers it halts and doesn't show connected for long time.\n\nA: Try installing gnome-ppp package by :\nsudo apt-get install gnome-ppp\n\nIt's a graphical interface which does same work as wvdial.\nOpen it from the applications panel and in settings try \"detect serial port\". And manually change the modem type to \"USB\" and save. On main screen enter the credentials and try connecting. Let us know what you get.\n", "Q: Ubuntu 15.10 connect to VPN server on port 443 without certificate I need to connect to a VPN server from Ubuntu 15.10. I know gateway, port 443 username and password. Usually I connect from Windows using Forticlient, but there is no version of this software for Ubuntu.\nI've tried through Network Manager > Configure VPN > OpenVPN. But this requires a certificate, which I don't have and it's not needed when I connect from Windows. I've tried to use openvpn from the command line, but failed to run it. I don't have sufficient Linux knowledge to conquer this task and would appreciate some help.\n\nA: When you connect to OpenVPN from Windows you must have profile/configuration file somewhere with .ovpn extension, quite sure it can be found from C:\\Program Files\\OpenVPN\\. When you open-up your configuration file at Windows you will see where certificates are located at your computer.\nYou can copy-paste your configuration from Windows to Linux (aswell certificates) but make sure you edit certificates locations.  \nAfter that, connect from command line at linux with your config file.\nopenvpn --config ~/workvpn.ovpn\n\n\nA: Good news: There is a FortiClient for Linux (For Ubuntu and RedHat) At the link you can download the .deb or .rpm files.\nHere you find more detailed information for adding the package to your repositories.\nYou can use FortiClient to connect to VPN Server without need to add the CA certificate. :)\nAll that said, I have to admit that I tried to find a \"pure\" Ubuntu solution and it was to no avail. I encourage people to post an answer without FortiClient.\nNote: As of 11-2020, The Forticlient is officially only available for Ubuntu versions 16.04 and 18.04., but I guess that now (4 years later) you are no more using the 15.10. as it is no more supported.\n", "Q: Building KVM images What is the best way to build Ubuntu 14.04 and 16.04 images for KVM?\nUntil now, I have been using vmbuilder for Ubuntu 12.04 LTS, but it seems it is no longer supported.\n\nA: python-vm-builder seems to still be the standard way to do it.\n", "Q: How to open a file in the same display I am working it? I have connected a LCD to my laptop. When I try to open a file in Nautilus, the target application opens in my laptop display, rather than the second display (in which nautilus window is open).\nI don't want to change the default display. I want to open windows in the display I am working in. If my file manager is in laptop display, I want the apps to open in laptop display. If my file manager is in external display, I expect to open files there.\nThe output of xrandr\nScreen 0: minimum 320 x 200, current 3286 x 1080, maximum 32767 x 32767\neDP1 connected 1366x768+0+0 (normal left inverted right x axis y axis) 256mm x 144mm\n   1366x768       60.1*+\n   1360x768       59.8     60.0  \n   1024x768       60.0  \n   800x600        60.3     56.2  \n   640x480        59.9  \nVGA1 disconnected (normal left inverted right x axis y axis)\nHDMI1 connected primary 1920x1080+1366+0 (normal left inverted right x axis y axis) 527mm x 296mm\n   1920x1080      60.0*    50.0     59.9  \n   1920x1080i     60.1     50.0     60.0  \n   1680x1050      59.9  \n   1280x1024      75.0     60.0  \n   1440x900       59.9  \n   1280x960       60.0  \n   1280x800       59.9  \n   1152x864       75.0  \n   1280x720       60.0     50.0     59.9  \n   1440x576i      50.1  \n   1024x768       75.1     70.1     60.0  \n   1440x480i      60.1     60.1  \n   832x624        74.6  \n   800x600        72.2     75.0     60.3     56.2  \n   720x576        50.0  \n   720x480        60.0     59.9  \n   640x480        75.0     72.8     66.7     60.0     59.9  \n   720x400        70.1  \nDP1 disconnected (normal left inverted right x axis y axis)\nHDMI2 disconnected (normal left inverted right x axis y axis)\nVIRTUAL1 disconnected (normal left inverted right x axis y axis)\n\n\nA: The behaviour you describe (opening the window on the current screen) should be the default behaviour, On my 14.04 it is like that.\nDue to minor incompatibilities with some graphics driver/GPU combinations, \"peculiarities\" might occur in some cases. If there is no \"clean\" option available (fix), you can use the workaround below. \nIt exists of a background script, looking for new windows to appear. In case a new window exists, the script compares the window position to the current mouse position. If both the mouse and the new window are not on the same screen, the window is moved, using the xdotool windowmove` command.\nIs a background script a bad idea?\nIf you do not need a background script, don't use it. \nAt the same time: if it adds important functionality and/or saves you time, It would be silly not to, if the script is well organized and therefore \"low on fuel\". \nAs a reference: on both my laptop and my Desktop, I constantly run at least 5 background scripts + occasionally some additional ones for testing purposes, without any notice.\nWhat is done to save fuel:\n\n\n*\n\n*The script has a variable loop cycle\nOnce per 10 seconds, the script checks for the second screen to be connected. If not, the script skips the whole window check- procedure and re- checks after 10 seconds. This means that the script only acts if a second screen is attached. Once a second screen is connected, within 10 seconds, the loop is changed to a period of 2 seconds.\n\n*All (next) actions the script takes are conditional\ne.g. the mouse position is only checked if there are new windows etc.\n\n\nAll together, on my system I could not notice nor measure any additional load, as a result of the script.\nThe script\n#!/usr/bin/env python3\nimport subprocess\nimport time\n\ndef get(cmd):\n    try:\n        return subprocess.check_output(cmd).decode(\"utf-8\").strip()\n    except subprocess.CalledProcessError:\n        pass\n\ndef screen_limit():\n    screendata = [s for s in get(\"xrandr\").split() if s.count(\"+\") == 2]\n    if len(screendata) == 2:\n        return int([s.split(\"x\")[0] for s in screendata if \"+0+0\" in s][0])\n\nwd1 = get([\"wmctrl\", \"-lG\"])\n\nt = 0\nwhile True:\n    time.sleep(2)\n    # once per 10 seconds, check for a second screen\n    if t == 0: \n        while True:\n            rightside = screen_limit()\n            # if no second screen, skip the procedure\n            if rightside == None:\n                time.sleep(10)\n            else:\n                break\n    wd2 = get([\"wmctrl\", \"-lG\"])\n    # check for buggy wmctrl\n    if all([wd2 != None, wd1 != None]):\n        wins = [w.split() for w in wd2.splitlines()]\n        # check for new windows\n        relevant = [w for w in wins if not w[0] in wd1]\n        if relevant:\n            # if new windows appeared, see if they match the mouse pos\n            mousepos = int(get([\n                \"xdotool\", \"getmouselocation\"\n                ]).split()[0].split(\":\")[1])\n            for w in relevant:\n                check = [mousepos < rightside, int(w[2]) < rightside]\n                if check[0] != check[1]:\n                    # if mouse and window are not on the same screen > move\n                    if check[0] == False:\n                        cmd = [\"xdotool\", \"windowmove\", w[0],\n                            str(int(w[2]) + rightside), w[3]]                    \n                    else:\n                        cmd = [\"xdotool\", \"windowmove\", w[0],\n                            str(int(w[2]) - rightside), w[3]]\n                    subprocess.Popen(cmd)\n    wd1 = wd2\n    t = 0 if t == 10 else t\n    t += 1\n\nHow to use\n\n\n*\n\n*The script needs both wmctrl and xdotool. Run in a terminal:\nsudo apt-get install xdotool wmctrl\n\n\n*Copy the script into an empty file, save it as move_windows.py\n\n*Test- run the script by the command:\npython3 /path/to/move_windows.py\n\n\n*If all works as expected, add it to Startup Applications: Dash > Startup Applications > Add. Add the command:\n/bin/bash -c \"sleep 15 && python3 /path/to/move_windows.py\"\n\n", "Q: Google Chrome disappeared entirely Google Chrome suddenly disappeared from my computer entirely after a reboot. I was using Chromium for some time but suddenly, Chrome appeared without me downloading it, and I thought something weird with the updates happened. So I was using it for some months and today it is just gone. I only care for my bookmarks. Is there anything I can do to restore it? or any thoughts on why this thing happened? (I am using Kubuntu 12.04 on a Dell Latitude E5420)\n\nA: All of Chromium's data should be stored in /home/username/.config/chromium. To be more precise, your bookmarks are located in \n/home/username/.config/chromium/<Profile ##>/Bookmarks \nor \n/home/username/.config/chromium/Default/Bookmarks.\nIf the bookmarks are really important, save a backup of this file. Then you can reinstall the chromium-browser package and it should hopefully find the bookmarks.\n", "Q: badwolf color scheme does not work on ubuntu 14.04 I want to use color scheme badwolf for my vim so I downloaded it from here https://github.com/sjl/badwolf and copied colors/badwolf.vim to my ~/.vim/colors directory. But it does not work. It does not do any changes. I have Ubuntu 14.04 now but when I had Ubuntu 15.04 and Ubuntu 15.10 (yes, I had to downgrade my system because of some issues) exactly the same .vimrc and badwolf worked.\nI have vim version 7.4.52 and in my .vimrc I have line color badwolf. My uname -a:\nLinux dima-UX32LN 4.2.0-35-generic #40~14.04.1-Ubuntu SMP Fri Mar 18 16:37:35 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nMy bash verison: GNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)\nPS also Ctrl+End stopped working. I can't navigate to the end of page using it.\nMy terminal (echo $COLORTERM) is gnome-terminal.\nUpdate\nMy vim --version:\nVIM - Vi IMproved 7.4 (2013 Aug 10, compiled Jan  2 2014 19:39:32)\nIncluded patches: 1-52\nModified by pkg-vim-maintainers@lists.alioth.debian.org\nCompiled by buildd@\nHuge version without GUI.  Features included (+) or not (-):\n+acl             +farsi           +mouse_netterm   +syntax\n+arabic          +file_in_path    +mouse_sgr       +tag_binary\n+autocmd         +find_in_path    -mouse_sysmouse  +tag_old_static\n-balloon_eval    +float           +mouse_urxvt     -tag_any_white\n-browse          +folding         +mouse_xterm     -tcl\n++builtin_terms  -footer          +multi_byte      +terminfo\n+byte_offset     +fork()          +multi_lang      +termresponse\n+cindent         +gettext         -mzscheme        +textobjects\n-clientserver    -hangul_input    +netbeans_intg   +title\n-clipboard       +iconv           +path_extra      -toolbar\n+cmdline_compl   +insert_expand   -perl            +user_commands\n+cmdline_hist    +jumplist        +persistent_undo +vertsplit\n+cmdline_info    +keymap          +postscript      +virtualedit\n+comments        +langmap         +printer         +visual\n+conceal         +libcall         +profile         +visualextra\n+cryptv          +linebreak       +python          +viminfo\n+cscope          +lispindent      -python3         +vreplace\n+cursorbind      +listcmds        +quickfix        +wildignore\n+cursorshape     +localmap        +reltime         +wildmenu\n+dialog_con      -lua             +rightleft       +windows\n+diff            +menu            -ruby            +writebackup\n+digraphs        +mksession       +scrollbind      -X11\n-dnd             +modify_fname    +signs           -xfontset\n-ebcdic          +mouse           +smartindent     -xim\n+emacs_tags      -mouseshape      -sniff           -xsmp\n+eval            +mouse_dec       +startuptime     -xterm_clipboard\n+ex_extra        +mouse_gpm       +statusline      -xterm_save\n+extra_search    -mouse_jsbterm   -sun_workshop    -xpm\n   system vimrc file: \"$VIM/vimrc\"\n     user vimrc file: \"$HOME/.vimrc\"\n 2nd user vimrc file: \"~/.vim/vimrc\"\n      user exrc file: \"$HOME/.exrc\"\n  fall-back for $VIM: \"/usr/share/vim\"\nCompilation: gcc -c -I. -Iproto -DHAVE_CONFIG_H     -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1      \nLinking: gcc   -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -o vim        -lm -ltinfo -lnsl  -lselinux  -lacl -lattr -lgpm -ldl    -L/usr/lib/python2.7/config-x86_64-linux-gnu -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions \n\nMy .vimrc:\nset nocompatible              \" be iMproved, required\n    filetype off                  \" required\n\" set the runtime path to include Vundle and initialize\nset rtp+=~/.vim/bundle/Vundle.vim\ncall vundle#begin()\n\nPlugin 'VundleVim/Vundle.vim'\n\nPlugin 'tpope/vim-fugitive'\nPlugin 'L9'\nPlugin 'git://git.wincent.com/command-t.git'\nPlugin 'Valloric/YouCompleteMe'\n\nPlugin 'dag/vim2hs'\n\ncall vundle#end()            \" required\nfiletype plugin indent on    \" required\n\n\" YCM settings {{{\nlet g:clang_library_path = \"/usr/lib64/\"\nlet g:clang_complete_copen = 0\nlet g:clang_hl_errors = 1\nlet g:clang_snippets = 1\nlet g:clang_snippets_engine = \"ultisnips\"\nlet g:clang_close_preview = 1\nlet g:clang_complete_macros = 1\n\nlet g:ycm_autoclose_preview_window_after_completion = 1\nlet g:ycm_autoclose_preview_window_after_insertion = 1\nlet g:ycm_use_ultisnips_completer = 1\nlet g:ycm_key_list_select_completion=[]\nlet g:ycm_key_list_previous_completion=[]\n\nlet g:ycm_global_ycm_extra_conf = \"~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py\"\n\" }}}\n\nsyntax on\n\ncolor badwolf\nset cursorline\n\" hi CursorLine term=bold cterm=bold guibg=Grey40\n\nlet python_highlight_all = 1\n\nset autoread\nset ruler\nset ignorecase\nset incsearch\nset number\nset hlsearch \" Enable search highlighting\n\nset expandtab\nset smarttab\nset shiftwidth=4\nset tabstop=4\n\nset ai\nset si\n\nset encoding=utf8\n\nset fileformat=unix\nset ffs=unix,dos,mac\n\nvnoremap <silent> # :call VisualSelection('b')<CR>\n\nset laststatus=2\n\nset pastetoggle=<F2>\n\nmap <F5> :edit!<cr>\nmap <c-s> :w<cr>\nmap <c-z> :undo<cr>\nnmap \\M :set noexpandtab tabstop=8 softtabstop=4 shiftwidth=4<CR>\nnmap \\t :set expandtab tabstop=4 softtabstop=4 shiftwidth=4<CR>\n\n\" open tagbar\nnmap <F8> :TagbarToggle<CR>\n\" open nerdtree\nnmap <F7> :NERDTreeToggle<CR>\n\" open it automatically\n\" autocmd vimenter * NERDTree\n\nnnoremap <C-S-tab> :tabprevious<CR>\nnnoremap <C-tab>   :tabnext<CR>\nnnoremap <C-t>     :tabnew<CR>\n\nau BufNewFile *.cpp 0r ~/.vim/template.cpp | let IndentStyle = \"cpp\"\n\ncommand Compile !g++ -O2 -std=c++11 -Wall -Wextra -DLOCAL -Wpedantic %:t\nexecute pathogen#infect()\ncall pathogen#helptags()\n\n\nA: Finally found the answer. The problem was that by default full color support in ~/.bashrc and ~/.vimrc is disabled. I did not face this problem on Ubuntu 15. I found a fix here: How do I enable full-color support in Vim?. So all I had to do is to insert\nif $COLORTERM == 'gnome-terminal'\n    set t_Co=256\nendif\n\nin my ~/.vimrc\nUPDATE\nAs @muru said it's better to insert\nif [ \"$COLORTERM\" == \"gnome-terminal\" ]; then\n    export TERM=xterm-256color\nfi\n\nin your .bashrc (see why in a link above)\n", "Q: How to first boot Ubuntu from a laptop on Raspberry Pi 3? I have watched many tutorials on how to boot Ubuntu on Raspberry Pi. Every time, after inserting the imaged SD card on the Pi, people attach it with a monitor and a keyboard. But if I  want to attach it with my laptop instead of a monitor, what would I have to do? How would I connect it? And if I connect the Raspberry Pi with the newly imaged sd card, will it start booting for the first time?\n\nA: The RPi first boot needs to use the already embedded outputs to get the first setup done.  I highly doubt your laptop has the ability to use its monitor for external device displays.\nOnce configured you can install a VNC server on the RPi and then use VNC Viewer to access the display over the network (similar to a Remote Desktop type of experience)\n", "Q: Multiple file selection in list view I have found that using the shift or Ctrl keys in combination with the mouse does not work for selecting multiple files in Nautilus list view on 14.04. I have seen numerous posts stating that this works. I have also seen posts suggesting that compviz is involved. However these posts are all 6-10 years old and I would like a modern answer that will allow me to do multiple selection in list view.\n\nA: Multiple selections can be achieved via clicking on a file and using Shift +  Arrow Up (or Arrow Down).\nAs shown in Select multiple non-consecutive files in Nautilus using only the keyboard  , it is possible to make non-consecutive selection via holding Ctrl , press Space once , and use mouse to select multiple files. Note: this is only active while you hold Ctrl. Once you let go, non-consecutive selection becomes inactive. \nNon-consecutive selection can be used with both list and icon view. Below is example with icon view\n\n", "Q: Hyperv_fb not working I'm trying to run an Ubuntu VM on my windows 10 pc. \nThe VM works fine but I want to run it on a full screen. \nI followed some tutorials online and doing \nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash video=hyperv_fb:1680x1050\" in /etc/default/grub.\n\nallows me to run fullscreen. But there is noticeable lag. \nSo I enabled RemoteFX on hyper-v and the lag is gone, but hyperv_fb stops running so stuck with a fixed resolution (and the mouse is not being mapped from the main desktop) \nWhen I disable RemoteFX the vm goes back to full screen mode. \nSo the question is why is hyperv_fb not working when I enable remoteFX? :( \n\nA: hyperv_fb is looking for the Hyper_V video driver.\nhttp://lxr.free-electrons.com/source/drivers/video/fbdev/hyperv_fb.c\nWhen enabling RemoteFX, that driver is not loaded. As far as I know RemoteFX 3D accelerated adapters are not supported in Linux guests. I am still researching this, as it would be nice.\n", "Q: Can't boot Windows 7 from USB, GRUB still there I need to install Win 7 on a computer that previously had Ubuntu 14.04 installed. I created a bootable USB with the Windows 7 ISO on it, but I can't boot from it. From the BIOS/UEFI (not sure) I select the USB stick as boot device but it will not boot but go directly into GRUB.\nWhen I put my Ubuntu USB in, I can boot Ubuntu directly without going to GRUB. I'm really an amateur when it comes to Linux, but I wonder what I can do to repair my boot routine for booting the Windows 7 USB and install it?\nMy partitions\n\nA: I'm pretty sure that the problem is your burned USB for Windows. Maybe try to burn a new one by using the official application provide by Microsoft named Windows USB/DVD Download Tool.\nAnd just a trick: you could try your usb key to see if it's bootable by testing it on a Virtualbox's VM. To do that when you start a VM on the first seconds you see the text \"press F12 to select the boot device\". You certainly  need to boot a first time to mount the USB on the VM by going on Devices > Usb > NAMEOFYOURUSB. Then, you shutdown/start to press F12 the second time.\n", "Q: How can I exclude an application from Dash search? I have an application that I'd like not to show up when I search for it is Dash. How can I keep the application, but prevent it from being found when I search for it? \n\nA: To move the Steam Launcher out of /usr/share/applications, and place it into /opt, use the following command:\nsudo mv /usr/share/applications/steam.desktop /opt/\n\nThe launcher should still work if you navigate to /opt and doubleclick it. An update of Steam will probably put a new launcher into /usr/share/applications.\nFor more info on what mv does, see man mv.\n\nA: No need to make any changes that need sudo\nHow to prevent an application to show up in Dash\n\n*\n\n*Copy the corresponding .desktop file from /usr/share/applications to ~/.local/share/applications:\n  cp /usr/share/applications/steam.desktop ~/.local/share/applications\n\n\n\n*Open the local copy with gedit:\n  gedit ~/.local/share/applications/steam.desktop\n\n\n\n*Add the following line to the head section of the file (before the line, starting with Actions=)\n  NoDisplay=true\n\n\n\n*Save the changes, cLose the file, log out and back in and you're done.\nTo undo\nSimply remove the (local) file ~/.local/share/applications/steam.desktop\nExplanation\nIn general, it is considered bad practice to edit global .desktop files. Not only will changes effect all users, but if you fail, the file will be irreplaceable.\nA local copy of the file however will (after log out/in) will overrule the global one. Also possible updated launchers in /usr/share/applications will be overruled without further measures.\nThe line NoDisplay=true will prevent the application to appear in Dash/the Unity Launcher\n", "Q: HP 15 AC179TX - WiFi not working after Ubuntu Installation I've installed Ubuntu 14.04.4 LTS on my new laptop HP 15 AC179TX.\nI could not see any WiFi networks detected. I could SEE the option \"Enable WiFi\". But after turn on also none of the network is getting discovered. In my other laptop I could see the near by all networks.\nOne more interesting thing is the WiFi network from mobile hotspot is discovered. Only the WiFi signals from router is not discovered. This is weird but this is what happening.\nPlease assist me on how to fix it.\nBelow is the Wireless-info collected from the system.\n########## wireless info START ##########\n\nReport from: 16 Apr 2016 21:07 IST +0530\n\nBooted last: 16 Apr 2016 17:54 IST +0530\n\nScript from: 27 Sep 2015 00:34 UTC +0000\n\n##### release ###########################\n\nDistributor ID: Ubuntu\nDescription:    Ubuntu 14.04.4 LTS\nRelease:    14.04\nCodename:   trusty\n\n##### kernel ############################\n\nLinux 4.2.0-27-generic #32~14.04.1-Ubuntu SMP Fri Jan 22 15:32:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nParameters: ro, quiet, splash, vt.handoff=7\n\n##### desktop ###########################\n\nUbuntu\n\n##### lspci #############################\n\n02:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8101/2/6E PCI Express Fast/Gigabit Ethernet controller [10ec:8136] (rev 07)\n    Subsystem: Hewlett-Packard Company Device [103c:8136]\n    Kernel driver in use: r8169\n\n03:00.0 Network controller [0280]: Realtek Semiconductor Co., Ltd. RTL8723BE PCIe Wireless Network Adapter [10ec:b723]\n    Subsystem: Hewlett-Packard Company Device [103c:804c]\n    Kernel driver in use: rtl8723be\n\n##### lsusb #############################\n\nBus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 001 Device 007: ID 05c8:0382 Cheng Uei Precision Industry Co., Ltd (Foxlink) \nBus 001 Device 006: ID 0bda:b006 Realtek Semiconductor Corp. \nBus 001 Device 009: ID 14cd:125d Super Top \nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\n\n##### PCMCIA card info ##################\n\n##### rfkill ############################\n\n1: phy0: Wireless LAN\n    Soft blocked: no\n    Hard blocked: no\n2: hci0: Bluetooth\n    Soft blocked: no\n    Hard blocked: no\n\n##### lsmod #############################\n\nhp_wmi                 16384  0 \nsparse_keymap          16384  1 hp_wmi\nrtl8723be              90112  0 \nbtcoexist              53248  1 rtl8723be\nrtl8723_common         24576  1 rtl8723be\nrtl_pci                28672  1 rtl8723be\nrtlwifi                77824  2 rtl_pci,rtl8723be\nmac80211              729088  3 rtl_pci,rtlwifi,rtl8723be\niwlwifi               204800  0 \nwmi                    20480  1 hp_wmi\ncfg80211              540672  3 iwlwifi,mac80211,rtlwifi\n\n##### interfaces ########################\n\nauto lo\niface lo inet loopback\n\n##### ifconfig ##########################\n\neth0      Link encap:Ethernet  HWaddr <MAC 'eth0' [IF]>  \n          UP BROADCAST MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nwlan0     Link encap:Ethernet  HWaddr <MAC 'wlan0' [IF]>  \n          inet addr:192.168.43.74  Bcast:192.168.43.255  Mask:255.255.255.0\n          inet6 addr: fe80::<IP6 'wlan0' [IF]>/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:70 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:159 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:33391 (33.3 KB)  TX bytes:25713 (25.7 KB)\n\n##### iwconfig ##########################\n\neth0      no wireless extensions.\n\nlo        no wireless extensions.\n\nwlan0     IEEE 802.11bgn  ESSID:\"AndroidAP\"  \n          Mode:Managed  Frequency:2.437 GHz  Access Point: <MAC 'AndroidAP' [AC1]>   \n          Bit Rate=72.2 Mb/s   Tx-Power=20 dBm   \n          Retry short limit:7   RTS thr=2347 B   Fragment thr:off\n          Power Management:off\n          Link Quality=28/70  Signal level=-82 dBm  \n          Rx invalid nwid:0  Rx invalid crypt:0  Rx invalid frag:0\n          Tx excessive retries:0  Invalid misc:29   Missed beacon:0\n\n##### route #############################\n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         192.168.43.1    0.0.0.0         UG    0      0        0 wlan0\n192.168.43.0    0.0.0.0         255.255.255.0   U     9      0        0 wlan0\n\n##### resolv.conf #######################\n\nnameserver 127.0.1.1\n\n##### network managers ##################\n\nInstalled:\n\n    NetworkManager\n\nRunning:\n\nroot       824     1  0 17:54 ?        00:00:01 NetworkManager\n\n##### NetworkManager info ###############\n\nNetworkManager Tool\n\nState: connected (global)\n\n- Device: wlan0  [AndroidAP] ---------------------------------------------------\n  Type:              802.11 WiFi\n  Driver:            rtl8723be\n  State:             connected\n  Default:           yes\n  HW Address:        <MAC 'wlan0' [IF]>\n\n  Capabilities:\n    Speed:           72 Mb/s\n\n  Wireless Properties\n    WEP Encryption:  yes\n    WPA Encryption:  yes\n    WPA2 Encryption: yes\n\n  Wireless Access Points (* = current AP)\n    *AndroidAP:      Infra, <MAC 'AndroidAP' [AC1]>, Freq 2462 MHz, Rate 54 Mb/s, Strength 46 WPA2\n\n  IPv4 Settings:\n    Address:         192.168.43.74\n    Prefix:          24 (255.255.255.0)\n    Gateway:         192.168.43.1\n\n    DNS:             192.168.43.1\n\n- Device: eth0 -----------------------------------------------------------------\n  Type:              Wired\n  Driver:            r8169\n  State:             unavailable\n  Default:           no\n  HW Address:        <MAC 'eth0' [IF]>\n\n  Capabilities:\n    Carrier Detect:  yes\n\n  Wired Properties\n    Carrier:         off\n\n##### NetworkManager.state ##############\n\n[main]\nNetworkingEnabled=true\nWirelessEnabled=true\nWWANEnabled=true\nWimaxEnabled=true\n\n##### NetworkManager.conf ###############\n\n[main]\nplugins=ifupdown,keyfile,ofono\ndns=dnsmasq\n\nno-auto-default=<MAC 'eth0' [IF]>,\n\n[ifupdown]\nmanaged=false\n\n##### NetworkManager profiles ###########\n\n[[/etc/NetworkManager/system-connections/ptEHXgAAAAAAAwHgSundeep 1]] (600 root)\n[connection] id=ptEHXgAAAAAAAwHgSundeep 1 | type=802-11-wireless\n[802-11-wireless] ssid=ptEHXgAAAAAAAwHgSundeep | mac-address=<MAC 'wlan0' [IF]>\n[ipv6] method=auto\n[ipv4] method=auto\n\n[[/etc/NetworkManager/system-connections/AndroidAP]] (600 root)\n[connection] id=AndroidAP | type=802-11-wireless\n[802-11-wireless] ssid=AndroidAP | mac-address=<MAC 'wlan0' [IF]>\n[ipv4] method=auto\n[ipv6] method=auto\n\n[[/etc/NetworkManager/system-connections/ptEHXgAAAAAAAwHgSundeep]] (600 root)\n[connection] id=ptEHXgAAAAAAAwHgSundeep | type=802-11-wireless\n[802-11-wireless] ssid=ptEHXgAAAAAAAwHgSundeep | mac-address=<MAC 'wlan0' [IF]>\n[ipv4] method=auto\n[ipv6] method=auto\n\n##### iw reg get ########################\n\nRegion: Asia/Kolkata (based on set time zone)\n\ncountry 00:\n    (2402 - 2472 @ 40), (3, 20)\n    (2457 - 2482 @ 40), (3, 20), PASSIVE-SCAN, NO-IBSS\n    (2474 - 2494 @ 20), (3, 20), NO-OFDM, PASSIVE-SCAN, NO-IBSS\n    (5170 - 5250 @ 40), (3, 20), PASSIVE-SCAN, NO-IBSS\n    (5735 - 5835 @ 40), (3, 20), PASSIVE-SCAN, NO-IBSS\n\n##### iwlist channels ###################\n\neth0      no frequency information.\n\nlo        no frequency information.\n\nwlan0     13 channels in total; available frequencies :\n          Channel 01 : 2.412 GHz\n          Channel 02 : 2.417 GHz\n          Channel 03 : 2.422 GHz\n          Channel 04 : 2.427 GHz\n          Channel 05 : 2.432 GHz\n          Channel 06 : 2.437 GHz\n          Channel 07 : 2.442 GHz\n          Channel 08 : 2.447 GHz\n          Channel 09 : 2.452 GHz\n          Channel 10 : 2.457 GHz\n          Channel 11 : 2.462 GHz\n          Channel 12 : 2.467 GHz\n          Channel 13 : 2.472 GHz\n          Current Frequency:2.437 GHz (Channel 6)\n\n##### iwlist scan #######################\n\neth0      Interface doesn't support scanning.\n\nlo        Interface doesn't support scanning.\n\nChannel occupancy:\n\n      1   APs on   Frequency:2.437 GHz (Channel 6)\n\nwlan0     Scan completed :\n          Cell 01 - Address: <MAC 'AndroidAP' [AC1]>\n                    Channel:6\n                    Frequency:2.437 GHz (Channel 6)\n                    Quality=26/70  Signal level=-84 dBm  \n                    Encryption key:on\n                    ESSID:\"AndroidAP\"\n                    Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s\n                    Bit Rates:6 Mb/s; 9 Mb/s; 12 Mb/s; 18 Mb/s; 24 Mb/s\n                              36 Mb/s; 48 Mb/s; 54 Mb/s\n                    Mode:Master\n                    Extra:tsf=000000000229512a\n                    Extra: Last beacon: 60ms ago\n                    IE: IEEE 802.11i/WPA2 Version 1\n                        Group Cipher : CCMP\n                        Pairwise Ciphers (1) : CCMP\n                        Authentication Suites (1) : PSK\n\n##### module infos ######################\n\n[rtl8723be]\nfilename:       /lib/modules/4.2.0-27-generic/kernel/drivers/net/wireless/rtlwifi/rtl8723be/rtl8723be.ko\nfirmware:       rtlwifi/rtl8723befw.bin\ndescription:    Realtek 8723BE 802.11n PCI wireless\nlicense:        GPL\nauthor:         Realtek WlanFAE <wlanfae@realtek.com>\nauthor:         PageHe  <page_he@realsil.com.cn>\nsrcversion:     F4844EEE911CB18A8B2934B\ndepends:        rtlwifi,rtl8723-common,rtl_pci,btcoexist,mac80211\nintree:         Y\nvermagic:       4.2.0-27-generic SMP mod_unload modversions \nsigner:         Build time autogenerated kernel key\nsig_key:        73:6E:2F:9E:A1:B4:72:8A:15:AC:16:9B:18:69:26:7E:11:28:D6:E8\nsig_hashalgo:   sha512\nparm:           swenc:Set to 1 for software crypto (default 0)\n (bool)\nparm:           ips:Set to 0 to not use link power save (default 1)\n (bool)\nparm:           swlps:Set to 1 to use SW control power save (default 0)\n (bool)\nparm:           fwlps:Set to 1 to use FW control power save (default 1)\n (bool)\nparm:           msi:Set to 1 to use MSI interrupts mode (default 0)\n (bool)\nparm:           debug:Set debug level (0-5) (default 0) (int)\nparm:           disable_watchdog:Set to 1 to disable the watchdog (default 0)\n (bool)\n\n[rtl8723_common]\nfilename:       /lib/modules/4.2.0-27-generic/kernel/drivers/net/wireless/rtlwifi/rtl8723com/rtl8723-common.ko\ndescription:    Realtek RTL8723AE/RTL8723BE 802.11n PCI wireless common routines\nlicense:        GPL\nauthor:         Larry Finger    <Larry.Finger@lwfinger.net>\nauthor:         Realtek WlanFAE <wlanfae@realtek.com>\nsrcversion:     251C540A2D3AD38CCA85ED9\ndepends:        \nintree:         Y\nvermagic:       4.2.0-27-generic SMP mod_unload modversions \nsigner:         Build time autogenerated kernel key\nsig_key:        73:6E:2F:9E:A1:B4:72:8A:15:AC:16:9B:18:69:26:7E:11:28:D6:E8\nsig_hashalgo:   sha512\n\n[rtl_pci]\nfilename:       /lib/modules/4.2.0-27-generic/kernel/drivers/net/wireless/rtlwifi/rtl_pci.ko\ndescription:    PCI basic driver for rtlwifi\nlicense:        GPL\nauthor:         Larry Finger    <Larry.FInger@lwfinger.net>\nauthor:         Realtek WlanFAE <wlanfae@realtek.com>\nauthor:         lizhaoming  <chaoming_li@realsil.com.cn>\nsrcversion:     A888EFDC516033207A503FA\ndepends:        mac80211,rtlwifi\nintree:         Y\nvermagic:       4.2.0-27-generic SMP mod_unload modversions \nsigner:         Build time autogenerated kernel key\nsig_key:        73:6E:2F:9E:A1:B4:72:8A:15:AC:16:9B:18:69:26:7E:11:28:D6:E8\nsig_hashalgo:   sha512\n\n[rtlwifi]\nfilename:       /lib/modules/4.2.0-27-generic/kernel/drivers/net/wireless/rtlwifi/rtlwifi.ko\ndescription:    Realtek 802.11n PCI wireless core\nlicense:        GPL\nauthor:         Larry Finger    <Larry.FInger@lwfinger.net>\nauthor:         Realtek WlanFAE <wlanfae@realtek.com>\nauthor:         lizhaoming  <chaoming_li@realsil.com.cn>\nsrcversion:     F4CACC5FCAEBE7C22930A24\ndepends:        mac80211,cfg80211\nintree:         Y\nvermagic:       4.2.0-27-generic SMP mod_unload modversions \nsigner:         Build time autogenerated kernel key\nsig_key:        73:6E:2F:9E:A1:B4:72:8A:15:AC:16:9B:18:69:26:7E:11:28:D6:E8\nsig_hashalgo:   sha512\n\n[mac80211]\nfilename:       /lib/modules/4.2.0-27-generic/kernel/net/mac80211/mac80211.ko\nlicense:        GPL\ndescription:    IEEE 802.11 subsystem\nsrcversion:     FBF6EA073A00B4F3836226E\ndepends:        cfg80211\nintree:         Y\nvermagic:       4.2.0-27-generic SMP mod_unload modversions \nsigner:         Build time autogenerated kernel key\nsig_key:        73:6E:2F:9E:A1:B4:72:8A:15:AC:16:9B:18:69:26:7E:11:28:D6:E8\nsig_hashalgo:   sha512\nparm:           minstrel_vht_only:Use only VHT rates when VHT is supported by sta. (bool)\nparm:           max_nullfunc_tries:Maximum nullfunc tx tries before disconnecting (reason 4). (int)\nparm:           max_probe_tries:Maximum probe tries before disconnecting (reason 4). (int)\nparm:           beacon_loss_count:Number of beacon intervals before we decide beacon was lost. (int)\nparm:           probe_wait_ms:Maximum time(ms) to wait for probe response before disconnecting (reason 4). (int)\nparm:           ieee80211_default_rc_algo:Default rate control algorithm for mac80211 to use (charp)\n\n[iwlwifi]\nfilename:       /lib/modules/4.2.0-27-generic/kernel/drivers/net/wireless/iwlwifi/iwlwifi.ko\nlicense:        GPL\nauthor:         Copyright(c) 2003- 2015 Intel Corporation <ilw@linux.intel.com>\ndescription:    Intel(R) Wireless WiFi driver for Linux\nfirmware:       iwlwifi-100-5.ucode\nfirmware:       iwlwifi-1000-5.ucode\nfirmware:       iwlwifi-135-6.ucode\nfirmware:       iwlwifi-105-6.ucode\nfirmware:       iwlwifi-2030-6.ucode\nfirmware:       iwlwifi-2000-6.ucode\nfirmware:       iwlwifi-5150-2.ucode\nfirmware:       iwlwifi-5000-5.ucode\nfirmware:       iwlwifi-6000g2b-6.ucode\nfirmware:       iwlwifi-6000g2a-5.ucode\nfirmware:       iwlwifi-6050-5.ucode\nfirmware:       iwlwifi-6000-4.ucode\nfirmware:       iwlwifi-7265D-12.ucode\nfirmware:       iwlwifi-7265-12.ucode\nfirmware:       iwlwifi-3160-12.ucode\nfirmware:       iwlwifi-7260-12.ucode\nfirmware:       iwlwifi-8000-12.ucode\nsrcversion:     75997E53B9CC3BD2CA79F3B\ndepends:        cfg80211\nintree:         Y\nvermagic:       4.2.0-27-generic SMP mod_unload modversions \nsigner:         Build time autogenerated kernel key\nsig_key:        73:6E:2F:9E:A1:B4:72:8A:15:AC:16:9B:18:69:26:7E:11:28:D6:E8\nsig_hashalgo:   sha512\nparm:           swcrypto:using crypto in software (default 0 [hardware]) (int)\nparm:           11n_disable:disable 11n functionality, bitmap: 1: full, 2: disable agg TX, 4: disable agg RX, 8 enable agg TX (uint)\nparm:           amsdu_size_8K:enable 8K amsdu size (default 0) (int)\nparm:           fw_restart:restart firmware in case of error (default true) (bool)\nparm:           antenna_coupling:specify antenna coupling in dB (default: 0 dB) (int)\nparm:           nvm_file:NVM file name (charp)\nparm:           d0i3_disable:disable d0i3 functionality (default: Y) (bool)\nparm:           lar_disable:disable LAR functionality (default: N) (bool)\nparm:           uapsd_disable:disable U-APSD functionality (default: Y) (bool)\nparm:           bt_coex_active:enable wifi/bt co-exist (default: enable) (bool)\nparm:           led_mode:0=system default, 1=On(RF On)/Off(RF Off), 2=blinking, 3=Off (default: 0) (int)\nparm:           power_save:enable WiFi power management (default: disable) (bool)\nparm:           power_level:default power save level (range from 1 - 5, default: 1) (int)\nparm:           fw_monitor:firmware monitor - to debug FW (default: false - needs lots of memory) (bool)\n\n[cfg80211]\nfilename:       /lib/modules/4.2.0-27-generic/kernel/net/wireless/cfg80211.ko\ndescription:    wireless configuration support\nlicense:        GPL\nauthor:         Johannes Berg\nsrcversion:     7982686FBE8064A87E02753\ndepends:        \nintree:         Y\nvermagic:       4.2.0-27-generic SMP mod_unload modversions \nsigner:         Build time autogenerated kernel key\nsig_key:        73:6E:2F:9E:A1:B4:72:8A:15:AC:16:9B:18:69:26:7E:11:28:D6:E8\nsig_hashalgo:   sha512\nparm:           ieee80211_regdom:IEEE 802.11 regulatory domain code (charp)\nparm:           cfg80211_disable_40mhz_24ghz:Disable 40MHz support in the 2.4GHz band (bool)\n\n##### module parameters #################\n\n[rtl8723be]\ndebug: 0\ndisable_watchdog: N\nfwlps: Y\nips: Y\nmsi: N\nswenc: N\nswlps: N\n\n[mac80211]\nbeacon_loss_count: 7\nieee80211_default_rc_algo: minstrel_ht\nmax_nullfunc_tries: 2\nmax_probe_tries: 5\nminstrel_vht_only: Y\nprobe_wait_ms: 500\n\n[iwlwifi]\n11n_disable: 0\namsdu_size_8K: 0\nantenna_coupling: 0\nbt_coex_active: Y\nd0i3_disable: Y\nfw_monitor: N\nfw_restart: Y\nlar_disable: N\nled_mode: 0\nnvm_file: (null)\npower_level: 0\npower_save: N\nswcrypto: 0\nuapsd_disable: Y\n\n[cfg80211]\ncfg80211_disable_40mhz_24ghz: N\nieee80211_regdom: 00\n\n##### /etc/modules ######################\n\nlp\nrtc\niwlwifi\n\n##### modprobe options ##################\n\n[/etc/modprobe.d/blacklist-ath_pci.conf]\nblacklist ath_pci\n\n[/etc/modprobe.d/blacklist.conf]\nblacklist evbug\nblacklist usbmouse\nblacklist usbkbd\nblacklist eepro100\nblacklist de4x5\nblacklist eth1394\nblacklist snd_intel8x0m\nblacklist snd_aw2\nblacklist i2c_i801\nblacklist prism54\nblacklist bcm43xx\nblacklist garmin_gps\nblacklist asus_acpi\nblacklist snd_pcsp\nblacklist pcspkr\nblacklist amd76x_edac\n\n[/etc/modprobe.d/blacklist-rare-network.conf]\nalias net-pf-3 off\nalias net-pf-6 off\nalias net-pf-9 off\nalias net-pf-11 off\nalias net-pf-12 off\nalias net-pf-19 off\nalias net-pf-21 off\nalias net-pf-36 off\n\n[/etc/modprobe.d/iwlwifi.conf]\nremove iwlwifi \\\n(/sbin/lsmod | grep -o -e ^iwlmvm -e ^iwldvm -e ^iwlwifi | xargs /sbin/rmmod) \\\n&& /sbin/modprobe -r mac80211\n\n[/etc/modprobe.d/mlx4.conf]\nsoftdep mlx4_core post: mlx4_en\n\n##### rc.local ##########################\n\nexit 0\n\n##### pm-utils ##########################\n\n##### udev rules ########################\n\n[/etc/udev/rules.d/70-persistent-net.rules]\n# PCI device 0x10ec:0x8136 (r8169)\nSUBSYSTEM==\"net\", ACTION==\"add\", DRIVERS==\"?*\", ATTR{address}==\"<MAC 'eth0' [IF]>\", ATTR{dev_id}==\"0x0\", ATTR{type}==\"1\", KERNEL==\"eth*\", NAME=\"eth0\"\n# PCI device 0x10ec:0xb723 (rtl8723be)\nSUBSYSTEM==\"net\", ACTION==\"add\", DRIVERS==\"?*\", ATTR{address}==\"<MAC 'wlan0' [IF]>\", ATTR{dev_id}==\"0x0\", ATTR{type}==\"1\", KERNEL==\"wlan*\", NAME=\"wlan0\"\n\n##### dmesg #############################\n\n[  217.871815] Bluetooth: hci0: rtl: examining hci_ver=06 hci_rev=000b lmp_ver=06 lmp_subver=8723\n[  217.871818] Bluetooth: hci0: rtl: loading rtl_bt/rtl8723b_fw.bin\n[  217.871845] bluetooth hci0: Direct firmware load for rtl_bt/rtl8723b_fw.bin failed with error -2\n[  217.871848] Bluetooth: hci0: Failed to load rtl_bt/rtl8723b_fw.bin\n[  220.185321] r8169 0000:02:00.0 eth0: link down\n[  220.185377] IPv6: ADDRCONF(NETDEV_UP): eth0: link is not ready\n[  220.405619] r8169 0000:02:00.0 eth0: link down\n[  220.405678] IPv6: ADDRCONF(NETDEV_UP): eth0: link is not ready\n[  233.295995] IPv6: ADDRCONF(NETDEV_UP): wlan0: link is not ready\n[ 2562.692831] wlan0: authenticate with <MAC 'AndroidAP' [AC1]>\n[ 2562.713957] wlan0: send auth to <MAC 'AndroidAP' [AC1]> (try 1/3)\n[ 2562.719497] wlan0: authenticated\n[ 2562.723769] wlan0: associate with <MAC 'AndroidAP' [AC1]> (try 1/3)\n[ 2562.743411] wlan0: RX AssocResp from <MAC 'AndroidAP' [AC1]> (capab=0x8431 status=0 aid=1)\n[ 2562.744318] wlan0: associated\n[ 2562.744331] IPv6: ADDRCONF(NETDEV_CHANGE): wlan0: link becomes ready\n\n########## wireless info END ############\n\n", "Q: Samsung SCX-4200 Scanner not working (printing OK) 14.04 I have somehow lost the possiblity of scanning using my Samsung SCX-4200 3in1 printer. Priting works fine using the Linux driver, provided at initial instalation, however scanning stalls and fails.\nsane-find-scanner reveals:\n  # sane-find-scanner will now attempt to detect your scanner. If the\n  # result is different from what you expected, first make sure your\n  # scanner is powered up and properly connected to your computer.\n  # No SCSI scanners found. If you expected something different, make sure that\n  # you have loaded a kernel SCSI driver for your SCSI adapter.\nfound USB scanner (vendor=0x0bda [Generic], product=0x0129 [USB2.0-CRW]) at libusb:001:004\n  # Your USB scanner was (probably) detected. It may or may not be supported by\n  # SANE. Try scanimage -L and read the backend's manpage.\n  # Not checking for parallel port scanners.\n  # Most Scanners connected to the parallel port or other proprietary ports\n  # can't be detected by this program.\n\nPlus, when I try scanimage -L, another computer in my network is shown, not the Samsung one.\nscanimage -L\ndevice `hpaio:/net/Deskjet_3520_series?zc=HPC8CBB850038A' is a Hewlett-Packard Deskjet_3520_series all-in-one\n\nWhat can I do?\nThanks.\n\nA: This is a kind of an old question, but I had similar issues in Ubuntu 18.04.\nThe problem in my case was USB3. After putting the cable to an USB2 input, it worked all fine.\nThis has been discussed here (in french language): https://forum.ubuntu-fr.org/viewtopic.php?id=2023391\nMight be related to this one: scanner of Samsung SCX-4200 does not work on ubuntu 12.10\n", "Q: User add and shell script with password I know how to use the useradd comand but would like to make a shell script to automate the process so how would I put the users input to the password part which is a dialog presented after I have entered the comand.\n\nA: This should make it\n#!/bin/bash\n#Run ./x.sh username password\ncrypting=`perl -e 'printf(\"%s\\n\", crypt($ARGV[0], \"password\"))' \"$2\"`\nuseradd -m -p $crypting -s /bin/bash $1\n\nI made something like this a while ago, when I was bored\n#!/bin/bash\n#Run ./y.sh username password\ncrypting=$(perl -e 'print crypt($ARGV[0], \"password\")' $2)\nrandomid=$(echo $[ 1000 + $[ RANDOM % 10000000 ]]) \nmkdir /home/$1\necho \"$1:$crypting:16760:0:99999:7:::\" >> /etc/shadow\necho \"$1:$crypting:$randomid:$randomid:$1:/home/$1:/bin/bash\" >> /etc/passwd\n\n", "Q: Backing up Trusty for Xenial I want to install Xenial Xerus as soon as its final release is out but being an Ubuntu noob there's a fine chance that I might mess things up. I want to know if there's a way to back up my current installation so that I could recover it if things go wrong.\nEdit: The wifi link wasn't related but this one is.\n\nA: Based on this documentation you can use tar to make backup of whole your system in just one command:\nsudo tar -cvpzf backup.tar.gz --exclude=/backup.tar.gz --one-file-system /  \n\nIt will create backup.tar.gz archive in folder where you are in. You can change destination as you wish (e.g pendrive)\nIf you have your home on different partition you need to back it up separately, or omit --one-file-system flag and exclude such directries like  /proc, /sys, /mnt, /media, /run and /dev\n\nThere are also many others tools like rsync or Déjà Dup\n", "Q: Unable to boot into Ubuntu Live USB, boot priority ignored I recently did a clean install of Windows 10 with the intention of dual booting Ubuntu. \nUnfortunately, I am now unable to boot using the Live USB. I recreated the USB using the Universal Usb Installer (v15.10)\nIn BIOS, I go in and set the boot priority to UEFI: <name of usb manufactruer>\nbut then, it just boots into Windows. \nMy bios is:\nBIOS: Version/Date American Megatrends Inc. 1301, 12/20/2013\nProcessor: Intel(R) Core(TM) i7-4770K CP  @ 3.50GHz, 3501 Mhz, 4 Core(s), 8 \n\nI have an ASUS Mobo, if that helps. I was able to boot into USB prior to installing Windows, so inclined to believe that the win install changed some BIOS setting. \nFast startup, Hibernate and Sleep are all checked off in the Power settings. \n\nA: You have to disable hibernation and Fast startup.\nOpen command prompt as administrator - execute :  \npowercfg /h off  \n\nOpen the old version of the Windows Control Panel.\nGo to the Power Settings and uncheck Fast startup.\nIn case it is not visible, enable show hidden settings.  \nShutdown the machine completely - do NOT restart.\nBoot into BIOS and select to boot from the USB disk.\nSelect the Ubuntu entry with UEFI in front and boot.  \nUpdate addressing the information in your comment.\nIn case you still can't boot create the media this way.\nOpen command prompt as administrator - execute :  \ndiskpart\nlist disk  \nselect disk *  \nclean  \ncreate partition primary  \nactive  \nformat fs=fat32 quick  \nassign letter=**  \n\nNote : * = number of USB drive | ** = select a free drive letter\nNow mount the ISO file and copy its content to the USB drive.\nThis method from within Windows is proven to work properly.\n\nA: It is also quite possible that the creation of the boot media was unsuccessful.  If you set to boot from an unbootable medium usually it skips (without indication) to the next drive on the list of priorities.\n\nA: In Windows 10 u will have an option called Advanced Start-up using which u can boot through the USB.Go to Advanced Start-up option n restart your PC and choose the Device with USB which has Ubuntu.U must be able to do it.Or In case it still has Ubuntu left behind,u might need to fix the Bootrec.\n", "Q: bash: ./flash_tool: cannot execute binary file: Exec format error I try to run SP Flash Tool under Ubuntu MATE but after I chmod +x the executable file, I get this error:\nbash: ./flash_tool: cannot execute binary file: Exec format error\nbash: ./flash_tool.sh: Permission denied\n\nAnyone have any idea why?\n\nA: The Exec format error means you are using the wrong file for your computer.  Most likely you were trying to use the 64 bit version on a 32 bit Ubuntu.  You need to download the right one.\nType arch in a terminal to be sure which you should use.\nIf you get something like i386 as I suspect, download the \"Linux 32 Bit version\" under the heading \"Direct links for SP Flash Tool Download\" from http://spflashtool.com/\nCurrently, the supposed 32-bit version hosted there is in fact also 64-bit, and so no usable version is available for 32-bit Ubuntu.  You might be able to find a 32-bit one elsewhere, but be careful.  You cannot be certain any of these downloads (including the above link) are virus-free.\nIf you get x86_64 choose \"Download SPFlashTool for Linux - 64 Bit Tool\"\n\nA: The Download for 32bit Linux on http://spflashtool.com/ is not 32bit, it is the 64bit Version.\n\nA: Run it as non root user. I'm on Kali Linux with root user by default and I was able to run the flash_tool using a non root user , through gksu:\n<< gksu -u my_non_root_user ./flash_tool.sh >>\nOn Ubuntu it should work without sudo I suppose.\nThat works for me. I hope it may help!\n", "Q: How do I block Zeitgeist from ever being installed on my system? How do I block Zeitgeist from ever being installed on my system?\nI find it quite frustrating that this is continually trying to sneak in the back door. I do not want this on my computers, ever though there seems to be packages that insist on making it a dependency when it is not required.\nI just found the Zeitgeist-Datahub service running on my system and I am NOT happy about it.\n\nA: First you get your Ubuntu system to tty1 by pressing on CTRL+ALT+F1, then run the following:\nkillall zeitgeist\nsudo apt-get purge zeitgeist*\n\nThen block the Zeitgeist package by running:\nvim /etc/apt/preferences\n\nIf you don't have vim run:\nsudo apt-get install vim\n\nOn vim, you press I to insert the new line.\nThen you can add the following:\nPackage: zeitgeist \nPin: origin \"\" \nPin-Priority: -1\n\nThen press ESC to go to command mode, type :w and wait for writing progress, and when finished, type :q\nGo to GUI Mode again by either:\nsudo service lightdm restart\n\nOr press CTRL+ALT+F7 to get back to GUI, and then restart your computer.\n", "Q: Re-size boot drive partitions I recently swapped out a smaller drive (320gb) for a larger one (500gb) because I was getting warnings about space.  I had done all of the logical things I knew about to free up space and decided it was time to upgrade the drive.  The upgrade went well, but, now, I'm left with trying to re-size the partitions to take advantage of the new 180gb I've provided.  I'm somewhat at a loss.  I've looked at this, but, wasn't able to figure out what to do.\nThe new drive has 3 existing partitions and 180gb of free space.  They are:\n\n\n*\n\n*Partition 1 - Filesystem Ext2\n\n*Partition 2 - Extended 320 gb\n\n*Partition 5 - LVM2 PV 320 gb\n\n*Free space  - 180 gb\n\n\nI installed the LVM disk utility mentioned in the post above.  I could not figure out how to use the utility to re-size the partitions to take advantage of the new space.\nI'd greatly appreciate if someone can provide steps on how to increase my partition(s) so that the newly added space is used.\n\nA: I was able to figure this out.  My initial problem was understanding that Ubuntu does not treat a disk swap like Windows.  When a disk is swapped in Windows, the OS knows to extend the file system into the remaining space.  In Ubuntu, there are some extra steps that I found by reading How can I resize an LVM partition? (i.e: physical volume).\nBasically, the steps I took were...\n\n\n*\n\n*Use Clonezilla to copy the contents of the smaller drive to a larger\ndrive.\n\n*Use the Disk manager to create a new partition on the new free space\n(180gb).\n\n*Use the LVM (Logical Volume Management) tool to initialize the new\nspace.\n\n\nAnd, the steps I was missing....\n\n\n*\n\n*Reboot from a Live CD and install LVM according to the post above.\n\n*Use LVM to extend the file system into the new space.\n\n*Reboot and space is now available.\n\n\nI hope this helps someone else struggling with how to accomplish a disk swap.\n", "Q: Getting \"Scheme missing\" error with wget I wrote a little script that grabs a random wallpaper from the Desktoppr API and changes my desktop wallpaper to it:\n#!/bin/bash\nurl=$(curl 'https://api.desktoppr.co/1/wallpapers?page='$(shuf -i 1-1000 -n 1) | jq \".response[].image.url\" | sed $(shuf -i 1-20 -n 1)'!d') &&\nwget \"$url\"\n\nWhen I run the script, the final wget command fails with the error:\n\"http://a.desktopprassets.com/wallpapers/...jpg\": Scheme missing.\n\nWhen I put the URL directly into the wget command, like so:\nwget \"http://a.desktopprassets.com/wallpapers/...jpg\"\n\n... the command executes correctly and downloads the image, meaning that the error occurs because of some problem in the variable.\nI think this might have something to do with the jq library that I am using to parse the JSON response from the Desktoprr API.\n\nA: You need to remove the double quotes surrounding the URL, for example by using the -r option to jq:\nurl=$(curl 'https://api.desktoppr.co/1/wallpapers?page='$(shuf -i 1-1000 -n 1) | jq -r \".response[].image.url\" | sed $(shuf -i 1-20 -n 1)'!d')\n\nCurrently the command actually results in\nwget \"\\\"http://a.desktopprassets.com/wallpapers/...jpg\\\"\"\n\n\nA: I had a similar problem like this.\nThis return the Scheme Missing Error:\nresources=$(cat complete_list_of_urls.txt)\nfor resource in ${resources[@]};\ndo\n    wget --no-check-certificate https://cyberican.com/images/images/$resource\ndone\n\nBy removing the (\") quotation marks, I could extract the data.\nresources=$(cat complete_list_of_urls.txt | tr -d '\\\"')\nfor resource in ${resources[@]};\ndo\n    wget --no-check-certificate https://cyberican.com/images/images/$resource\ndone\n\nI hope this help anyone having the same problem :-)\n", "Q: only 96GB of ~750GB after mounting to /home/....? I got a 800 GB partition out of a 3 TB HDD, fomated it with ext4 and mounted it to /home/elliot/BigData permanently via /etc/fstab.\nIt works fine but after rebooting I got only 96GB free space out of the 800GB the rest turned to used space! \nReformated and tried again, I got the same result.\nWhat went wrong? Where is the rest of my space?\n\nUPDATE:\nwhen i mount the same partition to e.g. /media/test via /etc/fstab i get the full diskspace.... i tried it again with an other folder in the home-directory and again got only 96GB! O_o  Are there any restiction or a kind of an contingent when i mount something to /home/username/somefolder ????\n\nA: Start a shell and type \ndu /home/elliot/BigData\n\nThis will return the used space, as caulculated by the files that exist on the partition. You can append -h for human readable and -s for summary.\nPer your comment, it's only showing 6.1GB used so something seems to be wrong with the partition. You can attempt to fix this with fsck. You need to unmount the volume to do this:\nsudo umount /dev/sda4\nsudo fsck /dev/sda4\n\nHowever if this is your main Linux partition, you won't be able to do this from a running instance. You'll need to boot into a LiveCD/USB. Run sudo lsblk to find the partition name (which will be different from /dev/sda4 in the live environment) and run the fsck.\n", "Q: How can I encrypt my Ubuntu partition? I have Windows 10 and Ubuntu. I want to know how to encrypt the Ubuntu partition so no malware can jump from windows.\n\nA: If the only reason you want to encrypt your Ubuntu partition is because of fear for malware from Windows, then you probably don't want to do it.\nIt is almost impossible for Windows malware to harm Ubuntu as Ubuntu generally speaking does not understand EXE files (unless you use Wine).\nIf you want to encrypt your Ubuntu partition because you fear that Windows malware will corrupt the Ubuntu partition, encryption is not going to solve the problem.\n", "Q: NVIDIA GTX 960M not working I have Lenovo Y700 with Nvidia GeForce GTX 960M and Ubuntu 15.10 running in VirtualBox.\nI can't get my graphical card working under Linux.\nI have installed:\n\n\n*\n\n*nvidia-361\n\n*nvidia-opencl-icd-361\n\n*nvidia-prime        \n\n*nvidia-settings\nIn VirtualBox 3D acceleration is enabled. Yet if I run:\nlspci -k | grep -A 2 -E \"(VGA|3D)\"\n\nI get:\n00:02.0 VGA compatible controller: InnoTek Systemberatung GmbH VirtualBox Graphics Adapter\n\nWhich I take means that Linux doesn't see my card? Also since installing the nvidia-* drivers Cinnamon crashes on startup (I assume this is connected with the same issue).\nI tried to follow the arch-wiki and a few related answers here, but nothing seems to work (and/or seems outdated).\n\nA: I might be wrong but I think even with 3D acceleration VirtualBox uses its own graphicscard in the VM. I think it's not possible to put your GeForce through!\n", "Q: Ubuntu installation takes an hour. Is there any way to see logs? I'm trying to install Ubuntu 15.10 on my computer. It has been more than an hour. Is it normal? (I checked the option download the updates during the installation). Is there any way to see logs during the installation to be sure that it's still installing or downloading updates?\n\nA: This question made me curious so I tested it out by myself and answer is... YES you can.\nGo to non-graphical mode by pressing Ctrl+Alt+ F1.\nLogin with default username ubuntu and password is blank. Now you can access /var/log/ and see what's going on.\nSince you want to check your installation process, then tail installer debug log:\ntail -f /var/log/installer/debug\n\nSwitch back to the graphical interface with: Ctrl+Alt+F7.\n\nA: In the newer Ubuntu releases, if you install using autoinstall config via cloud-init, the installer log is curtin-install.log not debug.\nless /var/log/installer/curtin-install.log\n\nor\ntail -f /var/log/installer/curtin-install.log\n\n", "Q: How do I cd to CDROM directory How do I cd to into the inner cdrom (VBOXADDITIONS) directory?\n\n\nA: You change directories to locations on a CDROM the same way you change directories on your hard drive or any other media.\nBy default the cdrom will probably be mounted in your /media directory.  It appears from your image that you might have already noticed this and have gotten fairly close.\nWhen changing to a directory you have to be very careful to the spelling as well as the case of the letters.  A directory that has an upper case letter would be different from a directory with a lower case.\nYou can use the facility of Linux's completion by typing some of the characters and hitting the Tab key to complete the characters.  This can serve to help you get the spelling exact.  It has to be exact.\nYou might also consider using copy and paste to be sure to get the spelling and upper/lower case conditions more accurate.\nIn the case of the image you have above, typing cd VB then hitting the Tab key should have completed the spelling for you, then you could press Enter.\nAlso, looking at your image, you can't prefix the directory with just a forward-slash.  The forward-slash alone would indicate the root directory.\n", "Q: Trying to setup a 4096x2160 modline on a LG 31MU97 monitor So I have an LG 4k (31MU97) monitor that supports 4096x2160 at 60Hz. I can run 3840x2160 at 60Hz fine. When I run xrandr, I don't see the 4096x2160 mode:\nScreen 0: minimum 320 x 200, current 3840 x 2160, maximum 16384 x 16384\nDisplayPort-0 disconnected (normal left inverted right x axis y axis)\nDisplayPort-1 connected 3840x2160+0+0 (normal left inverted right x axis y axis) 621mm x 341mm\n   3840x2160     60.00*+  30.00  \n   1920x1080     60.00    59.94  \n   1600x900      60.00  \n   1280x1024     60.02  \n   1152x864      59.97  \n   1280x720      60.00    59.94  \n   1024x768      60.00  \n   800x600       60.32  \n   720x480       60.00    59.94  \n   640x480       60.00    59.94  \n   4096x2160_60.00  59.98  \nHDMI-0 disconnected (normal left inverted right x axis y axis)\nDVI-0 disconnected (normal left inverted right x axis y axis)\nDVI-1 disconnected (normal left inverted right x axis y axis)\n\nI've looked at some other guides including a forum thread and a pastebin that have very similar instructions:\nRun either CVT or GTF to generate a modeline string: \ncvt 4096 2160 60\n# 4096x2160 59.98 Hz (CVT) hsync: 134.18 kHz; pclk: 760.00 MHz\nModeline \"4096x2160_60.00\"  760.00  4096 4432 4880 5664  2160 2163 2173 2237 -hsync +vsync\n\nor\ngtf 4096 2160 60.0\n\n  # 4096x2160 @ 60.00 Hz (GTF) hsync: 134.10 kHz; pclk: 759.54 MHz\n  Modeline \"4096x2160_60.00\"  759.54  4096 4424 4880 5664  2160 2161 2164 2235  -HSync +Vsync\n\nThen I create a new mode\n xrandr --newmode <mode string>\n xrandr --addmode DisplayPort-1 4096_2160_60.00\n\nIf anyone remembers the old CRT monitors days, with the mode switch and a timer, you can do something similar just by running:\nxrandr -s \"4096x2160_60.0\"; sleep 15; xrandr --output DisplayPort-1 --mode 3840x2160 --auto\n\nAnyway, using both the CVT and GTF mode lines, I simply get a blank screen and my monitor says it can't find an input signal (you can use --rmmode and --delmode to remove a mode so you can add it again). I've tried some variations such as using 30.0HZ or 59.94Hz without successful results. \nWhat exactly are all the other numbers for in the modeline string? I'm suspecting these programs were written for CRT monitors, and didn't really have 2160p screens in mind. I know this monitor supports 4096x2160@60Hz (it currently warns me I'm not in the correct native resolution whenever I switch back to 3840x2160). \nIf I have both a 59.94 and a 30Hz modeline specified, I can get it to display 4096x2160 @ 30Hz, but not the higher 60Hz mode. \nIt probably doesn't matter, but I should add I'm using an AMD/ATi R7800 via mini-displayport (DP1.2) and the open source radeon kernel drivers.\nHow do I determine the correct modeline for this particular monitor? \n\nA: I just wanted to drop a line, and say that in Arch Linux on the new 4-7.1 kernel the 4096x2160 59Hz is showing up by default in the Display manager. It is working great so far. I spent a great  of time deal trying to get this monitor to work in the native resolution of 4096x2160, even with the xrandr settings being set manually it was not working. Someone should try Ubuntu with the upstream Kernel and see if it corrects the problem in Ubuntu also. \n\nA: So I discovered a forum post that documented the correct modelines. The closed source/binary AMD drivers property pull this information from the monitor, but the open source drivers do not yet. \nI have documented the commands needed to set the correct mode in the following blog post:\nhttp://penguindreams.org/blog/running-a-lg31mu97-on-linux-at-4096x2160-at-60hz/\nFor the impatient: \nxrandr --newmode \"4096x2160_60\" 556.730  4096 4104 4136 4176  2160 2208 2216 2222 +hsync +vsync\nxrandr --addmode DisplayPort-1 4096x2160_60\nxrandr -s \"4096x2160_60\"\n\n", "Q: Can't rotate screens I have a dual monitor setup and want to rotate one of the two screens, I looked up how to do it, but I get an error:\n{20:17}~ ➭ xrandr   \nScreen 0: minimum 8 x 8, current 3840 x 1080, maximum 16384 x 16384\neDP1 connected primary 1920x1080+0+0 345mm x 194mm\n   1920x1080      60.0*+   59.9  \n   1680x1050      60.0     59.9  \n   1600x1024      60.2  \n   1400x1050      60.0  \n   1280x1024      60.0  \n   1440x900       59.9  \n   1280x960       60.0  \n   1360x768       59.8     60.0  \n   1152x864       60.0  \n   1024x768       60.0  \n   800x600        60.3     56.2  \n   640x480        59.9  \nDP1 disconnected\nHDMI1 disconnected\nHDMI2 connected 1920x1080+1920+0 527mm x 296mm\n   1920x1080      60.0*+   50.0     59.9  \n   1920x1080i     60.1     50.0     60.0  \n   1600x1200      60.0  \n   1600x900       60.0  \n   1280x1024      75.0     60.0  \n   1152x864       75.0  \n   1280x720       60.0     50.0     59.9  \n   1024x768       75.1     60.0  \n   800x600        75.0     60.3  \n   720x576        50.0  \n   720x576i       50.1  \n   720x480        60.0     59.9  \n   720x480i       60.1     60.1  \n   640x480        75.0     60.0     59.9  \n   720x400        70.1  \nVIRTUAL1 disconnected\n{20:17}~ ➭ xrandr --output HDMI2 --rotate left\nxrandr: output HDMI2 cannot use rotation \"left\" reflection \"none\"\n\nSo why can't I rotate the HDMI2 output? I use Ubuntu 14.04 and I use the NVIDIA driver.\n\nA: The only way that I was able to rotate external monitor was by disabling nVida driver and enabling Intel driver in Nvidia's X Server Settings.\nNote: Remember to log out after enabling Intel driver.\n\n", "Q: Span Wallpaper Fails When Monitors Different Sizes When using unity's own \"span\" or the nitrogen tool to get a wallpaper to spread across two monitors I get the following effect.\n\nIs there a way to fix this? I tried using both a 4k and an 8k image and had the exact same result.\nThe resolution of my displays are 1920 x 1080 and 1024 x 768.\n\nA: I've done this on Windows 7, but my monitors both had a height of 900px, so that made it easier.\nWhat you need to do is create a new image that's 2944 x 1080, and expand your picture to fill the entire canvas. Then set it as background using the \"span\" mode.\nYou hit the nail straight-on in your comment. The image needs to be the width of the two screens combined and the height of the largest screen.\n", "Q: Ubuntu Studio low latency kernel I've installed Ubuntu Studio 14.04 on my computer and I thought that the installation would also give me a low latency kernel too, but when I click 'extra audio production application' it says that I can install the complete low latency kernel. My question is, is part of the kernel already installed or do I need to download it and then install it? Sorry if this may seem a noobish question.\n\nA: I can't answer your question exactly, but I'll try.\nAccording to this:\nhttps://help.ubuntu.com/community/UbuntuStudioPreparation\n\"ubuntu\" users can opt to install lowlatency kernel manually OR install the ubuntustudio package.  (Wich is not to install \"ubuntu studio\" flavour, wich is your case)\nI've been using Ubuntu studio since release 9.04 when it came with a realtime kernel.  I used 10.10 for many years and I had to manually install rt-kernel for it, and realtime was excellent for multitrack recording with audio.  Later on I used 12.04 live, wich came with a normal kernel, but some delay was noticeable for multitrack recording.\nThis year I choosed to upgrade to 16.04 LTS, but I preferred to install Ubuntu 16.04 and install \"ubuntu studio\" as a package over \"ubuntu\" (because ubuntu 16.04 is a 5 year support release, and ubuntu studio 16.04 is a only 3 years support release)\nInstalling ubuntu studio as a package did not install lowlatency kernel (and I found your question looking for information on that).\nIf you wanna check if you have a lowlatency kernel I suggest you to run synaptic (package manager) and search there for lowlatency to see if it's installed.  (I don't know the command for the kernel to inform it's version, sorry)  You can install Synaptic from \"Ubuntu Software\" application, and I recommend it for installing specific packages.  (Ubuntu used to came with Synaptic instead of \"ubuntu software\").\nIf lowlatency is not installed, you can install it from Synaptic, or run these two commands:\n\nsudo apt-get update\n\n(this will update the repositories with latest packages available for your 16.04 release)\nAND:\n\nsudo apt-get install linux-lowlatency linux-headers-lowlatency\n\nYou should install those 2 packages together.\nI think that in grub bootloader you'll have options to choose the kernel for each boot.  (lowlatency or normal)\nWell, that's all I can tell about this.\n", "Q: Can't cd into etc/profile, \"not a directory\" I am new to Ubuntu (or any Linux distro) and I encountered a problem where I cannot cd into etc/profile. I was trying to edit the bashrc so that I could change the colours in my terminal window.\nI tried to ls inside the /etc/ file, and I see that there is a profile file there; but I can't enter it.\n\nA: The reason why this fails is because /etc/profile is not a directory (unless you meant /etc/profile.d, but I don't think you did)\nInstead use gedit ~/.profile\nIf you want to edit .bashrc: gedit .bashrc\n\nA: By default /etc/profile is not a folder but a file so you can't cd into it.\nThe global bashrc file is /etc/bash.bashrc\n", "Q: Krusader will not open gzip archives Krusader will not open gzip archives. Krusader claims it will \"transparently handle\" gzip, zip and some other archives. I tested a zip archive and Krusader does open the archive and shows the contents; I can browse the zip archive. However, when I try to do the same with a gzip archive, I get a pop up window inviting me the select which program to use to open the archive. It will not open the gzip archive even though it claims that it can and will.\nDoes anybody know why? I see the Krusader forum is closed due to spamming. Thanks for any help :)\nI created the test archive using gzip from the command line and then used the file command to check the file type.\n$ file  youtube-bowie-13-1-2016.txt.gz\nyoutube-bowie-13-1-2016.txt.gz: gzip compressed data, was \"youtube-bowie-13-1-2016.txt\", last modified: Thu Jan 14 12:19:15 2016, from Unix\n\n\n\nAbout my system:\nUbuntu version: 15.04\nKrusader version: 2.4.0-beta3\n\nA: Although you question deals with an EOL Ubuntu release I have found that the same issue exists on Trusty Tahr. A partial fix is simple:\n\n\n*\n\n*Right click on the archive from within the Krusader winder\n\n*Select: Other\n\n*Select 'Browse'\n\n*Navigate to /usr/bin/file-roller and select this\n\n*Ensure you have selected the 'Remember Application...' button\n\n*Click OK\n\n\nA screenshot below to illustrate the crucial settings:\n\nYou will still not see the gzip file in the Krusader window (the 'Transparent' handling) but you will see it in File Roller. Annoyingly looks like that bug was actually closed as fixed in this version:\n\n\n*\n\n*Bug 306683 - gzip protocol not supported by krusader\n\nA: I encountered similar problem with zip archives - despite \"zip\" options checked in \"Archives\" configuration tab and zip/unzip programs recognized automatically and available in $PATH, zip archives were not handled by Krusader but opened in external program. \nThe solution was to add MIME type \"application/zip\" to \"krarc\" protocol in \"Protocols\" configuration tab. This entry should be present but mysteriously disappeared.\n", "Q: How do I install Ubuntu on an ASUS C100P Chromebook The download file will not open because it's not supported. How do I open the ubuntu desktop file and install it?\n\nA: First, activate developer mode for your Chromebook.\nNext, check and see whether your laptop model is supported by John Lewis' Seabios payload, which will allow you to boot an Ubuntu live USB after you run his script and choose one of the three options provided.\nIf you are able to run his script to rewrite the stock Chromebook BIOS, you will then be able to boot into the live USB drive and run the Ubuntu installer like you would from a DVD. Do note that these instructions carry the risk of bricking your device, but if you want to run Ubuntu on Chromebooks without further stability issues, you will want to explore this option.\n\nA: You need to burn the ISO to a DVD, and then boot the computer from that DVD. (Normally a computer boots from the hard disk) If you're using Windows, you can burn the ISO with the included tool.\nSee: http://windows.microsoft.com/en-us/windows7/burn-a-cd-or-dvd-from-an-iso-file\n", "Q: Bitlocker-encrypted Windows and LUKS-encypted Xubuntu in Dual Boot Company policies instruct me to use a Bitlocker encrypted Windows 10 (No turning off Secure Boot), but I also use Linux, which has to be LUKS encrypted. Now I need to set this system up for Dual-Boot on my Thinkpad W550s.\nThe encryption key for Windows is stored on the TPM, Secure Boot and UEFI Boot has to be enabled. I have planned to store Windows 10 on SDB (SSD, 250GB) and Ubuntu on SDA (HDD, 500GB, actually 250GB since I want to use the other half as common unencrypted data partition for not-security-relevant data).\nThat's my situation. I have tried installing Windows 10, leave it unencrypted and install Ubuntu, encrypted, but unfortunately GRUB2 completely messes up and doesn't boot Windows anymore. So I couldnt even get to the point where I encrypt Windows.\n\n/EndEntire file path: /ACPI(a0341d0,0)/PCI(2,1f)/UnknownMessaging(12) /HD(2,c8800,96000,fe030bf1430a6047,9a,9a)/File(\\EFI\\Microsoft\\Boot) /File(bkpbootmgfw.efi)/EndEntire error: cannot load image.\n\nor\n\n/EndEntire file path: /ACPI(a0341d0,0)/PCI(2,1f)/UnknownMessaging(12) /HD(2,c8800,96000,fe030bf1430a6046,9a,9a)/File(\\EFI\\Boot) /File(bkpbootx64.efi)/EndEntire error: cannot load image.\n\nChanging the boot order is pretty much not an option since it has to be locked, which would require me to go into the BIOS, disable the lock, change bootorder and enable the lock again.\nHas anybody been in the same super-annoying situation and found a solution? :)\nThanks in advance guys!\nTL;DR:\nSDB: LUKS-Ubuntu, 50% of SDA: Bitlocker-Windows (Key on TPM), 50% of SDA: Common Data Storage, Secure-Boot & EFI has to be enabled, No changing boot order in BIOS, Thinkpad W550s, Help?\n\nA: Put Windows on sda and only install grub2 on sdb where you'll have Linux. \nLeave the 250GB data partition unsecured. Doesn't sound like a problem\n", "Q: 14.04 Login incorrect ('Retry' placeholder in password field) it happened to my system after hard shutdown.\nNow on login screen I see placeholder 'Retry' in the password field, I can't type anything.\nLogin screen snapshot:\n\nThen I decided to watch what terminal says (ctrl+alt+f1):\nterminal snapshot:\n\nProper login doesn't work at all. Always get \"login incorrect\".\nWhat is that? Some broken auth package?\n\nA: The problem was a broken package, repaired it through recovery mode -> repair broken packages.\n", "Q: Unity hates my super key I have a bone stock XPS13, ubuntu 14.04\nI cannot figure out why my super key refuses to open dash.\nAlt works for shortcuts, super + w works for 'expose' and i used a keyboard tester to ensure all my buttons work.\n\n\n*\n\n*I tried to set the 'search' keyboard shortcut in Ubuntu Settings,\nhowever it keeps reverting to 'disabled'\n\n*I downloaded ccsm, I tried to set it from there however it keeps\nclearing to nothing.\n\n*I downloaded unity tweak tool, and tried to set the dash shortcut,\nhowever it keeps reverting to blank.\n\n*I used ccsm to reset unity's settings, however this changed nothing.\n\n\nI was able to map the 'show keyboard shortcuts' to z. However, this doesn't pull up the window, it only puts numbers on my docked applications. I cannot use z + num or super + num to get the docked apps to launch. Almost all, custom unity shortcuts based off of super dont work (except super + w oddly) I dug around dconf, I tried erasing my dotfiles in ~/ to no avail.\nI feel I am at my last wits before wiping my computer and installing and compiling the Dell fixes for skylake manually. Does anyone know anything else I can try? Most other people had their problems solved by answered questions on this site and on various forums however none worked for me, in fact, my use case is slightly unique in that it keeps self disabling the key mapping once it's set.\nUpdate\nI found this question, where they suggest uninstalling the dell-super-key package. This is for the Dell Precision however.\nmikey@mikey-XPS:~$ sudo dpkg -S dell-super-key\n[sudo] password for mikey: \ndell-super-key: /usr/share/doc/dell-super-key/changelog.gz\ndell-super-key: /usr/share/doc/dell-super-key/copyright\ndell-super-key: /usr/share/glib-2.0/schemas/41_dell-super-key.gschema.override\ndell-super-key: /usr/share/doc/dell-super-key\n\nI do have it installed, I'm open to removing it if I can easily reinstall it. It doesn't have any man pages included so I have to find a way to determine if this is causing it to be disabled.\n\nA: It appears the package dell-super-key is the culprit.\nI presume there is a hotkey combination to disable the super key on Windows and Dell wrote a shim to extend this functionality to the dev edition.\nI however, cannot find any key combination that I could've pressed to clear the lock.\nEDIT:\nOddly enough this is intended behavior.\nmikey@mikey-XPS:~$ apt-cache search dell-super-key\ndell-super-key - Disables the super key by default.\n\nI found (dpkg -l) and emailed the package maintainer, Dell is legally required to include this package on their sputnik devices. It is safe to remove, and can be reinstalled from the recovery partition.\n", "Q: firefox's profile is inaccessible after system reinstallation I reinstalled the system on the same partition, (home is on a different device) the version is the 14.04 LTS, unfortunately the Firefox profile is not loaded. How I can fix it?\n\nA: Disclaimer: not sure this will work. It might overwrite the current profile. Best to make a backup of the old profile before attempting.\n\n\n*\n\n*Run firefox -P\n\n*Click \"Create profile\". Follow the instructions.\n\n*When you get the option, click \"choose folder\" and select the location of the old profile. Finish the creation of the new profile.\n\n*Once you're back at the \"Choose user profile\" menu, select the one you just created and make sure \"Use the selected profile without asking at startup\" is selected, then click \"Start Firefox\".\n\n", "Q: Dualboot (Ubuntu 15.10, Win 10) hibernating issue (Ubuntu->hibernate->win->Ubuntu) I recently decided to dualboot my Win 10 Laptop (Legacy BIOS).\nAt first i used Linux Mint however i changed to Ubuntu 15.04 (and upgraded to 15.10 afterwards) because of several issues, Ubuntu solved all of them.\nFast boot in Windows is disabled.\nToday I decided to try out hibernating. Here is what works:\n\n\n*\n\n*Hibernating Win 10, using Ubuntu, reboot/hibernate that and get back into Win 10\n\n*Hibernating Ubuntu and rebooting into Ubuntu or Win 10(hibernated or not)\n\n\nWhat doesn't work however is hibernating Ubuntu, booting into Win 10, hibernating and then trying to get back into Ubuntu.\nWhat happens is that it displays 'ACPI more than one lid device found' and does some fsck-magic on the inodes (/dev/sda6, ext6, Ubuntu's partition), afterwards I get a black screen. REISUB doesn't help (except the reboot part, sometimes), neither does CTRL+ALT+F1.\nAfter creating the file following this guide: https://help.ubuntu.com/stable/ubuntu-help/power-hibernate.html instead of a black screen I got to the login screen. One time i could login, open console and everything froze, the other time it froze right after i could see the login screen. And again, nothing helped(REISUB, CTRL+ALT+F1).\nI figured that this particular thing just does not work in my case so I just had to be careful to always reboot into Ubuntu after hibernating it.\nSo then I wanted to reinstall grub-customizer and configure Ubuntu as first in grub. Then shit started to go down: while installing I got several errors that the directories are write-protected etc. so I rebooted. Fsck again, but it failed and i had to do a manual fsck on /dev/sda6, reboot again, fsck doing some stuff on the inodes as described before, luckily i got back into Ubuntu just fine (thank you fsck) and my filesystem seems to work normal again.\nWhile i could go fine with being careful not to boot into Windows after hibernating Ubuntu, this does pose a certain risk. I also have no clue as to why this happens, Windows shouldn't mess with an ext6 partition afaik.\nDoes anybody have an idea why this happens, or how to solve it?\nIf you need any additional information, I'll be happy to provide it.\n\nA: Perhaps also, rather than dual booting, you could install a base hypervisor, and thus have multiple VMs able to enter and exit a suspended state without issue, as it is effectively the hypervisor dealing with each & thus just removing the problem entirely.\n", "Q: Power management dies after suspend in Kubuntu 15.10 Ever since I upgraded to Kubuntu 15.10 from 14.10 power management dies after waking up from suspend (to disk or ram). The only thing that still works is dim display but it won't even un-dim. Screen does not turn off, system doesn't go to sleep on timer or anything. I can get it back by logging out and in again but that makes suspend rather pointless. Unfortunately just restarting upowerd isn't the solution. But what is?\nThis all used to work just fine in Kubuntu 14.10. System is Lenovo Thinkpad X201.\n\nA: As it sometimes happens, taking the time to formulate a question in writing can give one ideas. It came to me I might take a look at what powertop says when power management doesn't work and it does show (after sleep) that power saving is off for wifi (probably not significant) and also that USB auto-suspend is off for the 3G modem so it's active 100% of the time. So just doing what powertop proposes after sleep is one part of it. Although I have never done this for systemd before (i.e. run my own script after suspend), I just have a script for it so far.\nThe other part of this issue seems to have do with the way KDE power management works these days: it basically disables power management when it thinks some app is busy. At least that's shown in the battery applet but usually that means it thinks Chromium is busy. So sometimes killing Chromium is needed as well.\n", "Q: Is Snappy Core available for Raspberry Pi 3/4? If it's available, I can't seem to find it on the site. If it's not, can someone please link me to as much information as possible so that I can track progress on developments? Thanks.\n\nA: The rpi3 image will be available very shortly (once the Ubuntu core series 16 images are beeing released).\nTo keep posted on such announcement, best is to sign up for the snappy mailing list https://developer.ubuntu.com/en/snappy/support/ this is where you will hear the latest on the topic and / or find people to collaborate with on the topic. \n\nA: Canonical has released official Ubuntu Core images for Raspberry Pi.\n\n\n*\n\n*Ubuntu Core 16 is based on Ubuntu 16.04, and is supported for 5 years. \n\n*Ubuntu Core 18 for Raspberry Pi 2/3/4 is based on Ubuntu 18.04, and is supported for 10 years.\nA new release of Ubuntu Core is released every 2 years on even numbered years (2016, 2018, etc.).\nThe installation instructions from Raspberry Pi | Ubuntu developer portal are as follows.\n\nStart by downloading the Ubuntu Core 16 image for Raspberry Pi 3 to your ~/Downloads folder.\nInsert your SD card, unmount it and run:\nxzcat ~/Downloads/ubuntu-core-16-pi3.img.xz | sudo dd of=/dev/sdX bs=32M\nsync\nNote: replace /dev/sdX with the device name of your SD card (e.g. /dev/mmcblk0, /dev/sdg1 ...)\nEject the SD card physically from your PC, and insert the SD card in your Raspberry Pi.\nNotes\n  \n  \n*\n  \n*If your SD card is mounted when you insert it into your computer (you will know it if the file manager automatically opens a window showing the card's contents), you must manually unmount it before writing the Ubuntu Core image to it. Either eject your SD card from the file manager, or from the command line: sudo umount /media/$USER/*  \n  \n*You must specify the path to the disk device representing your SD card in the dd command above. Common device paths for the SD card disk device are either of the form /dev/sdX (such as /dev/sdb, not /dev/sdb1!) or /dev/mmcblk0 (not /dev/mmcblk0p1!)  \n  \n*Ensure there is no data you care about on the SD card before running the dd command above. \n  \n  \n  Prerequisites for booting Ubuntu Core\nAn Ubuntu SSO account is required to setup the first user on the board.\n  \n  \n*\n  \n*Start by creating an Ubuntu SSO account.  \n  \n*Import an SSH Key into your Ubuntu SSO account on this page.  \n  \n*Instructions to generate an SSH Key can be found here.  \n  \n*You will need a keyboard, monitor or a serial cable plugged into the board to be able to go through the first boot process and complete device.   \n  \n\n\nA: core 16 is almost finished; see: http://cdimage.ubuntu.com/ubuntu-core/xenial/daily-preinstalled/current/\n\nA: As of 2017 it's officially available at http://releases.ubuntu.com/ubuntu-core/16/\n", "Q: Which commands in terminal clean drive space no apt-get clean type commands work. won't download in Software Center nor update! not CCleaner Can you give EXACT terminal commands that work WITHOUT regurgitive mere basics that don't work such as Sudo Apt-get clean/autoclean. Is it Wily defect or what? I got Linux to be simple not to become a hacker for my own PC.\n\nA: The commands apt-get clean and autoclean are not primarily meant to free disk space. These commands are meant to work on the software packages that are installed on your computer.\n\n\n*\n\n*Now, if you want to know what did fill up your harddrive start with the command sudo df -m. This will tell you on which partition and in which directory the most disk space is used in MB. \n# sudo df -m\nS.Ficheros                    bloques de 1M Usados Disponibles Uso% Montado en\n/dev/dm-0                            366198  91120      275078  25% /\nudev                                     10      0          10   0% /dev\ntmpfs                                   766      9         757   2% /run\ntmpfs                                  1915      1        1915   1% /dev/shm\ntmpfs                                     5      1           5   1% /run/lock\ntmpfs                                  1915      0        1915   0% /sys/fs/cgroup\n/dev/sda1                               228     47         169  22% /boot\n/dev/mapper/laptop--user1-home        102350  13286       89065  13% /home\ntmpfs                                   383      1         383   1% /run/user/1000\n\n\n*Use the command sudo du -m --max-depth=2 within one Directory to find out which subdirectories have the biggest size in MB. This will take you to the Directory that filled up your hard disk.\nlike: sudo du -m --max-depth=2 /home.\nWhich will tell you which Directory of the User Account hold the most disk space in MB.\n# sudo du -m --max-depth=1 /home\n12425   /home/user1\n817     /home/user2\n13242   /home\n\nHere we see that 'user1' is using the most of the 13242 MB occupied on the /home partition\n\n*Once you have found out what did fill up your hard disk you will be able to decide best what is to do to free disk space. Like perhaps: Deleting user files or uninstalling software.\n", "Q: Cross Linux-Flavor Method - List all fonts I was trying to use x11, or file system, to get a list of all the installed fonts on the system. Is there a cross linux-flavor method to do this?\n\nA: You can run the fc-list command to list all the fonts the logged in user can use.\n", "Q: How to validate a user's password, with a shell script? I'm making a bash script for the Ubuntu Terminal. I need to verify the user before the code can continue. How do I ask and validate their existing log-in password?\n\nA: You can use Prompty. It will allow you to prompt the user for their password, and then you can use Prompty's exit code to determine if they entered the correct password or not. If they didn't then stop your script.\nInstallation:\n[Applies to Prompty 1.0]\n\n\n*\n\n*Download Prompty from one of the links posted at \"http://www.bleepingcomputer.com/forums/t/612007/prompty/\" to your Downloads folder.\n\n*Install Prompty and it's dependencies:\nsudo mkdir -p /opt/prompty\nsudo unzip \"$HOME/Downloads/Prompty 1.0 Stable.zip\" -d \"/opt/prompty\" \nsudo chown -R root \"/opt/prompty\"\nsudo chgrp -R root \"/opt/prompty\"\nsudo chmod -R u=rxX,g=rxX,o=rxX \"/opt/prompty\"\nsudo apt-get install sed grep coreutils bash\n\nUsage\n[Applies to Prompty 1.0]\n\n\n*\n\n*At the beginning of your script, execute Prompty.\nbash /opt/prompty/prompty-cli --task=\"1\" --useuserpassword=\"y\"\n\n\n*Check to see what the exit code was, and use that to determine if your script should terminate:\nif [ \"$?\" -ne \"254\" ] \nthen \n    exit 0\nfi\n\n\n*Add the rest of your script code.        \nSources\n\n\n*\n\n*\"About\" file from Prompty 1.0 Stable\n\n", "Q: A c program works well in Ubuntu but when I compile and run it in windows using MinGW, the program runs but in result it shows some garbage value I a wrote a C code in Ubuntu 14.04.4 LTS and compiled it. It is working as expected.But in windows it is running but at last in result it is showing some garbage values.\nThe code I wrote is\n#include <stdio.h>\n#include <stdlib.h>\nstruct poly{\n    int coe[100];\n    };\nvoid mul(struct poly *pr, int a, struct poly *p){\n    struct poly res;\n    int i;\n    for(i = 0; i < 100; i++){\n        res.coe[i] = 0;\n        int j;\n        for(j = 0; j <= i; j++){\n            res.coe[i] += ((*pr).coe[j])*((*(p + a)).coe[i - j]);\n        }\n    }\n    *pr = res;\n\n}\nvoid main(){\n    struct poly *p;\n    p = (struct poly *)malloc(100*sizeof(struct poly));\n    int n;\n    printf(\"no. of poly :\");\n    scanf(\"%d\", &n);\n    int i; int max = 0;\n    for(i = 0; i < n; i++){\n        int de;\n        printf(\"deg? of %d:\", i+1);\n        scanf(\"%d\", &de); max += de;\n        int j;\n        for(j = 0; j <= de; j++){\n            printf(\"co-eff of deg %d:\", j);\n            scanf(\"%d\", &p[i].coe[j]);\n        }\n    }\n    struct poly res;\n    struct poly *pr;\n    res = p[0];\n    pr = &res;\n    int fi;\n    for(fi = 1; fi < n; fi++){\n        mul(&res, fi, p);\n    }\n    for(i = 0; i < (max + 1); i++){\n        printf(\"%d\\n\", res.coe[i]);\n    }\n}\n\nand the result in windows is\nC:\\Users\\Sai\\Documents\\C++>gcc ac.c -o ac\n\nC:\\Users\\Sai\\Documents\\C++>ac\nno. of poly :3\ndeg? of 1:2\nco-eff of deg 0:1\nco-eff of deg 1:1\nco-eff of deg 2:1\ndeg? of 2:2\nco-eff of deg 0:1\nco-eff of deg 1:1\nco-eff of deg 2:1\ndeg? of 3:2\nco-eff of deg 0:1\nco-eff of deg 1:1\nco-eff of deg 2:1\n1\n3\n6\n85067032\n255201082\n510403447\n-1897503563\n\nC:\\Users\\Sai\\Documents\\C++>\n\nthe result in ubuntu is\nsai@sai-Inspiron-7548:~$ gcc ac.c -o ac\nsai@sai-Inspiron-7548:~$ ./ac\nno. of poly :3\ndeg? of 1:2\nco-eff of deg 0:1\nco-eff of deg 1:1\nco-eff of deg 2:1\ndeg? of 2:2\nco-eff of deg 0:1\nco-eff of deg 1:1\nco-eff of deg 2:1\ndeg? of 3:2\nco-eff of deg 0:1\nco-eff of deg 1:1\nco-eff of deg 2:1\n1\n3\n6\n7\n6\n3\n1\nsai@sai-Inspiron-7548:~$ \n\nHow to make this program run correctly in windows 10.\nIs something wrong in code that I wrote.\nThank you.\n\nA: While this should have been posted elsewhere, this is the solution:\nAlways initialize!\nYou are not initializing the coe[100] array of all the elements in your struct poly*.\nIn your loops you only set some of the entries, however your mul-function also accesses uninitialized ones.\nI assume that gcc on linux somehow takes care of that by intilializing them as 0 by default, however the standard defines the value of an uninitialized integer as undefined.\nMinGW does not intitialize it for you, so whatever is in the memory at that time messes up your results.\nEdit: Of course you should also free the allocated memory with free(p);!\nHere is how you can fix it:\n#include <stdio.h>\n#include <stdlib.h>\nstruct poly{\n    int coe[100];\n};\nvoid mul(struct poly *pr, int a, struct poly *p){\n    struct poly res;\n    int i;\n    for(i = 0; i < 100; i++){\n        res.coe[i] = 0;\n        int j;\n        for(j = 0; j <= i; j++){\n            res.coe[i] += ((*pr).coe[j])*((*(p + a)).coe[i - j]);\n        }\n    }\n    *pr = res;\n\n}\nvoid main(){\n    struct poly *p;\n    p = (struct poly *)malloc(100*sizeof(struct poly));\n    for(int k = 0; k < 100; k++)\n        for(int l = 0; l < 100; l++)\n            p[k].coe[l] = 0;\n    int n;\n    printf(\"no. of poly :\");\n    scanf(\"%d\", &n);\n    int i; int max = 0;\n    for(i = 0; i < n; i++){\n        int de;\n        printf(\"deg? of %d:\", i+1);\n        scanf(\"%d\", &de); max += de;\n        int j;\n        for(j = 0; j <= de; j++){\n            printf(\"co-eff of deg %d:\", j);\n            scanf(\"%d\", &p[i].coe[j]);\n        }\n    }\n    struct poly res;\n    struct poly *pr;\n    res = p[0];\n    pr = &res;\n    int fi;\n    for(fi = 1; fi < n; fi++){\n        mul(&res, fi, p);\n    }\n    for(i = 0; i < (max + 1); i++){\n        printf(\"%d\\n\", res.coe[i]);\n    }\n    free(p);\n}\n\n", "Q: Cannot find tcpprobe in ubuntu I want to use tcpprobe to record the state of a TCP connections but I cannot find tcpprobe in /proc/net. Is tcpprobe not present by default? \ntcpprobe\n\nA: You have to load the kernel module tcp_probe with the command: \nsudo modprobe tcp_probe\nIf you don't do this, the file doesn't exist. \n\nA: It is included. When you follow the referenced procedure the /proc/net/tcppdump gets created (checked Ubuntu 14.04.4 LTS, Ubuntu 15.10):\n$ ls -l /proc/net/tcppdump\nls: cannot access /proc/self/net/tcppdump: No such file or directory\n\n$ sudo modprobe tcp_probe port=5001\n$ ls -l /proc/net/tcpprobe\n-r-------- 1 root root 0 Apr 17 02:29 /proc/net/tcpprobe\n$\n\n\nA: If loading it with modprobe still does not work for you (as it didn't for me with Ubuntu 18.4.4 LTS using Kernel 5.3.0-59-generic), you should know that at some point, tcpprobe was removed from the kernel. Check out this answer.\n\ntcp_probe functionality has been removed from the kernel. I believe, but am not certain, that its removal and the associated removal of some of the required infrastructure got out of sync. I am saying that even though the module is still present for /lib/modules/4.15.0-55-generic/kernel/net/ipv4/tcp_probe.ko, it doesn't work.\n\n", "Q: How to delete a specific kernel? I have installed a wrong version of the kernel. I want delete it because it is also visible from the grub advanced option. \n\nA: Let's explain it by using an example ... boot with the kernel you want to keep, in this case kernel 4.2.0-35. \nTo check which kernel versions currently are installed, open a terminal and execute :  \ndpkg --get-selections | grep linux  \n\nThe output in this example shows that kernels 4.2.0-34 and 4.2.0-35 are currently installed.\nlinux-firmware                          install  \nlinux-generic                           install  \nlinux-headers-4.2.0-34                  install  \nlinux-headers-4.2.0-35                  install\nlinux-headers-4.2.0-34-generic          install\nlinux-headers-4.2.0-35-generic          install  \nlinux-headers-generic                   install  \nlinux-image-4.2.0-34-generic            install  \nlinux-image-4.2.0-35-generic            install\nlinux-image-extra-4.2.0-34-generic      install\nlinux-image-extra-4.2.0-35-generic      install  \nlinux-image-generic                     install  \nlinux-libc-dev:amd64                    install  \nlinux-signed-generic                    install  \nlinux-signed-image-4.2.0-34-generic     install  \nlinux-signed-image-4.2.0-35-generic     install\nlinux-signed-image-generic              install  \n\nAssuming that the older kernel 4.2.0-34 shall be removed - execute the following command :  \nsudo apt-get purge linux-headers-4.2.0-34 linux-headers-4.2.0-34-generic linux-image-4.2.0-34-generic linux-image-extra-4.2.0-34-generic linux-signed-image-4.2.0-34-generic\n\nDone! :-)\n", "Q: How can I delete all partion of my pen drive and create a single volume? I have 8GB pendrive. The current configuration of my pendrive in shown in image. It shows 6.9 GB as a free space, 2.3 MB as a FAT drive which is shown when i open it. \n\nI want to format drive but when I am going to format it, it shows an error message which is shown in Message.\n\"This partition cannot be modified because it contains a partition table; please reinitialize layout of the whole device. (udisks-error-quark, 11)\"\nI also tried to delete the volume and create a new volume but the message shows is\n\nPlease help me to delete all partion of my drive and create a single volume with 8 GB partion.\n\nA: Well my proposed solution might sound harsh and will definitively delete everything on that pen-drive so make sure you use the right path. I write my answer now on that setup seen on your screen-shots.\nOpen a terminal by pressing ctrl+alt+t.\nThen\n# like said make sure you use the right path to your stick !! \nsudo umount /dev/sdd1\nsudo dd if=/dev/zero of=/dev/sdd1 bs=4MB\n\nLet this run for a while (it will take a moment to write zero on 8 GB doing 4 MB steps).\nafter that nothing should be on that drive anymore and you should be able to start over fresh.\n\nA: This problem is caused  caused by a low-level device tools writing blocks at the wrong size directly onto the device.\nTo fix this, you will have to re-write the device blocks to the appropriate size. To do this open terminal(Ctrl+Alt+T) and enter the following command\nsudo dd if=/dev/zero of=/dev/sdX bs=2048 && sync\n\nRember to replace sdX  with the actual device for your flash drive.\nAfter doing this you can create a new partition using gparted or by terminal  using\nTo format as fat32\nsudo mkfs.vfat /dev/sdX1\n\nTo format ad ntfs\nsudo mkfs.ntfs /dev/sdX1\n\nTo format as EXT4\nsudo mkfs.ext4 /dev/sdX1\n\n\nA: STEP 1: install GParted Partition Editor.\nsudo apt-get install gparted \n\nSTEP 2: open gparted and insert pendrive. Then click on Gparted > devices and select your device.\nSTEP 3: delete all partitions and submit.\n", "Q: Upgrade to 16.04 LTS from ubuntu server 14.04 LTS with ubuntu-zfs I have a storage server running Ubuntu Server 14.04 LTS. I have ubuntu-zfs installed on it and I already use ZFS as my files system for the stored data.\nI am trying to look into what issues i might have trying to upgrade from 14.04 to 16.04. Here are some of my worries:\n\n\n*\n\n*Will the upgrade convert the ubuntu-zfs setup in 14.04 to the native ZFS in 16.04? I'm thinking that the safest way would be to export the pools uninstall ubuntu-zfs upgrade to 16.04 and then re-import the pools, but i would rather not go through the trouble if i don't have to.\n\n*Will there be issues importing pools created with ubuntu-zfs in 16.04 with native ZFS?\nThanks\n\nA: I found the upgrade straightforward(ish) in my case of non-root ZFS, just needing to remove old tools before adding new ones and nothing was left in a weird state:\n# Export ZFS Pool first - may need to switch to single user mode for this\nzfs umount -a; zpool export <poolname>\n# Remove old ZFS stuff\napt-get remove ubuntu-zfs zfs-doc spl-dkms\napt-get autoremove\nadd-apt-repository --remove ppa:zfs-native/stable\n\n# upgrade time!\ndo-release-upgrade\n\napt install zfsutils-linux\n\n#reboot\n\n...and on reboot my zpools / zfs file systems all imported and mounted OK\n\nA: FWIW, I have the same dilemma - although I'll probably wait until 16.04.1 before I take the jump.\nFrom what I can see, Xenial simply includes native replacement libraries for the zfs-linux stuff, e.g. ZFS on Linux lists 0.6.5.6-1~trusty (et al); native 'buntu has 0.6.5.6-0ubuntu8.\nSo, I'm assuming that it could be viewed as a change in PPA as much as anything, with kernel support meaning no dkms rebuilding. But...\n\nA: I was using zfs-fuse in 15.10 and updated to 16.04. As a backup measure I kept zfs snapshots. After reboot zfs-dkms was installed and my pool and file systems were recognized and mounted.\nApart from the speed improvement I haven't noticed any change.\n\nA: I just updated from 14.04 to 16.04.1, and it definitely broke my ZFS, but not beyond repair. You'll need to make sure you uninstall all the old ubuntu-zfs and related packages (notably zfs-utils and zfs-doc) and THEN install zfsutils-linux from the 16.04 PPA defaults. It automatically imported my pools, and I'm back up and running again.\n\nA: When I upgraded from Ubuntu 14.04 to 16.04, I also lost all file systems nested in the root.\nI decided as follows:\nInstead of a package ubuntu-zfs and zfsutils, was installed the package zfsutils-linux (not from PPA):\naptitude install zfsutils-linux\napt-get install -f\nupdate-initramfs -c -k all\nsystemctl start zfs-mount.service\n\nAll file systems was mounted. After the reboot, everything is OK as well.\n\nA: A bit off topic - since I've upgraded from 15.10 to 16.04 - we have several 15.10 Ubuntu servers with large ZFS filesystems - the systems are installed with standard filesystems (EXT4 I think?) and ZFS has been serving as backup repository on the side as secondary filesystem.\nZFS was installed as per instructions here: https://wiki.ubuntu.com/ZFS\nUpgrade procedure as we did succesfully:\n\n\n*\n\n*Normal apt-get update + apt-get upgrade + apt-get dist-upgrade + apt-get install update-manager-core + do-release-upgrade *As a result the ZFS was mounted and usable after the upgrade, but further action was needed\n\n*To remove unncessary kernel adds/modules: apt-get remove spl-dkms *This removes old ZFS related stuff\n\n*To further remove unncessary kernel adds/modules: apt-get autoremove *This also removes old ZFS related kernel stuff\n\n*Upgrade ZFS feature flags (not sure if this is needed?): zpool upgrade\n\n*Upgrade ZFS-POOL feature flags: zpool upgrade \"your-zfs-pool-name\"\n\n*Reboot (just in case)\n\n*DONE\n\n\nA: I did an upgrade last night and followed tschundler's instructions.\nI hit an error. When initially generating the initramfs and later on reboot, I got the error:\nVERIFY3(range_tree_space(rt) == space) failed (3959080 == 16216391680)\nPANIC at space_map.c:127:space_map_load()\n\nWhen I got in in recovery, I could manually import the zpool. From https://github.com/zfsonlinux/zfs/issues/3370, I suspected a problem with the cache. When I tried in single user, I could see a process hanging:\n/sbin/zpool import -c /etc/zfs/zpool.cache -aN\n\nWhat sorted it for me was going into recovery and removing /etc/zfs/zpool.cache Annoyingly, to do this is recovery, I had to remount / rw - the process of which meant Ubuntu ran all the startup scripts and the zpool process hung again!\nHowever, in the end, I (re)moved /etc/zfs/zpool.cache, rebooted and everything worked fine. Might file a bug against the zfsutils-linux package.\n", "Q: understanding the syntax for rtsp URL's By trial and error I was able to display the feed from an RTSP WiFi cam in VLC using the URL:\nrtsp://192.168.2.33:554?user=admin&password=&channel=2&stream=1.sdp\n\nHowever all the examples I find use something like:\nrtsp://192.168.2.33:554/user=admin&password=&channel=2&stream=1.sdp\n\nwith the / instead of the ?. The / does not work for me. VLC can not open the stream.  Does anyone know what the difference is?\n\nA: Question mark is used in URI as a separator of a path to the resource and query arguments. Per RFC 3986:\n    foo://example.com:8042/over/there?name=ferret#nose\n    \\_/   \\______________/\\_________/ \\_________/ \\__/\n     |           |            |            |        |\n  scheme     authority       path        query   fragment\n\nAnd in section 3.3:\n\nThe path is terminated by the first question mark (\"?\") or number sign (\"#\") character, or by the end of the URI.\n\nSo your first example is correct.\nThe second one (without ?) is wrong, because it combines query arguments into a path to the requested resource.\n\nAs a side note: browsers (at least current versions of Chrome or Firefox) will automatically change:\nhttp://192.168.2.33:554?user=admin&password=&channel=2&stream=1.sdp\n\ninto:\nhttp://192.168.2.33:554/?user=admin&password=&channel=2&stream=1.sdp\n\n\nA: Try \nrtsp://user:password@ip.of.your.device/\n\nThis should give you the first channel at least, after that it can be dependant on the device as to the syntax for the rest of it.\nrtsp://user:password@ip.of.your.device/cam/realmonitor?channel=1&subtype=1 \n\nworks for mine but your mileage may vary.\n", "Q: Gaming compatibility? My Dell Inspiron notebook 3542 has a i3 quad-core processor and Intel HD Graphics.\nBut, is Ubuntu gaming compatible? Or I need to install Windows?\nI am talking about games like Counter Strike, NFS Most Wanted, Dota, etc.\n\nA: Gaming in Linux is still behind, but so much better than a couple years ago (don't get me started on 15 years ago). \nThe drivers for Intel based cards are quite good on Linux, even though the card probably won't allow you gaming new games on high quality settings. \nThe best sources for commercial Linux games are in order of my personal preference:\n\n\n*\n\n*Steam (http://store.steampowered.com/search/?os=linux) \n\n*Humble bundle (store and bundles, some items are even drm free) (https://www.humblebundle.com/) \n\n*GOG.com (completely drm free) (https://www.gog.com/games?system=lin_mint,lin_ubuntu&sort=bestselling&page=1) \n\n\nIf you are interested in running Linux as a gamer, now is a great time to do it. But if all you want is gaming and you don't mind Windows 10 (not UI wise, but the privacy and store developments), you might be better off there. \nIf you own those games in Steam on Windows, just give Linux a try, all the games you currently own that are available in Linux (Dota 2 and csgo are among them), you can already play without buying them again. \nOn a personal note, I've been dual booting for over 15 years now, always keeping a Windows partition for gaming. Since the release of Windows 10 and the advancements of Steam I finally use Linux as my primary gaming system as well. \n", "Q: How to deactivate all the desktop effects of KDE permanently? I am aware that the shortcode of \"Shift + Alt + F12\" disables all the desktop effects of Kubuntu 15.10. However, is there a way to disable all those effects automatically and permanently in every future session?\nObjective: Speeding up Kubuntu 15.10 as much as possible.\n\nA: EDIT: this answer is for KDE 4 - not 5\nThis can be done from:\nSystem Settings > Workspace Appearance and Behaviour > Desktop Effects > General > Activation\n\nA screenshot to show the menu:\n\nAnd a lot of options in there to selectively block the effects so you don't miss out on all of the fun :)\n\nA: Head to \nSystem Settings > Hardware > Display and Monitor > Compositor\n\nRemove ✔ mark from Enable compositor on startup\n\nWhen this is done, make reboot.\n\nA: In openSUSE Leap 42.2 , to turn off desktop effect. click settings > configure desktop> scroll down to display and monitor> compositor...un-click enable compositor on start up.\n", "Q: How can I access my webcam data? Can I get access to my webcam data, like a real digital recording system?\n\nA: Install Cheese by clicking that link.\nThen, open Cheese from the Dash. You can record and view a live video stream of your webcam.\nP.S. You can also do this through VLC! Check https://askubuntu.com/a/614654/423626\n", "Q: Could not install platform-tools on Ubuntu 15.10 I am planning to install Android SDK for my Ubuntu 15.10. I downloaded the latest version of SDK, uncompressed and put it in folder /usr/local/android-sdk-linux with folders add-ons, platforms, tools. But I could not find Platform-tools. For install same I try Android SDK Manager using command:\n$ android\n\nAnd try to install Platform-tools only like below:\n\nI got the following error:\n\nAdvise me how I can install platform-tools to follow the post in\nHow to add android sdk in Ubuntu ..\n\nA: From IRC channel ubuntu I got solution. \nThanks , and  .. According to them download the sdk\non /home (~) and do the following stuff make the problem finished\nwget http://dl.google.com/android/android-sdk_r24.4.1-linux.tgz\ntar -xzf android-sdk_r24.4.1-linux.tgz\ncd android-sdk-linux && ./tools/android\nthen my android sdk manager not shown any error...\nAdvise: Don't put sdk library in any other path than home of a user..\nThanks\nAnes\n", "Q: How to install ubuntu-device-flash in Ubuntu 14.04? I m trying to install ubuntu-device-flash on Ubuntu 14.04 (64 bits). I'm following the instructions here: Prepare your Ubuntu desktop\nI do:\nsudo add-apt-repository ppa:ubuntu-sdk-team/ppa  \nsudo add-apt-repository ppa:phablet-team/tools  \nsudo apt-get update  \nsudo apt-get upgrade  \nsudo apt-get dist-upgrade  \n\n... and finally sudo apt-get install ubuntu-device-flash\ngives      \nReading state information... Done  \nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.  \nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:  \n ubuntu-device-flash : Depends: click-ubuntu-policy but it is not installable  \n                       Depends: ubuntu-snappy-cli but it is not installable\nE: Unable to correct problems, you have held broken packages.\n\nWhat has to be done for the installation to succeed?\n\nA: Add this ppa:\nsudo add-apt-repository ppa:snappy-dev/tools\n\nUpdate (thanks Joaquin):\nsudo apt-get update\n\nThen try the install again:\nsudo apt-get install ubuntu-device-flash\n\n", "Q: Can I install Ubuntu touch on any tablet? I have found this procedure for installing Ubuntu touch:\nhttp://www.pcadvisor.co.uk/how-to/linux/how-install-ubuntu-touch-image-3531970/\nI don't see any reason why it wouldn't work with any device.\n\n\n*\n\n*Is it risky? Does it work? If not, why?\n\n*Why is there no instruction on Ubuntu's website about how to install touch on a tablet?\n\n*And more generally, is it or not possible to install Ubuntu touch on any device? If not, will it ever be?\n\n\nA: \n\"Can I install Ubuntu touch on any tablet?\"\n\nNo\n\n\"I don't see any reason why it wouldn't work with any device.\"\n\nThere are a myriad of reasons, like different screens, chips, RAM etc, the same reasons you must have Android built for that specific device, not just any old Android rom.\n\n\"Is it risky? Does it work? If not, why?\"\n\nYes it is, there is the same risks as flashing anything, bootloop, brick etc... See answer above for the why.\n\n\"Why is there no instruction on Ubuntu's website about how to install\n  touch on a tablet?\"\n\nThere are\n\n\"And more generally, is it or not possible to install Ubuntu touch on\n  any device? If not, will it ever be?\"\n\nIt will never be possible to just install on any device, not all devices are created equally and compatibility is a big issue. More devices will get support in the future but never everything.\nAlthough, if you have exceptional programming skills, you could in theory port it to any device but it would be a lot of work.\nInfo on porting touch to your device and currently supported devices, plus 3rd party roms on XDA.\n", "Q: Open a PDF which is password protected One day ago, I downloaded a PDF that requires a password. Then I searched for software to decrypt the password that's called pdfcrack.\nThen I installed pdfcrack and ran a command in the Terminal:\npdfcrack -f encrypted.pdf\n\nMy doubt is when it completes in days or months or years\n\nA: It depends. It depends on your hardware, the strength of the encryption algorithm and the length of the password.\nAlso Ask Ubuntu is not the place for questions like these. You might want to try Crypto Stack Exchange.\n\nA: Unless you really have the rights to do it, better don't ask at all. \nAsk the issuer of the PDF for an unprotected version. And you better provide a good reason for that.\n", "Q: How to Assign an I.P. address to a Virtualbox Appliance? How do I configure a VirtualBox appliance to have its own I.P. address when running on a host Ubuntu machine?\nI've tried following the solution for this question but am not having any luck: Getting I.P address of Ubuntu Server running in Virtual Box\nThanks in advance.\n\nA: Configure your virtual machine adapter as Bridged Adapter.\nBoot into your Ubuntu VM and run following command to get your IP address.\nhostname -I\n\nNow you can use ssh to access your server with that IP address or open-up website from your browser if you're running any web server.\nIf you want to add local network to your server aswell, then add Network Adapter 2 as Internal Network\nEdit /etc/network/interfaces and add static adapter as eth1\nauto eth1\n    iface eth1 inet static\n    address 192.168.0.1\n    netmask 255.255.255.0\n    gateway 192.168.0.0\n\nWhen this is done, bring your adapter up.\nifup eth1\n\n", "Q: Cannot install ubuntu or Xubuntu. Screen hangs on splash screen. MSI Ghost Pro I am trying to install Linux onto my new MSI Ghost Pro GS60 6QE computer (I only found out today that MSI is notoriously unreliable with linux) and I am having a lot of trouble. For the whole day I tried to troubleshoot it but to no avail, my situation is this.\nI am trying to dual boot my computer with linux using the YUMI pendrive. To get the computer to even recognise the bootable drive I disabled Secure Boot, Fast Boot, Intel Virtualization Technology and Intel Speedstep and also changed \"Boot mode select\" to Legacy mode.\nWhen I actually run the Ubuntu installer it stalls on the splash screen, when I press escape it shows some process have been completed but seems to freeze on a random process (Eg. in one case it was \"Starting Cups ...\" and another time it was \"Starting WPA\"). This happened with all the distros I tried (Xubuntu 15.10, 15.4, 14.4 and Ubuntu 15.10 15.4).\nAs I am using Yumi and not in grub I don't have access to boot options using f6, all I could do was edit the executable and just replaced \"splash screen ---\" with \"nomodeset ---\" and it made no difference other then not loading the splash screen but still stalling on a random process.\nMy Specs are:\nProcessor: Intel Core i7-6700HQ CPU @ 2.60GHz 2.59 GHz\nMotherboard: Microstar International MS-16H7\nI hope someone has run into something similar and can help. If there is anyway to pinpoint the error could someone explain. \nThanks for taking the time, it's been a long day.\nL.\n\nA: Instead of YUMI, use Rufus. It's a lot faster and you'll be able to use UEFI.\nWhen you get to the installer GRUB menu, highlight the \"Try Ubuntu\" option and press E. Add nouveau.modeset=0 to the end of the line beginning with linux. Also set the nomodeset flag. Press F10 to boot.\nInstall Ubuntu and reboot. When presented with GRUB, follow the above procedure to boot into Ubuntu. Once booted, install the proprietary NVIDIA drivers by searching for the Additional Drivers app. Use that to select a proprietary driver, then hit Apply and reboot. You shouldn't need the flags again.\n\nA: I see you've found an answer; however, I want to point out some of the reasons you had problems, in the hopes of helping you and/or others avoid them in the future....\n\nI am trying to install Linux onto my new...\n\nBe aware that new hardware often requires the very newest OS version, or even not-yet-released software. With the release of Ubuntu 16.04 less than a week away, trying the latest pre-release version might have been worthwhile. (In the future, 16.10, 17.04, and later may be the pre-release versions worth trying, of course.)\n\nI am trying to dual boot my computer with linux using the YUMI pendrive.\n\nThe last I checked, YUMI was 100% useless for creating EFI-bootable disks. The vast majority of new computers boot Windows in EFI mode, and when dual-booting, it's important to install Ubuntu in the same boot mode (BIOS or EFI) as the original OS. Thus, YUMI is 100% useless for most new installations. Don't use it. Use Rufus, Unetbootin, dd, or something else instead.\nAlso, be aware that there are sometimes machine-specific quirks and interactions with the tools used to prepare boot disks, and sometimes with particular settings in these tools. Thus, you may need to try two or three programs, or play with the settings, before you find something that works.\n\nTo get the computer to even recognise the bootable drive I disabled Secure Boot, Fast Boot, Intel Virtualization Technology and Intel Speedstep and also changed \"Boot mode select\" to Legacy mode.\n\nSome of those changes (like disabling Fast Boot) are helpful. Disabling Secure Boot should not be necessary, and doing so increases your risk of contracting a pre-boot virus, so I recommend re-enabling Secure Boot. The biggest issue here was enabling BIOS/CSM/legacy support. This action enables booting in BIOS mode, which is the only way you'd be able to boot a YUMI-created disk, so it may seem like a helpful workaround; however, it greatly complicates the boot path and increases the odds of installing the OS in BIOS/CSM/legacy mode. In fact, with a YUMI-created disk, it more-or-less guarantees a cross-mode installation, which in turn will create new problems down the line -- problems that will be harder to overcome than the problem of booting the installer! Thus, enabling BIOS/CSM/legacy support, assuming you want to dual-boot with a pre-existing EFI-mode Windows, is almost certainly a big mistake. For more on this topic, see my Web page about it.\nOne more point: In addition to the EFI's \"fast boot\" option, there's an option in Windows called Fast Startup, and another called Hibernate. These MUST both be disabled if you're to safely dual-boot. See here and here for information on doing so. Failing to do this can lead to filesystem corruption and occasionally to damage to boot loaders, and thus to strange boot problems.\n", "Q: Should I upgrade to 16.04LTS from 15.10? I am currently running Ubuntu 15.10 and I am considering upgrading to 16.04LTS when it is released.\nI have lots of stuff on 15.10 that I don't want to lose, so I would prefer not to do a clean install of 16.04.\nIf I upgraded to 16.04 (when it is released), would there any issues (such as stability)?\nThanks guys and sorry for the noobie question. \n\nA: With an upgrade, there is always risk. You could upgrade and have your computer blow up, or be left with an unbootable installation. Your desktop environment may not work, your files may be gone, graphics may be broken, programs may not open, etc.\nWith that said, the chance of something like the above going wrong is rather low, if 15.10 was a fresh install, and you haven't modified any system files. With every upgrade and every modified system file, the risk that comes with an update increases. However, unless you've been upgrading since Ubuntu 12.04, you should be fine.\nIt's always better to back up and do a fresh install. You should be fine doing an upgrade, but definitely back up your data beforehand.\n\nA: The official documentation states highly recommended to upgrade when 15:10 reaches end of life - by July 2016.\nFrom http://www.ubuntu.com/info/release-end-of-life:\n\nUbuntu release end of life\nWhen an Ubuntu release reaches its “end of life” it receives no\n  further maintenance updates, including critical security upgrades.\n  We highly recommend that you upgrade to a recent version of Ubuntu at this point.\n\n\nA: Since you are not running an LTS release, I would say yes to 16.04 if that was your only choice. However, Ubuntu is notorious for having problems for a bit of time after a new \"stable\" upgrade release. If you are doing a clean install, I would recommend 14.04.3. 16.04 is probably going to have a few problems within a few weeks/months after its release. If you can, downgrade to 14.04.3. Also, if you are using a certain ATI graphics card, 16.04 will be dropping support for it. (also, keep in mind that non-LTS releases have a very brief support period, so sticking with LTS releases would be good. 12.04 is an LTS release, and is still supported, while 15.04 is not an LTS release, and support was dropped for it a while back.)http://www.ubuntu.com/info/release-end-of-life <-- this is a recommended read.\n\nA: It depends on your hardware\nIf your hardware is too old and not supported by the device vendor anymore than please don't upgrade\n\nA: The word is not \"should\" instead is MUST since the support of 15.10 ends with the new release, so you must upgrade. \nRemember to always backup everything, if you have the patience is always better to do a clean install, but the guys at Canonical Ltd worked very hard to make sure you can do a release upgrade without affecting your current system, so anyway you should be fine. Worth to mention, if you are using whole disk encryption be EXTRA careful!\n", "Q: VPN in non-browser applications? I am at a boarding university with restricted internet access (most broad-band using sites (YT, other video sites, gaming content sites) are blocked). I can bypass the YT blockade easily in browsers using a VPN. \nIs this also possible for the general internet access? \nFor example, I cannot use/update skype, Steam or any other application using the Internet, because these applications cannot access the Internet.\nIn the network settings there is an option for proxy networks and then I could apply systemwide after entering the IPs and port ID. Is it as simple as that and I just need specific data (IP, port # etc.)? If yes, is there a source that gives these access data for free? \nbest, \nMo\n\nA: Most common usage of VPN is to tunnel entire internet connection on system on which it's set. I've no idea how you did it only for browser... Did you perhaps meant Tor Browser? It's a different network. There are some free VPN's, but for good one you will need to pay.\nYou can redirect entire connection with free Tor network, check \"TORtp\". Don't know how and if it will work on Ubuntu, seen it on \"Freepto\" OS and there's also similar solution on \"Tails\" OS. I've found however this topic for Ubuntu:\nHow to route all internet traffic through Tor (the onion router)?\n\nA: It is possible to route ALL traffic through a VPN. It will depend on the setup of both machines. \nYou will almost certainly need to pay for a good VPN, there are free options, but they usually have some catch, limited speed, strange software, time limits. Try this link http://www.thetop10bestvpn.com/best-free-vpn-service\nAlso be aware that some web sites will load pages inside their page to try an bypass filters. This is not a \"real\" VPN.\n", "Q: Would install LAMP conflict with python? I am currently using ubuntu 14.04.\nI have PyCharm installed and using django-oscar with mysql.\nI am wondering what I would install in order to get php working?\nI am used to windows installing wamp to get localhost working for php but I have no single clue what's the best way to do it in Ubuntu and I don't want to duplicate any installs.\nI have searched and found commands to install lamp which would get apache, php and mysql.  Would this actually conflict anything with django-oscar? Would there be a duplicate installation with mysql?\nSorry if this didn't make sense in a way.\nThanks in advance\n\nA: Python is not related to any of the lamp packages. So no, they shouldn't conflict with each other.\nP.S. If you do not need the full LAMP stack, you don't have to install all of its packages. For example, if you need to install just PHP Apache, you can do that by running\nsudo apt-get install php5\n\nIf you need both Apache and PHP, then you would run\nsudo apt-get install php5 apache2\n\n", "Q: Windows Ubuntu dual boot - Windows boot problem after updates My Windows - Ubuntu dual boot system was working perfect for up to 6 months. After Windows updates, Windows can't boot. I have tried several things but nothing seems to work. You can find a Boot Repair report about my system here\nIs there any way to get my Windows back?\nThanks.\n\nA: Boot into a windows RecoveryCD/Installation Disk, click on Repair, then click on Advance/Other options, select CMD Prompt as the recovery option, then run the following.\n\n\n*\n\n*bootrec.exe /fixboot\n\n*bootrec.exe /fixmbr\nOnce you have done so, restart your computer and it should boot into windows automatically.\nFrom there you will need to boot into your Ubuntu LiveCD and run boot-repair to repair grub back to it's normal state.\n", "Q: Endless \"Wait-for-state stop-waiting\" when shutdown Problem description\nWhen I shutdown my pc with: \n\n\n*\n\n*sudo shutdown -v now  \n\n*sudo reboot  \n\n*or a normal shutdown\n\n\nI'm getting an endless shutdown.\nBy pressing F1 or Esc I can get black console window with line\nWait-for-state stop/waiting\n\nWhen I press Ctrl-Alt-Delete some lines appear, but I can't see error there.\nCtrl+Alt+F1 enables a console, but I can't type there while shutting down. \n\nAdditional information\nProblem appeared after installation of Canon LBP6000 printer's driver. \nI used this instruction.\nAlso I done some neccesary things to make printer work: chmod 777 /dev/usb/lp0\n\nWhat I did to solve this problem (but still no luck)\nI completed suggestions from here.\nResult of this and my system information are here.\n\nA: Ran into the same problem with ubuntu 14.04 and canon printer drivers. Had to remove everything i installed. \nOnly after running one of these solved shutdown/restart problem:\nsudo apt-get purge libpopt0:i386\nsudo update-rc.d -f ccpd remove\n# commented out in /etc/ccpd.conf: section <Printer> completely and inside <Ports>\nsudo apt-get purge cups cups-daemon cups-server-common\nsudo apt-get purge portreserve\n\nI'm pretty sure that sudo update-rc.d -f ccpd remove is the fix, but i won't install canon drivers ever again :)\nPS: please note that removing ccpd from upstart job will not start printing stuff automatically.\n\nA: I encounter the wait-for-state/stop-waiting on shutdown of a 14.04 live CD session on a specific machine, Packard Bell PEW92, single core Celeron 64bit architecture.\nBelow you will find the readout.\nI do not install anything though I remove remote login service plus uninstall amazon regardless what machine I utilize.\nI toggle the same DVD with ubuntu 14.04 live CD ISO between a variety of machines.\nThe Packard Bell is the only machine where this happens.\nHowever, a full 14.04 install with all updates (from a while ago) on an 8GB Sandisk SSD salvaged from a Motorola mediabox does not feature this issue (same purge plus uninstall performed).\nMy conclusion is this issue is hardware specific, differs per case.\nOther then a purge of what triggers the event, this issue is not preventable since this event is triggered by software that doesn't function in full compatibility with the specific hardware utilized at the moment the event is triggered.\n*Stoppin rsync deamon rsync [ok]\n*speech-dispatcher disabled; edit /etc/default/speech-dispatcher\n*Asking all remaining processes to terminate... [ok]\n*All processes ended within 1 seconds... [ok]\nModemManager[1267]: <info> Caught signal, shutting down...\n\nModemManager[1267]: <info> ModemManager is shut down\n\n*Unmounting temporary filesystems... [ok]\n*Deactivating swap... [ok]\n*Stopping early crypto disks [ok]\n\nAfter a Ctrl+Alt+Del\n[[ 4967.912031] ata2.00: exception Emask 0x10 SAct 0x0 SErr 0x10000 action 0xe frozen\n\n[ 4967.912071] ata2.00: irq_stat 0x00400003, PHY RDY changed\n\n[ 4967.912095] ata2: SError: { PHYRdyChg }\n\n[ 4967.912121] ata2.00: cmd a0/00:00:00:08:00/00:00:00:00:00:/a0 tag 28 pio 16392 in\n\n[ 4967.912121]          Get event status notification 4a 01 00 00 10 00 00 00 08\n                        00res 50/00:03:00:08:00/00:00:00:00:00/a0 Emask 0x10 (ATA bus\n                        error)\n[ 4967.912222] ata2.00: status: { DRDY }\n\nAfter another Ctrl+Alt+Del\n* Starting Waiting for state [ok]\n* Starting Waiting for state [fail]\n\nstart: Job failed to start\n* Stopping Waiting for state [ok]\n* Asking all remaining processes to terminate... [ok]\n* All processes ended within 1 seconds... [ok]\n* Deactivating swap... [ok]\n* Stopping early crypto disks... [ok]\n\n", "Q: On Aquaris m10 Ubuntu edition, an external keyboard is missing many characters Weirded out owner of the first convergence device here.\nI bought a bluetooth keyboard and mouse the day the tablet showed up in the mail. The tablet is engineered to be used that way, right? Pairing, check, desktop mode, check. Open some webpage to see how everything works. \"Please enter email address and password\" (I must have been on facebook or something)... Epic fail: I can't type the character \"@\".\nOn a standard German layout, the \"@\" sign is reached with the combination of \"alt gr\" and \"Q\". There are plenty of characters that can only be reached through \"alt gr\": \"{ ,[ ,\\, ~, |\".\nSince then, I also found out that none of the dead keys work. To make a \"ê\", I'd type \"^\" then \"e\". Typing \"^\" doesn't do anything. Typing \"e\" afterwise does a regular \"e\". Same with every other accents and non-ascii characters that the non-anglosaxon world absolutely needs to communicate. I mean, I started writing an email in French to my mom and stopped after a while and finger-typed it on the screen, because the unaccented version didn't make any sense.\nI could spend a few hours remapping the keyboard, but the \"keyboards\" utility we've all been enjoying since the night of the age doesn't seem to exist in Ubuntu Touch, and has been replaced with a 3-options-menu.\nBefore you mention it, that 3-options menu doesn't let you pick a \"compose\" key. And, while we're at it, I did select the correct keyboard layout. All keys produce the expected character, except the dead keys and the ones that require \"alt gr\".\nThe keyboard itself is not at fault. I paired it with an android device, and it works as expected. I'm even typing with it right now! @ é è € {[]}\n\nA: Are you saying that the \"Germany\" keyboard layout is not available on the tablet's options? What type of keyboard does the tablet believe it's dealing with? \nTo activate the accented ASCII character combinations, you usually have to go into the system settings and tell it explicitly which \"compose\" key to use. That's the key that signals to the system that you're about to ask for a combo to be treated as a single alternative character. \nFor example, if you want to combine CTRL + \"^\" + \"e\" to get \"ê\" -- then your \"compose\" key is CTRL. You have to tell the system that one of the CTRL keys is the start of a combo. \nOn Macs, it's set up by default, but on most of the Linuxes I've set up recently, there's no compose key configured until you select one yourself. \nTo do this on desktop Ubuntu, there's a help file with instructions, here: https://help.ubuntu.com/community/ComposeKey\nI don't have the Aquaris tablet yet, so I can't give you explicit instructions on the tablet version, but I bet if you get your tablet into Desktop mode, you can apply those instructions to the tablet too.  \n\nA: Sounds like this bug, which is targetted to be fixed in the next over the air updated, OTA-12.\nhttps://bugs.launchpad.net/bugs/1565236\n", "Q: Can't install Upwork application on Ubuntu 15 with gksu I am not able to install Upwork 64 bit application on Ubuntu, reason I am asking this again as I followed the answer posted in another similar question but I could not get it working.\nI am having issues while installing gksu\nThe following packages have unmet dependencies:\nupwork: Depends: gksu but it is not installed\n        Depends: libgcc1 (>= 1:4.1.1) but 1:5.2.1-22ubuntu2 is installed\n        Depends: libnspr4 (>= 4.10.7-0) but 2:4.10.8-2ubuntu1 is installed\n        Depends: libstdc++6 (>= 4.6) but 5.2.1-22ubuntu2 is installed\n        Depends: libudev1 (>= 198) but 225-1ubuntu9 is installed\n        Depends: libx11-6 (>= 2:1.4.99.1) but 2:1.6.3-1ubuntu2 is installed\n        Depends: libxcomposite1 (>= 1:0.3-1) but 1:0.4.4-1 is installed\n        Depends: libxdamage1 (>= 1:1.1) but 1:1.1.4-2 is installed\n        Depends: libxi6 (>= 2:1.2.99.4) but 2:1.7.4-1 is installed\n\n\nA: You can try two way to solve this issue:\n\n\n*\n\n*Try to fix package dependencies automatically\n\n*Manually install packages needed by Upwork\nFirst Solution:\nRun the following command that should fix packages dependencies:\nsudo apt-get install -f\n\nMore information about this command can be read in the manual with this command:\nman apt-get\n\nSecond Solution:\nWatch at all packages that aren't installed and install them. In this case seems that you only need gksu package, while the other packages have all a greater version than the required and this is not a problem. To install gksu run this command:\nsudo apt-get install gksu\n\nNow you can try to install Upwork and shouldn't get any package dependencies error.\nI hope this could help you.\n", "Q: Unable to install NVIDIA GPU drivers on Xenial I have an ASUS K55VM and I've been trying to install NVDIA GPU drivers on my laptop, but am not sure what I am doing wrong. \nThese are the packages I've installed:\n$:/usr/sbin# dpkg --get-selections | grep -v deinstall | grep bumb\nbumblebee                       install\nbumblebee-nvidia                install\n\n$:/usr/sbin# dpkg --get-selections | grep -v deinstall | grep nvidia\nbumblebee-nvidia                install\nnvidia-304                      install\nnvidia-current                  install\nnvidia-opencl-icd-304           install\nnvidia-settings                 install\n\nThis is my graphic card configuration:\n$ inxi -G\nGraphics:  Card-1: Intel 3rd Gen Core processor Graphics Controller\n           Card-2: NVIDIA GF108M [GeForce GT 630M]\n           Display Server: X.org 1.18.3 drivers: vesa,intel (unloaded: fbdev)\n           tty size: 168x43 Advanced Data: N/A for root\n\nThis is the output of optirun:\n$:/usr/sbin# optirun -vvv glxgears\n[ 4340.857497] [DEBUG]Reading file: /etc/bumblebee/bumblebee.conf\n[ 4340.857876] [INFO]Configured driver: nvidia\n[ 4340.858090] [DEBUG]optirun version 3.2.1 starting...\n[ 4340.858118] [DEBUG]Active configuration:\n[ 4340.858123] [DEBUG] bumblebeed config file: /etc/bumblebee/bumblebee.conf\n[ 4340.858129] [DEBUG] X display: :8\n[ 4340.858133] [DEBUG] LD_LIBRARY_PATH: /usr/lib/nvidia-current:/usr/lib32/nvidia-current\n[ 4340.858139] [DEBUG] Socket path: /var/run/bumblebee.socket\n[ 4340.858143] [DEBUG] Accel/display bridge: auto\n[ 4340.858148] [DEBUG] VGL Compression: proxy\n[ 4340.858168] [DEBUG] VGLrun extra options: \n[ 4340.858183] [DEBUG] Primus LD Path: /usr/lib/x86_64-linux-gnu/primus:/usr/lib/i386-linux-gnu/primus\n[ 4340.858255] [DEBUG]Using auto-detected bridge primus\n[ 4340.864799] [INFO]Response: No - error: [XORG] (EE) \n\n[ 4340.864836] [ERROR]Cannot access secondary GPU - error: [XORG] (EE) \n\n[ 4340.864855] [DEBUG]Socket closed.\n[ 4340.864896] [ERROR]Aborting because fallback start is disabled.\n[ 4340.864908] [DEBUG]Killing all remaining processes.\n\nThe following are the relevant bumblebee configuration settings:\n...\nDriver=nvidia\n...\n[driver-nvidia]\n# Module name to load, defaults to Driver if empty or unset\nKernelDriver=nvidia_304\nPMMethod=auto\n# colon-separated path to the nvidia libraries\nLibraryPath=/usr/lib/nvidia-current:/usr/lib32/nvidia-current\n# comma-separated path of the directory containing nvidia_drv.so and the\n# default Xorg modules path\nXorgModulePath=/usr/lib/nvidia-current/xorg,/usr/lib/xorg/modules\nXorgConfFile=/etc/bumblebee/xorg.conf.nvidia\n\n## Section with nouveau driver specific options, only parsed if Driver=nouveau\n[driver-nouveau]\nKernelDriver=nvidia-current\nPMMethod=auto\nXorgConfFile=/etc/bumblebee/xorg.conf.nouveau\n\n\nA: You install wrong drivers. Remove the legacy driver and install the correct driver this way:\nsudo apt purge 'nvidia.*'\nsudo apt install nvidia-361 nvidia-prime\n\nReboot.\n", "Q: Wifi not working after resume I have problem my wifi doesnt work after resume.\nI already tried lot of solution over google.\nWhat currently I have:\ncat /etc/pm/sleep.d/wakenet.sh\n#!/bin/bash\ncase \"$1\" in\nthaw|resume)\nnmcli nm sleep false\npkill -f wpa_supplicant\n;;\n*)\n;;\nesac\nexit $?\n\ncat /etc/pm/config.d/config\nSUSPEND_MODULES=\"ath10k_pci\"\n\nError log after resume:\n ath10k_pci 0000:04:00.0: Refused to change power state, currently in D3\n[   52.941724] ath10k_pci 0000:04:00.0: failed to wake target for write32 of 0x00000000 at 0x00034400: -110\n[   52.952859] ath10k_pci 0000:04:00.0: failed to wake target for write32 of 0x00000000 at 0x00034404: -110\n[   52.963313] ath10k_pci 0000:04:00.0: failed to wake target for read32 at 0x00034410: -110\n[   52.973762] ath10k_pci 0000:04:00.0: failed to wake target for write32 of 0xffff0000 at 0x00034410: -110\n[   52.984213] ath10k_pci 0000:04:00.0: failed to wake target for read32 at 0x0003444c: -110\n[   52.994663] ath10k_pci 0000:04:00.0: failed to wake target for write32 of 0xffff0000 at 0x0003444c: -110\n[   53.005114] ath10k_pci 0000:04:00.0: failed to wake target for write32 of 0x00000000 at 0x00034408: -110\n[   53.015563] ath10k_pci 0000:04:00.0: failed to wake target for write32 of 0x00000000 at 0x0003440c: -110\n[   53.026037] ath10k_pci 0000:04:00.0: failed to wake target for read32 at 0x00034450: -110\n[   53.036495] ath10k_pci 0000:04:00.0: failed to wake target for write32 of 0xffff0000 at 0x00034450: -110\n[   54.332051] ath10k_pci 0000:04:00.0: pci irq legacy interrupts 0 irq_mode 0 reset_mode 0\n[   57.467798] ath10k_pci 0000:04:00.0: failed to read device register, device is gone\n[   57.467809] ath10k_pci 0000:04:00.0: failed to reset chip: -5\n[   57.478781] ath10k_pci: probe of 0000:04:00.0 failed with error -5\n\nuname -a\n\nLinux sahal 4.4.0-18-generic #34~14.04.1-Ubuntu SMP Thu Apr 7 18:31:54\n  UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nI really need help now . Thank you !\n\nA: I used Owais Lone's answer to a similar question to enable automatic resume of wifi after suspension for my laptop (a Dell Precision) on 16.04 LTS.\nLike Owais, I created /etc/pm/sleep.d/10_resume_wifi:\n#!/bin/sh\n\ncase \"${1}\" in\n    resume|thaw)\n      nmcli radio wifi off && nmcli radio wifi on;;\nesac\n\nfollowed by a sudo chmod +x /etc/pm/sleep.d/10_resume_wifi.\nIn case you're wondering about the double semicolons or the solitary close parenthesis like I was, see http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_03.html -- that's just how the case syntax works.\n\nA: I found a solution finally! Just make this script to remove the module before suspend and reload after.\nhttps://pastebin.com/93pAZC45\n", "Q: How can I hibernate a running application? Example use case: \nI run Chromium with a couple of tabs open and decide that I don't need to access the application for the next 20 minutes. In order to conserve laptop battery time, I would like to hibernate (freeze) Chromium without having to close the application (re-opening and re-loading all tabs requires time that I would like to save by hibernating it).\n\nA: To suspend, try:\nkillall -SIGTSTP chromium-browser\nIf this does not work, try the forceful version: killall -SIGSTOP chromium-browser.\nEither way, to continue use killall -SIGCONT chromium-browser. I tried with Firefox and it worked. Do note however, that if you click buttons in Chromium while it is suspended it will execute that stuff once you continue it's execution.\n\nA: You can use the killall command to send a SIGSTOP signal to all processes matching a given name to freeze them and later send SIGCONT the same way to thaw them again.\nFirst find out the process name using pgrep -l SEARCH_PATTERN:\n$ pgrep -l chrom\n13010 chromium-browse\n13036 chromium-browse\n13038 chromium-browse\n13153 chromium-browse\n13166 chromium-browse\n13169 chromium-browse\n13175 chromium-browse\n13187 chromium-browse\n13195 chromium-browse\n13206 chromium-browse\n\nNote that it will trim long names, therefore the r is missing. But this isn't a problem as you can use Tab completion to enter the process name which will complete it automatically.\nThen you send the SIGSTOP signal to all processes named chromium-browser like this:\n$ killall -s STOP chromium-browser \n\nThe Chromium window will grey out as if it became unresponsive. Well, it really became unresponsive, so that was to be expected. You can't interact with the window in any way now (except for the menu bar and minimizing etc. which is handled by the window manager and not the application itself). But the events from clicking buttons etc. are still generated and added to the application's event queue, so they will all be processed at once when you thaw the application again!\nYou thaw the application again by simply running this command that sends the SIGCONT signal to the specified processes:\n$ killall -s CONT chromium-browser \n\n\nSometimes freezing an application this way can cause it to crash, so make sure important stuff is saved before freezing an application. \nIn rare cases even the desktop environment/window manger/whatever else might become unresponsive as well. In this case you have to thaw the frozen application through a TTY:\nPress Ctrl+Alt+F1 to switch to TTY1. You will be asked to log in, so enter your username and password. Then run the command to thaw the application the same way you would run it through your normal terminal emulator. After that switch back to the desktop (TTY7) using Ctrl+Alt+F7 and you should be fine again.\n\nA: You can try the following (in a Terminal):\nps aux | grep gedit\n\nThen you'll see something like this:\nbarend    7166  5.3  1.0 722620 39044 ?        Sl   16:19   0:00 gedit\n\nWrite down the number 7166 (or whatever number it is) and then do:\nkill -STOP 7166\n\nThat will suspend execution of the process. It won't immediately free the memory used by it, but the memory will be available for other processes if they need it.\nThen do\nkill -CONT 7166 to work with the program again.\nNote that you have to change 7166 where appropriate.\n", "Q: Problems with Ubuntu desktop 14.04.4 download - 1.5GB RAM Having downloaded, a window appears. It's a Roxio registration which disappears and I'm left with three black dots - that's it, no more installation action. Help!\nps Is my \"weedy\"  1.5GB of RAM the issue here\npps Don't think I can burn to a DVD as the drive in my 900yo HP 530 Notebook is busted\nAny help/suggestions ratefully accepted\n\nA: You have downloaded an ISO file which needs to be burnt to a DVD. As your DVD drive is faulty Roxio is hanging.\nDownload the ISO file and burn the DVD on a friends PC.\n", "Q: Problem while trying to boot Ubuntu 14.04 So I try to boot up and install Ubuntu 14.04.4 from a DVD and I get this error:\n\nCan someone help?\n\nA: Your DVD (or DVD drive) is dirty or broken. Please clean it or replace it. Or use a different medium type to install Ubuntu (e. g. a USB thumb drive).\n\nA: Something or another is causing your computer to have trouble reading and/or using the DVD correctly. (could be a scratched DVD, a dirty/broken disc drive, or a corrupt ISO) Your best bet is to boot off of a medium that doesn't use your disc drive, i.e. a flash drive or SD card. If the problem persists, it is probably a corrupt ISO file.\n", "Q: How do I get the latest beta version of Juju? The Getting started for Juju tells you how to install the stable version of Juju using the stable PPA but I want to try the beta version: \nhttps://launchpad.net/juju-core/trunk/2.0-beta4\nWhat is the PPA configuration needed so I can install that version?\n\nA: Juju has documentation about Geting the Latest Juju version and provides specific information for installing the development branch which is currently version 2.0 Beta 4:\nsudo add-apt-repository ppa:juju/devel\nsudo apt-get update\nsudo apt-get install juju\njuju version\n2.0-beta4-trusty-amd64\n\n", "Q: file manager permission based on users on Ajenti I installed Ajenti-v on my Ubuntu server 15.10 and I want to create multiple users with specific access to their home directory.\nCurrently, whenever I create a new ajenti user (which is synced with OS Users), it can access to the whole file system.\nHow can I limit their access to a specific directory like /home/user?\nThere is an option within the Configure > Plugins section of the root user which will limit the access on all users's file managers, but it cannot be used for specifying directories for each users.\n\nA: I have finally found the solution here.\n", "Q: light and simple like Leafpad but with Highlight Misspell words and Spelling Suggestions like Gedit I am Linux beginner user.\nTell me please can I find anywhere online the \"core version\" (if I can say like that) of Gedit? The only two features I would still in it are \"Highlight Misspell words\" and \"Spelling Suggestions\", available only for English language.\nIf not Gedit, is there any other application which could meet my requests? Like for example LibreOffice, OpenOffice etc?\nI use an old computer and it counts to use a lightweight application Until now I used Leafpad, but I changed to Gedit for Highlight Misspell words. I use them to write only plain texts.\nIt would be great if it exists a simpler, version of Gedit, fast like Leafpad or even more faster, and with the above mentioned two options.\nThank you.\n\nA: LibreOffice Write would be massively too heavy for you I suspect but well worth a look is Abiword which has the features you are after:\n\n\n*\n\n*Relatively lightweight\n\n*Highlights bad spelling\n\n*Allows right click suggestions for spelling\n\n\nI would say that it is not as fast as Leafpad but the extra features do come at a price. Abiword is certainly fast enough on my ancient Latitude D520 laptop.\nInstall it as follows:\nsudo apt-get install abiword\n\nBelow is a screenshot demonstrating the features you were after in Abiword running on Trusty Tahr:\n\n", "Q: Ubuntu 14.04.4 LTS Enablement Stack has unmet mesa-dev dependencies I have just updated to the latest LTS Enablement Stack for Ubuntu 14.04.4 using the wiki.\nI am trying to install some dependencies for building plexhometheater and getting an error.\nAny ideas what the issue could be? Why are these libraries not provided by the installed libgl1-mesa-dev-lts-wily and libgles2-mesa-dev-lts-wily packages.\nsudo apt-get -s install libgl1-mesa-dev libgles2-mesa-dev\n...\n...\nThe following packages have unmet dependencies:\nlibgl1-mesa-dev : Depends: mesa-common-dev (= 10.3.0-0ubuntu2intel1)\nlibgles2-mesa-dev : Depends: libgles2-mesa (= 10.3.0-0ubuntu2intel1)\nE: Unable to correct problems, you have held broken packages.\n\n\ndpkg -l | grep mesa\nii  libegl1-mesa-dev-lts-wily:amd64           11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the EGL API -- development files\nii  libegl1-mesa-lts-wily:amd64               11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the EGL API -- runtime\nii  libgl1-mesa-dev-lts-wily:amd64            11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the OpenGL API -- GLX development files\nii  libgl1-mesa-dri-lts-wily:amd64            11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the OpenGL API -- DRI modules\nii  libgl1-mesa-glx-lts-wily:amd64            11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the OpenGL API -- GLX runtime\nii  libglapi-mesa-lts-wily:amd64              11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the GL API -- shared library\nii  libgles1-mesa-lts-wily:amd64              11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the OpenGL|ES 1.x API -- runtime\nii  libgles2-mesa-dev-lts-wily:amd64          11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the OpenGL|ES 2.x API -- development files\nii  libgles2-mesa-lts-wily:amd64              11.0.2-1ubuntu4~trusty1                       amd64        free implementation of the OpenGL|ES 2.x API -- runtime\nii  libglu1-mesa:amd64                        9.0.0-2                                       amd64        Mesa OpenGL utility library (GLU)\nii  libglu1-mesa-dev                          9.0.0-2                                       amd64        Mesa OpenGL utility library -- development files\nii  libmirclientplatform-mesa:amd64           0.1.8+14.04.20140411-0ubuntu1                 amd64        Display server for Ubuntu - client platform library for Mesa\nii  libwayland-egl1-mesa-lts-wily:amd64       11.0.2-1ubuntu4~trusty1                       amd64        implementation of the Wayland EGL platform -- runtime\nii  mesa-common-dev-lts-wily:amd64            11.0.2-1ubuntu4~trusty1                       amd64        Developer documentation for Mesa\nii  mesa-utils                                8.1.0-2                                       amd64        Miscellaneous Mesa GL utilities\n\ndpkg -l | grep xorg\nii  python3-xkit                              0.5.0ubuntu2                                  all          library for the manipulation of xorg.conf files (Python 3)\nii  xorg                                      1:7.7+1ubuntu8.1                              amd64        X.Org X Window System\nii  xorg-docs-core                            1:1.7-1                                       all          Core documentation for the X.org X Window System\nii  xorg-sgml-doctools                        1:1.11-1                                      all          Common tools for building X.Org SGML documentation\nii  xserver-xorg-core-lts-wily                2:1.17.2-1ubuntu9.1~trusty1                   amd64        Xorg X server - core server\nii  xserver-xorg-input-all-lts-wily           1:7.7+7ubuntu4~trusty1                        amd64        X.Org X server -- input driver metapackage\nii  xserver-xorg-input-evdev-lts-wily         1:2.9.2-1ubuntu1~trusty2                      amd64        X.Org X server -- evdev input driver\nii  xserver-xorg-input-mouse-lts-wily         1:1.9.1-1~trusty1                             amd64        X.Org X server -- mouse input driver\nii  xserver-xorg-input-synaptics-lts-wily     1.8.2-1ubuntu1~trusty1                        amd64        Synaptics TouchPad driver for X.Org server\nii  xserver-xorg-input-vmmouse-lts-wily       1:13.1.0-0ubuntu1~trusty1                     amd64        X.Org X server -- VMMouse input driver to use with VMWare\nii  xserver-xorg-input-wacom-lts-wily         1:0.30.0-0ubuntu3~trusty1                     amd64        X.Org X server -- Wacom input driver\nii  xserver-xorg-lts-wily                     1:7.7+7ubuntu4~trusty1                        amd64        X.Org X server\nii  xserver-xorg-video-all-lts-wily           1:7.7+7ubuntu4~trusty1                        amd64        X.Org X server -- output driver metapackage\nii  xserver-xorg-video-ati-lts-wily           1:7.5.0+git20150819-0ubuntu1~trusty1          amd64        X.Org X server -- AMD/ATI display driver wrapper\nii  xserver-xorg-video-cirrus-lts-wily        1:1.5.3-1ubuntu1~trusty1                      amd64        X.Org X server -- Cirrus display driver\nii  xserver-xorg-video-fbdev-lts-wily         1:0.4.4-1build3~trusty1                       amd64        X.Org X server -- fbdev display driver\nii  xserver-xorg-video-intel-lts-wily         2:2.99.917+git20150808-0ubuntu4~trusty2       amd64        X.Org X server -- Intel i8xx, i9xx display driver\nii  xserver-xorg-video-mach64-lts-wily        6.9.5-1~trusty1                               amd64        X.Org X server -- ATI Mach64 display driver\nii  xserver-xorg-video-mga-lts-wily           1:1.6.4-1~trusty1                             amd64        X.Org X server -- MGA display driver\nii  xserver-xorg-video-neomagic-lts-wily      1:1.2.9-1~trusty1                             amd64        X.Org X server -- Neomagic display driver\nii  xserver-xorg-video-nouveau-lts-wily       1:1.0.11-1ubuntu3~trusty1                     amd64        X.Org X server -- Nouveau display driver\nii  xserver-xorg-video-openchrome-lts-wily    1:0.3.3-1ubuntu1~trusty1                      amd64        X.Org X server -- VIA display driver\nii  xserver-xorg-video-qxl-lts-wily           0.1.4-3ubuntu1~trusty1                        amd64        X.Org X server -- QXL display driver\nii  xserver-xorg-video-r128-lts-wily          6.10.0-1~trusty1                              amd64        X.Org X server -- ATI r128 display driver\nii  xserver-xorg-video-radeon-lts-wily        1:7.5.0+git20150819-0ubuntu1~trusty1          amd64        X.Org X server -- AMD/ATI Radeon display driver\nii  xserver-xorg-video-savage-lts-wily        1:2.3.8-1ubuntu1~trusty1                      amd64        X.Org X server -- Savage display driver\nii  xserver-xorg-video-siliconmotion-lts-wily 1:1.7.8-1ubuntu4~trusty1                      amd64        X.Org X server -- SiliconMotion display driver\nii  xserver-xorg-video-sisusb-lts-wily        1:0.9.6-2build3~trusty1                       amd64        X.Org X server -- SiS USB display driver\nii  xserver-xorg-video-tdfx-lts-wily          1:1.4.6-1~trusty1                             amd64        X.Org X server -- tdfx display driver\nii  xserver-xorg-video-trident-lts-wily       1:1.3.7-1~trusty1                             amd64        X.Org X server -- Trident display driver\nii  xserver-xorg-video-vesa-lts-wily          1:2.3.4-0ubuntu1~trusty1                      amd64        X.Org X server -- VESA display driver\nii  xserver-xorg-video-vmware-lts-wily        1:13.1.0-0ubuntu1build2~trusty1               amd64        X.Org X server -- VMware display driver\n\ndpkg -l | grep intel\nii  i965-va-driver:amd64                      1.4.0-0intel1                                 amd64        VAAPI driver for Intel G45 & HD Graphics family\nii  intel-gpu-tools                           1.8-1                                         amd64        tools for debugging the Intel graphics driver\nii  libdrm-intel1:amd64                       2.4.64-1~ubuntu14.04.1                        amd64        Userspace interface to intel-specific kernel DRM services -- runtime\nii  libva-dev:amd64                           1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- development files\nii  libva-drm1:amd64                          1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- DRM runtime\nii  libva-egl1:amd64                          1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- EGL runtime\nii  libva-glx1:amd64                          1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- GLX runtime\nii  libva-intel-vaapi-driver                  1.3.0-1ubuntu1                                all          VAAPI driver for Intel G45 & HD Graphics family (transitional package)\nii  libva-tpi1:amd64                          1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- TPI runtime\nii  libva-wayland1:amd64                      1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- Wayland runtime\nii  libva-x11-1:amd64                         1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- X11 runtime\nii  libva1:amd64                              1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- runtime\nii  va-driver-all:amd64                       1.4.0-0intel1                                 amd64        Video Acceleration (VA) API -- driver metapackage\nii  vainfo                                    1.4.0-0intel1                                 amd64        Video Acceleration (VA) API for Linux -- info program\nii  xserver-xorg-video-intel-lts-wily         2:2.99.917+git20150808-0ubuntu4~trusty2       amd64        X.Org X server -- Intel i8xx, i9xx display driver\n\n\nA: If you have wily stack, you should install wily packages\nsudo apt-get install libgl1-mesa-dev-lts-wily libgles2-mesa-dev-lts-wily\n\nThese packages are alternatives to libgl1-mesa-dev and libgles2-mesa-dev.\n", "Q: Ubuntu Autopilot Openstack Dashboard inaccessible After a successful Autopilot install, I had to recommission nodes in order to reenable ssh.  Since then, the Openstack Dashboard is offline.  The once reachable IP Address for the dashboard is now not reachable.  How do I go about reenabling access to the Openstack Dashboard?\n\nA: The entire stack is offline.  Will have to recommission and re-run openstack-install.\n", "Q: How to unlock all tracks in Linux version of SuperTuxKart 0.9? I want to set up an open-source gaming party, kinda small, in my local area, all of the machines running Ubuntu. One of the games I plan on have there is SuperTuxKart, specifically the 0.9 version. I want to unlock everything in the game without taking the time to play through the entire campaign mode, so I figured that I would cheat. I've seen millions of guides telling you to modify ~/.config/supertuxkart/challenges.xml, but for the life of me I cannot find that file in that location. Please help, I need this up and running in a week or so.\n\nA: According to the STK FAQ, there are two possible locations for the config file:\n\n\n*\n\n*~/.config/supertuxkart/0.8.2\n\n*~/.supertuxkart/0.8.2\nIn one of these directories, you should find a .xml file (probably challenges.xml), in which you'll need to change all occurrences of \"false\" to \"true\", for each track. Note that 0.9 stores its config data in the 0.8.2 directory, since the files are compatible with various versions.\nHave fun :-)\n\nA: Yay, I finally figured this out!\nFind your configuration directory -- mine was in ~/.config/supertuxkart/0.8.2/.\nOpen players.xml and find where the challenges are listed under the <story-mode> tag.\nChange all occurrences of solved=\"none\" to solved=\"easy\". (You can also say solved=\"hard\"; I'm not sure what the difference is.)\nSources:\n\n\n*\n\n*http://forum.freegamedev.net/viewtopic.php?t=6289&p=63809\n\n*https://www.reddit.com/r/linux/comments/33dosv/supertuxkart_09_released_full_review/.\n\n", "Q: GRUB shows Windows recovery instead of normal Windows I just installed Windows 10 + Ubuntu on my Lenovo laptop. Windows is installed on SSD and Ubuntu is installed on HDD. sda1 is Windows recovery and sda2 is Windows 10. Ubuntu is installed on sdb. Bootloader was installed in sda.\nMy problem is that GRUB2 shows only win recovery on sda1. I already tried updating grub and running os-prober as was suggested in other asks (where Windows was not found at all), but it only finds sda1. I read somewhere that it may be Lenovo's fault, but I'm not sure about it.\nCan I fix it any other way than manually adding Windows 10 to grub files? Various threads says that for Windows 8.1 and 10 that can be buggy to add them manually.\n\nA: There is nothing wrong if Windows boots correctly when you select the Windows Recovery entry. GRUB detects all boot loaders and the first Windows boot loader detected is the one that points to the Windows Recovery Environment. The complete Windows Boot Environment starts when you select the Windows Recovery Environment entry from the GRUB boot menu entries list.\nSo this is absolutely nothing you should worry about ... it is just a misleading wrong name.\n\nA: In my system (Ubuntu 21.04), the program Boot Repair worked fine.\nsudo add-apt-repository ppa:yannubuntu/boot-repair\nsudo apt-get update\nsudo apt-get install -y boot-repair && boot-repair\n\n", "Q: echo $SHELL: unexpected result I am facing a problem related to the shell change, when I change the shell from bash to csh and type the comand echo $SHELL, I expect the shell to print:\n/bin/csh\n\nBut instead it prints:\n/bin/bash\n\nWhat is the reason for that? How do I print the path to the currently running shell instead?\n\nA: To view your current shell use:\necho $0\n\n$SHELL prints the default shell.\n", "Q: Compiling GCC compiler....shows error So I started to setup for AVR programing and I found this nice tutorial to guide me.\nI am on step 3 of the tutorial.\nWhen I type the command:\nmake CC=\"cc --no-cpp-precomp\"\nI get this error:\nmake: *** No targets specified and no makefile found.  Stop.\n\nAny suggestions?\n\nA: Okay so I've searched around a bit more and found that the \"make\" command doesn't work because the previous ./configure command doesn't work. I read the full error in the terminal and it said to install gmp, mpc and mpfr (Newest versions). In the gcc directory there is a file that downloads them for you and installs them nicely. Here's the link, It'll guide you on how to install these packages\nhttps://gcc.gnu.org/wiki/InstallingGCC\nGood luck.\n", "Q: Am i missing packages ? - After removing Wine 1.9.5 - removed packages - help I have been using Ubuntu for a while now.\nYesterday I tried to install WINE 1.9.5.\nFor some reason it didn't show up in the Dash so I tried to uninstall it\nas instructed in the terminal: sudo ppa-purge ppa:wine/wine-builds\nI noticed it started to uninstall/remove applications-packages I\nhadn't even installed, although i'm not quite sure about a few packages\n(so I cancelled it halfway through the process) and my Question is: \n1: why did it remove/uninstall packages like (for example: extremetux-data) when i don't have it installed ?\n2: did it actually removed some packages i needed who were installed in the basic setup or atleast before i installed WINE like: (pandoc, pandoc-data or tcl) ?\n-\nHERE'S THE TERMINAL LOG and WHAT PACKAGES IT TRIED TO REMOVE (before i cancelled it):\nRemoving kde-l10n-ja (4:4.13.0-0ubuntu1) ...\nRemoving ibus-anthy (1.5.4-2) ...\nRemoving anthy (9100h-23ubuntu2) ...\nRemoving anthy-common (9100h-23ubuntu2) ...\nRemoving calligra-l10n-ca (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-cs (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-da (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-de (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-fr (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-hu (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-it (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-nb (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-nl (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-pl (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-pt (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-ptbr (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-ru (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-sv (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-uk (1:2.8.1-0ubuntu1) ...\nRemoving calligra-l10n-zhtw (1:2.8.1-0ubuntu1) ...\nRemoving extremetuxracer-data (0.4-5ubuntu1) ...\nRemoving extremetuxracer-extras (0.6-1) ...\nRemoving fonts-inconsolata (001.010-5) ...\nRemoving gnome-web-photo (0.10.6-1) ...\nRemoving kde-l10n-zhtw (4:4.12.97-0ubuntu1) ...\nRemoving ibus-chewing (1.4.10.1-1) ...\nRemoving kde-l10n-ko (4:4.13.0-0ubuntu1) ...\nRemoving ibus-hangul (1.4.2-3) ...\nRemoving kde-l10n-bg (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-ca (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-cs (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-da (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-de (4:4.13.3-0ubuntu0.1) ...\nRemoving kde-l10n-engb (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-fr (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-hu (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-id (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-it (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-nb (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-nl (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-pl (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-pt (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-ptbr (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-ru (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-sv (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-th (4:4.10.97-0ubuntu1) ...\nRemoving kde-l10n-uk (4:4.13.0-0ubuntu1) ...\nRemoving kde-l10n-vi (4:4.13.0-0ubuntu1) ...\nRemoving libanthy0:amd64 (9100h-23ubuntu2) ...\nRemoving libchewing3:amd64 (0.3.5-4build1) ...\nRemoving libchewing3-data:amd64 (0.3.5-4build1) ...\nRemoving libhangul1:amd64 (0.1.0-3) ...\nRemoving libhangul-data (0.1.0-3) ...\nRemoving pandoc (1.12.2.1-1build2) ...\nRemoving liblua5.1-0:amd64 (5.1.5-5ubuntu0.1) ...\nRemoving libmozjs185-1.0 (1.8.5-1.0.0+dfsg-4ubuntu1) ...\nRemoving tcl8.5 (8.5.15-2ubuntu1) ...\nRemoving libtcl8.5:amd64 (8.5.15-2ubuntu1) ...\nRemoving libtimezonemap1 (0.4.1) ...\nRemoving pandoc-data (1.12.2.1-1build2) ...\nRemoving python3-regex (0.1.20140216-1) ...\nRemoving python-regex (0.1.20140216-1) ...\nRemoving python3-enchant (1.6.5-2build1) ...\nRemoving python3-levenshtein (0.11.2-1build1) ...\nRemoving sbsigntool (0.6-0ubuntu7) ...\nProcessing triggers for gnome-menus (3.10.1-0ubuntu2) ...\n\nim very pleased with ubuntu and my system is very stable\nthats why i want to know if i messed something up or accindentally uninstalled packages! (i am running the Gnome desktop enviroment ofcourse)\nHopefully somebody can give me some more information about this?\n\nA: Many packages have other packages they depend on to work, (aptly) called \"dependencies.\" These are installed automatically, the only reaction from the user being to confirm the install for the base package. The packages you see marked for removal are these dependencies.\nThe ppa-purge command deletes the specified repository (WINE's in this case), any installed packages available from it and any dependencies for these packages.\nRun sudo apt-get install -f and sudo dpkg --configure -a before running the ppa-purge command again. Then run sudo apt-get install -f to make sure everything's OK.\nEDIT: I just noticed there are a few system packages that you have already removed. The PPA Purge option may not be a good one. Instead, try running sudo apt-get install -f and then sudo apt-get remove wine-*.\n\nA: @Zacharee1\n(SOLVED)\nthankyou very much for taking the time to explain.\nofcourse! i don't know why i haven't thought about its dependencies\nbut then again i still don't fully understand why packages(dependencies) like \nfor example: (languagepackages) kde-l10n's ,or calligra-l10n etc.\nhave to do anything with WINE, removing WINE or Wine's repository ?\nluckily i solved it, but with a diffrent approach. \n(since this accident occured on my laptop)\n\n\n*\n\n*i uninstalled it with a diffrent tutorial, then installed it\nand uninstalled it AGAIN, making sure it was completely removed!\n\n*i have another PC with exactly the same ubuntu version\nand exactly the same programs installed (without WINE ofcourse) very stable.\nso i opened SYNAPTIC PACKAGE MANAGER and compared all the packages\nit removed when i accidentally used the ppa:purge command.\n\n*thankgod it where only a few packages(65) to compare and i noticed\neverything was the same, none of the packages that were Removed on my laptop\nwere installed on my PC! except for only 3 packages:\nsbsigntool (0.6-0ubuntu7)\nlibtimezonemap1 (0.4.1)\nlibmozjs185-1.0 (1.8.5-1.0.0+dfsg-4ubuntu1)\n\n*I installed those 3 packages! but with or without those packages \ni luckily havent experienced anything Missing yet or noticed instability\nwhatsoever!*\nI SUPPOSE THIS SHOULD SOLVE THE WHOLE PROBLEM I HAD, FINDING OUT\nIF I WAS MISSING ANYTHING OR MESSED SOMETHING UP IN UBUNTU,\nOR IS THIS A WRONG SOLUTION/APPROACH AND DID I FORGET SOMETHING ??\n", "Q: Is there another place to host/machine name? I have a cloned VirtualBox machine that I've asked to clear MAC address after cloning. The machine name was changed from \"node01\" to \"new-host-7.home\" and I changed to \"node02\" by using conventional methods (hostname, change in traditional files, etc...). All seems to be changed until my Java program get the old machine name...\nMy /etc/hosts file:\n127.0.0.1       node02.home     node02  localhost\n192.168.25.25   node01.home     node01\n192.168.25.27   node03.home     node03\n\nMy /etc/hostname file:\nnode02\n\nMy prompt:\nroot@node02:/\n\nBut when I start a Java program that ask for the machine's name, I'm getting the old machine name:\nnew-host-7.home\n\nHere is how I got this name:\nInetAddress ip = getFirstNonLoopbackAddress(true, false);\nthis.machineName = ip.getCanonicalHostName();\n\nThe method:\nprivate InetAddress getFirstNonLoopbackAddress(boolean preferIpv4, boolean preferIPv6) throws SocketException {\n    Enumeration<NetworkInterface> en = NetworkInterface.getNetworkInterfaces();\n    while (en.hasMoreElements()) {\n        NetworkInterface i = en.nextElement();\n        for (Enumeration<InetAddress> en2 = i.getInetAddresses(); en2.hasMoreElements();) {\n            InetAddress addr = en2.nextElement();\n            if (!addr.isLoopbackAddress()) {\n                if (addr instanceof Inet4Address) {\n                    if (preferIPv6) {\n                        continue;\n                    }\n                    return addr;\n                }\n                if (addr instanceof Inet6Address) {\n                    if (preferIpv4) {\n                        continue;\n                    }\n                    return addr;\n                }\n            }\n        }\n    }\n    return null;\n} \n\nI don't know if AskUbuntu is the better place for this question or StackOverflow.  \nTIA.\nEDIT:\nip -o a\n\n1: lo    inet 127.0.0.1/8 scope host lo\\       valid_lft forever preferred_lft forever\n2: enp0s3    inet 192.168.25.26/24 brd 192.168.25.255 scope global enp0s3\\       valid_lft forever preferred_lft forever\n\ngetent hosts\n\n127.0.0.1       node02.home node02 localhost\n192.168.25.25   node01.home node01\n192.168.25.27   node03.home node03\n127.0.0.1       localhost ip6-localhost ip6-loopback\n\n\nA: Based on the updates to the initial question, you can see the IP command is returning 192.168.25.26 as the IP address in use, yet you have not defined a hostname on this ip address.\n/etc/hosts needs the following entry:\n192.168.25.26 node02.home\n\nAfter a restart you should see the DNS on your network update and your Java code return the correct hostname.\n", "Q: Problem Booting I have two hard drives 1TB and 250GB. I installed windows on the 1TB drive and I installed ubuntu 14.04 32 bit on 250GB drive. My problem is it is not asking which OS to boot. Is there any thing except changing hard disk priority every time I wants to boot OS?\n\nA: I overcome this problem by changing the hardDisk priority\nchange ubuntu installed hard disk(250gb) has to boot first in boot menu\n", "Q: Will \"linux-image-grsec\" be present on Ubuntu 16.04? I use the linux-image-grsec Kernel on Debian Sid and Arch, but I'd like to completely move to Ubuntu if Canonical supports that Kernel.\nDoes anyone have information on whether or not it will be supported? I could only find the following page, but it does not contain the Kernel image: https://launchpad.net/ubuntu/+source/linux-grsec-base/6\n\nA: Canonical will not support that kernel, but it still can be installed.\nlinux-grsec-base package is already included in Ubuntu Xenial repositories.\nIt can be installed by\nsudo apt install linux-grsec-base\n\nhttp://packages.ubuntu.com/xenial/linux-grsec-base\n", "Q: Error while sniffing packets using scapy arp = ARP(pdst=ip1,psrc=ip2,op=\"is-at\")\npacket = ethernet / arp\nwhile True:\n    sendp(packet, iface=iface)\n    time.sleep(10)\n\nAnd the Error is -\nFile \"/home/darshan/.local/lib/python2.7/site-           packages/scapy/arch/linux.py\", line 414, in __init__\nself.ins = socket.socket(socket.AF_PACKET, socket.SOCK_RAW,   socket.htons(type))\nFile \"/usr/lib/python2.7/socket.py\", line 191, in __init__\n_sock = _realsocket(family, type, proto)\nerror: [Errno 1] Operation not permitted\n\nI am a newbie in networking so please help. I am unable to debug it.\n\nA: Only root is allowed to open raw sockets. Use sudo to run your Python program.\n", "Q: Ifconfig does not show my IP When i'm putting the code on: ifconfig\nifconfig results in a terminal shows:\neth0 Link encap:Ethernet HWaddr: f8:a9:63:64:3f:1c \nUP BROADCAST MULTICAST MTU:1500 Metric:1 \nRX packets: 0 errors:0 dropped: 0 overruns: 0 frame: 0 \nTX packets: 0 errors:0 dropped: 0 overruns: 0 carrier: 0 \ncolisions: 0 txqueuelen:1000 \nRX bytes:0 (0.0 B) TX bytes:0 (0.0 B) \n\nDoes not show my Itnet addr, bcast and mask!\nWhat's that supposed to mean?\n\nA: The interface eth0 is up, so the underlying device is found. There no IP address associated to this interface. \nAssign an ip address manually:\n$ sudo ifconfig eth0 w.x.y.z\n\nOr contact the DHCP server, if it exists, and let it provides an ip address for the interface:\n$ sudo dhclient -v eth0\n\nIf something goes wrong, dhclient will print error messages. They should be used to troubleshoot.\n----\nIf the system just booted, then there could be a missing configuration or a mistake in interfaces configuration.\nIn order to fix issues of interfaces setting at boot or If you would like to make the settings persistent over the reboot:\n\n\n*\n\n*man interfaces\n\n*edit /etc/network/interfaces file\n\n", "Q: How to Upgrade 16.04 Linux Kernel to 4.5? I need some features in the Linux Kernel 4.5. It would be great if there is coming any support for it soon. I am interested in how you can upgrade 16.04 to Linux kernel 4.5?\n\nHow to Upgrade 16.04 Ubuntu's kernel to 4.5?\n\nA: You can install any kernel to any version of Ubuntu from Mainline Kernel PPA\nThe 4.5 kernel will not be included in Ubuntu repositories.\n\nA: As of the time of writing this (December 2016) you can simply install the package linux-image-generic-hwe-16.04-edge to get kernel 4.8.\nAccording to the package description, this will always keep your Ubuntu 16.04 machine up to date with \"the latest generic kernel image available\".\n", "Q: Ubuntu 16.04 LTS with 3.* Kernel? I really don't know much about Kernels, so please excuse me if my questions sounds silly to you. :)\nIs it possible to run Ubuntu 16.04 LTS and install, for example a 3.19.0-* Kernel? I know it's possible on Ubuntu 14.04 LTS since they run those Kernels anyways, but can you do it on 16.04 LTS?\n\nA: Yes, 16.04 should be compatible with 3.19 since it would be used in 14.04, which can be upgraded to 16.04.\nSome people are still using 3.19 due to issues such as https://github.com/vmware/open-vm-tools/issues/74\neldamir was able to manually install the 3.19 packages in this manner:\nmkdir kernel\ncd kernel\nwget http://launchpadlibrarian.net/220635919/linux-headers-3.19.0-31-generic_3.19.0-31.36~14.04.1_amd64.deb\nwget http://launchpadlibrarian.net/220668669/linux-headers-3.19.0-31_3.19.0-31.36~14.04.1_all.deb\nwget http://launchpadlibrarian.net/220635970/linux-image-3.19.0-31-generic_3.19.0-31.36~14.04.1_amd64.deb\nsudo dpkg -i linux-*\n\nNote:\nThe kernels are related to hardware support, so the machines that upgraded from 14.04 to 16.04 should be able to use the same kernel before the upgrade (at least for some time), since there was no change in the hardware. It is possible that a machine may have new hardware that is only supported in kernels newer than 3.x, but this does not mean that 16.04 is strictly incompatible with 3.x kernels, just that the machine will need to use a newer kernel.\n\nA: I was looking into doing this myself since I am finding 16.04 highly unstable. I installed 16.04 as a fresh install and get dependency errors trying to install the 3.19.0-31-generic:\n\ndpkg: error processing package linux-image-3.19.0-31-generic (--install):\n   dependency problems - leaving unconfigured\n  Errors were encountered while processing:\n   linux-image-3.19.0-31-generic\n\nThis post states that, though 16.04 may work with 3.19..., it works without any problem for those who have upgraded from 14.04. For anybody else it is likely much more hassle than it is worth if it will work at all. I will consider a fresh install of an older Ubuntu.\nA kernel support page can be found here.\n", "Q: How to see my wlan ip? Ubuntu 14.04 LTS I know i need to go to terminal and enter \n\nifconfig\n\nbut when i do that i only get etho and lo informaion. So anyone know something?\n\nA: The ifconfig command should show you the status of all your active devices.\nAn alternate command is: ip addr or ip address\nThis cli should show you yhour wlan ip if it's activated:\n$ ip address | egrep wlan\n\nAre you sure you have a wlan active connection?\n\nA: An easy way you can see your wlan ip address is to click on the wifi icon and go to Connection information... Then Bingo!\n", "Q: Problem with sudo apt-get upgrade It tells me to try to run apt-get -f install.  The error says \"Unmet dependencies. Try using -f.\"  When I try sudo apt-get -f install I get an error that says\ndpkg-deb: error: subprocess paste was killed by signal (Broken Pipe)\n\nErrors were encountered while processing\n/var/cache/apt/archives/linux-image-3.16.0-70-generic_3.16.--70.90~14.04.1_i386.deb\n/var/cache/apt/archives/linux-image-3.16.0-67-generic_3.16.0-67.87~14.04.1_i.386.deb\n\nE: Sub-process /usr/bin/dpkg returned an error code(1)\n\n\nA: Try running the following commands.  You might have to run them more than once to get all the updated repository links correct.\n$ sudo apt-get update\n$ sudo apt-get upgrade\n\n", "Q: How do I wipe a harddrive with Ubuntu on it? I want to completely wipe a harddrive with Ubuntu on it, so I can put Windows back on it. How do I do that? I don't want to dual boot either, I just want to wipe the drive and put Windows on it. How do I do this? Thanks!\n-Trace\n\nA: You can do this directly from Windows installer, just select \"Advanced\" partitioning, remove all partitions of your drive, create a new one (Windows will create addtitional partitions - recovery and ESP) and proceed as in normal installation.\nAlternatively you could use Live CD/Live USB of some Linux distribution, e.g. drive you installed Ubuntu from. Click \"Try Ubuntu without installing\". There are variety of tools you can use at this point. For GUI operation I'd recommend GParted, you can install it using apt-get install gparted like you'd do on regular Ubuntu installation. Operation is preety straightforward, but in case of problems you can refer to manual.\nPlease note that this will remove all your data from the drive you kept Ubuntu on!\n", "Q: Dual boot issue suddenly after working for a long time - Windows 7 and Ubuntu 14.04 I have a Windows 7 laptop and about a year ago I installed Ubuntu to dual boot with. I struggled through it since I knew nothing of computers and eventually got it to work. I've been able to restart my computer and boot into either Windows or Ubuntu without any problems since then.\nNow, for seemingly no reason, I went to restart my computer to switch to Ubuntu and it just went straight to Windows. It's been so long that I hardly remember anything about how I installed Ubuntu, so I feel kind of lost with what to do to try to fix this, or how to go about it. Any ideas how to get my Ubuntu back?\nThanks!\n\nA: I fixed it! \nI held down f12 as I was rebooting my computer and selected ubuntu from the menu. Then, once I was in my old ubuntu partition, I ran the boot repair that reinstalled and updated grub. I'm not sure if this was a necessary step, since after that when I rebooted it again went straight to windows. From there though, I opened an admin command prompt, and typed:\nbcdedit /set {bootmgr} path \\EFI\\ubuntu\\shimx64.efi\n\nAfter that, I rebooted and grub was back. I chose ubuntu to make sure it worked, then rebooted back to windows to check if that still worked, and finally back again to ubuntu. It looks like it's all back to normal. Thank you everyone for your responses. Hopefully this helps someone like me in the future :)\nAlec\n", "Q: problem with youtube-dl youtube-dl https://www.udemy.com/android-tutorial/learn/v4/t/lecture/131089\n[udemy] 131089: Downloading webpage\n[udemy] 131089: Downloading lecture JSON\n[udemy] 25584: Enrolling in the course\n[udemy] 131089: Downloading lecture JSON\nERROR: Unable to download JSON metadata: HTTP Error 403: FORBIDDEN (caused by \nHTTPError()); please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; type  youtube-dl -U  to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n\nHow I can solve this please?\n\nA: Use this command instead:\nyoutube-dl -u username@example.com -p yourpassword https://www.udemy.com/android-tutorial/learn/v4/t/lecture/131089\n\nUse your email address login associated with Udemy as your login (-u) and your associated Udemy password (-p).\n", "Q: Ubuntu 15.10 having troubles with internet connection (first time boot) This is my first time that I've installed Ubuntu on this machine and I'm running the 15.10 version (most recent one). \nI installed Ubuntu and all seemed fine. I went ahead and connected to my home network via wireless and it showed me a valid connection but when I go to open up Firefox, it does not seem to work at all. It says that the server cannot be found. \nI have restarted several times, checked my internet connection and even restarted the router, yet nothing works. I have also tried pinging www.google.com but I get 'unknown host www.google.com'.\nI have looked at a lot of threads about this and none of them seem to work for me.\nWhy can I not connect to the internet?\nEDIT:\nI have figured out the problem myself.\nI went into\n/etc/network/interfaces\n\nand below everything else I added:\ndns-nameservers 8.8.8.8 8.8.4.4\n\nTo use Google's DNS servers. This seemed to fix my problem.\n\nA: I have figured out the problem myself.\nI went into\n/etc/network/interfaces\n\nand below everything else I added:\ndns-nameservers 8.8.8.8 8.8.4.4\n\nTo use Google's DNS servers. This seemed to fix my problem.\n", "Q: What are alternative reasons for low network connectivity? Excluding this, as I have tried all methods listed on this site.\nAnd excluding this and this, they are in the aforementioned site.\nWhat are possible causes for a software based slowdown of internet.\nSymptoms:\n\n\n*\n\n*Booting in Windows or other live-boot disk makes Internet work, pings anything 0% loss.\n\n*Router can be pinged by the PC in question, while running Ubuntu, with 0% loss as well as anything in the same network 0% loss.\n\n*Pinging or mtr, by the PC in question to anything outside the network(on the other side of the router) results in 100% loss.\n\n*If the Router or other devices on the network try to ping the computer in question, they have 80% to 95% loss.\n\n\nWhat could possibly be the cause of this kind of network failure on Ubuntu?\nUbuntu PCs with this problem have responses to lspci -knn | grep Eth -A2:\n02:00.0 Ethernet controller [0200]: Qualcomm Atheros AR8131 Gigabit Ethernet [1969:1063] (rev c0)\n    Subsystem: Micro-Star International Co., Ltd. [MSI] Device [1462:7599]\n    Kernel driver in use: atl1c\n\nThis one has under 80% loss ~50% using a USB to Cat5 network port\n00:13.2 USB controller [0c03]: Advanced Micro Devices, Inc. [AMD/ATI] SB7x0/SB8x0/SB9x0 USB EHCI Controller [1002:4396]\n    Subsystem: Advanced Micro Devices, Inc. [AMD/ATI] SB7x0/SB8x0/SB9x0 USB EHCI Controller [1002:4396]\n    Kernel driver in use: ehci-pci\n\n\nA: This is and always will be a will guess without being on-site, but there here are some reasons that might prevent Ethernet to function properly.  Windows driver for the card might be able to do some automagic to degrade the settings of your card.  Or the card needs some poke to do the autonegotiation.\n\n\n*\n\n*The most obvious might be duplicate MAC addressed.  List the MAC addresses on the affected PC, then shut it down and then try arping the MAC addresses from different machine.\n\n*Your router might be a real deal and block some default IP settings.  If you could try using some other generic router on the network, then do so to rule out this possibility.\n\n*Crooked or old cabling that prevent the card to function at higher speeds.  You might try setting the link mode to 10M or 100M manually using either mii-tool or ethtool.\n\n*Similar with full-duplex or half-duplex settings on the card.\nHere's an article on mii-tool/ethtool that goes there in more detail.\nOne more idea how to debug the issue:\n\n\n*\n\n*You can try sniffing the network interface using tcpdump or wireshark and observe the differences between pings initiated at the PC in question and pings initiated elsewhere.\n\n*The same can be done on the router if it's f.e. running embedded Linux, or you can plug a \"sniffer\" consisting of two network cards bridged together between router and the inside network.\n\n\nA: Another tool that you might want to employ is iperf. You can use this to determine if the local networking is killing your throughput. A reference is located at: https://iperf.fr/. You can simply generate high bandwidth loads and then check what that actual reported throughput is. If you have two nodes you can do the following check. First run\nsudo lshw -c network\n\non both machines. Find your interface and note the reported link speed, should be something of the form:\nsize: 100Mbit/s\ncapacity: 100Mbit/s\ncapabilities: ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd autonegotiation\n\nThis interface reports 100Mbit/s, check this on both devices and determine the\nminimum you expect. Next use iperf to push a large ammount of traffic to determine what the actual throughput is\nOn node 1 run:\niperf -s -i 2\n\nOn node 2 run:\niperf -n 1000M -i 2 -c <SERVER IP>\n\nThis will generate a report on the client side of the form:\n------------------------------------------------------------\nClient connecting to <SERVER IP>, TCP port 5001\nTCP window size: 85.0 KByte (default)\n------------------------------------------------------------\n[  3] local <CLIENT IP> port 36114 connected with <SERVER IP> port 5001\n[ ID] Interval       Transfer     Bandwidth\n[  3]  0.0- 2.0 sec  22.5 MBytes  94.4 Mbits/sec\n[  3]  2.0- 4.0 sec  22.2 MBytes  93.3 Mbits/sec\n[  3]  4.0- 6.0 sec  22.5 MBytes  94.4 Mbits/sec\n[  3]  6.0- 8.0 sec  22.4 MBytes  93.8 Mbits/sec\n\nand something similar on the server side (the -s node).  You'll note that in this case the throughput is pretty close to the reported ideal. You should expect to loose a couple of Mbits/sec to TCP overhead, but if this value is far off, you can blame something inside your network. If this number is within some tolerance (say 5-7% of reported), you're problem lies beyond your gateway. \nAt that point one can ask if your service provider is proxing, or doing some flavor of traffic shaping that gives preferential treatment to certain types of traffic?\n", "Q: Ubuntu 14.04 unstable wifi connection with Intel wifi card I have problem with my Intel wireless card. Connection is very unstable and very often gets lost. I've tried to disable IPv6 settings but it doesn't help.\n$ lspci -nn | grep 0280\n01:00.0 Network controller [0280]: Intel Corporation Centrino Wireless-N 1030 [Rainbow Peak] [8086:008a] (rev 34)\n\nAny idea?\n\nA: If your WiFi card is working there are two courses of action you can take:\n\n\n*\n\n*You can also verify that you're not using generic drivers for your specific card.\nhttp://www.intel.com/content/www/us/en/support/network-and-i-o/wireless-networking/000005511.html\nAlso, Intel has an entire wiki on maintaining drivers for their devices located here.\n\n*You may just have to turn the power up. I know this sounds bad, but unfortunately the drivers for WiFi just aren't that great and unfortunately do not match their Windows counterparts. I experienced this on my box as well.\nPlease keep in mind that this can cause excessive heat on your board.\nsudo iw reg set BO\nsudo iwconfig wlan0 txpower 30\n\nThis turns up the power and switches your country to Bolivia.\n", "Q: manage PPA via terminal I was searching for a way to manage my repositories in an advanced way and I found y-ppa-manager GUI application. it is a great application, that's for sure. But is there a way to manage them via *terminal?\nLike backup current repos to some kind of file, restoring them from a file. Other words is there a smiler application to y-ppa-manager on terminal?\n\nA: You can add a repository by add-apt-repostory command, e.g.\nsudo add-apt-repository ppa:hanipouspilot/rtlwifi\n\nYou can remove a repository by add-apt-repostory -r, e.g.\nsudo add-apt-repository -r ppa:hanipouspilot/rtlwifi\n\nYou can also purge all packages installed from a repository by ppa-purge. You will need to install it first\nsudo apt-get install ppa-purge\n\nThen use it this way\nsudo ppa-purge ppa:hanipouspilot/rtlwifi\n\nThe command will purge all the packages and revert them to the previous ones from the standard repos, if anything has been upgraded from the PPA.\nTo backup repository lists you can backup the contents of /etc/apt/sources.list.d directory. The lists are stored there.\n", "Q: Help updating and getting apps on Lubuntu I'm getting back into Linux distributions.  I need assistance with getting and updating applications in Lubuntu.  (ie. Outlook type programs, Open Libre, Firefox, etc.)  This may be too generic but I forgot a lot. Thank you in advance for your time and patience on this matter. \n\nA: Open your terminal, and install Synaptic:\nsudo apt-get install synaptic\n\nAfter install it should be placed somewhere in menu, like Administration -> Synaptic and with it you can manage, install and update whatever packages you want. Here's the nice tutorial how to use it.\nThere's also \"Software Center\" app. It might be considered easier to install new apps with it.\nsudo apt-get install lubuntu-software-center\n\nAnd other way to update everything:\nsudo apt-get update\nsudo apt-get upgrade\n\n", "Q: How to make a permanent alias in oh-my-zsh? In my .zshrc I tried to make a few aliases .I looked into a lot of places, but I couldn't find out a way that worked. I used this code below:  \n# Set personal aliases, overriding those provided by oh-my-zsh libs, \n# plugins, and themes. Aliases can be placed here, though oh-my-zsh \n# users are encouraged to define aliases within the ZSH_CUSTOM folder. \n# For a full list of active aliases, run alias. # # Example aliases\nalias zshconfig=\"mate ~/.zshrc\"\nalias ohmyzsh=\"mate ~/.oh-my-zsh\"\nalias n= \"nano\"  \nalias m= \"mkdir\"\nalias w= \"cd ~/Documents/UoMWorkspace/Semester2\"  \nalias j= \"cd ~/Documents/UoMWorkspace/Semester2/COMP17412\"\n\nThen I wrote a command source ~/.zshrc. Still it didn't resolve the issue. I get error messages like zsh: command not found: j\nCould anyone help me with any suggestions and let me know what am I doing wrong?\n\nA: There must not be any whitespaces around between = and either alias name or alias definition:\nalias zshconfig=\"mate ~/.zshrc\"\nalias ohmyzsh=\"mate ~/.oh-my-zsh\"\nalias n=\"nano\"\nalias m=\"mkdir\"\nalias w=\"cd ~/Documents/UoMWorkspace/Semester2\"\nalias j=\"cd ~/Documents/UoMWorkspace/Semester2/COMP17412\"\n\n\nBTW: If you are looking for a way to shorten directory names, I suggest looking into Named Directories and the AUTO_CD option instead of aliases:\nhash -d w=~/Documents/UoMWorkspace/Semester2\nhash -d j=~/Documents/UoMWorkspace/Semester2/COMP17412\n\nThis allows you to use ~w instead of ~/Documents/UoMWorkspace/Semester2 and ~j instead of ~/Documents/UoMWorkspace/Semester2/COMP17412 (or ~w/COMP17412). So cd ~j is identical to cd ~/Documents/UoMWorkspace/Semester2. It also works as part of a path, e.g. cat ~j/somedir/somefile.\nWith \nsetopt AUTO_CD\n\nzsh will automatically cd to a directory if it is given as command on the command line and it is not the name of an actual command. e.g.\n% /usr\n% pwd\n/usr\n% ~w\n/home/YOURUSERNAME/Documents/UoMWorkspace/Semester2\n\n", "Q: Can multiple versions of the same package co-exist on the same system? In order to install tmux 2.1, I needed to install libtinfo5 version 6, I did this by downloading a .deb archive containing libtinfo5 and installing directly with command:\nsudo dpkg -i libtinfo5_6.0+20160213-1ubuntu1_amd64.deb\n\nThis satisfied tmux 2.1's dependency and tmux installed ok.\nNow I tried to install vnstat using\nsudo apt-get install vnstat \n\napt-get error exited with the following\n$ sudo apt-get install vnstat\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nYou might want to run 'apt-get -f install' to correct these:\nThe following packages have unmet dependencies:\n libncurses5 : Depends: libtinfo5 (= 5.9+20150516-2ubuntu1) but 6.0+20160213-1ubuntu1 is to be installed\n libncursesw5 : Depends: libtinfo5 (= 5.9+20150516-2ubuntu1) but 6.0+20160213-1ubuntu1 is to be installed\nE: Unmet dependencies. Try 'apt-get -f install' with no packages (or specify a solution).\n\nMy understanding has always been that Ubuntu's package management system was capable of installing and managing multiple versions of the same package, for situations exactly like this.  In other words apt/dpkg recognises\n\n\n*\n\n*tmux needs libtinfo5 - version 6 to work\n\n*vnstat needs libtinfo5 - version 5 to work\n\n\nThen apt/dpkg say's ok, I'll install both versions.\nI can see how certain programs like a system binary, e.g. bash or ls can only be installed once as most invocations simply say bash -c \"<command>\" and not bashv.3.2 -c \"<command>\".\nSo my question is can the package manager install and manage multiple dependencies?, or is this just not possible because, like in the bash example above, most programs make a call to the dependency by the dependencies name without specifying version. In which case the issue is beyond the control of the package manager (i.e. its more of a programming compilation/configuration/organisation issue) and the package manager gives up at that point? \n\nA: No, it is not possible to have two versions of the same package, because there will be conflicting files. If a library is capable of being installed in two different versions at the same time is a different matter. If you're brave, you could get the source code for one version and see if you can install that to a different directory. This could very well mess up your system in nasty ways. It could also just plain not work. Dpkg won't be satisfied, so you'll have to get the source for one of the programs and compile that too. But bear in mind that once you start compiling programs yourself, you can cause yourself all kinds of problems.\n\nA: No, you can not have different versions of the same package installed at the same time.  Usually dependencies are expressed as at least version X.  For packages that are all built from the same source however, the dependency is often exact.  This is what you have run into.  libncurses5 and libtinfo5 are both built from the ncurses source package.  If you want to upgrade one of the packages built from this source, you must upgrade all of them, so you simply need to get and install the same version of the other packages built from this source, so they are all on the same version.\n", "Q: Block port on one network address I'd like to block a series of ports (mailserver) for all the network addresses on my server except one.  I've got a server running Ubuntu 14.04.4 and configured with 2 ipv4 addresses per Linode's Static IP configuration tutorial.  /etc/network/interfaces looks something like this:\nauto eth0 eth0:0\n\niface eth0 inet static\n    address 93.184.216.34/24\n    gateway 93.184.216.1\n\n# This is a second public IP address\niface eth0:0 inet static\n    address 93.184.216.35/24\n\nI need first address to run the mailserver but the second needs to drop all incoming traffic except webserver ports (80,443).\nI'm having a bit of difficulty here since every search result I get seems to relate to blocking specific IP addresses from connecting - instead of blocking all IP address from connecting to a specific server iface / ip address.\n\nA: From the UFW MAN Page \n   By default, ufw will apply rules to all available interfaces. To  limit\n   this,  specify  DIRECTION on INTERFACE, where DIRECTION is one of in or\n   out (interface aliases are not supported).  For example, to  allow  all\n   new incoming http connections on eth0, use:\n\nExample :\nufw allow in on eth0:0 to any port 80 proto tcp && ufw allow in on eth0:0 to any port 443 proto tcp\n\nNote I am unable to test this as I don't have two interfaces, but this should work fine. Im not sure how it will handle eth0:0 or if it needs a second real interface, like eth1, but I suspect it should be fine.\n", "Q: Understand the differences between two network configurations for MAAS I am trying to understand the differences between two network configurations for MAAS. My understanding is that the both achieve the same tasks where the first network connects to the internet and the second is managed by MAAS. The second network is then configured to forward traffic out via the public network interface. \nDespite achieving the same results the configuration looks rather different which is where my confusion lies.\nFirst configuration\nThe first suggested configuration comes from the following Cloudbase Solutions Wiki page. They propose a simple /etc/network/interfaces with eth0 connecting to an external network and eth1 going to an internal network and being given a static address:\n# The primary network interface (external)\nauto eth0\niface eth0 inet dhcp\n\n# The secondary NIC (used internal for MAAS)\nauto eth1\niface eth1 inet static\naddress 192.168.1.1\nnetmask 255.255.255.0\n\nThe corresponding iptables rules are then held in /etc/rc.local. As far as I can tell this has something to do with the forwarding of network traffic between eth1 and eth0.\n/sbin/iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n/sbin/iptables -A FORWARD -i eth0 -o eth1 -m state --state RELATED,ESTABLISHED -j ACCEPT\n/sbin/iptables -A FORWARD -i eth1 -o eth0 -j ACCEPT\n\nSecond configuration\nThe second configuration comes from the Ubuntu Openstack Installer for Multi Installer Guide. Their /etc/network/interfaces file has more network interfaces but is similar to the previous configuration where eth0 connects to an external network and eth1 is internal:\n# The loopback network interface\nauto lo\niface lo inet loopback\n  dns-nameservers 127.0.0.1\n  pre-up iptables-restore < /etc/network/iptables.rules\n\nauto eth0\niface eth0 inet dhcp\n\nauto eth1\niface eth1 inet manual\n\nauto br0\niface br0 inet static\n  address 172.16.0.1\n  netmask 255.255.255.0\n  bridge_ports eth1\n\nQuestions that pop to my head at this stage are why does the lo have a DNS Name Server and iptables applied to it? Why is a bridged connection used in this instance?\nTheir iptable rules also look different and are placed in /etc/network/iptables.rules and assume this enables the forwarding of traffic:\n*nat\n:PREROUTING ACCEPT [0:0]\n:INPUT ACCEPT [0:0]\n:OUTPUT ACCEPT [0:0]\n:POSTROUTING ACCEPT [0:0]\n-A POSTROUTING -s 172.16.0.1/24 ! -d 172.16.0.1/24 -j MASQUERADE\nCOMMIT\n\nSummary\nCan someone help explain what they are doing differently and why? \nLet me know if this question is too big and I can chunk it down to separate questions but in the first instance I thought this provided more context.\n\nA: The first network configuration is pretty clear. The /etc/network/interfaces file is familiar to everyone and of course IP forwarding through iptables is need while using MAAS, to provide internet to nodes that are being managed by MAAS.\nThe second configuration other than the DNS part and the br0 part is understandable. The DNS part is to actually make the MAAS server realize that it itself is hosting the DNS services. That line may be shifted to /etc/resolve.conf which includes other DNS configurations.\nIf this DNS entry is not made you will reach this error during JUJU bootstrap: https://github.com/Ubuntu-Solutions-Engineering/openstack-installer/issues/901\nHowever, I am not really sure about the bridge br0. Did this network configuration actually work?\n\nA: Both configurations are pretty much the same with some nuances. \niface lo inet loopback\n  dns-nameservers 127.0.0.1\n  pre-up iptables-restore < /etc/network/iptables.rules\n\nThis configuration will guarantee that even if your eth0 cable is off while booting, you will still have a DNS resolver and firewall rules set (it's difficult to get rid of loopback network device right?). Off course this example presumes that you will have a running DNS resolver service locally.\nI do not see any problems with setting a bridge device. This configuration should work without a problem, but don't really think you need it in your case, unless you are planning something that is going to use it (KVM virtual machines, for example).\nIn the first case iptables rules are written for a shell script that's why their syntax looks different from /etc/network/iptables.rules which should be used with iptables-restore.\n*nat\n:PREROUTING ACCEPT [0:0]\n:INPUT ACCEPT [0:0]\n:OUTPUT ACCEPT [0:0]\n:POSTROUTING ACCEPT [0:0]\n-A POSTROUTING -s 172.16.0.1/24 ! -d 172.16.0.1/24 -j MASQUERADE\nCOMMIT\n\nThere's only one rule here and it allows 172.16.0.0/24 subnet to be masqueraded. \n/sbin/iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n/sbin/iptables -A FORWARD -i eth0 -o eth1 -m state --state RELATED,ESTABLISHED -j ACCEPT\n/sbin/iptables -A FORWARD -i eth1 -o eth0 -j ACCEPT\n\nRules above allows any subnet coming from eth1 through eth0 to be masqueraded with some filtering involved.\nPersonally I would rather go with a mix of configurations above.\n", "Q: SSH Terminal like SecureCRT On Windows I used to use SecureCRT and GNS3. Ubuntu also has GNS3 and its free.\nIs there a free alternative to SecureCRT, an SSH terminal which has a multi-tab facility to access multiple routers at same time. \n\nA: I concur with mikeymop: Gnome Terminal, the default terminal emulator of Ubuntu, supports tabs (see below). So do many other popular terminal emulators. You could easily run ssh in any or each of the tabs.\n\nAn other options would be a terminal multiplexer like screen or tmux.\n", "Q: Installing Driver for ATI Radeon HD 4000 Series I am dual booting Ubuntu 15.10 (64-bit / Kernel 4.2.0-35-generic) with OSX on my iMac (mid-2010). I managed to install, and am able to use, Ubuntu with the nomodeset workaround, but the monitor can't wake out of sleep and I can't play games without a proper graphics driver.\nMy question is: How do I install the most up-to-date graphics driver available for my ATI Radeon HD 4670? I realize it will almost certainly be third party, and that's fine.\nAny assistance would be greatly appreciated.\n*Edit: I should add that I can't even adjust my brightness, which is my main concern as it makes my computer run really hot and also requires sunglasses.\n**Edit: The currently installed driver is Gallium 0.4 on llvmpipe and no drivers are available in the additional drivers option.\n\nA: Better use the open source software form additional driver option.\n15.10 has some issues with fglrx driver as it has been stated in the release notes.\n", "Q: Cannot boot ubuntu 15.10 from Samsung 950 Pro PCIe NVME SSD I just installed desktop 15.10 but met the same problem described here http://ubuntuforums.org/showthread.php?t=2309056\nubuntu is installed on /dev/nvme0n1p2 ~ /dev/nvme0n1p5, which is not recognized by gparted\nI tried the boot-repair method but it told me \"An error occurred during the repair.\" when it finished running and it still couldn't boot. It sometimes ran into no such device error and booted into a grub cmd like this - \n> error: no such device: .......  \ngrub rescue>\n\nI have windows 10 installed on another disk. 950 pro is an empty disk. I tried both automatic install (remove everything on the disk) and manual partition(something else). Can somebody plz help?\nSee detailed error info here\n\nA: With cutting edge hardware, you need the newest versions of software, and sometimes even ppa's to get newer than in standard distributions.\nIf using gparted, be sure to download the newest version: gparted should be at least version 0.24.0-1 to recognize NVMe devices \nhttp://gparted.sourceforge.net/index.php \nSince 16.04 is now released.But be sure to review release notes:\nhttps://wiki.ubuntu.com/XenialXerus/ReleaseSchedule\nhttps://wiki.ubuntu.com/XenialXerus/ReleaseNotes\nhttp://releases.ubuntu.com/16.04/\n\nA: You can burn ubuntu 15.10 in a pen drive and load it up during boot. Start installation, and you will get an option to \"remove 15.10 and install it again\", select that option and continue. This should resolve your problem! \n", "Q: Ubuntu Touch - clearing down notifications on restart Today, I had two notifications in the morning. One for a text message and one for a Telegram message. The notification's icon at the top of the screen was highlighted as normal. Then while trying to make a call, my phone crashed and I needed to restart it. When it came back up the notifications for the two messages had gone and the notification icon (at the top of the screen) was normal.\nWhat settings do I need to change to stop this from happening in the future? As if the phone goes down, battery goes, crashes or anything like that. I do not want a situation where I do not know about messages, emails, calls and such like as the notification has been cleared down and not by me actioning them.\n\nA: This has been raised as a defect and awaiting a fix under https://bugs.launchpad.net/ubuntu/+source/indicator-messages/+bug/1388189\nThanks to pomsky for providing the details.\n", "Q: Scala build tool error in Ubuntu I installed Apache spark(1.5.2) and IPython(0.12.1) notebook in my Ubuntu 12.04. Before creating a profile for IPython specifically for PySpark, I want to install scala build tool. I followed the following query to build sbt.\nwget http://apt.typesafe.com/repo-deb-build-0002.deb `\n\n#Install the repository\nsudo dpkg -i repo-deb-build-0002.deb\n\n#Refresh\nsudo apt-get update\n\nI got the below error while running apt-get update.\nuser@user-VirtualBox:~/spark$ sudo apt-get update\nE: Malformed line 2 in source list /etc/apt/sources.list.d/sbt.list (dist)\nE: The list of sources could not be read.\n\nI searched the web to solve this issue. As per the instructions in the net the issue is in the line 2, I commented the line 2 ie \n# deb http://in.archive.ubuntu.com/ubuntu/ precise main restricted\ndeb-src http://in.archive.ubuntu.com/ubuntu/ precise main restricted\n\nBelow is the actual output of /etc/apt/sources.list\n$ cat /etc/apt/sources.list\n\n# deb cdrom:[Ubuntu 12.04.4 LTS _Precise Pangolin_ - Release amd64 (20140204)]/ dists/precise/main/binary-i386/\n# deb cdrom:[Ubuntu 12.04.4 LTS _Precise Pangolin_ - Release amd64 (20140204)]/ dists/precise/restricted/binary-i386/\n# deb cdrom:[Ubuntu 12.04.4 LTS _Precise Pangolin_ - Release amd64 (20140204)]/ precise main restricted\n# See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to\n# newer versions of the distribution.\ndeb http://in.archive.ubuntu.com/ubuntu/ precise main restricted\ndeb-src http://in.archive.ubuntu.com/ubuntu/ precise main restricted\n## Major bug fix updates produced after the final release of the\n## distribution.\ndeb http://in.archive.ubuntu.com/ubuntu/ precise-updates main restricted\ndeb-src http://in.archive.ubuntu.com/ubuntu/ precise-updates main restricted\n## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu\n## team. Also, please note that software in universe WILL NOT receive any\n## review or updates from the Ubuntu security team.\ndeb http://in.archive.ubuntu.com/ubuntu/ precise universe\ndeb-src http://in.archive.ubuntu.com/ubuntu/ precise universe\ndeb http://in.archive.ubuntu.com/ubuntu/ precise-updates universe\ndeb-src http://in.archive.ubuntu.com/ubuntu/ precise-updates universe\n## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu \n## team, and may not be under a free licence. Please satisfy yourself as to \n## your rights to use the software. Also, please note that software in \n## multiverse WILL NOT receive any review or updates from the Ubuntu\n## security team.\ndeb http://in.archive.ubuntu.com/ubuntu/ precise multiverse\ndeb-src http://in.archive.ubuntu.com/ubuntu/ precise multiverse\ndeb http://in.archive.ubuntu.com/ubuntu/ precise-updates multiverse\ndeb-src http://in.archive.ubuntu.com/ubuntu/ precise-updates multiverse\n## N.B. software from this repository may not have been tested as\n## extensively as that contained in the main release, although it includes\n## newer versions of some applications which may provide useful features.\n## Also, please note that software in backports WILL NOT receive any review\n## or updates from the Ubuntu security team.\ndeb http://in.archive.ubuntu.com/ubuntu/ precise-backports main restricted universe multiverse\ndeb-src http://in.archive.ubuntu.com/ubuntu/ precise-backports main restricted universe multiverse\ndeb http://security.ubuntu.com/ubuntu precise-security main restricted\ndeb-src http://security.ubuntu.com/ubuntu precise-security main restricted\ndeb http://security.ubuntu.com/ubuntu precise-security universe\ndeb-src http://security.ubuntu.com/ubuntu precise-security universe\ndeb http://security.ubuntu.com/ubuntu precise-security multiverse\ndeb-src http://security.ubuntu.com/ubuntu precise-security multiverse\n## Uncomment the following two lines to add software from Canonical's\n## 'partner' repository.\n## This software is not part of Ubuntu, but is offered by Canonical and the\n## respective vendors as a service to Ubuntu users.\n# deb http://archive.canonical.com/ubuntu precise partner\n# deb-src http://archive.canonical.com/ubuntu precise partner\n## This software is not part of Ubuntu, but is offered by third-party\n## developers who want to ship their latest software.\ndeb http://extras.ubuntu.com/ubuntu precise main\n# deb-src http://extras.ubuntu.com/ubuntu precise main\n\nAfter commenting, still I am getting Malformed line 2 in source list /etc/apt/sources.list.d/sbt.list error.\nHow can I solve this issue? As I need to solve this issue and need to create profile in IPython.\n\nA: It's complaining about the malformed line 2 in file /etc/apt/sources.list.d/sbt.list, instead of the /etc/apt/source.list file.\nYou can try to do the same thing to comment out the second line (or fix it with the correct format) of the /etc/apt/sources.list.d/sbt.list file.\n", "Q: GCC won't compile to an executable file I was able to reproduce this issue with a simple case (shown below). The problem in particular is that the output of compiling my main C file is a file with format data (returned by running file on the file). When the file is run, the command line gives the error cannot execute binary file: Exec format error. \nThe file, main.c contains the following code:\n#include <stdlib.h>\n\nint main(int argc, char* argv[]) \n{\n    return 0;\n}\n\nI am using this command to compile the code: gcc main.c -o main. \nOutput of gcc --version:\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.1) 4.8.4\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\nAny thoughts, comments, or ideas are appreciated.\n\nA: Your gcc might be corrupted, try to re-install gcc-4.8:\napt-get install --reinstall gcc-4.8\n\n", "Q: How do I get a Mac like Dock I want to get rid of the normal Ubuntu task bar and have a dock displayed at the bottom of my screen. I tried using Cairio Dock but I dont really like it and still could not get rid of the default dock besides putting it on autohide\n\nA: use Plank Dock to get a Mac like Dock in Ubuntu\n`sudo apt-get install plank`\n\nset the sensitivity to the lowest to avoid the taskbar\n", "Q: Unable to remove Multiple Nvidia Drivers Ubuntu There were multiple drivers installed on my Ubuntu 14.04 system, so I was unable to run OpenCL programs. I therefore did sudo apt-get remove --purge nvidia* to start all over again.\nHowever when I do  cat /proc/driver/nvidia/version It still returns: NVRM version: NVIDIA UNIX x86_64 Kernel Module 352.63 Sat Nov 7 21:25:42 PST 2015.\nAny ideas on how to remove all these drivers? (304.131, 352.39, 352.63) from my system?\nThanks.\nEdit : I also did sudo apt-get remove --purge cuda*, sudo /usr/bin/nvidia-uninstall and i'm still having the same issues.\nMoreover dmesg|grep NVRM gives the output:\n[ 10.206595] NVRM: The NVIDIA GPU 0000:01:00.0 (PCI ID: 10de:1380)\n[ 10.206595] NVRM: installed in this system is not supported by the 304.131\n[ 10.206595] NVRM: NVIDIA Linux driver release. Please see 'Appendix\n[ 10.206595] NVRM: A - Supported NVIDIA GPU Products' in this release's\n[ 10.206595] NVRM: README, available on the Linux driver download page\n[ 10.206595] NVRM: at www.nvidia.com.\n\n[ 10.206744] NVRM: The NVIDIA probe routine failed for 1 device(s).\n[ 10.206745] NVRM: None of the NVIDIA graphics adapters were initialized!\n[ 18.076754] NVRM: The NVIDIA GPU 0000:01:00.0 (PCI ID: 10de:1380)\n[ 18.076754] NVRM: installed in this system is not supported by the 304.131\n[ 18.076754] NVRM: NVIDIA Linux driver release. Please see 'Appendix\n[ 18.076754] NVRM: A - Supported NVIDIA GPU Products' in this release's\n[ 18.076754] NVRM: README, available on the Linux driver download page\n[ 18.076754] NVRM: at www.nvidia.com.\n\n[ 18.076960] NVRM: The NVIDIA probe routine failed for 1 device(s).\n[ 18.076961] NVRM: None of the NVIDIA graphics adapters were initialized!\n[ 18.130159] NVRM: The NVIDIA GPU 0000:01:00.0 (PCI ID: 10de:1380)\n[ 18.130159] NVRM: installed in this system is not supported by the 304.131\n[ 18.130159] NVRM: NVIDIA Linux driver release. Please see 'Appendix\n[ 18.130159] NVRM: A - Supported NVIDIA GPU Products' in this release's\n[ 18.130159] NVRM: README, available on the Linux driver download page\n[ 18.130159] NVRM: at www.nvidia.com.\n\n[ 18.130394] NVRM: The NVIDIA probe routine failed for 1 device(s).\n[ 18.130395] NVRM: None of the NVIDIA graphics adapters were initialized!\n[2599693.694878] NVRM: loading NVIDIA UNIX x86_64 Kernel Module 352.63 Sat Nov 7 21:25:42 PST 2015\n[2601583.725270] NVRM: API mismatch: the client has the version 352.39, but\n[2601583.725270] NVRM: this kernel module has the version 352.63. Please\n[2601583.725270] NVRM: make sure that this kernel module and all NVIDIA driver\n[2601583.725270] NVRM: components have the same version.\n\n\nA: Upon upgrading from 14.04 to 16.04 (immediately after upgrading from 12.04 to 14.04), X11 errored on launch similarly, with other versions of the Nvidia driver:\nnvidia api mismatch the nvidia kernel module has version 340.96 but this nvidia driver component has version 304.131\nI got a working X11 desktop through the following steps:\nsudo aptitude remove nvidia-340 nvidia-304\nsudo dpkg-reconfigure xserver-xorg\nreboot # (into low-res X11)\n\nUnity dash/launcher --> Additional Drivers --> enable proprietary Nvidia-340\nreboot again\nAnswers to the following question were helpful:\nCannot properly boot into Ubuntu after installation of Nvidia driver\n\nA: after you run \"sudo apt-get remove\" run the following command;\nsudo apt-get autoremove. This command will remove all unnecessary installation files. Try that to see if those folders gets removed. \n", "Q: I installed Ubuntu only, not dual-boot. But now I can't find my drives I recently clean installed Ubuntu without dual boot, so everything was erased, but now I can't seem to find where my C and D drives are located. \nHere are the results of some commands that I tried:\nsudo fdisk -l\nDisk /dev/sda: 160.0 GB, 160041885696 bytes\n255 heads, 63 sectors/track , 19457 cylinders, total 312581808 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/0 size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifiers: 0x000cf109\n\nDevice     Boot        Start         End       Blocks    Id  Systems\n/dev/sda1   *          2048       308457471  154227712   83  Linux\n/dev/sda2         308459518       312580095   2060289     5  Extended\n/dev/sda5         308459520       312580095   2060288    82 Linuxswap/Solaris\n\nmount \n/dev/sda1 on / type ext4 (rw, errors = remount - ro)\nproc on /proc type proc (rw,noexec, nosuid, nodev)\nsysfs on /sys type sysfs (rw,noexec,nosuid,nodev)\nnone on /sys/fs/cgroup type tmpfs (rw)\nnone on /sys/fs/fuse/connections type fusectl (rw)\nnone on /sys/kernel/debug type debugfs (rw)\nnone on /sys/kernel/security type securityfs (rw)\nnone on /dev type devtmpfs (rw, mode = 0755)\ndevpts on /dev/pts type devpts (rw, noexec, nosuid, gid = 5, mode = 0620)\ntmpfs on /run type tmpfs (rw,noexec, nosuid, size = 10%, mode = 0755)\nnone on /run/lock type tmpfs (rw, noexec, nosuid, nodev, size = 5242880)\nnone on /run/shm type tmpfs (rw,nosuid,nodev)\nnone on /run/user type tmpfs (rw,noexec,nosuid,nodev,size=104857600,mode=0755)\nnone on /sys/fs/pstore type pstore (rw)\nsystemd on /sys/fs/cgroup/systemd type cgroup (rw,noexec,nosuid,nodev,none,name=systemd)\ngvfsd-fuse on /run/user/1000/gvfs type fuse.gvfsd-fuse (rw,nosuid, nodev, user = dangmanhtruong)\n\nsudo lsblk\nNAME              MAJ:MIN   RM      SIZE    RO    TYPE   MOUNTPOINT\nsda                 8:0      0     149.1G    0    disk    \n--sda1              8:1      0     147.1G    0    part   /\n--sda2              8:2      0         1K    0    part\n--sda5              8:5      0         2G    0    part   [swap]\n\nPlease help me thank you very much\n\nA: There is no C: partition and no D: partition anymore. As you said that you installed Ubuntu by choosing the option to use the whole disk for Ubuntu, of course the disk was erased completely.  \nThe C: partition on which most probably the Windows operating system was located and the D: partition on which most probably your personal data was located before are gone forever.  \nLet's explain it as easy as possible to understand the difference ... your new disk layout now is :\nsda1 (formerly C:) used for Ubuntu and sda2 / sda5 (formerly D:) used for linux-swap\n", "Q: Lenovo G50 cannot connect to Wi-Fi I am new to Ubuntu. ^^\nIt seems I cannot connect to Wi-Fi. When I click on the Networking logo on the top bar, it only shows \"Ethernet Network\" and \"disconnected\".\n\n\n*\n\n*Version of Ubuntu is 14.04 LTS.\n\n*I am using a Lenovo G50 laptop.\n\n*Ubuntu is on a 32GB SanDisk Extreme USB 3.0.\n\n*I chose to boot my USB in Boot Menu (fn + F12)\n\n*On boot, I chose to try Ubuntu without installing it.\n\n*Enable Networking is ticked.\n\n*I did a little research and tried different methods, but they couldn't fix my problem.\n\n*I learnt that there is this module called wlan0 that sort of lets me connect to a Wi-Fi network, but it did not show up when I did rfkill list all.\n\n\n\nHere are some information that may be useful.\nrfkill list all:\n0: ideapad_wlan: Wireless LAN\n        Soft blocked: no\n        Hard blocked: no\n1: ideapad_bluetooth: Bluetooth\n        Soft blocked: Yes\n        Soft blocked: no\n\nifconfig:\neth0      Link encap:Ethernet  HWaddr 28:d2:44:ad:17:6a\n          UP BROADCAST MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 MB)  TX bytes:0 (0.0 KB)\n\nlo        Link encap:Local Loopback (bla bla bla)\n\nlspci -knn | grep 0280:\n02:00.0 Network controller [0280]: Broadcom Corporation BCM43142 802.11b/g/n [14e4:4365] (rev 01)\n\nsudo rfkill -r ideapad-laptop:\nSome say this works but for me it just removed all modules.\nlsb_release -a:\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 14.04.4 LTS\nRelease:        14.04\nCodename:       trusty\n\n\nPlease do comment if you need any more information. As said before, I am a noob so I have little idea what info to give and what to solve the problem.\n\nA: try installing the bcmwl file from  the boot usb\n\nA: First connect your notebook with an ethernet cable to the wired network and install the Ubuntu system. After having finished boot into the installed Ubuntu operating system and install the proprietary BROADCOM wireless drivers. Open a terminal and execute these commands :  \nsudo apt get update  \nsudo apt-get install bcmwl-kernel-source  \nsudo reboot\n\n", "Q: Unable to SSH to a host within my home LAN by using the hostname or local IP address I want to access the SSH server on a Raspberry Pi (with Raspbian OS) from an SSH client on a X86_64 computer with Ubuntu 14.04, both located inside the same home LAN.\n I am able to SSH from the Raspberry Pi using the following command: ssh pi@73.***.***.***; where 73.***.***.*** is the internet-routable IP address assigned to me by the ISP. But when I try ssh pi@pi.local the terminal immediately returns: ssh: Could not resolve hostname pi.local: Name or service not known. Similarly, when I try ssh pi@raspberrypi.local the terminal returns ssh: Could not resolve hostname raspberrypi.local: Name or service not known.\nFurthermore, when I try ssh pi@raspberrypi then the terminal prompts me to input the password for pi@raspberrypi. After I enter the password then nothing happens; there's no error message, there's no feedback at all. There is just a blinking cursor at the start of a blank line. The blinking cursor is NOT after a shell prompt ie. it does not appear after the foo@localhost:~$ prompt. There are the similar results when I try ssh pi@192.168.2.16 as when I tried ssh pi@raspberrypi.\nI want and I think I should be able to do SSH by specifying the local IP address or the hostname, instead of relying on the public IP address. If it's possible, how can I achieve this? Somebody suggested that I should add an entry to the (Ubuntu) computer's hosts file in order to resolve the name resolution issue. I am quite clueless about the subject of host files and I do not know how to proceed. Can somebody please help?\n\nA: You can edit file hosts that is located in etc directory:\nsudo nano /etc/hosts\n\nAt the end of the file you put the follow line:\n192.168.xxx.xxx pi.local\n\nRemeber that 192.168.xxx.xxx needs to be the IP address of your raspberry.\n\nA: There's a file in your /etc directory named hosts. Add the entries to the file to resolve the hostnames. You may associate raspberrypi with 192.168.2.16 so as to make your system to resolve raspberrypi to 192.168.2.16. By default there's only one entry in the file which is localhost associated to 127.0.0.1. The syntax is pretty simple consisting of IP address and hostname only.\n127.0.0.1 localhost\n\nMake sure you do not have a # in front of your entry or it'll be nothing more than a comment in a code.\nEvery time you type in an IP address it gets resolved at system level using this file. If the hostname isn't found in this file the the hostname is forwarded to your default gateway for its resolution. It keeps on getting forwarded depending on the design of network at the end of which you finally receive an error hostname could not be resolved.\nYou need to understand this hierarchy and find out where, exactly, is the problem. Since you're working with a LAN, I don't think it'd be so complicated.\n", "Q: Delayed touchpad scroll event causes crazy zooming if top of the page is reached I have been experiencing this issue for years and that is quite annoying :)\nIf I scroll down using \"two finger\" touchpad gesture, the scroll itself takes effect immediately. But if I'm on the top of the page and I (occasionally) scroll up and then (within 2-3 secs after finishing scrolling and releasing the touchpad) press Ctrl, system interprets these two events (scroll and ctrl) as a single Scroll+Ctrl event as and starts zooming everything crazy, even though these events are not overlapping (and even have 2-3 seconds between them).\nTypical scenario: I'm scrolling a page, hit the top of the page, wait a little (1-3 sec), then press Ctr-Tab and together with switching the tab, I also get both of my tabs content zoomed crazily (typically ~700% in chrome). And that's somewhat annoying, because you have to 1) wait until chrome re-renders it with a new scale 2) press Ctrl-0 3) wait until in re-renders it again with a default scale :)\nAn interesting detail is that I do not observe this behavior in any application if scroll event was successfully \"dispatched as a scroll\": if I'm not hitting the top of the page yet, and scroll up, and press Ctrl immediately - no zooming takes place (as if - as soon as it is not the top of the page - this \"scroll\" was successfully \"eaten\"=\"dispatched\" by the target app and removed from event queue).\nSystem and UI themselves run super-smoothly so it's definitely not an event-handling lag.\nThis guy describes similar experiance here: Mouse wheel scroll events persist after hitting meta key\nOr there might be a tweak for Unity that disables zooming scroll behavior at all? (like this: How to disable ctrl + scroll zoom in Lubuntu or openbox )\nUbuntu 14.04.4\nAcer Aspire V5-171\nGraphics: Intel HD 4000 (out-of-box drivers)\n\nA: It seems like I'm not the only one [1][2] concerned with that issue and that is a Xor bug.\nThe only workaround I found which kind of works is this extension for chrome.\nUPD Extension does not seem to work properly with last version of chrome, but doing synclient CoastingSpeed=0 seems to handle everything perfectly for me without any negative side effects.\n", "Q: ubuntu 14.04 mounting usb with \"can't read superblock \" My usb was working pretty normally and now it is unable to open showing the following message:\nError mounting /dev/sdb1 at /media/sooraj/7D64-9145: Command-line `mount -t \"vfat\" -o \"uhelper=udisks2,nodev,nosuid,uid=1002,gid=1002,shortname=mixed,dmask=0077,utf8=1,showexec,flush\" \"/dev/sdb1\" \"/media/sooraj/7D64-9145\"' exited with non-zero exit status 32: mount: /dev/sdb1: can't read superblock\n\n\nA: You need to repair your filesystem. You can do it with testdisk:\nsudo apt-get install testdisk\nsudo testdisk\n\n>Create a new log file\n[Choose Disk]\n>Intel/PC partition\n>Advanced\n[Choose Partition]\n>Boot\n>Repair FAT\n[Accept Defaults and Write]\n>(Q)uit until exited\n\nSource link here\n", "Q: If I uninstall windows 10 from my laptop to install Ubuntu will I beable to go back to windows 10 at a later time I have an ASUS X555LAB it came with Windows 10 installed but did not come with any windows disk. I want to know if I completely wipe my HDD and install Ubuntu will I be able re-install windows 10 at a later date if I wanted to...\nOr should I shrink down my windows partition as much as possible and dual boot. I have never been a big fan of dual booting but I want to make sure I dont lose lose windows 10 forever.   \n\nA: Your second option is probably the best because as you said \n\nWindows 10 installed but did not come with any windows disk\n\nmeaning that if you completely reinstall you will lose it\n\nA: Did ASUS install Windows 10 on your machine as default Operating System?\nOr did you buy Win 10 in the Windows Store or get it as (free) upgrade from Win 7+?\nIn the first case, you should have the product key around somewhere. Probably on a sticker on the device. You can re-activate the Windows installation with that key, in the same fashion as an older Windows edition would be activated.\nIn the latter case (and some more, see Source link below), Microsoft has given you a Digital Entitlement, and will automatically activate during the installation process\n\nDigital entitlement is a new method of activation in Windows 10 that doesn't require you to enter a product key.\n\nSo, if you have the Product Key or have a Digital Entitlement, you can safely perform a clean install on the full HDD without losing the possibility to return to the previously activated Windows version.\nSource: http://windows.microsoft.com/en-us/windows-10/activation-in-windows-10\nWindows Media Creation Tool (needs Windows OS): https://www.microsoft.com/software-download/windows10\n\nA: In order to go back to Windows installation I would recommend to back it up using Clonezilla or from Windows use third party tool called Macrium Reflect. Using the backup you can go back any time you wish.\n\nA: Go for the resizing and dual boot. Whenever you are comfortable with Ubuntu later, you can reinstall and go for it all the way.\nThat's how I went. Started dual boot 2 year's ago on a W7, but when W10 came, and U14.04, I wiped the drive. Now looking to go to U16.04 soon.\n\nA: *\n\n*As explained by others, dual boot will be a better option for you compared to   completely wiping out your HDD. You will get best of both worlds. \nIf you are considering this option, do not disturb your C drive(Windows 10 installation). Instead delete any other secondary drive for Ubuntu installation.\n\n*Also as you don't have any installation disk provided with Windows 10, cleaning HDD might get you in trouble while re-installation. Though having Product Key might be helpful. Still if you prefer to go by this option and want to revert back to Windows at a later point in time, have a look at following links:\nhow to change the os ubuntu 14.04 to windows completely? \nand\nHow to remove Ubuntu and put Windows back on?\n\n*Looking at how concerned you are about not losing Windows 10, you might consider using Ubuntu on Virtual machine.\n\nA: Usually the Windows OEM Edition (preinstalled) comes with NO physical backup disk (CD/DVD/USB disk). For anti-piracy reasons. But it comes with a RECOVERY partition on the internal disk, containing all the Windows installation files. You can put those files in an ISO file, like this:   \nMS-create bootable ISO from recovery\nMake sure you have a backup for the Windows Product Key too (write it on paper, in a txt file, whatever). This is important! After you reformat your internal disk, Product Key is unrecoverable.\nMake a bootable DVD or USB from the ISO file. Test your bootable medium and make sure it works (it boots up). That's all.\n", "Q: Ubuntu booting into gnome not Unity First I have installed Gnome and removed unity. But now I want back unity. So I again installed unity and purged gnome. Problem is on booting it boots with gnome animation and before it i have a black screen which hangs for around 10sec. I want to get Unity booting back. Please help\n\nA: Logout and there will be a setting icon,you can select the the Unity from it.\nOr\nTry this command on terminal 'unity --replace'\n", "Q: Showing error when Installing ubuntu on my HP Probook 450 G2 I am trying to install Ubuntu on my HP Pro-book 450 G2.\nBut after booting when I select Try Ubuntu or Install Ubuntu it takes some time and goes to a black screen and then shows the Ubuntu loading screen for few seconds and then returns to the black screen again and finally stays there.\nAnd there are some errors in this screen.\n\n\n*\n\n*[drm:gen8_irq_handler [i915_bpo]] ERROR The master control interrupt lied (SDE)!\n\n*[drm:gfx_v8_0_ring_test_ring [amdgpu]] ERROR amdgpu: ring 0 test failed (scratch(0xC040)=0xCAFEDEAD)\n\n*amdgpu 0000:03:00.0: Fatal error during GPU init\n\n\nSo I have turned of hybrid GPU from my bios and then tried again. And this time only number 1 error from the above was shown repeatedly. Every time I tried to boot this error was showing.\nAnd I was left in the initramfs command line... I don't know how to fix this issue.\nIS there any solution to this problem?\nHow can I install Ubuntu on this laptop?\nWill be waiting for your answers.\nThanks\n\nA: I had to do two things to get an installation of Ubuntu (not a dual boot) to boot straight Ubuntu.\n\n*\n\n*Go into the bios and make sure that in \"Boot Mode\" \"UEFI Native (without CSM)\" is selected. So NOT \"legacy\" or \"UEFI Hybrid (with CSM)\".\n\n*Also in the bios, use a customized boot option. Add as the path in the box that appears when you click on the option (leave off the double quotes when enetering) \"\\EFI\\ubuntu\\grubx64.efi\". That is for when secure boot is not selected. If secure boot is selected, I think it should be \"\\EFI\\ubuntu\\shimx64.efi\", but I didn't try that.\n\nBefore I did 1, the boot did not recognise any OS at all. After 1, the computer went into a \"reset system\" loop and I could only boot by going to F9 in the bios and selecting Ubuntu every time. After 2, the boot to Ubuntu was automatic.\n", "Q: How to fix the problem of drop-down menus being transparent and not readable in Kubuntu 15.10 The Problem: The task manager dropdown menus are all transparent and not readable at all. The same goes for all the dropdown menus of libre office. I have tried to change the desktop theme but the transparency kept on appearing on all those menus hindering me from reading them. Disabling all the effects of the desktop (ALT + Shift + F12) did not help at all as well.\nObjective: I need to remove all the opacity and transparency of those menus. I simply need a clear readable desktop environment.\nAny suggestions, comments or solutions will be greatly appreciated.\nNote: I am using Kubuntu 15.10 (Not a fresh installation. I have just installed the KDE desktop environment on top of the Ubuntu Mate 15.10 then decided to use it as my default.\n\nA: Head to\nSystem Settings > Workspace Theme > Desktop Theme > Theme\n\nChoose style you like, Oxygen seems to be darkest\n\n\nA: In my case it was the Application Colour Scheme in: Settings -> Appearance -> Colour. \nChange the Theme with a Darker one and see how it goes. My menus were white and my theme dark so no menus were visible when I click on a drop-down menu.\n\n", "Q: How to unpair bluetooth device from the command line How do you unpair a bluetooth device from the command line?\nI was able to pair my computer with an Android phone via bluetoothctl, but there doesn't seem to be any \"unpair\" option. Even though I removed the pairing on the phone, running paired-devices still lists it. I've tried running disconnect and remove but they say my device doesn't exist.\n\nA: first of all start your Bluetooth from System settings.\nOpen terminal and type:\nbluetoothctl\n\nthen you should see the list of devices you have paired with and their corresponding MAC address. If you do not, type:\npaired-devices\n\nTo un-pair a device type:\nremove aa:bb:cc:dd:ee:ff\n\nreplace aa:bb:cc:dd:ee:ff with the MAC address of the device to un-pair.\nthere is no un-pair commmand\n\nA: In case somebody looks for an up to date answer.\nThe interface of bluetoothctl has changed a bit. The following answer is valid for Ubuntuu 20.04 LTS:\nTo unpair, now do the following:\nOpen the bluetooth command line by entering\nbluetoothctl\n\nin the command line. After this you get a list of all paired bluetooth devices by entering paired-devices\n[bluetooth]# paired-devices\nDevice F4:4E:FD:48:08:FF SoundCore mini\nDevice 30:C0:1B:79:6B:FF JBL GO 2\nDevice 7C:96:D2:88:2A:FF Soundcore Motion+\n\nNow you can remove pairing of the desired devices with remove mac:id and control the result with executing `paired-\n[bluetooth]# remove 7C:96:D2:88:2A:FF\n[DEL] Device 7C:96:D2:88:2A:FF Soundcore Motion+\nDevice has been removed\n[bluetooth]# paired-devices\nDevice F4:4E:FD:48:08:FF SoundCore mini\nDevice 30:C0:1B:79:6B:FF JBL GO 2\n\nnow you can leave the bluetooth command line by entering exit\n", "Q: No networking: Failed to bring up eth0 The networking service fails to start / doesn't start on reboot.\nRestarting networking (via systemctl): networking.serviceJob for networking.service failed because the control process exited with error code.\n\nI can still access the server via remote console, but nothing else, since without network, there is no way out nor in.\nsystemctl status networking.service says:\n● networking.service - Raise network interfaces\n   Loaded: loaded (/lib/systemd/system/networking.service; enabled; vendor prese\nt: enabled)\n  Drop-In: /run/systemd/generator/networking.service.d\n           └─50-insserv.conf-$network.conf\n   Active: failed (Result: exit-code) since Mo 2016-04-18 06:53:11 UTC; 43s ago\n     Docs: man:interfaces(5)\n  Process: 3551 ExecStart=/sbin/ifup -a --read-environment (code=exited, status=\n1/FAILURE)\n  Process: 3546 ExecStartPre=/bin/sh -c [ \"$CONFIGURE_INTERFACES\" != \"no\" ] && [\n -n \"$(ifquery --read-environment --list --exclude=lo)\" ] && udevadm settle (cod\ne=exited, status=0/SUCCESS)\n Main PID: 3551 (code=exited, status=1/FAILURE)\n\nApr 18 06:53:11 h2502988.stratoserver.net ifup[3551]: For info, please visit htt\nps://www.isc.org/software/dhcp/\nApr 18 06:53:11 h2502988.stratoserver.net ifup[3551]: Usage: dhclient [-4|-6] [-\nSNTP1dvrx] [-nw] [-p <port>] [-D LL|LLT]\nApr 18 06:53:11 h2502988.stratoserver.net ifup[3551]:                 [-s server\n-addr] [-cf config-file] [-lf lease-file]\nApr 18 06:53:11 h2502988.stratoserver.net ifup[3551]:                 [-pf pid-f\nile] [--no-pid] [-e VAR=val]\nApr 18 06:53:11 h2502988.stratoserver.net ifup[3551]:                 [-sf scrip\nt-file] [interface]\nApr 18 06:53:11 h2502988.stratoserver.net ifup[3551]: Failed to bring up eth0.\nApr 18 06:53:11 h2502988.stratoserver.net systemd[1]: networking.service: Main p\nrocess exited, code=exited, status=1/FAILURE\nApr 18 06:53:11 h2502988.stratoserver.net systemd[1]: Failed to start Raise netw\nork interfaces.\nApr 18 06:53:11 h2502988.stratoserver.net systemd[1]: networking.service: Unit e\nntered failed state.\nApr 18 06:53:11 h2502988.stratoserver.net systemd[1]: networking.service: Failed\n with result 'exit-code'.\n\nMy /etc/network/interfaces looks like: \n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# The primary network interface\nauto eth0\niface eth0 inet dhcp\n\nWhere can I start to debug?\nThanks for any hint!\nRegards, K\n# sudo ifup --verbose eth0\nConfiguring interface eth0=eth0 (inet)\n/bin/run-parts --exit-on-error --verbose /etc/network/if-pre-up.d\nrun-parts: executing /etc/network/if-pre-up.d/ethtool\nrun-parts: executing /etc/network/if-pre-up.d/wireless-tools\nrun-parts: executing /etc/network/if-pre-up.d/wpasupplicant\n\n/sbin/dhclient -1 -v -pf /run/dhclient.eth0.pid -lf /var/lib/dhcp/dhclient.eth0.leases -I -df /var/lib/dhcp/dhclient6.eth0.leases eth0  \nInternet Systems Consortium DHCP Client 4.2.4\nCopyright 2004-2012 Internet Systems Consortium.\nAll rights reserved.\nFor info, please visit https://www.isc.org/software/dhcp/\nUsage: dhclient <snip>\nFailed to bring up eth0.\n\n\nA: I am assuming that you have just installed/upgraded to a newer OS such as Ubuntu 16.04,  and due to the departure from the tradition interface naming schemes such as eth0 or eth1, the system cannot start up you interface.\nTry editing your /etc/network/interfaces to either use ens32 or ens192 instead of eth0 like\n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# The Ethernet interface\nauto ens192\niface ens192 inet dhcp\n\nThat should enable you network interface restart. I hope it helps.\nFor  details about the predictive network interface changes \nhttps://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/\n\nA: Not sure if this is still useful: It seems that the dhclient no longer has the \"-I\" or \"-df\" option, which according to the man page does DDNS:\n\n-I     Use the standard DDNS scheme from RFCs 4701 & 4702.\n\nOnce I remove that option from the command line, dhclient is able to bring up eth0.\n[EDIT]: Now if I could find where that \"-I\" option is...\n\nA: This just happened to me.  The reason was that there was a package dependency inconsistency that interrupted my upgrade from trusty to xenial, so some package versions were inconsistent.  In my case the inconsistency was caused by squid3 and ca-certificates-java.\nI restored the network connection by running just dhclient eth0.  After resolving the package inconsistency by removing the offending packages and running apt-get install -f, I ran apt-get dist-upgrade and apt-get install ubuntu-standard.  This resolved my problem completely.\nWhat led me to suspect the inconsistency is that /sbin/ifup binary contained the outdated dhclient command line with the no longer supported -I option.  It must be a package version inconsistency.\n\nA: I had a similar issue as OP and Wei Wang, where ifup was trying to run dhclient with the -I option, but my dhclient was an older version which didn't support it. My guess is this was due to my previous hacky way to download/install the Xenial (16.04) Chromium while keeping my system on Trusty (14.04), it must have also upgraded some other parts of my system.\nLong story short, my fix was to manually download and install the relevant packages related to dhclient in upstream Xenial. There's three packages required, and it needs to be installed in the following order:\n\n\n*\n\n*libisc-export160 (https://ubuntu.pkgs.org/16.04/ubuntu-main-amd64/libisc-export160_9.10.3.dfsg.P4-8_amd64.deb.html)\n\n*libdns-export162 (https://ubuntu.pkgs.org/16.04/ubuntu-main-amd64/libdns-export162_9.10.3.dfsg.P4-8_amd64.deb.html)\n\n*isc-dhcp-client_4.3.3 (https://ubuntu.pkgs.org/16.04/ubuntu-main-amd64/isc-dhcp-client_4.3.3-5ubuntu12_amd64.deb.html)\n\n\nAfter that, dhclient --version showed I had 4.3.3 which supports the -I option, and I was able to use ifup again.\n\nA: Try this:-\nsudo ifdown --exclude=lo -a && sudo ifup --exclude=lo -a\n\nSo replace networking restart with ifdown... && ifup....\nJust as an aside: ifconfig has also been deprecated for a long time - use ip from the package iproute2 \nYou could try also\nifconfig eth0 down && ifconfig eth0 up\n\n(or whatever your network interface is called) to restart the network.\n\nA: @jos mentions in a comment on the original post:\n\nThe presence of the \"Usage:...\" lines makes it look as if the dhclient command fails because there is an error in the parameters...\n\nI had this precise problem and the verbose logging was the hint.\nifup --verbose eth0\nLook for output explaining DHCP parameters. \nI then took the output from:\n/sbin/dhclient -4 -v -pf /run/dhclient.eth0.pid -if /var/lib/dhcp/dhclient.eth0.leases -I -df /var/lib/dhcp/dhclient6.eth0.leases eth0\nto simply:\n/sbin/dhclient -4 -v -pf /run/dhclient.eth0.pid eth0 and then I got an address.\nI believe some software update made dhclient get out of sync what was happening on my Debian 7.11 system.\n", "Q: Automating SSH login gives unresponsive remote-shell, dropping back to client-terminal (without errors) I have a problem with the tool expect under Ubuntu 14.04 LTS. I want to automate ssh logins to some Sophos UTM Firewalls and evelate my rights directly after with \"sudo su -\" and the correct password. I don't have to worry about plain text passwords, because my script runs directly out of the KeePass URL field (doubleclick executes the script and fills it with the correct passwords via agrument/KeePass {Placeholder} behind the script).\nI managed to get all of this done, except for having a remote-root shell, which is not executing any commands and \"dropping the connection\" back to my ubuntu system. So the command I'm trying to run remotely is not excecuting for 4-5 seconds and then gets suddenly executed on the ubuntu system, without telling me what happened.\nWhat do I have to do, to have fully functioning remote-shell?\nSSH-Keys and direct root-login is not a solution for me, as we are having too much Sophos UTMs out there.\nExplained stuff happening:\nsshtool.sh:\n#!/usr/bin/expect -f\nspawn sshpass -pPASSWORD ssh -t loginuser@192.168.1.254 \"sudo su -\"\nexpect -- \"oot's password:\"\nsend \"PASSWORD\\r\"\nexpect -- \"/root #\"\nexpect eof\n\n\n\nWhat happens in the terminal:\nvct@vct-virtual-machine:~$ ./sshtool.sh\nspawn sshpass -pPASSWORD ssh -t loginuser@192.168.1.254 sudo su -\nroot's password:\nutm:/root # whoami\n# *enter*\n# not reacting for 4-5 seconds\nvct@vct-virtual-machine:~$ whoami\nvct\nvct@vct-virtual-machine:~$\n\nChanging the script like this, doesn't help with the dropping connection issue:\nsshtool.sh:\n#!/usr/bin/expect -f\nspawn ssh loginuser@192.168.1.254\nexpect -- \"password:\"\nsend \"PASSWORD\\r\"\nexpect -- \"/home/login > \"\nsend -- \"sudo su -\\r\"\nexpect -- \"oot's password:\"\nsend \"PASSWORD\\r\"\nexpect -- \"/root #\"\nsend -- \"whoami\\r\"\nexpect eof\n\n\nvct@vct-virtual-machine:~$ ./sshtool.sh\nspawn ssh loginuser@192.168.1.254\nloginuser@192.168.1.254's password:\nLast login: Mon Apr 18 09:14:41 2016 from 192.168.1.44\n\n\nSophos UTM\n(C) Copyright 2000-2015 Sophos Limited and others. All rights reserved.\nSophos is a registered trademark of Sophos Limited and Sophos Group.\nAll other product and company names mentioned are trademarks or registered\ntrademarks of their respective owners.\n\nFor more copyright information look at /doc/astaro-license.txt\nor http://www.astaro.com/doc/astaro-license.txt\n\nNOTE: If not explicitly approved by Sophos support, any modifications\n      done by root will void your support.\n\n<M> loginuser@utm:/home/login > sudo su -\nroot's password:\n# Following \"whoami\" directly executed by the script itself works fine\n<M> utm:/root # whoami\nroot\n# After 4-5 seconds, it's dropping the connection again\n<M> utm:/root # vct@vct-virtual-machine:~$\n\nThanks in advance!\n\nA: I had a problem similar to this. The issue was that my remote .bashrc file had some lines to do nothing if not running interactively.\n", "Q: what version of ubuntu should i install on my laptop should i install the x32 or the x64 and what is the difference? also is ubuntu 14 better then ubuntu 15? Also what is the difference in all the flavors of ubuntu\n\nA: The platform you choose (x32,x64) depends on your CPU architecture. Check your CPU. Which version of Ubuntu is better? It depends on your needs. Read carefully this page and you will get it. https://wiki.ubuntu.com/LTS\n", "Q: I can't download new Plasma widgets and Plasma themes in Kubuntu 16.04 LTS Each time I try to download the new Plasma widget from the Plasma Add-On Installer, I get the following error: \nLoading of providers from file: http://download.kde.org/ocs/providers.xml failed\n\nScreenshot: \nThe same problem is also happening when I am trying to install new theme. Please check the below screenshot for clarification:\n\nAny suggestions, comments or answers will always be appreciated. Thanks.\n\nA: I found about 20 files in /etc/xdg/ that all reference \nProvidersUrl=http://download.kde.org/ocs/providers.xml\n\nI think the download.kde server currently sends a redirect to \nhttps://autoconfig.kde.org/ocs/providers.xml\n\nBut I guess its not followed.\n\nA: I think this python code will help you out..\nimport os\n\nos.chdir(\"/etc/xdg\")\nfile_list=os.listdir(\"/etc/xdg\")\n\nhome=os.getenv(\"HOME\")\n\nos.mkdir(home+'/.kde/share/apps/providers')\n\nprovider=\"\"\"<providers>\n<provider>\n<id>api.kde-look.org</id>\n<location>https://api.kde-look.org/ocs/v1/</location>\n<name>api.kde-look.org</name>\n<termsofuse>https://api.kde-look.org/content/terms</termsofuse>\n<register>https://api.kde-look.org/register</register>\n<services>\n<person ocsversion=\"1.6\"/>\n<content ocsversion=\"1.6\"/>\n</services>\n</provider>\n</providers>\"\"\"\n\nprov=open(home+'/.kde/share/apps/providers/providers.xml', 'w')\nprov.write(provider)\nprov.close()\n\ns_add=\"ProvidersUrl=\"+home+\"/.kde/share/apps/providers.xml\\n\"\n\nfor i in range(len(file_list)):\n    try:\n    with open(file_list[i]) as t:\n\n        new=\"\"\"\"\"\"\n\n        x=1\n        for line in t:\n            if \"ProvidersUrl=http://download.kde.org/ocs/providers.xml\" in line:\n                new=new+s_add\n                print file_list[i] + \"====> is changed\"\n\n            else:\n                new=new+line\n\n\n    t.close()\n    with open(file_list[i],'w') as f:\n        f.write(new)\n\n    f.close()\nexcept IOError:\n    pass\n\nAnd sorry if my code is bad!..Just did my best!!\n\nA: For me this worked:\ncd /etc/xdg\nkhotnewstuff4 plasmoids.knsrc\n\nI adapted this from here https://bugs.launchpad.net/ubuntu/+source/kde-runtime/+bug/1610665.\nThe bug is also discussed here http://defrances.co/post/kdelook/.\n\nA: Type https://autoconfig.kde.org/ocs/providers.xml in browser.\nCopy contents.\nCreate a providers.xml file and paste them into it.\nGo to /etc/xdg/\nChange this line \nProvidersUrl=http://download.kde.org/ocs/providers.xml\n\nto\nProvidersUrl=file:///path/to/your/custom/xml/file/providers.xml\n\nin all the files that have it.\nI'm sure there is a single terminal command you can use to do that in all files, but I don't know what that is. Maybe someone can improve this answer. I suggest changing it on a single file first and testing the corresponding app first. The file that corresponds to the plasma add-on installer mentioned should have a pretty obviously fitting name.\nI found the info in this guide and followed it myself for a different error:\nhttps://bugs.launchpad.net/ubuntu/+source/kde-runtime/+bug/1610665\nI'm not sure why just changing the line to\nProvidersUrl=https://autoconfig.kde.org/ocs/providers.xml\n\nwouldn't work. I can't test that, because I don't have the question's error.\nOr why the guide uses a local path url that doesn't seem to work on my end...I posted here what worked for me.\n", "Q: I installed unity tweak tool but cant find it in dash I installed unity tweak tool in the terminal but i cant find it to run in my dash. does anyone know how to run it\n\nA: Since Unity-Tweak-Tool is normaly not a CLI tool you should be able to find it in Dash after a logout/reboot, but if not simply run it from terminal:\nunity-tweak-tool\n\n\nA: Simply putting 'Tweak' in the Dash should be enough:\n\n", "Q: How do you make my root system behave like a live system? One of my friends doesn't have an hdd , so I will install linux distro on a usb stick. It will be a full install just like installing to hdd but it will install on a flash stick instead of hdd. \nThe problem here:  USB 2.0 sticks are very slow , If you write a lot on it , it will wear out quickly because if have limited number of write cycles \nso I want to do a full system install on a usb stick, and make it something, like read only filesystem so that any changes like installing packages will written on ram , at the end before I shutdown run a script to write all the changes on the flash drive over the old system. \nthis is good for flash sticks because all writes are in ram and then are written to flash drive only ONCE per session when you shutdown. \nI think this is possible because Puppy Linux  does a similar thing when you shutdown it asks you to save all the changes you made to a sfs file and it will be loaded next time you boot. I want to do the same thing but instead of the sfs file I want the changes to be written over the old system , also I don't want to run the full system on ram like puppy. \nI read about overlayfs and rsync , but didn't quite understand , I need some help here.\nI tried the following options:\n\n\n*\n\n*install the system on flash stick and use it just like HDD ? I tried, but was painfully slow. Maybe because of the simultaneous read and writes. \n\n*live CD was very fast, but the customization I made will be lost if I shutdown. \n\n*live cd with persistence was very slow because changes are continuously written to the usb stick, and there's hidden services that always write logs something like that.\n\nA: I think you should also consider a persistent live system (with an overlay method for persistence). You can use mkusb to make it.\nYou can compare a persistent live system with an installed system (installed to a USB pendrive in the same way as installed to an internal drive).\nIt is probably a good idea to try an ultra-light flavour of Ubuntu: Lubuntu, or a medium light-flavour, Ubuntu MATE or Xubuntu. The difference is the desktop environment, and a lighter flavour will make it faster with a slow drive.\nYou should also consider using a fast USB 3 pendrive, even if the computer only has USB 2 ports.\nSee the following link and links from it:\nTry Ubuntu (Kubuntu, Lubuntu, Xubuntu, ...) before installing it\n\nA: You can still use a usb and get fast speed.\nInstall Ubuntu to a usb drive, then install overlayroot. overlayroot allows you to toggle booting into ram or with persistance. Persistance will be slow (like you've experienced), but booting into ram will give you speed you want.\nI would use gparted to make a separate partition on the usb install so you can save documents.\nGrab overlayroot and configure it so you boot into ram:\nsudo apt-get install overlayroot\nsudo pico /etc/overlayroot.conf\n\nWith the latter file open, page down all the way to the end. There is a pair of empty quotes. Add tmpfs between them. Then reboot.\nNow you will be booting into ram each time. If you want to save things, save them on a partition on the usb or another drive. If you want to customize the user account, you must do this:\nsudo overlay-chroot\npico /etc/overlayroot.conf\n\nPage down to end of file and remove tmpfs from the quotes leaving the quotes empty: \"\"\nReboot and then customize user account, the turn tmpfs back on when done and reboot.\n\nIf you want to save all modifications for the user at the end you can do this to.\nYou have to create a user account. At the end of each live session, just:\ncp -purv /home/user /media/persistant/drive/\n\nWhen you boot up again:\ncp -purv /media/persistant/drive/ /home/\n\nCreate the user using the command drive and make sure you use the home folder you copied over.\nIf you create a script it will be much easier each time.\n", "Q: Removing faulty links from /var/lib/apt/ When I use apt-get, I get the following error:\nE: GPG error: http://repository.spotify.cofy.com stable Release: The following signatures were invalid: NODATA 1 NODATA 2\n\nI've pasted the link into chrome and it returns error message 503.\nFirst, I tried grepping and rm:ing every single file or directory in /var/lib/apt/lists which had the name spotify in it, and then apt-get update. The problem persists. \nGuidance from this thread i did rm -v /var/lib/apt/lists* and the apt-get update. This is not a very elegant solution, as it removes everything, right? How much is it safe to remove and then get back again?\nHowever, The problem still persists. The faulty file is obviously somewhere else. Where is it, and how do I get at the bastard?\n\nA: Like @Jos said you need to find the bad entry in /etc/apt/sources.list and /etc/apt/sources.list.d. \nTo do it easily without explore all the files and the lines you can make a search with grep :\ngrep -nri \"repository.spotify.cofy.com\" /etc/apt/sources.list /etc/apt/sources.list.d\n\nParameters:\n-n  Prefix each line of output with the 1-based line number within its input file.\n-r  recursive\n-i  ignore-case\n", "Q: what is that job that cannot be done without \"lsof\"? I want to know the use of the overwhelming output of lsof and maybe a specific example where lsof feels like a blessing.\n\nA: Personally I've never used this function but I found the page which describes the topic. http://www.thegeekstuff.com/2012/08/lsof-command-examples/\n", "Q: Ubuntu software centre - accessing the installed programs I have just installed Ubuntu along with Windows 7. I'm eager and excited to explore the Ubuntu OS. I have found some free developer tools for Biological application and installed them. Unlike in windows, I was not sure how to access the installed programs. Help me with that. Thanks  \n\nA: press the super button on your keyboard (the windows button) and then in the search bar search for your new installs\n", "Q: How to replace string containing file path using sed I want to replace a file path to other using sed. I am attaching a small part of my file \nKindly help \nsource file :\nDir=D:\\test\\foo\nDir=D:\\test\\bar\n\nthe result should look like this \nDir=E:\\test1\\foo\nDir=E:\\test1\\bar\n\n\nA: Using sed with pattern grouping:\nsed -r 's/(.*=)D(:\\\\[^\\]+)(\\\\.*)/\\1E\\21\\3/' file.txt\n\n\n\n*\n\n*All () are indicating pattern groups, the purpose of grouping is to use them in the replacement by just using \\# reference (replace # with group number, incrementing from 1, left to right)\n\n*(.*=) will match the portion before first D, this is referenced as group 1 i.e. \\1 in replacement\n\n*(:\\\\[^\\]+) matches upto the second \\ after D, this is \\2\n\n*(\\\\.*) matches everything else after second \\ (including), this is \\3\nExample:\n$ cat file.txt \nDir=D:\\test\\foo\nDir=D:\\test\\bar\n\n$ sed -r 's/(.*=)D(:\\\\[^\\]+)(\\\\.*)/\\1E\\21\\3/' file.txt\nDir=E:\\test1\\foo\nDir=E:\\test1\\bar\n\n\nIf you have multiple occurrences and you want to replace them all:\n$ cat file.txt\nDir=D:\\test\\foo Dir=D:\\bar\\foo\nDir=D:\\test\\bar\n\n$ sed -r 's/D(:\\\\)[^\\]+/E\\1test1/g' file.txt\nDir=E:\\test1\\foo Dir=E:\\test1\\foo\nDir=E:\\test1\\bar\n\n", "Q: Updating Ubuntu 14.04 to 15.10 Failed I tried to upgrade from 14.04 to 15.10 and everything crashed. Nothing is working D:\nSudo apt-get update && sudo apt-get upgrade \n\nIt's not working!!\n\nA: since i can not comment yet, you should try this, first open up your /etc/apt/sources.list and change all trusty links to wily\nthen indeed do apt-get update;apt-get upgrade and apt-get -f install, maybe it works? please post your results!\n", "Q: Error in resuming ubuntu related to pciehp_resume I sometimes(not always) cannot resume my laptop after suspending.\nThe following error is printed in the screen:\n\npciehp 0000:00:1c.1:pcie04: Device 0000:03:00.0 already exists at 0000:03:00, cannot hot-add \n  pciehp 0000:00:1c.1:pcie04: Cannot add device at 0000:03:00 \n\nSomeobody mentioned this issue  Here but I haven't been able to find a solution:\n\"Currently, pciehp_resume will call pciehp_enable_slot() to add \ndevice if there is a device in the slot. But if the device was \npresent before suspend, it's no necessary to add again. Now in \nsuch case, there is some uncomfortable message like above\"\nAs far as I know, that device is Wireless card. While it is suspended, I didn't add/remove any cards. The only reason I could think of is that: the suspend phase didn't remove the Wireless card (but it is supposed to remove that card), so later on the resume phase would try to add this card, printing that uncomfortable message, not letting me to resume.\nIs there a good solution for user like me? Or I should wait until someone fixes it in the kernel code?\n\nA: I had this problem on 16.04 & what fixed it was removing acpid:\nsudo apt remove acpid\n\nI don't really know the consequences of this but now the laptop suspends & that might be more important than many things.\nThis will remove this package, which controls pressing the power button.\nBut don't worry, works fine without it.\n\nA: This is an ancient bug with Nvidia cards drivers, probably related to the acpid package\nIf you need to use your graphics card, switch the driver in Sowtware&Updates > Additional Drivers to the Nvidia driver and reboot. Don't forget that you still can't suspend your laptop.\nOtherwise, just run sudo apt remove acpid, the driver will be switched to xorg automatically (xorg works fine). I didn't experience problems without acpid yet.\nThis is not a complete solution to the problem (I'm not sure if there exists one yet), but the only one way to use your graphics card. \n", "Q: Cannot change brightness in laptop I am trying to change the brightness of my laptop using xrandr, but I get this error.\nHere's the segment:\njanreggie@janreggie-T100TA:~$ xrandr\nScreen 0: minimum 8 x 8, current 1368 x 768, maximum 32767 x 32767\nDSI1 connected primary 1368x768+0+0 (normal left inverted right x axis y axis) 0mm x 0mm\n   1368x768      60.10*+\nDP1 disconnected (normal left inverted right x axis y axis)\nHDMI1 disconnected (normal left inverted right x axis y axis)\nVIRTUAL1 disconnected (normal left inverted right x axis y axis)\njanreggie@janreggie-T100TA:~$ xrandr --output DSI1 --set backlight 10\nX Error of failed request:  BadName (named color or font does not exist)\n  Major opcode of failed request:  140 (RANDR)\n  Minor opcode of failed request:  11 (RRQueryOutputProperty)\n  Serial number of failed request:  34\n  Current serial number in output stream:  34\n\nWhat am I doing wrong? Any help would be appreciated.\nMy laptop is an ASUS Transformer T100TA, installed per Lubuntu 15.10 ISO.\n\nA: Xrandr has brightness parameter not backlight. You can set brightness level (eg. 0.9):\nxrandr --output DSI1 --brightness 0.9\n\nor use solution from here \n", "Q: trading and charting platform for ubuntu 15.10 is there any charting and trading platform available for ubuntu 15.10 64 bit which get data from yahoo/google EOD / RT and shows charts Pitch fork , p&F etc. for indian market ?\nFYI: \nhttp://www.multicharts.com/ ; http://ninjatrader.com/ i used to know very popular trading platform but for windows only . is there anything same for ubuntu 15.10 64 bit ? i am looking for some alternatives to them in ubuntu 15.10 64 bit. \n\nA: You can try the free open source version of Chart Geany\nThey provide Ubuntu packages too.\n", "Q: How does Ubuntu manage so many daily images? From these pages, https://cloud-images.ubuntu.com/locator/daily/ and http://cloud-images.ubuntu.com/releases/16.04/beta-2/, Ubuntu provides daily images for different releases (14.04 to 16.04), platforms (AWS, Azure, KVM, Vagrant...) and architectures (i386, amd64...).\nThis must need great automation. I'm curious about the architecture of this kind of build system. Are there any documents regarding this? Thanks. \n\nA: For Ubuntu probably it is done in a similar way than for Debian. Here some info about the Debian Autobuilder network.\nHere some details on how to build a specific Ubuntu installer image.\nFor Debian, to decrease server-load, there are many mirrors which e.g. provide the cd-images build by the main Debian-servers. Most mirrors are maintained by volunteers. Here some doc about : Debian Mirrors. The same exists for Ubuntu: Ubuntu Mirrors\nIt should be sufficient to have one or maybe two build-servers per architecture. Each build-server can build the cd-images for its own architecture, for all the platforms, for all versions periodically.\n( When using cross-compilation, even less build-servers could be needed )\nBefore uploading a installer-cd-image there are many integration-tests which need to be run in order to validate, that newly build packages do work with each other (see specification dep8) And of course there are package-specific tests during the build of each package.\nHowever I dont know if the cd-builds itself are triggered by script + a cron job, or if they use some kind of software for continous integration (e.g. Jenkins). Or if they use a tool like automated linux from scratch.\n", "Q: How to automatically sync the contents of a local folder with the contents of a ftp folder? After searching everywhere I have not managed to find a specific answer for my question.\nOn Windows there is an application called FTPbox that will automatically sync a local folder with an ftp one every set period of time.\nMy question is, how do I achieve the same thing using Ubuntu? The main thing is here that I dont want to have to do it manually. It needs to be a totally automatic process with no human intervention required (obviously I will have to set this up if that classes as human intervention LOL).\nMany thanks in anticipation for helpful answers.\n-Edward\n\nA: First solution\nInstall lftp\nsudo apt-get install lftp\n\nafter that create script\n#!/bin/bash\nHOST='mysite.com'\nUSER='myuser'\nPASS='myuser'\nTARGETFOLDER='/new'\nSOURCEFOLDER='/home/myuser/backups'\n \nlftp -f \"\nopen $HOST\nuser $USER $PASS\nlcd $SOURCEFOLDER\nmirror --reverse --delete --verbose $SOURCEFOLDER $TARGETFOLDER\nbye\n\"\n\nSave it on some place with name upload.sh. Give it +x permission.\nsudo chmod +x /path_to_script/upload.sh\n\nSetup crontab to run this command on every x period of time\nFor editing crontab run\ncrontab -e\n\nFor running command on every 5 min code is\n */5 * * * * /path_to_script/upload.sh\n\non every hour\n 0 */1 * * * /path_to_script/upload.sh\n\nto run on 4 am\n 0 4 * * * /path_to_script/upload.sh\n\nSolution two\nCreate a small and easy script called lftp-script that LFTP can read:\nopen ftp://username:password@website.com\nmirror --reverse -v --only-newer /home/local/path/ /website.com/public_html/\n\nFinally you can run LFTP and start the synchronisation. Set crontab like I write but put command\nlftp -f /path/to/lftp-script\n\nsomething like this\n */5 * * * * lftp -f /path/to/lftp-script\n\nSolution three\nInstall curlftpfs\nsudo apt-get install curlftpfs\n\nyou need to do in order to mount ftp locally is to to run these commands\ncreate dir witch will be sync-ed\nmkdir hostr\n\nmount remote ftp dir to local\nsudo curlftpfs -o allow_other ftp://user:pass@ftp.example.com host\n\nuser:pass is the username and password to log into ftp account.\nYou can add curlftpfs to fstab for automatic mounting by using this line :\ncurlftpfs#user:pass@ftp.example.com /mnt/host fuse rw,uid=500,user,noauto 0 0\n\n", "Q: How to set serial port parameters with stty? I am working with a serial port (RS232), and i have come across the following.\nWhen i list serial port settings with\nstty -F /dev/ttyS0\n\ni get, among other things:\n\n... eof = ^D; eol = ; eol2 = \n\nHow can i set end of line charater to the line feed? That is - i do not know where to get table of character representations (so that i could understand what all ^C mean) and how should it be entered in the following command:\nsudo stty /dev/ttyS0 9600 eol=<line feed>\n\nWhen i try to send or recieve character data from it with\necho 'hello' > /dev/ttyS0\ncat < /dev/ttyS0\n\nall i get is blinking cursor, and no data seem to transmit.\n\nA: \nFrom this wiki page I understand that the standard line feed character is\nCTRL+J or ^J. You could try that.\n\n–\nJos\nJust note, that while on setting you need to type ^ as it is, while on runtime you should use CTRL itself.\n", "Q: Grub Installation failed into target I tried to install Ubuntu 14.04 on Windows 10 having created partitions for swap area and root. But when I am installing ubuntu it keeps saying \"failed to install grub-efi-amd64-signed\" into target. I have tried several times but it keeps saying the same thing and installation fails.\nPlease help me as how to proceed further. \n\nA: I've come across this problem when Installing Mint 17.3, Lubuntu 16.04 and Ubuntu LTS 16.04 on a 16GB Flashdisk from a live USB.\nYou see when I created the Live USB, I used rufus making bootable USB, I also tried using Mint's Create Bootable USB tool. Same results, failure to install grub...\nThe problem was that all these tools were creating the Live USB to be compatible with UEFI boards. Thus when you boot your live USB in UEFI mode, your installer will create GPT disk rather than MBR, and for that you need a dedicated partition where you put /boot/efi.\nHowever I wanted MBR, so I started the computer with my Live USB, opened gparted and erased then formatted my installation target, which like I said earlier was a 16GB Flash disk (I like having a portable OS), when you create the new partitions, select MBR theme. After you're done with partitioning your target, install Linux as you would normally do and that dreaded error message won't appear at the end of the installation.\nGood Luck\n", "Q: ZFS filesystem on SSD for normal use Ubuntu 16.04 will be out soon and it seems ZFS will be natively supported. I have used ext4 for years but have read some of the newer file-systems (like the still fairly experimental btrfs) will have nifty features like better support for solid state drives (how the ssd is written to and read so as to prolong drive life).\nI have read the upsides to using ZFS in a RAID configuration due to the file integrity features.\nIf not using RAID, are there any real benefits to using ZFS on a single solid state drive for normal OS use?\n\nA: There is no installer support for 16.04 with ZFS, so you won't be able to create a bootable ZFS-only system just right now using the installer. I'd generally recommend ZFS for multi-drive configurations; a single SSD with ZFS may not be  as performant as ext4.\nIt is my personal opinion that ZFS is far more robust than btrfs, and it is my preferred choice for large data storage, mainly because of useful features such as compression, snapshots, cloning, send/receive, easy VDEV configuration, flexible raid options and a lot more. \nSee also:\n\n\n*\n\n*https://wiki.ubuntu.com/Kernel/Reference/ZFS\n\nA: To install zfs on root, you need to follow the procedure outlined on github for the moment, since the installer cannot use zfs for the moment. Make sure that you don't use the zfsonlinux ppa, but just the official packages from 16.04LTS.\nWhy should you do it? While it's correct that ext4 is faster, with zfs you gain the ability to make snapshots, even automatically with zfs-auto-snapshot, and can use these snapshots to make a complete rollback of the system and boot from them.\nFor me, this advantage outweighs the slight impact in speed. Snapshots can also be used via zfs send and receive to a remote system, which makes backups a breeze. \n\nA: There are disadvantages of using ZFS with implementations of OpenZFS at the time of writing besides booting, another one is missing encryption. eCryptfs works on ZFS like almost everywhere else and is recommended over LUKS, but it has disadvantages like reducing the maximum filename length if used with filename encryption. The ZFS competitor btrfs is also missing encryption in it's feature set and EXT4's encryption wasn't very user-friendly the last time I checked. As a reminder, if you are looking for a purely flash optimized file system there is F2FS and the Arch Wiki states that it is possible to install on an F2FS root if you have a separate boot partition (or store kernels and GRUB modules on the EFI system partition), the Ubuntu installer doesn't support it though, so you need a workaround: Installing Ubuntu 14.04 on a F2FS partition\n(Yes, I consider using encryption and use of long filenames as normal use.)\n", "Q: Alternative to HTTP to avoid corruption when downloading I have a 76GB file I want to download from my web server, but am affraid it may become corrupt when downloading via HTTP. Are there any options to download files that will check for corruption?\n\nA: Since you didn't mention any, I expect you don't have any restrictions regarding ports or programs on both sites.\nI would download it via http with a client that can resume (e.g. wget -c). Then check the md5sum. If there is anything wrong with it, which I don't expect, I would then use rsync over ssh, which should transfer (only) the rest. Alternatively you could replace the first http transfer with the rsync, but IMO http is simpler. \n\nA: BitTorrent is also a possibility, as it ensures that each piece of the file(s) matches the original signatures.\nWill also reduce server loading if many people need the file.\n\nA: zsync basically does what Jakob Lenfers suggests in his answer, but BitTorrent has proven to be the better alternative where it is available and the network connection can at least transfer some bits correctly it will get the job done for you with the least hassle for a client/receiving device. A more consumer-friendly version would be Syncthing.\n", "Q: Where are localized interface names of launcher items defined if they are not in the .desktop file? Naming of a launcher\n- In most cases...\nThe interface -name of a launcher, in most cases, is defined in the (first) line, starting with:\nName=\n\nof its corresponding .desktop file:\n\n\n- Localized naming from the .desktop file\nFor localized naming, some applications (like Thunderbird) use extensive lists with launguage- specific names:\n\n\n- But where is the localized name defined if it's not defined in the .desktop file?\nIn some cases however, the icon is named differently, but the name is nowhere in the .desktopfile:\n\nWhere is this name connected with the .desktop file?\nContext\nA few years ago, I wrote the QLE Quicklist editor. That version used the International interface names. I am rewriting it now in Gtk+, but need to find a reliable way to display the localized launcher names.\nNote\nNo doubt, this question is related to this one, but not exactly a dupe; I'd like to know where the information is stored to fetch the localized name(s) myself.\n\nEDIT\nAs a proof, the content of gnome-screenshot.desktop, named Scermafdruk localized  (translated: Screenshot). No trace of the string \"Scermafdruk\" in the file...\n[AU] \n[Desktop Entry]\nName=Screenshot\nComment=Save images of your screen or individual windows\nKeywords=snapshot;capture;print;\nExec=gnome-screenshot --interactive\nTerminal=false\nType=Application\nIcon=applets-screenshooter\nStartupNotify=true\nCategories=GTK;GNOME;Utility;\nNotShowIn=KDE;\nX-GNOME-Bugzilla-Bugzilla=GNOME\nX-GNOME-Bugzilla-Product=gnome-utils\nX-GNOME-Bugzilla-Component=screenshot\nActions=Screen;Window;Area\nX-Ubuntu-Gettext-Domain=gnome-screenshot\n\n[Desktop Action Screen]\nName=Take a Screenshot of the Whole Screen\nExec=gnome-screenshot\nOnlyShowIn=Unity;\n\n[Desktop Action Window]\nName=Take a Screenshot of the Current Window\nExec=gnome-screenshot -w\nOnlyShowIn=Unity;\n\n[Desktop Action Area]\nName=Take a Screenshot of a Selected Area\nExec=gnome-screenshot -a\nOnlyShowIn=Unity;\n\n\nA: As you found out yourself while testing, the entry responsible for such behavior is:\nX-Ubuntu-Gettext-Domain=gnome-screenshot\n\nFrom https://wiki.ubuntu.com/UbuntuDevelopment/Internationalisation/Packaging:\n\nDESKTOP ENTRIES\nTranslations of desktop entries (.desktop files) are also stripped out and included in language packs.\nContrary to what other distros do (except currently OpenSUSE), the translations are not expected to be in the .desktop files themselves (static translations), but rather in the same .mo file of the application, from which they are then loaded at runtime. We do this in order to be able to translate them in Launchpad and to ship them in language packs, so that they can be edited and updated by Ubuntu translators.\nThe runtime loading is done by patches to patch glib and kdelibs, which recognises the the X-Ubuntu-Gettext-Domain additional key we add to all Ubuntu .desktop files and adds gettext support when loading them. Note that if the .desktop file already contains translations, these static translations will be preferred.\nAdding the X-Ubuntu-Gettext-Domain= key is done during build time in the packaging either automatically with the package build system or (increasingly rarely) with patches.\n\nIn other words, that means that the patched version of glib and kdelib on Ubuntu use the X-Ubuntu-Gettext-Domain key to add gettext support at runtime if a translation is not available by other means in the desktop file, translation which is retrieved from the application's .mo file.\nNotice also that this implies that the support for the X-Ubuntu-Gettext-Domain key is a Ubuntu-specific implementation, and that desktop files using the X-Ubuntu-Gettext-Domain are only portable across distributions that use the same patched version of glib / kdelib.\n", "Q: Creating a USB media using UNetbootin isn't recognized as booting media I've installed Ubuntu by USB many times before. It's not working now and I'm not sure why.\nI format the USB drive (a Kingston DataTraveler 100 G2, 16 GB) using GParted by wiping it and installing a FAT32 primary partition on it. I change the permissions of the drive filesystem from root to the main user (sudo chown user1: /media/user1/4B8C-3997). I download Ubuntu (wget http://mirror.switch.ch/ftp/mirror/ubuntu-cdimage/15.10/ubuntu-15.10-desktop-amd64.iso) and then write the ISO to USB using UNetbootin. Then, when I try to boot from the drive, it simply loops back to asking which drive to boot from.\nDo you have any ideas about what might be causing this?\n\nA: Use this git clone for a faster bootable usb creator.\ngit clone git://github.com/pbatard/rufus\n\nAlternative Windows mirror: https://github.com/pbatard/rufus/archive/v2.8.zip\nIt can also format the partition to FAT32 easily\n\nA: Unetbootin does not create the Ubuntu installation media properly.\nUse the Disks tool (gnome-disk-utility) to create the USB media.  \nOpen Disks, select Restore Disk Image from the menu on the top right.\nChoose the ISO file and the USB drive to write it to and start restoring.  \nWhen you want to create the installation media from within Windows,\nboot Windows, open command prompt as administrator and execute :  \ndiskpart\nlist disk  \nselect disk *  \nclean  \ncreate partition primary  \nactive  \nformat fs=fat32 quick  \nassign letter=**  \n\nNote : * = number of USB drive | ** = select a free drive letter\nNow mount the ISO file and copy the content to the USB disk.  \n\nA: If you want to boot from USB and you are prepared to wipe all existing contents from the USB device, there is a much simpler way:\ncat ubuntu-15.10-desktop-amd64.iso >/dev/sdx\n\nWhere /dev/sdx is the device name of the USB media. Be very careful because a small typo in this command could wipe your hard drive.\nThis works because the Ubuntu ISO images utilize the free space at the start of any ISO image to include a partition table and boot loader suitable for booting from USB.\nIt is also possible to partition the USB device manually, create a file system, copy the ISO file to that file system, install a boot loader, create a boot menu entry to boot from the ISO file. But performing all of these steps manually is more work, and it is easy to make mistakes meaning you have to try a few times before you get the system to boot.\n\nA: I was having the same problem on Mac, and I believe it was because of how I'd formatted my USB stick. Originally I had just created a partition as FAT and was able to load many different ISOs onto the device. Then I made a mistake and had to re-format(?) the whole device, which included re-making the file/partition table. Originally I just chose the default \"Scheme\", \"GUID Partition Map\". From this point on I was having trouble. I had a hunch that it might require the \"Master Boot Record\" scheme, so I erased the whole USB stick again with that setting. Then when I ran unetbootin again it worked without issue.\nwhat's more, if unetbootin is still not working with you, then change to another tools like SYSGeeker's WonderISO or rufus.\n\nA: I think Etcher is worth a mention and works on all platforms.\n", "Q: lenovo thinkpad E560 trackpad stopped working Last week my trackpad was working and this week just decided not to. Tried a update with no success.  \nVirtual core pointer                        id=2    [master pointer  (3)]\n⎜   ↳ Virtual core XTEST pointer                id=4    [slave  pointer  (2)]\n⎜   ↳ DELL DELL USB Laser Mouse                 id=9    [slave  pointer  (2)]\n⎣ Virtual core keyboard                     id=3    [master keyboard (2)]\n    ↳ Virtual core XTEST keyboard               id=5    [slave  keyboard (3)]\n    ↳ Power Button                              id=6    [slave  keyboard (3)]\n    ↳ Video Bus                                 id=7    [slave  keyboard (3)]\n    ↳ Sleep Button                              id=8    [slave  keyboard (3)]\n    ↳ Integrated Camera                         id=10   [slave  keyboard (3)]\n    ↳ AT Translated Set 2 keyboard              id=11   [slave  keyboard (3)]\n    ↳ ThinkPad Extra Buttons                    id=12   [slave  keyboard (3)]\n\nLinux 4.2.0-35-generic #40~14.04.1-Ubuntu\n\nA: I have the thinkpad e560 and have not experienced any problems until last night. I tried many things and the only thing that fixed the track pad was to close the lid, putting the computer to sleep and then opening it back up and it worked again! No idea why this fixed it but it did.\n\nA: i solved the same problem by updating the kernel to the newest LTS version (in this case 4.4.7), maybe that is an option for you.\nhttp://ubuntuhandbook.org/index.php/2016/01/how-to-install-linux-kernel-4-4-in-ubuntu/\n\nA: I can't seem to find a permanent solution to this yet, but a temporary one is to: 1. Close the laptop lid which puts it in sleep mode. 2. Start it again and click the touchpad and the three mousebuttons above at the same time.\nThis should fix it until the next time your computer runs out of power, but it is a fkd up way to fix it.\n", "Q: Where do I find Firefox NoScript .xpi on my system? Ubuntu 14.04 32bit, Firefox 45.0.1 I have checked the following folders:\n/usr/lib/firefox-addons/extensions\n/usr/lib/mozilla/plugins\n/usr/lib/firefox-addons/plugins\n~/.mozilla/firefox\n~/.mozilla/extensions\n\nHave not found actually anything that would be what I am looking for.\nUPDATE: I did a locate *.xpi, but could not find it, and locate *noscript* returns nothing. The extension is actually installed and enabled. \n\nA: Using locate was a good idea, but Firefox extensions are referred to by UUIDs, unique names rather than human readable ones to prevent different extensions from having the same name.\nAs NoScript's is 73a6fe31-595d-460b-a920-fcc0f8843232, you should find:\nlocate *73a6fe31-595d-460b-a920-fcc0f8843232*\n\nto be more helpful.\n", "Q: How do I check if I have the beta or stable version of Kubuntu? I installed the Kubuntu 16.04 beta 2 and I plan to upgrade to the final release when it's out. I just want to know now how to check so I can make sure.\nThe solution here tells me that I have the stable version, even though I don't\n\nA: After the release announcement is made, check that all your packages are up to date, e.g., sudo apt-get update && sudo apt-get upgrade should say\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n\nIf it does, you are on \"the final release\" (i.e., you have the same set of packages as someone who downloaded the release ISO and installed from it).\n\nA: You can look at your version by simply putting this command in terminal:\ncat /etc/issue\n\nLTS - means long term support\nHere is more information about releases:\nhttps://wiki.ubuntu.com/Releases\n", "Q: When running commands with && how can I keep it running when one command fails? For example I have a .gitconfig for one project, since I do a lot of code reviews, that reads: \nreview = \"!f(){ git checkout master && git pull origin master && git branch -D $1 && git fetch && git checkout $1 && git pull origin $1 && bundle install && rake db:migrate && git checkout -f; };f\"\n\nNow I know it's a little overkill and I don't need it all but I like it that way. It makes me feel like the review branch is totally clean. Sometimes it's nice to see the message Already up-to-date.\nNow when the branch does not exist yet then git branch -D $1 will fail and it throws an error and doesn't run the rest of the commands. \nIs there a way that I can make the rest of the commands run even if one of the commands fail? \n\nA: That's the whole point of && - ensuring that the previous command succeeded before running the next. If you don't need that, use ; instead. The following will echo foo:\nfalse; echo foo\n\nAnd the following won't:\nfalse && echo foo\n\nSee Bash manual, section List of Commands:\n\nCommands separated by a ‘;’ are executed sequentially; the shell\n  waits for each command to terminate in turn. The return status is the\n  exit status of the last command executed.\nAND and OR lists are sequences of one or more pipelines separated by\n  the control operators ‘&&’ and ‘||’, respectively. AND and OR\n  lists are executed with left associativity.\nAn AND list has the form\ncommand1 && command2\n\ncommand2 is executed if, and only if, command1 returns an exit\n  status of zero.\nAn OR list has the form\ncommand1 || command2\n\ncommand2 is executed if, and only if, command1 returns a non-zero\n  exit status.\n\n\nA: Yes, just replace && with ;.\nThe command after ; will run regardless of the exit status of the command before ;.\n\nA: Don't use && as this means only complete this command if the previous command completed successfully.\nUse ; instead, it's comparable to a new line, and is not dependent on the exit status of the previous commands.\n", "Q: Ubuntu 14.04 failed to boot after a failed upgrade to 16.04 I tried to install ubuntu 16.04 beta on my laptop which has ubuntu 14.04 installed 3 days before the official release. So I ran the command \ndo-release upgrade -d\n\nThe download went on well. But during installation, it started showing many errors and suddently the process stopped saying that \"too many errors were encountered during the process\". I did'nt know what to do. So I restarted the system. But the laptop failed to shutdown but showed a black screen with the led backlight still on. I had to force shutdown the system by pressing the power button. Then when I tried to turn on the system back, It came to black screen showing some errors which I have attached:\nI have windows 10 also installed on my system and grub seems be working properly but I really want to recover ubuntu which I use more often. Any help would appreciated. Thanks.\n\nA: First, advice to others who want to install a beta version, besides the classic \"backup your data\":\n\n\n*\n\n*if update-manager -d fails with too many errors and does not rewind what it has done, do not force a restart.\n\n*close update-manager, if necessary, kill the process.\n\n*do an apt-get -f install, followed by apt full-upgrade.\n\n*Repeat with apt update and apt full-upgrade and make sure that the process runs without complaints.\n\n\nThis should let you succeed in 9 of 10 cases. Only then restart into the new kernel.\nFor your situation:\n\n\n*\n\n*Make a bootable installation media (flash drive or DVD) of the latest 16.04.\n\n*Boot into the installer CD.\n\n*Use the repair option with whatever suits you. Try to repair the existing installation, keeping your data - this works surprisingly well.\n\n*After the repair has done its thing, reboot and remove the installer drive.\n\n\nTo clarify what the 'repair' means: When you try to install to an existing Ubuntu system without formatting, the installer detects the existing system and gives you a repair menu in the next step where you can choose to overwrite or repair the existing installation.\nYou have to choose the install option, it is not mentioned that the repair option pops up later in the process if it is an existing installation.\nEnjoy 16.04LTS.\n", "Q: Using lvm and thin provisioning (thinpool) on a PV larger than 2T Initial problem\nI'm trying to make use of lvm thin volumes on Trusty 14.04 with an external drive of 3TB as the PV for the volumegroup, but for some reason this fails and the thinpool gets somehow corrupted.\nOn a 2TB drive as the PV this all works fine and I can even create thin snapshots of the thin volumes etc.\nHere's what I've done:\n1) Setup the PV:\n# pvcreate /dev/sdb\n\n2) Create the volume group:\n# vgcreate vg_backups /dev/sdb\n\n3) Create the thinpool:\n# lvcreate --thin -L2,5T --chunksize 1M --poolmetadatasize 16G /dev/vg_backups/backup_thinpool\n\n4) Create a new thin volume:\n# lvcreate --thinpool /dev/vg_backups/backup_thinpool -n test_lv -V400G\n\n5) So far everything seems to go fine and the thin LV seems to be active but when I want to make the VG inactive with:\n# vgchange -an /dev/vg_backups\n\n...I first get this warning:\nWARNING: Integrity check of metadata for thin pool vg_backups/backup_thinpool failed.\n\nThen if I try to re-activate the VG by:\n# vgchange -ay /dev/vg_backups\n\n...I get:\nCheck of thin pool vg_backups/backup_thinpool failed (status:1). Manual repair required (thin_dump --repair /dev/mapper/vg_backups-backup_thinpool_tmeta)!\n\n... and the thin volume cannot be activated. Running the thin_dump --repair command just gives:\n# thin_dump --repair /dev/mapper/vg_backups-backup_thinpool_tmeta\nread failed\n\nAnd as I said, it all works if I use a 2TB drive as the PV. Also tested on a Centos 7 box and there it also works with the 3TB drive. So, something must be wrong with the lvm thinpool handling in Ubuntu.\nHas anyone run in to this issue? Any workarounds / fixes available?\nSome further testing and findings:\nI have another machine with 16.04 now installed (same results as on 15.10 btw) where I'm actually able to create the thin LV on the 3T disk and it gets activated and is usable. \nHowever, if I make a thin snapshot of the thin volume like this:\n# lvcreate -s --thinpool /dev/vg_backups/backup_thinpool -n test_lv_snapshot test_lv\n\n...then that thin snapshot won't become active and I cannot activate it even if I try:\n# lvchange -ay /dev/vg_backups/test_lv_snapshot\n\nI don't get any errors, the LV just doesn't become active.\nOn 16.04 I can deactivate and reactivate (vgchange) the volume group without errors -just the thin snapshots won't become active no matter what I try.\nAlso on 16.04 (and 15.10) even the 2T disk has the same behaviour -the thin snapshots won't become active. \nHowever, if I first create the thinpool, some thin volumes and some thin snapshots of those thin volumes on the 2T disk on the 14.04 machine and then attach the disk to the 16.04 machine then those thin volumes and their snapshots are activated. \nBut if I then make some more thin snapshots on that disk on the 16.04 machine those thin snapshots cannot be activated on the 16.04 machine but if I attach the disk back to the 14.04 machine even the thin snapshots created on the 16.04 machine are seen as active...???\nSo, I see possibly two separate problems here:\n1) Somehow 14.04 cannot handle the 3T disk as it does the 2T disk\n2) Thin snapshots on any disk created on 16.04 cannot be activated\nThis means that any thin snapshots created on 16.04 (and 15.10) cannot be accessed (cannot activate and mount the volumes) which is very bad!\nSo, if anyone has solutions to these issues that would be great!\n\nA: To activate the snapshots, try adding \"-K/--ignoreactivationskip\"\nSomeone decided the default for snapshots on thin volumes is for setactivationskip to be 'yes'. You can disable the skipping permanently by running \"lvchange --setactivationskip n\" on each new snapshot.\n", "Q: cannot login into locked Ubuntu 14.04 session Unity I cannot login into locked Ubuntu 14.04 session Unity.\nOutput from /var/log/auth.log:\nApr 18 15:10:45 trusty-1 unix_chkpwd[3171]: check pass; user unknown\nApr 18 15:10:45 trusty-1 unix_chkpwd[3171]: password check failed for user (martin)\nApr 18 15:11:02 trusty-1 dbus[660]: [system] Rejected send message, 2 matched rules; type=\"method_return\", sender=\":1.13\" (uid=0 pid=1328 comm=\"lightdm \") interface=\"(unset)\" member=\"(unset)\" error name=\"(unset)\" requested_reply=\"0\" destination=\":1.67\" (uid=1000 pid=2154 comm=\"/usr/lib/x86_64-linux-gnu/indicator-session/indica\")\nApr 18 15:11:02 trusty-1 lightdm: PAM unable to dlopen(pam_kwallet.so): /lib/security/pam_kwallet.so: cannot open shared object file: No such file or directory\nApr 18 15:11:02 trusty-1 lightdm: PAM adding faulty module: pam_kwallet.so\nApr 18 15:11:02 trusty-1 lightdm: pam_unix(lightdm-greeter:session): session opened for user lightdm by (uid=0)\nApr 18 15:11:02 trusty-1 systemd-logind[871]: New session c5 of user lightdm.\nApr 18 15:11:03 trusty-1 lightdm: PAM unable to dlopen(pam_kwallet.so): /lib/security/pam_kwallet.so: cannot open shared object file: No such file or directory\nApr 18 15:11:03 trusty-1 lightdm: PAM adding faulty module: pam_kwallet.so\nApr 18 15:11:03 trusty-1 lightdm: pam_succeed_if(lightdm:auth): requirement \"user ingroup nopasswdlogin\" not met by user \"martin\"\nApr 18 15:11:12 trusty-1 lightdm: pam_unix(lightdm-greeter:session): session closed for user lightdm\n\n\nA: I solved by installing libpam-kwallet4 libpam-kwallet5 .\n$ sudo apt-cache search kwallet |grep pam\nlibpam-kwallet4 - KWallet (KDE 4) integration with PAM\nlibpam-kwallet5 - KWallet (Kf5) integration with PAM\n$ sudo apt-get install libpam-kwallet4 libpam-kwallet5\n$ sudo service lightdm restart\n\n\nA: Your log suggests that there is a problem with /lib/security/pam_kwallet.so. Can you determine if that file still exists, you may have to reload the kwallet:\nsudo apt-get purge kwalletmanager\nsudo apt-get install kwalletmanager\n\n\nA: Rebuild the pam authentication settings. Go to another TTY CTRL-ALT-F1, then run:\nsudo pam-auth-update\n# Make no changes and select \"Ok\" to update the config\nsudo service lightdm restart\n\n\nA: with showing up\n$ sudo apt-cache search kwallet |grep pam\n\nand whatever pam-kwallet version being used, but please use the version with your desktop manager's support compatibility.\nfollowing by https://ubuntu.pkgs.org/20.04/ubuntu-universe-amd64/libpam-kwallet5_5.18.4.1-0ubuntu1_amd64.deb.html\nlibpam-kwallet5 that is installed is right here...\n$ ll /lib/x86_64-linux-gnu/security/pam_kwallet5.so\n\nso just link'ing up this pam_kwallet5 to your asked /lib/security/pam_kwallet.so system path.\nhere is command might you need to run at,\n$ sudo ln -sf /lib/x86_64-linux-gnu/security/pam_kwallet5.so /lib/security/pam_kwallet.so\n\nthen try to restart service that might you have to be..\n$ sudo service lightdm restart\n\nif $ journalctl -xe error still showing up, mybe ther's /etc/securetty not found, any other or permission failure\njust run mkdir and give chown 644 on it\n$sudo sh -c \"mkdir /etc/securetty && chown 0644 /etc/securetty\"\n\nand again, test it. happy solving\n", "Q: What is the correct way to ensure `mongod` starts on system startup in 16.04? I installed MongoDB through the software centre in Ubuntu 16.04:\nmongodb 1:2.6.10-0ubuntu1\n\nI believe this currently contains MongoDB 2.6.10.\nI am running an application on apache2 localhost setup and have to start mongod manually each time the system starts with:\nmongod\n\nI want it to start automatically.  \nI've come across two main methods to do this:\nupdate-rc.d mongodb defaults\n\nfrom:  https://askubuntu.com/a/89914/367134\nwhich results in:\nupdate-rc.d mongodb defaults\ninsserv: fopen(.depend.stop): Permission denied\n\nBut this didn't produce error:\nsudo update-rc.d mongodb defaults\n\nI've also seen a few references to edit the \"MongoDB config file\", but I'm not sure what this refers to as I can see config files in more than one location:\n\n\n*\n\n*/etc/mongodb.conf  \n\n*/etc/init/mongodb.conf  \n\n*/etc/init.d/mongodb\nAnd, once in the correct file, I'm not sure what to change in there.   \nIn /etc/init/mongodb.conf I can see:\nstart on runlevel [2345]\nstop on runlevel [!2345]\n\nWhat is the correct way to ensure mongod starts on system startup in 16.04?  \nI've been reading this, and looked in /etc/rc2.d and can see:\nS01mongodb@                       --> /etc/init.d/mongodb\n\nUpdate:\nAfter running suggestion:\nsudo systemctl enable mongodb \nand then restarting, running systemctl status mongodb returns:\n* mongodb.service - An object/document-oriented database\n   Loaded: loaded (/lib/systemd/system/mongodb.service; enabled; vendor preset: enabled)\n   Active: failed (Result: exit-code) since Mon 2016-04-18 23:42:28 AEST; 7min ago\n     Docs: man:mongod(1)\n  Process: 655 ExecStart=/usr/bin/mongod --config /etc/mongodb.conf (code=exited, status=100)\n Main PID: 655 (code=exited, status=100)\n\nApr 18 23:42:27 me-comp systemd[1]: Started An object/document-oriented database\nApr 18 23:42:28 me-comp systemd[1]: mongodb.service: Main process exited, code=exited, status=100/n/a\nApr 18 23:42:28 me-comp systemd[1]: mongodb.service: Unit entered failed state.\nApr 18 23:42:28 me-comp systemd[1]: mongodb.service: Failed with result 'exit-code'.  \n\nPermission Troubleshooting\n/var/lib/mongodb = drwxr-xr-x mongodb mongodb.\n/var/log/mongodb = drwxr-xr-x mongodb mongodb.\n/var/log/mongodb/mongodb.log = -rw-r--r-- mongodb nogroup.\n/var/log/mongodb/mongod.log = -rw-r--r-- mongodb mongodb.\n/data/db/mongod.lock = -rwxrwxr-x me me and 0 bytes.\n/data = drwxr-xr-x root root.\n/data/db = drwxr-xr-x me root.     \nConfig File Contents\n/etc/mongodb.conf:  \n# Where to store the data.\ndbpath=/var/lib/mongodb\n\n#where to log\nlogpath=/var/log/mongodb/mongodb.log\n\nlogappend=true\n\nbind_ip = 127.0.0.1\n#port = 27017 ...\n\n\nA: Installing\nThis is the method I ended up using (from user Adam C's comment re: using more up to date version of mongodb).  It worked for me but I'm not an authority on the matter.  \nhttps://askubuntu.com/a/757385/367134\nThen I had to make a service file, see:\nhttps://askubuntu.com/a/694226/367134\nAnd edit the path in that service file from:\n/etc/mongodb.conf \n\nto:\n/etc/mongod.conf\n\nAnd then make mongodb start on system startup with:\nsudo systemctl enable mongodb\n\nsee:  \nhttps://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units\nNow mongodb is starting on 16.04 system startup.  \nUninstalling Old MongoDB\nBefore I did that however, I had to remove the existing installs and directories, which i did like this (steps mainly from https://askubuntu.com/a/497144/367134):\n# go to /etc/apt/sources.list.d and remove any mongodb lists, then:\n\n# sanity check - see what is installed\nsudo dpkg -l | grep mongo\n\n# remove all packages \nsudo apt-get remove mongodb* --purge\nsudo apt-get autoremove\n\n# remove old directories\nsudo rm -r -f /var/lib/mongodb/\nsudo rm -r -f /var/log/mongodb/\n\n\nA: While you're developing you may also want the opposite sometimes: to have multiple local separable instances that you start individually, rather than one global install...\nmongod --dbpath ./mongo_db_data/ --logpath ./mongo_logs/mongodb.log --port 12345\n\n\nA: For me works just doing sudo systemctl enable mongod\n\nA: For me, it is because of the wrong permission of db path. just\nchown mongodb:mongodb /var/lib/mongodb\n\n", "Q: Do gaming mice work with Ubuntu ? I want to purchase a mid range gaming mouse but confused whether it will work with Ubuntu or not. Will all the keys be configurable like in Windows. For playing CS and DOTA.\n\nA: Yes, multi-button mice work in Ubuntu according to the community help wiki page... If you have more than seven buttons (note that a clickable scroll wheel counts as three buttons), then you should install imwheel from the Universe repository and run imwheel -cfrom a terminal window to launch imwheel's graphical interface.\n\nA: Yes, multi-button mice work fine in Ubuntu. However, configuration of buttons may not be as easy, and you can't use the software which comes with the mouse, to configure it, as generally only Windows is supported by such device manufacturers.\n", "Q: Get unique lines from log using grep and tail I have the following log file. I want to extract the last 10 unique entries from this file. Is it possible to do with grep and tail?\n2016-04-18 10:13:11,925 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.7088348025036650 on 711b3fb7d875:80\n2016-04-18 10:13:12,383 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.9277403071419588 on 711b3fb7d875:80\n2016-04-18 10:13:14,000 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.5617050735043505 on 711b3fb7d875:80\n2016-04-18 10:13:18,305 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.3502119403604215 on 711b3fb7d875:80\n2016-04-18 10:13:25,571 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.1448386101904803 on 711b3fb7d875:80\n2016-04-18 10:13:42,529 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.6017618280263232 on 711b3fb7d875:80\n2016-04-18 10:21:20,257 (glastopf.glastopf) 150.70.188.165 requested GET / on 711b3fb7d875:80\n2016-04-18 10:35:27,775 (glastopf.glastopf) 150.70.173.55 requested GET / on 711b3fb7d875:80\n2016-04-18 10:44:21,799 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.8457383350172993 on 711b3fb7d875:80\n2016-04-18 10:44:23,550 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.2291251627482913 on 711b3fb7d875:80\n2016-04-18 10:44:24,885 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.9121516725350658 on 711b3fb7d875:80\n2016-04-18 10:44:28,611 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.6517709326810913 on 711b3fb7d875:80\n2016-04-18 10:44:36,656 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.3339893597346100 on 711b3fb7d875:80\n2016-04-18 10:44:52,579 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.9653746532564283 on 711b3fb7d875:80\n2016-04-18 11:07:15,576 (glastopf.glastopf) 204.12.196.236 requested GET / on 711b3fb7d875:80\n2016-04-18 11:14:46,990 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.6323574164650954 on 711b3fb7d875:80\n2016-04-18 11:14:49,798 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.1343994230148844 on 711b3fb7d875:80\n2016-04-18 11:14:50,923 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.2092851733275502 on 711b3fb7d875:80\n2016-04-18 11:14:54,015 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.6364011485956100 on 711b3fb7d875:80\n2016-04-18 11:15:02,021 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.2105667716533854 on 711b3fb7d875:80\n2016-04-18 11:15:17,763 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.5330510476532333 on 711b3fb7d875:80\n2016-04-18 11:45:51,204 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.7162577798366348 on 711b3fb7d875:80\n2016-04-18 11:45:51,456 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.4097472747050946 on 711b3fb7d875:80\n2016-04-18 11:45:53,562 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.0435891326571879 on 711b3fb7d875:80\n2016-04-18 11:45:57,368 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.9764200678378154 on 711b3fb7d875:80\n2016-04-18 11:46:05,598 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.2539390798717596 on 711b3fb7d875:80\n2016-04-18 11:53:59,103 (glastopf.glastopf) 150.70.173.9 requested GET / on 711b3fb7d875:80\n2016-04-18 12:16:07,343 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.0022258971071879 on 711b3fb7d875:80\n2016-04-18 12:16:07,411 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.6543056525672964 on 711b3fb7d875:80\n2016-04-18 12:16:09,210 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.0771392409002968 on 711b3fb7d875:80\n2016-04-18 12:16:21,475 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.4621648610735409 on 711b3fb7d875:80\n2016-04-18 12:16:37,413 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.1810763849106982 on 711b3fb7d875:80\n2016-04-18 12:46:31,160 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.0759114015016254 on 711b3fb7d875:80\n2016-04-18 12:46:33,023 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.9823929541441208 on 711b3fb7d875:80\n2016-04-18 12:46:42,262 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.1670975464416704 on 711b3fb7d875:80\n2016-04-18 12:46:44,977 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.3061602425336546 on 711b3fb7d875:80\n2016-04-18 12:47:00,555 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.5692431772822398 on 711b3fb7d875:80\n2016-04-18 12:50:34,078 (glastopf.glastopf) 150.70.188.178 requested GET / on 711b3fb7d875:80\n\nSo basically I want the last 10 unique log entries, identified by unique IPs.\nEDIT. Example last two unique entries:\n2016-04-18 12:47:00,555 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.5692431772822398 on 711b3fb7d875:80\n2016-04-18 12:50:34,078 (glastopf.glastopf) 150.70.188.178 requested GET / on 711b3fb7d875:80\n\n\nA: Using sort with a bit of help from tac:\nsort -k4,4 file.log | tac | sort -uk4,4 | sort -k1,2\n\nTo get last 10 entries, send to tail -10 at the end:\nsort -k4,4 file.log | tac | sort -uk4,4 | sort -k1,2 | tail -10\n\n\n\n*\n\n*-k option of sort let us sort by space separated field number as key\n\n*tac will reverse the lines of input content i.e. last goes first and first goes last; this is needed as sort -u will output the first entry as unique while using key-wise sort i.e. not all the lines have similar content but they match on a specific field\nExample:\n$ sort -k4,4 file.log | tac | sort -uk4,4 | sort -k1,2\n2016-04-18 10:21:20,257 (glastopf.glastopf) 150.70.188.165 requested GET / on 711b3fb7d875:80\n2016-04-18 10:35:27,775 (glastopf.glastopf) 150.70.173.55 requested GET / on 711b3fb7d875:80\n2016-04-18 11:07:15,576 (glastopf.glastopf) 204.12.196.236 requested GET / on 711b3fb7d875:80\n2016-04-18 11:53:59,103 (glastopf.glastopf) 150.70.173.9 requested GET / on 711b3fb7d875:80\n2016-04-18 12:47:00,555 (glastopf.glastopf) 115.239.248.245 requested GET http://zc.qq.com/cgi-bin/common/attr?id=260714&r=0.5692431772822398 on 711b3fb7d875:80\n2016-04-18 12:50:34,078 (glastopf.glastopf) 150.70.188.178 requested GET / on 711b3fb7d875:80\n\n\nA: The uniq command can be used to eliminate all consecutive lines which are identical in whole or in part. By default, it only operates on whole lines. That is, if in a file you have several identical consecutive lines, uniq removes the duplicates.\n$ cat foo.txt \nfoo\nfoo\nfoo\nbar\nbaz\nbaz\nfoo\nfoo\n$ uniq foo.txt \nfoo\nbar\nbaz\nfoo\n\nIn order to remove all duplicate lines, even non-consecutive ones, it can be run after sort:\n$ sort foo.txt | uniq\nbar\nbaz\nfoo\n\nSome flags can be used in order to only consider one part of a line when determining duplicates. Here we want to consider only IP addresses, which are in the fourth column, so first we need to tell uniq to disregard the first three columns, this is done with the -f flag. And after that we need to tell it to only consider the IP addresses. This one can be tricky because we can only tell it to considet a fixed number of characters (with the -w flag), but IP addresses can vary in length. Fortunately here this is not a problem because IP addresses are always followed by requested, so even if the first few characters of this word are included in the comparison, it will have no effect on whether a line is correctly detected as a duplicate. In the end, applying uniq -f 3 - w 15 to the input seems to produce the desired result.\nOne additional thing to note is that when we only consider one part of lines in the duplicates detection, all the lines in the group of \"duplicates\" need not be entirely identical, and so we must decide which one will be printed in the output. uniq prints the first one, but can be made to print the last one by first running the input through tac.\n", "Q: Troubleshoot ssh prompting for password I am using Ubuntu 15.10 and I am having trouble to login through ssh without password although I added my ssh keys. It was working before and then suddenly stopped working. I do not know what I did exactly to make it stop working. Could you help me troubleshoot this? Is there a way to reset everything and start from the beginning?\nWhile trying to fix it, I run several times but without success the following 2 commands:\nssh-keygen -t rsa\nssh-copy-id myusername@remotehost\n\nNow in the remote machine when i do:\ncat authorized_keys\n\nIt gives me three keys.\nAnd in the client machine:\nHere are the permisions that I have for .ssh folder:\ndrwx------  2 user user    4096 Apr 18 09:44 .ssh\n\nAnd here are the permissions inside that folder:\n-rw------- 1 user user  822 Apr 15 13:08 authorized_keys\n-rw------- 1 user user 1679 Apr 18 09:44 id_rsa\n-rw-r--r-- 1 user user  411 Apr 18 09:44 id_rsa.pub\n-rw-r--r-- 1 user user 2335 Apr 14 16:06 known_hosts\n\nHere is the verbose outpout:\n$ ssh -v user@localhost\nOpenSSH_6.9p1 Ubuntu-2ubuntu0.1, OpenSSL 1.0.2d 9 Jul 2015\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug1: Connecting to localhost [127.0.0.1] port 22.\ndebug1: Connection established.\ndebug1: identity file /home/user/.ssh/id_rsa type 1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/user/.ssh/id_rsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/user/.ssh/id_dsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/user/.ssh/id_dsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/user/.ssh/id_ecdsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/user/.ssh/id_ecdsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/user/.ssh/id_ed25519 type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /home/user/.ssh/id_ed25519-cert type -1\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_6.9p1 Ubuntu-2ubuntu0.1\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_6.9p1 Ubuntu-2ubuntu0.1\ndebug1: match: OpenSSH_6.9p1 Ubuntu-2ubuntu0.1 pat OpenSSH* compat 0x04000000\ndebug1: Authenticating to localhost:22 as 'user'\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug1: kex: server->client chacha20-poly1305@openssh.com <implicit> none\ndebug1: kex: client->server chacha20-poly1305@openssh.com <implicit> none\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\ndebug1: Server host key: ecdsa-sha2-nistp256 SHA256:/CGAtknCe0ao9c+ZRoBDrbdBEaoweEKCtN0r+gO9Nyg\ndebug1: Host 'localhost' is known and matches the ECDSA host key.\ndebug1: Found key in /home/user/.ssh/known_hosts:6\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug1: Authentications that can continue: publickey,password\ndebug1: Next authentication method: publickey\ndebug1: Offering RSA public key: /home/user/.ssh/id_rsa\ndebug1: Server accepts key: pkalg ssh-rsa blen 279\ndebug1: Trying private key: /home/user/.ssh/id_dsa\ndebug1: Trying private key: /home/user/.ssh/id_ecdsa\ndebug1: Trying private key: /home/user/.ssh/id_ed25519\ndebug1: Next authentication method: password\n\nI just noticed this and home it gonna be a hint for something:\ndebug1: Offering RSA public key: /home/user/.ssh/id_rsa\n42  debug1: Server accepts key: pkalg ssh-rsa blen 279      42  debug1: Server accepts key: pkalg ssh-rsa blen 279\n43  debug1: Trying private key: /home/user/.ssh/id_dsa      43  debug1: Trying private key: /home/user/.ssh/id_dsa\n44  debug1: Trying private key: /home/user/.ssh/id_ecdsa        44  debug1: Trying private key: /home/user/.ssh/id_ecdsa\n45  debug1: Trying private key: /home/user/.ssh/id_ed25519      45  debug1: Trying private key: /home/user/.ssh/id_ed25519\n\nI do not have these files in my .ssh folder here is what i have:\n-rw------- 1 user user 1233 Apr 18 12:31 authorized_keys\n-rw------- 1 user user 1679 Apr 18 09:44 id_rsa\n-rw-r--r-- 1 user user  411 Apr 18 09:44 id_rsa.pub\n-rw-r--r-- 1 user user 2335 Apr 14 16:06 known_hosts\n\nThanks\n\nA: The solution that I found is kind of extreme, but solved the issue:\nsudo apt-get --purge remove openssh-client openssh-server\n\nThen rename my .ssh folder, and started from scratch. this fixed the problem from my localhost connection as well as other remote servers I am using. I had obviously to copy the public key to all machines.\nThanks\n", "Q: Ubuntu 14.04 waiting for network configuration on ESXi I'm running Ubuntu 14.04.4 LTS on VMWare ESXi 5.5 with 2x E1000 Adapters (tried VMXNET 3 aswell, but no changes on the issue below)\nI'm using 2 static public IP's, but the server is continuesly waiting for it's network connection, and only 1 IP at the time is working (sometimes eth0, sometimes eth1)\nMy /etc/network/interfaces file:\n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# The primary network interface\nauto eth0\niface eth0 inet static\n        address xx.x.66.169\n        netmask 255.255.255.224\n        network xx.x.66.160\n        gateway xx.x.66.161\n        dns-nameservers 8.8.8.8 8.8.4.4\n\nauto eth1\niface eth1 inet static\n        address xx.x.66.170\n        netmask 255.255.255.224\n        network xx.x.66.160\n        gateway xx.x.66.161\n        dns-nameservers 8.8.4.4 8.8.8.8\n\nifconfig -a output:\nusr@server:~$ ifconfig -a\neth0      Link encap:Ethernet  HWaddr 00:0c:29:c5:a1:0a\n          inet addr:xx.x.66.169  Bcast:xx.x.66.191  Mask:255.255.255.224\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:196 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:21341 (21.3 KB)  TX bytes:0 (0.0 B)\n\neth1      Link encap:Ethernet  HWaddr 00:0c:29:c5:a1:14\n          inet addr:xx.x.66.170  Bcast:xx.x.66.191  Mask:255.255.255.224\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:314 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:166 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:35728 (35.7 KB)  TX bytes:29220 (29.2 KB)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nAs of now, I can connect to the server on the .170 address, but not on the .169.\nWhen attempting ifdown eth0 && ifup eth0, I get the error message that eth0 is not configured:\nifdown: interface eth0 not configured\nRTNETLINK answers: File exists\nFailed to bring up eth0.\n\nAny ideas on how to fix this issue ?\n\nA: It looks like it thinks your network interface is in a half-configured state.\nUbuntu will say interface eth0 not configured when it doesn't think that eth0 is configured as specified in /etc/network/interfaces, or the interface wasn't configured using the ifdown/ifup system.  The RTNETLINK answers: File exists happens when something like an IP address or route is already configured, and it tries to configure it a second time (not the best error message, I agree!).\nI tend to see this problem when changing the /etc/network/interfaces config. Usually, if I'm directly sitting at the machine, I will ifdown the interface, change the config, and then ifup it to not trigger this.\nIn this case, you need to manually clean up the interface state.\nSo, do this, from the VMware console (not over SSH as you are taking some of the networking down and might lock yourself out).\n#will probably get an error- thats fine\nifdown eth0\n# remove default gateway route\nip route del default via xx.x.66.161 dev eth0\n# remove the IP address on the interface\nip addr del xx.x.66.169/27 dev eth0\n# Mark the interface as down\nifconfig eth0 down\n# Use the /etc/network/interfaces config system to configure the interface\nifup eth0\n\nIf you still have problems after that, it might be because of having gateway stuff on both connections -- but I might just be being overly cautious about that since I have never really run a setup that way.\n", "Q: Enrolled in AD realm, but can´t resolve AD users with getent passwd Situation:\nWindows SBS Server (AD controller, DNS server), Proxmox 4.1 server hosting a Ubuntu 14.04 lxc container.\nWhat I want to achieve:\nIntegrate the Ubuntu container into the AD, so that I´m able to log in with AD credentials.\nWhat I did:\nI followed this guide:\nhttp://koo.fi/blog/2015/06/16/ubuntu-14-04-active-directory-authentication/?replytocom=3415#respond\nThis worked fine for me the first time, except I had to edit the nsswitch.conf. Then I had to shut down both physical servers to install new fans and clean them. After rebooting them I can´t login with any AD user in Ubuntua anymore, resolving them using getent doesn´t return anything.\nI´ve set up multiple new containers (with a new IP and a different name of course) and followed the guide again. I can enroll in the realm, but I still can´t resolve the AD users.\nThe configuration is exactly the same in all containers.\nAny tipps for me? Any logs I can provide?\nThanks in advance.\nEdit (160421):\nFollowing the above steps with a Ubuntu 14.04 KVM machine works. I can resolve users using getent, I can su AD-user, I can log in over ssh with AD users.\nAll containers that have been enrolled in the AD realm appear in the AD management console on the windows server in the desired ou.\n\nHere´s the configuration:\nkrb5.conf:\n[libdefaults]\n    default_realm = MY.DOMAIN\n\n    krb4_config = /etc/krb.conf\n    krb4_realms = /etc/krb.realms\n    kdc_timesync = 1\n    ccache_type = 4\n    forwardable = true\n    proxiable = true\n\n\n    v4_instance_resolve = false\n    v4_name_convert = {\n            host = {\n                    rcmd = host\n                    ftp = ftp\n            }\n            plain = {\n                    something = something-else\n            }\n    }\n    fcc-mit-ticketflags = true\n\n[realms]\n    MY.DOMAIN= {\n    kcd = domain-server\n    admin_server = domain-server\n    default_domain = my.domain\n    }\n[domain_realm]\n     .my.domain= MY.DOMAIN\n      my.domain= MY.DOMAIN\n\n[login]\n    krb4_convert = true\n    krb4_get_tickets = false\n\nrealmd.conf:\n[service]\nautomatic-install = no\n\n[users]\ndefault-home = /home/%D/%U\ndefault-shell = /bin/bash\n\n[c4b.local]\ncomputer-ou = OU=Linux_2,DC=my,DC=domain\nautomatic-id-mapping = yes\nfully-qualified-names = no\n\nnsswitch.conf:\npasswd:         compat sss\ngroup:          compat sss\nshadow:         compat\n\nhosts:          files dns\nnetworks:       files\n\nprotocols:      db files\nservices:       db files\nethers:         db files\nrpc:            db files\nnetgroup:       nis sss\nsudoers:        files sss\n\nRunning realm list returns:\nmy.domain\n  type: kerberos\n  realm-name: MY.DOMAIN\n  domain-name: my.domain\n  configured: kerberos-member\n  server-software: active-directory\n  client-software: sssd\n  required-package: sssd-tools\n  required-package: sssd\n  required-package: libnss-sss\n  required-package: libpam-sss\n  required-package: adcli\n  required-package: samba-common-bin\n  login-formats: %U\n  login-policy: allow-realm-logins\n\n\nA: Ok, there were two problems:\n1) I installed ntp and set the windows server as the only timesource, but forgot to set the timezone.\n2) The permissions for /etc/sssd/sssd.conf were wrong. The file needs to be owned by root.root and needs to have 0600 permissions.\nNow I am able to resolve AD-users and groups and I can log in with AD-users. Only su AD-user doesn´t work, but this is irrelevant for my setup.\n", "Q: Logo of NVIDIA appearing during booting While I was turning on my PC today (Ubuntu 14.04), and before the log in screen appeared, there was for just a moment a screen about NVIDIA which hadn't appeared before. It wasn't an error message or text but the logo of NVIDIA. The screen flashed so quick that I didn't get to see it properly though. Was there any updates that changed the way that NVIDIA advertises the drivers that the PC uses?\n\nA: Nothing weird about that if you are using NVIDIA's priopriatary driver... Perhaps it got updated and now shows that logo or maybe this time it just worked a little slower and showed itself for a while longer. I have NVIDIA drivers on two machines and one time logo shows and other is just too fast to notice or display does not react to screen mode change that fast...\n", "Q: Unable to connect to the Internet using wired connection, even when its plugged in I recently clean installed Ubuntu without dual boot, so everything was erased, but now I'm unable to connect to the Internet, even using wired connection. On \"Connection Information\", it says it is \"Active Network Connections\" but I can't get online. Here are the results of some commands that I found online:\nifconfig\n\neth0      Link encap:Ethernet  HWaddr 00:23:54:2a:b5:fd  \n          inet addr:10.42.0.1  Bcast:10.42.0.255  Mask:255.255.255.0\n          inet6 addr: fe80::223:54ff:fe2a:b5fd/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:138 errors:0 dropped:5 overruns:0 frame:0\n          TX packets:1730 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:15637 (15.6 KB)  TX bytes:337255 (337.2 KB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:6386 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:6386 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:502340 (502.3 KB)  TX bytes:502340 (502.3 KB)\n\n----------------------------------------------\nsudo lshw -C network\n\n*-network               \n       description: Ethernet interface\n       product: RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller\n       vendor: Realtek Semiconductor Co., Ltd.\n       physical id: 0\n       bus info: pci@0000:0c:00.0\n       logical name: eth0\n       version: 02\n       serial: 00:23:54:2a:b5:fd\n       size: 10Mbit/s\n       capacity: 1Gbit/s\n       width: 64 bits\n       clock: 33MHz\n       capabilities: pm msi pciexpress msix vpd bus_master cap_list rom ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd 1000bt 1000bt-fd autonegotiation\n       configuration: autonegotiation=on broadcast=yes driver=r8169 driverversion=2.3LK-NAPI duplex=half ip=10.42.0.1 latency=0 link=yes multicast=yes port=MII speed=10Mbit/s\n       resources: irq:28 ioport:e800(size=256) memory:fcfff000-fcffffff memory:fcfe0000-fcfeffff memory:fea00000-fea0ffff\n------------------------------------------------\nsudo ifconfig -a\n\neth0      Link encap:Ethernet  HWaddr 00:23:54:2a:b5:fd  \n          inet addr:10.42.0.1  Bcast:10.42.0.255  Mask:255.255.255.0\n          inet6 addr: fe80::223:54ff:fe2a:b5fd/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:410 errors:0 dropped:12 overruns:0 frame:0\n          TX packets:1799 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:43699 (43.6 KB)  TX bytes:345354 (345.3 KB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:7716 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:7716 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:613180 (613.1 KB)  TX bytes:613180 (613.1 KB)\n\n--------------------------------------------------\nlspci -nnk | grep -i net -A2\n\n0c:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller [10ec:8168] (rev 02)\n    Subsystem: Lenovo Device [17aa:2108]\n    Kernel driver in use: r8169\n---------------------------------------------------\ncat/etc/network/interfaces\nbash: cat/etc/network/interfaces: No such file or directory\n---------------------------------------------------\n cat /etc/resolv.conf\n# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)\n#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN\n-----------------------------------------------------\nroute -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n10.42.0.0       0.0.0.0         255.255.255.0   U     1      0        0 eth0\n--------------------------------------------\ncat /var/lib/NetworkManager/NetworkManager.state\n[main]\nNetworkingEnabled=true\nWirelessEnabled=true\nWWANEnabled=true\nWimaxEnabled=true\n------------------------------------------\n sudo ethtool eth0\nSettings for eth0:\n    Supported ports: [ TP MII ]\n    Supported link modes:   10baseT/Half 10baseT/Full \n                            100baseT/Half 100baseT/Full \n                            1000baseT/Half 1000baseT/Full \n    Supported pause frame use: No\n    Supports auto-negotiation: Yes\n    Advertised link modes:  10baseT/Half 10baseT/Full \n                            100baseT/Half 100baseT/Full \n                            1000baseT/Half 1000baseT/Full \n    Advertised pause frame use: Symmetric Receive-only\n    Advertised auto-negotiation: Yes\n    Link partner advertised link modes:  10baseT/Half \n    Link partner advertised pause frame use: No\n    Link partner advertised auto-negotiation: No\n    Speed: 10Mb/s\n    Duplex: Half\n    Port: MII\n    PHYAD: 0\n    Transceiver: internal\n    Auto-negotiation: on\n    Supports Wake-on: pumbg\n    Wake-on: g\n    Current message level: 0x00000033 (51)\n                   drv probe ifdown ifup\n    Link detected: yes\n----------------------------------\ncat syslog\ncat: syslog: No such file or directory\n\nPlease help me, thank you very much\n\nA: Notice that your ethernet has an IP address, the very unusual 10.42.0.1. That suggests that the ethernet is set to be shared with another computer on the network; instead, it should be set to ask for and receive an IP address from your router, switch or other access point.\nPlease click the Network Manager icon, select 'Edit Connections,' highlight the ethernet connection and select 'Edit.' Select IPv4 settings and make sure it is set to 'Automatic (DHCP).'\n\nRestart Network Manager from the terminal:\nsudo service network-manager restart\n\nAny improvement?\n", "Q: In file browser: connect to ssh server via other ssh server in my file browser I have problems connecting remotely to a machine which sits behind a nasty firewall. Usually in a terminal our procedure to connect to that server goes via an ssh connection within another ssh session connecting to the \"portal\" to that server. In the terminal it goes like this:\nssh -p portNumber myName@portalServer.com/\nssh serverBehindFirewall\n\nBut how can I do the same using Ubuntu's \"connect to server\" function? I can connect easily to the portal server like this:\nssh://myName@portalServer.com:portNumber/\n\nBut how do I add in the additional ssh connection?\nIs it possible to have something like:\nssh://myName@portalServer.com:portNumber/ssh://serverBehindFirewall\n\nLooking forward for your answers!\n\nA: You could use ssh port forwarding on the console, so you could connect directly from your computer to serverBehindFirewall.\n# This will open a tunnel from your local machine, port 22022 to port\n# 22 on serverBehindFirewall. You'll need to leave this window open.\nlocalmachine:~$ ssh -L22022:serverBehindFirewall:22 myName@portalServer.com\n\n# now you can open a second terminal on your local machine and\n# connect directly to serverBehindFirewall on localhost:22022\nlocalmachine:~$ ssh -p 22022 userbehindFirewall@localhost\n\nAfter the first step, you can also use the \"connect to server\" function with ssh://userbehindFirewall@localhost:22022/. If you want it as a permanent solution, you could use something like autossh (Homepage, Guide)\n", "Q: Can I take a screenshot and directly open it in Gimp? Common use case for me and printscreen:\n\n\n*\n\n*Hit printscreen and save .png\n\n*Open up Gimp\n\n*Find file I've saved\n\n*Edit file (crop and highlight regions)\n\n\nIt seems like the first three steps could be combined into a single key bind, e.g. printscreen auto opens Gimp, ready to edit. Is that possible?\n\nA: With xfce4-screenshooter you can choose from programs to open screenshot with, or save it. Supports selecting area, delay before taking screenshot. Directly point-and-click solution. \n\n\nA: For xfce and Xubuntu users, the action can be achieved with the following command:\nxfce4-screenshooter -f -o gimp\n\nTo implement, change the shortcut in Settings -> Keyboard, as shown below:\n\n\nA: If you're willing to switch screenshot applications, this is an option that scrot provides:\n   -e, --exec APP\n        Exec APP on the saved image.\n…\nEXAMPLE\n       scrot '%Y-%m-%d_$wx$h.png' -e 'mv $f ~/shots/'\n       This would create a file called something like 2000-10-30_2560x1024.png\n       and move it to your shots directory.\n\nSo, you could change the PrntScr shortcut to run:\nscrot -e 'gimp $f'\n\n\nShutter, another screenshot application, provides some editing facilities itself, so you might not even need to start GIMP at all.\n\n\n\nA: Quick version\nLiterally doing what you asked; in one action:\n\n\n*\n\n*Take a screenshot\n\n*Save it in your preferred directory\n\n*Opening it with Gimp\n\nThe script\n#!/bin/bash\n\npicsdir=~/Pictures/out.png\ngnome-screenshot -f \"$picsdir\"\ngimp \"$picsdir\"\n\nHow to use\n\n\n*\n\n*Copy the script into an empty file, save it as take_ashot.sh\n\n*Set your preferred directory to save the files in, in the line:\npicsdir=~/Pictures/out.png\n\nI'd leave it as it is if your system is English, else you'd need to change the Pictures folder name. \n\n*Test-run it by the command:\n/bin/bash /path/to/take_ashot.sh\n\n\n*If all works fine, add it to a shortcut: Choose: System Settings > \"Keyboard\" > \"Shortcuts\" > \"Custom Shortcuts\". Click the \"+\" and add the command:\n/bin/bash /path/to/take_ashot.sh\n\nNote\nSince you mentioned not to save the source file in most cases, I made the script overwrite previous files. If you don't want that, we'd need to build in a few renaming- lines.\n\nA: Why not just take the screenshot with Gimp? File > Create > Screenshot.\n\nThis requires no intermediate storage at all.\n\nA: If you're running Gnome then you can use the built-in screenshot shortcuts to at least bypass the \"save to disk and open the file\" step.\n\n*\n\n*Press the appropriate \"to clipboard\" shortcut (basically the standard \"save to file\" shortcut with Ctrl):\n\n*\n\n*Ctrl+PrintScreen\n\n*Ctrl+Alt+PrintScreen to capture a window\n\n*Ctrl+Shift+PrintScreen to capture an area\n\n\n\n*Open GIMP\n\n*If there are no images open in GIMP, Ctrl+V pastes as a new image\n\nThe shortcuts are configurable in Gnome Settings under Keyboard > View and customise shortcuts > Screenshots.\n\nI've disabled saving screenshots because I use custom shortcuts with gnome-screenshot to save to ~/temp/ rather than ~/Pictures/ (because I care about Pictures but not about anything in temp, like random screenshots)\n\nA: For Linux Mint version Mate, just run the commands below to configure your system once and press the PrtScn on your keyboard.\nsudo apt install scrot\ngsettings set org.mate.Marco.global-keybindings run-command-screenshot \"disabled\"\ndconf write /org/mate/desktop/keybindings/custom0/action \\'\"scrot -e \\\"gimp \\$f\\\"\"\\'\ndconf write /org/mate/desktop/keybindings/custom0/binding \\'Print\\'\ndconf write /org/mate/desktop/keybindings/custom0/name \\'PrintScreen\\'\n\nThe screenshot will be saved in your home folder at ~/ if you don't want them there, you can always use this below to move the screenshot in the /tmp folder:\ndconf write /org/mate/desktop/keybindings/custom0/action \\'\"scrot -e \\\"mv \\$f /tmp; gimp /tmp/\\$f\\\"\"\\'\n\n", "Q: Echo command hangs when writing to serial device I have a serial device set to raw mode with stty -F /dev/ttyS0 raw. When i try to send any data through it with echo 'hello' > /dev/ttyS0, following happens:\n\n\n*\n\n*No data is recieved by the other side; oscilloscope shows no data is being sent\n\n*No prompt appears for approximately 40 seconds, terminal seems to be hanging\nWhat could be the reason for this behaviour?\nP.S. The serial port settings as output with stty -F /dev/ttyS0 -a are:\n\nspeed 9600 baud; stty: /dev/ttyS0 line = 0; intr = ^C; quit = ^\\;\n  erase = ^?; kill = ^U; eof = ^D; eol = < undef>; eol2 = < undef>;\n  swtch = < undef>; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase\n  = ^W; lnext = ^V; flush = ^O; min = 1; time = 0;\n  -parenb -parodd cs8 hupcl -cstopb cread clocal -crtscts\n  -ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr -icrnl -ixon -ixoff -iuclc -ixany -imaxbel -iutf8\n  -opost -olcuc -ocrnl -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0\n  -isig -icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke\n\n\nA: If one uses RTS/CTS hardware flow control then the serial will block waiting for the RTS (Ready-To-Send).  You probably want to enable software flow control instead by disabling CTS and RTS:\nstty -F /dev/ttyS0 -crtscts\n\n\nA: After long search for the possible reason, i happened across the solution. It had to do with a certain error during initialisation of my hardware under linux. Solution was to manually (well, from a program run with elevation) set a flag that controlled signal level for interruptions.\nAfter that was set, serial port started working as expected.\nI have found solution here: linux.org forums. It references superiotool as inspiration\n", "Q: Ubuntu 14.04.4 keeps logging me out I installed ubuntu 14.04.4 on my laptop last ight and it keeps logging me out. Its not my display setting i have it set to never turn the screen off. when it logs me out it closes all programs and turns off num lock its almost like its doing a reboot but not rebooting all the way. I think it might be an xorg issue but do not fully understand how to fix that. \nI have tried changing my hardware acceleration from good to fast and it did not work so i tired switching it from fast to best and that still has not worked.\nMemory 3.8 gb\nprocessor: intel core i3-5020u\nGraphics: intel HD Graphics 5500(broadwell GT2)\nOS type 64-bit\ndisk 980.3 GB\nScript for ibus started at run_im.\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd main process ended, respawning\ninit: at-spi2-registryd respawning too fast, stopped\n\ndmesg| tail \n[  463.283921] traps: compiz[2178] general protection ip:7f808536235c sp:7ffdf84a3570 error:0 in ld-2.19.so[7f808534f000+23000]\n[  663.464382] traps: compiz[3194] general protection ip:7fd00761f35c sp:7ffce5a5fc10 error:0 in ld-2.19.so[7fd00760c000+23000]\n[  959.854820] systemd-hostnamed[4443]: Warning: nss-myhostname is not installed. Changing the local hostname might make it unresolveable. Please install nss-myhostname!\n[ 2671.419581] traps: compiz[4177] general protection ip:7fb4b4d7535c sp:7ffc94b9cc60 error:0 in ld-2.19.so[7fb4b4d62000+23000]\n[ 2672.896054] [drm:gen8_irq_handler [i915]] *ERROR* The master control interrupt lied (SDE)!\n[ 2906.746254] traps: compiz[5593] general protection ip:7fbb13eca35c sp:7ffdb5d2d7f0 error:0 in ld-2.19.so[7fbb13eb7000+23000]\n[ 2906.785327] systemd-hostnamed[5942]: Warning: nss-myhostname is not installed. Changing the local hostname might make it unresolveable. Please install nss-myhostname!\n[ 2931.320379] traps: compiz[6533] general protection ip:7f30c302035c sp:7ffdccd40fe0 error:0 in ld-2.19.so[7f30c300d000+23000]\n[ 2932.490230] [drm:gen8_irq_handler [i915]] *ERROR* The master control interrupt lied (SDE)!\n[ 2932.490411] [drm:gen8_irq_handler [i915]] *ERROR* The master control interrupt lied (SDE)!\n\n\nA: I solved my problem by removing ubuntu 14.04 and installing elementary OS. I was kind of iffy about it at first but wow elementary is a great OS very solid so far have had no issues.\n", "Q: How to mount directory from vagrant box on local FS using SSHFS? I want to mount the / of the vagrant box on to the local fs using sshfs.\nthe command i used was\nsshfs hadoopuser@192.168.0.106:/ .\nThe authenticity of host '192.168.0.106 (192.168.0.106)' can't be established.\nECDSA key fingerprint is 9d:80:94:dc:f1:c4:bc:30:2d:e0:e2:7e:7c:5d:46:e3.\nAre you sure you want to continue connecting (yes/no)? yes\nhadoopuser@192.168.0.106's password: \nhadoopuser@192.168.0.106's password: \nhadoopuser@192.168.0.106's password: \nread: Connection reset by peer\n\nhow do i solve this problem? \nAnd \n\n\n*\n\n*where do i find the public key for my machine\n\n*Where do i keep it on the other machine so that the login authentication is done via keys?\n\nA: If you're on Ubuntu your keys are stored in\n/home/<user>/.ssh/\n\nyou will need your public key id_rsa.pub.\nIf you don't have it then do\nmkdir ~/.ssh\nchmod 700 ~/.ssh\nssh-keygen -t rsa\n\nOn your remote server you'll need to copy your public key into\n/root/.ssh/authorized_keys\n\neither manually copy/paste or using commands like\nssh-copy-id <username>@<host>\n\nor if you need to copy someone else's public key do\nscp id_rsa.pub <username>@<host>:/root/.ssh/ #copies file to remote server\nssh <username>@<host> # login to remote server\ncd /root/.ssh/ # go to copied file\ncat id_rsa.pub >> authorized_keys # concatenate it onto the authorized_keys\n\nSource: help.ubuntu.com\n", "Q: Can't install Ubuntu 15.10 from USB - Windows Dualboot I've installed Ubuntu on several other machines but cant get it to run on my new build. \nI'v created a bootable USB drive using the official 15.10 iso from ubuntu using pendrive linux. Secure boot is disabled, fast boot is disabled and IOMMU is enabled. When booting from USB the I get the list where I select \"Install Ubuntu.\" The Ubuntu Logo screen appears and then I get this error screen:\n\nHere is my BIOS Info:\n\nSystem info:\n\n\n*\n\n*Gigabyte GA 970 Gaming\n\n*AMD FX 8320\n\n*GTX 960 4gb SSC\n\n*16gb Crucial Ram\n\n*Kingston 120gm SSD (Reserved for Linux install)\n\n*M2 SSD (Running Windows OS)\n\n*WD 1TB HDD (Windows Storage) \n\n\nAny ideas on how to get past this?\n\nA: I've had some issues with a usb and 15.10 too. I solved it by going old-school, burn the iso to a dvd and installed it that way. Maybe this works for you too, if not.... Well, at least you tried.\n\nA: You are facing an NVIDIA graphics related issue ... and that is what you have to do :  \nStep 1 : Ubuntu system installation  \nBoot from the installation media and select Try Ubuntu without installing.\nPress the E key - add nouveau.modeset=0 at the end of the linux line.\nSet a Space between the last character in the linux line and nouveau.modeset=0.\nPress the F10 key to boot into the Ubuntu Live desktop and now install Ubuntu.  \nStep 2 : NVIDIA drivers installation\nWhen finished reboot the system and now select the Ubuntu menu entry.\nPress the E key - add nouveau.modeset=0 at the end of the linux line.\nSet a Space between the last character in the linux line and nouveau.modeset=0.\nPress the F10 key to boot into the Ubuntu system and install the NVIDIA drivers.  \nReboot the Ubuntu system ... now you don't have to add the parameter any more.\n", "Q: find Noise level iwlist and iwconfig commands I'm tryng to find out the noise level, and the commands below should show the information in the Quality lines, but somehow it doesn't show.\nAny ideas?\niwlist scan\nwlp3s0    Scan completed :\n      Cell 01 - Address: 30:B5:C2:B4:F2:A8\n                Channel:11\n                Frequency:2.462 GHz (Channel 11)\n         --->   Quality=70/70  Signal level=-40 dBm\n                Encryption key:on\n                ESSID:\"Ariel\"\n                Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s; 6 Mb/s\n                          9 Mb/s; 12 Mb/s; 18 Mb/s\n                Bit Rates:24 Mb/s; 36 Mb/s; 48 Mb/s; 54 Mb/s\n                Mode:Master\n                Extra:tsf=0000000000000000\n                Extra: Last beacon: 499772ms ago\n                IE: Unknown: 0005417269656C\n                IE: Unknown: 010882848B960C121824\n                IE: Unknown: 03010B\n                IE: Unknown: 2A0100\n                IE: IEEE 802.11i/WPA2 Version 1\n                    Group Cipher : CCMP\n                    Pairwise Ciphers (1) : CCMP\n                    Authentication Suites (1) : PSK\n                IE: Unknown: 32043048606C\n                IE: Unknown: 2D1AAD0103FFFF000000000000000000000000000000000000000000\n                IE: Unknown: 331AAD0103FFFF000000000000000000000000000000000000000000\n                IE: Unknown: 3D160B071700000000000000000000000000000000000000\n                IE: Unknown: 34160B071700000000000000000000000000000000000000\n                IE: Unknown: DD180050F2020101850003A4000027A4000042435E0062322F00\n                IE: Unknown: DD0900037F01010000FF7F\n                IE: Unknown: DD9B0050F204104A0001101044000102103B000103104700100001020304050607080930B5C2B4F2A91021000754502D4C494E4B1023000A544C2D5744523433303010240003312E3010420003312E301054000800060050F20400011011001A576972656C65737320526F7574657220544C2D57445234333030100800020086103C000101104900140024E26002000101600000020001600100020001\n\nsudo iwconfig wlp3s0\nwlp3s0    IEEE 802.11abg  ESSID:\"Ariel\"  \n        Mode:Managed  Frequency:2.462 GHz  Access Point: 30:B5:C2:B4:F2:A8   \n        Bit Rate=144 Mb/s   Tx-Power=200 dBm   \n        Retry short limit:7   RTS thr:off   Fragment thr:off\n        Encryption key:off\n        Power Management:off\n --->   Link Quality=70/70  Signal level=-40 dBm\n        Rx invalid nwid:0  Rx invalid crypt:0  Rx invalid frag:0\n        Tx excessive retries:0  Invalid misc:0   Missed beacon:0\n\n\nA: There is another question similar to this. It looks like this is because of driver capabilities\nhttps://stackoverflow.com/questions/11232433/iwconfig-does-not-show-noise-level-for-wireless\n\nA: iw survey:\neg:\niw wlan1 survey dump\n\nOutput is each frequency and has noise:\nSurvey data from wlan1\n        frequency:                      2437 MHz [in use]\n        noise:                          -105 dBm\n        channel active time:            50 ms\n        channel busy time:              17 ms\n\n\nYour wifi driver needs to support it, some come out with an empty output\n", "Q: Ubuntu 14.04 only boots with USB stick My Ubuntu screen turns black after boot up, unless I insert the \"live\" USB in the PC before booting up.  I have tried different distros, USB sticks and computers and they all have the same issue.\nDo I need to change Grub files?  How can I resolve this issue?\n\nA: Your grub is surely not installed in your Hard drive but your booting device... Install grub on your Hard Disk Drive and observe again.\n", "Q: Is there any Auto-scroll focus in Ubuntu? In Windows 10, there is a nice new behavior with the scrolling:\nWhen you start to scroll on a window who aren't focus, window acquire the focus and scroll automatically.\nIn the previous Window and Ubuntu, you have to click, and then scroll, which is not convenient.\nI wonder if there any tips in Ubuntu for such a behavior.\nThanks !\n\nA: I use Kubuntu 14.04.1 LTS, and I can scroll a background window without it coming to the foreground, using the mouse scroll wheel.  All I do is hover the mouse cursor over a visible portion of the window I want to scroll, and roll the wheel.  This in KDE/Plasma desktop, which is the only Ubuntu I've used, so I don't know if the capability exists in other Ubuntu desktop environments.\n", "Q: how can I print multiple odt files from the command line? I have a bunch of odt files in a directory I want to print.\nI tried lpr *.odt I got so much junk print outs.  Clearly that isn't the answer, so what is?\n\nA: lowriter -p file.odt does the job for one file. The help text* says it works on multiple files, so you could use lowriter -p *odt to do the lot, or some form of shell script to specify those you want...\nI didn't test this on multi files myself, but do use it for singles.\n*The output of lowriter --help is helpful!\nlpr is sending raw data to your printer, and .odt files are not raw text; it will print a .txt or .asc file OK.\n", "Q: RTL8723BE no module loaded after reboot When I'm trying to install windows driver for RTL8723BE on Lenovo IdeaPad100 wlan0 disappeared. I fixed it with this:  \nhttps://askubuntu.com/a/593015/531813 \nbut after reboot I must type:  \nsudo modprobe -r \nsudo modprobe rtl8723be  \n\nHow I can load modules on boot/why it is not loaded now?\n\nA: It should be fixed by\nsudo update-initramfs -u\n\nBut still you will have to re-install the driver after kernel updates.\nYou can also install the same driver in DKMS format from a PPA.\nhttps://askubuntu.com/a/635629/167850\nThis way you won't need to re-install it every time you upgrade a kernel.\nBut most likely you will need to uninstall the driver from git first.\n\nA: I fixed it by adding rtl8723be to /etc/modules\n", "Q: How to install wxpython ubuntu 16.04 I have a problem with playonlinx, and it requires me to install wxpython, but I have it already installed. I've used different methods, but every-time I do import wx, it gives me this error:\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named wx\n\nSo I don't know what to do now, I've also installed and reinstalled playonlinux, and still it doesn't work.\n\nA: Meanwhile it's possible to install wxPython with sudo pip install wxpython, eventually you have to use sudo pip install --upgrade wxpython. If you need 4.x which isn't provided by Ubuntu (for some years) this is the sanest option.\n\nA: I could install it by typing in a terminal:\nsudo apt-get install python-wxgtk3.0\n\nI don't know but I think that the older versions (2.8, 2.6, …) aren't currently in the 16.04 repositories.\n\nA: I installed wxPython as part of the PsychoPy experiment builder dependencies, and had considerable trouble getting it to install properly as well initially. But this was what worked for me at the end. I use Ubuntu 16.04, python 3.5, pip3 19.0.3\npip3 install -U     -f https://extras.wxpython.org/wxPython4/extras/linux/gtk3/ubuntu-16.04     wxPython --user\n\n", "Q: Newbie: Slow Apache2 Response Time As the title says I'm a newbie with this stuff but I'm willing to learn what I need to know. I'm simply ignorant atm. This is a Rackspace server with Ubuntu 15.10 running Apache2.\nI have a PHP web app that runs with (not yet optimized) good load times on my local machine but stalls for about 2-4 seconds on page load/reload on the server. This seems to be an accumulating stall. The more time that passes (users logging in?) the slower it seems to get.\nThings I've tried to troubleshoot and other information:\n\n\n*\n\n*I've checked both Chrome network tools and pingdom.com and both reveal that the first initial request is where the longest wait, not local or external resources. \n\n*Restarting apache helps a little but running the stop then start command seem to temporarily increase load speeds. One thing I noticed here is that I start to get quite a few entries under \"CGroup: /system.slice/apache2.service\" when I run the command \"systemctl status apache2.service\". I'm not sure if this should indicate anything to me or not.\n\n*I'm peaking at around 250m memory\n\n*Also, if it is pertinent, I am using nodejs, forever and socketio along side Laravel 5 though I don't think that any of this is the culprit for the long wait on the initial response.\n\n\nWhat other reports or logs do I need to generate or look at to determine what might be the cause? I've heard some people having an issue with \"resource leeching\" and others with DDOS. How might I rule something like this out?\nHere is a pingdom result of a faster load but still non-optimal. (I know, I need to bundle my scripts and styles ;) )\nhttp://tools.pingdom.com/fpt/#!/jl6bX/http://barkerbot.com/\nThank you in advance!\n\nA: There are many possible causes for performance issues, but for optimization in general i recommend using a Profiler. There is some discussion going on here\nPersonally i use XHProf/XHGui and did not try the others that much.\n", "Q: aptitude: symbol lookup error: aptitude: undefined symbol When I run the following in my terminal:\n aptitude search linux-headers | grep ^i\n\nI get the following error:\naptitude: symbol lookup error: aptitude: undefined symbol: _ZNK13Configuration10FindVectorB5cxx11EPKc\n\nHow can I fix this error?\n\nA: From this launchpad bug it looks like running the following will fix your issue:\nsudo apt-get install aptitude libapt-pkg4.16\n\nIf you get unable to locate package libapt-pkg4.16 run this:\napt-cache search libapt-pkg | grep 'package management' | cut -d ' ' -f1\n\nAnd replace libapt-pkg4.16 with whatever output you get from there (for me on 14.04 it's libapt-pkg4.12)\n", "Q: Why are utopic packages installed by default on 14.04.2? I've installed Ubuntu into VirtualBox 5.0.16 from a 14.04.2 iso image.  I didn't do anything fancy, just accepted the defaults all the way through the installation process, except choosing to install SSH server.\nThis is what I find in /var/log/apt/history.log, which must have been run automatically by the installation process.\nCommandline: apt-get --yes upgrade\nCommandline: apt-get -o APT::Status-Fd=4 -o APT::Keep-Fds::=5 -o APT::Keep-Fds::=6 -q -y --no-remove install linux-generic-lts-utopic\nCommandline: apt-get -o APT::Status-Fd=4 -o APT::Keep-Fds::=5 -o APT::Keep-Fds::=6 -q -y --no-remove install pciutils\nCommandline: apt-get -o APT::Status-Fd=4 -o APT::Keep-Fds::=5 -o APT::Keep-Fds::=6 -q -y --no-remove install usbutils\nCommandline: apt-get -o APT::Status-Fd=4 -o APT::Keep-Fds::=5 -o APT::Keep-Fds::=6 -q -y --no-remove install biosdevname\nCommandline: apt-get -o APT::Status-Fd=4 -o APT::Keep-Fds::=5 -o APT::Keep-Fds::=6 -q -y install tasksel\n....\n\nNotice one of the things it is installing is linux-generic-lts-utopic, even though this is trusty, not utopic.  Usually that wouldn't bother me, if the packagers want me to have utopic headers, fine.  Except when I do apt-get upgrade now, I get the message:\nThe following packages have been kept back:\n  linux-generic-lts-utopic linux-headers-generic-lts-utopic\n  linux-image-generic-lts-utopic\n0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\n\nWhy is it by-default installing things that it doesn't know how to upgrade?  I understand that can happen when you start mucking around with non-standard repositories, but I haven't done anything like that.\n\nA: There are no \"utopic\" packages installed by default in 14.04.2. However, 14.04.2 is the hardware enablement release, which includes the kernel version which was included in Utopic (14.10), by default. This is packaged as linux-generic-lts-utopic as you see in the package name.\nThe packages are held back, not because the system doesn't know how to upgrade them, but because they require installing new packages (a new kernel image). You will need to use apt-get dist-upgrade to install them from the CLI.\n", "Q: How to embed a terminal the desktop of Ubuntu 15.10 I tried the Compiz window rule. But it doesn't work for Ubuntu 15.10 since you can no longer customize the title of your gnome terminal. \nDo you guys have any idea how to do it? \n\n\nA: Here is how I do it!\n1.Download the Tilda. \n2.Set up the Tilda to your preferred position. \n3.In Compiz,  configure the Window Rules as follow.\nImage of window rules\n4.Add a startup option\nImage of startup application settings\n5.You are done!!!\n", "Q: How can I make an icon which presses a key when double- clicked? Is there any way to make a document/file when double clicked presses the Super key for example. I have no idea if something like this is possible on Ubuntu.\n\nA: You need a script written in bash or sh.\nFirst, install xdotool.\nThen, the file should have:\n#!/bin/sh\n\nxdotool key Super_L\n\nSave it as superkey.sh or whatever name, with the .sh extension.\nSuper_L refers to the Left Super key. You can also press other keys like Tab, Caps_Lock or so.\nNow set the file to execute - either through the file properties or the Terminal like chmod +x superkey.sh.\nYou can now double-click on the file and the Left Super key will be pressed.\n\nA: A simple way to create a double click-able icon, running a straightforward command, like simulating a key press, is using a .desktop file.\nIn your example:\n[Desktop Entry]\nName=Press Key\nExec=xdotool key Super_L\nType=Application\n\n\n*\n\n*Install xdotool, needed to simulate key press:\n  sudo apt-get install xdotool\n\n\n\n*Save the code above as presskey.desktop, make it executable (!) and enjoy :)\nNote\nYou can \"pimp\" your launcher with a custom icon, by adding the line:\nIcon=/path/to/icon.png\n\n\n", "Q: Virtual Box won't allow me to enter base memory I'm trying to install virtual box in my Ubuntu 15.04 machine. I specifically want to use Windows XP for some project. I used\nsudo apt-get install virtual box\n\nto install Virtual Box. After that I did this:\n\n*\n\n*Selected Windows architecture and Windows XP 64-Bit as OS. Entered Name as Windows XP\n\n\n*Now when I'm given the option to enter base memory. Virtual box won't let me move forward. here is the image of what is happening:\n\ncan someone please help?\n\nA: If you look in /home/<user>/VirtualBox VMs/<path to VM>\nLook for <VM>.vbox and edit this file\nLook for the Memory line and modify this carefully.\nRun the emulator an check the memory\n\nA: Your window looks very weird. Window Border looks like from Ambiance, but rest like from broken Redmond or like you've run it on WINE... Maybe try different theme? Or maybe your system is missing something required for this theme to work properly... Don't know what you have for changing themes, some tools can give clues in case you need to install additional libraries.\nYou can also try installing VirtualBox using latest version from it's website:\nhttps://www.virtualbox.org/wiki/Linux_Downloads\nYou can install it with:\nsudo dpkg -i virtualbox-5.0_5.0.18-106667~Ubuntu~wily_amd64.deb\n\nOr even better do it with \"Software Center\" or \"GDebi\" (dpkg might not work properly in some cases).\n", "Q: How can I disable continuous scrolling in ubuntu touchpad? In Trusty Tahr (14.04 LTS) when I use two-finger scrolling in everywhere, say chrome and it  sensed the touch-pad for 1 second to go up or down for scrolling. The website  continued the scrolling for 3 or 4 seconds. And  when I press any key on my keyboard, it's supposed to know that I am use that key with scrolling (say Ctrl+scrolling cause to zoom out or in very very much). Is there any way to turn off or disable this bad function?\n\nA: Your question is similar to this one (and was answered): Turn off trackpad scroll \"momentum\"\nRunning this command helps:\nsynclient CoastingSpeed=0\n\n", "Q: Installed Ubuntu, can't boot into Windows 10 http://paste.ubuntu.com/15919501/\nI'm not exactly sure how to boot into windows 10 again.\n\nA: *\n\n*There are some disk read/write errors. Please check the disk for any\nerrors.\n\n*Apart from this make sure that your BIOS points to the device where\n/boot is being created.\n\n\nA: I used the boot-repair software with the advanced options, and was able to boot into windows 10. Also I converted my windows install from legacy MBR to UEFI. This made it a lot easier to create a dual boot installation of ubuntu.\n", "Q: Acer_wmi blocking my wifi Every time I log in I have to type \"sudo rmmod acer_wmi\" to get wifi to work. How do I get this to run on startup or permanantly delete acer_wmi.\nThx\n\nA: Edit the blacklist: \nsudo vi /etc/modprobe.d/blacklist.conf\n\nAnd add the faulty module there (at the end): \nblacklist acer_wmi\n\nreboot and voilà\n\nA: You can blacklist that module. It is convenient to make a separate file. Run in terminal:\nsudo tee /etc/modprobe.d/blacklist-acer-wmi.conf <<< \"blacklist acer_wmi\"\n\n\nA: ​I realize I'm replying to this question rather late, but there's another method I've used when booting into liveUSBs. Since there is no easy way to edit their /etc/modprobe.d/ after creating the USB, add this snippet when you see the kernel selection screen add this by pressing [tab]\nmodprobe.blacklist=acer_wmi\n\nWhether this gets carried over from the liveUSB to the distro once it's been installed can be hit or miss. If it doesn't, adding this parameter to /etc/default/grub on the line containing GRUB_CMDLINE_LINUX_DEFAULT=\nNow every time you boot it'll be blacklisted!\nI'm not always the best at explaining things like this so if you need clarification please let me know. \n", "Q: Docker on Ubuntu Core - docker.service not found I am trying to get docker working on Ubuntu core using snappy to install.  I am following this guide.\nMy VM is behind a proxy but using http_proxy env settings and sudo -E I seem to be able to get snappy to install docker:\n(amd64)ubuntu@ubuntu-snappy:~$ snappy list -v\nName          Date       Version   Developer  \nubuntu-core   2016-02-25 16        ubuntu*    \ndocker        2016-04-18 1.6.2.005 canonical* \ngeneric-amd64 2016-02-25 1.4       canonical* \n(amd64)ubuntu@ubuntu-snappy:~$\n\nMy problems begin when trying to set the proxy for docker daemon.  Firstly systemctl doesn't seem to be able to find docker.service:\n(amd64)ubuntu@ubuntu-snappy:~$ sudo systemctl status docker\n● docker.service\n   Loaded: not-found (Reason: No such file or directory)\n   Active: inactive (dead)\n(amd64)ubuntu@ubuntu-snappy:~$ \n\nso setting the proxy as described here doesn't seem to have any effect.\nCan anyone offer any advice?\n(amd64)ubuntu@ubuntu-snappy:~$ cat /etc/os-release \nNAME=\"Ubuntu\"\nVERSION=\"15.04 (Vivid Vervet)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 15.04\"\nVERSION_ID=\"15.04\"\nHOME_URL=\"http://www.ubuntu.com/\"\nSUPPORT_URL=\"http://help.ubuntu.com/\"\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\n(amd64)ubuntu@ubuntu-snappy:~$ uname -a\nLinux ubuntu-snappy 3.19.0-51-generic #57-Ubuntu SMP Fri Feb 19 14:05:05 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n(amd64)ubuntu@ubuntu-snappy:~$ \n\n\nA: I had the exactly the same issue with Ubuntu Core 16 (on raspberry pi 2).\nCould you please try the following workaround? \nTry to run docker with sudo snap run :\n<my-user>@localhost:/home/~ sudo snap run docker login\nLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\nUsername: <my_user_name>\nPassword: \nLogin Succeeded\n\n<my-user>@localhost:/home/~ sudo snap run docker ps\nCONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS               NAMES\n7992d18555f1        zsoltm/postgresql-armhf   \"/entrypoint.sh postg\"   13 minutes ago      Up 13 minutes       5432/tcp            db\n\nRoot Cause:\nThe root cause of this issue seems to be that my user is not part of the docker group and i cannot use usermod to add my user to the docker group because it is Read-only FS (!!) :\n<my-user>@localhost:~$ sudo usermod -aG docker <my-user>\nusermod: /etc/group.1612: Read-only file system\nusermod: cannot lock /etc/group; try again later.\n\n\nA: Probably docker isn't running yet (for some reason).\nYou can try starting docker with sudo snappy activate docker due to how snappy works.\n", "Q: xmlrpc.php not found or unable to stat [Ubuntu 14.04 Server] I just setup a new Ubuntu server with a LAMP stack. I'm using it only for some React.JS development, and has no domain name associated to it. I'm finding that my error log is riddled with this error:\n[Mon Apr 18 15:59:18.045904 2016] [:error] [pid 24059] [client 188.241.234.58:50084] script '/home/pinetar/public_html/xmlrpc.php' not found or unable to stat\n\nI understand the error that the file doesn't exist, and from what I can tell its probably just bots looking for an exploit. My concern is the error log getting out of hand and wasting server resources.\nIs there a way to block requests for this file or is there a downside to doing so? My server isn't very powerful (512MB) since it's just for development and testing..\nThanks!\n\nA: I wouldn't be concerned about logging overhead or log file size. If the log file size grows out of hand you can logrotate(8) it and compress old logs in the process. Text files with many similar entries tend to be very well compressible.\nYou could even set up your custom cron job to filter those entries out of the rotated log files.\n", "Q: how to set some application to run only as root I'm running Ubuntu 14.04 and I was wondering is there a way to set some applications to run only as root?\nfor example the application X can normally executed by any user, and I want to set it to be executed only as root. how could I do that.\n\nA: First, set the owner of the application to root (if it isn't already):\nsudo chown root:root /path/to/app\n\nThen configure rights with chmod, e.g.:\nsudo chmod 700 /path/to/app\n\nThis would give root the right to read, write and execute while all other users have no rights. There are other possible combinations. The number 4 is for read, 2 for write and 1 for execute, just add up whatever you want.\nIf your command is chmod xyz, x would be the rights for owner, y for the group and z for others.\n", "Q: Can't Log In As User After Using A Restore Script I used this script to restore my files and installed packages (home folder not encrypted) after upgrading to Ubuntu 16.04 64 bit.  But when I tried to log in as a user, graphically, it just took me back to the log in screen.  I can log on as a user via command-line from the log in screen.\nAs the solution to can't log into ubuntu after rsync restore of home folder, says to remove the ~/.Xauthority file from the home folder and create a new one, this didn't work for me.\n\nA: When you backup and restore, the permissions need to be identical, otherwise, you will not be able to log in. You could probably boot into recovery mode and do a recursive chown on your home directory. This should probably fix it.\n", "Q: What is 'AHCI mode' - HP ProLiant MicroServer Gen8 I have just purchased this server and I would like to install Ubuntu Server on it. I would like to keep RAID support, although I'm currently only using one HDD which will have my files and OS on it.\nI've seen I can install Ubuntu after I set the embedded SATA configuration to 'AHCI mode'. What does this mean? What are the pros and cons?\nDoes this turn off RAID? I mainly bought this because eventually I'd like to have two drives mirroring each other. I've also read somewhere on ask ubuntu that going in to 'AHCI mode' mode makes the fans louder too.\nI've also just seen this if it helps:\n\nNOTE: The B140i storage controller (HPDSA) driver v1.2.4-140 is ONLY supported with Ubuntu 14.04.1 LTS (v3.13.x) kernel. Please use AHCI Mode with newer Hardware Enabled Kernels (HWE). Future platforms with the Dynamic RAID controller will be certified using AHCI SATA mode.\n\nThis is the first server I've ever owned so any help setting this up will be much appreciated.\nEDIT:\nI've also seen this, will using this custom version of Ubuntu allow me to install it whilst keeping the smart array? Heck what even is smart array?\n\nA: AHCI is the standard interface for SATA controllers.  Other options usually include IDE mode, where the controller pretends to be an old IDE controller for compatibility with older operating systems, and RAID, which means fake raid support.  Fake raid is actually just an AHCI controller that has bios code and windows drivers to implement raid in software.  For more information, see http://wiki.ubuntu.com/FakeRaidHowto.  Unless you are dual booting with Windows, it is best avoided and you should stick with conventional linux software raid, which is better supported.\n", "Q: Binding a terminal command to a set of keys for Kubuntu 15.10 I have just installed cmus and to run it I need to go into terminal and enter the command \"cmus\". Is there any way I can bind this to a set of keys? \nThanks.\n\nA: To create a shortcut for cmus via Terminator while running Kubuntu first follow this path:\nKMenu > System Settings > Shortcuts & Gestures > Custom Shortcuts\n\nFrom here you can create the shortcut by drilling through this path:\nEdit > New > Global Shortcut > Command/URL\n\nNow follow these steps:\n\n\n*\n\n*Where it says 'New Action' type in 'Open Cmus' (without the apostrophes)\n\n*Go to 'Trigger > Shortcut' and press Alt+F9 (or other keys)\n\n*Go to 'Action' and type in: terminator -e cmus\n\n*Press 'Apply'\n\n\nThis works beautifully on my system:\n\nKDE will obligingly tell you if there is any conflict with the key combination you have selected versus any existing shortcuts...\n", "Q: Problem with resolution of Ubuntu 14 on Windows7 x64 Virtualbox5 I'm running Windows7 x64, Virtualbox 5.0.16 and just installed Ubuntu 14.04. \nUbuntu starts fine, but gives a very low resolution (e.g. 640x460).\nI tried running sudo apt-get install virtualbox-guest-dkms virtualbox-guest-utils virtualbox-guest-x11\nbut this gives me the error\n\nUnable to locate package virtualbox-guest-x11: depends on xorg-video abi-15\n  depends on xserver-xorg-core etc.etc.\n\nI'm stuck here. Any suggestions (using newbie language?)\nThanks!\n\nA: As first you need to download the VirtualBox 5.0.17 Guest Additions installer image from here.\n(P.S.: make sure you download one for Linux 32-bit or 64-bit depending on the system you installed on your VM)\nAfter that add this image into your VM's DVD and start your VM.\nWhen booted up and logged in you might need to mount the cd image (in case you use a server image of Ubuntu) and aswell need some software to install.\n\n# Run those commands if youre using Ubuntu server\nsudo mount /dev/sr0 /media/cdrom\n\n# The following you need always\nsudo apt-get install build-essentials\nsudo sh /media/cdrom/VBoxLinuxAdditions.run\n\n", "Q: GRUB doesn't show Windows 10 Whenever I boot into my system, Linux directly boots. If I press shift, GRUB shows only Linux, not Windows. Here are results of fdisk and update-grub. I think I have installed Linux the wrong way.\n$ fdisk\nWARNING: GPT (GUID Partition Table) detected on '/dev/sda'! The util fdisk doesn't support GPT. Use GNU Parted.\n\n\nDisk /dev/sda: 1000.2 GB, 1000204886016 bytes\n255 heads, 63 sectors/track, 121601 cylinders, total 1953525168 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisk identifier: 0x00000000\n\n   Device Boot      Start         End      Blocks   Id  System\n/dev/sda1               1  1953525167   976762583+  ee  GPT\nPartition 1 does not start on physical sector boundary.\n\n$ update-grub\nGenerating grub configuration file ...\nWarning: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported.\nFound linux image: /boot/vmlinuz-3.19.0-32-generic\nFound initrd image: /boot/initrd.img-3.19.0-32-generic\nFound memtest86+ image: /boot/memtest86+.elf\nFound memtest86+ image: /boot/memtest86+.bin\n  No volume groups found\ndone\n\n\nA: First I tried with sudo os-prober and sudo update-grub and it didn't recognize my windows.\nFinally I solved this problem following steps of Boot-Repair\nInstall boot-repair\nsudo add-apt-repository ppa:yannubuntu/boot-repair\nsudo apt-get update\nsudo apt-get install -y boot-repair && boot-repair\n\nPush \"Recommended repair\"\nAnd put in a terminal some commands as it suggested.\nI think my Grub doesn't recognize windows due to a bad shutdown, and it solved the problem.\nI hope this help you.\n", "Q: Ubuntu Webcam does not work on Google Hangouts or Skype I installed my Ubuntu 14.04 LTS alongside my Windows system. It's a ThinkPad E555 laptop. I just tried to use Skype and Google Hangouts today but could not get my built-in webcam to work. I would like to be able to use my webcam so please help if you can! Thank you very much!\nI ran cheese and it shows \"No device found\":\n** Message: cheese-application.vala:291: Error during camera setup: No device found\n(cheese:4268): cheese-CRITICAL **: cheese_camera_device_get_device_node: assertion 'CHEESE_IS_CAMERA_DEVICE (device)' failed\n(cheese:4268): GLib-CRITICAL **: g_variant_new_string: assertion 'string != NULL' failed\n(cheese:4268): GLib-GIO-CRITICAL **: g_settings_schema_key_type_check: assertion 'value != NULL' failed\n(cheese:4268): GLib-CRITICAL **: g_variant_get_type_string: assertion 'value != NULL' failed\n(cheese:4268): GLib-GIO-CRITICAL **: g_settings_set_value: key 'camera' in 'org.gnome.Cheese' expects type 's', but a GVariant of type '(null)' was given\n** (cheese:4268): CRITICAL **: cheese_preferences_dialog_setup_resolutions_for_device: assertion 'device != NULL' failed\n\nI also tried:\nsudo apt-get install cheese build-essential linux-headers-`uname -r`\n[sudo] password for kangnahua: \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nbuild-essential is already the newest version.\ncheese is already the newest version.\nlinux-headers-3.19.0-58-generic is already the newest version.\nThe following packages were automatically installed and are no longer   required:\nlibntdb1 python-appindicator python-ntdb\nUse 'apt-get autoremove' to remove them.\n0     upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n\nSo cheese is the newest and the problem isn't cheese itself. Below is my lsmod:\nlsmod\nModule                  Size  Used by\nctr                    16384  1 \nccm                    20480  1 \nfglrx               13512704  162 \nbnep                   20480  2 \nrfcomm                 69632  8 \nuvcvideo               90112  0 \nvideobuf2_vmalloc      16384  1 uvcvideo\nvideobuf2_memops       16384  1 videobuf2_vmalloc\nvideobuf2_core         53248  1 uvcvideo\nv4l2_common            16384  1 videobuf2_core\nvideodev              159744  3 uvcvideo,v4l2_common,videobuf2_core\nmedia                  24576  2 uvcvideo,videodev\nkvm                   479232  0 \ncrct10dif_pclmul       16384  0 \ncrc32_pclmul           16384  0 \naesni_intel           172032  3 \naes_x86_64             20480  1 aesni_intel\nlrw                    16384  1 aesni_intel\ngf128mul               16384  1 lrw\nglue_helper            16384  1 aesni_intel\nablk_helper            16384  1 aesni_intel\ncryptd                 20480  2 aesni_intel,ablk_helper\narc4                   16384  2 \njoydev                 20480  0 \nserio_raw              16384  0 \nrtsx_pci_ms            20480  0 \nmemstick               20480  1 rtsx_pci_ms\nedac_core              53248  0 \nsnd_hda_codec_hdmi     53248  1 \nsnd_hda_codec_conexant    24576  1 \nsnd_hda_codec_generic    69632  1 snd_hda_codec_conexant\nedac_mce_amd           24576  0 \nthinkpad_acpi          86016  1 \nk10temp                16384  0 \nfam15h_power           16384  0 \nrtl8723be             143360  0 \nbtcoexist             413696  1 rtl8723be\nsnd_seq_midi           16384  0 \nrtl_pci                40960  1 rtl8723be\nrtlwifi               135168  3 btcoexist,rtl_pci,rtl8723be\nsnd_seq_midi_event     16384  1 snd_seq_midi\nnvram                  16384  1 thinkpad_acpi\nbtusb                  40960  0 \nmac80211              720896  3 rtl_pci,rtlwifi,rtl8723be\nsnd_hda_intel          36864  9 snd_hda_codec_hdmi\nbluetooth             491520  22 bnep,btusb,rfcomm\nsnd_hda_controller     32768  1 snd_hda_intel\nsnd_hda_codec         143360  5   snd_hda_codec_hdmi,snd_hda_codec_conexant,snd_hda_codec_generic,snd_hda_in    tel,snd_hda_controller\nsnd_hwdep              20480  1 snd_hda_codec\nsnd_rawmidi            32768  1 snd_seq_midi\ni2c_piix4              24576  0 \ncfg80211              532480  2 mac80211,rtlwifi\nsnd_pcm               106496  6 snd_hda_codec_hdmi,snd_hda_codec,snd_hda_intel,snd_hda_controller\nsnd_seq                65536  2 snd_seq_midi_event,snd_seq_midi\nshpchp                 40960  0 \namd_iommu_v2           20480  1 fglrx\nsnd_seq_device         16384  3 snd_seq,snd_rawmidi,snd_seq_midi\nsnd_timer              32768  2 snd_pcm,snd_seq\nsnd                    86016  26 snd_hwdep,snd_timer,snd_hda_codec_hdmi,snd_hda_codec_conexant,snd_pcm,snd_seq,snd_rawmidi,snd_hda_codec_generic,snd_hda_codec,snd_hda_intel,thinkpad_acpi,snd_seq_device\nsoundcore              16384  2 snd,snd_hda_codec\nwmi                    20480  0 \nvideo                  20480  0 \nmac_hid                16384  0 \nparport_pc             32768  0 \nppdev                  20480  0 \nlp                     20480  0 \nparport                45056  3 lp,ppdev,parport_pc\nhid_generic            16384  0 \nusbhid                 53248  0 \nhid                   110592  2 hid_generic,usbhid\nrtsx_pci_sdmmc         24576  0 \npsmouse               118784  0 \nr8169                  81920  0 \nmii                    16384  1 r8169\nahci                   36864  2 \nlibahci                32768  1 ahci\nrtsx_pci               49152  2 rtsx_pci_ms,rtsx_pci_sdmmc\n\nand my lsusb:\nlsusb\nBus 009 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 006 Device 002: ID 5986:055a Acer, Inc \nBus 006 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 008 Device 002: ID 0bda:b728 Realtek Semiconductor Corp. \nBus 008 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 005 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 007 Device 002: ID 093a:2510 Pixart Imaging, Inc. Optical Mouse\nBus 007 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 004 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\n\n\nA: Looks like an known problem: https://bugs.launchpad.net/ubuntu/+source/linux-lts-utopic/+bug/1433906.\nMy suggestion would be to get Ubuntu 16.04 LTS burn it onto a DVD/USB-Stick (released on the 21st of April), boot from it and see if your webcam is recognized/working, if yes upgrade your installed Ubuntu 14.04 to 16.04.\n", "Q: Xubuntu 15.10 mounting data cd as audio cd I am trying to run a game on my Xubuntu machine. When I put the CD in for the game it recognizes it as an audio CD with a \"Track 2.wav\" that is the same size as the collective files on the disk. When I try to mount the cd, it gives me the error\nray@gilberts:~$ sudo mount /dev/cdrom /mnt\n[sudo] password for ray: \nmount: /dev/sr0 is write-protected, mounting read-only\nmount: wrong fs type, bad option, bad superblock on /dev/sr0,\n       missing codepage or helper program, or other error\n\n       In some cases useful info is found in syslog - try\n       dmesg | tail or so.\n\nI decide to do what it says and I get this:\nray@gilberts:~$ dmesg | tail\n[  368.511331] sr 4:0:0:0: [sr0] Add. Sense: Illegal mode for this track\n[  368.511333] sr 4:0:0:0: [sr0] CDB: Read(10) 28 00 00 04 91 ba 00 00 01 00 00 00\n[  368.511335] blk_update_request: I/O error, dev sr0, sector 1197800\n[  368.511337] Buffer I/O error on dev sr0, logical block 299450, async page read\n[  368.512164] sr 4:0:0:0: [sr0] FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE\n[  368.512165] sr 4:0:0:0: [sr0] Sense Key : Illegal Request [current] \n[  368.512168] sr 4:0:0:0: [sr0] Add. Sense: Illegal mode for this track\n[  368.512169] sr 4:0:0:0: [sr0] CDB: Read(10) 28 00 00 04 91 bb 00 00 01 00 00 00\n[  368.512171] blk_update_request: I/O error, dev sr0, sector 1197804\n[  368.512172] Buffer I/O error on dev sr0, logical block 299451, async page read\n\nThe CD works in my windows machine and other CDs work in my Xubuntu machine. In fact, I only have two CDs that are doing this, but they work in my windows machine.\n\nA: I was just facing the same problem after trying out CDs of old Windows 95 games on Ubuntu 16.04.\nSome background: Back in the days, CDs of Windows games contained both a data track and audio tracks. The game data is on the data track, and the audio tracks were for the in-game audio. You can actually insert these CDs in a regular CD player and it will play the music from track 2 and up.\nUbuntu recognizes these types of CDs as audio CDs, which is thus not entirely incorrect. But you can easily mount the data track with the following command:\nsudo mkdir /mnt/cdrom/\nsudo mount -t iso9660 /dev/sr0 /mnt/cdrom/\n\nThen can you can open the directory /mnt/cdrom/ with your file browser to view the data content of the CD. Then you can proceed to install the game with Wine. But you might also need DosBox for the older games.\n", "Q: Samba Share user/password error after update this is the first time that I couldn't find an answer so this is my first question. I will provide as much information as possible. I have an ASUS router that has 2 HDDs. There is only 1 username/password to access the media while on the network. My PC no longer seems to be able to access it after an update.\nAfter initially entering the login credentials and selecting \"Remember forever\" I had always (over 2 years) been able to access the drives by going to \"Browse Network\" in nautilus and clicking on the Router's Icon then clicking the folder I want to access. Today I had a security update which contained the following:\n\nNow when I go to access the folders on the HDDs this pops up:\n\nI select \"Registered User\" enter the username, password and select \"Remember forever\" then click Connect and the box pops back up greyed out with the fields reset to defaults. \nIf I click the connect button again the same greyed out pop-up keeps coming back over and over.\nIf I manually close it. A brand new pop-up appears that allows me to enter in the credentials. However, if I enter them again nautilus simply closes and I occassionally get a pop-up saying that Ubuntu has encountered and internal error etc.\nThere are 3 Phones, 1 Tablet, 1 Win7 PC, and another Ubuntu 15.10 PC that can connect to the network drives and read/write without issue. I should add that I ignored the update mentioned above on the other Ubuntu PC once I started to have this issue on mine.\nSo far the only way I can access the HDDs with my PC is to turn off my router's security for samba access. I really have no idea how to remedy this or how to get it back to the way it was.\nThanks in advance for any help.\n\nA: I had exactly the same problem.\nAdding\nclient use spnego = no\n\nto the [global] section of /etc/samba/smb.conf solved the problem in my case.\nApparently the default value changed to \"yes\" after the update to v.4.3.8, so I needed to explicitly set it.\nSee the online manpage for reference.\n\nA: I first added the line client use spnego = no at the end of file /etc/samba/smb.conf, but it did not work. After I placed the line near the beginning of the file, the network drives worked.\n\nA: I tried use smbclient to see what happened I got this:\n\nSMB server does not support EXTENDED_SECURITY  but 'client use spnego = yes and 'client ntlmv2 auth = yes'\n\nI think this means samba client is telling the samba server use features which are not there. From use Samba's note above with this link I found this:\n\nThe impact of 'client ntlmv2 auth = yes' is that by default we will not use NTLM (NT Local Machine) authentication as a client.\n\nSince I am not using any extended security I just turn this off as\n\"client ntlmv2 auth = no\" in /etc/samba/smb.conf. I have to added a line to override the default. Everything is working again.\n\nA: Check that you have winbind installed. Install it if haven´t got it and restart samba-ad-dc again. You should be fine after that.\nhttps://lists.samba.org/archive/samba/2016-April/199291.html\n\nA: Yes after the latest update I did yestarday samba was not able to connect as a client via the nautilus.\nMounting via the mount direct command still was working.\nI had to change the smb.conf file as suggested above by adding\nclient use spnego = no\nThen you have to restart the samba network stack (just reboot).\nEverything is working now.\n", "Q: I'm getting a new pc without an OS, so can I download Ubuntu onto a CD on a separate laptop, then put that CD into the disk drive on the new PC? I'm getting a new pc without an OS, and I'm wondering if I could download Ubuntu onto a CD, on a separate laptop, then put that CD into the disk drive on the new PC? Can I do that? Thanks.\n\nA: Absolutely. (Though Ubuntu is too big for a CD. You'll need a DVD) I'd recommend waiting three days so you can get 16.04LTS though...\n\nA: You can burn it to a CD or to a USB Stick and boot. If you don't want to spare a CD, then USB is better. If the other laptop is running on Ubuntu, you're so lucky to use \"Startup Disk Creator\" built in.\n\n\nA: The good thing is that you can go to the Ubuntu website and then download the iso file and then put it on to usb. One good thing, is that by not having any other os on the system, you will not have any dual booting. You lucky person, it can be a bit of a pain.The usb option would be the way to go though and waiting for the latest build.\n", "Q: Where can I download the chrome i386 deb file? Where can I download the Chrome i386 deb file? Google does not allow installing Chrome 32 bit from its web anymore. I am running xubuntu 15.10\n\nA: That's because Chrome 32-bit is no longer supported on Ubuntu. Chrome is also no longer supported on Ubuntu 12.04 with either 32-bit or 64-bit.\nIt is not a good idea to install the 32-bit version of Chrome on Ubuntu, as it no longer receives updates of any kind. That means an you'll have an outdated and insecure browser as soon as you install.\nIf you can't get 64-bit Ubuntu, you'll have to install Chromium instead.\nsudo apt-get install chromium-browser\n\nhttp://betanews.com/2015/11/30/google-killing-chrome-for-32-bit-linux/\n", "Q: matlab crash dump log file I installed matlab 2016 and it crashed when I started it. The problem is reproducible. Why does it happen? \nMATLAB crash file:/home/dac/matlab_crash_dump.3815-1:\n\n\n------------------------------------------------------------------------\n       Segmentation violation detected at Tue Apr 19 02:44:12 2016\n------------------------------------------------------------------------\n\nConfiguration:\n  Crash Decoding      : Disabled\n  Crash Mode          : continue (default)\n  Current Visual      : 0x20 (class 4, depth 24)\n  Default Encoding    : UTF-8\n  GNU C Library       : 2.21 stable\n  Host Name           : dac-Latitude-E7450\n  MATLAB Architecture : glnxa64\n  MATLAB Root         : /usr/local/MATLAB/R2016a\n  MATLAB Version      : 9.0.0.341360 (R2016a)\n  Operating System    : Linux 4.2.0-35-generic #40-Ubuntu SMP Tue Mar 15 22:15:45 UTC 2016 x86_64\n  Processor ID        : x86 Family 6 Model 61 Stepping 4, GenuineIntel\n  Virtual Machine     : Java 1.7.0_60-b19 with Oracle Corporation Java HotSpot(TM) 64-Bit Server VM mixed mode\n  Window System       : The X.Org Foundation (11702000), display :0\n\nFault Count: 1\n\n\nAbnormal termination:\nSegmentation violation\n\nRegister State (from fault):\n  RAX = 0000000000000000  RBX = 00007f60ea915160\n  RCX = 0000000000000000  RDX = 0000000000000003\n  RSP = 00007f617fff7550  RBP = 00007f617fff7670\n  RSI = 0000000000000000  RDI = 00007f60ea914350\n\n   R8 = 0000000000000018   R9 = 0000000000000000\n  R10 = 00007f60ea914000  R11 = 00007f60ea915478\n  R12 = 00007f60eab80fa0  R13 = 0000000000000006\n  R14 = 00007f60ea914758  R15 = 00007f610061f8e0\n\n  RIP = 00007f619fdb490a  EFL = 0000000000010206\n\n   CS = 0033   FS = 0000   GS = 0000\n\nStack Trace (from fault):\n[  0] 0x00007f619fdb490a                        /lib64/ld-linux-x86-64.so.2+00051466\n[  1] 0x00007f619fdbd501                        /lib64/ld-linux-x86-64.so.2+00087297\n[  2] 0x00007f619fdb84b4                        /lib64/ld-linux-x86-64.so.2+00066740\n[  3] 0x00007f619fdbc9f3                        /lib64/ld-linux-x86-64.so.2+00084467\n[  4] 0x00007f619d4fdfc9                   /lib/x86_64-linux-gnu/libdl.so.2+00004041\n[  5] 0x00007f619fdb84b4                        /lib64/ld-linux-x86-64.so.2+00066740\n[  6] 0x00007f619d4fe62d                   /lib/x86_64-linux-gnu/libdl.so.2+00005677\n[  7] 0x00007f619d4fe061                   /lib/x86_64-linux-gnu/libdl.so.2+00004193 dlopen+00000049\n[  8] 0x00007f6199d490b6      /usr/local/MATLAB/R2016a/bin/glnxa64/libut.so+00315574\n[  9] 0x00007f6199d49c76      /usr/local/MATLAB/R2016a/bin/glnxa64/libut.so+00318582 _Z11utGetModuleRKSbIDsSt11char_traitsIDsESaIDsEEPi+00000022\n[ 10] 0x00007f6199d49d6b      /usr/local/MATLAB/R2016a/bin/glnxa64/libut.so+00318827 utGetModule+00000171\n[ 11] 0x00007f618e7a1d45 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00482629\n[ 12] 0x00007f618e794eaf /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00429743 _ZN13Mlm_MATLAB_fn8try_loadEv+00000031\n[ 13] 0x00007f618e78be95 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00392853 _ZN13Mlm_MATLAB_fn4loadEv+00000037\n[ 14] 0x00007f618e7895e9 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00382441 _ZN13Mfh_MATLAB_fn11dispatch_fhEiPP11mxArray_tagiS2_+00000057\n[ 15] 0x00007f618b93b42e /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+10728494\n[ 16] 0x00007f618b93b4c9 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+10728649\n[ 17] 0x00007f618b6a3e1c /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08011292\n[ 18] 0x00007f618b71e45a /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08512602\n[ 19] 0x00007f618b71f83c /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08517692\n[ 20] 0x00007f618e1a0c86 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_interpreter.so+03157126 inCallFcnWithTrap+00000086\n[ 21] 0x00007f618e22d25c /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_interpreter.so+03732060 inMexCallMATLAB+00000348\n[ 22] 0x00007f618da2f2af     /usr/local/MATLAB/R2016a/bin/glnxa64/libmex.so+00098991 mexCallMATLAB+00000063\n[ 23] 0x00007f618cdab108  /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_ir.so+00246024 mps_call_constant_mxarray_function_constant+00000184\n[ 24] 0x00007f618d1f369c /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_parser.so+02111132\n[ 25] 0x00007f6189a26999 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00055705\n[ 26] 0x00007f6189a2983e /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00067646\n[ 27] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 28] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 29] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 30] 0x00007f6189a23cfc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044284\n[ 31] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 32] 0x00007f6189a23cfc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044284\n[ 33] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 34] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 35] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 36] 0x00007f6189a23cfc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044284\n[ 37] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 38] 0x00007f6189a23cfc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044284\n[ 39] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 40] 0x00007f6189a23cfc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044284\n[ 41] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 42] 0x00007f6189a23d35 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwir_xfmr.so+00044341\n[ 43] 0x00007f618d1ed30f /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_parser.so+02085647 _Z19mps_xf_fold_mf_termP15M_folder_structP9term_nodePKDsPKhPj+00000127\n[ 44] 0x00007f618e2447b4 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_interpreter.so+03827636\n[ 45] 0x00007f618e244cee /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_interpreter.so+03828974 _Z27in_parse_M_function_for_lxeP19_m_parser_interfacePFbPvPKvPKcEPFS5_mPS5_S5_bES5_RKSbIDsSt11char_traitsIDsESaIDsEEPKhmP9_dsbufferSK_SK_bb+00000766\n[ 46] 0x00007f618b795008 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08998920\n[ 47] 0x00007f618b7d4a41 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09259585\n[ 48] 0x00007f618b7d4bf4 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09260020\n[ 49] 0x00007f618b7d5d74 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09264500\n[ 50] 0x00007f618b7d6cfd /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09268477\n[ 51] 0x00007f618e7e3476 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00750710 _ZN8Mlm_file7load_mfEv+00000134\n[ 52] 0x00007f618e794eaf /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00429743 _ZN13Mlm_MATLAB_fn8try_loadEv+00000031\n[ 53] 0x00007f618e78be95 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00392853 _ZN13Mlm_MATLAB_fn4loadEv+00000037\n[ 54] 0x00007f618b7c9b4e /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09214798\n[ 55] 0x00007f618b7c9c0d /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09214989\n[ 56] 0x00007f618b74c170 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08700272\n[ 57] 0x00007f618b74c37e /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08700798\n[ 58] 0x00007f618b74c4cf /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08701135\n[ 59] 0x00007f618b388539 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04752697\n[ 60] 0x00007f618b386ebc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04746940\n[ 61] 0x00007f618b3849ea /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04737514\n[ 62] 0x00007f618b384db1 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04738481\n[ 63] 0x00007f618b386a63 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04745827\n[ 64] 0x00007f618b386be9 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04746217\n[ 65] 0x00007f618b43716f /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+05468527\n[ 66] 0x00007f618b43a22a /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+05481002\n[ 67] 0x00007f618b6dc543 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08242499\n[ 68] 0x00007f618b7bf1ec /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09171436\n[ 69] 0x00007f618e7e2505 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00746757 _ZN8Mfh_file16dispatch_fh_implEMS_FviPP11mxArray_tagiS2_EiS2_iS2_+00001509\n[ 70] 0x00007f618e7e29a0 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00747936 _ZN8Mfh_file11dispatch_fhEiPP11mxArray_tagiS2_+00000032\n[ 71] 0x00007f617ea58165 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcos_impl.so+01102181\n[ 72] 0x00007f617eb5d1d3 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcos_impl.so+02171347\n[ 73] 0x00007f617eae0116 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcos_impl.so+01659158\n[ 74] 0x00007f617eae11f6 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcos_impl.so+01663478\n[ 75] 0x00007f617eae90a5 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcos_impl.so+01695909\n[ 76] 0x00007f617eae27cb /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcos_impl.so+01669067\n[ 77] 0x00007f617eb5f376 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcos_impl.so+02179958\n[ 78] 0x00007f618b855cb0 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09788592\n[ 79] 0x00007f618b856871 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09791601\n[ 80] 0x00007f618b7e5761 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09328481\n[ 81] 0x00007f618b7e69dc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09333212\n[ 82] 0x00007f618b85c6ec /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09815788\n[ 83] 0x00007f618b7f12e8 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09376488\n[ 84] 0x00007f618b84c930 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09750832\n[ 85] 0x00007f618b8d8a31 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+10324529\n[ 86] 0x00007f618b3879b7 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04749751\n[ 87] 0x00007f618b388a4c /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04753996\n[ 88] 0x00007f618b386ebc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04746940\n[ 89] 0x00007f618b3849ea /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04737514\n[ 90] 0x00007f618b384db1 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04738481\n[ 91] 0x00007f618b386a63 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04745827\n[ 92] 0x00007f618b386be9 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04746217\n[ 93] 0x00007f618b43716f /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+05468527\n[ 94] 0x00007f618b43a22a /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+05481002\n[ 95] 0x00007f618b6dc543 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08242499\n[ 96] 0x00007f618b7bee5c /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09170524\n[ 97] 0x00007f618e7e227e /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00746110 _ZN8Mfh_file16dispatch_fh_implEMS_FviPP11mxArray_tagiS2_EiS2_iS2_+00000862\n[ 98] 0x00007f618e7e29a0 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_dispatcher.so+00747936 _ZN8Mfh_file11dispatch_fhEiPP11mxArray_tagiS2_+00000032\n[ 99] 0x00007f618b7ce1c9 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+09232841\n[100] 0x00007f618b8fadbf /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+10464703\n[101] 0x00007f618b8f0a5a /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+10422874\n[102] 0x00007f618b8b9911 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+10197265\n[103] 0x00007f618b387b2a /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04750122\n[104] 0x00007f618b388a4c /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04753996\n[105] 0x00007f618b386ebc /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04746940\n[106] 0x00007f618b3849ea /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04737514\n[107] 0x00007f618b384db1 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04738481\n[108] 0x00007f618b386a63 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04745827\n[109] 0x00007f618b386be9 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+04746217\n[110] 0x00007f618b43716f /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+05468527\n[111] 0x00007f618b43a22a /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+05481002\n[112] 0x00007f618b6dc543 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08242499\n[113] 0x00007f618b6a507e /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08015998\n[114] 0x00007f618b6a9058 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08032344\n[115] 0x00007f618b6a9107 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08032519\n[116] 0x00007f618b71f2c5 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08516293\n[117] 0x00007f618b71f792 /usr/local/MATLAB/R2016a/bin/glnxa64/libmwm_lxe.so+08517522\n[118] 0x00007f618eae2769   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcr.so+00788329\n[119] 0x00007f618eb02474   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcr.so+00918644 _Z32mnRunPathDependentInitializationv+00000036\n[120] 0x00007f618eae45a3   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcr.so+00796067 _ZN11mcrInstance26init_on_interpreter_threadEP11MfileReaderP13MexFileReader+00000483\n[121] 0x00007f6199121d6c /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmlutil.so+04328812 _ZNK5boost9function0IbEclEv+00000028\n[122] 0x00007f618eaed8e5   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcr.so+00833765\n[123] 0x00007f618eaf3d09   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcr.so+00859401 _ZN5boost6detail17task_shared_stateINS_3_bi6bind_tIbPFbRKNS_8functionIFbvEEEENS2_5list1INS2_5valueIS6_EEEEEEbE6do_runEv+00000025\n[124] 0x00007f618eaf443b   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcr.so+00861243 _ZN5boost6detail22task_base_shared_stateIbE3runEv+00000059\n[125] 0x00007f618eaf4497   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcr.so+00861335\n[126] 0x00007f618eacb75a   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwmcr.so+00694106\n[127] 0x00007f618ee3ec06   /usr/local/MATLAB/R2016a/bin/glnxa64/libmwiqm.so+00969734\n\n\nIf this problem is reproducible, please submit a Service Request via:\n    http://www.mathworks.com/support/contact_us/\n\nA technical support engineer might contact you with further information.\n\nThank you for your help.\n\n\nA: In /usr/local/MATLAB/R2016a/sys/os/glnxa64/ there are 3 files that need to be linked to the OS libraries, which are different that those than Matlab was compiled against.\nTo do this you need to type the following at a terminal\ncd /usr/local/MATLAB/R2016a/sys/os/glnxa64/\nsudo ln -sf /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0 libgfortran.so.3\nsudo ln -sf /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0 libquadmath.so.0\nsudo ln -sf /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.19 libstdc++.so.6\n\nThese changes resolved the problem for me in 14.04.4. I assume also that libquadmath0:amd64 and libgfortran3:amd64 are installed already. If not enter the following:\nsudo apt-get install libquadmath0:amd64 libgfortran3:amd64\n\n", "Q: Kinda newish to Ubuntu, and I need some internet help I've Ubuntu on a dual boot, and I primarily use Windows. I was having an issue where my machine would completely crash when I tried to log in with the GUI. So I figured that I could get an update from the command line to fix it, which fixed the crashing issue.\nHowever, most of the way through this long update process, it started displaying lots of error messages before finishing up. I didn't know what any of them meant (and unfortunately don't have any images), but it finished up, and fixed that other issue, but now it fails to connect to any network, wired or not.\nViewing the network settings in the GUI, I see something like there's no network hardware detected or something like that. I would look now but I'm booted into Windows on the affected machine. \nEdit:\nI saw a comment asking for my machine and version so I'll add those now:\nI'm on an HP Envy dv7 laptop, I believe a 2012 model though I've had trouble finding a serial number or anything (got it refurb before I knew anything at all whatsoever about computers) and it's running Ubuntu 14.04 dual booted with Windows 10.\nEdit 2:\nsudo lshw -class network returned hardware specifications (addresses, manufacturers, etc.)\narp -a returned nothing\n\nA: While a lot of times GUI would just work for most people, sometimes you will need to use the terminal (the black window where you can type commands) to fix problems. In general, no network can be because of several things.\n\n\n*\n\n*Do you have the proper driver installed. Run the following command and see if anything is returned.\nsudo lshw -class network\n\n\n*Can the driver correct auto configure ethernet interface. Try run the following and see if you see your router address.\narp -a\n\n\n*Do you have the correct network layer settings. Try the following and see if your computer has an IP address.\nifconfig\n\n\n*Do you have the correct routing settings. Try the following and see if you have the correct routing table.\nroute -n\n\n\n*Do you have the correct DNS settings. Try the following and see if your DNS can resolve to a well known website.\nnslookup www.google.com\n\nIf any item doesn't have the correct settings, the remaining items will probably not work either.\nRef:\nhttps://help.ubuntu.com/lts/serverguide/network-configuration.html\n", "Q: why is ubuntu incorrectly detecting my graphics card? So in my ubuntu I was using the latest mesa drivers from the ppa. I also had the amdgpu and radeon xorg drivers installed. I was running a 16.04 gnome version of ubuntu. Maybe I am reading the terminal output wrong also, but my r9 390 has 8GB of memory and ubuntu doesnt seem to be reporting that.\nubuntu is not installed at the moment since I had to reinstall windows to make sure it just wasnt some issue with the card I never noticed.\nwhy does my card show up as a 290 in linux (incorrect) and a 390 in windows (correct)?\n\n\n\nA: You can first update the PCI ID database on Ubuntu by running sudo update-pciids in a terminal to see if this helps to correct the name.\nFrom the latest database snapshot:\n1002  Advanced Micro Devices, Inc. [AMD/ATI]\n    67b0  Hawaii XT [Radeon R9 290X]\n        1043 046a  R9 290X DirectCU II\n        1043 046c  R9 290X DirectCU II OC\n        1043 0474  Matrix R9 290X Platinum\n        1043 0476  ARES III\n        1458 227c  R9 290X WindForce 3X OC\n        1458 2281  R9 290X WindForce 3X OC\n        1458 228c  R9 290X WindForce 3X\n        1458 228d  R9 290X WindForce 3X OC\n        1458 2290  R9 290X WindForce 3X\n        1458 22c1  Grenada PRO [Radeon R9 390]\n\nIt looks like that the Radeon R9 390 is only specific to a card with 1458 22c1 as its subclass ID, you can check the ID of your card with lspci -nnv\nThis lookup table is maintained by the community, if the information is not correct, you can make changes here: http://pci-ids.ucw.cz/\n", "Q: Is it possible that PC can use phone battery during suspend? I plugged in my phone to recharge using USB recharger. When I went to bed I put my PC to suspend and then when I woke up my phone battery was 0% (even if it was almost full when I left it).\nIs it possible that my desktop PC with Ubuntu on it used my phone's battery during suspend?\n\nA: @Kunok your phone is built to use the pc's energy, not the contrary. So I think your usb cable was not more establishing the connection whereas your phone was draining. If that fails to be the case then you should check your phone charging system. Now, Ubuntu OS cannot be responsible for that right? I mean just be fair... cheers.\n", "Q: Trying to find ubuntu-8.10-umpc-i386.img I am trying to find a version of Ubuntu 8.10 that was configured specifically for UMPCs (as described here, but it appears to have completely disappeared off the internet; it's no longer on cdimage.ubuntu.com and the only torrent I can find has zero seeders. It boggles the mind that an operating system can just vanish into thin air. Anyone know where I can find this?\n\nA: It took some searching but try the following:\n\n\n*\n\n*mirrors.mit.edu\n\n*solar-one.mit.edu\n\n*solar-two.mit.edu\nwhich worked well on my system. Google tends to index ftp sites poorly and this is usually where the old gems are hiding :)\n", "Q: Installing steam to an SD card? I have a chromebook. I installed crouton and unity. I cannot install steam to the main hardrive because it only has 3.2 gigs of memory left. I mounted a micro sd card to my chromebook and one of my friends told me to use \"symlink\" to install it to the sd card. I would really like some help on how to install it to the sd card, 'cause I have no idea what to do. I am new to linux.\n\nA: This is one way of doing this, which again, I warned about the lack of life on the SD card in the comments, you are warned again.\nInstall steam to your hard-drive. Yes I know you only have 3.2GB left, it won't stay on the drive, but get it on there initially. It should only take 1-2 GB of space.\nMove the steam directory, located at ~/.local/share/Steam, onto the drive. You can do this either in the terminal, mv ~/.local/share/Steam /media/USER/FLASHDRIVE/, or through a file manager. You will have to maybe do CTRL + H to show the hidden .local folder.\nMake the symbolic link through a terminal by running ln -s /media/USER/FLASHDRIVE/.steam ~/.local/share/Steam. This creates a link TO /media/USER/FLASHDRIVE/.steam named/located at ~/.local/share/Steam. The paths will need to be correct, Tab completion is your friend.\nTest run steam and install some games, you should start seeing the size of the drive go down when adding games, and your system will probably be at 3 gigs by the end of this (for a few application files in root for steam to run properly).\nNote that this will only work if the drive is mounted to the same place every time it is connected. Also, don't attempt to start steam without the flashdrive in...I'm not sure what that would do.\n\nAn alternate way of doing this would be to install steam on your computer like normal, but setup, download, and play games from a different directory (your microsd drive). Steam itself isn't that large, and wouldn't take up more than a gig (I think). Just, when you install/download games, change the desination directory to the drive.\n", "Q: Deploy MAAS, Juju, Openstack I have look in to dozens on online document but none give me the exact steps and recommendation for deploying MAAS, Juju and OpenStack on Ubuntu.\nThere's plenty of documentation available but none discuss the whole project in one.\nCan someone point me to a tutorial?\n\nA: It's a bit difficult to find a single place that provides all the details.\nHowever, I can help to some extent.\nsudo apt-get install software-properties-common python-software-properties\nsudo add-apt-repository ppa:juju/stable\nsudo add-apt-repository ppa:maas/stable\nsudo add-apt-repository ppa:cloud-installer/stable\nsudo apt-get update\nsudo apt-get install maas\nsudo maas-region-admin createadmin\nsudo apt-get install etherwake\n\nTo get the version of the current MAAS installed \napt-cache policy maas{,-dns,-dhcp} | grep Installed -B1 -A1\n\nIn /etc/maas/templates/power/ether_wake.template, make the following changes:\n#elif [ -x /usr/bin/wakeonlan ]\n#then\n#    /usr/bin/wakeonlan $mac_address\nelif [ -x /usr/sbin/etherwake ]\nthen\n   sudo /usr/sbin/etherwake -i eth0 $mac_address\n\nIn /etc/sudoers.d/99-maas-sudoers add the following line at the end:\nmaas ALL= NOPASSWD: /usr/sbin/etherwake\n\nEnable IP forwarding on MAAS server:\nsudo sysctl -w net.ipv4.ip_forward=1\n\niptables -A FORWARD -i <interface without internet> -o <interface with internet> -j ACCEPT\n\n iptables -A FORWARD -i <interface with internet> -o <interface without internet> -m state --state ESTABLISHED,RELATED -j ACCEPT\n\niptables -t nat -A POSTROUTING -o <interface with internet> -j MASQUERADE\n\nInclude 127.0.0.1 in the list of DNS servers in /etc/resolv.conf on MAAS server.\nsudo apt-get install openstack\nsudo openstack-install\n\nThe above list of commands should successfully install Openstack Autopilot.\nYou may also refer to the github issues on MAAS-JUJU-Autopilot at https://github.com/Ubuntu-Solutions-Engineering/openstack-installer\n\nA: There isn’t a single guide to point you towards, mainly due to the size of the project and subsequent ways it can be tailored for an individual’s needs. The question itself spans four different software projects and multiple fields of technology including networking, virtualisation and storage configuration. \nThe most basic of guides can be found on Ubuntu’s Installing Canonical’s OpenStack Autopilot page. While at the other end of the spectrum you have Openstack’s Installation Guide for Ubuntu. Then once you are up and running you can then use Openstack’s Operations Guide\nThe best attempt at an overall guide is from the Openstack in the basement project and all his Ubuntu Openstack install videos. \nTo make things simpler people make use of the Openstack installer which handles Juju for you which is why a lot of guides don't mention any Juju configuration.\n\nA: There is a single document which describes all this, it is here:\nhttps://help.ubuntu.com/lts/clouddocs/en/Intro.html\nBeware that it is a bit outdated with respect to some topics as it was written two years ago.\nSimilar documentation exists for the autopilot installer:\nhttps://help.ubuntu.com/lts/clouddocs/installer/\n", "Q: Doesn't Matlab work on ubuntu 16.04? MATLAB Crash Dump:\n    ------------------------------------------------------------------------\n       Segmentation violation detected at Thu Mar  3 01:40:49 2016\n------------------------------------------------------------------------\n\nConfiguration:\n  Crash Decoding      : Disabled\n  Crash Mode          : continue (default)\n  Current Graphics Driver: Unknown hardware \n  Current Visual      : 0x20 (class 4, depth 24)\n  Default Encoding    : UTF-8\n  GNU C Library       : 2.21 stable\n  Host Name           : ShapeShifter\n  MATLAB Architecture : glnxa64\n  MATLAB Root         : /usr/local/MATLAB/R2015b\n  MATLAB Version      : 8.6.0.267246 (R2015b)\n  OpenGL              : hardware\n  Operating System    : Linux 4.5.0-040500rc6-generic #201602281230 SMP Sun Feb 28 17:33:02 UTC 2016 x86_64\n  Processor ID        : x86 Family 6 Model 78 Stepping 3, GenuineIntel\n  Virtual Machine     : Java 1.7.0_60-b19 with Oracle Corporation Java HotSpot(TM) 64-Bit Server VM mixed mode\n  Window System       : The X.Org Foundation (11703000), display :0\n\nFault Count: 1\n\n\nAbnormal termination:\nSegmentation violation\n\nRegister State (from fault):\n  RAX = 0000000000000000  RBX = 00007f785858f0b8\n  RCX = 0000000000000000  RDX = 0000000000000006\n  RSP = 00007f78ee99fcb0  RBP = 00007f78ee99fdd0\n  RSI = 00007f7860cfd7a0  RDI = 00007f78585658a8\n\n   R8 = 0000000000000030   R9 = 0000000000000000\n  R10 = 00007f7858562000  R11 = 00007f78585942d8\n  R12 = 00007f78588e5ef0  R13 = 0000000000000006\n  R14 = 00007f7858566280  R15 = 00007f788836aa80\n\n  RIP = 00007f790b1de8ca  EFL = 0000000000010206\n\n   CS = 0033   FS = 0000   GS = 0000\n\nStack Trace (from fault):\n[  0] 0x00007f790b1de8ca                        /lib64/ld-linux-x86-64.so.2+00051402\n[  1] 0x00007f790b1e74e1                        /lib64/ld-linux-x86-64.so.2+00087265\n[  2] 0x00007f790b1e2474                        /lib64/ld-linux-x86-64.so.2+00066676\n[  3] 0x00007f790b1e69d3                        /lib64/ld-linux-x86-64.so.2+00084435\n[  4] 0x00007f79095c6f09                   /lib/x86_64-linux-gnu/libdl.so.2+00003849\n[  5] 0x00007f790b1e2474                        /lib64/ld-linux-x86-64.so.2+00066676\n[  6] 0x00007f79095c756d                   /lib/x86_64-linux-gnu/libdl.so.2+00005485\n[  7] 0x00007f79095c6fa1                   /lib/x86_64-linux-gnu/libdl.so.2+00004001 dlopen+00000049\n[  8] 0x00007f79059ed00a      /usr/local/MATLAB/R2015b/bin/glnxa64/libut.so+00311306\n[  9] 0x00007f79008497e5 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_dispatcher.so+00456677\n[ 10] 0x00007f790083c1af /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_dispatcher.so+00401839 _ZN13Mlm_MATLAB_fn8try_loadEv+00000031\n[ 11] 0x00007f7900833ae5 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_dispatcher.so+00367333 _ZN13Mlm_MATLAB_fn4loadEv+00000037\n[ 12] 0x00007f7900830b09 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_dispatcher.so+00355081 _ZN13Mfh_MATLAB_fn11dispatch_fhEiPP11mxArray_tagiS2_+00000057\n[ 13] 0x00007f78faf068af /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+08612015\n[ 14] 0x00007f78fb02a7ff /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+09807871\n[ 15] 0x00007f78fb02047f /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+09766015\n[ 16] 0x00007f78fafed981 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+09558401\n[ 17] 0x00007f78fac4fd6c /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+05766508\n[ 18] 0x00007f78fac3a4c1 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+05678273\n[ 19] 0x00007f78fac49075 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+05738613\n[ 20] 0x00007f78fae1a033 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+07643187\n[ 21] 0x00007f78fade1c40 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+07412800\n[ 22] 0x00007f78fade4078 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+07422072\n[ 23] 0x00007f78fade4140 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+07422272\n[ 24] 0x00007f78fae5b6bc /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+07911100\n[ 25] 0x00007f78fae5babc /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_lxe.so+07912124\n[ 26] 0x00007f78ffdbbd0d /usr/local/MATLAB/R2015b/bin/glnxa64/libmwm_interpreter.so+02600205 _Z51inEvalCmdWithLocalReturnInDesiredWSAndPublishEventsRKSbIDsSt11char_traitsIDsESaIDsEEPibbP15inWorkSpace_tag+00000077\n[ 27] 0x00007f79019b6a12   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwiqm.so+00915986 _ZNK3iqm18InternalEvalPlugin24inEvalCmdWithLocalReturnERKSbIDsSt11char_traitsIDsESaIDsEEP15inWorkSpace_tag+00000098\n[ 28] 0x00007f79019b6bd8   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwiqm.so+00916440 _ZN3iqm18InternalEvalPlugin7executeEP15inWorkSpace_tagRN5boost10shared_ptrIN14cmddistributor17IIPCompletedEventEEE+00000120\n[ 29] 0x00007f78dafb83b2 /usr/local/MATLAB/R2015b/bin/glnxa64/libnativejmi.so+00861106 _ZN9nativejmi21JmiInternalEvalPlugin7executeEP15inWorkSpace_tagRN5boost10shared_ptrIN14cmddistributor17IIPCompletedEventEEE+00000274\n[ 30] 0x00007f78dafdd565 /usr/local/MATLAB/R2015b/bin/glnxa64/libnativejmi.so+01013093 _ZN3mcr3mvm27McrSwappingIqmPluginAdapterIN9nativejmi21JmiInternalEvalPluginEE7executeEP15inWorkSpace_tagRN5boost10shared_ptrIN14cmddistributor17IIPCompletedEventEEE+00000437\n[ 31] 0x00007f79019b01c6   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwiqm.so+00889286\n[ 32] 0x00007f790199d645   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwiqm.so+00812613\n[ 33] 0x00007f78fc51abf9 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwbridge.so+00146425\n[ 34] 0x00007f78fc51b1f4 /usr/local/MATLAB/R2015b/bin/glnxa64/libmwbridge.so+00147956\n[ 35] 0x00007f78fc5206cd /usr/local/MATLAB/R2015b/bin/glnxa64/libmwbridge.so+00169677\n[ 36] 0x00007f78fc5207bc /usr/local/MATLAB/R2015b/bin/glnxa64/libmwbridge.so+00169916\n[ 37] 0x00007f78fc520ead /usr/local/MATLAB/R2015b/bin/glnxa64/libmwbridge.so+00171693 _Z8mnParserv+00000749\n[ 38] 0x00007f7900b71b4f   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00686927 _ZN11mcrInstance30mnParser_on_interpreter_threadEv+00000031\n[ 39] 0x00007f7900b5e443   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00607299\n[ 40] 0x00007f7900b5ea39   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00608825 _ZN5boost6detail11task_objectIvNS_3_bi6bind_tIvPFvRKNS_8functionIFvvEEEENS2_5list1INS2_5valueIS6_EEEEEEE6do_runEv+00000025\n[ 41] 0x00007f7900b5ff47   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00614215 _ZN5boost6detail9task_baseIvE3runEv+00000071\n[ 42] 0x00007f7900b5ffa7   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00614311\n[ 43] 0x00007f7900b5b2fa   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00594682\n[ 44] 0x00007f78f451a6b6   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwuix.so+00313014\n[ 45] 0x00007f78f4500862   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwuix.so+00206946\n[ 46] 0x00007f79014f10df /usr/local/MATLAB/R2015b/bin/glnxa64/libmwservices.so+03002591\n[ 47] 0x00007f79014f124c /usr/local/MATLAB/R2015b/bin/glnxa64/libmwservices.so+03002956\n[ 48] 0x00007f79014f2d9f /usr/local/MATLAB/R2015b/bin/glnxa64/libmwservices.so+03009951\n[ 49] 0x00007f79014f384c /usr/local/MATLAB/R2015b/bin/glnxa64/libmwservices.so+03012684 _Z25svWS_ProcessPendingEventsiib+00000092\n[ 50] 0x00007f7900b5b9b8   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00596408\n[ 51] 0x00007f7900b5bcd4   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00597204\n[ 52] 0x00007f7900b47fed   /usr/local/MATLAB/R2015b/bin/glnxa64/libmwmcr.so+00516077\n[ 53] 0x00007f7909d9c66a              /lib/x86_64-linux-gnu/libpthread.so.0+00030314\n[ 54] 0x00007f7909ad201d                    /lib/x86_64-linux-gnu/libc.so.6+01077277 clone+00000109\n[ 55] 0x0000000000000000                                   <unknown-module>+00000000\n\n\nIf this problem is reproducible, please submit a Service Request via:\n    http://www.mathworks.com/support/contact_us/\n\nA technical support engineer might contact you with further information.\n\nThank you for your help.\n\n\nA: Oh... I found answer myself:\nYou can force MATLAB to load the newer version of the library provided by the operating system, by following these instructions:\n\n\n*\n\n*Identify the location where MATLAB is installed.\n\n*Navigate to the sys/os/glnxa64 directory within this installation folder.\n\n*Rename libstdc++.so.6 library to libstdc++.so.6.old.\n\n\nA: I had this problem. but after I installed matlab-support the problem solved. \nsudo apt-get install matlab-support\n\nI answered my question here.\n\nA: I'm using Ubuntu 16.04LTS on a Lenovo ThinkStation S20 with GeForce 610 graphics card and installed Matlab R2016a. I renamed the library above but this fix did not work for me. Instead, I switched display drivers from Nvidia to the open source Nouveau. Matlab is working now.   \n\nA: I'm experiencing similar problems. I think the trouble started after upgrading the proprietary Nvidia driver. I'm using an Nvidia GTX 750 Ti with driver version 361.45.18 and the version of MATLAB I'm using is 2016a. ( see https://devtalk.nvidia.com/default/topic/926199/linux/361-28-crashes-matlab-r2016a/ )\nI tried to completely install and reinstall all nvidia packages, but this did not solve my problem. Then I stumbled on this thread, I tried the proposed fixed by @Yihui He (renaming libstdc++.so.6). After I've done this MATLAB would still crash but a couple seconds later, after the UI was loaded. Now the stack trace of the error was much more clear:\nStack Trace (from fault):\n[  0] 0x00007f78d2dea18d               /usr/lib/x86_64-linux-gnu/libGL.so.1+00344461\n\nI knew there was a cli switch to use software openGL, tried that and MATLAB 2016a dit not crash anymore when starting with:\n$ matlab -softwareopengl\n\nI will try to update this post if I find the final solution, but this might help another temporarily.\n", "Q: If I install a development library, do I need to install th regular library package? If I install the -dev package of a library, do I need the normal library package? for example, if I install libdb-dev, do I also need to install libdb5.3?\n\nA: Generally speaking, every time you use a packaging tool (like APT, APTITUDE or SYNAPTIC) to install the development file of a library, such packaging tool will automatically select dependencies for that installation, and the library itself will be one of the dependencies.\nThis happens because, generally speaking, the development package of a library file is configured to depend on the installation of the library itself.\nA possible reason why the compiled library is configured to be installed along with the library's development file is because after the installation of the library the packagin tool runs ldconfig, thus making it easier for the developer to test the compiled library's features and performance before deciding wheter to modify the library's source or not. It also makes it easier for the developer to test new compilations of the modified library under the same library name.\n", "Q: MySQL won't start after changing the datadir (14.04, mysql 5.7) I've mounted a separate hdd to /mnt/temp, and changed datadir to point to this. I added the correct settings in apparmor and worked away with mysql for a few hours. After adding performance_schema to my.cnf and attempting to restart mysql, I am getting the errors:\n[Warning] Can't create test file /mnt/temp/some_dir/blah.lower-test\n...\n[ERROR] InnoDB: The innodb_system data file 'ibdata1' must be writable\n...\n\nI've since chmod -R 777 /mnt/temp, shut down app armor, remounted the partition, manually killed any processes that would be interacting with the partition, and removed performance_schema from my configuration.\nAny suggestions?\n\nA: From Learning MySQL: AppArmor and MySQL\nIf you want to relocate the data directory in MySQL (in this example, to the /data/directory), and AppArmor is not letting you, add the following two lines to the bottom of /etc/apparmor.d/local/usr.sbin.mysqld:\n/data/ r,\n/data/** rwk, \n\n...and then reload the AppArmor profiles: \nsudo service apparmor reload \n\n\nA: I encountered the same, and could figure it was an issue with ownership (this also gave me the illusion of an issue with AppArmor).\nMay be you can try this (change /var/lib/mysql if it’s not matching yours):\nsudo chown -R mysql /var/lib/mysql\nsudo chgrp -R mysql /var/lib/mysql\n\nAs an explanatory side note, the user and group IDs for MySQL changed since older Ubuntu release. The previous user ID and group ID was now looking as hplip and pulse-access. Since the data directory is a mount‑bind for me (on another partition), it still had these previous IDs whose assignation changed.\n", "Q: Ubuntu 14.04 updated last night - HDMI video stopped working Ubuntu 14.04 with an integrated Intel graphics card that has worked for 6 months connected only to a Samsung TV via HDMI.\nSoftware update ran last night, installed some new packages.  After rebooting, the computer will not recognize the HDMI TV connected to it - the only video device.  VNC & ssh was installed, so I connected that way fine.  \nOne of my drives (non-boot /dev/sdb mapped to /home) was full - it is usually pretty full.  I cleaned out space and rebooted, no luck.  \nDid another apt-get update with no luck.\nVerified that a new boot image in /vmlinuz and /initrd.img point to /boot/vmlinuz-3.19.0-58-generic created this evening and ...-56 was created this morning. \nUsed grub to boot from the previous version ...-51 created end of March with no luck.\nTried:\nxrander --addmode 1920x1020 \nxrander --output HDMI1 --mode --1920x1080\n\nhung the computer.  \nTried different HDMI cable and different HDMI port on the TV, no luck.\nI have downloaded intel graphics package and could start building it from scratch (havent done kernel build in years), or have done a dd backup of the boot drive - could reinstall ubuntu on it... 14 or 16rc?\nOutput of lshw and xrander:\nlshw   part\n        *-display\n             description: VGA compatible controller\n             product: 4th Generation Core Processor Family Integrated Graphics Controller\n             vendor: Intel Corporation\n             physical id: 2\n             bus info: pci@0000:00:02.0\n             version: 06\n             width: 64 bits\n             clock: 33MHz\n             capabilities: msi pm vga_controller bus_master cap_list rom\n             configuration: driver=i915 latency=0\n             resources: irq:29 memory:f7800000-f7bfffff memory:e0000000-efffffff\n ioport:f000(size=64)\n\nxrander\nScreen 0: minimum 8 x 8, current 1920 x 1080, maximum 32767 x 32767\nHDMI1 disconnected (normal left inverted right x axis y axis)\nVGA1 connected primary 1920x1080+0+0 (normal left inverted right x axis y axis) 886mm x 498mm\n   1920x1080      60.0*+\n   1680x1050      60.0  \n   1280x1024      75.0     60.0  \n   1440x900       75.0     59.9  \n   1280x960       60.0  \n   1360x768       60.0  \n   1280x800       59.8  \n   1152x864       75.0  \n   1024x768       75.1     70.1     60.0  \n   832x624        74.6  \n   800x600        72.2     75.0     60.3  \n   640x480        75.0     72.8     66.7     60.0  \n   720x400        70.1  \nVIRTUAL1 disconnected (normal left inverted right x axis y axis)\n\n\nA: As with most other issues I have seen here - it was a bunch of random actions that fixed it.  \n\n\n*\n\n*Connected to VGA and HDMI - only VGA worked. \n\n*Created an installation USB for ubuntu 14.04 using \"startup disk      creator\" and left it in the USB.  \n\n*Shutdown using the GUI.\n\n*Booted into BIOS and changed the boot order to have USB boot first\n(or so I thought).\n\n*Left the BIOS at Press Enter to Save & Close\n\n*Disconnected VGA cable\n\n*Pressed Enter... PC rebooted and HDMI worked - booted immediately into Ubuntu - not\nthe live/install USB.\n\n*Removed the USB, rebooted and it still works!?!\n\n", "Q: How do I automatically raise a window, called by a keyboard shortcut? So I've read through the tutorials on how to setup the web browser keyboard shortcuts but I can't seem to find how to make the default web browser keyboard shortcut appear on top.\nI'm going to settings -> keyboard -> shortcuts -> launcher -> launch web browser.\nI've set it to Shift+Ctrl+I.\nWhenever I execute the Shift+Ctrl+I command it launches a new web browswer....but in the background. How can I have it launch in the foreground? \n\nA: I just tried it on my laptop. You should create a custom shortcut with the command:\n\nexo-open --launch WebBrowser\n\nIt starts on the foreground for me.\nSource: xubuntu\n", "Q: Impress presentation format problem I have install Ubuntu 15.10 and am using libreoffice impress office version 5.1.1.3 and using windows fonts in Ubuntu, still am facing a problem am created some PPT  also am saved this files .pptx, but when am open this files in windows 7 then some contains and table messed up am also try to update libreoffice but no any solution found, and attachment\n\n\nA: The easiest way to solve this issue is to save the LibreOffice Impress file in its native ODP extension, on your Linux system. After you do that, access your Windows system, download and install the LibreOffice suite for Windows 7, then run it in order to open your ODP file on Windows 7.\nAn alternative to this - in case you don't need to edit the presentation file on Windows - is to use your Linux's LibreOffice Impress to export the presentation as a PDF file, so you can then open it and switch it to \"presentation mode\", which is nice if you want to use it e.g. on a business meeting.\nConcerning tables, pictures, polygons and other objects present in LibreOffice files (drawings, texts, presentations et cetera), there are known long-term issues that occur while LibreOffice converts to the Microsoft Office format (DOC, DOCX, PPT, PPTX, XLS, XLSX et cetera) files that contain such objects. Thus, it's wise to avoid attempting such conversions. Not even iWork (Apple's office suite) succeeds 100% when it tries to open (or convert) Microsoft Office files.\nPS: also notice that although PPTX is a \"XML PPT\" and thus it uses an open source format, traditionally Open Office and its forks (LibreOffice included) deal better with PPT files than with PPTX files. Thus, you should definitely give the PPT extension a try.\n\nA: You can try exporting the presentation to a PDF, where you can simply click through each slide. File -> Export to PDF This is what I would do, and it really is the only solution that doesn't involve a ton of re-editing. \nIf you have time, you can also make sure that Powerpoint has the same fonts as Impress, that would solve some issues. Powerpoint and Impress are known to not work well together, even when trying to share versions. Powerpoint simply has more features and is more complex than Impress. In the future, use one or the other.\nAnother thing to mention. If you can use Libreoffice Impress on Windows (preferably the same version), you should. It will definitely work with the Impress presentation created in Ubuntu, just be sure to save it as the default ODP format, and open the file in Windows. This would preserve transitions and rendering ability on the Windows side of things - you could present directly from Impress on Windows (if needed).\n", "Q: Ubuntu and proxy I have Ubuntu 15.10 and I can't get updates using sudo apt-get. I tried setting up a proxy using GUI settings and using this command in the terminal:\nexport http_proxy=\"http://user:password@host:port\n\nYet nothing is working. Any ideas?\n\nA: Create an empty file on \"/etc/apt/apt.conf\" \nEdit \"apt.conf\" file and add the below lines  \nAcquire::http::proxy \"http://admin:proxyusername@192.168.0.1:3128/\"; \nAcquire::ftp::proxy \"ftp://admin:proxyusername@192.168.0.1:3128/\"; \nAcquire::https::proxy \"https://admin:proxyusername@192.168.0.1:3128/\";\nOnce all done restart squid or squid3 services. and try to update\n", "Q: Ubuntu 14.04 not loading SSD with Windows 8 on it At the moment I have a 1.5tb WD HDD with Ubuntu 14.04 loaded on it. Instead of booting up Ubuntu I want to boot windows off of a sandisk 240gb SSD I also have installed. Every time I look at the drive in files while in Ubuntu it says that the disk contains an unclean file system. Please help as soon as possible.\n\nA: The unclean file system message has a very simple explanation - your Windows is not shut down but hibernated. You should start Windows, disable hibernation (run \"powercfg -h off\" command in an elevated command prompt), shutdown Windows, start Linux and I'm 99.99% confident you'll not get the unclean file system message anymore.\nIt's not clear from your post what you mean by \"I want to boot windows\" part - are you trying to boot Windows and fail? Just remove the Linux HDD and let only the Windows HDD in the system and try like this. Anyway, if you moved the Windows HDD from another system it might fail booting (and even if it will boot it will most probably miss drivers and/or ask to re-activate due to the hardware changes).\nYou should boot the Windows HDD on the system where Windows was installed. After you disable hibernation as instructed above and shut down than you could move the HDD to the Linux system in order to access files from it (but not booting Windows from it) from Linux.\n", "Q: Install guest additions with Dockerfile Right now I'm using docker to build a personalized virtual environment for tensor flow development.\nI will install fluxbox and guest additions ontop of an existing tensor flow Ubuntu Docker...\nhere is my Dockerfile\nFROM b.gcr.io/tensorflow/tensorflow:latest-devel\nRUN apt-get update && apt-get upgrade -y\n\nRUN apt-get install -y build-essential module-assistant\nRUN m-a prepare\nRUN m-a update\nRUN sh /media/cdrom/VBoxLinuxAdditions.run\n\nRUN apt-get -y install xorg openbox\nRUN apt-get -y install fluxbox\nRUN apt-get -y install gedit\n\nRUN apt-get update\nRUN apt-get upgrade -y\n\nUnfortunately RUN m-a prepare exits with code 101 expecting me to Click on Install Guest Additions… from the VirtualBox Devices menu.\nI am thinking that this is the same type of issue you get if you try to apt-get install without the -y option, the docker file results in a indeterminate state requiring user input and the whole thing crashes.\nNow I have been looking for a couple hours now and I can't figure how to install guest additions in with my Dockerfile...\nAny input would be awesome!\nI also posted this question here : https://superuser.com/questions/1067118/install-guest-additions-in-dockerfile\n\nA: You can install virtualbox-guest-dkms package instead, it contains the same guest drivers.\nsudo apt-get install virtualbox-guest-dkms\n\n", "Q: Know Ubuntu Distribution server or desktop I am asking question after googling and I tried multiple solution but need a specific answer. \nI have logged in another pc with SSH and I need to know that the OS distribution is server or desktop.\nI have tried following command and its output:\nlsb_release -a\n\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 12.04.5 LTS\nRelease:    12.04\nCodename:   precise\n\nSecond Command\ncat /proc/version\n\nLinux version 3.5.0-61-generic (buildd@toyol) (gcc version 4.6.3 (Ubuntu/Linaro 4.6.3-1ubuntu5) ) #90-Ubuntu SMP Sun Apr 26 11:23:53 UTC 2015\n\nNot at all duplicate with this \nHow to check if ubuntu desktop or server is installed?\n\nA: As mentioned in the linked post, it's not easy to determine if you use a desktop or server edition because all packages can be installed or removed. \nHere is my function I use for my scripts.\nBasically it checks if xserver-common or xwayland are installed. If one of them is installed it means its an desktop system.\n#!/usr/bin/env bash\n\ncheck_if_desktop (){\n  IS_DESKTOP=\"false\"\n\n  displayManager=(\n    'xserver-common' # X Window System (X.Org) infrastructure\n    'xwayland' # Xwayland X server\n  )\n  for i in \"${displayManager[@]}\"; do\n    dpkg-query --show --showformat='${Status}\\n' $i 2> /dev/null | grep \"install ok installed\" &> /dev/null\n    if [[ $? -eq 0 ]]; then\n      IS_DESKTOP=\"true\"\n    fi\n  done\n}\n\nHere are a few other things to check:\nBy default the server edition uses the classic /etc/network/interfaces, while the desktop edition operates with Network Manager, so check if Network Manager is installed\ndpkg -l network-manager\n\nOr run the command nmcli (the command line tool for NM)\nif you get a message like this:\nThe program 'nmcli' is currently not installed. You can install it by typing:\nsudo apt-get install network-manager\n\nthe probability is high that you are on a server edition.\nBut keep in mind, you can modify a server to operate with NM.\n\nUse the following command to determine if desktop components are installed\ndpkg -l ubuntu-desktop\n\nOn a Server you will get a message like this: \ndpkg-query: no packages found matching ubuntu-desktop\n\nOn a Desktop you will get a message that tells you which version is installed\n\nCheck for other packages that are typically found on a desktop:\ndpkg -l unity (gnome, mate and so one) # Desktop environments\ndpkg -l compiz (E17, fluxbox and so one) # Window manager\ndpkg -l xorg # X window server\n\nor use:\n dpkg-query --show --showformat='${Status}\\n' *packagename* 2> /dev/null | grep \"install ok installed\"\n\ncheck if the X server is running:\nps -e | grep X\nsudo netstat -lp | grep -i Xorg\n\n\nCheck for services that are only available on a desktop:\nIt depends on your Ubuntu version how to check the services:\nsudo service *servicename* status # on SysVinit \nsudo status *servicename* # on Upstart\nsystemctl status *servicename*.service # on systemd\n\ntypical services are:\n\n\n*\n\n*lightdm\n\n*x11-common\n\n*gnome-shell\n\n\nand some others that are associated with certain derivatives\n\n\nMy application depends on server distribution\n\nEven if it doesn't make any sense to run a server application on a desktop edition, there shouldn't be any issues with installing all the dependencies for your application on the desktop edition and make it working.\nCan you elaborate on this why it depends on the server distro?\n\nA: you should try the following\nstep 1: type dpkg --list\nthis will show you all installed packages (it will be a lot)\nstep 2: scroll up or down to find any *-session packages, i believe they are the sources of a desktop\nGood luck!\n", "Q: I need a script file for checking (ping) 3 ip address are working or not I need to create a script for checking (ping) 3 ip address are working or not.\nusing the crone tab and i do want to know how is it working.\nI was used a script using a test file, but i need to get the alert message in my mail af any one ip address is down..\nplease help me anyone.\nthanks in advance \ni have used this script..\n#!/bin/bash\n\nfor i in $( cat $HOME/iplist.txt )\ndo\nping -q -c2 $i > /dev/null\nif [ $? -eq 0 ]\nthen\necho $i \"Pingable\"\nelse\necho $i \"Not Pingable\"\nfi\ndone\n\nwith the ip list.txt file.\n\nA: Use a while loop with read to get each IP address and then use ping:\n#!/bin/bash\nwhile IFS= read -r ip; do\n    if ping -q -c2 \"$ip\" &>/dev/null; then\n        echo \"$ip is Pingable\"\n    else\n        echo \"$i Not Pingable\"\n    fi\ndone <\"$HOME\"/iplist.txt\n\n", "Q: Getting shared folders working in vmware fusion 8.1.0 and ubuntu 14.04 Yes, I've seen the other answers. Either they don't work or they do un-recommended things like installing the old deprecated VMWare Tools\nI'm looking for a solution that uses the recommended open-vm-tools\nThe offical instructions for Ubuntu 14.04 on vmware's site say\n\nVMware recommends using the Open VM Tools redistributed by the operating system vendors. \n\nThey then say\n\nTo use Open VM Tools:\n  \n  \n*\n  \n*Add the vmhgfs Driver\nIf you are using the interactive file drag-and-drop feature in VMware Workstation and Fusion, install the vmhgfs driver in the virtual machine. This driver is not included inbox in the operating system. Installing the additional vmhgfs driver does not disturb the other inbox VMware drivers or Open VMware Tools. To install this driver:\n\n    \n*\n    \n*Install Open VMware Tools.\n    \n*Install the traditional TAR Format VMware Tools that is bundled \n    with VMware Workstation or Fusion products.\n    \n  \n\n  \n*Add the deployPkg Tools Plug-in\nIf you are using the virtual machine as a template or if it will be protected by SRM (Site Recovery Manager), then install the deployPkg Tools plug-in. To install this plug-in:\n\n    \n*\n    \n*Obtain and import the VMware Packaging Public Keys:\n    \n    \n    \n      \n*\n      \n*Create a directory on your Ubuntu virtual machine to store the VMware Packaging Public Keys.\n      \n*Download all the VMware Public Packaging Public Key files from the http://packages.vmware.com/tools/keys directory.\n      \n*Save the files to the directory you created.\n      \n*For each key that you download, import the key:\n      $ sudo apt-key add /key_path/key_name\nkey_path is the directory in which you saved the keys.\n      key_name is the file name of a key.\n      \n    \n\n    \n*Create a file, /etc/apt/sources.list.d/vmware-tools.list, with the following content:\ndeb http://packages.vmware.com/packages/ubuntu ubuntu_version main\n\nubuntu_version is either precise or trusty.\n    \n*Install the package:\n$ apt-get update\n$ apt-get install open-vm-tools-deploypkg\n\n\n\nThese instructions are not clear to me at all.\nUnder Add the vmhgfs Driver it says \"1. Install Open VMWare Tools\" and \"2. Install the traditional TAR Format VMware Tools that is bundled with VMware Workstation or Fusion products.\" but #2 is explicitly what it told me NOT to do right at the top. It's listed as 2 steps but appears to be 2 options? (one or the other but not both)\nEven if I wanted to do step 2 it's incompatible with step 1. Running the VMWare Tools installer when the Open VMWare Tools are installed fails saying to uninstall them. Are there instructions on what this step 2 really means?\nTrying it anyway you can see it fails\n$ tar xvfz /media/gregg/VMware\\ Tools/VMwareTools-10.0.5-3228253.tar.gz\n$ cd vmware-tools-distrib\n$ sudo ./vmware-install.pl\nThe installer has detected an existing installation of open-vm-tools on this \nsystem and will not attempt to remove and replace these user-space\napplications. It is recommended to use the open-vm-tools packages provided by \nthe operating system. If you do not want to use the existing installation of \nopen-vm-tools and attempt to install VMware Tools, you must uninstall the \nopen-vm-tools packages and re-run this installer.\nThe packages that need to be removed are:\nopen-vm-dkms\nopen-vm-tools\nThe installer will next check if there are any missing kernel drivers. Type yes\nif you want to do this, otherwise type no [yes]\n\nOf course I type no because it specifically said above installing this so-called vmhgfs driver is compatible with open-vm-tools \nDoing just step 1, \"installing Open VMWare Tools\", based on the official instructions here, has not given me shared folders.\n$ dpkg --get-selections | grep open-vm\nopen-vm-dkms                    install\nopen-vm-tools                   install\nopen-vm-tools-deploypkg         install\nopen-vm-tools-desktop           install\nopen-vm-tools-dkms              install\n\nReally lost. I used to use the non-open VMware Tools which are deprecated. Every time I updated I had to reinstall them. It was always a chore. The Open VM Tools is supposed to solve this. Copy from host and paste to guest work. vmware-hgfsclient runs and shows me a list of the host folders I have shared.\nMounting manually fails (though I don't want to have to mount manually. I want it to work automatically like it did with the old VMWare Tools)\n$ ls -l /mnt\ndrwxr-xr-x 2 root root 4096 Apr 18 23:36 hgfs\n$ sudo mount -t vmhgfs .host:/temp /mnt/hgfs\nError: cannot mount filesystem: No such device\n$ sudo mount -t vmhgfs .host:/temp /mnt/hgfs/temp\nError: cannot canonicalize mount point: No such file or directory\n\nHelp!\n\nA: I had the same problem (Ubuntu 16.04LTS). This was how I solved it.\n\n\n*\n\n*Install Open VM tools:\nsudo apt-get install open-vm-tools-desktop\n\n*Use the vmhgfs-fuse that OpenDJ also suggested.\nmkdir $HOME/Shared\n/usr/bin/vmhgfs-fuse -o auto_unmount .host:/ $HOME/Shared\nThat's it! Good luck.\n\nA: There is no vmhgfs driver any more it seems.\nI found the following program within the open-vm-tools package:\n/usr/bin/vmhgfs-fuse --help\n\nSo I created a directory Shared in my home folder and did mount the host file system manually:\n/usr/bin/vmhgfs-fuse -o auto_unmount .host:/ $HOME/Shared\n\n", "Q: Backup script in Server I am using Ubuntu  12.10 server edition Now i need script which will backup Samba Share to USB drive attached to the server and also generate the back up log with Log File format containing File Name, Size and Time\nAlso confirm the Crontab Settings \nThanks in advance\n\nA: There are different packages you can use for backups. I personally use rsnapshot which encapsulates rsync.\nThere you have some configuration-file where you can specify all your wishes.\n\nA: If you don't have installed rsync install them\nsudo apt-get install rsync\n\nCreate script backup_script.sh\n#!/bin/bash\n\n# Script to backup personal files to the external USB drive.\n# Specify the mount point here (DO NOT end mount_point with a forward-slash).\nmount_point='/mnt/'\n\necho \"#####\"\necho \"\"\n# Check whether target volume is mounted, and mount it if not.\nif ! mountpoint -q ${mount_point}/; then\n    echo \"Mounting the external USB drive.\"\n    echo \"Mountpoint is ${mount_point}\"\n    if ! mount ${mount_point}; then\n        echo \"An error code was returned by mount command!\"\n        exit 5\n    else echo \"Mounted successfully.\";\n    fi\nelse echo \"${mount_point} is already mounted.\";\nfi\n# Target volume **must** be mounted by this point. If not, die screaming.\nif ! mountpoint -q ${mount_point}/; then\n    echo \"Mounting failed! Cannot run backup without backup volume!\"\n    exit 1\nfi\n\necho \"Preparing to transfer differences using rsync.\"\n\n# Use the year to create a new backup directory each year.\ncurrent_year=`date +%Y`\n# Now construct the backup path, specifying the mount point followed by the path\n# to our backup directory, finishing with the current year.\n# (DO NOT end backup_path with a forward-slash.)\nbackup_path=${mount_point}'/rsync-backup/'${current_year}\n\necho \"Backup storage directory path is ${backup_path}\"\n\necho \"Starting backup of /home/XXX/Pictures . . . \"\nmkdir --parents ${backup_path}/Pictures\n# This time use the -a flag with the tee command, so that it appends to the end\n# of the rsync-output.txt file rather than start a new file from scratch.\nsudo rsync --archive --verbose --human-readable --itemize-changes --progress --no-o --no-g \\\n--delete --delete-excluded \\\n/home/XXX/Pictures/ ${backup_path}/Pictures/ 2>&1 | tee -a /home/XXX/rsync-output.txt\n\n\necho \"\"\necho \"####\"\n\nYou must change\n\n\n*\n\n*mount point of your ext USB - in example I use /mnt/\n\n*path to folder you wish to backup - in exampl I use /home/XXX/Pictures\n\n*place to to write log file - in example I use /home/XXX/\nGive script execute privilege\nchmod +x /path_to_script/backup_script.sh\n\nSetup crontab to run this command on every x period of time\nFor editing crontab run\ncrontab -e\n\nFor running command on every 5 min code is\n*/5 * * * * /path_to_script/backup_script.sh\n\non every hour\n0 */1 * * * /path_to_script/backup_script.sh\n\nto run on 4 am\n0 4 * * * /path_to_script/backup_script.sh\n\nOptionaly, you can send log file to your mail with command\nmail -s \"SMB backup\" your@mail.com < /path_to_log/rsync-output.txt\n\nSetup cron to do for you\n0 4 * * * mail -s \"SMB backup\" your@mail.com < /path_to_log/rsync-output.txt\n\n", "Q: E: GPG error: http://mega.nz ./ InRelease: Clearsigned file isn't valid, got 'NODATA' (does the network require authentication?) Running Xubuntu 14.04LTS\nOriginally, I was getting the following error\nE: GPG error: http://mega.nz ./ Release: The following signatures were invalid: NODATA 1 NODATA 2\n\nDid what this answer told me to do, tried updating again. New problem arose. \nE: GPG error: http://mega.nz ./ InRelease: Clearsigned file isn't valid, got 'NODATA' (does the network require authentication?)\n\nHow do I fix this?\n\nA: I had the same error. Since its a recent issue, i believe it must have been a problem with the megasync server. I fixed it by going to \n/etc/apt/sources.list.d \nand then deleting all the files that started with mega using :\n\nsudo rm mega*\n\nThen run:\n\nsudo apt-get update\n\n\nA: I'm having the same error. \nThough the above mentioned technique may work, I'll suggest a more cleaner way\n\n\n*\n\n*Go to System Settings -> Software & Updates -> Other\nSoftware.\n\n*Uncheck the option containing http://mega.nz ./ InRelease.\n\n\nThis will get your apt-get update working without having to remove your configuration settings. \nLastly wait for Mega to create a patch for this bug and re check the the box again using the same steps.\n\nA: Megasync GPG issue is fixed by reinstall.(UBUNTU18.04)\nOpen \"software and update\",then delete \"https://mega.nz/linux/MEGAsync/xUbuntu_18.04/\" ripository.\nsudo apt-get --purge remove megasync\nrm -rf ~/.local/share/data/Mega\\ Limited\nsudo apt-get update\nsudo apt-get upgrade\nsudo apt autoremove\n\nDownload megasync-xUbuntu_18.04_amd64.deb from MegaSync\nsudo dpkg -i megasync-xUbuntu_18.04_amd64.deb\nsudo apt-get -f install\n\nlaunch Magasync.\n", "Q: I have 5 hosts which i need to ping if any one down i should be alerted through an email it is possible..? I have 5 hosts which i need to ping if any one down i should be alerted through an email it is possible..?\nand it will be checked with every 20 minutes. can anyone help me.. Thanks in advance...\ni have used this script.. Do i need to make any changes for getting the expected result ?\nPlease suggest any opinion please.\n    #!/bin/bash\n\n    for i in $( cat $HOME/iplist.txt )\n    do\n    ping -q -c2 $i > /dev/null\n    if [ $? -eq 0 ]\n    then\n    echo $i \"Pingable\"\n    else\n    echo $i \"Not Pingable\"\n    fi\n    done\n\n\nA: Your script looks ok. You should add exit 0 / exit 1, for failure / success .. more info below.\n\nand it will be checked with every 20 minutes\n\nIf the script should run always, each 20 minutes in the background, you should use cron, which is already available on your system.\nLike that all output of your script will be mailed to root, if the script returns 1(FAILURE) .. however per default the root-mail just goes to some folder. You need to install & configure a mail-daemon to forward the root-mail to your personal mail-address. How that can be done is e.g. explained here: https://superuser.com/questions/306163/what-is-the-you-have-new-mail-message-in-linux-unix\nOr here:\nEasy way to forward all email\nEdit:\nOk, here some commands to get things done.\n1.) First you need a version of your script which exits 1 on failure. Something like this should do:\n#!/bin/bash\n\nALL_HOSTS_AVAILABLE=true\nfor i in $( cat $HOME/iplist.txt )\ndo\n   ping -q -c2 $i > /dev/null\n   if [ $? -eq 0 ]\n   then\n      echo $i \"Pingable\"\n   else\n      echo $i \"Not Pingable\"\n      ALL_HOSTS_AVAILABLE=false\nfi\ndone\n\nif [ \"$ALL_HOSTS_AVAILABLE\" = false ] ; then\n   echo 'Some hosts were not available!'\n   exit 1\nfi\nexit 0\n\n2.) Now make sure you have sudo-permissions set for your user(you dont want to do things directly as root). If not, follow this manual:\nHow do I add a user to the \"sudo\" group?\nMaybe you first need to install the package sudo\nsu root\napt-get install sudo\n\n3.) Copy your script to some folder which is visible to all users and hand it over to root. E.g:\nsudo cp myScript /usr/local/bin\nsudo chown root /usr/local/bin/myScript\nsudo chgrp root /usr/local/bin/myScript\n\n4.) Setup a cronjob which runs your script\n# write out current crontab\ncrontab -l > mycron\n# echo new cron into cron file */20 means each 20 minutes\n# Check https://de.wikipedia.org/wiki/Cron for format\necho \"*/20 * * * * /usr/local/bin/myScript\" >> mycron\n# install new cron file\nsudo crontab mycron\nrm mycron\n\n5.) Install some MTA, so you get the email-notification working .. it looks like the most simple one is nullmailer\nsudo apt-get install nullmailer\n\n.. I dont know details, just google for help to do the nullmailer setup in the right way.\n", "Q: Ubuntu packages don't get update I get this output: \n7 packages can be updated.\n7 updates are security updates.\n\nLast login: Tue Apr 19 10:04:51 2016 from 10.0.0.199\n\nwhenever I connect to my server. and I still see these packages not updated!\nAnd I AM root (sudo su).\nWhen I sudo apt-get update I get this: \nmyserver@YHserver:~$ apt-get update\nE: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denie                                                                                                                                                             d)\nE: Unable to lock directory /var/lib/apt/lists/\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\nHit http://il.archive.ubuntu.com wily InRelease\nHit http://il.archive.ubuntu.com wily-updates InRelease\nHit http://il.archive.ubuntu.com wily-backports InRelease\nHit http://il.archive.ubuntu.com wily/main Sources\nHit http://il.archive.ubuntu.com wily/restricted Sources\nHit http://il.archive.ubuntu.com wily/universe Sources\nHit http://il.archive.ubuntu.com wily/multiverse Sources\nHit http://il.archive.ubuntu.com wily/main amd64 Packages\nHit http://il.archive.ubuntu.com wily/restricted amd64 Packages\nHit http://il.archive.ubuntu.com wily/universe amd64 Packages\nHit http://il.archive.ubuntu.com wily/multiverse amd64 Packages\nHit http://il.archive.ubuntu.com wily/main i386 Packages\nHit http://il.archive.ubuntu.com wily/restricted i386 Packages\nHit http://il.archive.ubuntu.com wily/universe i386 Packages\nHit http://il.archive.ubuntu.com wily/multiverse i386 Packages\nHit http://il.archive.ubuntu.com wily/main Translation-en\nHit http://il.archive.ubuntu.com wily/multiverse Translation-en\nHit http://il.archive.ubuntu.com wily/restricted Translation-en\nHit http://il.archive.ubuntu.com wily/universe Translation-en\nHit http://il.archive.ubuntu.com wily-updates/main Sources\nHit http://il.archive.ubuntu.com wily-updates/restricted Sources\nHit http://il.archive.ubuntu.com wily-updates/universe Sources\nHit http://il.archive.ubuntu.com wily-updates/multiverse Sources\nHit http://il.archive.ubuntu.com wily-updates/main amd64 Packages\nHit http://il.archive.ubuntu.com wily-updates/restricted amd64 Packages\nHit http://il.archive.ubuntu.com wily-updates/universe amd64 Packages\nHit http://il.archive.ubuntu.com wily-updates/multiverse amd64 Packages\nHit http://il.archive.ubuntu.com wily-updates/main i386 Packages\nHit http://il.archive.ubuntu.com wily-updates/restricted i386 Packages\nHit http://il.archive.ubuntu.com wily-updates/universe i386 Packages\nHit http://il.archive.ubuntu.com wily-updates/multiverse i386 Packages\nHit http://il.archive.ubuntu.com wily-updates/main Translation-en\nHit http://il.archive.ubuntu.com wily-updates/multiverse Translation-en\nHit http://il.archive.ubuntu.com wily-updates/restricted Translation-en\nHit http://il.archive.ubuntu.com wily-updates/universe Translation-en\nHit http://il.archive.ubuntu.com wily-backports/main Sources\nHit http://il.archive.ubuntu.com wily-backports/restricted Sources\nHit http://il.archive.ubuntu.com wily-backports/universe Sources\nHit http://il.archive.ubuntu.com wily-backports/multiverse Sources\nHit http://il.archive.ubuntu.com wily-backports/main amd64 Packages\nHit http://il.archive.ubuntu.com wily-backports/restricted amd64 Packages\nHit http://il.archive.ubuntu.com wily-backports/universe amd64 Packages\nHit http://il.archive.ubuntu.com wily-backports/multiverse amd64 Packages\nHit http://il.archive.ubuntu.com wily-backports/main i386 Packages\nHit http://il.archive.ubuntu.com wily-backports/restricted i386 Packages\nHit http://il.archive.ubuntu.com wily-backports/universe i386 Packages\nGet:1 http://security.ubuntu.com wily-security InRelease [65.9 kB]\nHit http://il.archive.ubuntu.com wily-backports/multiverse i386 Packages\nHit http://il.archive.ubuntu.com wily-backports/main Translation-en\nHit http://il.archive.ubuntu.com wily-backports/multiverse Translation-en\nHit http://il.archive.ubuntu.com wily-backports/restricted Translation-en\nHit http://il.archive.ubuntu.com wily-backports/universe Translation-en\nGet:2 http://security.ubuntu.com wily-security/main Sources [45.5 kB]\nGet:3 http://security.ubuntu.com wily-security/restricted Sources [2,854 B]\nGet:4 http://security.ubuntu.com wily-security/universe Sources [11.7 kB]\nGet:5 http://security.ubuntu.com wily-security/multiverse Sources [2,782 B]\nGet:6 http://security.ubuntu.com wily-security/main amd64 Packages [145 kB]\nGet:7 http://security.ubuntu.com wily-security/restricted amd64 Packages [10.9 k                                                                                                                                                             B]\nGet:8 http://security.ubuntu.com wily-security/universe amd64 Packages [52.1 kB]\nGet:9 http://security.ubuntu.com wily-security/multiverse amd64 Packages [6,253                                                                                                                                                              B]\nGet:10 http://security.ubuntu.com wily-security/main i386 Packages [142 kB]\nGet:11 http://security.ubuntu.com wily-security/restricted i386 Packages [10.8 k                                                                                                                                                             B]\nGet:12 http://security.ubuntu.com wily-security/universe i386 Packages [52.1 kB]\nGet:13 http://security.ubuntu.com wily-security/multiverse i386 Packages [6,430                                                                                                                                                              B]\nHit http://security.ubuntu.com wily-security/main Translation-en\nHit http://security.ubuntu.com wily-security/multiverse Translation-en\nHit http://security.ubuntu.com wily-security/restricted Translation-en\nHit http://security.ubuntu.com wily-security/universe Translation-en\nFetched 555 kB in 2s (227 kB/s)\nReading package lists... Done\n\nwhat should I do to get it updated? It's security updates and it seems important\nI always run apt-get upgrade -y after 'update'.\nI DIDN'T delete the lock file and followed the 2nd comment to this post: \nUnable to lock the administration directory (/var/lib/dpkg/) is another process using it?\nAnd this isn't helping. I cant see the process that's holding 'apt'\nroot      3004  0.0  0.0   9496  2260 pts/0    S+   10:32   0:00 grep --color=auto apt-get\nroot@YHserver:/home/myserver# kill -9 3004\nbash: kill: (3004) - No such process\nroot@YHserver:/home/myserver# kill -9 2260\nbash: kill: (2260) - No such process\nroot@YHserver:/home/myserver# kill -9 9496\nbash: kill: (9496) - No such process\n\n\nA: E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denie                                                                                                                                                             d)\nE: Unable to lock directory /var/lib/apt/lists/\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\nThis looks like you have some kind of permission problem. \nmyserver@YHserver ...\n\nYou should be root when doing update / upgrade. It looks like you are \"myserver\" instead of root. Do you connect to the machine via ssh, or directly ? ( You need to enable \"root via ssh\")\nPlease try to exec the commands patrick wrote and report the outcome here \nsudo apt-get update\nsudo apt-get upgrade -y\n\nIf that does not help, please try the following:\nsu\napt-get update\napt-get upgrade -y\n\nAnother possibilty that comes to my mind: Did you check for dist-upgrades ?\nsudo apt-get dist-upgrade\n\n\nA: try this\nsudo apt-get update;sudo apt-get upgrade -y\n\ni use that a lot and it will update any packages installed if there is an update available \n", "Q: Samba 2:3.6.25-0ubuntu0.12.04.2 error after 19 update After update USN-2950-1: Samba vulnerabilities\nthe samba server ubuntu cannot anymore get the domain controller\n/var/log/apt/history.log\nStart-Date: 2016-04-19  06:37:17\nUpgrade: libpam-winbind:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2), smbclient:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2), libwbclient0:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2), libpa\nEnd-Date: 2016-04-19  06:37:29\n\n/var/log/samb/log.mizar\n  domain_client_validate: Domain password server not available.\n[2016/04/19 06:41:00.442169,  0] auth/auth_domain.c:292(domain_client_validate)\n\nand more of these...\nHow do I resolve this?\n\nA: We have the same problem. The only workaround is matener we thought the old samba packages where our DOMAIN worked properly. To do reinstall the following packages that were updated:\nThese are the packages that were automatically updated.\n\nStart-Date: 2016-04-19  06:42:23\nUpgrade: smbclient:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2), libwbclient0:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2), samba-common:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2), samba-doc:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2), samba:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2), samba-common-bin:amd64 (3.6.3-2ubuntu2.17, 3.6.25-0ubuntu0.12.04.2)\nEnd-Date: 2016-04-19  06:42:38\n\nReinstalling previous packages.\n\nsudo apt-get install samba=2:3.6.3-2ubuntu2 samba-common=2:3.6.3-2ubuntu2 smbclient=2:3.6.3-2ubuntu2 samba-common-bin=2:3.6.3-2ubuntu2 samba-doc=2:3.6.3-2ubuntu2 libwbclient0=2:3.6.3-2ubuntu2\n\nAlso I disable automatic updates of ubuntu server.\n\nsudo dpkg-reconfigure -plow unattended-upgrades\n\nThus leaving the following configuration file:\n\ncat /etc/apt/apt.conf.d/20auto-upgrades\nAPT::Periodic::Update-Package-Lists \"0\";\nAPT::Periodic::Unattended-Upgrade \"0\";\n\nAnother way to avoid updating samba is blocking packages when upgrading other packages on the server.\nPaolo Dávila\n\nA: I had to enable, activate, run winbind.service to reactivate domain/ads login\n", "Q: I'm not able to upgrade NodeJS on Ubuntu 14.04 I'm currently using Ubuntu 14.04 LTS, and I installed NodeJS 0.10. I am now trying to upgrade to version 5 of NodeJS.\nI used the commands below to upgrade:\nwget -qO- https://deb.nodesource.com/setup_4.x | sudo bash -\nsudo apt-get install --yes nodejs\n\n\nA: Have you heard of n? With n you can interactively manage all your Node versions. You can have any amount of versions, for example 0.10.44 and 5.10.1 alongside each other.\nHow to do it:\n\n\n*\n\n*Install npm with sudo apt-get install npm.\n\n*sudo npm install n -g.\n\n*sudo n stable or any of the results of n ls to download and install that node version.\n\n*Sit back and let it install.\n\n*To verify that the installation was successful, type node -v.\nTo install another node version, simply run sudo n <version> (e.g 0.10). To switch, type sudo n and select your preferred version with the arrow up and down keys.\n", "Q: Change keyboard layout xmir I am a happy owner of the M10 tablet. Only when using the legacy x11 apps my keyboard layout does not follow the system settings. From what i understand these run in a container, so is there any way to change the keyboad layout in there?\n\nA: I have the same issue with my M10 tablet. I will post an update if I find a solution\nlittle update:there is already a bug filed on launchpad\nhttps://bugs.launchpad.net/libertine/+bug/1566487\nhope this can help\n", "Q: wlan0 interface informations available in linux I want all the information regarding wlan0 interface, like Mac Address, Received packet, Received bytes, Transmitted Packet, Transmitted bytes, Speed of transmission, etc..\nWhere can I find these details from Linux file system.\nI am using Ubuntu 14.04\n\nA: You can run:\nifconfig wlan0 for information like ip, mac, packets and bytes transmitted\niwconfig wlan0 for transmission speed, link quality, signal level, etc.\n", "Q: cannot define phpversion I installed LAMP on my Ubuntu 14.04. Then , I want to upgrade my php version. \nI checked my PHP version : \n php -v\nPHP 7.0.5-3+donate.sury.org~trusty+1 (cli) ( NTS )\nCopyright (c) 1997-2016 The PHP Group\nZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies\n    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2016, by Zend Technologies\nenter code here\n\nThen I want to create one script file . \nI use this :\nsudo nano /var/www/html/info.php\n\nInfor.php:\n<?php\nphpinfo();\n?>\n\nAnd I save it . after go to localhost/info, I see this:\n\nHow to solve it?\n\nA: run sudo apt-get install libapache2-mod-php7.0\n", "Q: Can one change the output path of cups pdf printer dynamically One can call lpr to use cups-pdf printer to print a file to pdf, for instance foo.txt\nlpr -P PDF foo.txt\n\nWhen calling, the printer creates a directory called PDF in the $HOME directory and creates a file named foo.pdf.\nThis manual shows how to change the printers default directory. I'm wondering whether it is possible however to pass an option to the pdf printer that sets the output path specifically. Something like:\nlpr -P PDF foo.txt -o bar.pdf\n\nSuch that only for this one call, the output path is bar.pdf.\nIs this possible?\n\nA: cups-pdf is not an extension to cups. All it does is provide a virtual printer which prints PDF files instead of physical sheets of paper. Since every printer has a single output tray where you collect your printed sheets, cups-pdf has the default output directory, hence there is no way to mention command line options to lpr to print to a different location. \nFor all the configurations in cups-pdf, refer official documentation.\n", "Q: Opening HiSuite daemon on Huawei phone I am trying to communicate my android Huawei Y330 to 'HiSuite' that runs under 'Wine'. Someone had suggested to first connect the Huawei Y330 to 'HiSuite' run under 'Windows'. Thus the 'HiSuite daemon', as he called it, would be installed on the phone.\nI quote: \n\"First I installed wine. Then I downloaded HiSuite (Huawei's official PC suite) Link to download page and installed it.\nThen I had to connect my phone to a windows PC, so the HiSuite daemon was installed on the phone.\nWhen that is done, just open the HiSuite daemon on the phone and choose connect with wiFi. Enter the code on HiSuite on the PC, and voila. Now the phone is connected to ubuntu :)\"\nI have done this and could not find any 'HiSuite daemon' on my phone to open.\nAny suggestions?\n\nA: Installing this drivers solve it for me\nhttps://github.com/siddht4/Huwaei_linux_drivers\n", "Q: Problem to compile python and C++ code using ubuntu Ubuntu 12.04.5 LTS: problem with gcc I am trying to compile a code involving python and C++  in Ubuntu 12.04.5 LTS and I have this type of error \nhammouc@kw13921:~/Documents/mimclib$ make\npython setup.py clean\nrunning clean\nremoving 'build/temp.linux-x86_64-2.7' (and everything under it)\nremoving 'build'\nrm -f -r build dist mimclib.egg-info\nrm -f -r /home/hammouc/.local/lib/python2.7/site-packages/mimclib*\npython setup.py build_ext --inplace\nrunning build_ext\nbuilding 'mimclib.libset_util' extension\ncreating build\ncreating build/temp.linux-x86_64-2.7\ncreating build/temp.linux-x86_64-2.7/mimclib\ncreating build/temp.linux-x86_64-2.7/mimclib/libsetutil\ncreating build/temp.linux-x86_64-2.7/mimclib/libsetutil/src\ngcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fPIC -I -I/usr/include/python2.7 -c mimclib/libsetutil/src/set_util.cpp -o build/temp.linux-x86_64-2.7/mimclib/libsetutil/src/set_util.o -std=c++11\ncc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for Ada/C/ObjC but not for C++ [enabled by default]\ncc1plus: error: unrecognized command line option ‘-std=c++11’\nerror: command 'gcc' failed with exit status 1\nmake: *** [inplace] Error 1\n\nCould anyone help since I am not so familiar with ubuntu. Thanks.\n\nA: You can upgrade your compiler, or just modify the setup.py file.\nFind the following line:\nextra_compile_args=['-std=c++11'])],\n\nAnd change the flag into -std=c++0x, which makes it:\nextra_compile_args=['-std=c++0x'])],\n\nAnd run it again, it should work with this. (Tested with the mimclib source code on github)\n\nA: You need at least gcc 4.8 to compile this. See How to install gcc-4.8 for how you can install it on Ubuntu 12.04.\n", "Q: I can't see install Ubuntu alongside windows 10 When i try installing Ubuntu alongside Windows, I see only 2 options: One is to erase all data and install Ubuntu, and the other one is \"Something else\". I can't see an option to install alongside Windows 10.\n\nA: I have this same issue, but there is a way to do it.\nI choose \"something else\" and manually set up the partitions and mount points, making sure I do not remove windows (If there is no free space, shrink your windows partition but it is important to note that there are some safe practices before shrinking a windows partition! Firstly Disable Hibernation File then Disable the Page File re-enable them AFTER shrinking!) \nAfter I install Ubuntu, I am not able to boot into windows (Which is okay, there's a fix for that!) \nI sign in, and run Boot Repair and then it works fine.\nThis only happens for me on some systems, on one system it only happened when I did not shrink my windows partition to allow space for Ubuntu first.\nGood luck! \n", "Q: Does Ubuntu 16.04 support hybrid graphics cards (bumblebee) Does Ubuntu 16.04 support hybrid graphics cards?\nI ask because of the support of ubuntu snappy core in Ubuntu 16.04.\nI use bumblebee to start, for example a game, in better graphics quality.\n(optirun ./start.sh)\nLink to bumblebee\nDoes that work with Ubuntu 16.04?\n\nA: Still nothing on the vsync problem. We'll need kernel 4.5, xorg patch (1.19) and nvidia patch.\nYou can follow up the thread here.\nhttps://devtalk.nvidia.com/default/topic/775691/linux/vsync-issue-nvidia-prime-ux32vd-with-gt620-m-/3\n\nA: The bumblebee version in the repos and the default nvidia-361 driver do not work.  You either have to install an older nvidia driver and manually edit multiple config files or install bumblebee and nvidia drivers from ppa's and  also manually edit files.  The alternative is to use nvidia-prime to switch graphics drivers but this requires that you log out each time.  Bumblebee works out of the box in several other distros  so its disappointing to have to jump through so many hoops to get it working in a major distro like ubuntu.\n\nA: I got it working after some trying (nvidia-364, from ubuntu graphics ppa).\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\n\nsudo apt-get install nvidia-364\n\nsudo apt-get install bumblebee bumblebee-nvidia primus linux-headers-generic\n\nsudo systemctl enable bumblebeed\n\nAfter that sudo gedit /etc/modules\nand add 2 lines:\ni915\nbbswitch\n\nthen\nsudo prime-select intel\n\nsudo gedit /etc/bumblebee/bumblebee.conf\n\nin line 22: Driver=nvidia\nMake sure to change lines change every nvidia-current to nvidia-364 (or whatever version you have).\nAfter that, you can safely reboot your computer.\n\nA: Bumblebee had no development since 2013 and is deprecated in 16.04, installation of nvidia-361 and nvidia-prime should take care of the bumblebee functionality. pilot6 gave the usage details here.\nDon't let the \"it's broken\" comment influence you. There were lots of improvements in the meantime. \n\nA: There are various ways to enable the Optimus technique. Bumblebee is just one of the solution for some supported computers. See this question with a link to the official Ubuntu wiki page. If you prefer to use Bumblebee, I suggest to wait for the Version 4.0 to come (soon) to avoid NVidia driver compatibility problems. Hope this helps.\n\nA: Yes, it’s supported. As Huba Buba pointed out, they are some issues that should be solved in the coming 4.0 version of Bumblebee. A pre-version is available through our testing PPA, if you test it please take a look at https://github.com/Bumblebee-Project/Bumblebee/issues/749, 759 and 761. Report your results here to tell us whether you still need editing of the bumblebee.conf file.\nAlso, note that the prime-select command (and thus installation of nvidia-prime) are not needed at all. And while you can install both, making both work together is a bit more complicated.\n", "Q: Can't change Theme or Icons in Xubuntu 14.04 As said by another user in a similar post, I can't change the set of fonts, icons etc. in Settings/Appearance. I can reach the menu, but the window then freezes for a bit and shuts down after a few seconds. Trying to reach the same window via terminal with \"xfce4-appeareance-settings\" doesn't solve the issue.\nVia terminal, I get this error message:\n\n(xfce4-appearance-settings:4909): GLib-ERROR **:\n  /build/buildd/glib2.0-2.40.2/./glib/gmem.c:133: failed to allocate\n  4136 bytes Rilevato trace/breakpoint (core dump creato)\n\nIf it can be of any help, I'm using an Asus EEE Pc 1015-CX.\nAny ideas? Thanks in advance!\n\nA: If you haven't tried here already, you can change settings in the Settings Editor, xfce4-settings-editor. Appearance settings are under the section xsettings. \nThemes\nYou can see your themes by pasting the following in terminal: \nls /usr/share/themes/\n\nTo change a theme you can run something like the following. Just put in the name you like. If it is two words wrap it in quotes.\nxfconf-query -c xsettings -p /Net/ThemeName -s Greybird\n\nIcons\nTo view icons: \nls /usr/share/icons/\n\nTo change icons:\nxfconf-query -c xsettings -p /Net/IconThemeName -s Tango\n\nFonts\nTo view fonts (sorry I don't have a better option here):\nfc-list\n\nTo set fonts:\nxfconf-query -c xsettings -p /Gtk/FontName -s \"DejaVu Sans 10\"\n\nI wish I knew how to fix the actual issue, but I hope this will help a little.\n", "Q: Combine partitions in GParted after removing Windows from dual boot Hello guys!\nI've just removed Windows 10 from my PC so now I am only with Ubuntu (Elementary OS).\nEverything is working just fine, but now I want to expand my Linux partition to take all the space on the HDD. I am using GParted, but\n\nI want to combine /dev/sda6 with the \"new partition\", please help me.\nThanks in advance! :)\n\nA: You don't combine partitions, you delete the old windows partition and grow the linux partition via GParted to claim all unused space. In your case, if you made a new partition to start clean, just delete it again.\nMake sure that there is no data to salvage from it before the delete.\nAfter this, you can grow the linux partition via GParted, but not if it is mounted. So you need to boot from a live install medium with GParted (latest Ubuntu install works fine) to accomplish this.\n", "Q: Apt-get installation broken after cleanup linux-image-extra-3.13.0-74 I'm having the following issue, yesterday I ran apt-get update, upgrade and then autoremove and now I get errors for anything I try to run regarding apt-get\napt-get purge  linux-image-extra-3.13.0-74-generic\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following packages were automatically installed and are no longer required:\n  linux-headers-3.13.0-77 linux-headers-3.13.0-77-generic\n  linux-image-3.13.0-77-generic linux-image-extra-3.13.0-77-generic\nUse 'apt-get autoremove' to remove them.\nThe following packages will be REMOVED:\n  linux-image-extra-3.13.0-74-generic\n0 upgraded, 0 newly installed, 1 to remove and 29 not upgraded.\n1 not fully installed or removed.\nAfter this operation, 152 MB disk space will be freed.\nDo you want to continue? [Y/n] Y\ndpkg: warning: files list file for package 'nvidia-304' missing; assuming package has no files currently installed\n(Reading database ... 846891 files and directories currently installed.)\nRemoving linux-image-extra-3.13.0-74-generic (3.13.0-74.118) ...\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 30: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: all:: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 31: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: install:: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 38: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: MODULE_NAME: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 39: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: VERSION_HEADER: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 46: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: CORE_OBJS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 47: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: patsubst: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 47: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: RESMAN_GLUE_OBJS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 49: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: MODULE_NAME: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 49: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: CORE_OBJS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 49: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: RESMAN_GLUE_OBJS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 49: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: -objs: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 56: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: KERNEL_GLUE_NAME: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 57: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: RESMAN_GLUE_OBJS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 57: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: MODULE_NAME: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 57: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: KERNEL_GLUE_OBJS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 59: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: MODULE_NAME: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 59: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: obj-m: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 66: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: src: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 66: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: EXTRA_CFLAGS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 67: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: DEFINES: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 67: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: INCLUDES: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 67: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: EXTRA_CFLAGS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 74: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: src: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 75: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: obj: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 83: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: shell: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 83: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: KERNEL_MODLIB: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 85: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: ifdef: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 86: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: SYSSRC: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 86: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: KERNEL_SOURCES: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 87: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: KERNEL_SOURCES: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 87: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: KERNEL_HEADERS: not found\n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: 88: /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm: Syntax error: \"else\" unexpected\ndpkg: error processing package linux-image-extra-3.13.0-74-generic (--remove):\n subprocess installed post-removal script returned error exit status 2\nErrors were encountered while processing:\n linux-image-extra-3.13.0-74-generic\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n\nA: I got it working with the renaming of the file /var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm to \n/var/lib/dpkg/info/linux-image-extra-3.13.0-74-generic.postrm_\nNow i can run again apt-get i still need to see about the nvidia error \n", "Q: Downloading packages from Ubuntu local package mirror during Ubuntu 14.04LTS server installation During Ubuntu 14.04LTS server installation using MAAS, some packages are downloaded from Ubuntu mirrors.\nIs there a way of installing Ubuntu using MAAS in an environment without internet connection i.e; instead of packages being downloaded from the internet, they are to be downloaded from a local mirror?\n\nA: You should be able to find the recenly installed packages in your local cache:\n/var/cache/apt/archive\nyou can backup them from there in a directory and use \ndpkg -i PACKAGENAME.deb\nto install them.\n\nA: That's should be pretty easy. There's a setting in MAAS for that.\nTake a look at http://your-maas-server/MAAS/settings Ubuntu section. I guess „Main archive (required)“ field is just what you are looking for. (Of course I presume that you already have local mirror in your internal network).\nI have an access to MAAS 2.0 at the moment, but 1.9 had the same setting too.\n", "Q: bash shell output history file location Where does the bash shell store the actual terminal session? I want to read the output of commands I used before. All I can find googling is how to store the output of a command.\nSince output is displayed on the screen, it has to be stored somewhere anyway. So my question is: where?\n\nA: There are lots of questions related to this one, but they all start with the (right) assumption that the output isn't logged.\n\nSo my question is: where?\n\nNowhere: Bash's (and any other shell that I know of's) output isn't logged.\n\nSince output is displayed on the screen, it has to be stored somewhere anyway.\n\nIt is, but most likely not in plain text and not even on the disk (although this really is up to the terminal emulator): most likely, and at least in most cases, in a memory segment allocated by the terminal emulator.\nHowever for sure it isn't logged to a file, at least not by the shell, and I don't know of terminal emulators which log the output to a file by default.\nIndeed this doesn't mean it's impossible to log the terminal output: first I'll mention something that I think not many are aware of, since I've never saw anyone mentioning this at least here on Ask Ubuntu: Konsole allows to save the scrollback to a file (perhaps there are other terminal emulators that provide such a functionality, Konsole is just the only one I know of), although this is limited by Konsole's scrollback size limit.\nThis is often not really useful though, and most likely you'll want to look into \"proper\" solutions to log a whole session's output to a file (How do I log all input and output in a terminal session? and Ron's answer).\n\nA: Bash only stores history of the commands you ran (which you can retrieve by typing history). Unless you already have set the scroll-back to a very high number, there is no way to see the outputs that are older than the set value of scroll-back. Also setting this value to a very high number will make your scrolling sluggish since the lines are stored in the memory.\nTo store your future commands and their outputs, there are few options:\nUsing screen\nStart a screen session by entering screen. Once you are inside screen, press Ctrl-a, then :, then enter log. All the I/O will be captured in screenlog files in the directory where you started the screen command.\nUsing script\nYou can start by typing script. A script session will start that will capture all the I/O to a file named typescript. You can exit the script session by Ctrl-d  and view the logs in the typescript file.\nUsing tee\ntee is a handy tool. You can do something like this:\n$ bash | tee log.txt\n\nThis will open a new bash shell inside the one you are already running. When you exit out of this, you can see the outputs in the file called log.txt\nOther ways\nAs Dustin Kirkland suggested in this post, you can also use byobu. Although, I have never used, terminal screencasting tools such as Shelr also sounds like an option.\n\nA: There is a command named as script , if not installed then apt-get install script would do it. \nThen in terminal just type script.  \nand do what ever you want , after you are done just type exit and then there will be a file created at your current directory with all stdout and stdin information. \nhope it helps you. \n\nA: This has nothing to do with your shell (bash), it isn a feature of the terminal emulator you are using. It is stored in your terminal's \"scrollback buffer\". I haven't been able to find any clear explanations of where exactly this is stored, but personal experience has shown me that it is stored somewhere in /tmp. \nAs the answer of the question linked to above suggests, it is most likely stored in a nameless file. To see what I mean, open a new file with a text editor:\ngedit newfile\n\nWrite a line of text to the file and save it. Now, while that file is still open, open a terminal and delete it:\nrm newfile\n\nSince you still have the file open in gedit, you can continue writing to it. You could even write several gigabytes of data into it, despite the fact that the file has been deleted. That's because deleting a file simply removes the link pointing to its inode. If its file descriptor is held open by another program, data can be written to it, despitre the fact that there is no longer an actual link (file) corresponding to the file descriptor on the file system.\nAll this is to say that your terminal's history is probably saved using a trick like that, somewhere in a deleted file in /tmp. What you probably actually want is to simply increase the scrollback buffer size of youre terminal emulator so you can just scroll up and see it. The details of how to do this depend ont he terminal emulator you are using. Most have a command line switch that lets yous et this and many also have a GUI way of setting it. For example, in gnome-terminal (the default on Ubuntu) it's Edit -> Preferences -> Profiles --- click on your profile --> Edit -> Scrolling -> Limit scrollback to NNN:\n\n\nA: Terminal session is stored in .bash_history file. Enter this in your terminal echo $HISTFILE, this would give you the path of .bash_history file.\n", "Q: How can I hide the Task sidebar in Evolution calendar? I would like to hide the taskbar on the right shown in Evolution Calendar.\n\n\nA: You simply have to drag the window divider over to the right while the Evolution window is not maximised:\n\nThis setting will be retained on restart. Oddly enough to revert these changes you can only easily drag the window open when Evolution is maximized, although I suspect that this is a 'feature' of the Unity Desktop's handling of scroll bars and I have found that with a steady hand this can be circumvented: \n\nCurious...\n\nA: Using Evolution 3.44.3, this option now seems to be available under View → Layout → Show Tasks and Memos pane.\n\n", "Q: Allow only network connections but not connect to internet I can do this by going to the network manager\nedit connections > myconn > ipv4 > routes\nand check\n\"use this connection only for resources on its network\"\nall this without inputing my sudoer password, how can I do the same in command line mode? without sudo if possible! thank you.\n\nA: You can use the ip command for setting up routes. You basically need to remove your default route. At make sure you have a route entry into your local network.\n\nA: I managed to do it but I had to use sudo, it would be nice to know how the Ubuntu GUI does it without prompting for a password.\nFor example if my network IP is 192.168.1.101 by doing:\nsudo ip route delete default\n\nI can access to 192.168.1.0/24 network\nIf I want to enable \"internet\" again, being my router 192.168.1.1 I just do:\nsudo ip route add default via 192.168.1.1\n\n", "Q: Monitor not idling after i3wm installation Yesterday I installed i3wm and noticed that after the screensaver turns on, the screens turns black, but the monitors stay on (have two of them). \nUp to now I was using Unity and the session locked and turned the monitors off after a set amount of time of idling. \nWhat do I need to do to make them behave like this again?\nthis is what happens when using gnome-screensaver-command -l\nHere's the output of xset q:\nKeyboard Control:\n  auto repeat:  on    key click percent:  0    LED mask:  00000000\n  XKB indicators:\n    00: Caps Lock:   off    01: Num Lock:    off    02: Scroll Lock: off\n    03: Compose:     off    04: Kana:        off    05: Sleep:       off\n    06: Suspend:     off    07: Mute:        off    08: Misc:        off\n    09: Mail:        off    10: Charging:    off    11: Shift Lock:  off\n    12: Group 2:     off    13: Mouse Keys:  off\n  auto repeat delay:  660    repeat rate:  25\n  auto repeating keys:  00ffffffdffffbbf\n                        fadfffefffedffff\n                        9fffffffffffffff\n                        fff7ffffffffffff\n  bell percent:  50    bell pitch:  400    bell duration:  100\nPointer Control:\n  acceleration:  2/1    threshold:  4\nScreen Saver:\n  prefer blanking:  yes    allow exposures:  yes\n  timeout:  600    cycle:  600\nColors:\n  default colormap:  0x20    BlackPixel:  0x0    WhitePixel:  0xffffff\nFont Path:\n  /usr/share/fonts/X11/misc,/usr/share/fonts/X11/Type1,built-ins\nDPMS (Energy Star):\n  Standby: 0    Suspend: 0    Off: 0\n  DPMS is Enabled\n  Monitor is On\n\n\nA: The the timeout values for all power saving features (Standby, Suspend and Off) are set to 0, which disables them.\nYou can set the timeouts with the xset command:\nxset dpms [standby [suspend [off]]]\n\nWhere standby, suspend and off are the timeout values in seconds. For most modern displays there is (at least in my experience) no real difference between those modes. So if you set\nxset dpms 0 0 600\n\nit will turn off your display after 10 minutes of idling.\nYou can just add this as an exec configuration to your ~/.i3/config:\nexec --no-startup-id xset dpms 0 0 600\n\n\nIf you want to immediately turn of your screen, you can do so with\nxset dmps force off\n\n", "Q: Mobile Broadband not working on Dell Inspiron after upgrading to 15.10 I've just upgraded my Dell Inspiron from ubuntu trusty to xubuntu wily (I formatted and performed a clean install rather than a usual upgrade). All the other things are working as usual except the Mobile broadband (ppp0). Strange thing is that the dongle (Huawei) works normally when I run the live CD, but on my installation, the dongle connects, but I'm unable to browse the internet. Here is the syslog output when I make the connection on my Mobile Broadband:\nApr 19 16:01:32 phoenix NetworkManager[811]: <info>  devices added (path: /sys/devices/virtual/net/ppp0, iface: ppp0)\nApr 19 16:01:32 phoenix NetworkManager[811]: <info>  device added (path: /sys/devices/virtual/net/ppp0, iface: ppp0): no ifupdown configuration found.\nApr 19 16:01:32 phoenix NetworkManager[811]: nm-pppd-plugin-Message: nm-ppp-plugin: (get_credentials): passwd-hook, requesting credentials...\nApr 19 16:01:32 phoenix NetworkManager[811]: nm-pppd-plugin-Message: nm-ppp-plugin: (get_credentials): got credentials from NetworkManager\nApr 19 16:01:32 phoenix pppd[5970]: CHAP authentication succeeded\nApr 19 16:01:32 phoenix pppd[5970]: CHAP authentication succeeded\nApr 19 16:01:32 phoenix NetworkManager[811]: CHAP authentication succeeded\nApr 19 16:01:32 phoenix NetworkManager[811]: CHAP authentication succeeded\nApr 19 16:01:32 phoenix NetworkManager[811]: nm-pppd-plugin-Message: nm-ppp-plugin: (nm_phasechange): status 8 / phase 'network'\nApr 19 16:01:32 phoenix whoopsie[826]: [16:01:32] Cannot reach: https://daisy.ubuntu.com\nApr 19 16:01:32 phoenix whoopsie[826]: [16:01:32] Cannot reach: https://daisy.ubuntu.com\nApr 19 16:01:35 phoenix pppd[5970]: Could not determine remote IP address: defaulting to 10.64.64.64\nApr 19 16:01:35 phoenix NetworkManager[811]: Could not determine remote IP address: defaulting to 10.64.64.64\nApr 19 16:01:35 phoenix pppd[5970]: local  IP address 100.115.3.25\nApr 19 16:01:35 phoenix pppd[5970]: remote IP address 10.64.64.64\nApr 19 16:01:35 phoenix pppd[5970]: primary   DNS address 59.144.127.117\nApr 19 16:01:35 phoenix pppd[5970]: secondary DNS address 202.56.215.41\nApr 19 16:01:35 phoenix NetworkManager[811]: local  IP address 100.115.3.25\nApr 19 16:01:35 phoenix NetworkManager[811]: remote IP address 10.64.64.64\nApr 19 16:01:35 phoenix NetworkManager[811]: primary   DNS address 59.144.127.117\nApr 19 16:01:35 phoenix NetworkManager[811]: secondary DNS address 202.56.215.41\nApr 19 16:01:35 phoenix NetworkManager[811]: nm-pppd-plugin-Message: nm-ppp-plugin: (nm_phasechange): status 9 / phase 'running'\nApr 19 16:01:35 phoenix NetworkManager[811]: nm-pppd-plugin-Message: nm-ppp-plugin: (nm_ip_up): ip-up event\nApr 19 16:01:35 phoenix NetworkManager[811]: nm-pppd-plugin-Message: nm-ppp-plugin: (nm_ip_up): sending IPv4 config to NetworkManager...\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  keyfile: add connection in-memory (d3804110-9c70-456c-ac9b-7f760b90f34a,\"ppp0\")\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ppp0): device state change: unmanaged -> unavailable (reason 'connection-assumed') [10 20 41]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ppp0): device state change: unavailable -> disconnected (reason 'connection-assumed') [20 30 41]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  Device 'ppp0' has no connection; scheduling activate_check in 0 seconds.\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ppp0): Activation: starting connection 'ppp0' (d3804110-9c70-456c-ac9b-7f760b90f34a)\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  PPP manager (IPv4 Config Get) reply received.\nApr 19 16:01:35 phoenix whoopsie[826]: [16:01:35] Cannot reach: https://daisy.ubuntu.com\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ppp0): device state change: disconnected -> prepare (reason 'none') [30 40 0]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ttyUSB0): device state change: ip-config -> ip-check (reason 'none') [70 80 0]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ppp0): device state change: prepare -> config (reason 'none') [40 50 0]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ppp0): device state change: config -> ip-config (reason 'none') [50 70 0]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ttyUSB0): device state change: ip-check -> secondaries (reason 'none') [80 90 0]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ppp0): device state change: ip-config -> ip-check (reason 'none') [70 80 0]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ttyUSB0): device state change: secondaries -> activated (reason 'none') [90 100 0]\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  NetworkManager state is now CONNECTED_LOCAL\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  NetworkManager state is now CONNECTED_GLOBAL\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  Policy set 'Airtel Default' (ppp0) as default for IPv4 routing and DNS.\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  Writing DNS information to /sbin/resolvconf\nApr 19 16:01:35 phoenix dnsmasq[1477]: setting upstream servers from DBus\nApr 19 16:01:35 phoenix dnsmasq[1477]: using nameserver 59.144.127.117#53\nApr 19 16:01:35 phoenix dnsmasq[1477]: using nameserver 202.56.215.41#53\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ttyUSB0): Activation: successful, device activated.\nApr 19 16:01:35 phoenix nm-dispatcher: Dispatching action 'up' for ppp0\nApr 19 16:01:35 phoenix NetworkManager[811]: <info>  (ppp0): device state change: ip-check -> secondaries (reason 'none') [80 90 0]\nApr 19 16:01:35 phoenix whoopsie[826]: [16:01:35] The default IPv4 route is: /org/freedesktop/NetworkManager/ActiveConnection/24\nApr 19 16:01:35 phoenix whoopsie[826]: [16:01:35] Network connection may be a paid data plan: /org/freedesktop/NetworkManager/Devices/16\n\nOn line number 7, I can see CHAP authentication succeeded, but I don't understand what else could be wrong here. When I do a simple ping google.com, I get the Unknown host error and the following lines are printed in syslog:\nApr 19 16:02:02 phoenix pppd[5970]: IPV6CP: timeout sending Config-Requests\nApr 19 16:02:02 phoenix NetworkManager[811]: IPV6CP: timeout sending Config-Requests\n\nAny pointers would be helpful.\nedit\nSo far, the only workaround I've found is to reinstall network-manager. When I reinstall this package and then reconnect, I'm magically able to connect to the internet! But I'm looking for a proper solution to this rather than a workaround.\nedit 2\nLooks like a Bug report has already been filed by folks on Launchpad for this. I forgot to mention it in the question, but I also get this below error dialog when I try to edit my problematic Mobile Broadband connection:\nsettings/nm-settings-connection.c.995 - Connection didn't have requested setting 'ppp'\n\nedit 3\nAnother observation is that this bug seems to occur with only particular models of Huawei modems. For instance, it occurs with my Airtel dongle, but doesn't occur when I use the BSNL dongle. I also think this is linked with the interface naming. With Airtel, the connection interface is named as ppp0 whereas with BSNL, it is named as wwt692d89159469, so that might be useful for troubleshooting.\n\nA: I tried to find a fix to this almost everywhere on the internet including this site, ubuntuforums.org and launchpad.net.\nHaving done all that, I hereby conclude that there is no fix for this in 15.10 (as of 2016-05-29). The only way to resolve this is to upgrade yourself to 16.10. Indeed, I should not have dabbled with a non-LTS version in the first place considering that similar things have happened in past!\n", "Q: KVM size limit on total number of machines There's an upper limit on the total amount of disk space that I can assign to my VM's in KVM. Although my total partition has 200 gb, I'm not able to assign more than 20 gb to my machines - and this is not enough. The graphical virt-manager doesn't provide any guidance to this. How do I remove or change this upper limit on total VM size assigned to KVM?\n\nA: Problem identified: I have partitioned my disk into / and /home, and since the machines are located at /var/lib/libvirt/images they are at the smaller root partition.\nSolution: Move the images somewhere on the /home partition and create a symbolic link (ln -s).\n", "Q: ubuntu installation using preseed I'm trying to do the unattended ubuntu installation using preseed.cfg. I am following the instruction as in http://searchitchannel.techtarget.com/feature/Performing-an-automated-Ubuntu-install-using-preseeding\nin the boot option I'm passing the parameter as \nurl=http://path/to/localhost/preseed.cfg locale=en_US\nconsole-setup/ask_detect=false console-setup/layoutcode=us \nhostname=unassigned-hostname domain=unassigned-domain \ninitrd=/install/initrd.gz quiet --\n\nbut this returns an error /install/initrd.gz is not found.\nHence I changed the parameter to:\nurl=http://path/to/localhost/preseed.cfg initrd=/casper/initrd.gz\n\nthis prompts me an error initramfs error. Hence I updated the parameter to:\nurl=http://path/to/localhost/preseed.cfg boot=casper initrd=/casper/initrd.gz\n\nThis stops the auto installation at the language select. What is going wrong here?\n\n\nA: The debian-installer is used for only for Server & Alternative CD. As you can see in InstallCDCustomization\nThat reference is quiet old ~2010 and it is clear from screen-shot that it uses server image. AFAIK, Alternative image is not released any more for Ubuntu.\nLive uses ubiquity installer, check in UbiquityAutomation for available options.\n\nAvailable preseeding keys\nUbiquity uses a subset of the components that Ubuntu's version of\n  debian-installer uses and therefore asks the same questions for those\n  components. However, there are some additional questions provided.\n  These are as follows:\n  \n  \n*\n  \n*ubiquity/summary: preseed empty to avoid the summary page.\n  \n*ubiquity/reboot: automatically reboot when the installer completes. Be sure to add 'noprompt' to the kernel command line to\n  also skip the \"please remove the disc, close the tray (if any) and\n  press ENTER to continue\" usplash prompt.\n  \n*ubiquity/failure_command: specify a command to be run should the install fail.\n  \n*ubiquity/success_command: similar to preseed/late_command. Specify a command to be run when the install completes successfully (runs\n  outside of /target, but /target is mounted when the command is\n  invoked). \nFurthermore, there are a few other components necessary for an\n  automated installation with ubiquity:\n  \n  \n*\n  \n*languagechooser/language-name: choose among the available languages, eg English\n  \n*countrychooser/shortlist: choose a country, territory or area, eg US\n  \n*localechooser/supported-locales: choose other locales to be supported, eg en_US.UTF-8 \nPreseeding keys for the following installer components will not be\n  used in Ubiquity, usually because they do not fit with Ubiquity's mode\n  of operation:\nnetcfg\nLVM and RAID partitioning\nbase-installer\npkgsel/tasksel\nfinish-install \n\nYou can use preseed/early_command with the live CD; it will be run by\n  \"casper\" (the component which sets up a live environment at boot time)\n  from the initramfs. Please note that, if you want to affect files in\n  the live environment, this means that you must prefix their filenames\n  with /root.\n\n", "Q: Google-Earth will not launch and autometically quit i have install Google earth version 7.1.4 in Ubuntu 15.10,  when am  going to run this application it is automatically quit i have tried to remove it configuration file from \"~/.googleearth\" when i have remove this directory this is working 2 to 3 minute fine, after 2 to 3 minute it's showing same issue.  \n\nA: This happens to me also. I found the solution was to disable networking, and then launch Google Earth. After it launches, re-enable networking.\nI know, not the ultimate solution, but it works!\nAlso see: Google Earth stops immediately after startup\n", "Q: Kernel panic not syncing timeout synchronizing machine check over cpus We installed an Ubuntu Server 14.04.4 LTS to one of our customer's server. Server has large storage drives and software RAIDed SSD disks for OS.\nServer is crashing randomly. And we are getting error message of:\n\nKernel panic not syncing: Timeout synchronizing machine check over CPUs\n\n\nI suspect that machine has a bad hard drive or memory. But customer insists that machine is healthy.\n\nA: Generally that error indicates that a fatal machine check exception occurred and a timeout occurred while waiting for all the CPUs to become synchronized.  While it is hard to say what kind of machine check exception (MCE) occurred from this error message, normally it indicates some fatal hardware error (for example memory <-> CPU or mother board related).\n", "Q: upgrade disrupted & nautilus crash I was upgrading to 15.04 from the previous version. The upgrade was disrupted due to power problems.\nAfter I booted the system, Nautilus is not working, network button not showing up. mouse not working but keyboard buttons work.\nIs there a way to go back or forward now (internet not working though there is a connection)?\n\nA: run terminal window and execute as root or with sudo below command without quotes \"apt-get -f install\" or \"dpkg-reconfigure -a\". This usually solves problem with broken upgrade, and no, they will not eat your files :)\n", "Q: Kubuntu 14.04.4 LTS: mouse pointer disapeared I am running Kubuntu 14.04 LTS since years without this problem. But last week my mouse cursor did disappear while working with the system (when closing some windows and switching between virtual desktops). I did not find a way to bring the mouse cursor back without restarting X. Switching to console and back to X did not change anything. The mouse cursor still did work, but it was invisible.\nToday this happened again!? As I did not change the hardware, it seems that this issue was introduced with some of the last updates? \nDoes anybody have an idea how to bring the cursor back if it happens again?\n\nA: I had almost exactly the same problem when moved to kernel 4.5.1.\nAfter adding kernel parameters, it appeared again.\nYou could try to add these two parameters:\ni8042.nomux=1 i8042.reset\n\nto /etc/default/grub file to variable GRUB_CMDLINE_LINUX_DEFAULT\nRemove hash sign before that line to make effect.\nFinally, save file, and update grub with grub-update command. Run with sudo or as root user. Then reboot the machine. \n", "Q: Wireless not working with Intel Wireless PRO 3956ABG on Inspiron 1525 with 14.04 I installed Ubuntu 14.04 on my laptop, and I found that Camera, CD drive adn wireless cards are not working \n\nWireless card is displayed by running \"lspci\"\n0b:00.0 Network controller: Intel Corporation PRO/Wireless 3945ABG [Golan] Network Connection (rev 02)\n\nBelow is the output of ifconfig -a\n\neth0      Link encap:Ethernet  HWaddr 00:1d:09:50:5d:d5  \n          inet addr:192.168.0.4  Bcast:192.168.0.255  Mask:255.255.255.0\n          inet6 addr: fe80::21d:9ff:fe50:5dd5/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:92788 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:65830 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:107595122 (107.5 MB)  TX bytes:8124966 (8.1 MB)\n          Interrupt:16 \n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:3637 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:3637 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:352356 (352.3 KB)  TX bytes:352356 (352.3 KB)\n\nwlan0     Link encap:Ethernet  HWaddr 00:1f:3c:27:6d:7d  \n          BROADCAST MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nI could not see enable wifi option as it is grayed out.\nKindly suggest what settings I need to change, I am a first time linux user.\nThanks in advance.\n\nAlso I could see that it is disabled:\n*-network DISABLED\n       description: Wireless interface\n       product: PRO/Wireless 3945ABG [Golan] Network Connection\n       vendor: Intel Corporation\n       physical id: 0\n       bus info: pci@0000:0b:00.0\n       logical name: wlan0\n       version: 02\n       serial: 00:1f:3c:27:6d:7d\n       width: 32 bits\n       clock: 33MHz\n       capabilities: pm msi pciexpress bus_master cap_list ethernet physical wireless\n       configuration: broadcast=yes driver=iwl3945 driverversion=4.2.0-36-generic firmware=15.32.2.9 latency=0 link=no multicast=yes wireless=IEEE 802.11abg\n       resources: irq:29 memory:fe7ff000-fe7fffff\n\n\nA: Saying it's not working might mean thousands of reasons and things to check, but first of all, I would check whether it's a problem with config or missing device at all.\nTry to execute below two commands from Terminal, as sudo or root user - \"lspci\" and \"ifconfig -a\", both without quotes. If lspci doesn't list your card (read precisely every row to search for Intel or network or wifi strings), but ifconfig commands shows it, then you might have problems only with proper configuration for wifi (or parameters for wifi driver module)\n", "Q: PHP7 on ubuntu 12.04 I would like to upgrade our production php version to new php7. Unfortunately we are currently running on ubuntu 12.04. I have already tried to install php7 on corresponding virtual machine using ppa:ondrej/php repository. It results with:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package php7.0-fpm\nE: Couldn't find any package by regex 'php7.0-fpm'\n\nIs there a way to use new php7 features without upgrading our production environment? I am currently trying to compile it from source, but as I am not experienced with it I am not quite sure about its result.\nThank you in advance.\n\nA: PHP 7 is not available in the Ubuntu 12.04 (Precise) official repositories, but you may be able to add it from a PPA following a guide like this one from DigitalOcean (though the DO one is for 14.04, so you'll have to adapt it a bit).\nNotice that the Ubuntu Developers maintained PPA for PHP 7.0 is only available for Xenial and Yakkety.\n\nA: Looks like you missed apt-get update. When it runs, check whether it actually contacts launchpad for this PPA.\n", "Q: Saving work automatically when battery is low I am a writer and of course I sometimes lose my work if the battery goes dead. I am looking for suggestions for ways to save when the battery gets to 5% or 1%.  Maybe a bash command written to save text and Libra documents at a certain percentage of battery? Thanks!\n\nA: I can think of two easy methods for this\n1) Pay attention to battery percentage?\n2) Use Libre Office's autosave feature. The screenshot below shows the setting's location the options menu:\n\n\nA: A script in Python:\n#!/usr/bin/env python\n\nimport subprocess\n\napps_to_save = ['Gedit', 'Writer']\n\nbattery_limit = 10  # in percent\n\ndef get_battery_percentage():\n\n    percentage, err = subprocess.Popen([r'upower -i $(upower -e | grep BAT) | grep --color=never -E percentage | xargs | cut -d ' ' -f2 | sed s/%//\n'], shell=True, stdout=subprocess.PIPE).communicate()\n\n    return(int(percentage))\n\nwhile True:\n\n    if get_battery_percentage() <= battery_limit:\n\n        for app in apps_to_save:\n\n            app_window_ids = subprocess.Popen(['xdotool', 'search', '--class', app],\n            stdout=subprocess.PIPE)\n\n            out, err = app_window_ids.communicate()\n\n            for app_window_id in out.splitlines():\n\n                subprocess.Popen(['xdotool', 'windowactivate', app_window_id,\n                ';', 'xdotool', 'key', 'ctrl+s'], shell=True)\n\nBy default, it saves all Gedit and LibreOffice Writer windows when battery reaches 10%.\nYou can add things to the apps_to_save list by modifying that line like:\napps_to_save = ['Gedit', 'Writer', 'SomeOtherApp']\n\nAnd change the battery_limit to whatever percentage you want to save on. (But don't add a % sign - just the number)\nIt would also be trivial to change this into something that saves every ten minutes or so - no matter what battery percentage.\n", "Q: How can'i pass this \" openssh-client' has no installation candidate \" I am trying to use ssh command, but I have this: \nsudo ssh git-codecommit.us-east-1.amazonaws.com\n[sudo] password for dali: \nsudo: ssh: command not found\n\nSo when i am trying to install openssh-client, I have this : \ndali@dali-Lenovo-G50-70:~$ sudo apt-get install openssh-client\nLecture des listes de paquets... Fait\nConstruction de l'arbre des dépendances       \nLecture des informations d'état... Fait\nPackage openssh-client is not available, but is referred to by another package.\nThis may mean that the package is missing, has been obsoleted, or\nis only available from another source\n\nE: Package 'openssh-client' has no installation candidate\n\nsame as when I remove it and reinstall it.\n\nA: You just need to update your repo list and reinstall openssh-client again.\n$apt-get update\n$apt-get install openssh-client \n\n\nA: You didn't say which operating system version you use, so I would first try to search for it, giving different package names, like ssh, ssh AND client etc etc.\nOpen Terminal windows and try make few searches and check whether package description says about ssh/ssh client.\n\nsudo apt-cache search XXX\n\n...where XXX is one of the following: openssh, ssh, ssh-client\nIF it does, then install this package with:\n\nsudo apt-get install  _package_name_received_\n\nEventually, search for this file on disk, as you might have it stored in different location, and if found, use absolute path to this ssh file.\n\nsudo find / -name ssh -type f 2>/dev/null\n\n", "Q: Extend home without unallocated space. With swap or ntfs I've just installed (some months ago) Ubuntu 14.04 on my Asus laptop. I followed a specific guide on partitions and thought everything was ok. But, beeing pretty new at this I probably made some mistake doing my partitions and now I have a nice mess. \nI left 46.5 Gb for /, then 15 Gb for /home, and then 123 Gb for swap. It appears (have a look on the image of my gparted) that I also left 542 Gb for ntfs Data and 15 Gb for ntfs Restore (and don't really know if those need so much space). Also, I don't have any unallocated space and I don't know if this is good or really bad.\nMy question is: I don't have enough space in my /home partition (it is already 98% full) and I'd like to know how to extend it without any - apparently - unallocated space. Can I take some space from the swap or the NTFS partitions? How? I think I left them too much space.. \n\n\nA: It's barely possible what you want to achieve and not worth effort.\nIn your case, I would consider mounting NTFS partition in Linux, so that its content would be visible under some folder on linux, like /home//Desktop/NTFS.\nThis Ubuntu page might be valuable for you to read and follow:\nhttps://help.ubuntu.com/community/MountingWindowsPartitions\n", "Q: How to keep a local ~/bin folder up to date with updates from various Github repositories? ~/bin contains a number of scripts that I downloaded from various Github repositories for which the Ubuntu default repositories do not provide the latest version and/or PPAs do not exist.\nWhat are good ways to keep all these scripts automatically up to date and synchronised with the most recent versions from their respective Github repositories?\n\nA: Simple solution\nWhat you want to do essentially is to run git fetch && git pull from inside each one of the repository folders inside ~/bin. The simplest way is to add this command to Startup Applications:\nfind /home/user/bin  -type d -exec sh -c 'cd {} && git fetch && git pull' \\;  2> /dev/null\n\nNote, that /home/user/bin must be full path to your ~/bin folder. \n\nPython script\nBut if you want a dedicated utility to this task, here's a python script that updates everything in your ~/bin recursively.  Usage is simple - run it from terminal as python git_updater.py and it will take care of the rest. That same command can be even added as entry to Startup Applications to run the script each time you log in\nThe script source is below, and is also available on my GitHub repository.\n#!/usr/bin/env python3\n# Author: Serg Kolo\n# Date: 10/21/2016\n# Written for: https://askubuntu.com/q/759058/295286\nfrom __future__ import print_function\nimport subprocess\nimport os\n\ndef run_cmd(cmdlist,workdir):\n     \"\"\" utility: reusable function for \n         running external commands \"\"\"\n     new_env = dict(os.environ)\n     new_env['LC_ALL'] = 'C'\n     try:\n         stdout = subprocess.check_output(\n                    cmdlist, \n                    env=new_env,\n                    cwd=workdir\n         )\n     except subprocess.CalledProcessError:\n         pass\n     else:\n         if stdout:\n             return stdout\n\ndef is_behind(cwd):\n    \"\"\" simple wrapper for checking\n        git status output\n    \"\"\"\n    fetch = run_cmd(['git','fetch','origin','master'],cwd)\n    status = run_cmd(['git','status'],cwd)\n    if 'Your branch is behind' in status.decode():\n        return True\n\ndef update(cwd):\n    print('> previous commit:')\n    print(run_cmd(['git','--no-pager','log','-1'],cwd).decode())\n    print(run_cmd(['git','pull'],cwd).decode())\n    print('> latest commit:')\n    print(run_cmd(['git','--no-pager','log','-1'],cwd).decode())\n\ndef main():\n    root_dir = os.path.join(os.path.expanduser('~'),'bin/')\n    base_cmd = ['git','--no-pager']\n    first_args = ['status']\n    second_args = ['log','-1']\n    third_args = ['pull']\n\n    for root,dirs,files in os.walk(root_dir):\n        for dir in dirs:\n            top_dir = os.path.join(root,dir)\n            git_dir = os.path.join(top_dir,'.git')\n            if os.path.exists(git_dir):\n                print('WORKING REPOSITORY:' + top_dir)\n                if is_behind(top_dir):\n                    print('repository is behind, will update')\n                    update(top_dir)\n                else:\n                    print('not behind, skipped')\n                print('-'*80)\n\nif __name__ == '__main__': main()\n\n\nScript Demo\n$ python git_updater.py                                                       \nWORKING REPOSITORY:/home/xieerqi/bin/sergrep\nFrom https://github.com/SergKolo/sergrep\n * branch            master     -> FETCH_HEAD\nrepository is behind, will update\n> previous commit:\ncommit ba629ef71c4d2bfe329b8ebe5f48d1ce21e76ebc\nAuthor: SergKolo <1047481448@qq.com>\nDate:   Wed Aug 24 21:22:06 2016 -0600\n\n    fixed sending sigterm to process\n\nUpdating ba629ef..dd0c962\nFast-forward\n disable_super_key.py   |   2 +-\n git_updater.py         |  61 ++++++++++++\n launcherctl.py         | 162 +++++++++++++++++++++++++++++++\n single_window_expo.py  | 138 ++++++++++++++++++++++++++\n windowctrl.py          | 258 +++++++++++++++++++++++++++++++++++++++++++++++++\n xml_wallpaper_maker.py | 152 +++++++++++++++++++++++++++++\n 6 files changed, 772 insertions(+), 1 deletion(-)\n create mode 100644 git_updater.py\n create mode 100755 launcherctl.py\n create mode 100755 single_window_expo.py\n create mode 100755 windowctrl.py\n create mode 100755 xml_wallpaper_maker.py\n\n> latest commit:\ncommit dd0c9627392540df7c4230e7898cb9e55adc7083\nAuthor: SergKolo <1047481448@qq.com>\nDate:   Fri Oct 21 02:37:01 2016 -0600\n\n    git updater script\n\n--------------------------------------------------------------------------------\nWORKING REPOSITORY:/home/xieerqi/bin/PythonStuff\nFrom https://github.com/mnovits1/PythonStuff\n * branch            master     -> FETCH_HEAD\nnot behind, skipped\n--------------------------------------------------------------------------------\n\n", "Q: Bash Automation without asking for password How do I automate this without being ask for password every time it loops?\n#!/bin/sh\nfor k in 2 3 5 10; do\n    sudo ldconfig ########  # password asking here everytime\n    python experiments.py \ndone\n\n\nA: Run your script as sudo: sudo ./script\n", "Q: Getting an error when I do sudo apt-get upgrade Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nCalculating upgrade... The following packages were automatically installed and are no longer required:\n  libntdb1 linux-image-generic-lts-vivid linux-signed-image-generic-lts-vivid python-ntdb thermald\nUse 'apt-get autoremove' to remove them.\nDone\nThe following packages have been kept back:\n  libgbm1 xorg\n0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n1 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nDo you want to continue? [Y/n] y\nSetting up oem-wireless-dw1550-1160187-dkms (6.30.223.64somerville1) ...\nRemoving old oem-wireless-dw1550-1160187-6.30.223.64somerville1 DKMS files...\n\n------------------------------\nDeleting module version: 6.30.223.64somerville1\ncompletely from the DKMS tree.\n------------------------------\nDone.\nLoading new oem-wireless-dw1550-1160187-6.30.223.64somerville1 DKMS files...\nFirst Installation: checking all kernels...\nBuilding only for 3.19.0-49-generic\nBuilding for architecture x86_64\nBuilding initial module for 3.19.0-49-generic\nERROR: Cannot create report: [Errno 17] File exists: '/var/crash/oem-wireless-dw1550-1160187-dkms.0.crash'\nError! Bad return status for module build on kernel: 3.19.0-49-generic (x86_64)\nConsult /var/lib/dkms/oem-wireless-dw1550-1160187/6.30.223.64somerville1/build/make.log for more information.\ndpkg: error processing package oem-wireless-dw1550-1160187-dkms (--configure):\n subprocess installed post-installation script returned error exit status 10\nErrors were encountered while processing:\n oem-wireless-dw1550-1160187-dkms\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n\nA: You have some old kernel(s) from a previous Ubuntu release installed that cause(s) compatibility issues when DKMS tries to compile kernel modules for it. You should delete them.\nStart with\nsudo apt-get purge -f 'linux-*-3.19*'\n\nand/or see How do I remove old kernel versions to clean up the boot menu?.\nApt may refuse to delete these packages because of unconfigured packages (because a kernel module couldn't be compiled for them). In that case please update your question with what you tried to do and any error messages encountered in the process and ping me in the comment section of this answer.\n\nA: Looks like a previous build crashed, I would remove the crash file (see path in the line below) and try another upgrade.\n\n[Errno 17] File exists: '/var/crash/oem-wireless-dw1550-1160187-dkms.0.crash'\n\nIf the build still crash, I would consult /var/lib/dkms/oem-wireless-dw1550-1160187/6.30.223.64somerville1/build/make.log to have more details.\n", "Q: Can't update/upgrade du to \"Could not execute 'apt-key' to verify signature\" I installed Ubuntu 16.04 last week on my server on a Digital Ocean droplet and since then I can't update nor upgrade anything on my server.\nMa version Linux 3.5.0-17-generic #28-Ubuntu SMP Tue Oct 9 19:31:23 UTC 2012 x86_64 x86_64 x86_64 GNU/Linux\nI get this error after a sudo apt-get update :\nGet:1 http://ppa.launchpad.net/ondrej/php/ubuntu xenial InRelease [23.9 kB]\nIgn:1 http://ppa.launchpad.net/ondrej/php/ubuntu xenial InRelease                                                                          \nHit:2 http://security.ubuntu.com/ubuntu xenial-security InRelease                                                                    \nGet:3 http://us.archive.ubuntu.com/ubuntu xenial InRelease [247 kB]                                       \nErr:2 http://security.ubuntu.com/ubuntu xenial-security InRelease\n  Could not execute 'apt-key' to verify signature (is gnupg installed?)\nErr:3 http://us.archive.ubuntu.com/ubuntu xenial InRelease     \n  Could not execute 'apt-key' to verify signature (is gnupg installed?)\nHit:7 http://us.archive.ubuntu.com/ubuntu xenial-updates InRelease\nErr:7 http://us.archive.ubuntu.com/ubuntu xenial-updates InRelease\n  Could not execute 'apt-key' to verify signature (is gnupg installed?)\nHit:8 http://us.archive.ubuntu.com/ubuntu xenial-backports InRelease\nErr:8 http://us.archive.ubuntu.com/ubuntu xenial-backports InRelease\n  Could not execute 'apt-key' to verify signature (is gnupg installed?)\nFetched 272 kB in 0s (363 kB/s)\nReading package lists... Done\nW: GPG error: http://ppa.launchpad.net/ondrej/php/ubuntu xenial         InRelease: Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: The repository 'http://ppa.launchpad.net/ondrej/php/ubuntu xenial InRelease' is not signed.\nN: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://security.ubuntu.com/ubuntu xenial-security InRelease: Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: GPG error: https://apt.dockerproject.org/repo ubuntu-xenial Release: Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: The repository 'https://apt.dockerproject.org/repo ubuntu-xenial Release' is not signed.\nN: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://us.archive.ubuntu.com/ubuntu xenial InRelease: Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://us.archive.ubuntu.com/ubuntu xenial-updates InRelease: Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://us.archive.ubuntu.com/ubuntu xenial-backports InRelease: Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: Failed to fetch http://us.archive.ubuntu.com/ubuntu/dists/xenial/InRelease  Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: Failed to fetch http://us.archive.ubuntu.com/ubuntu/dists/xenial-updates/InRelease  Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: Failed to fetch http://us.archive.ubuntu.com/ubuntu/dists/xenial-backports/InRelease  Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: Failed to fetch http://security.ubuntu.com/ubuntu/dists/xenial-security/InRelease  Could not execute 'apt-key' to verify signature (is gnupg installed?)\nW: Some index files failed to download. They have been ignored, or old ones used instead.\n\nI checked for apt-key which is there and working.\n\nA: I had the same problem on my Ubuntu droplet at Digital Ocean (after a distro upgrade).\nJust upgrade your kernel in the digital ocean administration site (yes, it's weird). There is a \"kernel\" option in the menu on the left side where you can select a new kernel image.\nIn my case the upgrade was from 3.x to 4.x series\n\nA: Changing the permission of /tmp back to their defaults worked for me:\nsudo chmod 1777 /tmp\n\n\nA: In my case I played with AppArmor and enabled complain mode on sshd. Disabling it by aa-disable /usr/sbin/sshd and re-connecting fixed my problem.\n\nA: I got this same problem and \"fixed it\" by downgrading to the version of apt present in 15.10.\nIn my case, I did the following:\nsudo add-apt-repository 'deb http://archive.ubuntu.com/ubuntu wily-updates main'\nsudo apt-get update # and ignore the errors\nsudo aptitude install apt=1.0.10.2ubuntu2\n\nAnd choose the less disruptive option. WARNING: Choosing a bad option might remove important packages from your system, proceed with caution.\nI chose the following option:\nThe following actions will resolve these dependencies:\n\n  Remove the following packages:                                                       \n1)      libapt-inst2.0                                                                     \n2)      libapt-pkg5.0                                                                      \n\n  Install the following packages:                                                      \n3)      libapt-inst1.7 [1.0.10.2ubuntu2 (wily-updates)]                                    \n\n  Downgrade the following packages:                                                    \n4)      apt-transport-https [1.2.10ubuntu1 (now, xenial) -> 1.0.10.2ubuntu2 (wily-updates)]\n5)      apt-utils [1.2.10ubuntu1 (now, xenial) -> 1.0.10.2ubuntu2 (wily-updates)]          \n6)      aptitude [0.7.4-2ubuntu2 (now, xenial) -> 0.7.3-1ubuntu1.1 (wily-updates)]         \n7)      aptitude-common [0.7.4-2ubuntu2 (now, xenial) -> 0.7.3-1ubuntu1.1 (wily-updates)]  \n8)      python-apt [1.1.0~beta1build1 (now, xenial) -> 1.0.1ubuntu0.1 (wily-updates)]      \n9)      python3-apt [1.1.0~beta1build1 (now, xenial) -> 1.0.1ubuntu0.1 (wily-updates)]     \n\n  Leave the following dependencies unresolved:                                         \n10)     libapt-pkg5.0 recommends apt (>= 1.2.10ubuntu1)                                    \n\n\nAccept this solution? [Y/n/q/?] Y\n\n", "Q: Enter password only once for shell script I have made a shell script to update & upgrade my existing packages all in one go. The script is:\n#!/bin/bash\nsudo apt-get update;\nsleep 10;\nsudo apt-get upgrade;\nsleep 10;\nsudo youtube-dl -U;\nsleep 10;\nsudo shutdown -h now;\nexit 0\n\nThe problem I am facing is that as my internet connection is not very fast, by the time it reaches to the third command, the password session expires and I have to re-enter my password. And for that I have to be infront of my PC the whole-time which actually defeats the purpose of the script.\nSo, my question is:\n\nIs there anyway by which I can store the password in a variable and on\n  every sudo the password is entered from the variable so that I don't\n  have to be near my computer the whole time? (or anything similar that\n  would do what I want)\n\nSomething like this:\n#!/bin/bash\nprintf \"Please enter your password: \";\nread -s password\nsudo apt-get update;\n$password\nsleep 10;\nsudo apt-get upgrade;\n$password\nsleep 10;\nsudo youtube-dl -U;\n$password\nsleep 10;\nsudo shutdown -h now;\n$password\nexit 0\n\n\nA: Remove the sudo from the commands in the script, and run the actual script as root, eg.\n#!/bin/bash\napt-get update;\nsleep 10;\napt-get upgrade;\nsleep 10;\nyoutube-dl -U;\nsleep 10;\nshutdown -h now;\nexit 0\n\nAnd run it with sudo ./my-script.sh\n\nA: This will allow you to put in the password once. For the apt-get commands, the following has the -y flag set \"Automatic yes to prompts\" for everything but dist-upgrade.  \nsudo bash -c \"apt-get -y update && apt-get dist-upgrade && youtube-dl -U && apt-get -y autoremove && apt-get -y autoclean && shutdown -h now\"\n\n", "Q: Ubuntu is fast at one moment, but slow at the other moment I am using Ubuntu 14.04 on my computer that acts as a server. Short pc spec list (lshw): http://pastebin.com/7ud6rpxX\nThe average number of procs is 500 (I have got a little widget that I forgot the name of on my desktop)\nThe server is running a GitLab server on it with a runner connected to it, but it isn't doing anything at the time of being slow. There is not really any connection to the things the server does on GitLab and the performance of the system. \nThe one moment it's fast, the other it's slow.\nCan't find out why, also the booting is very very slow (the terminal kind of bootdetails list is progressing very slow and takes it's time)\nShould I disable the visual effects? \nThanks,\nTim\nEDIT: I haven't found anything that uses my cpu above 2,5% and my memory above 8%. Could it be the GPU giving up?\nEDIT: Here is the second bootchart image:\nHIGH RES\nEDIT: This is the bootchart with the ureadahead pack file removed:\nHIGH RES with pack file removed\n\n\nA: At first you have to know what is causing this slows. You can monitor if your cpu is not excessive loaded:     \nwatch \"ps aux --sort -pcpu | head -11\"\n\nThis will monitor every default 2s top 10 consuming cpu processes.\nYou can send it to log file for further investigation with a little tee help:\nwatch \"ps aux --sort -pcpu | head -11 | tee -a logfile\"\n\nIn the same way you can monitor memory usage    \nwatch \"ps aux --sort -rss | head -11\"\n\nFor slow booting problems. You can install bootchart\nsudo apt-get install bootchart\n\nreboot your system and analyse chart which should be placed in /var/log/bootchart. It should tell you what causes slow boot. After all you can disable bootchart service with:\nsudo tee -a /etc/init/bootchart.override <<< manual\n\n\nYou can also use tools like top for process monitoring and iotop for I/O operations and check logs /var/log/syslog,/var/log/kern.log, /var/log/boot.log for \"suspicious\" entries\n", "Q: string \"if\" statement comparing is string empty I have problem checking if string is empty. \nI get first column of ls -l info and try to grep string searching for \"x\". If string is empty, I should countinue. But whenver string is empty or not, I still get my exit code 0 for this if statement. \nIf I the use command ls -l $1 | awk '{print $1}', I get -rw-r--r--\nand when I grep it, I get an empty string.\n#!/bin/sh\n\ntest= ` ls -l $1 | awk '{print $1}' | grep x ` ;\nif [ -n $test ];\necho \"file is not executable\";\n\nNotes:\n\n\n*\n\n*script is used for academic purposes to get code working without [ -x file ] option. \n\n*script is written in shell not bash.\n\n*If you are too lazy to scroll down there is fixed code fragment:\n  #!/bin/sh\n  PartOfString=` file $1 | awk '{print $2}' `;\n  if [ $PartOfString == executable ];\n  then\n  echo \"file is executable\";\n  else\n  echo \"file is not executable or its not file\";\n  fi\n\n\nA: The code you are using has a few issues:\n\n\n*\n\n*It is not recommended to parse ls, but let's keep it for now since it has nothing to do with your problem.\n\n*Using `` to execute your commands works, but is old style and should be replaced wit $(). Not very important here, but maybe worth mentioning for the future.\n\n*Your if-construct has the wrong syntax. It is missing a then and a fi.\n\n*The way you are using -n is wrong. -n tests if a string is not empty.\n\n\nHere is an improved version:\n#!/bin/sh                                       \n\ntestString=$(ls -l $1 | awk '{print $1}' | grep x)\nif [ -n \"$testString\" ]\nthen\n    echo \"file is executable\"\nelse\n    echo \"file is not executable\"\nfi\n\n\nThe question is about string manipulation and uses the executable flag only as example, but I still want to mention the recommended way to check if a file is executable:\n#!/bin/bash\nfile=\"$1\"\n\nif [[ -x \"$file\" ]]\nthen\n    echo \"File '$file' is executable\"\nelse\n    echo \"File '$file' is not executable or found\"\nfi\n\n\nA: It's unnecessary to use ls and awk for testing if file is executable , use -x flag with test\n  [ -x $1 ] && echo executable || echo not executable\n\n\nA: So I have finally found solution.\nnow code fragment looks like this:\n#!/bin/sh\n\ntest=` file $1 | awk '{print $2}' `;\nif [ $test == executable ];\nthen\necho \"file is executable\";\nelse\necho \"file is not executable or its not file\";\nfi\n\nnote that it's expected that first argument is the file you want to check. The idea of this code is to check if file is executable by not using -x option. If you looking for productive code and not for academic one, use Wayne_Yux method described before.\n", "Q: New tab Vs New window in terminal What is the difference between opening new tab of terminal in same window and opening new window of terminal?\nTaking in consideration \n\n\n*\n\n*user variable if x is defined in terminal and new tab is opened in this this terminal x is going to be passed automatically or not  in new tab \n\n*what about the application running it will be seen running in the same terminal or another pts ?\n\nA: Tabs and new windows don't differ a lot - they're all a new instance of an interactive shell.  There is a set of default variables which will show up in any instance of the shell : PS1 , USER, SHELL , etc. These are all documented in the bash manual , or whichever shell you use.\nIf you manually declare a variable in a window , it won't be visible to new tab or new window unless you use export keyword.  For example, export FOO=BAR will make variable FOO visible to all new tabs or windows. If you declare it as FOO=BAR  , it won't be visible.\n\nA: Nothing. In fact, you can drag a tab outside the window, and it will popup and become its own window.\n", "Q: How to tell git not to use rsa key but username + password I guess I messed with my ssh configuration. \nLately I cannot clone a local repository anymore. It seems like the git repository is accepting both publickey and password but instead of letting me choose one of the two options it tries to connect using some wrong RSA-key resulting in the message:\nReceived disconnect from myRemoteComputer : Too many authentication failures for myUsername\nfatal: Could not read from remote repository.\n\nSame happens when I ssh to that computer\n$ssh -v myRemoteComputerIP\ndebug1: Authentications that can continue: publickey,password\ndebug1: Next authentication method: publickey\ndebug1: Offering RSA public key: /home/myUsername/.ssh/id_rsa\ndebug1: Authentications that can continue: publickey,password\ndebug1: Offering RSA public key: myUsername@cvg04\nReceived disconnect from myRemoteComputerIP: Too many authentication failures for myUsername\n\nSo something is going wrong, since lately both commands were working. I would basically need to tell ssh and git to use username and password instead of randomly choosing a wrong \"RSA-key\". Does anyone know how to repair this?\nAlso I executed some ssh-add command lately following some forum advice but maybe it's part of the problem...\n\nA: Check your ~/.ssh/config. If you want to use password authentication, you can set it up just there like this:\nHost myRemoteComputerIP\n  PubkeyAuthentication no\n\nIt will never try public key authentication against this host.\n\n\nHow about when I have to connect with two different usernames once using a rsa key and an username / passwd authentification for the other?\n\nYou can use aliases in the ssh_config:\nHost alias1\n  Hostname myRemoteComputerIP\n  PubkeyAuthentication no\n  User user1\nHost alias2\n  Hostname myRemoteComputerIP\n  # PubkeyAuthentication yes # is default\n  User user2\n\nand then connect using ssh alias1 and ssh alias2.\n\nA: Clone using https and it will always ask for password. Example:\ngit clone https://github.com/my_company/myrepo.git\n\n", "Q: Installing Qt3 on Ubuntu 15.10 I wanted to try installing THELI (https://www.astro.uni-bonn.de/theli/) on my Ubuntu machine. In the installation notes it says that it needs qt3, and not qt4 or 5, for the GUI to work properly. I followed the instructions on the installations page and added:\n  deb http://debian.tryphon.eu jessie main contrib\n  deb-src http://debian.tryphon.eu jessie main contrib\n\nto my /etc/apt/sources.list, which works as it should. But now when I use:\nsudo apt-get install qt3-dev-tools\n\nI get the following error:\nThe following packages have unmet dependencies:\n qt3-dev-tools : Depends: libjpeg62-turbo (>= 1.3.1) but it is not installable\n                 Depends: libqt3-mt (>= 3:3.3.8b) but it is not going to be installed\n                 Recommends: libqt3-mt-dev but it is not going to be installed\nE: Unable to correct problems, you have held broken packages.\n\nSo what I took from that is, that libjpeg62-turbo was the problem here. After a little fiddling around I got apt to also install the libtools62-turbo which is an i386-Package (I think I got it working at least). After a new try of installing the qt3-dev-tools I still get the same error message, even though apt told me before that libjpeg62-tools was successfully installed.\nI also tried to build qt3 from source, but that didn't work as well because I got some kind of error during the make-phase.\nI would very much appreciate it if someone could help me figure out what I am doing wrong.\n\nA: Open a terminal and run this :\ngpg --keyserver pgpkeys.mit.edu --recv-key YOURKEY && gpg --export --armor YOURKEY | sudo apt-key add -\nIn your case:\ngpg --keyserver pgpkeys.mit.edu --recv-key D080CEF3C6ADBBD5 && gpg --export --armor D080CEF3C6ADBBD5 | sudo apt-key add -\nwould fix this problem.\n", "Q: Is there a way to redirect or forward just the www traffic from an ubuntu server to my website home page on another domain name? I have a website hosted on a particular place with a normal www.sitename.com.  I also purchased the .net version of the sitename and want to use it as an sftp only server.  The domain is from Google domains, and the sftp server is at digital ocean. I have the .net resolving and working perfectly with the sftp and it is just what I want, however even though we don't promote or publish the .net name I'm thinking that if I want to do this long term it would be nice if someone accidentally went to www.sitename.net, they would be re-directed to the .com website.  Is this possible, and if so how?\n\nA: The easiest way is to log into digital ocean .net domain and add the dns entry of the .com in the www field in the dns records.\n", "Q: MAAS 2.0. Importing custom images does not work? How should I import custom images to MAAS 2.0.0~beta2+bzr4920 in Ubuntu 16.04 LTS Beta2? \nThe command I successfully used in 1.9 is uploading an image without errors:\n$ maas local boot-resources create -d name=custom/foo architecture=amd64/generic filetype=tgz content@=/tmp/ubuntu1604-tgz\nThis image appears in MAAS > Images > Generated Images section, but I can't seem to find a way of deploying this image afterwards as only boot images from official http://images.maas.io/ appears in the OS to deploy drop list.\nBTW /tmp/ubuntu1604-tgz is a renamed copy of official Ubuntu 16.04 from /var/lib/maas/boot-resources/cache/, so I believe there shouldn't be any problems with the image itself and I'm just missing something out.\n$ dpkg -l | grep maas\nii  maas                               2.0.0~beta2+bzr4920-0ubuntu2    all          \"Metal as a Service\" is a physical cloud and IPAM\nii  maas-cli                           2.0.0~beta2+bzr4920-0ubuntu2    all          MAAS client and command-line interface\nii  maas-common                        2.0.0~beta2+bzr4920-0ubuntu2    all          MAAS server common files\nii  maas-dhcp                          2.0.0~beta2+bzr4920-0ubuntu2    all          MAAS DHCP server\nii  maas-dns                           2.0.0~beta2+bzr4920-0ubuntu2    all          MAAS DNS server\nii  maas-proxy                         2.0.0~beta2+bzr4920-0ubuntu2    all          MAAS Caching Proxy\nii  maas-rack-controller               2.0.0~beta2+bzr4920-0ubuntu2    all          Rack Controller for MAAS\nii  maas-region-api                    2.0.0~beta2+bzr4920-0ubuntu2    all          Region controller API service for MAAS\nii  maas-region-controller             2.0.0~beta2+bzr4920-0ubuntu2    all          Region Controller for MAAS\nii  python3-django-maas                2.0.0~beta2+bzr4920-0ubuntu2    all          MAAS server Django web framework (Python 3)\nii  python3-maas-client                2.0.0~beta2+bzr4920-0ubuntu2    all          MAAS python API client (Python 3)\nii  python3-maas-provisioningserver    2.0.0~beta2+bzr4920-0ubuntu2    all          MAAS server provisioning libraries (Python 3)\n\n$ lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 16.04 LTS\nRelease:    16.04\nCodename:   xenial\n\n\nA: OK, shame on me. I have forgot to run \nmaas local boot-resources import\n\nafter executing\nmaas local boot-resources create -d name=custom/foo architecture=amd64/generic filetype=tgz content@=/tmp/ubuntu1604-tgz  \n\nTook me a while to figure that out.\nSince MAAS documentation is rather poor when it comes to importing custom images, I think I'll write short guidelines how to do it.\nFirst you should know that naming is important. So if you want to import custom image, you should give an appropriate name parameter:\nmaas local boot-resources create name=custom/foo title=\"Title is not important\" architecture=amd64/generic content@=/path/to/your/image\nmaas local boot-resources import\n\nTake a close look at name=custom/foo. MAAS is expecting that custom image name starts with custom. There is no difference what you write after the slash, so name=custom/foo is as good as name=custom/bar123.\nIf you want to import CentOS image, naming is also important according to src/provisioningserver/drivers/osystem/centos.py. To import a custom image for CentOS 7.2, you should execute:\nmaas local boot-resources create -d name=centos/centos72 architecture=amd64/generic content@=/path/to/your/image\nmaas local boot-resources import\n\nYes, exactly. Name parameter should be name=centos/centos72 for CentOS 7.2, name=centos/centos67 for CentOS 6.7 and so on. That's how distro match regexp is implemented.\nHaven't tried importing custom SuSE and Windows images, but there should be naming restrictions too. Just take a look to MAAS sources in src/provisioningserver/drivers/osystem/.\n", "Q: 15.10: WiFi blocked/no resume after suspend/no bright hotkeys after upgrade I have a:\nSamsung Laptop model NP270E4E-K0ACL\nIntel Sandy Bridge Mobile Graphics Card\nAtheros AR9485 Wireless\n\nAfter a clean installation of Ubuntu 15.10 using an ISO burned image (kernel 4.2.0-16-generic), all system worked OK, no problems, no proprietary drivers required... all OK and ready to use. But after of sudo apt-get dist-upgrade after installation, I have four problems (upgraded to kernel 4.2.0-35-generic).\n\n\n*\n\n*WiFi is hard blocked, and it's impossible to enable (enable/disable hotkey is Fn+F12, no physical switch).\n\n*Resume after suspend doesn't work, black screen on resume.\n\n*Screen output control hotkey doesn't work (enable/disable hotkey is Fn+F4)\n\n*Bright screen controls doesn't work, I can change brightness with the Ubuntu Control Panel slider, but hotkeys doesn't work (Fn+F2 and Fn+F3)\n\n\nI tried every solution founded in Google: using rfkill, ifup wlan0, selecting in grub the previous kernel, uninstalling the new kernel, resetting BIOS/UEFI, changing WiFi internal minicard, external USB wifi adapter (WiFi works, if I remove the internal minicard), adding options in modules load, installing Intel provided driver, etc. But nothing works.\nxev doesn't recognizes the hotkeys for change bright (Fn+F2 and Fn+F3), control screen output (Fn+F4) and enable/disable WiFi (Fn+F11).\nAll another hotkeys works OK and keypresses are detected by xev: Enable/disable touchpad (Fn+F5) and Mute/Volume control (Fn+F6, Fn+F7 and Fn+F8)\nFn+F11 is Fan Control, never worked.\nThis is the second clean Ubuntu 15.10 installation and the second upgrade after installation and the problem is the same after upgrade Ubuntu 15.10\nWhat can I do?\nThanks in advance !\n(Posted in Ubuntuforums 3 with no answer http://ubuntuforums.org/showthread.php?t=2320615)\n\nA: Copied OP comment here:\nIt was a BIOS error from Samsung. The problem was solved according to next steps.\n\n\n*\n\n*Enter to BIOS/UEFI from Windows 8 installation disk.\n\n*On the BIOS/UEFI set hard disk to \"normal\" (not AHCI)\n\n*Install Windows 8 (no blue screen!)\n\n*Update BIOS/UEFI with Samsung Utility\n\n*BIOS/UEFI is now fixed, install Ubuntu deleting Windows and all Ubuntu features works OK!\n\n", "Q: Problem Installing MS fonts for Libre Office @ Ubuntu 14.04 codename Trusty MY FIRST STEP IN THE TERMINAL:\naivinor@mcph:~$ sudo apt-get install ttf-mscorefonts-installer\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following packages were automatically installed and are no longer required:\n  imagemagick-common liblqr-1-0 libmagickcore5 libmagickcore5-extra\n  libmagickwand5 libnetpbm10 linux-headers-3.13.0-32\n  linux-headers-3.13.0-32-generic linux-image-3.13.0-32-generic\n  linux-image-extra-3.13.0-32-generic netpbm\nUse 'apt-get autoremove' to remove them.\nThe following extra packages will be installed:\n  cabextract\nThe following NEW packages will be installed:\n  cabextract ttf-mscorefonts-installer\n0 upgraded, 2 newly installed, 0 to remove and 32 not upgraded.\nNeed to get 70.6 kB of archives.\nAfter this operation, 282 kB of additional disk space will be used.\nDo you want to continue? [Y/n] y\n\nMY SECOND STEP:  \n WARNING: The following packages cannot be authenticated!\n          cabextract ttf-mscorefonts-installer\n   Install these packages without verification? [y/N] y\n   0% [Connecting to 172.16.19.10 (172.16.19.10)]\n   Err http://in.archive.ubuntu.com/ubuntu/ trusty/universe cabextract amd64 1.4-4\n\nAT THIS POINT I FACE A NUMBER OF ERRORS THAT CLAIM INABILITY TO CONNECT TO 172.16.19.10 AS CONNECTION TIMED OUT - I HAVE NO INTERNET PROBLEMS \nSAYS FAILED TO FETCH AND HAS LINKS SUCH AS \nin.archive.ubuntu.com/ubuntu/ trusty/multiverse ttf-mscorefonts-installer all 3.4+nmu1ubuntu1\nin.archive.ubuntu.com/ubuntu/pool/universe/c/cabextract/cabextract_1.4-4_amd64.deb\n\nin.archive.ubuntu.com/ubuntu/pool/multiverse/m/msttcorefonts/ttf-mscorefonts-installer_3.4+nmu1ubuntu1_all.deb\n\nLAST LINE IS:\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n\n\nA: The problem seems to be related with network connection.\nSo, first check if your PC is connected to your router:\nifconfig\n\nThe above command will show you PC network interfaces. Now look at the command output and search the inet addr. It should be in the second line of one of your connected interface (under something like eth0 or wlan0 depending if your are connected via cable or through WI-FI). If the value of your inet addr is similar to 172.16.x.x your PC is in the same network of your router.\nIf it is not so you have to reconnect to your router. You can do this with Network Manager.\nNow you can check the connection between your PC and your router with this command:\nping 172.16.19.10\n\nIf it works you can check connectivity with internet:\nping www.google.com -c 8\n\nIf also this works, you can install fonts as suggested by @mikeymop:\nsudo apt-get update\nsudo apt-get install ubuntu-restricted-extras\n\n\nIf ping command didn't work it means 2 things:\n\n\n*\n\n*ICMP packets cannot be sent over your network or out of it.\n\n*You can't reach your router or external server (e.g. www.google.com)\n\n\nIn the first case you could try to check your connectivity directly running\n apt-get update\n\nIn the other case you can try to reboot your router and you have to hope that all things will work after.\nI hope this could help you.\n\nA: Have you tried\n$sudo apt-get update && sudo apt-get install ubuntu-restricted-extras\n\nThis package, includes the Microsoft fonts\n", "Q: Samba 2:3.6.25-0ubuntu0.12.04.2 as PDC (samba3 NT4 domain) Windows machines lost trust after USN-2950-1 update we have problem on some of our Windows 7 Pro/ Windows 8 Pro/ Windows 2008 Server machines which are in Samba3 Domain after yesterday USN-2950-1 update to 3.6.25 on Ubuntu 12.04 LTS\nWhen the user tries to log in to the computer it says \"The trust relationship between this workstation and primary domain failed.\" and i can see\nIn samba log is this error: _netr_ServerAuthenticate3: netlogon_creds_server_check failed. Rejecting auth request from client XXXX machine account XXXX$\nand Windows System event log is Event ID:5719\n\"This computer was not able to set up a secure session with a domain controller in domain CONTOSO due to the following: \nThere are currently no logon servers available to service the logon request. \nThis may lead to authentication problems. Make sure that this computer is connected to the network. If the problem persists, please contact your domain administrator.\"\nOn some computers can users login after few reboots, but then they again can't. And the only workaround which works is to disconnect computer from network during login and then connect it after.\nAll computers are fully updated and have also MS16-047 (KB3149090 for Win7 64bit) (the badlock update) installed.\nI tried and didn't work:\n\n\n*\n\n*rejoin computer to doimain without problem\n\n*checked if they use NTLMv2 for login\n\n*ntlm auth = no and lanman auth = no are applied in samba\n\n*tried raw NTLMv2 auth = yes but didn't help according to https://www.samba.org/samba/security/CVE-2016-2111.html\n\n*Checked for  \"RequireSignOrSeal\"=dword:00000001\n            \"RequireStrongKey\"=dword:00000001\nregistry keys according to https://wiki.samba.org/index.php/Required_settings_for_NT4-style_domains\nbut they are OK.\n\n\nDoes anybody same problem? Did you find solution? Any help appreciated. Thank you.\nUPDATE:\ndowngrade of samba to previous version worked as a workaround:\napt-get install samba=2:3.6.3-2ubuntu2 samba-common=2:3.6.3-2ubuntu2 libwbclient0=2:3.6.3-2ubuntu2 winbind=2:3.6.3-2ubuntu2 libpam-winbind=2:3.6.3-2ubuntu2 smbclient=2:3.6.3-2ubuntu2\napt-mark hold samba smbclient samba-common winbind libwclient0 libpam-winbind\n\nA: I have the same problem:\nhttps://serverfault.com/questions/771388/how-can-i-fix-samba-3-6-25-the-trust-relationship-between-this-workstation-and\nA workaround is to reinstall the old packages (see the link).\n\nA: Downgrade of samba to previous version worked as a workaround, not the real solution:\napt-get install samba=2:3.6.3-2ubuntu2 samba-common=2:3.6.3-2ubuntu2 libwbclient0=2:3.6.3-2ubuntu2 winbind=2:3.6.3-2ubuntu2 libpam-winbind=2:3.6.3-2ubuntu2 smbclient=2:3.6.3-2ubuntu2\n\napt-mark hold samba smbclient samba-common winbind libwclient0 libpam-winbind\n\n\nA: possibly related and see my answer there:\nSamba Share user/password error after update\nI will update this answer, if this is indeed the solution.\n", "Q: How to know the home directory size limit? Is there any way to know how large my home directory is allowed to be?\n\nA: If i got that right you have the quota package installed on your machine?\nThen it would be the command:\nrepquota\n(not sure if you need to sudo it or not)\nThe output should look like:\n\n# repquota -a \n                                Block limits               File limits \n        User            used    soft    hard  grace    used  soft  hard  grace \n        root      --  175419       0       0          14679     0     0 \n        bin       --   18000       0       0            735     0     0 \n        uucp      --     729       0       0             23     0     0 \n        man       --      57       0       0             10     0     0 \n        user1     --   13046   15360   19200            806  1500  2250 \n        user2     --    2838    5120    6400            377  1000  1500\n\n(Source)\n\nA: Use lsblk command to print mounted partitions. This will give you something similar to this\nNAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nsda      8:0    0 698,7G  0 disk \n├─sda1   8:1    0 651,9G  0 part /home\n├─sda2   8:2    0   1,9G  0 part [SWAP]\n└─sda3   8:3    0  44,8G  0 part /\nsdb      8:16   0   1,8T  0 disk \n└─sdb1   8:17   0   1,8T  0 part \nsr0     11:0    1  1024M  0 rom  \n\nIf you can't see /home partition then look at / (root, sda3 in my case) mountpoint.\n", "Q: How do I get to the shell on ubuntu tablet? Just got my brand-new Aquaris M10 ubuntu edition - but I don't seem to get beyond the few apps that are on the left-hand menu. How do I get to the shell? How do I start sshd?\n\nA: I got my Aquaris M10 today as well and figured our how to start the shell:\n\n\n*\n\n*slide in the Launcher bar by swipe in from the left and click the big\norange icon \n\n*slide in \"Manage\" by swipe in from the bottom  \n\n*click on Apps and there you'll find the \"Terminal\"\n\n\nTo make Terminal icon sticky in Launcher bar, tap and hold Terminal icon until a sub menu opens and stickt it.\nI also struggled with sshd and all solutions I found in Internet were too hacky and didn't work. But I found out, how to get sshd running:\nTo start sshd in Aquarius M10 enter these commands in Terminal:\nsudo su\nssh-keygen -A\nmkdir /var/run/sshd\n/usr/sbin/sshd\n\nThen connect from a computer in same network to your Aquarius M10 by typing:\nssh phablet@192.168.1.153\n\n...and you should be connected. Replace the IP address above with your M10's IP address.\nEdit: I figured out, that the tablet only accepts ssh connections while Terminal is the active application on tablet. But the good thing is, even when in standby, sshd works.\n", "Q: MAAS \"Failed deployment\" on node with 16.04 LTS We have a node with commodity hardware (Dell r620). I can successfully deploy Ubuntu 14.04 LTS and 15.04.  \nWhen I attempt to deploy 16.04 LTS MAAS eventually returned \"Failed deployment\".\nINFO    Mon, 18 April 2016 21:30:14 Node changed status — From 'Deploying' to 'Failed deployment'   \nINFO    Mon, 18 April 2016 20:56:09 PXE Request — local boot    \nINFO    Mon, 18 April 2016 20:54:06 Installation complete — Node disabled netboot   \nINFO    Mon, 18 April 2016 20:52:41 PXE Request — curtin install    \nINFO    Mon, 18 April 2016 20:52:41 PXE Request — curtin install    \nINFO    Mon, 18 April 2016 20:50:18 Node powered on \nINFO    Mon, 18 April 2016 20:50:14 Powering node on\n\nI'm unsure how to debug this further.  Any hints as to where to check next?\nEdit:\nSerial console outputs this:\nCLIENT MAC ADDR: EC F4 BB CC AD 7C  GUID: 44454C4C 5000 1044 8057 B7C04F503232\nCLIENT IP: 10.129.76.2  MASK: 255.255.255.0  DHCP IP: 10.129.49.2\nGATEWAY IP: 10.129.76.1\n!PXE entry point found (we hope) at 96B2:0106 via plan A\nUNDI code segment at 96B2 len 5E00\nUNDI data segment at 9072 len 6400\nGetting cached packet  01 02 03\nMy IP address seems to be 0A814C02 10.129.76.2\nip=10.129.76.2:10.129.49.2:10.129.76.1:255.255.255.0\nBOOTIF=01-ec-f4-bb-cc-ad-7c\nSYSUUID=44454c4c-5000-1044-8057-b7c04f503232\nTFTP prefix:\nTrying to load: pxelinux.cfg/01-ec-f4-bb-cc-ad-7c                   ok\nBooting local disk ...\nBooting...\n\nThe actual video output is nonsense. A bunch of weird symbols.  I'll have to take a picture of it and attache it but I don't think it'll be of any help.\n\nA: If I were you, I would take a look at the screen (display/SOL/IPKVM) of the machine being deployed. I bet you will see some interesting info there.\nYou can also change Ubuntu version used for commissioning to 16.04, recommission your machine with option \"Allow SSH access and prevent from powering off\" checked. That will give you a chance to look at the situation with your machine and Ubuntu 16.04 \"from inside\".\n", "Q: Choosing OS from startup - too many options I recently installed Linux Mint alongside my Windows 10, and after using boot-repair in Linux, now I can choose between my 2 operating systems. However, there are multiple choices on the start-up menu now that I don't want since other people might use my computer and accidentally enter system setup or other pathways and change something in the process. How can I get rid of all options except the 2 operating systems?\n\nA: You can modify the grub.cfg. It is located in \n/boot/grub2/grub.cfg\n\nThis file is laid out in an xml format. Looking at it you can gain an intuition as to how you would like it modified. I recommend commenting out the entries you dont want by putting # at the start of all lines relevant to the entry. Because you are new to this interface, I am showing you gedit, it works like a supercharged Windows Notepad.\nI recommend backing up your grub file with the first command.\n$sudo cp /boot/grub2/grub.cfg ~/grub.cfg.bak    \n$sudo gedit /boot/grub2/grub.cfg\n\nNow you can modify at will, because you have root permissions.\nIn the event you want to undo your modifications\n$sudo update-grub\n\nwill automatically detect,and setup all detected bootable partitions.\n", "Q: Ubuntu 16.04, how to get my GPU temp and fan speed? On Ubuntu 14.04 I got used to run during the boot process a python script for conky to read my GPU temperature and then change my FAN speed according to the temperature. This is the script: \n# \n# python /home/ibart/.scripts/ventola_ati.py\n#\n\nimport os\nimport time\n\nminTemp = 45.00\nmaxTemp = 70.00\nminSpeed = 10\nmaxSpeed = 90\nupdateInterval = 3\nfanSpeed = 25\n\nwhile True:\n\n    f = os.popen('aticonfig --od-gettemperature | grep \"Sensor 0\" | cut -c43-47')\n    currentTemp = eval(str(f.readlines())[2:7])\n\n    if currentTemp > maxTemp:\n        if fanSpeed < maxSpeed:\n            fanSpeed = fanSpeed + 1\n    if currentTemp < minTemp:\n        if fanSpeed > minSpeed:\n            fanSpeed = fanSpeed - 1\n\n    os.system('aticonfig --pplib-cmd \"set fanspeed 0 ' + str(fanSpeed) + '\"')\n\n    print fanSpeed\n    print currentTemp\n    time.sleep(updateInterval)\n\nWhat now that Ubuntu dropped the official drivers for my card, an old and fancy HD5770?\nThanks.\nedit. On 16.04 sensors detects it. Thanks Luca. \n\nA: Please use sensors-detect.\nsudo sensors-detect\n\nthen launch it with:\nsensors\n\n\nA: I assume you are trying to change the speed of the system fan in response to the GPU temperature. I think the speed of the GPU fan can only be controlled by the GPU driver (if at all).\nInstall 'lm-sensors' and 'fancontrol'. There is an excellent set of instructions for doing so here\nFrom the fragment of the output from sensors you have posted it seems you have installed but not configured lm-sensors. You do so by finding or writing a configuration file for your motherboard and placing it in /etc/sensors.d\nAs sensors is apparently reporting the GPU temperature correctly you don’t need to bother to do this if you don’t mind spurious readings from non-existent sensors and spurious warnings.\nThen configure 'fancontrol' to have the fan speed controlled by the GPU temperature.\n", "Q: Launcher, menubar and window borders disappeared in Ubuntu 16.04 After upgrading to 16.04 from 15.10 it was running smoothly for about one week, then it started getting random crashes and freezes and now all the windows borders disappeared. I would include a screenshot but the keyboard shortcut for screenshots doesn't work.\nLauncher is missing, and the global menu/ top bar is also missing. Right now my firefox window is maximized to the top and fills the screen like if I had pressed F11 to run it fullscreen. None of the keyboard shortcuts work.\nCan't open a terminal using Ctrl + Alt + T. I finally managed to get a terminal open and ran unity --debug and this is the result. [opened the terminal using ctrl+space to open synapse, apparently that works and also copying in terminal and pasting firefox also works]\nunity --debug\nunity-panel-service stop/waiting\nunity7 stop/waiting\nunity-panel-service start/running, process 2515\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n/usr/bin/compiz (core) - Info: Loading plugin: core\n/usr/bin/compiz (core) - Info: Starting plugin: core\n[New Thread 0x7ffff3638700 (LWP 2588)]\n/usr/bin/compiz (core) - Info: Loading plugin: ccp\n/usr/bin/compiz (core) - Info: Starting plugin: ccp\n[New Thread 0x7fffeb20e700 (LWP 2590)]\ncompizconfig - Info: Backend     : gsettings\ncompizconfig - Info: Integration : true\ncompizconfig - Info: Profile     : unity\n[New Thread 0x7fffeaa0d700 (LWP 2591)]\n/usr/bin/compiz (core) - Info: Loading plugin: composite\n/usr/bin/compiz (core) - Info: Starting plugin: composite\n/usr/bin/compiz (core) - Info: Loading plugin: regex\n/usr/bin/compiz (core) - Info: Starting plugin: regex\n/usr/bin/compiz (core) - Info: Loading plugin: commands\n/usr/bin/compiz (core) - Info: Starting plugin: commands\n/usr/bin/compiz (core) - Info: Loading plugin: resize\n/usr/bin/compiz (core) - Info: Starting plugin: resize\n/usr/bin/compiz (core) - Info: Loading plugin: place\n/usr/bin/compiz (core) - Info: Starting plugin: place\n/usr/bin/compiz (core) - Info: Loading plugin: move\n/usr/bin/compiz (core) - Info: Starting plugin: move\n/usr/bin/compiz (core) - Info: Loading plugin: snap\n/usr/bin/compiz (core) - Info: Starting plugin: snap\n/usr/bin/compiz (core) - Info: Loading plugin: session\n/usr/bin/compiz (core) - Info: Starting plugin: session\n/usr/bin/compiz (core) - Info: Loading plugin: imgpng\n/usr/bin/compiz (core) - Info: Starting plugin: imgpng\n/usr/bin/compiz (core) - Info: Loading plugin: compiztoolbox\n/usr/bin/compiz (core) - Info: Starting plugin: compiztoolbox\n/usr/bin/compiz (core) - Error: Plugin 'opengl' not loaded.\n\n/usr/bin/compiz (core) - Info: Loading plugin: mousepoll\n/usr/bin/compiz (core) - Info: Starting plugin: mousepoll\n/usr/bin/compiz (core) - Info: Loading plugin: vpswitch\n/usr/bin/compiz (core) - Info: Starting plugin: vpswitch\n/usr/bin/compiz (core) - Info: Loading plugin: workarounds\n/usr/bin/compiz (core) - Info: Starting plugin: workarounds\n/usr/bin/compiz (core) - Error: Plugin 'opengl' not loaded.\n\nThere is one error of opengl plugin not loading. Is that the problem?\n\nA: I found the answer from this thread (https://askubuntu.com/a/717860/25131)\n\n\n*\n\n*Alt + F10 and then open terminal from the menu\nthat appears\n\n*then type ccsm in to the terminal.\n\n*in there search for unity plugin and enable it.\n\n\nIt asks several questions because enabling it conflicts with another.\nAfter enabling it the Unity launcher and menu bar should appear.\n\nA: I do notice that once in a while compiz would freeze up on me and cause the environment to freeze also. Maybe try removing it to see if that changes anything? edit: im talking about the gui manager\n", "Q: Google reports dkim passing for invalid host I set up DKIM, SPF, and DMRAC on ubunutu server a month ago. Everything seemed to be working fine, until I received a curious DMARC report. A rouge server managed to send an email that passed DKIM verification at google.\nHow can this happen?\nIs this likely a replay 'attack' using an unchanged message?\n<record>\n  <row>\n    <source_ip>RougeIP</source_ip>\n    <count>1</count>\n    <policy_evaluated>\n      <disposition>none</disposition>\n      <dkim>pass</dkim>\n      <spf>fail</spf>\n    </policy_evaluated>\n  </row>\n  <identifiers>\n    <header_from>host.com</header_from>\n  </identifiers>\n  <auth_results>\n    <dkim>\n      <domain>host.com</domain>\n      <result>pass</result>\n    </dkim>\n    <dkim>\n      <domain>host.com</domain>\n      <result>pass</result>\n    </dkim>\n    <spf>\n      <domain>host.com</domain>\n      <result>fail</result>\n    </spf>\n  </auth_results>\n</record>\n\n\nA: Turns out DKIM is vulnerable to replay attacks, as documented here:\nhttp://www.zdnet.com/article/dkim-useless-or-just-disappointing/\nSPF failed as intended and the message was flagged properly.\n", "Q: Using arc4random on Ubuntu 14.04 trusty I am currently working with a C++ program where I wish to use arc4random function. Every time I compile, I receive a not declared in scope message for arc4random. I understand that this is an error in my included libraries in my program, and yet I have included both stdlib.h and stdio.h which I believe are the libraries it uses? I have installed 'sudo apt-get install libpcl-all', as well as, 'sudo apt-get install build-essential'. I have scoured the web, but am still unsure what I need at this point. I am still very new at Ubuntu, so any help with this problem would be appreciated.\n\nA: The arc4random function is a BSD utility that is not part of the standard C library on Ubuntu. To use it, I think that you will need to install the libbsd-dev package, and then include the BSD version of the header explicitly using\n#include <bsd/stdlib.h>\n\nYou will then need to link your executable with the libbsd library by adding -lbsd to your compiler command line, for example\ng++ -o prog -Wall prog.cpp -lbsd\n\n", "Q: How to install grub Ubuntu 14.04? I installed Windows8.1 and Ubuntu 14.04 but when boot up its only take Ubuntu not take Windows. I also try this sudo apt-get install grub. Its not take.\n\nA: open a terminal and use this code\nsudo grub-install /dev/sda\n\n", "Q: How to load \"snd-hda-intel\" at startup I always have to type in  sudo modprobe snd-hda-intel  in order to get my sound card to work\nI have already tried the solution to append snd-hda-intel to /etc/modules with\n\n sudo sh -c 'echo \"snd-hda-intel\" >> /etc/modules' \nThe line is added accordingly into the file, anyways that does not seem to work. Please give advice.\nedit:\nI did run  dmesg | grep snd  --> no result.\n\nafterward i run\n sudo modprobe snd-hda-intel  and then\nI did run  dmesg | grep snd  --> see output\n\noutput:\n[  162.098807] snd_hda_intel 0000:01:00.1: Handle VGA-switcheroo audio client\n[  162.134560] snd_hda_codec_realtek hdaudioC0D0: ALC892: SKU not ready 0x598301f0\n[  162.134978] snd_hda_codec_realtek hdaudioC0D0: autoconfig for ALC892: line_outs=1 (0x14/0x0/0x0/0x0/0x0) type:speaker\n[  162.134982] snd_hda_codec_realtek hdaudioC0D0:    speaker_outs=0 (0x0/0x0/0x0/0x0/0x0)\n[  162.134985] snd_hda_codec_realtek hdaudioC0D0:    hp_outs=1 (0x1b/0x0/0x0/0x0/0x0)\n[  162.134988] snd_hda_codec_realtek hdaudioC0D0:    mono: mono_out=0x0\n[  162.134991] snd_hda_codec_realtek hdaudioC0D0:    dig-out=0x1e/0x0\n[  162.134993] snd_hda_codec_realtek hdaudioC0D0:    inputs:\n[  162.134997] snd_hda_codec_realtek hdaudioC0D0:      Internal Mic=0x19\n[  162.134999] snd_hda_codec_realtek hdaudioC0D0:      Mic=0x18\n[  162.135002] snd_hda_codec_realtek hdaudioC0D0:      Line=0x1a\n \n\nA: After attempting an \"oss4\" audio install, I lost audio, and reverting my mistake, did not recover the audio.\nNeeded to \"manually\": modprobe snd-hda-intel\nevery boot....to get audio on Ubuntu\nUntil I found that the driver had been put in a blacklist.... on the oss4 attempt.\ngrep snd-hda-intel /etc/modprobe.d/*\n/etc/modprobe.d/oss4-base_noALSA.conf:blacklist snd-hda-intel\n\nmoved the \"oss4-base_noALSA.conf\" away from the \"/etc/modprobe.d\"\nsudo mv /etc/modprobe.d/oss4-base_noALSA.conf /root\n\nand now, do not need to manually \"modprobe snd-hda-intel\" after every boot....to get audio on Ubuntu\nHope it helps...\nSimilar to How can I ensure the `snd-hda-intel` module is loaded on startup? \n\nA: I had issues getting sound to work after upgrading to Ubuntu 20.04.\nmodprobe snd_hda_intel commands failed to load module:snd_hda_intel. \n\nThe module was missing. I installed it via:\nuname -r (note kernel version)\napt-get install linux-modules-extra-5.4.0-56-generic\n\nThis installed the missing module, after this, I could module:snd_hda_intel and everything worked!\n\nA: Please turn off secure boot using mokutil. Mine had the same problem but got it working by disabling secure boot. \n", "Q: permanently changing screen resolution I have to readjust my screen resolution every time I restart my laptop. Is there a way to permanently change it to what I want?\nI have been using xrandr to change it temporarily.\n\nA: So this worked for me:\nsudo -i\ncd /etc/X11\ntouch xorg.conf\nnano xorg.conf\nthen in the simple nano editor, write (or just paste) this:\nSection \"Device\"\n        Identifier      \"Configured Video Device\"\nEndSection\nSection \"Monitor\"\n        Identifier      \"Configured Monitor\"\nEndSection\nSection \"Screen\"\n        Identifier      \"Default Screen\"\n        Monitor         \"Configured Monitor\"\n        Device          \"Configured Video Device\"\n    SubSection \"Display\"\n\n      Modes \"1280x800\"\n\n    EndSubSection\n\nEndSection\nthen save the file using Ctrl+O, then quit Ctrl+x;\n", "Q: Install UBUNTU MINIMAL to external HDD I am trying to install UBUNTU minimal to a Seagate 1TB external HDD. I have disconnected my internal drive so that this installation doesn't conflict with Windows 7. But I am experiencing problems as the setup is not detecting my external drive. Instead it shows no disk drive was detected and asks me to choose the correct drivers. Although it does detect my 16GB HP pendrive.\nMy first partition on HDD is NTFS file format and Primary. Second partition is 20gb ext4 then I have about 300GB unallocated space. Further I have 3 logical partitions. Again I have about 4GB unallocated space.\nI downloaded the amd64 version of mini.iso from official site and it is the latest version.\nDo I need some drivers to install to external USB hdd ? When I select none of the above in the driver selection menu I do get the option to load the missing drivers from removable media.\nThanks for your help.\n\nA: After waiting so long for an answer, I decided to install UBUNTU to my 16GB pendrive, however the setup was unable to install grub bootloader so I installed it myself following the guide : http://howtoubuntu.org/how-to-repair-restore-reinstall-grub-2-with-a-ubuntu-live-cd\nThen I used dd to create a disk image. And restored the image to external HDD partition and installed bootloader to the external HDD. And now I have successfully booted into UBUNTU and I wrote this answer in UBUNTU.\nIf UBUNTU setup is unable to read the partitions on external HDD then repartition the entire drive. This always solves the issue.\n", "Q: NVidia and Intel in same Laptop: which card is used? I'm trying to get my graphics card working in my Dell Mobile Precision 5510, which should be an NVidia Quaddro M1000M. The machine also has Intel graphics.\nIf I run lspci, I get, among other things,\n00:02.0 VGA compatible controller: Intel Corporation Device 191b (rev 06)\n01:00.0 3D controller: NVIDIA Corporation GM107GLM [Quadro M1000M] (rev a2)\n\nThen, sometimes, after a few seconds, the machine freezes.\nFrom the output of lspci, it appears the machine has both an Intel graphics card, and an NVidia one (M1000M) as expected.\nThis being a laptop, I don't have separate adaptors, so I don't know how outputs are switched, but I'd like to make sure I'm using the NVidia card.\nI installed the NVidia drivers but X was just a blank screen.\nI'm reasonably happy with the Nouveau drivers, but I cannot confirm that the correct graphics card is being used. The laptop was delivered with Ubuntu 14.04 has has never run anything else.\nglxinfo gives me the following:\nOpenGL vendor string: Intel Open Source Technology Center\nOpenGL renderer string: Mesa DRI Intel(R) Skylake Halo GT2 \nOpenGL core profile version string: 3.3 (Core Profile) Mesa 10.5.9\n\nThis sounds like the Intel card is being used. Is there a setting somewhere I could check? Thank you.\n\nA: After two weeks of fiddling around and getting nowhere, I finally got the Nvidia card working with the NVidia drivers.\nThe issue is that I originally tried to install the Nvidia drivers with the Ubuntu software installer (don't do this) which was originally happily using the Intel drivers. This didn't work, and several reboots later it has removed the Intel option and was apparently using the Nouveau drivers on the Intel card - a configuration I'm not sure is even possible. My system was immensely unstable in this configuration and would lock up with lspci or when using 3D graphics.\nI went through a lot of steps in order to fix this, and I don't really know what worked.\nGet rid of whatever's there:\nsudo apt-get purge nvidia*\nsudo apt-get purge nouveau*\n\nInstall the Intel driver. For some reason this uninstalls a load of stuff, such as wine. Can install it again later so don't worry.\nsudo apt-get install xserver-xorg-video-intel\n\nI never explicitly uninstalled this (apt-get purge intel* is way too dangerous because of all the other Intel stuff) so presumably the Intel drivers are still there.\nAdd some respositories:\nsudo add-apt-repository ppa:bumblebee/stable\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\n\nInstall NVidia drivers and bumblebee:\nsudo apt-get install nvidia-364\nsudo apt-get install bumblebee bumblebee-nvidia primus linux-headers-generic\n\nThis didn't work at first. I've no idea why. X would either not start, or keep returning me to the log-in screen. I tried replacing lightdm with gdm, that didn't work at all, so I went back to lightdm. Finally had one last try with the above and it worked. I can even use the nvidia-settings app to change to the Intel card.\nOnly problem is that I have a 4k screen on a 15\" laptop. Most software doesn't scale properly. I can't run 1920x1080 anymore with the NVidia card for some odd reason (it runs in the centre of the screen with a massive black border) but it works with the Intel card ok.\nI hope this helps somebody, but beware that hybrid graphics (on laptops) can be a complete pain to get working.\n\nA: As you have hybrid graphics, you need to have the proprietary NVIDIA drivers and Optimus support installed to use the NVIDIA graphics adapter and to switch between both graphics.  \nTo check whether you are using the intel or the NVIDIA graphics open a terminal and execute :   \nlspci -k | grep -EA2 'VGA|3D'  \n\nThe output from this command will give you an information which will be something like this :  \nlspci -k | grep -EA2 'VGA|3D'  \n00:02.0 VGA compatible controller: Intel Corporation 4th Gen Core Processor Integrated Graphics Controller (rev 06)  \nSubsystem: CLEVO/KAPOK Computer Device 3501  \nKernel driver in use: i915  \n\n01:00.0 3D controller: NVIDIA Corporation GM107M [GeForce GTX 860M] (rev a2)  \nSubsystem: CLEVO/KAPOK Computer Device 3501  \nKernel driver in use: nvidia  \n\nWhen it shows Kernel driver in use: nvidia, you are using the NVIDIA graphics adapter.  \nWhen you want to switch to the intel card - open NVIDIA X Server Settings -> PRIME Profiles.  \nIf this for whatever reason doesn't work, you should install the latest official NVIDIA drivers.  \nOpen a terminal and execute the following commands :\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\nsudo apt-get install nvidia-361 nvidia-prime\nsudo reboot\n\nUpdate addressing your comment that you still cannot use the NVIDIA adapter properly : \nUse another method to install the drivers ... but first remove all installed NVIDIA software.  \nHighlight the Ubuntu entry in the GRUB boot menu and press the E key.\nAdd nouveau.modeset=0 at the end of the linux line - press F10 to boot.  \nOn login screen press Ctrl+Alt+F1 - enter user name and password and then execute :\nsudo apt-get purge nvidia*  \nsudo reboot  \n\nNow reinstall the drivers 361.42 supporting the NVIDIA Quadro M1000M.   \nHighlight the Ubuntu entry in the GRUB boot menu and press the E key.\nAdd nouveau.modeset=0 at the end of the linux line - press F10 to boot.\nOn login screen press Ctrl+Alt+F1 - enter user name and password and then execute :\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\nsudo apt-get install nvidia-361 nvidia-prime\nsudo reboot \n\nNote : Set a Space between the last character in the linux line and nouveau.modeset=0.\n", "Q: shell script storing run time with python I am trying to store the run time of a python program using this\n{ time python experiments.py --model iwae --k $k ; } 2> time$k.txt\n\nwhen I do this in a shell script, I get \n40.35user 3.12system 0:43.00elapsed 101%CPU (0avgtext+0avgdata 850788maxresident)k\n0inputs+30344outputs (0major+159448minor)pagefaults 0swaps\n\nwhen I only execute one line , I get \nreal    0m16.367s\nuser    0m15.420s\nsys 0m1.436s\n\nwhich is what I want.\nCan someone help me with logging run time of python script and storing the runtime in a text file please?\nscript\n# ! /bin/sh\n\nfor k in 3 5 10; do\n\necho $k\n\nsudo ldconfig /usr/local/cuda/lib64\n\n{ time python experiments.py --model iwae --k $k ; } 2> time$k.txt\n\ndone\n\n\nA: \ntime is many things. There's the external /usr/bin/time GNU program. There's the bash keyword time.\n$ type -a time\ntime is a shell keyword\ntime is /usr/bin/time\n\nWhen you run time … in an interactive shell, you'd be typically using bash, and so the time keyword takes effect.\nWhen you run time … in a script using /bin/sh, the shell used (dash)\n doesn't have time as a keyword, and the external time command is called.\nTo get the output you want, call the external time command with the -p option:\n-p, --portability\n      Use the following format string, for conformance with POSIX\n      standard 1003.2:\n                real %e\n                user %U\n                sys %S\n\nThe external command is also more friendly. Since it isn't a keyword, you don't need to do the wrap-in-{ … }-for-redirection trick to get the output in a file. There's an option for that:\n-o FILE, --output=FILE\n      Write the resource use statistics to FILE instead of to the\n      standard error stream.  By default, this overwrites the file,\n      destroying the file's previous contents.  This option is useful\n      for collecting information on interactive programs and programs\n      that produce output on the standard error stream.\n\nThe output is also far more customizable, making it easier for processing later on. With bash's time, the options provided in TIMEFORMAT are very limited.\n", "Q: I can't save things in terminal I have just installed Ubuntu mate 32 bit and can't seem to save things when I put them into terminal. I hit \"contr x\" then \"y\" but it doesn't seem to save them?\n\nA: If you are using nano, you can save with Contr + o and Enter. And exit with Contro + x and Enter. Make sure, that you have rights to edit this file\n", "Q: Ubuntu USB dongle I have recently installed Ubuntu on my PC that I have built. My mother board does not have wireless network card so I bought a CSL USB 2.0 Dual Band WLAN Adapter. I have got the driver disc and extracted them onto my PC but I don't know how to install them on Ubuntu. \nplease help. \nHere is the link for the usb dongle...\nhttps://www.amazon.co.uk/gp/product/B015Z8JAYS/ref=s9_simh_gw_p23_d0_i1?pf_rd_m=A3P5ROKL5A1OLE&pf_rd_s=desktop-1&pf_rd_r=26F1BADJA75ZG5YGZDZF&pf_rd_t=36701&pf_rd_p=867551807&pf_rd_i=desktop\nHere is the screen shots for the drivers:\n\n\nA: You can't install Windows drivers in Ubuntu.\nIf this is the adapter you're referring too, you shouldn't need to do anything other than just plug it in.\n", "Q: dual boot system can't boot from usb I have Ubuntu 15.10 and Windows 8.1 both installed on my PC and I want to boot from a USB just to check something, but GRUB does not give me any option to do so.\nThe USB is bootable (I checked it with another computer).\nHow can I boot from USB? And does this have something to do with the GRUB configuration or something different?\n\nA: You need to select USB boot in your motherboard's BIOS.  Usually there will be a screen that says 'Press Del to enter BIOS, F8 to enter Boot Menu'.  Press whatever key corresponds to the Boot Menu, and then select your USB from that.\nAlso, make sure your computer's BIOS is configured to boot from USB.  This will be a setting in the BIOS, usually labeled 'Boot Order'.\n\nA: Insert your USB key (bootable!) in the computer BEFORE you press the specific key on LENOVO G50. Then you should see the boot from USD device option. If still no luck. Than start the computer (with bootable USB key inserted) and select Advanced options in grub menu. This will take you to BIOS. Go under boot section and select there to boot first from USB.  \n\nA: Try to enable UEFI and boot again. It solved problem to me once. By the way I had problem where i couldnt boot not UEFI USB, reinstalling USB with Rufus helped me.\n", "Q: Login problem after failed update from 14.04 I have tried to update my Ubuntu 14.04 to wily wolf but somehow It failed and I restored my factory Ubuntu i.e.,14.04. Now I can't login to my desktop and every time I login it returns to the same page. I also can't access terminal from my login page. Cntlr+alt+ f2 and other keys are not working for me. I can access terminal from guest account but can't do much as guest user has no authority.please help.\nI know little about Ubuntu. I appreciate your Help. Thanks.\n\nA: It sounds like you really messed something up bad.  Try this:\n\n\n*\n\n*Boot from Live DVD/USB\n\n*Mount your / partition if not already mounted\n\n*Copy all your files from your old installation onto another drive (preferably an external USB)\n\n*Reinstall Ubuntu 16.04, with a clean install\n\n*Copy all your files back into the new installation.\n\n\nThat should do it.  Without more information I can't tell you what to do other than recover data and reinstall.\n", "Q: ClamAV found 34 threats Less than 2 weeks since I installed Ubuntu and today when I ran the ClamAV it found 34 threats. They are all sorts of different threats: \nPacker.PrivateExeProte\nTool.Packed\nTrojen.EmbededJS\nExploit.CVE\nand etc\n\nHere a screenshot of the scan results:\n\nAre these false positive or should I be worried? a lot of threats were found in texlive-doc folder. Should I delete or quarantine? \n\nA: All it does is scan software for specific patterns and Linux software will have those same patterns but for a totally legitimate reason where clamav incorrectly believes it found a -windows- infected file.\nRegarding the 1st:ClamAV PUA.Win.Packer.PrivateExeProte-7`. As you can see not only a -windows- problem but also a \"Potentially Unwanted Application\". Basically something they consider a problem. When using Windows. See ClamAV PUA.Win32.Packer.PrivateExeProte-7 \nRegarding the 3rd see the link in comments here: Virus PUA.Script.PDF.EmbededJS-1 Again a PUA.\n4th one: see ClamAV: PUA.Win.Exploit.CVE_2012_0110 FOUND (/usr/share/mime/mime.cache) Again a PUA.\nSorry, but the only thing clamav is good for is finding -windows- viruses in -windows- files. It really really really is useless on a Linux system. Even if it did ever find a virus the sheer amount of false positives makes it useless. You are wasting your time. \n", "Q: Dual-Boot Problems I'm having a really bad problem. I can't dual-boot Windows 10 with Ubuntu.\nI know the fdisk comand but it says it gonna to delete some sort of system files. I don't know at all what i have to do!\nI really need help and fast as possible!\nThank You! \n\nA: I've heard if you install Windows 10 first, and then use Ubuntu's installer off of a cd/flash drive, it gives you an option to install alongside Windows 10. Have you tried this? It should skip the whole manual process, automatically create an entry in the bootloader, and repartition the drive (without losing Windows data!).\nAfter you do this, set your BIOS to boot from the Ubuntu partition. If you want to boot into Windows, simply hold down SHIFT while booting up. This brings you to the GRUB bootloader, where you can select which partition to boot from.\n", "Q: Select language when launching a guest session I've run into a tricky situation.\nI'm setting up a public-access computer, where it is desirable that people log in using the guest account.\nThe people who need to use the computer speak a lot of different languages.\nThe computer is an old one, and it's currently running Lubuntu 15.10, Lightdm login.\nHowever, as it's only possible to switch system languages by logging out and back into an account, combined with the fact that the guest account gets wiped once it logs out...\nA bit of a catch 22.\nI'm probably going to have to solve this using some sort of a scripted language-picker.\nI see two possible solutions, and those form my question(s):\nIs there any way to change system language without a full logout?\nAlternatively, is it possible to launch a script during a login? I'm thinking several different guest-account/skel alternatives, and making a symlink during login.\n\nA: It's possible to change the environment variables LANG and LANGUAGE within the session, but it won't affect already running processes. So no, there is no practical way to do it without logging out.\nConsidering that lightdm-gtk-greeter already has a language selector for choosing the language when you log in to an ordinary account, the most elegant solution would probably be to somehow make use of that feature. Can't tell how, though...\nThe below example solution uses a wrapper script to let the user select the display language via a zenity dialog. The example includes English and Swedish; the languages you use must of course be installed. This solution should work with both unity-greeter and lightdm-gtk-greeter on later Ubuntu versions. I tested on 15.10 and 16.04.\nCreate /etc/guest-session/choose-language-wrapper.sh, give it this contents:\n#!/bin/sh -e\n\n# show zenity dialog only when launched from greeter\nONLYGUEST=true\nfor U in $(users); do\n    if [ \"${U%%-*}\" != 'guest' ]; then\n        ONLYGUEST=false\n        break\n    fi\ndone\n\nif $ONLYGUEST && [ -x /usr/bin/zenity ]; then\n    guestlang=$( zenity --list --title 'Select language' \\\n      --text 'Select language for the guest session' --radiolist \\\n      --column 'Pick' --column '' TRUE 'English' FALSE 'Swedish' )\n    if [ \"$guestlang\" = 'English' ]; then\n        echo 'export LANGUAGE=en_US' >> \"$HOME/.profile\"\n        echo 'export LANG=en_US.UTF-8' >> \"$HOME/.profile\"\n    elif [ \"$guestlang\" = 'Swedish' ]; then\n        echo 'export LANGUAGE=sv' >> \"$HOME/.profile\"\n        echo 'export LANG=sv_SE.UTF-8' >> \"$HOME/.profile\"\n    fi\nfi\n\nexec /usr/lib/lightdm/lightdm-guest-session \"$@\"\n\nand make it executable:\nsudo chmod +x /etc/guest-session/choose-language-wrapper.sh\n\nThen make lightdm use the wrapper script by creating this file:\n$ cat /etc/lightdm/lightdm.conf.d/50-choose-guest-language.conf\n[Seat:*]\nguest-wrapper=/etc/guest-session/choose-language-wrapper.sh\n\nAfter next reboot the zenity dialog should show up when launching a guest session from the greeter.\n", "Q: Cant properly connect to WiFi on 14.04.4 but Ethernet works fine I am getting frustrated.. I recently switched to Ubuntu on this PC, and WiFi does not work. Ethernet does however. That's the only way I can even type this. I have an HP 15-f377wm laptop, and for two reasons:\nInstalled because Windows 10 was constantly crashing and error ridden, and I missed Ubuntu very much and the freedoms I had. Help and advice would very much be appreciated right now.\n\nA: Follow the steps in the top rated answer here and paste the results in your question.\n", "Q: xdotool : inserting unicode \"by hand\": i.e NOT \"key U \" but \"ctrl+shift+u\" I've got a Russian keyboard layout. This one doesn't have the acute sign which is used for stress mark in academic field.\nI can do that by hand. After a character, for example, и:\nctrl+shift+u 301 space --> и́\nI'm trying to use xdotool to make a shortcut to insert this stress:\nI've already tried to use the same solution in How to make xdotool type Unicode characters, but for some reason, the acute sign is special (it's not a character by itself, it's adding itself to the previous one) and it's not working.\nSo, I want xdotool to type for me all the sequence ctrl+shift+u 301 space that I'm typing by hand.\nWhat I've done is now: \nsleep 0.2 &&\n  xdotool key --delay 15 'ctrl+shift+u' &&\n  sleep 0.2 &&\n  xdotool type 301 &&\n  xdotool key space\n\nBut when doing that, xdotool stops at \"U\", waiting for me to fill in the number\n\nA: U+301 is the combining acute accent (that is, it gets added onto the previous character). You want the non-combining acute accent, U+B4:\nxdotool key UB4\n\nThere's also a sub-optimal solution, which is to have xdotool send the combining acute accent and a space, but it only renders properly in some programs:\nxdotool key U301 space\n\nAlso, beside the point, but your code worked perfectly fine on my machine. I'm not sure why it didn't on yours.\n\nA: These are old questions but I'll share my experience in case it helps someone.\nI found that the xdotool solutions were unreliable, and because its driving a C library that is ASCII only there were limited options for solving the problem.\nIn the end I used Linuxes ability to display and store unicode characters to store them on the clipboard. Xdotool is used to paste them into the active window.  So the code is:\necho 'λ' | xclip -selection clipboard;  # save unicode char(s) on clipboard\nsleep 0.5; \nxdotool key 'ctrl+shift+v';  # paste to active window\nsleep 0.3;  \nxdotool key ctrl+h  # backspace because I was getting an extra linefeed\n\nI checked with xsel --clipboard and it also worked.\n", "Q: Samba share no longer visible on network Having an issue with an Ubuntu 14.04 server running a Samba share.\nThis server was configured by another person, and has been running for a few years now.  I was transferring files from a hard drive yesterday, but when I went to check to see if they had finished transferring, I was disconnected from the share.  I decided to just close the folder, and reopen it, but it isn't visible at all.\nNormally under Network (both Windows and Linux), the share appears under Windows Network, then Guest.  However, Guest is no longer visible.\nI did restart the server, but this did not fix the problem.\nI did restart the services:\nservice smbd restart\nservice nmbd restart\n\nThis did not fix the problem.\nI did check /var/log/samba/log.nmbd, and got this from it:\n[2016/04/19 06:26:07.759121,  0] ../source3/nmbd/nmbd_browsesync.c:354(find_domain_master_name_query_fail)\n  find_domain_master_name_query_fail:\n  Unable to find the Domain Master Browser name GUEST<1b> for the workgroup TCR-GUEST.\n  Unable to sync browse lists in this workgroup.\n\nI've yet to find a threat that addresses this problem.\nOne other thing to note; the server has no GUI, only a command line interface.\nUpdate 1:\nI forgot to mention, when I restart, or stop and start smbd, I get this:\nstop: Unknown instance:\nsmbd start/running, process 3781\n\nI also get this from testparm -s:\nLoad smb config files from /etc/samba/smb.conf\nrlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)\nWARNING: The \"syslog\" option is deprecated\nWARNING: Ignoring invalid value 'share' for parameter 'security'\nError loading services.\n\nUpdate 2:\nHere is the smb.conf file:\n[global]\nworkgroup = WORKGROUP\nserver string = %h server (Samba, Ubuntu)\nwins support = yes\ndns proxy = no\nlog file = /var/log/samba/log.%m\nmax log size = 1000\nsyslog = 0\npanic action = /usr/share/samba/panic-action %d\n\n####### Authentication #######\nserver role = standalone server\npassdb backend = tdbsam\nobey pam restrictions = yes\nunix password sync = yes\npasswd program = /usr/bin/passwd %u\npasswd chat = *Enter\\snew\\s*\\spassword:* %n\\n *Retype\\snew\\s*\\spassword:*   >%n\\n *password\\supdated\\ssuccessfully*\npam password change = yes\nsecurity = share\nmap to guest = Bad User\n\nI appreciate any answers that you would have.\n\nA: Try commenting out the line\nsecurity=share\n\nfrom your smb.conf file. That's what it took to get mine working again. Don't forget to restart smbd and nmbd afterwards.\n", "Q: Copying bookmarks from a crashed Ubuntu disk? My Ubuntu disk crashed and I need to get a copy for my bookmarks. I tried accessing .mozilla (for my firefox bookmarks) inside my home folder by booting through a bootable cd for Ubuntu, however it tells me I don't have permissions to access the folder. How can I copy the bookmarks.html?\nI also need to copy bookmarks for the Chrome browser.\n\nA: If you didn't encrypt you home folder, take out that drive and insert it as a secondary drive into a Windows Computer. Windows ignores Linux permissions.\n", "Q: Block IP beginning with, U.F.W Someone is running a registration bot on my site and I have taken steps to prevent the registration, but now I want to block the whole IP range from even being able to access my site.\nI have set up UFW on my server, but other than entering each IP individually I cant figure out how to block all IPs beginning with 91.\nOr even better yet block *vhoster.org but I dont know how to do that either since I'm new to UFW and ubuntu server all together.\nSo how can I block this thing for good?\nIP List\nNameServer List\n\nA: Command for deny whole 91.0.0.0/8 network is\n sudo ufw deny from 91.0.0.0/8\n\nwhen you list rules \n sudo ufw status\n\nyou will see\nTo                         Action      From\n--                         ------      ----  \n...\nAnywhere                   DENY        91.0.0.0/8\n\nThis will deny any traffic from ip's witch start with 91.x.x.x\nBut I recommend to use smaller network ranges for deny traffic.\nBased on your address list\nsudo ufw deny from 91.200.12.0/24\nsudo ufw deny from 91.213.126.0/24\nsudo ufw deny from 91.207.7.0/24\n\nUFW can not create rule based on logical names aka domains, but you can add rule using iptables in chain ufw-user-input \nsudo iptables -A ufw-user-input --src vhoster.org -j DROP\n\nthis will deny traffic from whole domain vhoster.org ip's\nTo list this rules use command \nsudo iptables -L\n\n", "Q: Wireless drivers for the newer linux kernels 4.x I've recently tried to install the latest stable kernel which is 4.4.6 and when the kernel was compiled and I brought the kernel up and running, there was a problem and the wireless driver (MT7630e 802.11bgn) seemed not working. Then I tried to reinstall it using the source code and the output was like:\n\n\nmake -C /lib/modules/uname -r/build M=/home/devin/Desktop/MT7630E-release linux wireless driver/rt2x00 modules\n     make[1]: Entering directory /home/devin/linux-4.4.6'\n     arch/x86/Makefile:148: CONFIG_X86_X32 enabled but no binutils support\n     make[1]: *** No rule to make targetlinux'.  Stop.\n     make[1]: Leaving directory /home/devin/linux-4.4.6'\n     make: *** [all] Error 2\n     cp -v firmware/*/* /lib/firmware/\n     ‘firmware/BT/mt76x0.bin’ -> ‘/lib/firmware/mt76x0.bin’\n     ‘firmware/Wi-FI/MT7650E234.bin’ -> ‘/lib/firmware/MT7650E234.bin’\n     cp rt2x00/mt7630e.ko /lib/modules/uname -r/kernel/drivers/net/wireless/\n     cp btloader/mt76xx.ko /lib/modules/uname -r`/kernel/drivers/net/wireless/\n     depmod\nmodprobe: ERROR: could not insert 'mt7630e': Exec format error \n     modprobe: ERROR: could not insert 'mt76xx': Exec format error\n\n\nI was trying to figure out what seems to be a problem, based on the output I guessed the final loadable modules that got compiled, they were not matched with the arch or something, or it could be because the proper options were not set while compiling the kernel.\nNow what I need to know is to get to know the process of loading LKMs when modprobe is invoked or something's wrong with the kernel?!\nthe arch of the kernel: x86_64\n\nA: \n/home/devin/Desktop/MT7630E-release linux wireless driver\n\nThe command make doesn't like spaces in the name. Please try renaming the folder to:\nMT7630E-release\n\nOr to:\n/home/devin/Desktop/MT7630E-release_linux_wireless_driver\n\nOr something with no spaces. Then try the make, sudo make install sequence again.\n\nA: Yes, you have to replace all the  missing files of this folder:\nhttps://github.com/benjarobin/MT7630E\nwith this one\nhttps://github.com/neurobin/MT7630E/tree/e7130a42f8198cbf503a5a307175073c078bf340\nfollowing the same procedure of the last one.\nwith my ASUS N751JK on Ubuntu 14.04.4 kernel 4.2.0-35-generic\n work fine !!!\nthank you  Devin Hudson\n", "Q: How do I remove a full file? Some 32 bit (mostly lib) files were downloaded to my computer by mistake.  How do I find them all and delete them with their contents?\n\nA: If you know the name you can use \nsudo apt-get remove *packagename* \n\nto uninstall. but make sure that they don't have any dependencies.\nor use: \nsudo apt-get autoremove\n\nFrom the man page:\n\nautoremove (and the auto-remove alias since 1.1)\n             autoremove is used to remove packages that were automatically installed to satisfy dependencies for other packages and\n  are now no longer needed.\n\nor use: \nsudo apt-get clean \n\nFrom the man page:\n\nclean clears out the local repository of retrieved package files. It removes everything but the lock file from\n  /var/cache/apt/archives/ and\n             /var/cache/apt/archives/partial/.\n\nor:\nsudo apt-get autoclean \n\nFrom the man page:\n\nautoclean (and the auto-clean alias since 1.1)\n             Like clean, autoclean clears out the local repository of retrieved package files. The difference is that it only removes\n  package files that can no longer\n             be downloaded, and are largely useless. This allows a cache to be maintained over a long period without it growing out of control.\n  The configuration option\n             APT::Clean-Installed will prevent installed packages from being erased if it is set to off.\n\nplease read the manual page of apt-get\nman apt-get\n\n\nA: In case you downloaded them \"by hand\", and not via apt-get, open a console and type:\ncd \nfind . -name \"FileName\"\n\ncd will go to your home-directory\nfind will search . (the current directory) for a file with the given name. If you dont know the full filename, you can use e.g. *File*. That would list all files which have File somewhere in the name.\n(probably on Ubuntu there is as well a graphical way to search)\n", "Q: Increase disk storage I can not shrink the boot drive i.e. C anymore, in order to reuse that space for the ubuntu partition which I have installed on dual boot.\nI want to know how to shrink the F partition and merge that space into my ubuntu partition?\n\nA: You can just boot with a Ubuntu live CD (or USB), and resize everything with gparted.\n", "Q: black screen on run and install I got an Asus fz50vw-ns52 that I've been trying to install both Ubuntu 14.04 and 15.10 and with both running Ubuntu off the jump drive and trying to install it I just see a black screen (without backlight) after I make my choice and it reboots.\nI read a review when I was researching the laptop that said the laptop had not been released in the us yet and I can't find it on the Asus site. I got it of newegg.\n\nA: I have the ASUS FZ50VW-NS51 and I was able to get ubuntu to load using\ni915.preliminary_hw_support=1 nouveau.modeset=0 acpi_osi=! acpi_backlight=vendor idle=nomwait\n\nas kernel parameters (Press e at the grub menu after selecting the boot option you want).\nEdit: Any time you reboot before installing the latest nvidia drivers you will have to specify the same parameters in order to boot.\n", "Q: Ubuntu stopped working without apparent reason I'm pretty new to the Linux System, I've installed Ubuntu 14.04.4 LTS and I am more then satisfied. I'm web delevoper,and for the first time in my life everything worked right away. \nI installed nvidia driver, because with default drivers video on Amazon was choppy. It worked great, I followed instruction to the letter. For few days everything was fine, and then one they I turned on my computer my screen was black and I could see only mouse pointer and system error message. I've read so many forum posts and tried everything.\nI deleted nvidia drivers, installed and reinstalled default drivers, reinstalled desktop and triend some other things. Nothing seemd to help me, so I came here for help. I have some data and settings I would like to keep.\nAfter some time console stopped opening and \" CTRL + ALT + T \" or with combination with F1 - F3 still wont open. But I do have acces to recovery mode.\nAny help will be appriciated ? Thank you very much.\nEDIT :\nI downloaded official driver from nvidia site. I have nvidia gtx 960.\nMy system is dual boot WINDOWS and Ubuntu,\nI have 16GB RAM DDR3,\nI have Intel i7-4790K and ASUS ROG motherboard.\nWindows is on SSD and Ubuntu on HDD, it has its own partition, but windows uses another partition from the same drive as storage.\nTo remove nvidia drivers I used sudo apt-get remove --purge \"nvidia-*\".\n\nA: I suggest removing all of the NVIDIA-related packages. This should reset X to use the nouveau driver. This will at least get your graphics back in order to troubleshoot. Here's how to do that:\n\n\n*\n\n*Power off your computer. Then turn it on while holding down the shift key. This will bring up the grub menu. Use the arrow keys and enter to go to \" Advanced Options\", then the first line ending in \"Recovery Mode\" (most likely the second line.)\n\n*Now a menu should come up. Select \"Drop to root shell prompt\". This prompt has root access, so be careful.\n\n*Mount your home partition with mount -o remount,rw /\n\n*Now, run apt-get remove --purge \"nvidia-*\". This will remove all packages starting with nvidia-, which will include all the drivers.\n\n*Reboot with by running reboot, and pray that nouveau starts properly.\n\n", "Q: How to zip a directory without zipping the parents directories? I have a directory called Klox with whats of files and images.\nKlox is located in ~/Projects/Klox\nWhen I use zip -r Klox.zip ~/Projects/Klox the archive is containing all the directories until reaching Klox. /home/vk/projects/Klox\nI want the zip file to contain only the Klox folder. So people don't have to open home folder, then open vk folder then open projects and finally open Klox\n\nA: The zip utility stores paths relative to the current working directory, so you have to use cd or pushd/popd to go to ~/Projects first:\ncd ~/Projects\nzip -r Klox.zip Klox\n\nor when you want to return to the original working directory afterwards:\npushd ~/Projects\nzip -r Klox.zip Klox\npopd\n\n", "Q: How do I get name of computer to display in arp-scan? I have an ubuntu laptop and an ubuntu desktop; I have both ethernet and WiFi.  When I connect them both to the ethernet router, my desktop and laptop IP addresses display.  However, there is no name next to the IP addresses. I see that my \"NETGEAR\" device is displaying a name though. \nHow do I reproduce this with my desktop?  I added the IP address and computer name to the hosts file in /etc/hosts, but nothing happened. \n\nA: Your /etc/hosts file should look like this:\n\n127.0.0.1   localhost\n127.0.1.1   HOSTNAMEHERE\n\n# The following lines are desirable for IPv6 capable hosts\n::1     ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n\nand your /etc/hostname file should look like this:\n\nHOSTNAMEHERE\n\n", "Q: install new kernel produce the message \"No space left on device\" although there is free space I compiled the kernel 4.5 and when I tried to install it using the command dpkg -i I get the message \"No space left on device\" although there is free space in boot partition\nHere the output of the command df -h : \nFilesystem                 Size  Used Avail Use% Mounted on\nudev                       1,4G  8,0K  1,4G   1% /dev\ntmpfs                      288M  1,3M  287M   1% /run\n/dev/mapper/mint--vg-root  291G  130G  146G  48% /\nnone                       4,0K     0  4,0K   0% /sys/fs/cgroup\nnone                       5,0M     0  5,0M   0% /run/lock\nnone                       1,5G   18M  1,4G   2% /run/shm\nnone                       100M   24K  100M   1% /run/user\n/dev/sda1                  236M   50M  175M  22% /boot\n\nand the output of df -i:\nFilesystem                  Inodes   IUsed    IFree IUse% Mounted on\nudev                        364279     540   363739    1% /dev\ntmpfs                       368151     564   367587    1% /run\n/dev/mapper/mint--vg-root 19333120 1224744 18108376    7% /\nnone                        368151      13   368138    1% /sys/fs/cgroup\nnone                        368151       2   368149    1% /run/lock\nnone                        368151      57   368094    1% /run/shm\nnone                        368151      21   368130    1% /run/user\n/dev/sda1                    62248     302    61946    1% /boot\n\nHow to resolve this problem ?\nBest regards\n\nA: You're having an inode problem.  You probably have many small files somewhere that is using a very small amount of space.  Each of the files are using up your inodes.\nYou can get your inode count with this command:\n$ df -i\n\nCheck out this link to help you to locate where you inodes are being used:\nhttps://stackoverflow.com/questions/347620/where-are-all-my-inodes-being-used\n", "Q: How to scan my hard drive for problems? I would need some help to find out if there is some problems with my hard drive. Could this be done by running Ubuntu from a dvd? \nKind regards, Victor \n\nA: You could try with booting from a live CD and\nsudo apt install smartmontools\nsudo smartctl --all /dev/YOUR_DISK\n\nor the GUI version \"gsmartcontrol\".\n\nA: You can use smartctl to check for and enable SMART support\nsudo apt-get install smartmontools     \nsudo smartctl -a /dev/sda | less\n\nTo enable SMART support (if it turn off) just type:\nsudo smartctl -s on /dev/sda\n\nFor more details and reference, please check Ubuntu Help (Wiki) https://help.ubuntu.com/community/Smartmontools \n\nA: You can open the Disks utility from the menu and check the drive's SMART health status.  You can also run a self test on the drive.\n", "Q: Unable to ping hostname only IP address I'm trying to connect to my linux server via the hostname for Samba. I'm have been able to access it with no problem then all of a sudden it stopped working. Here is what is happening.\nThis is what I have done from a windows PC\n\n*\n\n*Can ping the IP\n\n*Can NOT ping the hostname\n\n*Can do nslookup and it finds the hostname\n\n*Can traceroute IP and resolves the hostname\n\n*Can ping other things on my network by hostname\n\n*If I add the IP and hostname to the hosts file on my windows PC I can ping the hostname just fine. When I rebooted my router the issue persisted. (From 1st Line Supports answer)\n\nFrom the Ubuntu 14.04 server\n\n*\n\n*Can ping self by IP and hostname\n\n*Typing \"hostname\" resolves appropriate hostname\n\n*Can ping other things on my network\n\nHere is my /etc/hosts file\n\n127.0.0.1       localhost\n127.0.1.1       servername\n# The following lines are desirable for IPv6 capable hosts\n::1     ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n\nMy DNS server is my router which does dhcp and dns via dd-wrt.\nPlease any help would be greatly appreciated!\nThanks in advance\n\nA: Add the entry for your hostname and IP address in to the /etc/hosts\nIf it works, then it is probably DNS try rebooting the router and remove the entry you have just added.\n", "Q: Android Studio umake fail: no license With v. 15.10, I follow the umake method:sudo apt install ubuntu-make; umake android; Choose installation path: /home/.... ,; Then:\n  \"ERROR: We were expecting to find a license on the download page, we didn't.\"\nMy question: what are they talking about?\n\nA: When you run umake, it checks the Android Studio website for license text, which it then prompts you to accept. It looks like the website was changed, probably when Android Studio 2.0 was released recently, so the installer can't find the license in the expected location. You can get around this by disabling the license check: umake android android-studio --accept-license.\nThere's a bug for this issue on the umake GitHub project, and it's apparently been fixed. The readme suggests using the Ubuntu Make PPA rather than the version in the Ubuntu repository to ensure that you're always using the latest version.\n\nA: Android studio and the sdk changed the download pages significantly.\nThey’ve been fixed in master, and will be working again in the next release.\nIf you need you can clone the repository and install from that.\nIt’s less than ideal, but if it can help you for the time being.\ngit clone https://github.com/ubuntu/ubuntu-make\ncd ubuntu-make\nbin/umake android\n\nRef:\nhttps://github.com/ubuntu/ubuntu-make/issues/302\n", "Q: How to insert Tensor second order notation in libreOffice Math? How to put double bar over a character in libreoffice math 5. As we use in second order tensors.\n\n\n\n\nA: At least in LibreOffice 5, it appears to be possible simply by nesting the overline command:\n\n", "Q: How to reinstall grub by ubuntu 14.04 live CD? How to reinstall grub by ubuntu 14.04 live CD?\nCould you show me the installed steps?\nThanks.\nRegards,\nDavid\n\nA: This should let you install GRUB onto your computer.\n\n\n*\n\n*Boot from the LiveCD and select the \"Try Ubuntu\" option.\n\n*Once booted, open a terminal, either by searching for it or pressing Ctrl + Alt + T.\n\n*From the terminal, run  \nsudo grub-install /dev/sdX\n\n\n\n*\n\n*Note: X is the letter assigned to your hard drive. To find this, follow the steps below.\n\n\n*Search for Gparted in the Live Environment, open it and let it scan.\n\n*Once it's finished scanning, look at the top right corner of the Gparted window.\n\n*There should be a drive name here, most likely /dev/sda. It might be sdb or sdc, though.\n\n*Whatever the letter happens to be, use that in place of X in the command above.\nIf you have any questions, just ask.\n", "Q: VirtualBox: VT-x is disabled in the BIOS for all CPU modes Error I am trying to run a Virtual Machine of Ubuntu, but I get an error on start up:\nAccording to the error message, it is an error in the BIOS. Is there a way to access it and fix this error?\nEdit: On Windows 10, I've been trying to access my BIOS. I have held down Delete at Start Up along with the new method with UEFI. I still cannot find a solution.\n\nA: You need to go to your BIOS and enable VT-x, assuming your CPU supports it. If it doesn't, then you're out of luck.\n", "Q: How to set default style for libreOffice Object Formula? When I insert a formula, I have to anchor it to paragraph. I would like to do it automatically.\n\nA: type \"fn\" in the beginning of the paragraph + press {F3} and you will have everything formatted like a charm.\n", "Q: Failed to fetch postgresql problem on Ubuntu 14.04 I am having a problem fetching data from postgresql repository. I have already uninstalled this one. But it keeps showing when I issued a \"sudo apt-get update\" command.\n\n\nA: try to continue with apt-get install postgresql since old files may have been used... If installation does not work, then consider adding another repository... a different one. I had a similar problem with mysql. You can also see that it does not find the page right? 404 page not found. Hope this helps you.\n", "Q: display rendering problem ( most text, images and window edges split into tiny lines )? \n\nedit : I put Elementary os on my old pc and I first encountered this problem. Then I tried ubuntu 15.10 the problem still persisted. I tried this on 2 led monitors and both have the problem.\nI have a built in Intel 82Q963/Q965 graphics and I tried installing their drivers but I got this message when it rebooted :\nnone of the selected modes were compatible with the possible modes: Trying modes for CRTC 63 CRTC 63: trying mode 640x480@60Hz with output at 1366x768@60Hz (pass 0) CRTC 63: trying mode 640x480@60Hz with output at 1366x768@60Hz (pass 1) Trying modes for CRTC 64 CRTC 64: trying mode 640x480@60Hz with output at 1366x768@60Hz (pass 0) [same msg](pass 1) Trying modes for CRTC 65 CRTC 65: trying mode 640x480@60Hz with output at 1366x768@60Hz (pass 0) [same msg](pass 1) \nother data that might help:\n/var/log/Xorg.0.log.\nNo LSB modules are available.\nDistributor ID:    Ubuntu\nDescription:    Ubuntu 15.10\nRelease:    15.10\nCodename:    wily\n\nlspci -nnk | grep -A2 VGA:\n00:02.0 VGA compatible controller [0300]: Intel Corporation 82Q963/Q965 Integrated Graphics Controller [8086:2992] (rev 02)\n    Subsystem: Hewlett-Packard Company Device [103c:2808]\n    Kernel driver in use: i915\n\n\nA: First thing to try is to drop to a lower resolution and see if the problem goes away.  You didn't mention at what resolution Windows is actually running, along with the refresh rate.  The dot/pixel clock is generated from other values, see\nhttp://arachnoid.com/modelines/\n Section \"Monitor\"\n    # HorizSync source: xconfig, VertRefresh source: xconfig\n    Identifier     \"Monitor0\"\n    VendorName     \"Unknown\"\n    ModelName      \"CRT-0\"\n    HorizSync       28.0 - 55.0\n    VertRefresh     43.0 - 72.0\n    Option         \"DPMS\"\nEndSection\n\nThe above goes into the xorg.conf file, which you might have to generate.  Playing around with the monitor like this is dangerous, you can destroy the monitor, start fires, etc.  Best to drop to a lower resolution.  \n\nOr a lower refresh rate, 60Hz may be too high.  You never did say what the Windows refresh rate was -- match it and the resolution.\n", "Q: PPA 404 error upon apt-get update? (related to php7) I get a 404 error upon php7 update from url http://ppa.launchpad.net/ondrej/php-7.0/ubuntu/dists/wily/main/binary-amd64/Packages\nErr ppa.launchpad.net wily/main amd64 Packages\n  404  Not Found\n\nErr ppa.launchpad.net wily/main i386 Packages\n  404  Not Found\nFetched 10.4 kB in 4s (2,397 B/s)\nW: Failed to fetch ppa.launchpad.net/ondrej/php-7.0/ubuntu/dists/wily/main/binary-amd64/Packages  404  Not Found\n\nW: Failed to fetch ppa.launchpad.net/ondrej/php-7.0/ubuntu/dists/wily/main/binary-i386/Packages  404  Not Found\n\nE: Some index files failed to download. They have been ignored, or old ones used instead.\n\nWould anyone know what I should do? Is there another/new PPA for php7?\nI removed the http before the ppa.* links because I'm not reputable enough to post more than two links. Thank you for reading.\n\nA: Alright, I fixed it. I was doing sudo apt-get install mcrypt php-mcrypt7.0 (or something like that), you need to do sudo apt-get install mcrypt php-mcrypt\nwithout the 7.0\nthe old php 7 ppa doesn't work, you need to use ppa:ondrej/php instead!\nThank you for reading.\n", "Q: GLIBCXX_3.4.21 not defined in file libstdc++.so.6 with link time reference When trying to execute any c++ programs, I get this error. The full error message is:\n./main: relocation error: ./main: symbol _ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1Ev, version GLIBCXX_3.4.21 not defined in file libstdc++.so.6 with link time reference\n\nin my /usr/local/lib64 folder they all seem to be there:\n\nlibssp.so.0.0.0\n  libstdc++.a\n  libstdc++fs.a\n  libstdc++fs.la\n  libstdc++.la\n  libstdc++.so\n  libstdc++.so.6\n  libstdc++.so.6.0.21\n  libstdc++.so.6.0.21-gdb.py\n  libsupc++.a\n  libsupc++.la\n\nin my ./include folder, all the C++stdlib headers are there, and they seem to be working as I will get errors from them if I have syntax errors or something, hell, the files even compile fine but i get this error at runtime. I have not yet tried simply reinstalling all the libraries, as i'm not totally sure if that is necessary. Can someone help explain this error to me?\nI have tried various fixes suggested on GLIB_3.4.15 error pages on this site, although either I followed those instructions incorrectly or they did not work for me.\nI am running Ubuntu 14.04 LTS, and my GCC version is 5.3.0\n\nA: This is because it's looking for a symbol from GLIBCXX_3.4.21, while you presumably have a lower version. Update your library, it's the easiest way. Or you can do something like what's done here\nhttps://stackoverflow.com/questions/4032373/linking-against-an-old-version-of-libc-to-provide-greater-application-coverage\nhttps://stackoverflow.com/questions/32577224/unable-to-use-stdchrono-with-stdfuture-glibcxx-3-4-19-not-found?noredirect=1&lq=1\n", "Q: How to dual boot install Ubuntu 15 with Windows 10: No other operating system recognized I am trying to install Ubuntu 15.10 from the directions here.\nMy machine is a Windows computer running Windows 10, which was upgraded from Windows 8.1 several months ago.\nWhen I try to run the installer, after the \"For best results page\" I get the message:\n\"This computer currently has no detected operating systems\" \nwhich I did not see when I just installed Ubuntu from the same USB stick on my Windows 7 machine.\nI have toyed around with all of the boot options in the BIOS such as:\n\n\n*\n\n*Having the computer boot in UEFI mode (default) (no change)\n\n*Having the computer boot in \"legacy os mode\"\n\n\nFinally, turning fast boot off made one difference.  Now, when tying to install I immediately get this message (before it asks about any partitioning): \n\nclicking try again always fails, clicking continue anyway leads me to the screen where I selected where I am located but I am not sure I want to continue with that installation.\nI would appreciate any help.\n\nA: Maybee you didn't shutdown your computer completely before installing your Windows 10?\nYou have to disable quick boot and you should shutdown your computer completely before you proceed with the installation.\nhttp://www.tenforums.com/tutorials/7418-shut-down-computer-windows-10-a.html\nYou should install your bootloader into mbr of your system disc (sda) and not under the root partition. If it is not installed in mbr, grub2 will not recognize the operating systems on your hard disk.\nAnother way which might eventually help you to solve the problem is to boot into your Windows 10 and install Easy-BCD 2.3. It will search for the operating systems on the hard drive and you should be able to choose which one to boot on Windows 10 start - if there is any Ubuntu boot loader installed anywhere on the hard drive (like boot loader in the root partition).\nFast boot should be / stay disabled.\n\nA: Only one hard drive is a system disc - the one that holds the system partition, and where W10 is installed. Another drive is a data partition, I supose.\nIn Ubuntu, first hard drive will be called /sda, second one /sdb and so on and the partitions are number that follows like sda1, sda2...\nSo, the boot loader must be installed in the drive itself (no numbers). If you should install in sda or sdb i can not say since I don't know where is your existing mbr installed.\nhttps://www.youtube.com/watch?v=mOtMOws7GJg\n\nA: You do not have to overwrite anything. You just need to add some space for Ubuntu.\nThe easiest way is to start with the live session (try without install or something like that). That way, Ubuntu will mount all existing partitions.\nYou can then repartition (from Gparted in Ubuntu) or also under Windows when you are in Windows session - it's completely up to you.\nUbuntu you install on that new partition or on the other drive. That's up to you.\nImportant is only where do you place your boot code, as I explained on the beginning.\nYou should als check that secure boot is disabled!\n", "Q: virtualbox ppa for 14.04 I want to add a ppa to get virtualbox updates but I can't understand the debian-based steps on their webpage (or here). Normally I add repositories with sudo add-apt-repository ...\nCan anyone explain the steps?\n\nA: First you need to add the repository to your system.  Copy and paste the following to a terminal window:\nVirtualBox no longer supports i386, so add the repository like this:\necho \"deb [arch=amd64] http://download.virtualbox.org/virtualbox/debian $(lsb_release -cs) contrib\" | sudo tee /etc/apt/sources.list.d/virtualbox.list    \n\nThen you just step through the rest from https://www.virtualbox.org/wiki/Linux_Downloads; or I put the steps below.\nYou can just copy and paste each of these steps to finish your install of VirtualBox on your system:\nAdd the key:\nUbuntu 14.04 (No longer supported):\nwget -q https://www.virtualbox.org/download/oracle_vbox.asc -O- | sudo apt-key add -\n\nUbuntu 16.04 (no longer supported) and newer (18.04 and newer are supported still):\nwget -q https://www.virtualbox.org/download/oracle_vbox_2016.asc -O- | sudo apt-key add -\n\nThen do your update and install:\nsudo apt-get update\n\nInstall Virtualbox (6.1 is the newest for now):\nsudo apt-get install virtualbox-6.1\n\nIf this is a new installation, run the following to add vboxusers group to your username:\nsudo usermod -a -G vboxusers $USER\n\nThen log out and back in for changes to take effect.\nThen after it is all installed, it is recommended to install the VirtualBox Extension Pack from here.\nHope this helps!\n", "Q: Clone external hard drive to internal hard drive The hard drive failed on my new laptop so I installed Ubuntu 14.04.2 on an external hard drive and have been using it for the past 3 months. Now that the laptop manufacturer had sent me a new hard drive I want to clone whats on external hard drive to the internal hard disk. \nI'm looking for steps to take to do this correctly. \n\nA: You could use dd, from a live CD open a terminal an type:\ndd if=/dev/sda of=/dev/sdb bs=64K\n\nJust replace /dev/sda with your external hardrive name and /dev/sdb with your internal hardrive name.\n\nA: @user2308612 is right. You can use dd for this task. It does low level copy, the partitions will remain. You asked for step by step instructions and I think they are nicely written here (pictures included): http://www.howtogeek.com/howto/19141/clone-a-hard-drive-using-an-ubuntu-live-cd/\n", "Q: Problem connecting to private IP address The value of my inet addr is different for my laptop and my router, as they are on different networks i cannot proceed with sudo apt-get update. Im new to ubuntu so dont know how to use the Network manager to rectify the manner and need detailled instructions. \n\nA: Go to the right upper corner and click the network icon, go down to the bottom and right click edit connections.\nThis opens network connections and choose the connection to change, click edit and go to IPv4 settings. \nFor manual configuration\nChoose Method: Manual and then fill in the Address, Netmask and Gateway ... and your desired DNS server.\n\nIf you router have configured DHCP - Dynamic Host Configuration Protocol you can from manual switch to Automatic DHCP. Router will give you ip, nm, gw, dns\n", "Q: How to disable a touchscreen on Surface pro 3 Long story short, I dropped my surface and the screen cracked. \nThis is causing it to have false touches pretty frequently. I managed to disable it on my windows partition where I'm typing this from. But of the two suggested methods I've found:\n\n\n*\n\n*Either disabling it from xinput\n\n*Add Option \"Ignore\" \"on\" to 10-envdev.conf to the end of the section that said touchscreen\nhave not been successful.\n2 being so not successful that it completely broke my ubuntu distribution\nAddition bits of info:\nThe computer in question is a Surface Pro 3\nIt was running ubuntu 15.10\nYour help would be very much appreciated.\n\nA: Was in the same boat. \n\n\n*\n\n*Run xinput to list out the input devices. Your touchscreen should show as one of the \"pointers\".\n\n*xinput disable \"NTRG0001:01 1B96:1B05\" (your device ID may differ than mine)\n\n*Add this to your ~/.bashrc or such to do automatically upon login\n\nUPDATE: If you are able to attach an external monitor, using arandr to deactivate the tablet's monitor will also disable the pointer device. \n", "Q: Installing Ubuntu on Acer V-3-574G I just bought myself a Acer V3-574G with core i7 and Nvidia Geforce 940m 2gb vga with 12gb Ram with factory installed Win-10. I am having problem installing any linux distro on it even after I dissable UEFI. Coluld somebody please tell me how I could install linux on this computer.\nThank you\nNick.\n\nA: With Acer it could be a BIOS problem. Go look at Acer support pages if there is an BIOS update for your (EXACT) model of computer. If yes, follow the instructions there to install it. I had to do it with Lenovo. In my case the BIOS update was only possible in Windows.\n", "Q: Select/copy/paste in terminal using only the keyboard I'm looking for a way to select, copy and paste the text in the terminal completely without the mouse.\nI've been using tmux until now, but I find its key combinations a bit complex for everyday use of copy & paste, and I'm now looking for alternatives. \nDo you guys have any suggestions?\nTo be clear, this is not about piping to the clipboard but about selecting the text as it's possible in e.g. tmux!\n\nA: You could use screen selection mode.\nEnter a screen session using screen command.\nThen, use Ctrl+a and Esc to enter into the selection mode.\nYou can then move your cursor, select some text using space, quit the selection mode, and paste it when you want with Ctrl+a and ].\nMore information here: http://web.mit.edu/gnu/doc/html/screen_11.html\n\nA: To copy, use Ctrl+Shift+C\nTo paste, use Ctrl+Shift+V or Shift+insert\nAnother way to do this:\nFirst run command screen, after then can do following steps:\n\n\n*\n\n*Press Ctrl+a+Esc It will put the screen in copy mode.\n\n*Now, move the cursor to the beginning of the section to copy & hit enter.\n\n*then, move the cursor to the end of the section to copy & hit enter.\n\n*Now, press Ctrl+a+] to paste.\n\n\nA: Consider xclip, which is a command-line interface to the X clipboard, and is available with sudo apt-get install xclip.\nYou may have noticed that in Ubuntu, if you select some text and then press the middle mouse button, that text will get pasted into whatever input is in focus. xclip hooks right into that, so if you run seq 10 | xclip -i then middle-mouse somewhere, you'll paste the numbers 1 to 10. If you were to select my username then run xclip -o | cowsay, you'll get a cow saying the word \"ymbirtt\".\n\nA: I always use Ctrl+Shift+C and Ctrl+Shift+V to copy and paste in my (non tmux) terminal.\nYou can change these keyboard shortcuts in the keyboard preferences of your (non-tmux) terminal.\nIf however you want to keep using tmux you can also change the keyboard shortcuts of tmux by adding commands to ~/.tmux.conf. simply add the following in that file:\nbind-key -n [shortcut. for example Ctrl+v is C-v] [what you want to do. for example 'new-window' etc]\n\nIt will look like this\nbind-key -n C-t new-window\n\nYou don't need the command prefix key to execute the commands in the ~/.tmux.conf file.\nFor more info about the things available for ~/.tmux.conf check this link\nVery rudimentary copying and pasting can be done using this however for a bit more usefulness I recommend using a Vim-style copy/paste config.\nEnabling a Vim-style of copy/paste can be done with this config file or another config file. These do however require the use of the prefix key.\nSomeone even made a tmux extension to simplify the copy/paste action to the system clipboard in tmux. It might be worth a look.\nIf you want an alternative for Tmux you might try dvtm (sudo apt-get install dvtm dtach). I haven't used it myself but it looks like it has similar options.\n\nA: It can be done with emacs.\n\n*\n\n*Open emacs\n\n*Alt-X + term: opens a terminal in a new emacs buffer\n\n*Ctrl-C+Ctrl-J: enter line mode (more details on the modes below)\n\n*Select the desired text\n\n*Alt-W: copy the text\n\n*Ctrl-C+Ctrl-K: go back to char mode\n\n*Ctrl-Y: paste\n\nRemarks on line-mode and char-mode\nIn char-mode, each character you type is sent to the terminal (like in any terminal) and most emacs shortcuts are disabled (to enable terminal shortcuts). In particular, don't be surprised if shortcuts to change the buffer do not work. To change the buffer, you must first enter line mode. In line mode emacs behave like in a normal emacs buffer. More details here.\n", "Q: php extension fileinfo install in Ubuntu(15.10) I have tried to install php fileinfo extension in Ubuntu(15.10) and getting errors:\nsudo pecl install fileinfo\n\nError:\nWARNING: \"pear/Fileinfo\" is deprecated in favor of \"channel://php-src/ext/fileinfo/in php sources\"\nWARNING: channel \"pear.php.net\" has updated its protocols, use \"pecl channel-update pear.php.net\" to update\ndownloading Fileinfo-1.0.4.tgz ...\nStarting to download Fileinfo-1.0.4.tgz (5,835 bytes)\n.....done: 5,835 bytes\n3 source files, building\nrunning: phpize\nCannot find config.m4.\nMake sure that you run '/usr/bin/phpize' in the top level source directory of the module\n\nIf the command failed with 'phpize: not found' then you need to install php5-dev packageYou can do it by running 'apt-get install php5-dev' as a root userERROR: `phpize' failed\n\nand then I tried this command:\nsudo apt-get install php5-dev\n\nOutput:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nphp5-dev is already the newest version.\nThe following packages were automatically installed and are no longer required:\n  linux-headers-4.2.0-16 linux-headers-4.2.0-16-generic\n  linux-image-4.2.0-16-generic linux-image-extra-4.2.0-16-generic\n  linux-signed-image-4.2.0-16-generic\nUse 'apt-get autoremove' to remove them.\n0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\n\nHow I can install php fileinfo extension?\n\nA: From the error message you provided here, you will need to run /usr/bin/phpize command in the top level source directory of the module.\nYou will only need to install the php5-dev package if the previous step failed with the phpize: not found error message (which is unlikely to happen, as you already have it installed)\n", "Q: Repository adding > problem After running those two commands:\nsudo add-apt-repository ppa:tualatrix/next\nsudo apt-get update\n\nI am getting this output:\nReading package lists... Done\nW: The repository 'ppa.launchpad.net/tualatrix/next/ubuntu xenial Release' does not have a Release file.\nN: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\nE: Failed to fetch ppa.launchpad.net/tualatrix/next/ubuntu/dists/xenial/main/binary-amd64/Packages  404  Not Found\nE: Failed to fetch ppa.launchpad.net/tualatrix/next/ubuntu/dists/xenial/main/binary-i386/Packages  404  Not Found\nE: Some index files failed to download. They have been ignored, or old ones used instead.\n\nI don't really understand the error in the last few lines.\n(Had to remove the http: before the ppa (no more then 2 Links...)\nIf I dismiss these errors.\nThe installation of ubuntu-tweak does not work\nsudo apt-get install ubuntu-tweak\n\nThis output:\nniclas@ThinkPad:~$ sudo apt-get install ubuntu-tweak\n[sudo] password for niclas: \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package ubuntu-tweak\n\nWould be thankfull for any help\n\nA: use this repository\nsudo add-apt-repository ppa:tualatrix/ppa\n\n\nA: If you don't succeed to install Ubuntu tweak from ppa, you can install it from debian package (.deb) following these steps:\n\n\n*\n\n*Download package from Ubuntu Tweak website.\n\n*Open terminal and change your working directory where you downloaded the file (e.g Download directory).\ncd Download\n\n\n*Now you can install Ubuntu Tweak with this command:\nsudo dpkg -i <package>\n\n(change <package> with .deb name, e.g. ubuntu-tweak_0.8.7-1-trusty2_all.deb)\n\nYou can get more info about dpkg command reading manual with this command:\nman dpkg\n\nI hope this could help you.\n\nEDIT:\nIf your error is caused by some missing packages  you can try to solve it with the following command that will fix package dependencies:\nsudo apt-get install -f\n\nAfter this you can try to reinstall Ubuntu-tweak.\nIf previous solution doesn't work, it could means that Ubuntu Tweak package could be not ready for Ubuntu 16.04, since last update was made two years ago. I didn't find any information about compatibility with Ubuntu 16.04 neither on ubuntu wiki nor on official website. Hence I suggest to you to wait for a while and see if it will be released a new version.\nMeanwhile you can try to install unity-tweak-tool. It is a similar program that let you tweak some aspects of Unity. There isn't an Apps manager or Janitor, but if you only want to change appearance you can use it. You can install it with this command:\nsudo apt-get install unity-tweak-tool\n\n", "Q: Dual booting (Ubuntu over Windows) directly to Windows 10 Problem Case: Dual booting with Ubuntu (efi/gpt scheme) over Windows (efi/gpt scheme) and My HP pavilion is booting directly to Windows 10.\nDetails:\nPreviously installed Windows 10 with UEFI, fast start-up, secure boot enabled.\nLater installed Ubuntu (GPT partition scheme for Uefi computers and chose Install Ubuntu alongside Windows)\nInstallation was successful  and after a restart, Computer booted successfully into Ubuntu.\nBut Ubuntu was unable to access Windows (C drive partition), and suggested to disable fast-startup, so I disabled Fast start-up in Windows. After shutdown and power up, computer is booted directly to Windows 10. Tried many times, but every-time unable to choose OS. \nstrangely, EasyBCD showing Windows 10 as the only installed OS. \nEnabled fast start-up in Windows 10 again but in vain.\nDid a boot repair using Ubuntu Live USB [as explained here]\nRan these commands (one by one)\nsudo add-apt-repository ppa:yannubuntu/boot-repair\nsudo apt-get update\nsudo apt-get install -y boot-repair && boot-repair\n\nafter third command it gave error as 'no boot-repair found'\nThis was never a case with Ubuntu over Windows 7. \nIs it because Windows 10 is installed with efi/gpt scheme?\nWhat about following combination (Dual boot with Ubuntu over Windows 10).\nWhich of these cases is best for dual booting to prevent this problem.\n\n\n*\n\n*Windows (MBR scheme) and Ubuntu (MBR scheme)\n\n*Windows (efi/gpt scheme) and Ubuntu (efi/gpt scheme) [my problem case]\n\n*Windows (efi/gpt scheme) and Ubuntu (MBR)\n\n\nA: In my case I had to disable Secure boot in the BIOS first. Install Windows 10 and then Install Ubuntu.\n", "Q: What is oem-wireless-dw1550-1160187-dkms? I am new to Ubuntu. Can anyone please tell me what oem-wireless-dw1550-1160187-dkms package is and what it does? I am always getting the error below whenever I install or upgrade anything.\n\nErrors were encountered while processing: oem-wireless-dw1550-1160187-dkms\n\nWhen I run dkms status:\nintel-i915-backport-3.8-dkms, 3.8.6.0: added\noem-bt-dw1550, 0.1: added\noem-sdcard-o2micro, 1.0: added\noem-wireless-bluetooth-intel-7260, 3.10.20130828: added\n\nThe laptop model is Latitude-E7440. \nThanks.\n\nA: This is an issue with the BCM4352 aka Dell 1550 WLAN hardware. People running Linux got so frustrated with the driver that the proposed solution is: rip out the card, buy Intel.\nTry 16.04 if possible. You need the latest driver to have a chance with it.\n", "Q: How to remove the old Installation of Ubuntu I forgot my password and I decided to reinstall Ubuntu with the last version. Now, how can I get rid of the old version? I use VM Virtualbox as emulator.\nI must say that I am and old COBOL developer and everything is new here for me.\n\nA: Download the new system as an .iso file. Add this file to the list of Storage devices for this machine in Virtualbox. \nThen, with the virtual machine powered off, adjust the boot order under Settings, so the machine will boot off the .iso instead of the hard disk. Then start the machine. It will ask you if you want to install the new Ubuntu over the old one. You want the \"use the whole disk\" option (unless there is some data on it that you want to keep).\n\nA: If you don't intend to keep anything from the previous install, right-click on the virtual machine in Virtualbox, and click Remove.\nThen create a new Ubuntu by clicking \"new\" and following the prompts. This makes things really easy if you are not comfortable with Virtualbox.\n", "Q: Cutting out using DD command I need to cut out a partition, using DD command. How do I achieve this? In my case I need to copy from block 205267 to (including this block) 29311545. The blocksize is 512 Bytes.\n\nA: You can achieve this with:\n\n# make sure you set the right paths for sdX\ndd if=/dev/sdX of=~/outputfile bs=512 skip=205266 count=29106280\n\nExplanation of options:\n\n if=     describes the inputfile path\n of=     describes the output file path\n bs=     states the blocksize in bytes\n skip=   skips bs size blocks at the beginning of input file\n count=  read N blocks (so in your case N = (End+1)-Begin)\n\n", "Q: How to add new Users to Ubuntu tablet BQ M10? I have just unboxed my all-new BQ Aquaris M10 Ubuntu Edition and started it for the first time. The device comes with Ubuntu 15.04 pre-installed.\nWhile playing around, I was unable to find any setting menu to add new users to the device. One of the main reasons for my decision to wait four years for an Ubuntu powered tablet was to have all users use their own system account.\nUpdate: I have added a Terminal app from the Ubuntu store. I opened a root console and tried \n# adduser USERNAME --ingroup phablet\n\nThis is what happens:\nAdding user `USERNAME' ...\nAdding new user `USERNAME' (1002) with group `phablet' ...\nuseradd: cannot lock /etc/passwd; try again later.\nadduser: `/usr/sbin/useradd -d /home/USERNAME -g phablet -s /bin/bash -u 1002 USERNAME' returned error code 1. Exiting.\n\nError code 1 for useradd command says Can't update password file according to http://linux.die.net/man/8/useradd \nSo, how to add and edit user profiles on the tablet?\n\nA: To add users via the gui :\ngo to the System Settings (the cog icon) -> User Accounts\n\nIf you want to add users via the cli:\nsudo adduser USERNAME --ingroup phablet\n\nIf you still have problems:\ncheck the permissions of the password file:\n    ls -l /etc/passwd \nthey should be -rw-r--r-- and belong to root:root\nyou can fix this with chmod to change permissions\nand chown to change owners. For info on how to use\nthose commands postfix --help to see thier options.\n", "Q: Ubuntu 14.04 syslog showing @@@@ for long time period My Ubuntu Server wasn't accessible for a long time, only after restarting the server I could access it again. I have checked the syslog file which shows something like @@@@@@@@@@@@@ from last night until the point I restarted the system. What is it?\n\nA: Typically a bunch of @@@@ in a log file are actually 0X00 bytes, and are due to some sort of crash or failure event where things have gone astray. Typically, the only recovery is a hard reset, as you found in your case. You should examine all the files in `/var/log' to try to gain insight into what happened.\n", "Q: ubuntu server 14.04 LTS too slow Last two weeks my ubuntu server is too slow. It happens every day. All the services are pretty slow or died. Reboot server helps for 4-5 hours and after that issue occurs again.\nI've made screenshots for top command: \n\n\n*\n\n*right after reboot server (all services like proftpd, apache, mysql work fine): https://gyazo.com/3714f56db283baf9bf169dcabc08a152\n\n*after 8-9 hours: https://gyazo.com/0efce9186e6459f9451a3e25acf1a5be\nAs I see free memory were decreased. Maybe that is the root of the issue? But what cause it ? Can anyone help ?\n\n\nA: First to check your hardware.  Run MemTest86 at least 24 hours to make sure your memory is not root cause.\nDue to sendmail-mta hangs, my experience is due to DNS issue (by gethostent) or YP/NIS issue (if you have installed nis).\nTry this command to see whether you have installed nis.\ndpkg -l nis\n\nIf yes, try to remove it by apt-get remove nis if you don't need nis service.  Otherwise, you might need to check YP/NIS settings. (like nisdomainname to see your YP/NIS domain is properly set, and ypwhich to see if NIS client is working)\nTry this commands to see whether it's gethostent issue:\n# to see if it's very slow when system is abnornormal.\nping www.google.com\n\nIf you have root permission, you might want to use strace to debug sendmail-mta to verify which syscall blocks your process, and it would help a lot.\n\nA: The screenshots are showing a server with modest RAM, but apparently OK as you aren't using swap space even on the 10 hour one, and it's usually swap that kills a computer's speed if it's a memory problem.\nI think you need to run & monitor top to see if it varies much & uses swap space when it is slow, also to see if there's a CPU hog.\nI use a utility called gkrellm as a side-bar which shows up disk & network accesses as well, this might shed more light on what's slowing it down.\nThere is also slabtop which is a lot less easy to interpret, but gives RAM use in more detail.\n", "Q: flash player working in firefox and not in chrome I have ubuntu 14.04 and latest firefox and chrome versions, videos are working on firefox normally but on chrome is not working, I tried both \nsudo apt-get install pepperflashplugin-nonfree\n\nand\nsudo apt-get install adobe-flashplugin\n\nand it didn't make any difference\n\nA: Try:\necho application/x-shockwave-flash\nswf swfl > ~/.mime.types\n\nYou may need to log out and back in.\n", "Q: Unable to install java 8 on Ubuntu 14.04 32 bit I used the following code to install openjdk 7 and to add repository,\nsudo apt-get install openjdk-7-jdk\nsudo apt-add-repository ppa:webupd8team/java\n\nThen I have updated the packages using sudo apt-get update, After this when I try to install Java using the following command,\nsudo apt-get install oracle-java8-installer\nI am getting error, the error code response is,\n2016-04-20 13:00:45 (442 MB/s) - ‘jdk-8u77-linux-i586.tar.gz’ saved [5165]\nDownload done.\nRemoving outdated cached downloads...\nsha256sum mismatch jdk-8u77-linux-i586.tar.gz\nOracle JDK 8 is NOT installed.\ndpkg: error processing package oracle-java8-installer (--configure):\n subprocess installed post-installation script returned error exit status 1\nErrors were encountered while processing:\n oracle-java8-installer\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nHow to debug and resolve this, I am new to Ubuntu. Thanks.\n\nA: it seems that your download is corrupted.\n\n[..] sha256sum mismatch jdk-8u77-linux-i586.tar.gz [..]\n\nTry to remove the package\nsudo apt-get purge oracle-java8-installer\nsudo apt-get clean\nsudo apt-get update\n\nthen remove the repo and reimport it\nsudo add-apt-repository --remove ppa:webupd8team/java\nsudo apt-get update\nsudo apt-add-repository ppa:webupd8team/java\n\nand reinstall the package\nsudo apt-get update\nsudo apt-get install oracle-java8-installer\n\nupdate:\nif you want to install java you can use this code instead of the last line :\nsudo apt install default-jdk\n\n\nA: I had a similar problem. Looking at /var/cache/oracle-jdk8-installer, I noticed the jdk-8u111-linux-x64.tar.gz was only 5.3kB. I deleted it , downloaded the correct file from http://www.oracle.com/technetwork/java/javase/downloads/index.html and then put it in the /var/cache/oracle-jdk8-installer folder then reran\n$sudo apt-get install oracle-java8-installer\nfollowed by\n$ sudo apt install oracle-java8-set-default\nand it installed correctly. \n", "Q: Can't use Ubuntu 14.04 I installed ubuntu 14.04 on my machine but unfortunately I can't use it !\nAt first, I had this famous error :\nerror: line '/grub/i386-pc/normal.mod' not found\nI looked on the Internet and I found that it is necessary to reinstall grub2.\nAfter the installation, I found this screen:\n\nand when I click Ubuntu I got this error:\n error: unknown filesystem\n Entering rescue mode...\n grub rescue>\n\nI tried to apply this solution but it doesn't work!\nWho has an idea please?\n\nA: Download and run Gparted, you can download it from here:\nhttp://gparted.org/download.php\nIt's a live ISO so burn to cd and run. Then delete all partitions on the hard drive. Then remove the Gparted from the dvd-rom and insert the Ubuntu install disc. Now run the Ubuntu install from scratch.\n\nA: After several manipulations and searches, I reinstalled Ubuntu 14.04 by making a new partition of my hard disk ! (except that I lost my Windows).\n", "Q: Postgis installation on Ubuntu 15.10 server gives dependencies error I am trying to install Postgis on Ubuntu server 15.10 using the following command:\nsudo apt-get install postgresql-9.5-postgis-2.2\n\nbut I am getting following error:\nThe following packages have unmet dependencies:\npostgresql-9.5-postgis-2.2 : Depends: libgdal1h (>= 1.9.0) but it is not installable\n\n\nA: The package name for libgdal1h has been changed to libgdal1i after 15.04 Vivid.\nAlso, it looks like this postgresql-9.5-postgis-2.2 package is available only in 16.04 Xenial.\nYou should try to install postgresql-9.4-postgis-2.1 for 15.10 Wily instead, just run sudo apt-get install postgresql-9.4-postgis-2.1, check the launchpad postgis package page for more detail.\n", "Q: Rename files adding their parent folder name I want to rename file name with its parent folder name, adding the folder name before the current name.\nfor example:\nFolder structure\nSOCH NC KT 633-ROYAL BLUE-MULTI\n|\n| 1.jpg\n|\n| 2.jpg\n|\n| 3.jpg\n\nExpected Result\nSOCH NC KT 633-ROYAL BLUE-MULTI\n|\n|_SOCH NC KT 633-ROYAL BLUE-MULTI1.jpg\n|\n|_SOCH NC KT 633-ROYAL BLUE-MULTI2.jpg\n|\n|_SOCH NC KT 633-ROYAL BLUE-MULTI3.jpg\n\nSOCH NC KT 710-BLACK-MULTI\n\nCould anyone advise how this can be done in a .sh file? Is there any utility is available to do the operation?\n\nA: In a small python script, renaming files recursively (folders as well as sub folders):\n#!/usr/bin/env python3\nimport shutil\nimport os\nimport sys\n\ndr = sys.argv[1]\n\nfor root, dirs, files in os.walk(dr):\n    for f in files:\n        shutil.move(root+\"/\"+f, root+\"/\"+root.split(\"/\")[-1]+f)\n\nHow to use\n\n\n*\n\n*Copy the script into an empty file, save it as rename_files.py\n\n*Run it with the directory as an argument:\npython3 /path/to/rename_files.py /directory/with/files\n\nNote\nAs always, first try on a sample!\nExplanation\nThe script:\n\n\n*\n\n*Walks through the directories, looking for files.\n\n*If files are found, it splits the path to the file with the delimiter \"/\", keeping the last in the row (which is the parent's folder name) , to be pasted before the file's name:\nroot.split(\"/\")[-1]\n\n\n*Subsequently, move the file to the renamed one:\nshutil.move(root+\"/\"+f, root+\"/\"+root.split(\"/\")[-1]+f)\n\n\nA: You can do this with rename:\nrename -n 's/(.*)\\//$1\\/$1/' */*\n\nThis command needs to be started in the directory directly above the directories you want to process. It will first only list the changes for you to check, if you're happy with the results run it without -n to perform the renaming.\nExample run\n$ tree\n.\n└── SOCH NC KT 633-ROYAL BLUE-MULTI\n    ├── 1.jpg\n    ├── 2.jpg\n    └── 3.jpg\n$ rename 's/(.*)\\//$1\\/$1/' */*\n$ tree\n.\n└── SOCH NC KT 633-ROYAL BLUE-MULTI\n    ├── SOCH NC KT 633-ROYAL BLUE-MULTI1.jpg\n    ├── SOCH NC KT 633-ROYAL BLUE-MULTI2.jpg\n    └── SOCH NC KT 633-ROYAL BLUE-MULTI3.jpg\n\nExplanation\nrename 's/(.*)\\//$1\\/$1/' */*\n\n\n\n*\n\n*s/a/b/ – substitute a by b\n\n*(.*)\\/ – take everything until (excl.) the last slash saving it as group 1 \nand substitute it by\n\n*$1\\/$1 – group 1 (dir name), a slash and group 1 again (file name prefix)\n\n\nA: Using only shell (bash) with a little help from mv:\n#!/bin/bash\nshopt -s globstar  ##globstar will let us match files recursively\nfiles=( /foo/bar/**/*.jpg )  ##Array containing matched files, mention where to search and what files here\nfor i in \"${files[@]}\"; do \n    d=\"${i%/*}\"  ##Parameter expansion, gets the path upto the parent directory\n    d_=\"${d##*/}\"  ##gets the name of parent directory\n    f=\"${i##*/}\"  ##gets the file name\n        echo mv \"$i\" \"$d\"/\"${d_}\"\"$f\"  ##renaming, remove echo after confirming what will be changed and you are good\ndone\n\nExample:\n$ shopt -s globstar\n$ files=( /foo/bar/**/*.jpg )\n$ for i in \"${files[@]}\"; do d=\"${i%/*}\"; d_=\"${d##*/}\"; f=\"${i##*/}\"; echo mv \"$i\" \"$d\"/\"${d_}\"\"$f\"; done\nmv /foo/bar/KT/633-ROYAL/4.jpg /foo/bar/KT/633-ROYAL/633-ROYAL4.jpg\nmv /foo/bar/KT/633-ROYAL/5.jpg /foo/bar/KT/633-ROYAL/633-ROYAL5.jpg\nmv /foo/bar/KT/633-ROYAL/6.jpg /foo/bar/KT/633-ROYAL/633-ROYAL6.jpg\nmv /foo/bar/KT/633-ROYAL/BLUE-MULTI/1.jpg /foo/bar/KT/633-ROYAL/BLUE-MULTI/BLUE-MULTI1.jpg\nmv /foo/bar/KT/633-ROYAL/BLUE-MULTI/2.jpg /foo/bar/KT/633-ROYAL/BLUE-MULTI/BLUE-MULTI2.jpg\nmv /foo/bar/KT/633-ROYAL/BLUE-MULTI/3.jpg /foo/bar/KT/633-ROYAL/BLUE-MULTI/BLUE-MULTI3.jpg\n\n\nA: Here's a small example of how that can be done form the directory you want to edit.\n$> ls                                                                          \nfile1.txt  file2.txt  file3.txt\n$> pwd\n/home/xieerqi/testing_dir\n$> find . -type f -printf \"%f\\0\" | \\                                           \n> while IFS=\"\" read -d \"\" filename ; do \\                                      \n> echo $filename ${PWD##*/}_$filename   ; done\nfile2.txt testing_dir_file2.txt\nfile1.txt testing_dir_file1.txt\nfile3.txt testing_dir_file3.txt\n\nReplace echo with mv or cp for copying or moving as necessary\n\nA: Bash solution, executing from folder where filenames you want to change are placed. You have to change workdir to your path\n#!/bin/bash\n\nshopt -s globstar\n\nworkdir=\"/path/to/your/dir\"\n\nfor folder in $workdir/**/*;do\n  if [[ -d \"$folder\" ]]; then\n    for file in \"$folder\"/*;do\n        if [[ -f \"$file\" ]]; then\n            fi=\"`basename \"$file\"`\"\n            fo=\"`basename \"$folder\"`\"\n            mv \"$file\" \"$folder/$fo$fi\"\n        fi\n    done\n  fi\ndone\n\nIt will change all files in all directories recursively from your workdir .\n\nA: Yet another bash-only approach, to be executed in the folder where the files that need renaming reside:\nfor f in * ;  do mv \"$f\" \"$(basename \"$(pwd)\")\"_\"$f\" ;  done\nThis will also handle file and folder names with spaces.\n", "Q: Epson xp205 printer status \"stopped\" Ubuntu 16.04 beta2  printer Epson xp205.  After a bit of working around I got the Epson driver installed.  All looks good except that the printer status is \"stopped\"  Tried releasing job but still at stopped.  \nJobs show in print queue and the printer is enabled.  \nI did a clean install of 16.04 due to the problems I was having with Ubuntu 15.10, but I have many of the same problems in 16.04 plus a few more.\nWhat should I do?\n\nA: Try deleting all the print jobs in the queue and turning the printer off for 30 seconds.\nUnder the printers properties check that 'Enabled' is ticked and the error policy is set to 'Retry job'.\nIf these don't work paste the output from lpinfo -v into your question and attach /var/log/cups/error_log.\n", "Q: Perl: warning: Setting locale failed I have problems when installing the tool and performing upgrades in Ubuntu 14.04 LTS. Please assist me\n    Fetched 6738 kB in 1min 19s (85.1 kB/s)                                        \nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n    LANGUAGE = \"en\",\n    LC_ALL = \"en_GB.UTF-8\",\n    LC_TIME = \"id_ID.UTF-8\",\n    LC_MONETARY = \"id_ID.UTF-8\",\n    LC_ADDRESS = \"id_ID.UTF-8\",\n    LC_TELEPHONE = \"id_ID.UTF-8\",\n    LC_NAME = \"id_ID.UTF-8\",\n    LC_MEASUREMENT = \"id_ID.UTF-8\",\n    LC_IDENTIFICATION = \"id_ID.UTF-8\",\n    LC_NUMERIC = \"id_ID.UTF-8\",\n    LC_PAPER = \"id_ID.UTF-8\",\n    LANG = \"en_US.UTF-8\"\n    are supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\nCan't exec \"locale\": No such file or directory at /usr/share/perl5/Debconf/Encoding.pm line 16.\nUse of uninitialized value $Debconf::Encoding::charmap in scalar chomp at /usr/share/perl5/Debconf/Encoding.pm line 17.\nUnescaped left brace in regex is deprecated, passed through in regex; marked by <-- HERE in m/^(.*?)(\\\\)?\\${ <-- HERE ([^{}]+)}(.*)$/ at /usr/share/perl5/Debconf/Question.pm line 72.\nUnescaped left brace in regex is deprecated, passed through in regex; marked by <-- HERE in m/\\${ <-- HERE ([^}]+)}/ at /usr/share/perl5/Debconf/Config.pm line 30.\nPreconfiguring packages ...\ndpkg: warning: 'ldconfig' not found in PATH or not executable\ndpkg: error: 1 expected program not found in PATH or not executable\nNote: root's PATH should usually contain /usr/local/sbin, /usr/sbin and /sbin\nE: Sub-process /usr/bin/dpkg returned an error code (2)\n\n\nsudo apt-get install locales\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n libc6 : Breaks: locales (< 2.22) but 2.13+git20120306-12.1 is to be installed\n         Recommends: libc6-i686\nE: Error, pkgProblemResolver::Resolve generated breaks, this may be caused by held packages.\n\nsudo apt-get install libc6-i686\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nPackage libc6-i686 is a virtual package provided by:\n  libc6 2.19-0ubuntu6.7 [Not candidate version]\n  libc6 2.19-0ubuntu6 [Not candidate version]\n\nE: Package 'libc6-i686' has no installation candidate\n\n\nA: Try:\nlocale-gen id_ID.UTF-8\n\nHowever, some PPA might not be installed unless LC_ALL=C sets, e.g. PPA for PHP.\n", "Q: Ubuntu 16.04 LTS Can't Restart I am using Acer laptop. I have nvidia 940m. Whenever I restart laptop, my screen freeze and display breakdown intro pieces shown in the figure below. \nI tried editing grub reboot=pci , acpi , bios , efi etc  but none worked. \n\nUbuntu: 16.04\nGPU: NVidia 940m    \n\nA: I also has this problem. but it's solved, when i replace my kernal to 4.4.15.\nlink for kernal 4.4.15\n\n\n*\n\n*download the link on it.\n\n*if your computer is 64 bit download first 4 link.\n\n*and extract to a specific folder.\n\n*open a terminal from there.\n\n*and write the code.\nsudo dpkg -i *.deb\nthat's all.....\n\nA: You can restart with the command of restarting.\nman reboot\n\nto shut down \n\nshutdown -r now\n\n", "Q: Advice on best remote control solution for Ubuntu from Windows I have a laptop which is running Ubuntu 14.04 (will switch to 16.04 tomorrow). I use this laptop for university, which consists of programming and database management (Oracle). Seeing as the laptop is the only place where I am using Linux, I try to work on my laptop as much as I can (especially for homework). \nSo, to the point: I want to control my Ubuntu laptop from my desktop at home. Both laptop and desktop are on the same network, so LAN remote control would be possible (if it exists). I care about a few things, listed below in order of priority:\n\n\n*\n\n*Low latency, lag-free\n\n*Able to use my two monitors that I have on my desktop\n\n*Full-screen usage, without any silly borders\n\n*Audio optional, but would be nice to have if it's high quality\n\n\nCould you, experienced Linux users, give any recommendations as to what remote-control program I want to use that fits my criteria? \nI don't mind paying for it!\n\nA: One option i can recommend is Teamviewer which is free for personal use, easy to set up, avaiable for a lot of platforms.\nLink to developer website. \n", "Q: Preventing tearing / ripping noises from speaker I own a Lenovo Y500 and run Ubuntu 15.10 on it. The laptop is getting a bit old and the speakers are wearing out especially the left one.\nI have noticed that when I play certain high pitch songs it gives a ripping/tearing noise. I have adjusted the left/right balance to compensate for that. Is there a way to filter certain frequency sounds for my speaker.\nOr is there a better way to handle this (besides buying a new laptop/speaker)?\n\nA: Speakers that have been overdriven tend to melt the glue on the voice coil, so the wires rub on the magnet - often there will be a resonant frequency + harmonics, so you will find a range of notes hit this - it really isn't practical to run an active filter all the time, but if you have a 'tone' control on the speaker it might help.\nExternal speakers aren't expensive, I have a £10 bluetooth one from Lidl which is more than adequate for a laptop...\n\nA: If you are OK with opening up your laptop it is easy to test and change its speakers. They will be at the front just behind the speaker grills. They normally just lift out. \nBe very gentle with them. The cones are made of paper. Look at the cone of the faulty speaker very carefully to see if it is creased or torn. Press down very gently on the centre of the speaker. If you feel and hear a grating noise as the cone moves there are forign objects such as metal filings between the coil on the cone and the magnet. You may be able to clean this out with a fine artists brush or by sucking using a drinking straw. Do not use a vacuum cleaner. It is too powerful and will damage the speaker.\nIf you need to replace the speaker, photograph the speaker showing which wire goes where (there are only two). Read the manufactures name and part number and enter this in eBay. It will probably be available for a trivial amount. When it arrives unsolder the old speaker and solder the new one to the wires.\n", "Q: How can I install OpenJDK on Ubuntu 16.04? Since I upgraded to the latest version of Ubuntu, I cannot install the Java OpenJDK package needed to compile Android custom ROMs. When I run sudo apt-get install openjdk-7-jdk, the following error appears:\nReading package lists... Done Building dependency tree        Reading\nstate information... Done Some packages could not be installed. This\nmay mean that you have requested an impossible situation or if you are\nusing the unstable distribution that some required packages have not\nyet been created or been moved out of Incoming. The following\ninformation may help to resolve the situation:\n\nThe following packages have unmet dependencies:  openjdk-7-jdk :\n Depends: openjdk-7-jre (= 7u51-2.4.6-1ubuntu4) E: Unable to correct\n problems, you have held broken packages.\n\nHow do I fix this problem?\n\nA: had the same problem too.. but i solved it with these commands:  \nsudo add-apt-repository ppa:openjdk-r/ppa  \nsudo apt-get update   \nsudo apt-get install openjdk-7-jre  \n\n\nA: The one I did on 16.04 was:\nFor OpenJDK 8.X\nsudo apt install openjdk-8-jre\n\nFor OpenJDK 9.X\nsudo apt install openjdk-9-jre\n\nNote: There was no openjdk-6-jre nor openjdk-7-jre for me on Ubuntu 16.04. Also there is NO need to install Oracle JDK (Actually OpenJDK is much better than Oracle one for me).\n\nA: Some feedback with 16.04... If you are installing as part of a \"software script\" package, you always have to check which version of Java the programs support first. \nFor example, using openjdk-8-jre (newer version) on the install script. \nsudo apt-get update && sudo apt-get upgrade\nsudo apt-get install openjdk-8-jre\n\n", "Q: AMD R7 M265 Hybrid Graphic Card can't download driver I have Intel/AMD R7 M265 Hybrid Graphic Card and I am working on Ubuntu 14.04.3 LTS.\nI am trying to setup AMD Drivers but it is not working. It always give to me same error.\nAfter I setup fglrx or fglrx-update, I reboot my computer but my Ubuntu is not opening. I always get error like wrong display card. \nWhen i wrote lspci I got this:\n01:00.0 Display controller: Advanced Micro Devices, Inc. [AMD/ATI] Opal XT [Radeon R7 M265] (rev ff)\n\nHow i can solve this problem ? Do you have any suggestion for it ?\n\nA: You can download the latest AMD driver for your card from here. AMD R7 M265 Driver download page\nDetailed instructions for installing on Ubuntu 14.04 are given here. AMD Linux installation instructions\n", "Q: Cannot connect as Guest to ubuntu usershare from MAC OSX Yosemite? I cannot connect to my shared folders on my Ubuntu server from my Mac.\nMy Windows computer can connect without any problems.\nGiving Ubuntu credentials as opposed to using \"Anonymous\" used to work, but that has stopped working as well... \nWhen I try connecting to my Ubuntu server smb://192.168.0.100/ as a Guest from my Mac I get:\n\"There was a problem connecting to the server “192.168.0.100”. Check the server name or IP address, and then try again. If you continue to have problems, contact your system administrator.\"\n\nThese are my testparm results\nLoad smb config files from /etc/samba/smb.conf\nrlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)\nProcessing section \"[profiles]\"\nWARNING: No path in service profiles - making it unavailable!\nNOTE: Service profiles is flagged unavailable.\nProcessing section \"[printers]\"\nProcessing section \"[print$]\"\nProcessing section \"[Alba]\"\nProcessing section \"[AS2]\"\nProcessing section \"[scan]\"\nProcessing section \"[public]\"\nLoaded services file OK.\nServer role: ROLE_STANDALONE\n\nPress enter to see a dump of your service definitions\n\n# Global parameters\n[global]\n    workgroup = ALBA\n    server string = %h server (Samba, Ubuntu)\n    interfaces = 127.0.0.0/8 eth0\n    bind interfaces only = Yes\n    security = USER\n    map to guest = Bad User\n    obey pam restrictions = Yes\n    pam password change = Yes\n    passwd program = /usr/bin/passwd %u\n    passwd chat = *Enter\\snew\\s*\\spassword:* %n\\n *Retype\\snew\\s*\\spassword:* %n\\n *password\\supdated\\ssuccessfully* .\n    username map = /etc/samba/smbusers\n    log file = /var/log/samba/log.%m\n    max log size = 1000\n    dns proxy = No\n    usershare allow guests = Yes\n    panic action = /usr/share/samba/panic-action %d\n    idmap config * : backend = tdb\n    guest ok = Yes\n\n\n[profiles]\n    available = No\n\n\n[printers]\n    comment = All Printers\n    path = /var/spool/samba\n    create mask = 0700\n    printable = Yes\n    browseable = No\n\n\n[print$]\n    comment = Printer Drivers\n    path = /var/lib/samba/printers\n\n\n[Alba]\n    path = /home/administrator/Alba\n    read only = No\n\n\n[AS2]\n    path = /home/administrator/AS2\n    read only = No\n\n\n[scan]\n    path = /home/scan\n    read only = No\n\n\n[public]\n    path = /home\n    read only = No\n\n\nA: Due to the recent fixes for the Badlock Samba vulnerability, and many of the changes necessary to address it, there are a large number of regressions.  This is one of the things hit by the regressions as a result of the fix.  (It is not likely a case of your configuration being wrong)\nThere is a bug open on this on Launchpad, but as of yet there is no fix.  There is no workarounds for this issue yet, either, so there is currently no way to 'fix' this issue.\n\nThis post may be updated in the future if this changes, and if a fix is made available.\n\n", "Q: Error in installation of odoo in ubuntu 16.04 I am using Ubuntu 16.04 i want to install odoo v9.\nI followed these steps:\n\nTo install Odoo 9.0 on Debian-based distribution, execute the\n  following commands as root:\nwget -O - https://nightly.odoo.com/odoo.key | apt-key add -\necho \"deb http://nightly.odoo.com/9.0/nightly/deb/ ./\" >> /etc/apt/sources.list\napt-get update && apt-get install odoo\n\n\nBut it returns an error such as\n/var/lib/dpkg/info/odoo.postinst: 28: /var/lib/dpkg/info/odoo.postinst: update-python-modules: not found\ndpkg: error processing package odoo (--configure):\nsubprocess installed post-installation script returned error exit status 127\nErrors were encountered while processing:\n odoo\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nWhy is this error occurring?\n\nA: Those commands would fix the above issue as it works for me\nwget http://ftp.de.debian.org/debian/pool/main/p/python-support/python-support_1.0.15_all.deb\ndpkg -i python-support_1.0.15_all.deb\napt install odoo\n\nSource link https://github.com/odoo/odoo/issues/11785\n", "Q: Jailkit - Missing file / directory colors? I have set up Jailkit on my server and wanted to create a new user that is restricted to this \"jail\".\nThat worked fine and so far through intense experimenting, I could not escape this jail :)\nHowever, I noticed something:\nWhenever I list files or directories via the ls command, it doesn't show them in different colors?\nI'm used to seeing e.g. directories in the color blue, but every file is in gray.  \nAm I missing something, perhaps?  \n~ Greets.\n\nA: Use ls --color=always\nSo you don't have to do it every time, add the line alias ls=\"ls --color=always\" to the end of your .bashrc\n", "Q: How to correct the command for PHP 7.0.* in following PHP cli and git installation? I'm using Ubuntu Linux 14.04 LTS 64-bit OS on my machine. \nI just updated all the softwares and packages installed on my system by running following commands from the terminal :\nsudo apt-get update\n\nsudo apt-get upgrade\n\nNow I'm using PHP 7.0.5, the latest current stable version of PHP.\nFor checking it I run the following command from the terminal :\nphp -v\n\nPHP 7.0.5-3+donate.sury.org~trusty+1 (cli) ( NTS )\nCopyright (c) 1997-2016 The PHP Group\nZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies\n    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2016, by Zend Technologies\n\nNow I was trying to install Composer(The Project Dependency Management Software). As a prerequisite it needs cli and Git to be installed so for it I typed in following command and got following error. How to resolve this error?\nsudo apt-get install curl php5-cli git\n\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ncurl is already the newest version.\ncurl set to manually installed.\ngit is already the newest version.\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n php5-cli : Depends: php5-common (= 5.5.9+dfsg-1ubuntu4.14) but 5.5.32+dfsg-1+deb.sury.org~precise+1 is to be installed\n            Recommends: php5-readline but it is not going to be installed\nE: Unable to correct problems, you have held broken packages.\n\nThe error I want to resolve is as below from above output :\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n php5-cli : Depends: php5-common (= 5.5.9+dfsg-1ubuntu4.14) but 5.5.32+dfsg-1+deb.sury.org~precise+1 is to be installed\n            Recommends: php5-readline but it is not going to be installed\nE: Unable to correct problems, you have held broken packages.\n\nSomeone please provide me the correct command I need to run from the terminal and remove this error.\nI think it's occurring since I'm no more using PHP 5.5.9. Just provide me the necessary command.\nThanks in advance.\n\nA: PHP 7.0 packages has been renamed, so you are looking either for apt-get install php-cli to install dependency package that will pull default PHP version, or just apt-get install php7.0-cli. I recommend the former. \n", "Q: how can I update the path to Android Studio? I was using Android studio 1.5. I fired up the studio and then locked it to the launcher. That made it very easy to fire up from there on.\nNow I just updated to 2.0. I unlocked the first icon from the launcher, went to the 2.0 directory and used ./studio.sh. As expected, up came version 2.0. Great, now to lock it to the launcher bar. Done. Exit the studio and press the icon. What comes up? Good ole 1.5 which I no longer want to use.\nThere must be some sort of path variable which I am not finding. What I got from printenv is\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\nwhich clearly has no reference to either version of Android studio. So where does the icon on the launch bar get its location from? How can I update it to the new location?\n\nA: 1) Go to the installation dir, and fire it up with ./studio.sh\n2-A) [For > v2.0] There is an option to add a shortcut in Android Studio's \"main menu\":\n\n\n2-B) [For < v2.0] There is an option to add a shortcut in Android Studio's \"main menu\":\n\n", "Q: Can we make a folder and its contents remain locked for certain times of the day and unlocked for the rest of the time? Suppose I have a Games folder. I don't want to waste my time on games. So is there someway that the folder remains inaccessible for most of the day, and only becomes accessible for say 3 hours after 11 o'clock. \n\nA: One solution could be setting up cronjobs to lock/unlock the game directory. To do so follow the steps below.\n\n\n*\n\n*Make sure cron-daemon is installed\n\n\nsudo apt-get install cron\n\n\n*Prepare the game directory to be owned by root (alter the paths to fit your situation)\n\n\n\nsudo chown -v root:root ~/GameDirectory\nsudo chmod -v u+rwx ~/GameDirectory\nsudo chmod -v go-rwx ~/GameDirectory\n\n\n\n*Setting up the cronjob to run for root\n\n\nStart editing the cronjob by issuing following command:\nsudo crontab -e\nAdd the folowing lines into the editor:\n\n00 11 * * * chmod go+rwx ~/GameDirectory\n00 14 * * * chmod go-rwx ~/GameDirectory\n\nThe above lines will make the cronjob unlock the directory at 11 am (hour setting is the second number from the left 0-23 hr style) and lock the directory at 2 pm.\nBe advised that, since you have the ability to elevate your rights with sudo, you still need discipline to not overgo your own restrictions.\nI never did set up cronjobs myself yet so if anyone finds an error in my solution, comment on it and I will correct it.\n", "Q: Sound playing through speaker and headphones I have an Asus ROG G752VY dual booted with win 10 and Ubuntu 15.10\nEverything works fine in windows. Switching to Ubuntu the speakers work fine but as soon as I plug in the headphones nothing worked.\nI added \noptions snd-hda-intel model=asus-mode5 (I tried asus-mode1 through to 8 too)\nto /etc/modprobe.d/alsa-base.conf\nthe headphones now work beautifully, but sound is still played through the speakers.\nRunning cat /proc/asound/card0/codec* | grep Codec I get Codec: Realtek ALC668\nAlso, the built-in microphone isn't working, though it works fine in Windows.\nAny ideas?\nEDIT: Auto-mute is enabled in alsamixer\nEDIT 2: After looking in pavucontrol even though the headphones are plugged in, it thinks they are not plugged in. It appears to be treating the headphones as an extension of the speaker as when I change the \"speaker\" volume in alsamixer it changes the volume through the headphones too.\nEDIT 3: Output for $ pacmd list-sinks\n$ pacmd list-sinks\n2 sink(s) available.\n    index: 0\n    name: <alsa_output.pci-0000_01_00.1.hdmi-stereo>\n    driver: <module-alsa-card.c>\n    flags: HARDWARE DECIBEL_VOLUME LATENCY DYNAMIC_LATENCY\n    state: SUSPENDED\n    suspend cause: IDLE \n    priority: 9050\n    volume: front-left: 65536 / 100% / 0.00 dB,   front-right: 65536 / 100% / 0.00 dB\n            balance 0.00\n    base volume: 65536 / 100% / 0.00 dB\n    volume steps: 65537\n    muted: no\n    current latency: 0.00 ms\n    max request: 0 KiB\n    max rewind: 0 KiB\n    monitor source: 0\n    sample spec: s16le 2ch 44100Hz\n    channel map: front-left,front-right\n                 Stereo\n    used by: 0\n    linked by: 0\n    configured latency: 0.00 ms; range is 0.50 .. 371.52 ms\n    card: 0 <alsa_card.pci-0000_01_00.1>\n    module: 6\n    properties:\n        alsa.resolution_bits = \"16\"\n        device.api = \"alsa\"\n        device.class = \"sound\"\n        alsa.class = \"generic\"\n        alsa.subclass = \"generic-mix\"\n        alsa.name = \"HDMI 0\"\n        alsa.id = \"HDMI 0\"\n        alsa.subdevice = \"0\"\n        alsa.subdevice_name = \"subdevice #0\"\n        alsa.device = \"3\"\n        alsa.card = \"1\"\n        alsa.card_name = \"HDA NVidia\"\n        alsa.long_card_name = \"HDA NVidia at 0xdc080000 irq 17\"\n        alsa.driver_name = \"snd_hda_intel\"\n        device.bus_path = \"pci-0000:01:00.1\"\n        sysfs.path = \"/devices/pci0000:00/0000:00:01.0/0000:01:00.1/sound/card1\"\n        device.bus = \"pci\"\n        device.vendor.id = \"10de\"\n        device.vendor.name = \"NVIDIA Corporation\"\n        device.product.id = \"0fbb\"\n        device.product.name = \"GM204 High Definition Audio Controller\"\n        device.string = \"hdmi:1\"\n        device.buffering.buffer_size = \"65536\"\n        device.buffering.fragment_size = \"32768\"\n        device.access_mode = \"mmap+timer\"\n        device.profile.name = \"hdmi-stereo\"\n        device.profile.description = \"Digital Stereo (HDMI)\"\n        device.description = \"GM204 High Definition Audio Controller Digital Stereo (HDMI)\"\n        alsa.mixer_name = \"Nvidia GPU 71 HDMI/DP\"\n        alsa.components = \"HDA:10de0071,10431ced,00100100\"\n        module-udev-detect.discovered = \"1\"\n        device.icon_name = \"audio-card-pci\"\n    ports:\n        hdmi-output-0: HDMI / DisplayPort (priority 5900, latency offset 0 usec, available: no)\n            properties:\n                device.icon_name = \"video-display\"\n    active port: <hdmi-output-0>\n  * index: 8\n    name: <alsa_output.pci-0000_00_1f.3.analog-stereo>\n    driver: <module-alsa-card.c>\n    flags: HARDWARE HW_MUTE_CTRL HW_VOLUME_CTRL DECIBEL_VOLUME LATENCY DYNAMIC_LATENCY\n    state: RUNNING\n    suspend cause: \n    priority: 9959\n    volume: front-left: 20375 /  31% / -30.44 dB,   front-right: 20375 /  31% / -30.44 dB\n            balance 0.00\n    base volume: 65536 / 100% / 0.00 dB\n    volume steps: 65537\n    muted: no\n    current latency: 9.82 ms\n    max request: 2 KiB\n    max rewind: 64 KiB\n    monitor source: 11\n    sample spec: s16le 2ch 44100Hz\n    channel map: front-left,front-right\n                 Stereo\n    used by: 1\n    linked by: 2\n    configured latency: 11.61 ms; range is 0.50 .. 371.52 ms\n    card: 1 <alsa_card.pci-0000_00_1f.3>\n    module: 7\n    properties:\n        alsa.resolution_bits = \"16\"\n        device.api = \"alsa\"\n        device.class = \"sound\"\n        alsa.class = \"generic\"\n        alsa.subclass = \"generic-mix\"\n        alsa.name = \"ALC668 Analog\"\n        alsa.id = \"ALC668 Analog\"\n        alsa.subdevice = \"0\"\n        alsa.subdevice_name = \"subdevice #0\"\n        alsa.device = \"0\"\n        alsa.card = \"0\"\n        alsa.card_name = \"HDA Intel PCH\"\n        alsa.long_card_name = \"HDA Intel PCH at 0xda128000 irq 327\"\n        alsa.driver_name = \"snd_hda_intel\"\n        device.bus_path = \"pci-0000:00:1f.3\"\n        sysfs.path = \"/devices/pci0000:00/0000:00:1f.3/sound/card0\"\n        device.bus = \"pci\"\n        device.vendor.id = \"8086\"\n        device.vendor.name = \"Intel Corporation\"\n        device.product.id = \"a170\"\n        device.product.name = \"Sunrise Point-H HD Audio\"\n        device.form_factor = \"internal\"\n        device.string = \"front:0\"\n        device.buffering.buffer_size = \"65536\"\n        device.buffering.fragment_size = \"32768\"\n        device.access_mode = \"mmap+timer\"\n        device.profile.name = \"analog-stereo\"\n        device.profile.description = \"Analogue Stereo\"\n        device.description = \"Built-in Audio Analogue Stereo\"\n        alsa.mixer_name = \"Realtek ALC668\"\n        alsa.components = \"HDA:10ec0668,10431ced,00100003\"\n        module-udev-detect.discovered = \"1\"\n        device.icon_name = \"audio-card-pci\"\n    ports:\n        analog-output-speaker: Speakers (priority 10000, latency offset 0 usec, available: unknown)\n            properties:\n                device.icon_name = \"audio-speakers\"\n        analog-output-headphones: Headphones (priority 9000, latency offset 0 usec, available: no)\n            properties:\n                device.icon_name = \"audio-headphones\"\n    active port: <analog-output-speaker>\n\n\nA: Firstly, keep options snd-hda-intel model=asus-mode5 added to /etc/modprobe.d/alsa-base.conf\nDisable pulseaudio's auto spawning capabilities and kill all instances\n$ echo autospawn = no >> /etc/pulse/client.conf\n$ killall pulseaudio\n\ncheck if there is anything else using the sound card\n$ sudo fuser -v /dev/snd/*\n\nmake sure you kill anything that comes up and stop it from respawning too, how to do this will depend on what the program is.\nInstall alsa-tools-gui\n$ sudo apt-get install alsa-tools-gui\n$ sudo hdajackretask\n\nWhen the GUI loads, click \"Show unconnected pins\" and override the first unconnected pin to be a headphone jack and apply the settings. Daemonise pulseaudio puslseaudio -D and test the sound, repeat this for all unconnected ports until you find the right one.\nOnce you have found the one the correct jack, click \"Install boot override\" and restart to make sure everything works. Now edit the pulseaudio config file and remove the line added earlier to allow respawning again.\nUntil you reboot, volume can only modified using alsamixer rather than the usual GUI component. After rebooting, everything goes back to normal.\n", "Q: How do I re-enter a sqlite database that I already created? I am using sqlite3 and created a new database in the terminal by using:\nsqlite3 test.db\n\nI then created some tables in this database but then I closed sqlite3. How can I re enter my test.db? Do I simply write \nsqlite3 test.db \n\nagain? I dont want to try it without knowing for sure in case it overwrites my work. Sorry for the beginner question, I couldn't find out how on the web as I guess its so simple.\n\nA: Yes, \nsqlite3 test.db \n\nopens test.db if it exists and lets you work with the content it contains.\n", "Q: Agent admitted failure to sign using the key After a fresh ubuntu install, it seems I can't use any bzr branch commands. I get the following error:\n   Agent admitted failure to sign using the key. Permission denied\n   (publickey). ConnectionReset reading response for 'BzrDir.open_2.1',\n   retrying Agent admitted failure to sign using the key. Permission\n   denied (publickey). bzr: ERROR: Connection closed: Unexpected end of\n   message. Please check connectivity and permissions, and report a bug\n   if problems persist.\n\nI followed the steps provided here but without luck. Also, other solutions provided on the forum were not helpful.\nAny idea what to do?\n\nA: You should be able to fix this error by loading your keys into your SSH agent with ssh-add:\nType ssh-add in your terminal, on the root folder where you want to clone the project.\n", "Q: Having difficult time using or downloading videos with Youtube-dl Having difficult time using or downloading videos from Youtube it keeps saying \nbash: /usr/local/bin/youtube-dl: Permission denied\n\nI don't even know if I installed it correctly.\nMy OS is Ubuntu 15.10 64.\n\nA: It's possible the executable does not have the correct permissions.\nFor it to be in /usr/local/bin/youtube-dl, you probably ran it with a sudo make install or similar.  it's in there as root:root which is fine, but it's not going to work right.\nLet's set the executable bit: sudo chmod +x /usr/local/bin/youtube-dl\nThen try and use youtube-dl.\n\nA: Try to install it via pip3\nAt first intall python3-pip python-pip\n sudo apt-get install python3-pip python-pip\n\nthen\n sudo pip3 install --upgrade youtube-dl\n\n", "Q: Gnome-Terminal Auto Close I configured my terminal to run \"bluetooth off\" at start up and exit terminal after the command. Now the terminal opens, runs the command and closes instantly rendering me unable to run any more commands. \nI have tried reinstalling the terminal application but the settings still remain the same. How can I restore the default terminal setting?\n\n\nA: There's a couple of ways to reset gnome-terminal. One has been suggested in the comments already : remove or move the $HOME/.gconf/apps/gnome-terminal/ folder. Second approach would be to open Unity dash , search for xterm (which is a standard terminal emulator on almost any Linux) and run form there gnome-terminal -e bash which will open the shell instead of whatever command you specified. From there you should be able to reset the preferences. \n", "Q: How to run Multiple Magento2 setup with Nginx I want to configure multiple Magento2 setup (like 3 setups) with single domain name. like..\nIf I browser the URL as below then it should load separate directory based on Nginx request.\n\ntest.com/m21  > /var/www/m21\ntest.com/m22  > /var/www/m22\ntest.com/m23  > /var/www/m23\n\nSo can anyone guide me to setup nginx virtual host configuration file which can fulfill my about requirement to load multiple Magneto2 setup over the single domain name.\nWaiting for helping hand.\n\nA: Yeah, it's fairly easy to do so in Nginx.\nYou just have to edit the Nginx virtual host file.\nLet's take one case for example.\nCase : One Website, Multiple Store Views\nFor example, we have\nmystore.com (store code: mystore_en)\nmystore.de (store code: mystore_de)\nmystore.es (store code: mystore_es)\n…\n\nStep 1. Edit your Nginx virtual host configuration file as\nFile: Usually located under /etc/nginx/sites-available/ or /usr/local/etc/nginx/sites-available/ or other depending upon the OS type.\nmap $http_host $MAGE_RUN_CODE {\n    mystore.com mystore_en;\n    mystore.de mystore_de;\n    mystore.es mystore_es;\n}\nserver {\n    listen 80;\n    server_name mystore.com mystore.de mystore.es;\n    set $MAGE_ROOT /path/to/your/magento2;\n    set $MAGE_MODE default;\n    include /path/to/your/magento2/nginx.conf.sample;\n}\n\nHere you can see how the Nginx map block is used to set MAGE_RUN_CODE as per host. And server_name directive includes all the available domains.\nStep 2. Send MAGE_RUN_CODE and MAGE_RUN_TYPE variables to the php-fpm server\nFile: include path from above, example: path/to/your/magento2/nginx.conf.sample\n#...\n# PHP entry point for main application\nlocation ~ (index|get|static|report|404|503)\\.php$ {\n    try_files $uri =404;\n    fastcgi_pass   fastcgi_backend;\n    fastcgi_buffers 1024 4k;\n\n    fastcgi_param  PHP_FLAG  \"session.auto_start=off \\n suhosin.session.cryptua=off\";\n    fastcgi_param  PHP_VALUE \"memory_limit=768M \\n max_execution_time=600\";\n    fastcgi_read_timeout 600s;\n    fastcgi_connect_timeout 600s;\n\n    #add here - start\n    fastcgi_param  MAGE_RUN_TYPE store;\n    fastcgi_param  MAGE_RUN_CODE $MAGE_RUN_CODE;\n    #end\n\n    fastcgi_index  index.php;\n    fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n    include        fastcgi_params;\n}\n#...\n\nHere Nginx fastcgi_param‘s MAGE_RUN_TYPE & MAGE_RUN_CODE will create the environment variables for PHP so that the script can access the values via\n$_SERVER['MAGE_RUN_TYPE']\n$_SERVER['MAGE_RUN_CODE']\n\nFor details please check: http://www.blog.magepsycho.com/set-multiple-magento-2-websites-stores-nginx/\n", "Q: ata2.00 failed to enable aa I'm new to the world of Ubuntu. Installed Ubuntu 14.04LTS yesterday on a Lenovo Ideapad Y580 and till now I already recognized, that Lenovo is a bit infamous for this problem.\nSo when I boot up the laptop he gives me the error ata2.00 failed to enable aa and an error mask in brackets. \nI surfed a bit around and it seems that the hard drive advertised something for it it doesn't have or isn't activated. \nI'm always getting a black sreen after booting and I already saw this threat, but I dont know how to use it or get the command working because when I boot in the shell to have a root command line it wont work. \nAlso I clearly don't want to give up the performance by deactivating ncq. I know I'm asking for a lot but can somebody please give me an instruction how to get the drivers set up to get the fpdma working or am I doomed? the numbers before the lines are always the same... hhd information moreinfo\n\nA: So first of all i fixed my own problem ( a lenovo ideapad y580 ) by formatting the disk ( for information see the hdd information image in the question) and then doing a full erase with a seatools for dos bootable cd. Then i set the sata controller in the bios from \"ahci\" to \"compatible\" and reinstalled ubuntu 14.04 lts from the live cd. Now it mostly boots up fine, but i sometimes need to go into standby with the power button of the laptop after logging in, because the screen then sometimes still goes black. But after reactivating the laptop from standyby, ubuntu does work :) \nHope that helps somebody too, but these solution might only be possible with the same hardware specs and as you can tell, it isnt the best solution at all...\n", "Q: Why using (or not) dedicated bridges with LXD? Question: Are there specific drawbacks of using a single bridge, as opposed to a dedicated one per container?\nDetails: I have a host which runs a few LXD containers. I initially decided to have one bridge per container, mostly to ease the firewalling between them, the host, the LAN and Internet. I therefore have several 10.10.1x.0/24 networks matching a brx bridge (where x is incremented for each container which gets a 10.10.1x.1 address and a default gateway of 10.10.1x.254 which is the bridge).\nWith the advent of LXD2 and its new bridge lxdbr0 I started to wonder if it would not be better to move to a single bridge solution, with a 10.10.10.0/24 network, each of the containers getting its 10.10.10.y IP, all of them routed though 10.10.10.254 (on the bridge).\nMy main consideration is separation of the containers and ease of administration of the firewalling. \n\nA: One of the reasons, I found out in the meantime, is that the bridge will be working at ISO/OSI layer 2 and therefore firewalling is much more difficult (it requires specific marking of traffic - with the source port/NIC).\nHaving separated bridges (and separated networks) makes firewalling more straightforward.\n", "Q: Problem with IPv6 sudo apt-get update/upgrade I am using Ubuntu 16.04 Beta 2 at the moment and every time I try to update at home via sudo apt-get update or upgrade trough sudo apt-get upgrade I wont get any feedback. Even installing of anything will have the same result. It will just \"hang up\" on 0% while fetching data.\n$ sudo apt-get update\n[sudo] password for niclas: \n0% [Connecting to archive.ubuntu.com (2001:67c:1560:8001::11)] [Connecting to archive.canonical.com (2001:67c:1360:8c01::1b)]\n\nI have no idea how to solve the problem. I already tried to ping6 archive.ubuntu.com with 100% packet loss while just ping wont have any loss.\nI changed the DNS-Server (IPv4 & IPv6) to Google's one no solution either.\n\nA: \nThanks to this Unix and Linux post by mmoya on Unix and Linux for the answer.\n\nWe can try and force apt to use IPv4 instead.\nTry this command set, based off the information in the aforementioned link:\napt-get -o Acquire::ForceIPv4=true update\napt-get -o Acquire::ForceIPv4=true upgrade\n\nThis should force IPv4 in place of IPv6.\n\nYou can make this persistent for all apt-get in the future (so you don't have to provide the arguments to make this work) by doing the following (also from the other U&L post):\necho 'Acquire::ForceIPv4 \"true\";' | sudo tee /etc/apt/apt.conf.d/99force-ipv4\n\nThis will make a configuration file for apt and apt-get to parse, which will then include the ForceIPv4 true options going forward for all apt-get runs.\n", "Q: Ubuntu HP laptop getting overheated while playing DOTA 2 I am running DOTA 2 on lowest graphics and with GPU enabled and the temp is getting (I am not joking) 90-95 °C. What to do it's getting too hot!\nMy Laptop specs:\n\n\n*\n\n*processor: Intel i3 3rd gen\n\n*Ram: 4 GB \n\n*GPU: Nvidia 850 m (1gb)\n\n\nA: Please note the following answer is taken from HP themselves, and is not written by me. Please read the whole article before you do ANYTHING.\nInformation to read:\n\nWHAT IS OVERHEATING?\n  Heat buildup can cause problems for any laptop (notebook). Generally, when temperatures inside the case rise above 35 degrees Celsius (95 degrees Fahrenheit), the risk of damaging important internal components increases greatly. The most common cause of overheating is the accumulation of dust inside the laptop. The electrical components in a notebook generate heat and fans inside the notebook help move the air to keep the components cooled to normal operating temperatures. Inadequate cooling can cause excess heat to build up inside the case which can damage components. The sound of the fan running constantly may indicate that the laptop is getting hot and is not running as efficiently as possible and that there is a problem with accumulated dust clogging the air vents.\n\nLocation of vents:\n\nStep 1: WHERE ARE MY VENTS?\n  Most notebook computers have vents located around the case to allow air to flow through the case. If these vents become clogged, or if heat-generating parts become covered with dust, the fan cannot cool the components properly, because the laptop is hot and overheating becomes a problem. Lint and dust accumulation prevents air from flowing around the cooling fan blades and causes the fan to work harder and the laptop to get hot. If there is dust in the vents, you should clean the laptop by blowing out the dust from around the fan and heat shield. This prevents dust from accumulating.\n  It is not necessary to open the notebook (laptop) to clean out the dust with the canned, compressed air.\n  The following graphics show the dust accumulation on the inside of the laptop, but dust around the fans and heat shield of the laptop can be cleaned without opening the computer.\n\n\n\n\n\n\nStep 2: ENSURING PROPER SPACE FOR VENTILATION \n  To decrease the likelihood of overheating problems, ensure the fans on your laptop are able to ventilate properly. Proper ventilation for the system is important for laptop operation. Follow these guidelines to ensure adequate ventilation:\n  Keep the laptop upright and on a sturdy, level surface.\n  Provide at least 15.25 centimeters (6 inches) of clearance around each vent.\n  If the laptop is being used at very high altitudes, above 1500 meters (5000 feet), take extra care to keep the laptop cool. The maximum limit of 35 degrees Celsius (95 degrees Fahrenheit) drops 1 degree Celsius (~34 degrees Fahrenheit) every ~300 meters (1000 feet) of altitude.\nStep 3: UPDATING THE BIOS.\n  After releasing a laptop, HP regularly provides updates for the BIOS and other components. Check for BIOS updates and install them using instructions in the HP support document Updating the BIOS.\nStep 4: USING HP COOLSENSE TECH.\n  HP CoolSense technology is a feature in some HP notebook (laptop) computers that combines hardware, software, and mechanical design to dynamically manage the temperature of your laptop computer. HP CoolSense uses a motion sensor in your laptop to sense when your laptop is being used in a stationary or mobile setting, and automatically adjusts the laptop performance and fan speed to keep the computer cool. You can set HP CoolSense software to your specifications. For more information, see HP Notebook PCs - HP CoolSense Technology.\nStep 5: PLACE THE NOTEBOOK IN A COOLER ROOM\n  If your laptop is overheating, place it in a cooler room. A small difference in temperature might be all that is needed to prevent a component from failing. Move the laptop to a cooler room in the house or office. If this is not an option, continue with the next step.\nStep 6: TESTING FOR HARDWARE FAILURE.\n  If overheating issues persist after cleaning the vents and moving the computer to a cooler room, a hardware component might be damaged. Test the computer to see if any hardware, such as memory, the processor, or the graphics hardware, have failed. Most HP and Compaq notebook computers have diagnostic software to verify hardware failures. For more information, see the appropriate document:\n\n\n\n*\n\n*Testing for Hardware Failures (Windows 10, 8)\n\n*Testing for Hardware Failures (Windows 7)\n\n*Checking Your Notebook PC Using the HP System Health Scan for laptops running Windows Vista\n\n*If hardware has failed, either replace the bad component or contact HP for further assistance using the Contact Support tab at the top of this screen.\n", "Q: Using /usr/local/bin/mpd instead of /usr/bin/mpd I want to run a patched mpd installed in /usr/local/bin. Usually it's started by:\nsudo service mpd start.\nChanging the:\nDAEMON=/usr/bin/mpd\nto\nDAEMON=/usr/local/bin/mpd\nin /etc/init.d/mpd has no effect: service still starts /usr/bin/mpd.\nI noticed a /lib/systemd/system/mpd.service file and try to change its\nExecStart=/usr/bin/mpd --no-daemon $MPDCONF\nto\nExecStart=/usr/local/bin/mpd --no-daemon $MPDCONF\nbut now the mpd service won't start.\nHere is the output from systemctl status mpd\n● mpd.service - Music Player Daemon\n   Loaded: loaded (/lib/systemd/system/mpd.service; enabled; vendor preset: enabled)\n   Active: failed (Result: start-limit) since jeu. 2016-04-21 11:04:26 CEST; 2s ago\n  Process: 26778 ExecStart=/usr/local/bin/mpd --no-daemon $MPDCONF (code=exited, status=1/FAILURE)\n Main PID: 26778 (code=exited, status=1/FAILURE)\n\navril 21 11:04:25 lago systemd[1]: Started Music Player Daemon.\navril 21 11:04:26 lago mpd[26778]: cmdline: No configuration file found\navril 21 11:04:26 lago systemd[1]: mpd.service: Main process exited, code=exited, status=1/FAILURE\navril 21 11:04:26 lago systemd[1]: mpd.service: Unit entered failed state.\navril 21 11:04:26 lago systemd[1]: mpd.service: Failed with result 'exit-code'.\navril 21 11:04:26 lago systemd[1]: mpd.service: Start request repeated too quickly.\navril 21 11:04:26 lago systemd[1]: Failed to start Music Player Daemon.\navril 21 11:04:26 lago systemd[1]: mpd.service: Failed with result 'start-limit'.\n\nI check that:\nsudo /usr/local/bin/mpd --no-daemon /etc/mpd.conf\nworks from command line.\nI'm lost in this service configuration. What should I modify?\n\nA: It turns out that changing $MPDCONF to /etc/mpd.conf fixed the problem. What is weird is that this line was working fine with /usr/bin/mpd\n", "Q: What is gstatic and why did it show up in my spreadsheet? I'm running 14.04 LTS.  I have a LibreOfficeCalc spreadsheet that I save to Dropbox.  Today when I opened the sheet, near the last row containing data is a vertically oriented web address, in red text, over top both data and empty cells.  The web address begins with \"https://ssl.gstatic.com/ui/v1/icon/mail/images/cleardot/gif . . .\"\nI've placed the cursor in all of the cells but cannot find the cell this originates in.\nI searched gstatic.com and have found that it is either owned and for the benefit of Google or other sites report it is a malicious virus.\nWhat is it?  I'm already concerned.  What should I do?\n\nA: Fear not. gstatic.com is a domain owned and controlled by Google, Inc. They use the domain to host static content for their own services. I'm not sure how or why it ended up in your spreadsheet, but it's probably not malicious.\n", "Q: Does Ubuntu damage some LCD screens? I have an Acer Aspire 5732 Z, with 4 GB RAM and Pentium(R) Dual-core 2.20 GHz Processor. My graphics card is: Mobile Intel® 4 Series.\nI had been using Windows since 2013, then I decided to use Ubuntu last summer (June 2015). So, I installed Ubuntu (and removed Windows 7). And I enjoyed Ubuntu for about four months (December 2015).\nOne day, Ubuntu started showing a low-graphics mode error... I tried to log in to my account using the command line. It says that I logged in successfully while asking me again to enter my password and username... This happened endlessly.\nSo, as all my work data was on GitHub, I decided to format my computer, and I installed Windows 7 again.\nAfter working with Windows 7 for less than a month, my LCD screen started to show vertical lines (that increase in intensity over time), and nothing shows up on the screen. This never happened until I switched to Ubuntu and switched back to Windows 7 again.\nSo, I started using desktop screens (with a VGA cable) for about two months, then I changed the LCD display of my laptop, and it's fixed and working great now.\nBut, I still want to use Ubuntu. Could the LCD problem be caused by Ubuntu (or at least a specific configuration in it)?\n\nA: No. It is physically impossible for an operating system to damage the LCD.\nMost likely the problem was that the LCD's ribbon cable had a loose connection to the motherboard.\nEither that or the display died on its own...\n", "Q: Does the OEM video play after an ordinary OEM install? I am giving an Ubuntu PC with an OEM install to my mom to convince her that Ubuntu is actually useful for \"regular users\", and I want the first boot video from Dell's Ubuntu machines to play when she boots up an OEM'd laptop for the first time. Does the OEM install do this automatically? https://www.youtube.com/watch?v=FeqfxttHPmA\n\nA: No it doesn't, at least not with 14.04\nYou can try it for yourself. Here is a how to.\nhttps://help.ubuntu.com/community/Ubuntu_OEM_Installer_Overview\n", "Q: MAAS unable to to keep Node details under MAAS nodes Ubuntu 14.04.4 --- MAAS 1.9.1+bzr4543-0ubuntu1 (trusty1)\nI have a Machine that PXE Boot and getting the console messages below\nStart PXE over IPV4\nBooting under MAAS direction\n..........\n....Bunch of Lines....\n.....................\nStarting Load Fallback graphics devices ..............[OK]\nStarting Load Fallback graphics devices ..............[fail]  ----> This is the Only Fail\n....................................\n.............\n..............\nUbuntu 14.04.1 LTS\nsjc-os-controller1 login: Cloud-init v. 0.7.5 running 'modules:config' at .......\nGenerating Locales \n.........\nGeneration Complete\n...........\n....Bunch of Lines....\n...............\n\nThen the PXE boot machine/node powers off \nNo Node present under MASS GUI under Nodes \n0 Nodes | 0 Device\nMAAS --> Nodes --> Add Machine\nIf i try to add machine with its MAC Address ..... i then get status:(=Failed Commissioning)\nQs: Is there a Log that i can look into to check the root cause and fix the failure and commission nodes in MAAS.......Thank you \n\nA: Logs can be found here /var/log/maas/maas.log The documentation for  automatic discovery describes the process that should happen:\n\nWith nodes set to boot from a PXE image, they will start, look for a\n  DHCP server, receive the PXE boot details, boot the image, contact the\n  MAAS server and shut down.\n\nIt looks like the server was able to connect to the DHCP server and receive a boot image but wasn't able to communicate back so make sure you have configured your Cluster Controller correctly and have added an SSH Key. \n\nA: Some time ago I had to deal with servers having the same interesting feature/bug. Two network interfaces that were recognized as eth0 and eth1 in BIOS, switched their positions when booting to Linux. I mean an interface that was eth0 in BIOS became eth1, and eth1 – eth0.\nYou could leave the interface eth1 (which you said is on the same network as MAAS) and disable eth0 in BIOS. If there's no option in BIOS for switching off eth0, then you'll have to boot into some Live Linux distro and check the order of NICs.\nOr you just try switching cables and see if that helps. If it does, then you do have a problem with NIC ordering and you have just solved your problem :-)\n", "Q: How to start a snap package I have read some tutorials about Snapcraft and snappy and I am really excited about it.\nI am using 16.04 and used snap find to find and install the ubuntu-calculator-app snap. But I don't know how to start it.\nIt is neither in my Dash (Unity 7) nor in my path (using zsh)\nAlso, I followed the instructions in this blog post\nTo create a links snap and install it. But, again, I don't know how to start the app.\n\nA: Snaps can be run with snap run, so for the example in the question snap run ubuntu-calculator-app. But that is annoying so it is better to add snaps to your path. If the app is a gui, once you open it you can right-click on the launcher icon and select add to dash.\nSnaps are not in your path by default on 16.04. They are stored in /snap/bin. Since snaps are a system-wide installation it would probably be best to add this directory to your system-wide path. This is done via the file /etc/environment. The following can break stuff, so you should backup the file before editing it sudo cp /etc/environment /etc/environment.bak. Use an editor with sudo to open /etc/environment, and add :/snap/bin to the end of the PATH entry. Make sure you restart your terminal or source /etc/environment\nIf that still doesn't work, you need to make sure your user .bashrc file has added /etc/environment to its sources. grep \"source /etc/environment\" ~/.bashrc will echo that line if it exists. If it doesn't echo \"source /etc/environment\" >> ~/.bashrc will add it.\n\nA: Just log out and log back in. If you are upgrading from an earlier version of 16.04 development release you will not have /snap/bin in your PATH environment variable.\n\nA: Just including the path to the /snap/bin in the local ~/.bashrc works for me.\nRun the following\n\n\n*\n\n*echo \"export PATH=$PATH:/snap/bin\" >> ~/.bashrc\n\n*source ~/.bashrc\n\nA: Essentially, as Zygmunt was saying. For completeness, the other alternative is to run the app from the command line:\nubuntu-calculator-app.calculator\n\nCheck out the documentation on how to get started with snaps on classic Ubuntu.\n", "Q: Samba problems with recent update: cant access servers, keeps asking for credentials I'm using Ubuntu 15.10. I work in an office of about 10 computers (all of them running Windows 7). I had a problem with my computer so I had to re-install Ubuntu from scratch (same version, same configuration, same all). Before that, I could:\n\n\n*\n\n*Browse the network and see all the computers with no problems\n\n*Access shared files from those computers\n\n*Prevent my computer from showing up in the network (I didn't really do anything, it simply worked like that from the beginning).\n\n\nI never configured anything samba-related before, everything worked out of the box. After re-installing, I can no longer access shared files. It keeps asking for credentials, even though they are all public and I never had to enter no credentials. No matter what credentials I enter, it doesn't work. No computer here is password protected.\nSo I looked around, and then installed system-config-samba hoping it would give me a GUI to configure it (?). Didn't work at all, but with this tool something changed because now my computer shows up in the Windows network, which I really don't want.\nI then tried to remove all samba-related stuff trying to re-install everthing. So I did: \napt-get purge samba samba-common\napt-get autoremove\n\nHere's a log of what it removed:\nStart-Date: 2016-04-20  11:48:31\nCommandline: apt-get purge samba\nPurge: samba:amd64 (4.3.8+dfsg-0ubuntu0.15.10.2), system-config-samba:amd64 (1.2.63-0ubuntu6)\nEnd-Date: 2016-04-20  11:48:39\n\nStart-Date: 2016-04-20  11:50:54\nCommandline: apt-get purge samba-common\nPurge: samba-common-bin:amd64 (4.3.8+dfsg-0ubuntu0.15.10.2), samba-common:amd64 (4.3.8+dfsg-0ubuntu0.15.10.2), nautilus-share:amd64 (0.7.3-1ubuntu5)\nEnd-Date: 2016-04-20  11:50:57\n\nStart-Date: 2016-04-20  11:53:39\nCommandline: apt-get autoremove\nRemove: python-crypto:amd64 (2.6.1-5build1), apturl:amd64 (0.5.2ubuntu9), libaio1:amd64 (0.3.110-1), python-samba:amd64 (4.3.8+dfsg-0ubuntu0.15.10.2), python-dnspython:amd64 (1.12.0-1), tdb-tools:amd64 (1.3.8-0ubuntu0.15.10.1), python-tdb:amd64 (1.3.8-0ubuntu0.15.10.1), python-libuser:amd64 (0.60~dfsg-1.2), samba-dsdb-modules:amd64 (4.3.8+dfsg-0ubuntu0.15.10.2), apturl-common:amd64 (0.5.2ubuntu9), libuser1:amd64 (0.60~dfsg-1.2), samba-vfs-modules:amd64 (4.3.8+dfsg-0ubuntu0.15.10.2), python-ldb:amd64 (1.1.24-0ubuntu0.15.10.1), attr:amd64 (2.4.47-2)\nEnd-Date: 2016-04-20  11:53:43\n\nBut, it's still working! (I have no idea why or how). Everything's the same... Nautilus still shows me the computers in the network, my computer keeps showing up in the network, I'm still unable to access shared files because of credentials.\nSo I'm completely lost. ALL I want is:\n\n\n*\n\n*To access shared files (and printers) in my Windows network\n\n*For my computer to not show up at all in the network.\n\n\nedit\nUsing sysv-rc-conf I disabled the services: smbd, samba-ad-dc, nmbd and the computer still shows in the network! \n\nA: It was a bug.\nhttp://www.ubuntu.com/usn/usn-2950-2/\nSimply updating the packages (after they submitted the fix) fixed it.\n", "Q: Grub black screen on external hdd I have a HP Pavilion dv6 laptop with HD Radeon and with W7 preinstalled in a internal hdd.\nI try to install ubuntu in a external hdd, but the Grub don't load, only appear a black screen and i only can to power off the laptop.\nIf i change the hdd's, W7 can load from the external hdd and ubuntu works fine from the internal hdd.\nWhats happen?\nThanks.\n\nA: Is the output of cat /boot/grub/grub.cfg | grep \"menuentry 'Ubuntu'\" -A 15 \nmenuentry 'Ubuntu' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-26e384d0-b064-49c9-98a1-dd92bdfc8174' {\n        recordfail\n        load_video\n        gfxmode $linux_gfx_mode\n        insmod gzio\n        if [ x$grub_platform = xxen ]; then insmod xzio; insmod lzopio; fi\n        insmod part_msdos\n        insmod ext2\n        set root='hd1,msdos8'\n        if [ x$feature_platform_search_hint = xy ]; then\n          search --no-floppy --fs-uuid --set=root --hint-bios=hd1,msdos8 --hint-efi=hd1,msdos8 --hint-baremetal=ahci1,msdos8  3d95e70d-8342-4c37-bf28-53e843f66a22\n        else\n          search --no-floppy --fs-uuid --set=root 3d95e70d-8342-4c37-bf28-53e843f66a22\n        fi\n        linux   /vmlinuz-4.2.0-16-generic root=UUID=26e384d0-b064-49c9-98a1-dd92bdfc8174 ro  quiet splash $vt_handoff\n        initrd  /initrd.img-4.2.0-16-generic\n\n", "Q: How can I know if some Ubuntu 10.04 packages are still available in Ubuntu 14.04? I have an Ubuntu 10.04 running on a server. I know that it isn't supported anymore, so I want to upgrade it to Ubuntu 14.04.\nI have had problems trying to do this (in a testing environment, of course), because some dependencies couldn't be resolved or some packages couldn't be found (And to be certain, that was from Ubuntu 10.04 to Ubuntu 12.04). I want to make certain that some packages are available in Ubuntu 14.04, or at least alternatives, because the server has a lot of applications that need dependencies which are, maybe, only available in Ubuntu 10.04 and when migrated... Not good things are going to happen if I upgrade it and they aren't available.\nWhat can I do to make certain that all the necessary dependencies are going to be met? I was thinking about an dpkg -l in both Ubuntu versions and compare them...\n\nA: Not exactly a straight answer, but, as you have mentioned, how about you create a list of packages available on both versions of Ubuntu (10.04 and 14.04) and then compare it using diff?\nYou can create this list executing the commands below on each server:\n\n$ sudo apt-get update\n$ dpkg -l > packages_version.txt\nWhere version could be an identification of OS version you executed (like \"10.04\" or \"14.04\").\nOnce you have both lists you could analyze it manually or execute diff to check the differences. Something like:\n$ diff packages_10.04.txt packages_14.04.txt\n", "Q: Ubuntu Touch: no onscreen keyboard in Firefox? How can I open an on-screen keyboard in Firefox on Ubuntu Touch (bq M10, OTA10.1)? I've tried in both tablet and desktop mode, and no keyboard pops up. I tried some other things, such as dragging from the bottom, without any luck.\nFirefox, despite being preinstalled, seems to be a pure desktop app. LibreOffice (also not adapted for Touch) appears to have the same problem.\n\nA: Searching some more I found that this seems to be a known bug actually: https://bugs.launchpad.net/canonical-pocket-desktop/+bug/1543351\nThis is the latest comment at this point:\n\nkevin gunn (kgunn72) wrote on 2016-04-15: #6\njust confirming, this is definitely on our todo list as a high priority.\n\nUPDATE 2016-07-06: the fix is currently in testing, and has been available through the rc-proposed channel for the last week. It is expected to be available in the OTA-12 stable release (mid July).\nUPDATE 2016-12-27: the fix is out in stable for some time now.\n\nA: The issue is already fixed on rc-proposed channel.\n\nLaunchpad Janitor (janitor) wrote on 2016-06-16:  #13\nThis bug was fixed in the package libertine -\n  1.2+16.10.20160615.1-0ubuntu1\n\nhttps://plus.google.com/u/0/+MichaelHall119/posts/ZhGsYNnRbnH\n", "Q: Skylake Intel 530 + 960m equals 100% fan usage on ubuntu 16.04 I just bought a new laptop, the Asus ROG 501jw with the Skylake i7 6700HQ + Intel graphics 530 and the Nvidia 960m. When running Ubuntu 16.04 the fans runs at 100% constantly when using the intel graphics, while there seems to be no problems when using the Nvidia proprietary driver. Is this a kernel related issue? Should I wait it out or is there a fix for this here and now?\n\nA: Same issue here on Asus Zenbook Pro UX501VW (same GPU and CPU, Ubuntu 16.04). After I changed \"quiet splash\" in grub to\nacpi_osi=! acpi_backlight=native idle=nomwait\nthe fan stopped spinning like mad and integrated GPU seems to work.\nBut now the system fails to shutdown normally and also hangs on executing glxinfo command.\nActually I don't quite understand what this line in grub means, but it was supposed to fix Fn+f5/f6 brightness buttons, which it does)\n\nA: I have the ROG G501vw (same CPU and GPU) and I had the same problem in any distro I tested.\nI solved it by disabling Nouveau, just add nouveau.modeset=0 to your grub kernel boot parameters.\nI tested this on other distros such as KDE Neon and Antergos and works fine (If you add it to the LiveCD options, it also solves the problem of it freezing on the splash screen).\nIn case you don't know how, add it to the line GRUB_CMDLINE_LINUX_DEFAULT in /etc/default/grub \nThis is how mine looks like:\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash acpi_osi=! acpi_backlight=native idle=nomwait nouveau.modeset=0\"\n\nHope it works for you :)\n\nA: I have exactly the same CPU and GPU and the same issue, I posted a similar question about this issue. From what I've read sky lake CPU's are not supported fully yet.\n", "Q: How to safely change OS name in grub boot menu? I have a system where I am dual-booting Ubuntu GNOME 15.10 and Ubuntu GNOME 16.04, however after installing Ubuntu GNOME 16.04, I have found that in the GRUB boot entry list it is called \"Ubuntu\", whereas the other one is called something like \"Ubuntu GNOME 15.10\", is there any way I can change the text of the \"Ubuntu\" one to \"Ubuntu GNOME 16.04\"? And also change the names of the other options so that instead of \"Advanced options for Ubuntu\" it says \"Advanced options for Ubuntu GNOME 16.04\" etc?\nI rather do it manually if it is safe to do so, or a piece of software could be recommended, however nothing from a PPA or other untrusted not official source (I will only install software from the Ubuntu official repositories).\n\nA: Open the grub configuration file:\nsudo nano /etc/default/grub\n\nJust comment the line starting with GRUB_DISTRIBUTOR and add one line:\n# GRUB_DISTRIBUTOR=`lsb_release -i -s 2> /dev/null || echo Debian`\nGRUB_DISTRIBUTOR=\"Ubuntu 15.10\"\n\nAfterwards, run\nsudo update-grub\n\nIt should work after the next reboot. You will need to boot to both ubuntu installations and to change both names.\nImportant Note: Something you'll want to avoid doing is editing the file /etc/lsb-release and modifying the value for DISTRIB_ID which is read from the command lsb_release -i -s. While this does work to rename the grub menu entry (if you haven't modified /etc/default/grub), other programs also rely on the default name and may crash if it's modified (e.g. \"Ubuntu\" for Xubuntu). With that said though, kernel updates also replace this file, which will undo any changes to it.\n\nA: There is a program called Grub Customizer that you can use for this. You can add, delete, move and rename entries. It also has a lot more features to set display resolution and so on.\nSee for yourself: https://launchpad.net/grub-customizer\nInstallation (Ubuntu >= 19.04):\nThe grub-customizer package is part of the default Ubuntu repositories:\nsudo apt install grub-customizer \n\nInstallation (older Ubuntu versions):\nThe following steps are copied from the page above:\nsudo add-apt-repository ppa:danielrichter2007/grub-customizer\nsudo apt-get update\nsudo apt-get install grub-customizer\n\nRename entry:\nAfter the installation I have a new entry under Application > System Tools > Administration called Grub Customizer.\n\n\n*\n\n*Start Grub Customizer\n\n*You will see the list of grub menu entries. Right click on one and choose \"Rename\".\n\n*Enter the new name\n\n*Click save in the toolbar and close the program\n\n\nThat's it.\n\nA: To automatically insert Ubuntu version number, and your own text prefix, replace\nGRUB_DISTRIBUTOR=`lsb_release -i -s 2> /dev/null || echo Debian`\n\nwith\n# GRUB_DISTRIBUTOR=`lsb_release -i -s 2> /dev/null || echo Debian`\nGRUB_DISTRIBUTOR=`{ printf My_Text_ && lsb_release -d -s ; } 2> /dev/null || echo Debian`\n\nI typically put some identifying text like 750G_ for disk size in there, which would show \n750G_Ubuntu 19.10\n\nfor Ubuntu 19.10.\nThis has been tested with Ubuntu 16.04 & 19.10. No, I do not know how to put a suffix. No, I do not know how to insert spaces. I have been swapping multiple disks around in multi-drive computers and just wanted confirmation of where I was.\n\nA: I have named my systems (see https://ubuntuhandbook.org/index.php/2016/06/change-hostname-ubuntu-16-04-without-restart/) and replaced\nGRUB_DISTRIBUTOR=lsb_release -i -s 2> /dev/null || echo Debian\nwith\nGRUB_DISTRIBUTOR=cat /etc/hostname || lsb_release -i -s 2> /dev/null || echo Debian\nand that works well.\nFor grub see https://www.gnu.org/software/grub/manual/grub/grub.html#Configuration\n", "Q: Ubuntu Touch: chromium port? There doesn't seem to be a chromium (or Google Chrome) port available in Ubuntu Touch (OTA10.1, bq M10). Does one exist, or are there any plans to have one (even without touch / small screen optimizations)?\n\nA: The system browser in the phone/tablet images is based on the Chromium Content API, and so is roughly the same experience as one would have with Chromium.\nIf you wish to use Chromium as a legacy X11 app, you should be able to install it inside the legacy apps container with Libertine, in the same way that Firefox/Libreoffice are available.\nGoogle does not provide generic ARM builds of Chrome, so the proprietary Chrome browser version will not be usable.\n\nA: You can use the command line tools to install applications in a libertine container. First you create a container in the writable part of the file system. I used the instructions here\nhttps://docs.google.com/document/d/1yJepibh68YaQijWO3Z3dWTtTTmzXnMmEE8eswhUXzw4/edit?pref=2&pli=1\nThe intsructions also tell you how to make a desktop file so it appears in the apps scope. I successfully installed emacs this way.\nIf you try to do this in the terminal app, you will run into problems due to lack of permissions. The easiest way around this is to start the ssh server with\nsudo android-gadget-service enable ssh\n\nThen run\nssh-keygen\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\neval $(ssh-agent)\nssh localhost\n\nNow you can follow the instructions and set up your libertine container and install applications. This script automates the process (I haven't tried it):\nhttp://paste.ubuntu.com/16001183/\n\nA: I am going to find a way to install Chromium on Ubuntu touch. The other methods mentioned here are not completely correct.\nWhile it is true that Google does not provide arm64 builds for Chromium, valid working builds do exist. I have installed one that provides casting to my smart TV, on Manjaro linux. This was done on my Pinephone. Now however, I am running Ubuntu Touch on my Pinephone.\nThe state of Libertine containers is pretty messy today. It is a lot of hassle and does not work as advertised from the Settings --> System Screen. So to me Libertine is not the answer.\n", "Q: Executing file with other application through terminal Is there any way for me to execute a .jar file with JRE through the command line. I'm having an issue with the file and I wanna see if I can get any information as to what the error is. When I try to execute it with ./ it says that that it can't execute binary file.  But the icon gives me the option to run with Java Runtime Environment.\n\nA: You have to run it though the JRE, not directly. ie. java -jar myapp.jar\n\n./ Is not actually a command to run a program/script/binary. It simply refers to the current directory. For example, if I have a script, myscript.sh, in my home directory;\n\nI can either run ./myscript.sh or /home/myusername/myscript.sh\nBoth of those would run the script.\nThe reason why you couldn't just run myscript.sh is because the termnal would try to interprit it as a known command, and throw this error: myscript.sh: command not found because it isn't smart enough to know that you were trying to direct it to a file in your current dir.\n\nA: As far as i know, the dote . can only be used to run shell scripts.\nSo you have to use java command to run .jar files\njava -jar your_file_name.jar\n\nThat's it !\n", "Q: apt-get keeps wanting to download a package, overriding my decision I've recently had a problem with the graphics on my laptop. I am currently trying a working nvidia driver, as my computer had problems with the previous one. When I try to issue any install command for any nvidia driver, apt get overrides my decision and installs a custom nvidia driver version (nvidia-340 to be precise). How can I deselect that package from command line? \n\nA: nvidia-330 (actually, all nvidia-3XX packages from nvidia-310 onwards) are transitional packages that actually install nvidia-340. If you want an older driver, use nvidia-304 instead.\n", "Q: Some programs print errors to stdout instead of stderr, and don't set $? when an error occurs. Why? See title. I've seen this twice recently, with both udisks and pacmd, and they are 100 times harder to script because of it. Why do programmers do this?\nFor example, I want to switch the audio output from a given program (sink input) onto a different output device (sink):\n$ pacmd move-sink-input $sink_input $sink\nWelcome to PulseAudio! Use \"help\" for usage information.\n>>> No sink input found with this index.\n>>> $ pacmd move-sink-input $sink_input $sink > /dev/null\n$ echo $?\n0\n\n\nA: pactl is more suitable to run a single command and gives better feedback.\npacmd is more for “shell sessions” with the PulseAudio daemon.\n", "Q: Should I avoid Ubuntu 16.04 with AMD Radeon Graphics card? Should I avoid Ubuntu 16.04 with AMD Radeon R5 Graphics card?  I heard AMD proprietary drivers are out and you must use the open-source ones.  Anyone with experience with these graphics cards on Ubuntu 16.04?  Will it make a difference?\n\nA: The best answer depends on how flexible you can be.  If you're a gamer and rely on the AMD card, then perhaps you should hold off.\nIf you have hybrid graphics (you also have Intel onboard graphics) then you could still run Ubuntu just fine, but again, you're limited in gaming to what the Intel can do.\nI for one, have a hybrid graphics laptop which has both an Intel and Radeon 7960XT graphics.  Graphics performance is perfectly fine for every day usage since I don't run games in Linux (I switch to Windows for that).  Browsing the net and other desktop apps run great and smooth.  I actually went ahead and disabled my AMD card and run only the Intel one.\nIf you really want to know for sure before installing 16.04, you can always download the 16.04 ISO and make it into a boot disk or bootable USB so that you can try it first, and see how it behaves.\nI strongly suggest using a bootable USB since you can install software and updates on it which will remain after you reboot.  Do this by making a boot stick using a program called unetbootin.\nDownload the ISO.\nInstall unetbootin if you don't have it with sudo apt-get install unetbootin\nRun unetbootin and select your ISO.\nIn the area \"Space used to preserve files across reboots\" give yourself at least 500MB or more if you can.  On my 32GB stick I opted for 2GB (2000MB).\nSelect your USB drive from the bottom dropdown menus and click OK.  Then reboot and boot off of the USB stick to test out 16.04.\nThe space you selected to preserve will be used to download updates and additional programs.  Now when you first login, you can connect to your network and get the latest updates.  Once everything is updated you can try out the OS with your graphics card(s) and even install some games to test out.  Again, use a large USB stick and allocate as much space as you can.\n\nA: I made the mistake of recently selecting and installing 14.04 LTS (amd_x64), under the false guidance that it would let me keep using the proprietary fglrx driver with my HD5670...only to find out they'd updated X to Xenial in this version as well (same version as in 16.04).\nHOWEVER, I must say that the open source driver has worked surprisingly well, even for 3D gaming.  I'm actually running some Windows OpenGL games using Wine, and the performance has been BETTER in Linux than it was on Win x64!  I haven't had any graphics related crashes or problems at all.\nI do wish there were more of a GUI for configuring 3D settings, but there are some tools to do some of the things you used to be able to control with CCC out there (see radeon-profile in ppa:trebelnik-stefina/radeon-profile for controlling power/frequency profiles, and driconf for configuring the Mesa/Gallium 3D settings).\nOne KEY thing I have discovered is that some 3D games, particularly those run under Wine (and probably many older games), will cause performance problems if you don't manually force the CPU and GPU to run in \"Performance\" mode.  To emulate the Windows thread scheduler (and perhaps how the older Linux kernels worked, too), there are lots of little sleeps and things peppered here and there...these cause the CPU to think it has a light load, and so it sheds clock cycles.  This, in turn, causes it to take longer to send commands to the GPU, which then does the same thing.  They throttle themselves back, and you get really erratic and slow frame rates, yet the CPU and GPU utilization %'s are only like 15-20%.\nIf your chip is well supported by the driver (many are), I think it will be a very positive experience.\n", "Q: phablet-dev-bootstrap: error: Cannot fetch CyanogenMod/android_external_koush_Superuser error: Exited sync due to fetch errors I was trying to run phablet-dev-bootstrap ../phablet it was throwing loads of 404 errors then eventually threw a fatal error:\ncurl: (22) The requested URL returned error: 404 Not Found\nServer does not provide clone.bundle; ignoring.\nfatal: remote error: Git repository not found\nfatal: remote error: Git repository not found\nerror: Cannot fetch CyanogenMod/android_external_koush_Superuser\n\nerror: Exited sync due to fetch errors\nERROR:phablet-dev-bootstrap:Error while trying to sync repository\n\nAny help will be appreciated!\n\nA: After discussing in chat, we figured out that using a different branch stopped the 404s & 503s & the Superuser issues. I also sent a email to a person who will hopefully fix the repo so we don't have to continue using another branch.\nEDIT: As of April 27th, 2016, this should be fixed on the main branch.\n", "Q: Can't get nVidia drivers working with 16.04, logs out right after login I have installed Ubuntu 16.04 beta 2 on Monday, Apr 18th. When I try to install nvidia-current, nvidia-361 or the version that jockey installs, either lightdm fails to start entirely or I can't get past the login window. When I log in, lightdm.log reports that I have logged in successfully, for some reasons it shows the sound volume I have set and then it returns back to the login screen.\nI have a laptop with hybrid nVidia/Intel graphics with the Optimus technology (I don't really need GPU switching, but I want nVidia to run properly), the exact nVidia model is GT630M.\nHere is Xorg.0.log:\n[    41.529] \nX.Org X Server 1.18.3\nRelease Date: 2016-04-04\n[    41.529] X Protocol Version 11, Revision 0\n[    41.529] Build Operating System: Linux 3.13.0-85-generic x86_64 Ubuntu\n[    41.529] Current Operating System: Linux dugi 4.4.0-21-generic #37-Ubuntu SMP Mon Apr 18 18:33:37 UTC 2016 x86_64\n[    41.529] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-4.4.0-21-generic root=UUID=77b76089-cd8b-4d0c-b074-1ec581c0a8a9 ro quiet splash\n[    41.529] Build Date: 07 April 2016  09:18:50AM\n[    41.529] xorg-server 2:1.18.3-1ubuntu2 (For technical support please see http://www.ubuntu.com/support) \n[    41.529] Current version of pixman: 0.33.6\n[    41.529]    Before reporting problems, check http://wiki.x.org\n    to make sure that you have the latest version.\n[    41.529] Markers: (--) probed, (**) from config file, (==) default setting,\n    (++) from command line, (!!) notice, (II) informational,\n    (WW) warning, (EE) error, (NI) not implemented, (??) unknown.\n[    41.529] (==) Log file: \"/var/log/Xorg.0.log\", Time: Fri Apr 22 00:40:13 2016\n[    41.530] (==) Using system config directory \"/usr/share/X11/xorg.conf.d\"\n[    41.530] (==) No Layout section.  Using the first Screen section.\n[    41.530] (==) No screen section available. Using defaults.\n[    41.530] (**) |-->Screen \"Default Screen Section\" (0)\n[    41.530] (**) |   |-->Monitor \"<default monitor>\"\n[    41.530] (==) No monitor specified for screen \"Default Screen Section\".\n    Using a default monitor configuration.\n[    41.530] (==) Automatically adding devices\n[    41.530] (==) Automatically enabling devices\n[    41.530] (==) Automatically adding GPU devices\n[    41.530] (==) Max clients allowed: 256, resource mask: 0x1fffff\n[    41.530] (WW) The directory \"/usr/share/fonts/X11/cyrillic\" does not exist.\n[    41.530]    Entry deleted from font path.\n[    41.530] (WW) The directory \"/usr/share/fonts/X11/100dpi/\" does not exist.\n[    41.530]    Entry deleted from font path.\n[    41.530] (WW) The directory \"/usr/share/fonts/X11/75dpi/\" does not exist.\n[    41.530]    Entry deleted from font path.\n[    41.530] (WW) The directory \"/usr/share/fonts/X11/100dpi\" does not exist.\n[    41.530]    Entry deleted from font path.\n[    41.530] (WW) The directory \"/usr/share/fonts/X11/75dpi\" does not exist.\n[    41.530]    Entry deleted from font path.\n[    41.530] (==) FontPath set to:\n    /usr/share/fonts/X11/misc,\n    /usr/share/fonts/X11/Type1,\n    built-ins\n[    41.530] (==) ModulePath set to \"/usr/lib/x86_64-linux-gnu/xorg/extra-modules,/usr/lib/xorg/extra-modules,/usr/lib/xorg/modules\"\n[    41.530] (II) The server relies on udev to provide the list of input devices.\n    If no devices become available, reconfigure udev or disable AutoAddDevices.\n[    41.530] (II) Loader magic: 0x55a83676cda0\n[    41.530] (II) Module ABI versions:\n[    41.530]    X.Org ANSI C Emulation: 0.4\n[    41.530]    X.Org Video Driver: 20.0\n[    41.530]    X.Org XInput driver : 22.1\n[    41.530]    X.Org Server Extension : 9.0\n[    41.530] (++) using VT number 7\n\n[    41.530] (II) systemd-logind: logind integration requires -keeptty and -keeptty was not provided, disabling logind integration\n[    41.531] (II) xfree86: Adding drm device (/dev/dri/card0)\n[    41.532] (--) PCI:*(0:0:2:0) 8086:0166:1028:0590 rev 9, Mem @ 0xf7400000/4194304, 0xd0000000/268435456, I/O @ 0x0000f000/64\n[    41.532] (WW) \"glamoregl\" will not be loaded unless you've specified it to be loaded elsewhere.\n[    41.532] (II) \"glx\" will be loaded by default.\n[    41.532] (II) LoadModule: \"glx\"\n[    41.532] (II) Loading /usr/lib/x86_64-linux-gnu/xorg/extra-modules/libglx.so\n[    41.537] (II) Module glx: vendor=\"NVIDIA Corporation\"\n[    41.537]    compiled for 4.0.2, module version = 1.0.0\n[    41.537]    Module class: X.Org Server Extension\n[    41.537] (II) NVIDIA GLX Module  304.131  Sun Nov  8 22:03:20 PST 2015\n[    41.537] (==) Matched intel as autoconfigured driver 0\n[    41.537] (==) Matched intel as autoconfigured driver 1\n[    41.537] (==) Matched modesetting as autoconfigured driver 2\n[    41.537] (==) Matched fbdev as autoconfigured driver 3\n[    41.537] (==) Matched vesa as autoconfigured driver 4\n[    41.537] (==) Assigned the driver to the xf86ConfigLayout\n[    41.537] (II) LoadModule: \"intel\"\n[    41.537] (II) Loading /usr/lib/xorg/modules/drivers/intel_drv.so\n[    41.537] (II) Module intel: vendor=\"X.Org Foundation\"\n[    41.537]    compiled for 1.18.1, module version = 2.99.917\n[    41.537]    Module class: X.Org Video Driver\n[    41.537]    ABI class: X.Org Video Driver, version 20.0\n[    41.537] (II) LoadModule: \"modesetting\"\n[    41.537] (II) Loading /usr/lib/xorg/modules/drivers/modesetting_drv.so\n[    41.537] (II) Module modesetting: vendor=\"X.Org Foundation\"\n[    41.537]    compiled for 1.18.3, module version = 1.18.3\n[    41.537]    Module class: X.Org Video Driver\n[    41.537]    ABI class: X.Org Video Driver, version 20.0\n[    41.537] (II) LoadModule: \"fbdev\"\n[    41.538] (II) Loading /usr/lib/xorg/modules/drivers/fbdev_drv.so\n[    41.538] (II) Module fbdev: vendor=\"X.Org Foundation\"\n[    41.538]    compiled for 1.18.1, module version = 0.4.4\n[    41.538]    Module class: X.Org Video Driver\n[    41.538]    ABI class: X.Org Video Driver, version 20.0\n[    41.538] (II) LoadModule: \"vesa\"\n[    41.538] (II) Loading /usr/lib/xorg/modules/drivers/vesa_drv.so\n[    41.538] (II) Module vesa: vendor=\"X.Org Foundation\"\n[    41.538]    compiled for 1.18.1, module version = 2.3.4\n[    41.538]    Module class: X.Org Video Driver\n[    41.538]    ABI class: X.Org Video Driver, version 20.0\n[    41.538] (II) intel: Driver for Intel(R) Integrated Graphics Chipsets:\n    i810, i810-dc100, i810e, i815, i830M, 845G, 854, 852GM/855GM, 865G,\n    915G, E7221 (i915), 915GM, 945G, 945GM, 945GME, Pineview GM,\n    Pineview G, 965G, G35, 965Q, 946GZ, 965GM, 965GME/GLE, G33, Q35, Q33,\n    GM45, 4 Series, G45/G43, Q45/Q43, G41, B43\n[    41.538] (II) intel: Driver for Intel(R) HD Graphics: 2000-6000\n[    41.538] (II) intel: Driver for Intel(R) Iris(TM) Graphics: 5100, 6100\n[    41.538] (II) intel: Driver for Intel(R) Iris(TM) Pro Graphics: 5200, 6200, P6300\n[    41.538] (II) modesetting: Driver for Modesetting Kernel Drivers: kms\n[    41.538] (II) FBDEV: driver for framebuffer: fbdev\n[    41.538] (II) VESA: driver for VESA chipsets: vesa\n[    41.538] (II) intel(0): Using Kernel Mode Setting driver: i915, version 1.6.0 20151010\n[    41.538] (II) intel(0): SNA compiled: xserver-xorg-video-intel 2:2.99.917+git20160325-1ubuntu1 (Timo Aaltonen <tjaalton@debian.org>)\n[    41.538] (II) intel(0): SNA compiled for use with valgrind\n[    41.538] (WW) Falling back to old probe method for modesetting\n[    41.538] (WW) Falling back to old probe method for fbdev\n[    41.538] (II) Loading sub module \"fbdevhw\"\n[    41.538] (II) LoadModule: \"fbdevhw\"\n[    41.538] (II) Loading /usr/lib/xorg/modules/libfbdevhw.so\n[    41.538] (II) Module fbdevhw: vendor=\"X.Org Foundation\"\n[    41.538]    compiled for 1.18.3, module version = 0.0.2\n[    41.538]    ABI class: X.Org Video Driver, version 20.0\n[    41.538] (WW) Falling back to old probe method for vesa\n[    41.539] (--) intel(0): Integrated Graphics Chipset: Intel(R) HD Graphics 4000\n[    41.539] (--) intel(0): CPU: x86-64, sse2, sse3, ssse3, sse4.1, sse4.2, avx; using a maximum of 2 threads\n[    41.539] (II) intel(0): Creating default Display subsection in Screen section\n    \"Default Screen Section\" for depth/fbbpp 24/32\n[    41.539] (==) intel(0): Depth 24, (--) framebuffer bpp 32\n[    41.539] (==) intel(0): RGB weight 888\n[    41.539] (==) intel(0): Default visual is TrueColor\n[    41.539] (II) intel(0): Output LVDS1 has no monitor section\n[    41.552] (--) intel(0): Found backlight control interface intel_backlight (type 'raw') for output LVDS1\n[    41.552] (II) intel(0): Enabled output LVDS1\n[    41.552] (II) intel(0): Output VGA1 has no monitor section\n[    41.552] (II) intel(0): Enabled output VGA1\n[    41.552] (II) intel(0): Output HDMI1 has no monitor section\n[    41.552] (II) intel(0): Enabled output HDMI1\n[    41.552] (II) intel(0): Output DP1 has no monitor section\n[    41.552] (II) intel(0): Enabled output DP1\n[    41.552] (--) intel(0): Using a maximum size of 256x256 for hardware cursors\n[    41.552] (II) intel(0): Output VIRTUAL1 has no monitor section\n[    41.552] (II) intel(0): Enabled output VIRTUAL1\n[    41.552] (--) intel(0): Output LVDS1 using initial mode 1366x768 on pipe 0\n[    41.552] (==) intel(0): TearFree disabled\n[    41.552] (==) intel(0): DPI set to (96, 96)\n[    41.552] (II) Loading sub module \"dri2\"\n[    41.552] (II) LoadModule: \"dri2\"\n[    41.552] (II) Module \"dri2\" already built-in\n[    41.552] (II) Loading sub module \"present\"\n[    41.552] (II) LoadModule: \"present\"\n[    41.552] (II) Module \"present\" already built-in\n[    41.552] (II) UnloadModule: \"modesetting\"\n[    41.552] (II) Unloading modesetting\n[    41.552] (II) UnloadModule: \"fbdev\"\n[    41.552] (II) Unloading fbdev\n[    41.553] (II) UnloadSubModule: \"fbdevhw\"\n[    41.553] (II) Unloading fbdevhw\n[    41.553] (II) UnloadModule: \"vesa\"\n[    41.553] (II) Unloading vesa\n[    41.553] (==) Depth 24 pixmap format is 32 bpp\n[    41.553] (II) intel(0): SNA initialized with Ivybridge (gen7, gt2) backend\n[    41.553] (==) intel(0): Backing store enabled\n[    41.553] (==) intel(0): Silken mouse enabled\n[    41.553] (II) intel(0): HW Cursor enabled\n[    41.553] (II) intel(0): RandR 1.2 enabled, ignore the following RandR disabled message.\n[    41.553] (==) intel(0): DPMS enabled\n[    41.553] (==) intel(0): Display hotplug detection enabled\n[    41.553] (II) intel(0): [DRI2] Setup complete\n[    41.553] (II) intel(0): [DRI2]   DRI driver: i965\n[    41.553] (II) intel(0): [DRI2]   VDPAU driver: va_gl\n[    41.553] (II) intel(0): direct rendering: DRI2 enabled\n[    41.553] (II) intel(0): hardware support for Present enabled\n[    41.553] (--) RandR disabled\n[    41.556] (II) SELinux: Disabled on system\n[    41.557] (EE) Failed to initialize GLX extension (Compatible NVIDIA X driver not found)\n[    41.558] (II) intel(0): switch to mode 1366x768@60.0 on LVDS1 using pipe 0, position (0, 0), rotation normal, reflection none\n[    41.558] (II) intel(0): Setting screen physical size to 361 x 203\n[    41.582] (II) config/udev: Adding input device Power Button (/dev/input/event3)\n[    41.582] (**) Power Button: Applying InputClass \"evdev keyboard catchall\"\n[    41.582] (II) LoadModule: \"evdev\"\n[    41.582] (II) Loading /usr/lib/xorg/modules/input/evdev_drv.so\n[    41.582] (II) Module evdev: vendor=\"X.Org Foundation\"\n[    41.582]    compiled for 1.18.1, module version = 2.10.1\n[    41.582]    Module class: X.Org XInput Driver\n[    41.582]    ABI class: X.Org XInput driver, version 22.1\n[    41.582] (II) Using input driver 'evdev' for 'Power Button'\n[    41.582] (**) Power Button: always reports core events\n[    41.582] (**) evdev: Power Button: Device: \"/dev/input/event3\"\n[    41.582] (--) evdev: Power Button: Vendor 0 Product 0x1\n[    41.583] (--) evdev: Power Button: Found keys\n[    41.583] (II) evdev: Power Button: Configuring as keyboard\n[    41.583] (**) Option \"config_info\" \"udev:/sys/devices/LNXSYSTM:00/LNXPWRBN:00/input/input3/event3\"\n[    41.583] (II) XINPUT: Adding extended input device \"Power Button\" (type: KEYBOARD, id 6)\n[    41.583] (**) Option \"xkb_rules\" \"evdev\"\n[    41.583] (**) Option \"xkb_model\" \"pc105\"\n[    41.583] (**) Option \"xkb_layout\" \"sk\"\n[    41.583] (**) Option \"xkb_variant\" \"qwerty\"\n[    41.596] (II) config/udev: Adding input device Video Bus (/dev/input/event6)\n[    41.596] (**) Video Bus: Applying InputClass \"evdev keyboard catchall\"\n[    41.596] (II) Using input driver 'evdev' for 'Video Bus'\n[    41.596] (**) Video Bus: always reports core events\n[    41.596] (**) evdev: Video Bus: Device: \"/dev/input/event6\"\n[    41.596] (--) evdev: Video Bus: Vendor 0 Product 0x6\n[    41.596] (--) evdev: Video Bus: Found keys\n[    41.596] (II) evdev: Video Bus: Configuring as keyboard\n[    41.596] (**) Option \"config_info\" \"udev:/sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A08:00/LNXVIDEO:01/input/input8/event6\"\n[    41.596] (II) XINPUT: Adding extended input device \"Video Bus\" (type: KEYBOARD, id 7)\n[    41.596] (**) Option \"xkb_rules\" \"evdev\"\n[    41.596] (**) Option \"xkb_model\" \"pc105\"\n[    41.596] (**) Option \"xkb_layout\" \"sk\"\n[    41.596] (**) Option \"xkb_variant\" \"qwerty\"\n[    41.596] (II) config/udev: Adding input device Video Bus (/dev/input/event5)\n[    41.596] (**) Video Bus: Applying InputClass \"evdev keyboard catchall\"\n[    41.596] (II) Using input driver 'evdev' for 'Video Bus'\n[    41.596] (**) Video Bus: always reports core events\n[    41.596] (**) evdev: Video Bus: Device: \"/dev/input/event5\"\n[    41.596] (--) evdev: Video Bus: Vendor 0 Product 0x6\n[    41.596] (--) evdev: Video Bus: Found keys\n[    41.596] (II) evdev: Video Bus: Configuring as keyboard\n[    41.596] (**) Option \"config_info\" \"udev:/sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A08:00/device:19/LNXVIDEO:00/input/input7/event5\"\n[    41.596] (II) XINPUT: Adding extended input device \"Video Bus\" (type: KEYBOARD, id 8)\n[    41.596] (**) Option \"xkb_rules\" \"evdev\"\n[    41.596] (**) Option \"xkb_model\" \"pc105\"\n[    41.596] (**) Option \"xkb_layout\" \"sk\"\n[    41.596] (**) Option \"xkb_variant\" \"qwerty\"\n[    41.597] (II) config/udev: Adding input device Power Button (/dev/input/event1)\n[    41.597] (**) Power Button: Applying InputClass \"evdev keyboard catchall\"\n[    41.597] (II) Using input driver 'evdev' for 'Power Button'\n[    41.597] (**) Power Button: always reports core events\n[    41.597] (**) evdev: Power Button: Device: \"/dev/input/event1\"\n[    41.597] (--) evdev: Power Button: Vendor 0 Product 0x1\n[    41.597] (--) evdev: Power Button: Found keys\n[    41.597] (II) evdev: Power Button: Configuring as keyboard\n[    41.597] (**) Option \"config_info\" \"udev:/sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0C0C:00/input/input1/event1\"\n[    41.597] (II) XINPUT: Adding extended input device \"Power Button\" (type: KEYBOARD, id 9)\n[    41.597] (**) Option \"xkb_rules\" \"evdev\"\n[    41.597] (**) Option \"xkb_model\" \"pc105\"\n[    41.597] (**) Option \"xkb_layout\" \"sk\"\n[    41.597] (**) Option \"xkb_variant\" \"qwerty\"\n[    41.597] (II) config/udev: Adding input device Lid Switch (/dev/input/event0)\n[    41.597] (II) No input driver specified, ignoring this device.\n[    41.597] (II) This device may have been added with another device file.\n[    41.598] (II) config/udev: Adding input device Sleep Button (/dev/input/event2)\n[    41.598] (**) Sleep Button: Applying InputClass \"evdev keyboard catchall\"\n[    41.598] (II) Using input driver 'evdev' for 'Sleep Button'\n[    41.598] (**) Sleep Button: always reports core events\n[    41.598] (**) evdev: Sleep Button: Device: \"/dev/input/event2\"\n[    41.598] (--) evdev: Sleep Button: Vendor 0 Product 0x3\n[    41.598] (--) evdev: Sleep Button: Found keys\n[    41.598] (II) evdev: Sleep Button: Configuring as keyboard\n[    41.598] (**) Option \"config_info\" \"udev:/sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0C0E:00/input/input2/event2\"\n[    41.598] (II) XINPUT: Adding extended input device \"Sleep Button\" (type: KEYBOARD, id 10)\n[    41.598] (**) Option \"xkb_rules\" \"evdev\"\n[    41.598] (**) Option \"xkb_model\" \"pc105\"\n[    41.598] (**) Option \"xkb_layout\" \"sk\"\n[    41.598] (**) Option \"xkb_variant\" \"qwerty\"\n[    41.598] (II) config/udev: Adding input device HID 04d9:1133 (/dev/input/event7)\n[    41.598] (**) HID 04d9:1133: Applying InputClass \"evdev pointer catchall\"\n[    41.598] (II) Using input driver 'evdev' for 'HID 04d9:1133'\n[    41.598] (**) HID 04d9:1133: always reports core events\n[    41.598] (**) evdev: HID 04d9:1133: Device: \"/dev/input/event7\"\n[    41.652] (--) evdev: HID 04d9:1133: Vendor 0x4d9 Product 0x1133\n[    41.652] (--) evdev: HID 04d9:1133: Found 3 mouse buttons\n[    41.652] (--) evdev: HID 04d9:1133: Found scroll wheel(s)\n[    41.652] (--) evdev: HID 04d9:1133: Found relative axes\n[    41.652] (--) evdev: HID 04d9:1133: Found x and y relative axes\n[    41.652] (II) evdev: HID 04d9:1133: Configuring as mouse\n[    41.652] (II) evdev: HID 04d9:1133: Adding scrollwheel support\n[    41.652] (**) evdev: HID 04d9:1133: YAxisMapping: buttons 4 and 5\n[    41.652] (**) evdev: HID 04d9:1133: EmulateWheelButton: 4, EmulateWheelInertia: 10, EmulateWheelTimeout: 200\n[    41.652] (**) Option \"config_info\" \"udev:/sys/devices/pci0000:00/0000:00:14.0/usb3/3-2/3-2:1.0/0003:04D9:1133.0001/input/input9/event7\"\n[    41.652] (II) XINPUT: Adding extended input device \"HID 04d9:1133\" (type: MOUSE, id 11)\n[    41.652] (II) evdev: HID 04d9:1133: initialized for relative axes.\n[    41.652] (**) HID 04d9:1133: (accel) keeping acceleration scheme 1\n[    41.652] (**) HID 04d9:1133: (accel) acceleration profile 0\n[    41.652] (**) HID 04d9:1133: (accel) acceleration factor: 2.000\n[    41.652] (**) HID 04d9:1133: (accel) acceleration threshold: 4\n[    41.653] (II) config/udev: Adding input device HID 04d9:1133 (/dev/input/mouse0)\n[    41.653] (II) No input driver specified, ignoring this device.\n[    41.653] (II) This device may have been added with another device file.\n[    41.653] (II) config/udev: Adding input device Laptop_Integrated_Webcam_HD (/dev/input/event10)\n[    41.653] (**) Laptop_Integrated_Webcam_HD: Applying InputClass \"evdev keyboard catchall\"\n[    41.653] (II) Using input driver 'evdev' for 'Laptop_Integrated_Webcam_HD'\n[    41.653] (**) Laptop_Integrated_Webcam_HD: always reports core events\n[    41.653] (**) evdev: Laptop_Integrated_Webcam_HD: Device: \"/dev/input/event10\"\n[    41.653] (--) evdev: Laptop_Integrated_Webcam_HD: Vendor 0x1bcf Product 0x2982\n[    41.653] (--) evdev: Laptop_Integrated_Webcam_HD: Found keys\n[    41.653] (II) evdev: Laptop_Integrated_Webcam_HD: Configuring as keyboard\n[    41.653] (**) Option \"config_info\" \"udev:/sys/devices/pci0000:00/0000:00:1a.0/usb1/1-1/1-1.5/1-1.5:1.0/input/input12/event10\"\n[    41.653] (II) XINPUT: Adding extended input device \"Laptop_Integrated_Webcam_HD\" (type: KEYBOARD, id 12)\n[    41.653] (**) Option \"xkb_rules\" \"evdev\"\n[    41.653] (**) Option \"xkb_model\" \"pc105\"\n[    41.653] (**) Option \"xkb_layout\" \"sk\"\n[    41.653] (**) Option \"xkb_variant\" \"qwerty\"\n[    41.653] (II) config/udev: Adding input device HDA Intel PCH Mic (/dev/input/event12)\n[    41.653] (II) No input driver specified, ignoring this device.\n[    41.653] (II) This device may have been added with another device file.\n[    41.654] (II) config/udev: Adding input device HDA Intel PCH Headphone (/dev/input/event13)\n[    41.654] (II) No input driver specified, ignoring this device.\n[    41.654] (II) This device may have been added with another device file.\n[    41.654] (II) config/udev: Adding input device HDA Intel PCH HDMI/DP,pcm=3 (/dev/input/event14)\n[    41.654] (II) No input driver specified, ignoring this device.\n[    41.654] (II) This device may have been added with another device file.\n[    41.654] (II) config/udev: Adding input device Atmel Atmel maXTouch Digitizer (/dev/input/event9)\n[    41.654] (**) Atmel Atmel maXTouch Digitizer: Applying InputClass \"evdev touchscreen catchall\"\n[    41.654] (II) Using input driver 'evdev' for 'Atmel Atmel maXTouch Digitizer'\n[    41.654] (**) Atmel Atmel maXTouch Digitizer: always reports core events\n[    41.654] (**) evdev: Atmel Atmel maXTouch Digitizer: Device: \"/dev/input/event9\"\n[    41.709] (--) evdev: Atmel Atmel maXTouch Digitizer: Vendor 0x3eb Product 0x8803\n[    41.709] (--) evdev: Atmel Atmel maXTouch Digitizer: Found absolute axes\n[    41.709] (--) evdev: Atmel Atmel maXTouch Digitizer: Found absolute multitouch axes\n[    41.709] (II) evdev: Atmel Atmel maXTouch Digitizer: No buttons found, faking one.\n[    41.709] (--) evdev: Atmel Atmel maXTouch Digitizer: Found x and y absolute axes\n[    41.709] (--) evdev: Atmel Atmel maXTouch Digitizer: Found absolute touchscreen\n[    41.709] (II) evdev: Atmel Atmel maXTouch Digitizer: Configuring as touchscreen\n[    41.709] (**) evdev: Atmel Atmel maXTouch Digitizer: YAxisMapping: buttons 4 and 5\n[    41.709] (**) evdev: Atmel Atmel maXTouch Digitizer: EmulateWheelButton: 4, EmulateWheelInertia: 10, EmulateWheelTimeout: 200\n[    41.709] (**) Option \"config_info\" \"udev:/sys/devices/pci0000:00/0000:00:1d.0/usb2/2-1/2-1.5/2-1.5:1.0/0003:03EB:8803.0002/input/input10/event9\"\n[    41.709] (II) XINPUT: Adding extended input device \"Atmel Atmel maXTouch Digitizer\" (type: TOUCHSCREEN, id 13)\n[    41.709] (II) evdev: Atmel Atmel maXTouch Digitizer: initialized for absolute axes.\n[    41.709] (**) Atmel Atmel maXTouch Digitizer: (accel) keeping acceleration scheme 1\n[    41.709] (**) Atmel Atmel maXTouch Digitizer: (accel) acceleration profile 0\n[    41.709] (**) Atmel Atmel maXTouch Digitizer: (accel) acceleration factor: 2.000\n[    41.709] (**) Atmel Atmel maXTouch Digitizer: (accel) acceleration threshold: 4\n[    41.710] (II) config/udev: Adding input device Atmel Atmel maXTouch Digitizer (/dev/input/mouse2)\n[    41.710] (II) No input driver specified, ignoring this device.\n[    41.710] (II) This device may have been added with another device file.\n[    41.710] (II) config/udev: Adding input device AT Translated Set 2 keyboard (/dev/input/event4)\n[    41.710] (**) AT Translated Set 2 keyboard: Applying InputClass \"evdev keyboard catchall\"\n[    41.710] (II) Using input driver 'evdev' for 'AT Translated Set 2 keyboard'\n[    41.710] (**) AT Translated Set 2 keyboard: always reports core events\n[    41.710] (**) evdev: AT Translated Set 2 keyboard: Device: \"/dev/input/event4\"\n[    41.710] (--) evdev: AT Translated Set 2 keyboard: Vendor 0x1 Product 0x1\n[    41.710] (--) evdev: AT Translated Set 2 keyboard: Found keys\n[    41.710] (II) evdev: AT Translated Set 2 keyboard: Configuring as keyboard\n[    41.710] (**) Option \"config_info\" \"udev:/sys/devices/platform/i8042/serio0/input/input4/event4\"\n[    41.710] (II) XINPUT: Adding extended input device \"AT Translated Set 2 keyboard\" (type: KEYBOARD, id 14)\n[    41.710] (**) Option \"xkb_rules\" \"evdev\"\n[    41.710] (**) Option \"xkb_model\" \"pc105\"\n[    41.710] (**) Option \"xkb_layout\" \"sk\"\n[    41.710] (**) Option \"xkb_variant\" \"qwerty\"\n[    41.710] (II) config/udev: Adding input device SynPS/2 Synaptics TouchPad (/dev/input/event8)\n###/// A load of unrelated stuff about touchpad ///###\n[    41.794] (**) Option \"config_info\" \"udev:/sys/devices/virtual/input/input13/event11\"\n[    41.794] (II) XINPUT: Adding extended input device \"Dell WMI hotkeys\" (type: KEYBOARD, id 16)\n[    41.794] (**) Option \"xkb_rules\" \"evdev\"\n[    41.794] (**) Option \"xkb_model\" \"pc105\"\n[    41.794] (**) Option \"xkb_layout\" \"sk\"\n[    41.794] (**) Option \"xkb_variant\" \"qwerty\"\n[    42.345] (II) intel(0): EDID vendor \"CMN\", prod id 5558\n[    42.345] (II) intel(0): Printing DDC gathered Modelines:\n[    42.345] (II) intel(0): Modeline \"1366x768\"x0.0   76.66  1366 1397 1462 1592  768 772 784 802 +hsync -vsync (48.2 kHz eP)\n[    42.345] (II) intel(0): Modeline \"1366x768\"x0.0   51.01  1366 1380 1409 1592  768 770 777 800 +hsync -vsync (32.0 kHz e)\n\nThis is the xorg.conf.XXXXXXXX in use:\nSection \"ServerLayout\"\n    Identifier \"layout\"\n    Screen 0 \"nvidia\"\n    Inactive \"intel\"\nEndSection\n\nSection \"Device\"\n    Identifier \"intel\"\n    Driver \"modesetting\"\n    BusID \"PCI:0@0:2:0\"\n    Option \"AccelMethod\" \"None\"\nEndSection\n\nSection \"Screen\"\n    Identifier \"intel\"\n    Device \"intel\"\nEndSection\n\nSection \"Device\"\n    Identifier \"nvidia\"\n    Driver \"nvidia\"\n    BusID \"PCI:2@0:0:0\"\n    Option \"ConstrainCursor\" \"off\"\nEndSection\n\nSection \"Screen\"\n    Identifier \"nvidia\"\n    Device \"nvidia\"\n    Option \"AllowEmptyInitialConfiguration\" \"on\"\n    Option \"IgnoreDisplayDevices\" \"CRT\"\nEndSection\n\nFor now, I am stuck with nouveau/intel, which is sometimes quite limiting. Any idea what can be going on? Maybe the missing /etc/X11/xorg.conf file could be the problem, but I don't know why it isn't there.\nNote:\nAs of the main release of 16.04, the error has changed from no devices detected and no screens found to Failed to initialize GLX extension (Compatible NVIDIA X driver not found). Now, lightdm starts easier, but I still can't get past the login screen.\nFurther edit:\nI had secure boot disabled all the time. I have installed bumblebee that added the nvidia driver (tried 304 and 340), but it was not able to start programs using the nVidia video card. Futher investigation has shown that modprobe for nvidia was failing due to something like this:\ncould not insert 'nvidia': Unknown symbol in module, or unknown parameter (see dmesg)\n\nI tried a later version of the driver (361), but it kept on failing. I have read somewhere that i915 drivers were causing this trouble, but I had not them installed.\nMore information:\nThis appears to be the root cause. With nVidia driver installed together with its DKMS module, I could not insert it into kernel (using modprobe). The reported error was that it can't find it a specific PCI port (the one where it should be according to lspci). I haven't saved the exact wording, sorry for that.\n\nA: I had some problems with Nvidia and 16.04 - finally got it working. on an nvidia gtx980m (asus G752 gaming laptop) - I suggest making sure you try to install from command line, and not simply enabling the proprietary drivers from the gui...(read on)\nI am not getting the boot loop described, but I was getting low res (800x600) and it would not work at all - but the nouveau one was fine. (all via the drivers gui)\nI finally dropped to command line and installed the same package via \"sudo apt-get install nvidia-xxx (in my case was 361 - also tried 352) \nit then installed as normal, but a menu popped in the terminal up that said \"UEFI\" secure boot was enabled and you would have to put in a one time password to disable it on reboot\" to boot into insecure mode. So I did that.\nOnce that was done, on reboot - sure enough a UEFI window menu popped up and I choosed to change boot mode to insecure. It then asked me several characters \"by position\" (EG...type in character 6, then type in character 4, etc) followed by enter each time. Eventually after 3-4 characters, it allowed me to turn off secure boot. Then the machine rebooted again, and said \"booting insecure mode\" and the drivers then worked. \nAlso discovered then when installing virtualbox as well via synaptic, but at least it worked and popped up a menu using that method....\nhope that helps...\n\nA: How do I get my desktop back?\nBy pressing ctrl-alt-f1 from the login screen, you can go to a commandline. Login using your username and password. From this commandline, you can uninstall the nvidia drivers by running the following commands:\nsudo apt remove nvidia-361\nsudo apt autoremove\n\nNote that the specific version of nvidia might be different. You can find out the version of the installed nvidia driver by running apt search nvidia | grep installed | grep nvidia\nor if you just want to switch to the Intel graphics card without removing the nvidia driver, run\nprime-select intel\n\nBut I want to use my nvidia card!\nThere are a few options you can try:\nDisable secure boot\nAs @biff said, Secure Boot might block the nvidia driver from loading. To disable secure boot, install the nvidia driver using the commandline. Ubuntu will ask you to disable secure boot during the installation.\nInstall the older nvidia driver\nSome problems might be fixed by installing the older nvidia driver.\n\nA: Thanks to the collective effort of the community, I have managed to get it working.\nFirst, get to a Terminal (by pressing ctrl-alt-f1 if you can't log in, or through recovery mode). Install nVidia drivers version 364 (package nvidia-364).\nsudo apt-get install nvidia-364\n\nIf the package is not found, add the ppa that contains it:\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\n\nReboot your computer.\nsudo reboot -i NOW\n\nIf you're not thrown back to the login screen, but you get to see only your background, force it to recreate your user settings (saving a backup):\nsudo mv ~/.config/dconf/user ~/.config/dconf/user.old\n\nThen, restart lightdm:\nsudo service lightdm restart\n\nIf you want to install bumblebee, beware that its configuration will be set badly and it will look for nvidia-current even if nvidia-current is not installed. I have edited it to refer to nvidia-364 instead (because the installed files are in /usr/lib/nvidia-364) and I was able to start programs with optirun.\n\nA: I have a GTX980 and was not able to login after upgrade to 16.04 (from 15.10). Remove nvidia:\nsudo apt-get purge nvidia*\n\nand logged in. It worked but resolution was limited to 800x600. \nFollowing steps resolved my issue:\n\n\n*\n\n*Reinstall nvidia: sudo apt-get install nvidia-361\n\n*Reboot, goto BIOS and disable Secure Boot\n\n\nThanks biff for the tip to disable secure boot :-)\n\nA: I have the same problem. Running Ubuntu 16.04. Intel HD4600 and Nvidia 765M. Tried all the suggestions above. \nIt worked when installing using terminal, but if I use multiple monitors it bugs out and I end up in a boot loop. \nI've read someone suggesting that the beta driver 364xx works.\n\nA: In my case, just installing nvidia-364 solved the problem.  My configuration is NVidia GTX 750Ti on ASUS H170 + Intel i7 6700 + 32Gb DDR4 running Ubuntu 16.04.\n", "Q: How to upgrade or downgrade QtCreator? I am trying to avoid this nasty bug in QtCreator 3.5.1.\nhttps://bugreports.qt.io/browse/QTCREATORBUG-15291\nI am quite sure that it is not present either in QtCreator 3.6.1 or in QtCreator 3.4.2. However I am not able to install either of them.\n\n\n*\n\n*The online installers from Qt redirect me to 3.5.1.\n\n*The offline installers from Qt are only for 64bit Linux\n\n*I tried addning a PPA, then apt-get update upgrade, but nothing happened\n\n\nAny guidance is well appreciated.\n\nA: There is an archive of old Qt version on their website on: http://download.qt.io/official_releases/qtcreator/ or http://download.qt.io/archive/ (for older versions)\nIf you feel like compiling, you may download any version from github and compile it for yourself: https://github.com/qtproject/qt-creator\n", "Q: OpenGL error in Snaps Ubuntu 16.04 Snap packages are failing to launch the UI complaining of \nlibGL error: No matching fbConfigs or visuals found\nlibGL error: failed to load driver: swrast\nUnrecognized OpenGL version\nUnrecognized OpenGL version\n\nI've purged the Nvidia drivers to see if the Open Source ones would work, but with no luck. The packages that I have attempted to install have opengl as a listing in the yaml file. OpenGL seems to be working in other aspects of the system so I don't believe it to be an issue with the system.\n\nA: I'm curious if you downloaded the calculator/clock snaps from the store? or did you package those locally? I'm assuming from the store, if so, it would be interesting if you could try to package those locally and sideload them.\nYou can find them from lp:snappy-desktop-examples\nAlso here's an interesting link on the topic of nvidia gpu and failing to load Problems with libGl, fbConfigs, swrast through each update? \n", "Q: Dual boot win 10 ubuntu I do not have the option to install Ubuntu along side windows 10.\nIt only gives the option to format the drive, and install Ubuntu. \nHowever I have partitioned my drive to make space for Ubuntu.\n\nA: There should be an option to do something else, at the bottom of the window. If you pick that one, it will let you pick the partition you want to use for Ubuntu, which ones do you want to format and which you don't, pretty much anything you might possibly want.\n", "Q: How to copy an image to the clipboard from a file using command line? I'd like to write a script to take an image file, scale it 50% and put it on the clipboard so it can be pasted easily. The bit I'm stuck on is how to place an image on the clipboard.\nI know of xclip, but AFAICS that only deals with text. Is it possible to have an image on the clipboard without the application that generated it sitting around? - Sorry I'm not sure of the internals of how the clipboard works!\nEDIT\nThanks to Florian's answer below I was able to achieve what I wanted, which was to take a screenshot and automatically scale it to a max of 600px wide (e.g. for pasting into an email). The further problem I faced was that Thunderbird won't accept image/png from the clipboard. I got round this by converting it to text/html with a data url. Here's my code in case anyone finds it useful:\n#!/bin/bash\nTMP=/tmp/screenshot.png\nfunction screenshotfail {\n  notify-send -u low -i image \"Screenshot failed.\"\n  exit\n}\n# Take screenshot\ngnome-screenshot -a -b -p -f \"$TMP\" || screenshotfail\n# Ensure it's max 600px wide\nmogrify -resize '>600x' \"$TMP\" || screenshotfail\n# optimise the png if optipng is installed.\nwhich optipng >/dev/null && optipng \"$TMP\"\n\n# Copy to clipboard.\n#\n# This is what does not work for Thunderbird:\n#   xclip -selection clipboard -t image/png <\"$TMP\" || screenshotfail\n# But this does:\necho \"<img src='data:image/png;base64,\"$(base64 -w0 \"$TMP\")\"' />\" | \\\n  xclip -selection clipboard -t text/html || screenshotfail\n\n# Remove the temp file.\nrm -f \"$TMP\"\n\n# Notify user.\nnotify-send -u low -i image \"600px screenshot copied to clipboard\"\n\n\nA: Use the -t option to specify the content type, like\nxclip -selection clipboard -t image/png -i example.png\n\n", "Q: USB 3.0 Host Controller not working on Xubuntu 14.04 LTS I installed Xubuntu 14.04 LTS on a Dell Inspiron 14R N4110 notebook and recently the USB 3.0 ports (blue ports) has intermittent operation. I know that these ports are on the I/O board which contains audio and ethernet ports that are working perfectly.\nI've already tried adding 'usbcore.autosuspend' to the '/etc/default/grub' but this doesn't work.\nSomeone who has had a similar problem? Is it possible solve using some configs or just replacing the board?\nlsusb\nBus 002 Device 005: ID 8087:07d9 Intel Corp. \nBus 002 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub\nBus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 001 Device 003: ID 1bcf:2b80 Sunplus Innovation Technology Inc. \nBus 001 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\n\nlspci\n00:00.0 Host bridge: Intel Corporation 2nd Generation Core Processor Family DRAM Controller (rev 09)\n00:02.0 VGA compatible controller: Intel Corporation 2nd Generation Core Processor Family Integrated Graphics Controller (rev 09)\n00:16.0 Communication controller: Intel Corporation 6 Series/C200 Series Chipset Family MEI Controller #1 (rev 04)\n00:1a.0 USB controller: Intel Corporation 6 Series/C200 Series Chipset Family USB Enhanced Host Controller #2 (rev 05)\n00:1b.0 Audio device: Intel Corporation 6 Series/C200 Series Chipset Family High Definition Audio Controller (rev 05)\n00:1c.0 PCI bridge: Intel Corporation 6 Series/C200 Series Chipset Family PCI Express Root Port 1 (rev b5)\n00:1c.2 PCI bridge: Intel Corporation 6 Series/C200 Series Chipset Family PCI Express Root Port 3 (rev b5)\n00:1c.4 PCI bridge: Intel Corporation 6 Series/C200 Series Chipset Family PCI Express Root Port 5 (rev b5)\n00:1d.0 USB controller: Intel Corporation 6 Series/C200 Series Chipset Family USB Enhanced Host Controller #1 (rev 05)\n00:1f.0 ISA bridge: Intel Corporation HM67 Express Chipset Family LPC Controller (rev 05)\n00:1f.2 SATA controller: Intel Corporation 6 Series/C200 Series Chipset Family 6 port SATA AHCI Controller (rev 05)\n00:1f.3 SMBus: Intel Corporation 6 Series/C200 Series Chipset Family SMBus Controller (rev 05)\n01:00.0 Network controller: Intel Corporation Centrino Wireless-N 1030 [Rainbow Peak] (rev 34)\n02:00.0 USB controller: NEC Corporation uPD720200 USB 3.0 Host Controller (rev 04)\n03:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8101/2/6E PCI Express Fast/Gigabit Ethernet controller (rev 05)\n\nlshw\nWARNING: you should run this program as super-user.\nblackice                  \n    description: Computer\n    width: 64 bits\n    capabilities: vsyscall32\n  *-core\n       description: Motherboard\n       physical id: 0\n     *-memory\n          description: System memory\n          physical id: 0\n          size: 3845MiB\n     *-cpu\n          product: Intel(R) Core(TM) i3-2310M CPU @ 2.10GHz\n          vendor: Intel Corp.\n          physical id: 1\n          bus info: cpu@0\n          size: 952MHz\n          capacity: 952MHz\n          width: 64 bits\n          capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp x86-64 constant_tsc arch_perfmon pebs bts nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer xsave avx lahf_lm arat epb pln pts dtherm tpr_shadow vnmi flexpriority ept vpid xsaveopt cpufreq\n     *-pci\n          description: Host bridge\n          product: 2nd Generation Core Processor Family DRAM Controller\n          vendor: Intel Corporation\n          physical id: 100\n          bus info: pci@0000:00:00.0\n          version: 09\n          width: 32 bits\n          clock: 33MHz\n        *-display\n             description: VGA compatible controller\n             product: 2nd Generation Core Processor Family Integrated Graphics Controller\n             vendor: Intel Corporation\n             physical id: 2\n             bus info: pci@0000:00:02.0\n             version: 09\n             width: 64 bits\n             clock: 33MHz\n             capabilities: vga_controller bus_master cap_list rom\n             configuration: driver=i915 latency=0\n             resources: irq:28 memory:d0000000-d03fffff memory:c0000000-cfffffff ioport:3000(size=64)\n        *-communication\n             description: Communication controller\n             product: 6 Series/C200 Series Chipset Family MEI Controller #1\n             vendor: Intel Corporation\n             physical id: 16\n             bus info: pci@0000:00:16.0\n             version: 04\n             width: 64 bits\n             clock: 33MHz\n             capabilities: bus_master cap_list\n             configuration: driver=mei_me latency=0\n             resources: irq:26 memory:d0705000-d070500f\n        *-usb:0\n             description: USB controller\n             product: 6 Series/C200 Series Chipset Family USB Enhanced Host Controller #2\n             vendor: Intel Corporation\n             physical id: 1a\n             bus info: pci@0000:00:1a.0\n             version: 05\n             width: 32 bits\n             clock: 33MHz\n             capabilities: ehci bus_master cap_list\n             configuration: driver=ehci-pci latency=0\n             resources: irq:16 memory:d070a000-d070a3ff\n        *-multimedia\n             description: Audio device\n             product: 6 Series/C200 Series Chipset Family High Definition Audio Controller\n             vendor: Intel Corporation\n             physical id: 1b\n             bus info: pci@0000:00:1b.0\n             version: 05\n             width: 64 bits\n             clock: 33MHz\n             capabilities: bus_master cap_list\n             configuration: driver=snd_hda_intel latency=0\n             resources: irq:29 memory:d0700000-d0703fff\n        *-pci:0\n             description: PCI bridge\n             product: 6 Series/C200 Series Chipset Family PCI Express Root Port 1\n             vendor: Intel Corporation\n             physical id: 1c\n             bus info: pci@0000:00:1c.0\n             version: b5\n             width: 32 bits\n             clock: 33MHz\n             capabilities: pci normal_decode bus_master cap_list\n             configuration: driver=pcieport\n             resources: irq:16 memory:d0600000-d06fffff\n           *-network DISABLED\n                description: Wireless interface\n                product: Centrino Wireless-N 1030 [Rainbow Peak]\n                vendor: Intel Corporation\n                physical id: 0\n                bus info: pci@0000:01:00.0\n                logical name: wlan0\n                version: 34\n                serial: bc:77:37:4d:97:c0\n                width: 64 bits\n                clock: 33MHz\n                capabilities: bus_master cap_list ethernet physical wireless\n                configuration: broadcast=yes driver=iwlwifi driverversion=4.2.0-35-generic firmware=18.168.6.1 latency=0 link=no multicast=yes wireless=IEEE 802.11bgn\n                resources: irq:27 memory:d0600000-d0601fff\n        *-pci:1\n             description: PCI bridge\n             product: 6 Series/C200 Series Chipset Family PCI Express Root Port 3\n             vendor: Intel Corporation\n             physical id: 1c.2\n             bus info: pci@0000:00:1c.2\n             version: b5\n             width: 32 bits\n             clock: 33MHz\n             capabilities: pci normal_decode bus_master cap_list\n             configuration: driver=pcieport\n             resources: irq:18 memory:d0500000-d05fffff\n           *-usb UNCLAIMED\n                description: USB controller\n                product: uPD720200 USB 3.0 Host Controller\n                vendor: NEC Corporation\n                physical id: 0\n                bus info: pci@0000:02:00.0\n                version: 04\n                width: 64 bits\n                clock: 33MHz\n                capabilities: xhci cap_list\n                configuration: latency=0\n                resources: memory:d0500000-d0501fff\n        *-pci:2\n             description: PCI bridge\n             product: 6 Series/C200 Series Chipset Family PCI Express Root Port 5\n             vendor: Intel Corporation\n             physical id: 1c.4\n             bus info: pci@0000:00:1c.4\n             version: b5\n             width: 32 bits\n             clock: 33MHz\n             capabilities: pci normal_decode bus_master cap_list\n             configuration: driver=pcieport\n             resources: irq:16 ioport:2000(size=4096) ioport:d0400000(size=1048576)\n           *-network\n                description: Ethernet interface\n                product: RTL8101/2/6E PCI Express Fast/Gigabit Ethernet controller\n                vendor: Realtek Semiconductor Co., Ltd.\n                physical id: 0\n                bus info: pci@0000:03:00.0\n                logical name: eth0\n                version: 05\n                serial: 14:fe:b5:a6:2d:78\n                size: 100Mbit/s\n                capacity: 100Mbit/s\n                width: 64 bits\n                clock: 33MHz\n                capabilities: bus_master cap_list ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd autonegotiation\n                configuration: autonegotiation=on broadcast=yes driver=r8169 driverversion=2.3LK-NAPI duplex=full firmware=rtl_nic/rtl8105e-1.fw ip=192.168.0.107 latency=0 link=yes multicast=yes port=MII speed=100Mbit/s\n                resources: irq:25 ioport:2000(size=256) memory:d0404000-d0404fff memory:d0400000-d0403fff\n        *-usb:1\n             description: USB controller\n             product: 6 Series/C200 Series Chipset Family USB Enhanced Host Controller #1\n             vendor: Intel Corporation\n             physical id: 1d\n             bus info: pci@0000:00:1d.0\n             version: 05\n             width: 32 bits\n             clock: 33MHz\n             capabilities: ehci bus_master cap_list\n             configuration: driver=ehci-pci latency=0\n             resources: irq:23 memory:d0709000-d07093ff\n        *-isa\n             description: ISA bridge\n             product: HM67 Express Chipset Family LPC Controller\n             vendor: Intel Corporation\n             physical id: 1f\n             bus info: pci@0000:00:1f.0\n             version: 05\n             width: 32 bits\n             clock: 33MHz\n             capabilities: isa bus_master cap_list\n             configuration: driver=lpc_ich latency=0\n             resources: irq:0\n        *-storage\n             description: SATA controller\n             product: 6 Series/C200 Series Chipset Family 6 port SATA AHCI Controller\n             vendor: Intel Corporation\n             physical id: 1f.2\n             bus info: pci@0000:00:1f.2\n             version: 05\n             width: 32 bits\n             clock: 66MHz\n             capabilities: storage ahci_1.0 bus_master cap_list\n             configuration: driver=ahci latency=0\n             resources: irq:24 ioport:3088(size=8) ioport:3094(size=4) ioport:3080(size=8) ioport:3090(size=4) ioport:3060(size=32) memory:d0708000-d07087ff\n        *-serial UNCLAIMED\n             description: SMBus\n             product: 6 Series/C200 Series Chipset Family SMBus Controller\n             vendor: Intel Corporation\n             physical id: 1f.3\n             bus info: pci@0000:00:1f.3\n             version: 05\n             width: 64 bits\n             clock: 33MHz\n             configuration: latency=0\n             resources: memory:d0704000-d07040ff ioport:efa0(size=32)\n  *-network\n       description: Ethernet interface\n       physical id: 1\n       logical name: wmx0\n       serial: 64:d4:da:50:85:3a\n       capabilities: ethernet physical\n       configuration: driver=i2400m_usb firmware=i6050-fw-usb-1.5.sbcf link=no\n\n\nA: Adriano,\nFrom the lsusb output you posted it seems that your Linux side is not recognizing your USB hub as two different devices. Instead of having both a USB 2.0 hub and a USB 3.0 hub, it just shows the same USB 2.0 hub twice (they have identical IDs).\nFor instance, on my system lsusb gives me the following: \nBus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\n...\n\nNotice there is both a 2.0 and a 3.0 hub with unique IDs. My suggestion would be to run sudo apt-get update && sudo apt-get upgrade to bring your system up to date. If this does not work, check your computer's BIOS settings to see if XHCI_Hand_off is enabled. Otherwise, go digging HERE  for compatible drivers. \nGood luck!\n", "Q: Is my AMD hybrid-graphics card supported by Ubuntu 16.04 driver? so before I try a clean install of 16.04 LTS when it's released, is there any way to find out whether my AMD graphics card is fully supported by the driver?\nI'm not talking gaming, just the open source driver that is replacing the fglrx driver. I'm using a hybrid Intel/AMD system.\nHere's my card:\n04:00.0 Display controller: Advanced Micro Devices, Inc. [AMD/ATI] Venus XTX [Radeon HD 8890M / R9 M275X/M375X] (rev ff)`\n\n\nA: In 16.04 the AMD graphics card driver is AMDGPU. The list of supported cards is here . This says your card is fully supported.\n", "Q: How to configure nullmailer to work with gmx Last time I used postfix, and it was a mess until everything was configured to send my root-mail to my gmx-address .. however in the end it worked.\nThis time I wanted to prevent that mess by using nullmailer .. however nullmailer as well  provides some trouble.\nHere my settings: \nsudo less /etc/nullmailer/adminaddr\nmyMailAddress@gmx.de\n\n/etc/nullmailer/defaultdomain is empty\nsudo less /etc/nullmailer/remotes\nmail.gmx.net smtp --port=465 --starttls --user=myMailProxy@gmx.de --pass=someSecret\n\nI as well configured /etc/aliases ... no idea if that matters at all:\n....\nroot: myMailAddress@gmx.de\n\nAfter configuration and restarting the service:\nsudo service nullmailer restart\n\nI tried to send  a testmail:\nmail -s \"whatever\" root < /dev/null\n\nBut it failed ... I can read the following error in /var/log/mail.err:\nApr 20 22:20:58 desktop-pc nullmailer[4727]: smtp: Failed:\nApr 20 22:20:58 desktop-pc nullmailer[4717]: Sending failed:  Protocol error\n\nSo how to get things debugged now ? Or should I pick another mail provider to send my root-mails ?\nEdit1: \nUsing port 587 with TLS leads to another error:\n( Same when using port 465 with --ssl )\nApr 21 08:12:43 schwinn-desktop nullmailer[1319]: smtp: Failed: 550-Requested action not taken: mailbox unavailable#012550 Sender address is not allowed.\nApr 21 08:12:43 schwinn-desktop nullmailer[1285]: Sending failed:  Permanent error in sending the message\n\nEdit2:\nFinnaly, thanks to emk2203, I use dma(dragonfly mail transfer agent) instead of nullmailer, which I was able to bring to work in less than 5min.\n\nA: The way GMX documents it, you have to use port 465 with SSL - you are using it with TLS, which should use port 587. So either change your port or your protocol, both should work.\nAlso, as an anti-spam measure, GMX only accepts messages from a valid GMX sender - no stuff like root@mymachine.local or similar.\nWhat works is if you send a mail via nullmailer-inject -f myaccount@gmx.de.\nI just tested my old GMX account successfully with cat testmail.mail | nullmailer-inject -h -f myaccount@gmx.de. You need to force an envelope with your real address with the -f myaccount@gmx.de option, otherwise it gets rejected. The -h option is just so only the information in the email file is used, no command line information for to: and other fields.\nMy format for the test mail was below. Taken from nullmailer troubleshooting, fill out the From:, To:, and Cc: fields, otherwise it won't work!\nSubject: Nullmailer test at Do 21. Apr 13:56:57 CEST 2016\nFrom: Yourfirst Yourlast  <yourself@yourdomain.com>\nTo: Yourfirst Yourlast  <yourself@yourdomain.com>\nCc: Friendfirst Friendlast <friend@friendsdomain.com>\n\nSent at Do 21. Apr 13:56:57 CEST 2016\n\nYourfirst Yourlast was here\nand now is gone\nbut left his name\nto carry on.\n\nThis is a second paragraph thats kinda long, really really long, so long that I truly hope that it does the right thing and wraps.\n\nSincerely\nYourfirst Yourlast\n\nMy /etc/nullmailer/remotes file looks like this:\nmail.gmx.net smtp --port=587 --starttls --auth-login --user=myaccount@gmx.de --pass=password\nIf you want to use mail like you did, make sure that the -f myaccount@gmx.de option is used. How to do this depends on your MUA (mail user agent) which is behind the mail alias.\nLastly, I want to point out that nullmailer has an inherent security flaw. Even though the /etc/nullmailer/remotes file is only readable by root and the user mail, it calls the smtp program with the content of this file as options, so every user on the system can see your credentials while smtp runs via ps aux or htop. Maybe this is fixed in 2.0, but even 16.04 has only a 1.x version, and no ppa is offering a newer one.\nA nice alternative to nullmailer is dma, the dragonfly mail transfer agent. I could set it up to use my GMX credentials in less than one minute. If you use the MASQUERADE=myaccount@gmx.de option in the settings file, you don't even need to fool around to pass options with mail.\nPut just the following into /etc/dma/dma.conf, your credentials into /etc/dma/auth.conf, and you are done:\nSMARTHOST smtp.gmx.net\nPORT 587\nAUTHPATH /etc/dma/auth.conf\nSECURETRANSFER\nSTARTTLS\nMASQUERADE myaccount@gmx.de\n\nNo further configuration or adaptation needed, easy, and secure.\n", "Q: Customizing Grub 2 Menu I'm trying to customize the Grub 2 menu.  I have Win 10, Ubuntu, Win 7, Win 95, Win XP on my hard drive.\nThe Grub Bootloader can see Win 10, Win 7, and Ubuntu.  It does not see the other 2 operating systems.\nI can create a sub-menu addition(named Other Windows Systems) but do not know how to direct Grub to the particular partitions.\nI searched for command lines but being new to Ubuntu  I don't understand what I need to do.\nThanks for the help. I am on the road and will try your suggestions when I return. \n\nA: The grub update command will scan all the connected drives and add all the recognized partitions to the menu.\nRun this command:\n$ sudo update-grub\n\nAs far as customizing grub, you can edit the grub configuration file.  Most of the options documented in the file by comments.\n$ nano /etc/default/grub\n\nAfter making changes you have to update the boot files with the command above.\n", "Q: I have an unwanted Apache 2 redirection between my virtual Hosts, seems to be since latest update As said in the title, I discovered yesterday that all my virtual hosts are redirected to the last (alphabetically, if it matters) virtual host.\nI have been checking, and did not see any changes made recently to the different .conf files, and I do NOT use .htaccess\nI am on Ubuntu. Everything looks right in my settings. Like I said, I did not change anything lately there.\nI just noticed that on the last apt-get upgrade (or apt-get dist-upgrade) there was a question about updating some configuration in Apache2. I asked to see the comparison, did not looks like anything regarding Virtual hosts, so I said OK.\nAnybody has an idea where I should look at, or, how could I roll back that very recent Apache upgrade?\nThanks for your help, I am puzzled by this one.\nHere is an example:\n<VirtualHost *:80>\n    ServerAdmin webmaster@localhost\n    ServerName ecritsduchateau.fr\n    ServerAlias www.ecritsduchateau.fr\n    DocumentRoot /var/www/ecritsduchateau/public_html\n    <Directory />\n            Options FollowSymLinks\n            AllowOverride All\n    </Directory>\n    <Directory /var/www/>\n            Options Indexes FollowSymLinks MultiViews\n            AllowOverride All\n            Order allow,deny\n            allow from all\n    </Directory>\n\n    ScriptAlias /cgi-bin/ /usr/lib/cgi-bin/\n    <Directory \"/usr/lib/cgi-bin\">\n            AllowOverride All\n            Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch\n            Order allow,deny\n            Allow from all\n    </Directory>\n\n    ErrorLog ${APACHE_LOG_DIR}/ecrits_du_chateau_error.log\n\n    # Possible values include: debug, info, notice, warn, error, crit,\n    # alert, emerg.\n    LogLevel warn\n\n    CustomLog ${APACHE_LOG_DIR}/ecrits_du_chateau_access.log combined\n\nAlias /doc/ \"/usr/share/doc/\"\n<Directory \"/usr/share/doc/\">\n    Options Indexes MultiViews FollowSymLinks\n    AllowOverride None\n    Order deny,allow\n    Deny from all\n    Allow from 127.0.0.0/255.0.0.0 ::1/128\n</Directory>\n</VirtualHost>\n\n\nI have been checking with Fiddler, to see if it would give me some hints. Here is the raw answer:\nHTTP/1.1 301 Moved Permanently\nDate: Thu, 21 Apr 2016 17:59:26 GMT\nServer: Apache/2.4.20 (Ubuntu)\nX-Pingback: http://lebearcnc.com/xmlrpc.php\nLocation: http://lebearcnc.com/\nContent-Length: 0\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\nContent-Type: text/html; charset=UTF-8\n\nIf it helps you to see a reason, great, as it does not help me much.... :-)\n\nA: I finally found the proper answer to that problem, and it was indeed linked to a recent Ubuntu update.\nWhen I tried to do as Dan suggested, sudo a2ensite ecritsduchateau, I got the error Site does not exist while I knew it was there, I was looking at it!\nSo I searched for that error, to find the answer here: Stack Overflow: Site does not exist error for a2ensite\nIn a nutshell, a recent upgrade of Apache 2.4.x make the .conf extension mandatory, which I had not put on a couple of my sites definitions.\nAs soon as I fixed this and reloaded Apache2, everything went back to normal.\n", "Q: Set application that displays desktop I'm using Ubuntu Mate 15.10 by default it comes with caja file manager.\nI've installed pcmanfm and removed caja from the system.\nNow the files on desktop are not shown, but they are present in relevant folder when opened by file manager.\nCan I get directions on how to get desktop displayed while using pcmanfm?\n\nA: Yes, you can run it with --desktop to manage the desktop.\npcmanfm --desktop\n\nFor more info see: man pcmanfm. You can add it to startup applications or just take nautilus example below:\n$ more /etc/xdg/autostart/nautilus-autostart.desktop\n[Desktop Entry]\nType=Application\nName=Files\nExec=nautilus -n\nOnlyShowIn=GNOME;Unity;\nAutostartCondition=GSettings org.gnome.desktop.background show-desktop-icons\nNoDisplay=true\nX-Ubuntu-Gettext-Domain=nautilus\n\n\nA: The files on the desktop are shown by caja. Most desktops show the desktop using a file manager, Unity uses Nautilus, Windows uses Explorer, etc.\nAccording this this: https://forums.linuxmint.com/viewtopic.php?t=180262 , there is no easy solution.\n", "Q: Regular security checks on server I am administrating a server and obviously i am slightly paranoid if its security is compromised. Hence i regularly try to check if the security is still intact. Here are the things that i do roughly twice a week, maybe you could comment on it and/or give some additions.\nI do:\n\n\n*\n\n*Run chkrootkit and rkhunter\n\n*check cat /var/log/auth.log | grep opened | grep sshd:session For user logins (i know who is on vacation, hence these people should not login)\n\n*Check cat /var/log/auth.log | grep opened | grep root to see if somebody gained root access (despite me)\n\n*Loosely check the running tasks if something suspicious pops up\n\n\nI do not really want to discuss safety measures, but rather how you check the security-integrity on a regular basis in few time (the stuff i do takes roughly 10 minutes).\nThanks for your help.\n\nA: I would personally suggest a piece of software called OSSEC HIDS (Host Intrusion Detection System) which if configured properly (which is reasonably easy to do so, just follow the installer) will regularly send you system and security related information such as what is listening on which port, if the hashsums of any important files have been changed, when software is installed, removed, purged, or upgraded, if any adapters enter promiscuous mode, etc. It is also highly customizable so you can change what it alerts you about and increase certain alerts such as the files it monitors.\nI would also suggest that you regularly scan your server with an AV such as clamav which can be installed with.\nAnd that you setup fail2ban to block any hackers trying to login into your server many times trying to brute force their way in.\n\nA: This answer is more for if you just want to simplify / automate different tasks you do using scripts and crontab.\nYou can set up a script that you can run whenever you wish.\n#!/bin/bash\n\nchkrootkit\nrkhunter\n\ncat /var/log/auth.log | grep opened | grep sshd:session | more\n#the ' | more' splits output into multiple screens, you can cut it off if you want\n\nread\n#delays the next command, waits until you press enter to move on, again, uncomment if you are doing this automatically\n\ncat /var/log/auth.log | grep opened | grep root | more\nread\n#same as previous command\n\nps aux          \n#change this to whatever command you use to check processes...\n\nread\n\nJust modify the script however you see fit. Make sure it is executable with chmod +x myNewScript.sh. Run this (bash /path/to/script/myNewScript.sh) whenever you want.\nYou can also alias this command by putting alias secCheck='bash /path/to/script/myNewScript.sh in your .bashrc file (home dir). Then just run secCheck at any time whenever you want to check security.\nIf you want to make the script automated, as in no user interaction needed, remove all read's and output the cat's somewhere to maybe check later, etc. You can then set up crontab to run the script as frequently as you like.  \n", "Q: How can I install a newer python on Trusty? I'd like to install a newer python 2.7 on trusty.\nInstalling \"python\" installs python 2.7. The newest version available on trusty is 2.7.6. I'd like to install the most updated version of 2.7. I am not interested in python 3.\nTo do this I would have to add a new source to apt. Which is a good source to use?\n\nA: This PPA should have the latest version of Python 2.7:\nsudo add-apt-repository ppa:fkrull/deadsnakes-python2.7\n\nAdd it by running:\nsudo add-apt-repository ppa:fkrull/deadsnakes-python2.7\nsudo apt-get update\n\nThen run sudo apt-get upgrade and it should upgrade Python.\n", "Q: How to setup meld as merge tool on Ubuntu 15.10? EDIT: gitkraken now features a merge tool with conflict resolution. Its available from the official gitkraken website. So I have a working solution\n\nI am using gitkraken as my GUI-git client, which doesn't have an internal merge tool, so I am required to use meld as merge tool.\nWhen I run meld in my terminal it works just fine. \nHowever when I need to resolve a merge conflict in gitkraken it fails to open the tool, saying that the tool was not found; so I suspect I setup the .gitconfig wrong.\nHere you can find part of my .gitconfig: \n[merge]\n    tool = meld\n[diff]\n    tool = meld\n\nboth set up with:\ngit config --global merge.tool\n\nand \ngit config --global diff.tool\n\n\nA: This seems to be old but I'll contribute with my answer anyway. I had the same issue as you and I could solve it by providing this configuration: \n    [diff]\n        tool = meld\n    [merge]\n        tool = meld    \n    [difftool \"meld\"]\n        cmd = meld \"$LOCAL\" \"$REMOTE\"\n\nSo I think that the difference between your issue and mine is that you may be missing the command line specification.\n\nA: For the ppl who still want to use external merging tool,\nOnce you see a merge conflict in gitkraken just go to the terminal (in your project root folder) and type git mergetool. this will try to open the default merge tool configured.\nOnce merging is done, you can go back to gitkraken and commit and merge the changes.\n", "Q: Vista to Ubuntu? 2007 laptop I have a 2007 Windows Vista laptop that I am wanting to make the switch to Ubuntu on. These are the questions I have.\nQ. What is the stable version?\nA. \nQ. What size USB do I need?\nA. \nAnd steps on how to make the switch. \nBTW I do not need anything to come of the laptop. And I will add full laptop name when I find it. \n\nA: If you wait until 12:00AM UTC (so about 50 minutes), you can pick up the latest version of Ubuntu, as it is going to be released then. Tomorrow's release (16.04) is an LTS (Long-Term Support) release, meaning it will be supported by Canonical and AskUbuntu for a very long time.\nTo install it, you need either a DVD or a USB stick. You should use a USB stick that is at least 4GB. Download the Ubuntu ISO from the website (16.04 won't be shown until it is released), and burn it to the USB stick using Rufus. Don't follow the instructions on the Ubuntu website. The program suggested is terrible.\nIn the installer, you should eventually be prompted with some options on how you want to install Ubuntu. Choose the option resembling Erase Hard Drive and Install Ubuntu to do exactly what that says. Let Ubuntu install, unplug the USB drive when it's finished and reboot into Ubuntu.\nRemember, Ubuntu is more than a little different than Windows, but there are countless tutorials online and we on AskUbuntu are (mostly) here to help. When you ask a question, just make sure it is a clear and detailed as possible. Also do your research before asking a question, as it may already be answered. Questions you may find about relatively recent Ubuntu versions (I'd say 14.04 and up) should be recent enough to work for 16.04.\nGood luck, and happy Ubuntu-ing!\nEDIT:\nAs some people have pointed out, there are more lightweight alternatives to normal Ubuntu. If your computer ends up not running very well, it may be a good idea to try out Lubuntu or Xubuntu.\n", "Q: why I have to use a replacement for Mac OS X Terminal on Mac? During my work, I use Ubuntu, but sometimes I work at home with Mac OS.\nMy question is following:\nWhen I connect to the cluster (with Ubuntu) with my Mac terminal and compile package, eg. VTK, I always get ERROR like \nCMake Error at /usr/share/cmake/Modules/CMakeTestCCompiler.cmake:61 (message):\nThe C compiler \"/share/apps/intel/composer_xe_2013/bin/icc\" is not able to compile a simple test program.\n\nHowever, if I connect the cluster (with Ubuntu) with terminal client on Mac, e. g. MacTerm, I could compile the VTK perfectly.\nWhy does this happen?\n\nA: I understand that you are using two different ssh clients. Try login in with both of them and checking the output of the \"env\" command together with \"echo $PATH\", and compare the results. If one of the \"MacTerm\" environmental variables or entries in the PATH is different, set it to the same value as in the \"Mac Terminal\".\n\nA: The only thing I can think of that might change based on the terminal you use to connect would be locale-related settings (which do sometimes interfere with compiling).\nCheck the values of your $LANG or $LC_<whatever> environment variables (using e.g. echo $LANG). Sometimes setting LANG=C (export LANG=C) helps in getting things to compile (but it might mess up the output in your terminal).\nYour $TERM variable is likely different also, but that shouldn't affect compiling.\n", "Q: How to write an Upstart script for a background service (db)? I am on Ubuntu 14.04 server and I am trying to write a script for my database. I have added the file /etc/init/neo.conf. The file is the following:\ndescription \"neo4j upstart\"\n\nstart on startup\nstop on shutdown\n\nscript\n  echo $$ > /var/run/neo_start.pid\n  exec /home/ubuntu/neo/neo4j-enterprise-2.3.1/bin/neo4j start\nend script\n\npre-start script\n  echo \"[`date`] Neo4j Starting\" >> /var/log/neo.log\nend script\n\npre-stop script\n  rm /var/run/neo_start.pid\n  echo \"[`date`] Neo4j Stopping\" >> /var/log/neo.log\nend script\n\nsudo service neo start works fine but sudo service neo stop tells me: stop: Unknown instance:.\nAny ideas? Maybe something to do with the PID?\n\nA: Looks like bin/neo4j start creates it's own daemon process that upstart loses sight of. If you use bin/neo4j console upstart will be able to keep track of it like a normal process.\n", "Q: Can't find latest NVIDIA Propietary Drivers I'm trying to update my Nvidia drivers to 361.15 Proprietary (Prime) but it keep showing me the open source (Nouveau) drivers of it and I can't find the prime version of it. I tried manually installing it but it was confusing. The PPA i'm using is  launchpad.net/~graphics-drivers/+archive/ubuntu/ppa. So if anyone can please help me I would greatly appreciated it. \nDrivers list\nList of my PPA\n\nA: Open Source doesn't mean generic.\nEvery driver from that PPA is open source, but each one will work just as well as the proprietary driver.\nNouveau is the only generic driver there.\nOpen Source means you or anyone else can easily review the code that went into making the driver, and even use it to build your own version of the driver.\nProprietary means the code is not available to review or edit.\nGeneric drivers are made to work with a certain brand or category of device, but aren't optimized or anything to provide any sort of performance.\n", "Q: Using Grep to get specific entries and ignore others is there a way to use grep to ignore lines with 141.8. .. contained in them BUT get lines that have GET? Right now I have this but I must be doing something wrong \nsudo grep -v '^141.8.83.213' && \"GET\" /home/tsec/prototype/logs/glastopf.log | sort -k4,4 | tac | sort -uk4,4 | sort -k1,2 | tail -n 10 > /home/tsec/prototype/logs/ext$\nThis is what the log contains\n2016-04-20 13:30:59,818 (glastopf.glastopf) 141.8.83.213 requested GET /favicon.ico on e1f841a092e9:80\n2016-04-20 13:31:01,817 (glastopf.glastopf) 141.8.83.213 requested POST /index on e1f841a092e9:80\n2016-04-20 13:31:01,855 (glastopf.glastopf) 141.8.83.213 requested GET /style.css on e1f841a092e9:80\n2016-04-20 13:31:01,883 (glastopf.glastopf) 141.8.83.213 requested GET /favicon.ico on e1f841a092e9:80\n2016-04-20 16:39:55,713 (glastopf.glastopf) Initializing Glastopf 3.1.3-dev using \"/data/glastopf\" as work directory.\n2016-04-20 16:39:55,797 (glastopf.glastopf) Connecting to main database with: sqlite:///db/glastopf.db\n2016-04-20 16:39:55,834 (glastopf.glastopf) Glastopf started and privileges dropped.\n2016-04-20 17:54:33,857 (glastopf.glastopf) 62.210.252.43 requested GET / on de96c7b4104d:80\n2016-04-20 17:54:34,101 (glastopf.glastopf) 62.210.252.43 requested GET /HNAP1/ on de96c7b4104d:80\n2016-04-20 22:06:20,265 (glastopf.glastopf) Initializing Glastopf 3.1.3-dev using \"/data/glastopf\" as work directory.\n2016-04-20 22:06:20,399 (glastopf.glastopf) Connecting to main database with: sqlite:///db/glastopf.db\n2016-04-20 22:06:20,446 (glastopf.glastopf) Glastopf started and privileges dropped.\n2016-04-20 22:33:23,136 (glastopf.glastopf) 74.91.23.109 requested GET / on 11bbb1d43c02:80\n\nSo in the end I want to get the entries that have GET in string but ignore those who have the 141.8.83.213 IP\n\nA: Use two greps:\ngrep \"GET\" /home/tsec/prototype/logs/glastopf.log |  grep -vF 141.8.83.213 | ...\n\nFrom man grep:\n-F    Match using fixed strings. Treat each  pattern  specified  as  a\n      string  instead  of  a  regular  expression.  If  an  input line\n      contains any of the patterns as a contiguous sequence of  bytes,\n      the line shall be matched. A null string shall match every line.\n\n-v    Select  lines not matching any of the specified patterns. If the\n      -v option is not specified, selected lines shall be  those  that\n      match any of the specified patterns.\n\nSo -F lets us avoid escaping the ., which would otherwise match any character. -v is the classic way to tell grep to invert the match.\n\nA: Awk allows for logical operators in regex , so you can say match GET and also those lines that don't contain ip\n  awk '/GET/&&!/141\\.8\\.83\\.213/' log. txt\n\n\nA: Single grep,\ngrep -P '^(?!.*?141\\.8\\.83\\.213).*\\bGET\\b' file\n\nDEMO\n", "Q: mouse/cursor is disappearing after sleep I've got a problem where my mouse cursor keeps disappearing when my session times out. I log back in and it's invisible, though I can still move it around the screen and click things. I'm in Lubuntu 15.04 and I've tried...\n\n\n*\n\n*reading as many answered questions as I can find\n\n*installing gdm (says something is in use by another program and can't be installed)\n\n*Using unclutter to switch mouse on and off (can't find a command that toggles the mouse\n\n*Switching into the login screen and back (ctr-alt-f2 and ctr-alt-f7)\n\n\nSystem reboot is the only solution I've found and it's quite onerous. Any assistance would be appreciated!\n\nA: I have stumbled on this odd bug with a Lubuntu 16 on an Acer Aspire D250. Searching for a fix I found this workaround: pressing Ctrl-Alt-F1 and then Ctrl-Alt-F7 makes the cursor reappear. Works on my system.\n\nA: I found this looking for the solution to the same problem (this is still happening on Xubuntu 16.04, so updating to a supported release does not solve this issue). I don't know how to prevent this, but I can reliably recover the mouse cursor without rebooting. Open the display manager (Super + P) and make any change you want (change the screen resolution, then change it back. This brings the pointer back whenever a change like this is made. I took this one step further : you can use xrandr for this and map this to a keyboard shortcut. For my laptop I ended up setting Ctrl+Alt+Left arrow to run\nxrandr --output LVDS1 --rotate left\n\nand then Ctrl+Alt+Down runs\nxrandr --output LVDS1 --rotate normal\n\nso I can quickly rotate left then back to normal and bring the cursor back very easily. Still annoying, but easily overcome.\n\nA: I have one installation of 14.04 with exactly this behaviour. Don't know why, but workaround as follows.\n\n\n*\n\n*Bring up a terminal, Ctrl+Alt+t\n\n*Hit return in the terminal window and the mouse pointer reappears.\n\n\nA: I just came across this issue (Lubuntu 16.04), and found an answer that worked here.\nThe Fix:\nI added this ppa with:\nsudo add-apt-repository ppa:oibaf/graphics-drivers && sudo apt-get update\n\nAnd then updated xserver-xorg-video-intel with:\nsudo apt install xserver-xorg-video-intel\n\nThis seems to have fixed it for me.\nAlternative:\nAccording to the bug report, this was fixed in xserver-xorg-video-intel - 2:2.99.917+git20160325-1ubuntu1.1, so you might find that simply updating the package with sudo apt install xserver-xorg-video-intel works. You can see which packages will be installed with the following command:\n  ~ $ sudo apt-cache madison xserver-xorg-video-intel\nxserver-xorg-video-intel | 2:2.99.917+git1609021930.ebc066~gd~x | http://ppa.launchpad.net/oibaf/graphics-drivers/ubuntu xenial/main amd64 Packages\nxserver-xorg-video-intel | 2:2.99.917+git20160325-1ubuntu1.1 | http://gb.archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages\nxserver-xorg-video-intel | 2:2.99.917+git20160325-1ubuntu1 | http://gb.archive.ubuntu.com/ubuntu xenial/main amd64 Packages\n\n", "Q: Run PS2 eyetoy camera on ubuntu 14.04 What do I need to do to connect a Sony PS2 eyetoy camera to a Dell laptop (Ubuntu 14.04) or a Pandaboard (Ubuntu 12.04)?\n\nA: According to this website, that camera will work out of the box. You should just be able to plug it in and use it.\nYou can test it out by installing the program Cheese, available from the Ubuntu Software Center.\nA more recent post (2014) states that the camera works perfectly fine on 12.04.\n\nA: I know you didn't ask about Ubuntu 16.04, but I can confirm that the PS2 Eyetoy camera works out-of-the-box on that version. I checked to see if it was detected with:\nlsusb\n\nwhich returned:\nBus 002 Device 006: ID 054c:0155 Sony Corp.\n\nand then used Cheese Webcam Booth to test the picture.\nPS. These cameras have a manual focus ring on the front, took me a while to realise.\n", "Q: which Desktop would i get after ugrade to 16.04? Currently i'm using ubuntu 14.04 with xubuntu-desktop.\ni had completely remove unity from my system.\nnow i want to upgrade my 14.04 to 16.04 so my question will i get unity  back or it will have upgraded xubuntu-desktop \nIm upgrading referencing this  article \n\nA: It should not affect your desktop environment. You will keep whatever you have right now, same as when you do a regular upgrade.\n", "Q: I can't open gufw in Ubuntu 16.04 ** (gufw.py:28335): WARNING **: Failed to load shared library 'libwebkitgtk-3.0.so.0' referenced by the typelib: libgbm.so.1: 無法開啟共用目的檔: 沒有此一檔案或目錄\n/usr/share/gufw/gufw/view/gufw.py:117: Warning: cannot retrieve class for invalid (unclassed) type 'void'\nself.web_content = WebKit.WebView()\nTraceback (most recent call last):\nFile \"/usr/share/gufw/gufw/gufw.py\", line 29, in \ngufw = Gufw(controler.get_frontend())\n\nFile \"/usr/share/gufw/gufw/view/gufw.py\", line 79, in init\nself._set_objects_name()\n\nFile \"/usr/share/gufw/gufw/view/gufw.py\", line 117, in _set_objects_name\nself.web_content = WebKit.WebView()\n\nTypeError: could not get a reference to type class\n\nA: This post on reddit says that it's because of a broken dependency and the fix for that is:\nsudo apt-get install python-gobject\n\nAfter typing that in a terminal, I'm now able to start GUFW.\n", "Q: Lenovo Ideapad Y700 - Ubuntu 15.10: Constant speaker noise after login I bought a new Lenovo Ideapad Y700 and tried Ubuntu 15.10 live on it. The speakers are making a constant noise after I login. I've recorded and shared the sound in soundcloud: https://soundcloud.com/user-964869845/speaker-noise\nDoes anyone know what is happening and how to solve this problem? Below is the output of lsusb && lspci commands:\n$ lsusb && lspci\nBus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub\nBus 001 Device 003: ID 174f:14ea Syntek \nBus 001 Device 002: ID 8087:0a2a Intel Corp. \nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\n00:00.0 Host bridge: Intel Corporation Sky Lake Host Bridge/DRAM Registers (rev 07)\n00:01.0 PCI bridge: Intel Corporation Sky Lake PCIe Controller (x16) (rev 07)\n00:02.0 VGA compatible controller: Intel Corporation Device 191b (rev 06)\n00:14.0 USB controller: Intel Corporation Sunrise Point-H USB 3.0 xHCI Controller (rev 31)\n00:14.2 Signal processing controller: Intel Corporation Sunrise Point-H Thermal subsystem (rev 31)\n00:16.0 Communication controller: Intel Corporation Sunrise Point-H CSME HECI #1 (rev 31)\n00:17.0 SATA controller: Intel Corporation Sunrise Point-H SATA Controller [AHCI mode] (rev 31)\n00:1c.0 PCI bridge: Intel Corporation Sunrise Point-H PCI Express Root Port #6 (rev f1)\n00:1d.0 PCI bridge: Intel Corporation Sunrise Point-H PCI Express Root Port #11 (rev f1)\n00:1d.3 PCI bridge: Intel Corporation Sunrise Point-H PCI Express Root Port #12 (rev f1)\n00:1f.0 ISA bridge: Intel Corporation Sunrise Point-H LPC Controller (rev 31)\n00:1f.2 Memory controller: Intel Corporation Sunrise Point-H PMC (rev 31)\n00:1f.3 Audio device: Intel Corporation Sunrise Point-H HD Audio (rev 31)\n00:1f.4 SMBus: Intel Corporation Sunrise Point-H SMBus (rev 31)\n01:00.0 Display controller: Advanced Micro Devices, Inc. [AMD/ATI] Venus XTX [Radeon HD 8890M / R9 M275X/M375X] (rev ff)\n07:00.0 Network controller: Intel Corporation Device 3166 (rev 99)\n08:00.0 Unassigned class [ff00]: Realtek Semiconductor Co., Ltd. Device 524a (rev 01)\n09:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 15)\n\nLet me know if more information is needed.\nThanks,\nBruno.\n\nA: Try upgrading your audio driver using the Instructions to upgrade ALSA\n", "Q: Hadoop and Eclipse - Server IPC version 9 cannot communicate with client version 4 I'm working on Ubuntu and using Eclipse to work with Hadoop. After setting the Run configuration, a message says Incomplete HDFS URI, no host\nUPDATE: found the solution! but after running the program, the message says Server IPC version 9 cannot communicate with client version 4\nSolution: It seems I added a jar file used for Hadoop 1 version. Removed it and placed a new version :) \nThanks \n\nA: Look for your core-site.xml.\nMine looks like this:\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n  <property>\n    <name>fs.default.name</name>\n    <value>hdfs://localhost/</value>\n  </property>\n</configuration>\n\nwhen i am running the code from my Eclipse IDE.\nAlso please make sure that /usr/lib/hadoop/lib/*.jar(I have Cloudera Hadoop distribution) is in your Build path.\n", "Q: How to extract a source package? I have a source package:\napt-get source -y gcc-4.9-multilib\nI want to extract it:\n#dpkg-source -x gcc-4.9_4.9.2-0ubuntu1~12.04.dsc\n\ndpkg-source: warning: extracting unsigned source package (gcc-4.9_4.9.2-0ubuntu1~12.04.dsc)\ndpkg-source: info: extracting gcc-4.9 in gcc-4.9-4.9.2\ndpkg-source: info: unpacking gcc-4.9_4.9.2.orig.tar.gz\ndpkg-source: info: applying gcc-4.9_4.9.2-0ubuntu1~12.04.diff.gz\n\nThe extracted folder doesn't contents the sources:\n#ls gcc-4.9-4.9.2/\ndebian  gcc-4.9.2.tar.xz  gdc-20141020.tar.xz\n\n\nA: You have there now two tar archives which you can extract with:\n\ntar -xf gcc-4.9.2.tar.xz\ntar -xf gdc-20141020.tar.xz\n\n", "Q: Is Ubuntu's handling of other internal drives safe? When ever I restart or shutdown the computer, I have to click on the drive and it takes a few minutes until the drive is technically \"mounted\". \nIs it safe? does this means that every time the computer is restarted the internal drives are un-mounted and re-mounted? For example, when I first start the computer and I go to System Monitor and click File Systems the other drivers are not shown. After I click on the drive folder, it shows up there. \nIsn't that a potential danger to the hard drive and the data?\n\nA: Yes, it is safe.  The way Ubuntu is designed, the default is to only automatically mount the Ubuntu partition.  Whether you are trying to access other partitions on the same drive, or another drive, they are not set to mount on startup.  This is normal, and mounting them manually does not pose any risk to the data, nor does shutting down your system unmount them in an unsafe manner.\nThat said, there are ways to make it automatically mount other drives on startup, so that you will see them from the moment you log on.  Several of these ways are examined at https://help.ubuntu.com/community/AutomaticallyMountPartitions That said, unless it is a major inconvenience to you, there is no reason to set them up to automatically mount and if you are unsure of yourself (like if you are new to Ubtuntu) you may not want to risk making mistakes that could be irreversible.\n", "Q: Ubuntu Touch - Screen locking fade issue On my Ubuntu phone, I have set my screen lock to come on after a minute of none use. This is in the Settings > Security & Privacy > Locking & Unlocking. The lock does come on as requested however, it is instant. One second the screen is on and then the next the screen is locked and black. There is no fade (like on my Ubuntu tablet), which fades out giving me the option to cancel the locking, if you wish to.\nIs there a setting that stops my phone from locking so fast and where I can increase the fade?\n\nA: Today, I installed the new update and the fade issue when the timeout is set to 1 minute has been resolved. Now when set to one minute, the screen fades out and then locks. Giving you time to deactivate the fade/lock if you want to.\nGreat work guys, thanks for including this in the latest release.\n", "Q: How to setup Restricted (permission) access for Directories in Apache2 web server I am a new system admin and learning Ubuntu. \nI have to setup a restricted (permission) for directories in Apache web server. The scenario is as follows. The folders are,\n\n/var/www/data/\n/var/www/management/\n/var/www/hrd/\n/var/www/technical/\n\nThe users in hrd (HR Department) group must access /var/www/hrd/ contents only.\nThe users in technical group must access /var/www/technical/ contents only.\nThe users in management group can access all the contents.\nAll the users & groups can access the common /var/www/data/ directory.\nHow to implement this? Can anyone help me out? Thanks in advance.\n\nA: 1. Installation \nThe Apache2 web server is available in Ubuntu Linux. To install Apache2:\nAt a terminal prompt enter the following command:\nsudo apt-get install apache2\n\n2. Configuration and with care about 3. HTTPS Configuration\n4. Sharing Write Permission\nFor more than one user to be able to write to the same directory it will be necessary to grant write permission to a group they share in common. The following example grants shared write permission to /var/www/html to the group \"webmasters\".\nsudo chgrp -R webmasters /var/www/html\nsudo find /var/www/html -type d -exec chmod g=rwxs \"{}\" \\;\nsudo find /var/www/html -type f -exec chmod g=rw  \"{}\" \\;\n\nThese commands recursively set the group permission on all files and directories in /var/www/html to read write and set user id. This has the effect of having the files and directories inherit their group and permission from their parent. Many admins find this useful for allowing multiple users to edit files in a directory tree.\nIf access must be granted to more than one group per directory, enable Access Control Lists (ACLs).\n", "Q: automated Ubuntu Desktop 15.10 installation from local DVD with preseed I want to do an automated Ubuntu Desktop 15.10 installation from local DVD, with preseed file fetched from remote HTTP server.\nCan anyone help me out here ?\n\nA: A bit late response (I use 16.04 but must be the same) ... \nCreate a copy of the CD in a local folder:  \n# mkdir /mnt/cdrom\n# sudo mount -o loop ubuntu-16.04.1-desktop-amd64.iso /mnt/iso\n# mkdir /opt/iso\n# cp -rT /mnt/iso /opt/iso \n\nChange the timeout to a non zero value in the file /opt/iso/isolinux/isolinux.cfg  (10 == 1 second):\npath \ninclude menu.cfg\ndefault vesamenu.c32\nprompt 0\ntimeout 10\nui gfxboot bootlogo\n\nModify the 'live-install' option in the file /opt/iso/isolinux/txt.cfg to (192.168.1.1 is the location of the web server) and make it default:\ndefault live-install\nlabel live-install\n  menu label ^Install Xubuntu\n  kernel /casper/vmlinuz.efi\n  append auto url=http://192.168.1.1/xubuntu.cfg keyboard-configuration/layoutcode=us and console-setup/ask_detect=false boot=casper automatic-ubiquity noprompt initrd=/casper/initrd.lz ---\n\nCreate the new iso: \nmkisofs -D -r -V \"ATTENDLESS_UBUNTU\" -cache-inodes -J -l -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -o /opt/autoinstall.iso /opt/ubuntuiso\n\nBooting with autoinstall.iso the instal·lation will be totally automated.\n", "Q: Aquarius M10 Ubuntu Edition User Manual? The quick start guide for the Aquarius M10 Ubuntu Edition provides a web address on www.bq.com for downloading the full user manual for the M10.  Although manuals for other Aquarius devices exist, there is no manual for the M10 on this web page.  Is there some other way to download the user manual?\n\nA: Go to bq.com and click Support >> Downloads >> Tablets >> Aquaris M10 Ubuntu Edition. Then choose your preferred language in the select box provided and there you go. I found the full manual here: \nhttps://it-bqcom15-media.s3.amazonaws.com/prod/resources/manual/Aquaris_M10_Ubuntu_Edition_Complete_User_Manual-1460548936.pdf\nHope, that helps. \n", "Q: How to fix Software Updater Issue? While I update my device using software updater, I am getting following screen and then the updater paused in following screen:\n\nHere is my locale lists, i.e. list which will display after execute locale command:\n\nHere is a output of locale -a\n\nDo anyone have idea how to fix it?\nI have already tried the answers given over this stackoverflow question, but it didn't worked for me! :(\nEdit:\nAfter applying changes suggested in answer I am getting following error with my update-manager:\n\nAny help would be appreciated! Thanks in advance.\n\nA: Looks like the UTF-8 locale en_IN has not been generated on your system. So then generate it:\nsudo locale-gen en_IN\n\nEdit:\nThe error messages reveal a bug in Software Updater. A workaround to get rid of the error messages is to change LANG to \"en_IN.UTF-8\".\nsudo update-locale LANG=en_IN.UTF-8\n\nEdit II:\nTo fix the new problem, try these commands:\nsudo rm -f /var/lib/apt/lists/*\nsudo apt-get update\n\n\nA: Change /etc/default/locale settings to en_IT.UTF-8:\nLANG=\"en_IT.UTF-8\"\nLC_NUMERIC=\"en_IT.UTF-8\"\nLC_TIME=\"en_IT.UTF-8\"\nLC_MONETARY=\"en_IT.UTF-8\"\nLC_PAPER=\"en_IT.UTF-8\"\nLC_NAME=\"en_IT.UTF-8\"\nLC_ADDRESS=\"en_IT.UTF-8\"\nLC_TELEPHONE=\"en_IT.UTF-8\"\nLC_MEASUREMENT=\"en_IT.UTF-8\"\nLC_IDENTIFICATION=\"en_IT.UTF-8\"\nLANGUAGE=\"en_IT:en\"\n\n", "Q: Problem with Samba 4.3.8 I've installed samba (v.4.3.8) in Ubuntu Server 14.04.4 and provision a domain but when I try to join a Windows Client to domain, a Network resource is not available error is shown.\n.\nAlthough if I repeat the same process but using samba v.4.1.6, all the process works fine and I can join the windows client.\nIs there any news about this problem with Samba?\n\nA: How were you able to install an old version of samba? I am having a similar issue but need to revert to an old version since this new version also broke my shares.\nFound an answer:\n\napt-get install samba=2:4.1.6+dfsg-1ubuntu2\n  samba-common=2:4.1.6+dfsg-1ubuntu2 samba-libs=2:4.1.6+dfsg-1ubuntu2\n  samba-common-bin=2:4.1.6+dfsg-1ubuntu2\n  samba-dsdb-modules=2:4.1.6+dfsg-1ubuntu2\n  python-samba=2:4.1.6+dfsg-1ubuntu2 libldb1=1:1.1.16-1\n  python-ldb=1:1.1.16-1\n\n\nA: I've had similar issues when upgrading from Samba 4.1.6 to Samba 4.3.8 on multiple servers (apt-get upgrade on Ubuntu 14.04 LTS).\nSamba users could not connect anymore, and in some conditions Samba was even dumping core.\n\n\n*\n\n*I made a backup of /etc/samba/smb.conf\n\n*I performed these steps:\n\n\nservice smbd stop\n  apt-get remove samba-common --purge\n  rm -Rf /etc/samba\n  apt-get autoremove\n  apt-get purge samba-libs samba-vfs-modules\n  apt-get update\n  apt-get install samba\n\n\n*Restored /etc/samba/smb.conf\n\n*Restarted smbd\n\n\nSamba users can connect again, yay!\n\nA: There is a bug on 4.3.8. To solve it, just install winbind and libnss-winbind packages. No additional configuration needed. \n", "Q: Unable to install npm with bower I'm unable to install npm with bower in Ubuntu 12.04.\nnpm install -g bower\nnpm ERR! 404 Not Found\nnpm ERR! 404 \nnpm ERR! 404 'bower' is not in the npm registry.\nnpm ERR! 404 You should bug the author to publish it\nnpm ERR! 404 \nnpm ERR! 404 Note that you can also install from a\nnpm ERR! 404 tarball, folder, or http url, or git url.\n\nnpm ERR! System Linux 3.5.0-54-generic\nnpm ERR! command \"/usr/bin/node\" \"/usr/bin/npm\" \"install\" \"-g\" \"bower\"\nnpm ERR! cwd /home/rails-dev/my_projects/searchinmena\nnpm ERR! node -v v0.10.37\nnpm ERR! npm -v 1.4.28\nnpm ERR! code E404\nnpm ERR! \nnpm ERR! Additional logging details can be found in:\nnpm ERR!     /home/rails-dev/my_projects/searchinmena/npm-debug.log\nnpm ERR! not ok code 0\n\nCan anyone help, how I can install this.\n\nA: Maybe you need node (dependency to bower work), verify with:\nnode -v\n\nIf not installed, install node with:\ncurl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\nThen try install bower with NPM as admin access:\nsudo npm install -g bower\n\n\nA: In case you have upgraded Ubuntu from the end of life 12.04 to 16.04 by now, the installation of Bower has gotten a lot easier. In Ubuntu 16.04 and later Bower package manager can be installed from the Ubuntu Software app. Open Ubuntu Software, search for \"bower\" and click the Install button to install it. Or open the terminal and type:\nsudo snap install --classic bower  \nsudo npm install -g bower\n\n\n", "Q: Installing dual-boot Windows 10 and Ubuntu on separate disks I have a new computer. It has a 128GB SSD with Windows 10 pre-installed on it. It also has a 1TB HDD. I would like to install Ubuntu on a partition (say 100GB) on the HDD for a dual-boot. I would like to be prompted which OS I want to boot on start-up.\nI have searched for this online, but everyone seems to be saying something else, from just installing Ubuntu to manually setting up partitions and adding all sorts of entries in Grub.\nAre there any problems I am overlooking? What makes the tutorials diverge so much from one another? \n\nA: You would have to change the boot order of the drives depending on which OS you wish to boot if they are on separate drives.\nIf not then yes, you will need to add entries into GRUB.\nYour best option would be to either:\nA. Install Ubuntu, and Windows 10 on the SSD (Allocated 64GB to each which, should be plenty for the OS as long as if you have your /home on the HDD).\nB. Install Ubuntu, and Windows 10 on the HDD and have your /home on the SSD, and install Windows programs to the SSD for faster load times.\nSadly, you will not be able to put both on separate drives without doing some type of work to it.\n(Please note: I could be completely incorrect on this, but from personal experience, I have not been able to do this on 2 separate drives and still have an option to choose which OS I'd like to open from GRUB. However in BIOS, you will have that option).\n", "Q: Where does update-initramfs look for kernel versions? I needed to regenerate initrd. Doing this:\nupdate-initramfs -u -k all\n\nthrew up errors for a kernel I compiled and then deleted some time ago (because update-initramfs could not find the /lib/modules directory I had deleted of course).\nI thought I had completely removed the kernel by deleting all its entries in /boot and directory in /lib/modules & running sudo update-grub (as in this answer), but apparently there are traces of it somewhere that I should probably clean up.\nI read this and dug around in /usr/share/initramfs-tools but I couldn't figure it out.\nIn man update-initramfs I see that:\n\nThe use of \"all\" for the version string specifies update-initramfs to execute the chosen action for all kernel versions, that are already known to update-initramfs.\n\nBut how does it know them? Where does update-initramfs look for kernel versions?\nNote: many months later... I added the answer to this question to the tag wiki for initramfs\n\nA: I had the same problem as you, I also thought I had completely removed the kernel by deleting all its entries in /boot and directory in /lib/modules & updating GRUB, but I found the one directory that is used by update-initramfs to keep track of the kernels:\n/var/lib/initramfs-tools\n\n", "Q: How to check Qt is working or not I installed Qt version 4.8.5 in my ubuntu machine and how can i test a sample program. Can anyone provide me a sample .pro file and .cpp file ? or the sample of needful files to test Qt ? \n\nA: You can find many examples from Qt's website:\nhttp://doc.qt.io/qt-4.8/all-examples.html\nQML examples:\nhttp://doc.qt.io/qt-4.8/qdeclarativeexamples.html\n", "Q: Concatenate two paths I want concatenate following:\ncurrent_dir=/home/akshay/UCS\nsource_dir=/lib/python2.7/lib-dynload/\n\nI want to produce something like this:\n/home/akshay/UCS/lib/python2.7/lib-dynload/\n\nand then I will set above path as LD_LIBRARY_PATH.\nHow should I do this in bash script?\nEDIT: the script so far:\ncurrent_dir=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\" \necho ${current_dir} \n# Extract parent directory. \nparent_dir=\"$( dirname ${current_dir} )\" \necho ${parent_dir} \nsource_dir=/lib/python2.7/lib-dynload/ \necho \"$parent_dir$source_dir\"\n\nonly gives me $parent_dir back.\n\nA: Simply\ncurrent_dir=/home/akshay/UCS\nsource_dir=/lib/python2.7/lib-dynload/\necho \"$current_dir$source_dir\"\n\nAnd then export it\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$current_dir$source_dir\n\n", "Q: How do i update to Ubuntu 16.04 I'm using Ubuntu 15.04. I want to update to 16.04. But the Software updater does not show the required update. How do i update?\n\nA: First make sure that your software is up to date. (run update manager)\nThan open the terminal Ctrl+Alt+T and run this command\nsudo update-manager -d\nHit Enter and enter your password when asked.\nOf course, be sure to make backup of any important data. It should not alter them, but you never know.\n\nA: In order to upgrade your distribution you may give this a try:\nsudo apt-get dist-upgrade\n\nAs the manual page itself explains:\n\n   dist-upgrade\n       dist-upgrade in addition to performing the function of upgrade,\n       also intelligently handles changing dependencies with new versions\n       of packages; apt-get has a \"smart\" conflict resolution system, and\n       it will attempt to upgrade the most important packages at the\n       expense of less important ones if necessary.\n\n\nIt'll upgrade the distro to its latest version.\n\nA: First you need to upgrade to 15.10, then you can upgrade to 16.04.\nFrom a terminal window:\n\n\n*\n\n*sudo apt-get update\n\n*sudo apt-get upgrade\nReboot if asked.\n\n\n*sudo do-release-upgrade\nAnswer questions and reboot as required.  Now you should be at 15.10\n\n\n*sudo do-release-upgrade\nAnswer questions and reboot as required.  Now you should be at 16.04\n", "Q: Ibus anthy - removing given input modes For the Anthy engine in Ibus, you can press Ctrl + , to switch between entering text with hiragana, full width katakana, half width katakana, normal width latin and wide latin.\nI want to remove some of these (e.g. the half width katakana option and the wide latin option) as I never use them and it makes cycling between the ones I need slower. I have looked into the Ibus anthy settings but could not find anything. Searching AskUbuntu also found nothing similar.\nNote: I am using Ubuntu 14.04\nHow can this be done?\n\nA: Select Anthy, then Preferences-Anthy. In the Setup window go to the Key Binding tab.\n\nNormally the shortcut listed for \"hiragana-mode\", katakana-mode, etc. is [ ] for no shortcut.\nDoubleclick on an item and you can add a shortcut key description. I used Ctrl+H and Ctrl+K (of course use whichever you want). Then you can use those keys directly to select the kana mode, rather than cycling through the options. \n", "Q: Ubuntu 16.04 Xenial Xerus - change from release to stable channel Last week I installed a desktop and thought I should install Ubuntu 16.04 Xenial Xerus right away. That would prevent a later upgrade. As I understand in these last weeks nothing really changes, it's mostly testing. \nNow I would like to know if I need to change the channel from RC (release) to stable, or if this happens automatically? How can I check this?\n\nA: No, you don't need to change anything.\nIf you want you can check the package sources in the file /etc/apt/sources.list:\nAll lines that don't start with a # should have something with xenial in the third field (after the URL), for example\ndeb http://archive.ubuntu.com/ubuntu xenial main restricted\n\nor \ndeb-src http://de.archive.ubuntu.com/ubuntu xenial-updates multiverse\n\n", "Q: Ubuntu Touch: Google Hangouts on bq M10 Google Hangouts doesn't work in the default browser on Ubuntu Touch OTA10.1. It just gives a message \"It appears as if you're using an old or uncommon browser that doesn't support common standards\".\nI also tried it with Firefox, but it claims to need a plugin, which I can of course not install.\nThe Ubuntu Hangups app doesn't support calls (video or voice), so it doesn't help either.\n\nA: It turns out that this is a known issue, and supposedly fixed in the rc-proposed channel (meaning that the fix will be available in OTA-11 in a few weeks). See https://plus.google.com/+OliverGrawert/posts/aZi13q1bcWw and https://plus.google.com/u/0/+MikeKelly87/posts/32EUgtorgWJ\nI have tried it using the default browser after switching the tablet to rc-proposed and can confirm that it does work (albeit with some problems selecting the camera): https://plus.google.com/+JensGrivolla/posts/JyrN4sJSqst\n", "Q: When is the 16.04 LTS .iso file available? When is the 16.04 .iso file available? I mean the official .iso. I prefer torrent. Cant see any information on the page? Only 14.04 LTS :(\n\nA: When it is made available as a final release an announcement email will go out over the mailing list, which you can subscribe to here.  There is no set time for 16.04 release though - it will be out when it is ready at some point on April 21.  Usually this is time zone agnostic so we don't base \"April 21\" on any one time zone.\n\nA: From insights.ubuntu.com\n\nLONDON 20th April 2016: Canonical announced today it will release Ubuntu 16.04 LTS on 21st April\n\n\nA: Download from here http://cdimage.ubuntu.com/daily-live/current/ \nIs avalible 20 Aprile.\n", "Q: How to tell Ubuntu not to check link to directory? I have created a link to some directory on a partition that will not be automaticaly mounted at start-up. Of course, when I restart the computer Ubuntu marks this link as \"Broken\". Is there a way to tell Ubuntu 14.04 not to check this link's path until I click on the link.\nEdit: Is there a way to make Ubuntu recheck the link with some command? \n\nA: I found a simple way to make broken link work again. Instead of rechecking the link it is easier to remake the link. (Yes I know..LOL..I have little experience in Linux). When the partition is mounted I have done this in Terminal (CTRL+ALT+T) writing the command:\nln -s -f \"path_to_Target\" \"path_to_Link/LINK_NAME\"\nln command is used to make soft or hard links.\nThe -s option is to make \"soft link\" and the -f option is to \"force\" making it so that it does not give me an error because the link already exists. The ln command is described in more detail here.\nNext stage is to make the link run the command by itself when clicked. I posted another question for this.\n\nA: You could always bind mount the directory to a location that always exists and then link to that location.\nSo for instance, say you have /dev/sdb1 mounted on /media/user/sdb1. This contains the directory ClientDocs, which you want to have a link to on your desktop at all times. \nYou could then add the directory /media/permadirs/user/ClientDocs. Then, when you have your disk mounted, you can do sudo mount --bind /media/user/sdb1/ClientDocs /media/permadirs/user/ClientDocs.\nYou can then make a link to /media/permadirs/user/ClientDocs and this link will always be valid, whether or not the disk is mounted. \nYou'll still need to do the mounting, of course, but the link will always work. Perhaps that helps you in some way. \n", "Q: Looking for wifi drivers for Hp 250 g4 for ubuntu 14.04? As I have purchased new hp 250 g4 laptop and when I tried to install WiFi drivers its taking other drivers but not working fine.\nmost of the time it doesn't connected only to my WiFi device and also if it get connected also then there is a issue related to speed. \nI spoke to the customer care of HP and they said that you need to update the WiFi drivers. Realtek RTL8723BE/RTL8188EE 802.11b/g/n Wireless LAN drivers.\nPlease help me from where I can get this drivers.\n\nA: Short answer\nYou need to update, for which you'll need to use an ethernet cable or wifi dongle that works with Linux out of the box.\nOnce you've updated you can simple paste this into the terminal and press enter:\necho \"options rtl8723be ant_sel=1 fwlps=N\" | sudo tee /etc/modprobe.d/rtl8723be.conf\n\nIf you're asked for your password, enter it and press enter. Now reset your laptop and it should work. If it doesn't, try all the steps above again but this time change ant_sel=1 to ant_sel=2.\nDetails\nThe problem is that the wifi hardware only has one of the two antennas attached but the hardware reports the wrong antenna. So you need to force the driver to use the correct antenna, which can only be done with the newer driver. To see if your driver supports this option, open a terminal and do:\nmodinfo rtl8723be\n\nIf it has the output has the line:\nparm:           ant_sel:Set to 1 or 2 to force antenna number (default 0)\n (int)\n\nThen you have the updated driver. If not then you will need to update using an ethernet cable or wifi dongle to get internet access.\nOnce you have the right drivers you need to force it to use the right antenna, like so:\necho \"options rtl8723be ant_sel=1 fwlps=N\" | sudo tee /etc/modprobe.d/rtl8723be.conf\n\nAnd then reset the laptop. If this does not work then try the above again but change ant_sel=1 to ant_sel=2.\nThe fwlps=N prevents an issue where power saving would drop the connection after a time even when being used.\n16.04 note: You can temporarily try different antenna settings before permanently setting configuration by reloading the driver using the following:\nsudo modprobe -r rtl8723be\nsudo modprobe rtl8723be ant_sel=1\n\nThis will allow you to make sure it works without having to reset the laptop each time.\n", "Q: What does this \"find\" command do? I am so beginner on Linux and I have run the following command while I am on /root:\nfind . -type d -exec chmod 770 {} \\; && find . -type f -exec chmod 660 {} \\\n\nI meant to run that on a specific folder, but I didn't note that I was on /root.\nDid that affect every file on the machine?\n\nA: Given you have sufficient permissions, the find commands will recursively change the permission bits of all files to 660 and all directories to 770 starting from the directory where it is run.\nAs you were in /root (root's home directory) and assuming you were running as root and the owner user:group is root:root, this should not be a major problem except that some specific programs may complain about some specific files or directories, such as ssh might complain about the permissions of /root/.ssh directory and /root/.ssh/authorized_keys file when doing key-based authentication, you need to fix those manually.\nAlso, don't run any command found in the wild blindly, you should ask what the command does at first, and then run it.\n\nA: That command locates all of the directories from within the directory that you ran the command and modifies its permissions. It then does the same but with files. \nIn this case, the command changes the permissions of the directories so that you have full access but other users will not have any access. If you are the only user of the system, then this should not matter.\nThe command then changes the permissions of the files within /root to allow only read and write access but do not allow execution. You may find some issues with running programs and scripts but nothing that will make a major impact. Other users will also not have any access to files within /root.\nif you find a script or program that you can not run from within /root you can simply run this command on the file:\nsudo chmod 775 filename\n\nwhere filename is replaced with the name of the file that you are trying to run\nIf there are other users of the system and you would like everyone to be able to read from directories and files, it may be worth running the command again but changing it slightly to:\nfind . -type d -exec chmod 775 {} \\; && find . -type f -exec chmod 664 {} \\;\n\n\nA: That first dot after the command is the root of the tree where find searches.  So it affected the files of the folder you ran it, and the whole tree below it.\n", "Q: Moving LXD containers to clean install of 16.04 I have a load (~14) of LXD containers running on my 14.04 development machine.\nI would like to do a clean install of 16.04 but I need to keep my containers.\nWhat is the best approach to achieve this?\nShould I publish the containers as images and then create new containers using those images when 16.04 is installed?\n\nA: On your old Ubuntu 14.04:\n\n\n*\n\n*Publish your Container: \nlxc publish --force 'name of container\" --alias 'new name' \n\nExample:\nlxc publish --force 'lxc-wordpress' --alias 'lxc-image-wordpress' \n\n\n*Export image:\nlxc image  export 'new name' \n\nThe output is something like this:\nefaa243331f0a7c175376edaf796545a01ad09bb47f25a297b798e09fe66ee66.tar.gz \n\nShow size of export:\n    du -h efaa243331f0a7c175376edaf796545a01ad09bb47f25a297b798e09fe66ee66.tar.gz \n\n\n\n*Backup your export image.\n\n*Backup your containers profile/s\nyou can show with:\nlxc profile list\n\nYou can save your *tar.gz in whatever secure place. \nInstall Ubuntu 16.04.2 and configure your LXD environment\nCopy your backup image and, inside their directory, start import\n\n\n*\n\n*Import your container images:\n lxc image import efaa243331f0a7c175376edaf796545a01ad09bb47f25a297b798e09fe66ee66.tar.gz --alias lxc-image-wordpress \n\n\n*Create and start your container based on your image:\n lxc launch lxc-image-wordpress lxc-wordpress\n\n", "Q: Can't login to Ubuntu 16.04 after upgrade I installed Ubuntu 16.04 (dual boot with Win 10) and it doesn't login after.\nI upgraded from Ubuntu 15.10 via update-manager\nhttps://youtu.be/MrgPYvoVJfA\nI have tried old workarounds for previous versions, like:\n\n\n*\n\n*dpkg-reconfigure lightDM\n\n*chown user:user .Xauthority\n\n*chmod 666 .Xauthority\n\n*chmod a+wt /temp\n\n*mv .Xauthority smth\n\n*apt-get install ubuntu-session\n\n*Reinstalling Nvidia Drivers\n\n\nAny suggestions appre\n\nA: On all my systems (all had the same problem) the solution was:\n\n\n*\n\n*Switch to console using Ctrl+Alt+F1\n\n*Login to text console (your username is enough if your system only has one user. otherwise you will need root user or sudo)\n\n*rm /home/*/.Xauthority\n\n*reboot\n\nA: I was in the same situation as you.\nI did not reinstall nvidia drivers but remove it.\nsudo apt-get purge nvidia*\n\nAnd it worked.\n\nA: I ran into the same problem on my upgrade to 16.04 from 15.10.  I recalled that during the upgrade, there was a prompt regarding UEFI Secure Boot options.  I checked my BIOS settings and sure enough, Secure Boot was set to \"Windows Only\".  I selected \"Other OS\" from the list (your options may be different) and booted normally.  All fixed.\nHave not seen any other mentions of this fix so hopefully this will help.\n\nA: I have this problem to.\nThis problem reason is the new Unity match with 4.4.0 kernel version, and your kernel version same as 4.2.x now You have 2 solution for this problem:\n\n\n*\n\n*temp: install another desktop env same as gnome,lxde,or etc...\n\n*or update the kernel.\n\n\nfor run the command before or after loop ctrl+alt+F1:\nfor check kernel version: send this command\n$ uname -a \n\nand fore update kernel :\nhttp://ubuntuhandbook.org/index.php/2016/01/how-to-install-linux-kernel-4-4-in-ubuntu/\nfor install other desktop env googling about your desktop env.\n\nA: I just tried Nuno's idea..  Negative for me..  still stuck in the login loop on Console-7.. But, able to log in via console 1 (TTY1)..  I also ran into this back when i went the route of 12.10 to 13.x (both), and it landed in the same loop..  Only workaround I could find, was using an old \"Installed\" software list from Synaptic, doing a fresh install of 13.04, and also doing the same when i bumped up to 15.04.  , getting Synaptic loaded 1st, and then reading in the old software list.\n", "Q: Removing gvfsd-smb-browse I just had the problem where gvfsd-smb-browse starts taking up the whole cpu and needs to be killed.  Searching the Internet I see this is not uncommon, and there doesn't seem to be a general solution.  As I do not use samba I would like to just remove gvfsd-smb-browse; but it is installed with the larger package gvfsd-backends that I probably do not want to remove.  Is there a way to get rid of it?\n\nA: I was having the same issue after upgrading to 16.04. What I did was change the permissions on gvfsd-smb-browse so that it can only be executed as sudo or by root. Now gvfsd-smb-browse doesn't run on startup. Below is how you can change the permissions.\nsudo chmod 744 /usr/lib/gvfs/gvfsd-smb-browse\n\nNot sure if it is a real solution to the underlying problem. But it does resolve the cpu usage issue by not running gvfsd-smb-browse on startup.\n\nA: Well, The upstream package didn't set up a configuration file or folder. I think these folders are more suitable to be somewhere in /etc\n/usr/share/gvfs/mounts/\n/usr/share/gvfs/remote-volume-monitors/\n\nOr have at least an override there. Anyway let's make one.\nsudo mkdir -p /etc/gvfs/enabled\nsudo cp -ar /usr/share/gvfs/mounts /etc/gvfs/enabled\nsudo cp -ar /usr/share/gvfs/remote-volume-monitors /etc/gvfs/enabled\n\necho 'export GVFS_MONITOR_DIR=\"/etc/gvfs/enabled/remote-volume-monitors/\"' | sudo tee /etc/profile.d/gvfs.sh\necho 'export GVFS_MOUNTABLE_DIR=\"/etc/gvfs/enabled/mounts/\"' | sudo tee -a /etc/profile.d/gvfs.sh\nsudo chmod +x /etc/profile.d/gvfs.sh\n\nNow, you have full control:\n\n*\n\n*Disable: remove/rename back-ends & monitors definition files from /etc/gvfs/enabled/mounts/ & /etc/gvfs/enabled/remote-volume-monitors/ respectively.\n\n*Enable: copy back from origin or rename back (.mount &  .monitor extension)\n\nI have tested these instructions in Ubuntu 20.10, only with monitors for quick test (ps ax | grep -i gvfs).\nReference:\n\n*\n\n*https://wiki.gnome.org/Projects/gvfs/doc\n\nA: There is a similar question where the workaround is to edit your smb.conf like in Launchpad bug #1409032.\nIt worked for me reducing CPU usage and really sped things up!\nI just put this line under the globals statement after backing up my /etc/samba/smb.conf file:\n[global]\nname resolve order = wins lmhosts bcast\n\nNote: wins is no longer necessary on the majority of systems, especially those after the year 2000.\n", "Q: TCP Server and client application for ubuntu I am developing a wi-fi module now, and for testing I have only pc with Ubuntu and I am looking for an application for the connecting to my TCP server on the Wi-Fi module, on Windows platform I was using Hercules HW group application, where I could easily connect to the server and receive/send files, so what can I install on my PC with Ubuntu?\nThanks in advance\n\nA: For a \"raw\" TCP connection, take a look at netcat or telnet. There's a good chance you already have them installed, or you can easily get them with apt-get.\nI'm not sure what you mean with the receive/send files bit, that depends on whatever service you have running for that on your module (ftp, scp, http, webdav, smb, ...).\n", "Q: Postfix keeping email in queue for indefinite time. Sending from sendmail its working. Any idea? I have set up postfix on my ubuntu. I have configured it properly so when ever I send email through Command Line or from \"Read User Mail\" section of Webmin its working. But when I try sending php code its not working. It is putting that email in queue for indefinite time.\np.s. I am using different from email address in php code.\nAny Idea?\n\nA: Ohh my bad.\nMy receiving address has blocked this email and that's why it is not working.\n", "Q: 13 times 'zenity' with status Zombie I have 13 times zenity with status Zombie in my system-monitor.\nCould there be any virus or what else could it be?\nI have read this:\nWhat are zombie processes?\nbut I can't do anything with it regarding zenity\nwhich is just a helper tool for programmers as far I understood and I never used that programm.\n\nA: Thank you Mark, the answer in your linked helped me to get rid of it.\nps l gave only two lines but pstree -p $USER spit out a long tree list and I could find the parent was marco (a part of d.conf in Ubuntu Mate): I had created some shortcuts in d.fonf editor. \nI had terminated marco in system-monitor and all zenity's were gone. Stupidly I did this while the terminal still was running and all the windows were messed up, so I had to reboot. But now all is fine and I learned something new again :)\n", "Q: Where is the Ubuntu file system root directory in Windows Subsystem for Linux and vice versa? I have installed Ubuntu subsystem on Windows 10 (after enabling feature in settings), but where is the Ubuntu file system root directory located in the drive?\n\nA: You can quickly open Bash from a File Explorer window of the opened folder by typing bash in the location bar.\nIt's enough.\nAlso you can add a context menu item. I personally don`t recommend it if not needed, because adding shortcuts to the context menu uses more RAM.\nhttps://www.howtogeek.com/270810/how-to-quickly-launch-a-bash-shell-from-windows-10s-file-explorer/\n\nA: For Ubuntu installed from the Windows store:\n\nEach distribution you install through the store is installed to that\n  application's appdata directory. For example:\n  C:\\Users\\<username>\\AppData\\Local\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\\LocalState - benhillis\n\nFor WSL2 you can access to home directory from windows (Windows 10 build 18342) like this :\n\\\\wsl$\n\nIn earlier iterations of Windows Subsystem for Linux, the Ubuntu file system was at %localappdata%\\Lxss (e.g., C:\\Users\\Username\\AppData\\Local\\Lxss - replace the Username with your Username on Windows). See the WSL blog post on File System Support:\n\nThe primary file system used by WSL is VolFs. It is used to store the\n  Linux system files, as well as the content of your Linux home\n  directory. As such, VolFs supports most features the Linux VFS\n  provides, including Linux permissions, symbolic links, FIFOs, sockets,\n  and device files.\nVolFs is used to mount the VFS root directory, using\n  %LocalAppData%\\lxss\\rootfs as the backing storage. In addition, a\n  few additional VolFs mount points exist, most notably /root and\n  /home which are mounted using %LocalAppData%\\lxss\\root and\n  %LocalAppData%\\lxss\\home respectively. The reason for these separate\n  mounts is that when you uninstall WSL, the home directories are not\n  removed by default, so any personal files stored there will be\n  preserved.\n\nCAUTION\nCreating/modifying any files within the Linux subsystem using Windows apps & tools can cause Data corruption and data loss in Ubuntu subsystem! (Thanks to Rich Turner for suggesting these words of caution!) This is absolutely not supported. From the same blog post:\n\nInteroperability with Windows\nWhile VolFs files are stored in regular files on Windows in the\n  directories mentioned above, interoperability with Windows is not\n  supported. If a new file is added to one of these directories from\n  Windows, it lacks the EAs needed by VolFs, so VolFs doesn’t know what\n  to do with the file and simply ignores it. Many editors will also\n  strip the EAs when saving an existing file, again making the file\n  unusable in WSL.\n\n\nYour Windows file system is located at /mnt/c in the Bash shell environment.\n\nSource: Dustin Kirkland's blog, howtogeek\n\nA: This seems to have changed since Bash was originally introduced, and does not apply to distributions from the Windows Store, or maybe it is not consistent for all systems as my home directory is located in another location:\n%localappdata%\\lxss\\home\\{username}\n\nor:\nC:\\Users\\{user}\\AppData\\Local\\lxss\\{username}\n\nWhere {user} is your Windows Username and {username} is your UNIX Username set during install.\nSo the root directory would be:\n%localappdata%\\lxss\n\nNote that the root directory may not be visible in Windows Explorer from the %localappdata% directory. You should be able to access it anyways by typing it in the 'address bar' of Explorer.\n\nA: The only thing that worked for me was %localappdata%\\lxss\\home\\{username}, where the {username} is your BASH username you gave it during the installation. For some reason, after showing hidden folder's lxss refuses to appear in C:\\Users\\WINDOWS-USER\\AppData\\Local\\, and also giving the full C:\\ path with windows and BASH username does not work either.\nAnd please create a desktop shortcut for what works.\n\nA: For those who are looking for the image location:\nC:\\Users\\\\[username]\\AppData\\Local\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\\LocalState\\ext4.vhdx\n\n\nA: If you install Linux from MS Market:\n\n\n*\n\n*Free Ubuntu in Windows store\n\n*Free Open Suse in Windows store\nthey placed distros under:\n$ cat /proc/registry/HKEY_CURRENT_USER/Software/Microsoft/Windows/CurrentVersion/Lxss/\\{861c29b4-ebe2-49a5-8a22-7e53a27934a0\\}/BasePath\nC:\\Users\\user\\AppData\\Local\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\\LocalState\n\nDefault distro defined by:\nbash# cat /proc/registry/HKEY_CURRENT_USER/Software/Microsoft/Windows/CurrentVersion/Lxss/DefaultDistribution\n{861c29b4-ebe2-49a5-8a22-7e53a27934a0}\n\nLinux root is deeper:\nc:/Users/user/AppData/Local/Packages/46932SUSE.openSUSELeap42.2_022rs5jcyhyac/LocalState/rootfs\n\nPS. I used Cygwin to explore registry keys.\nIf using PowerShell for the same goal, the commands would be:\n# obtain the value of the ID of the default Linux distribution (and store it in a variable to avoid escaping characters issues):\n$DEFAULT_LXSS_ID = (Get-ItemPropertyValue -Path REGISTRY::HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Lxss\\ -name DefaultDistribution)\n\n# which will have a value like:\necho  $DEFAULT_LXSS_ID\n{bde539d6-0c87-4e12-9599-1dcd623fbf07}\n\n# display the directory containing the rootfs Windows directory (mapped to the / Linux directory)\nGet-ItemPropertyValue -Path REGISTRY::HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Lxss\\$DEFAULT_LXSS_ID -name BasePath | Format-List -property \"BasePath\"\n%LocalAppData%\\Packages\\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\\LocalState\n\nPPS. https://blogs.msdn.microsoft.com/commandline/2016/11/17/do-not-change-linux-files-using-windows-apps-and-tools/\n", "Q: How can I use the in-built function alert in Gnome Schedule? I want to access the alert function in Gnome Schedule.\nI can run alert from my default Bash command-line but receive the following error in Gnome Schedule:\n/tmp/tmpxi4X16: line 1: alert: command not found\nPress ENTER to continue and close this window.\n\nThe following screenshot illustrates the problem. The visible notification comes from the right terminal window. The left terminal window is the result of me manually running the recurrent task Mackup in Gnome Schedule.\n\n\nA: If you look into your ~/.bashrc file youll find the alias which defines alert.\n\n# Add an \"alert\" alias for long running commands.  Use like so:\n#   sleep 10; alert\nalias alert='notify-send --urgency=low -i \"$([ $? = 0 ] && echo terminal || echo error)\" \"$(history|tail -n1|sed -e '\\''s/^\\s*[0-9]\\+\\s*//;s/[;&|]\\s*alert$//'\\'')\"'\n\nExample:\nTry as input in your manual terminal:\n\nnotify-send \"Hello World!\"\n\n", "Q: Is choosing 'Security Updates Only' on installation of Ubuntu Server enough? I want necessary security updates on my Ubuntu servers, without my interference. In general, do I need to do anything else after selecting the 'Security updates only' option in the automatic updates section of the OS installation process?\nI've looked in /etc/apt/apt.conf.d/50unattended-upgrades and seen that the only archive available is indeed security. I'll probably set up the Unattended-Upgrade::Mail and Unattended-Upgrade::MailOnlyOnError parameters, and choose to reboot at a more convenient time with Unattended-Upgrade::Automatic-Reboot-Time \"02:00\".\nI've looked at the documentation for unattended-upgrades on 14.04 server, which I understand is for setting it up after installation. The guide suggests the following in /etc/apt/apt.conf.d/10periodic:\nAPT::Periodic::Update-Package-Lists \"1\";\nAPT::Periodic::Download-Upgradeable-Packages \"1\";\nAPT::Periodic::AutocleanInterval \"7\";\nAPT::Periodic::Unattended-Upgrade \"1\";\n\nBut my version of this file only contains:\nAPT::Periodic::Update-Package-Lists \"1\";\nAPT::Periodic::Download-Upgradeable-Packages \"0\";\nAPT::Periodic::AutocleanInterval \"0\";\n\nApart from the APT::Periodic::AutocleanInterval which I understand, are these only different because I have a 50unattended-upgrades file?\n\nA: In normal cases where you want a stable deployment of lets say LAMP and all what comes with it in production environment security updates are sufficient.\nYou need to change the \n/etc/apt/apt.conf.d/10periodic \nfile to this:\n\n# switches on the apt get update run 0 for off\nAPT::Periodic::Update-Package-Lists \"1\";\n# lets the server pre download available packages 0 for off\nAPT::Periodic::Download-Upgradeable-Packages \"1\";\n# runs apt-get clean every 7 days\nAPT::Periodic::AutocleanInterval \"7\";\n# switches the unattended upgrades on 0 for off\nAPT::Periodic::Unattended-Upgrade \"1\";\n\nBeside that you have a couple more options in the \n/etc/apt/apt.conf.d/50unattended-upgrades file.\nP.S.: all other upgrades are normally done on a server environment by hand.\n", "Q: Is this the actual 16.04 release of Ubuntu GNOME? I have gone to the Ubuntu GNOME website. There is no announcement stating that there is the 16.04 release. It still says the latest is Wily. The thing is that on http://cdimage.ubuntu.com/ubuntu-gnome/releases/xenial/release/ there is now the 16.04 files, which was not there earlier today. \nAnother thing is that there is no download for Ubuntu 16.04 with Unity on the Ubuntu site.\nHow can I check if this is the stable 16.04 Ubuntu GNOME release before installing it?\n\nA: According to https://wiki.ubuntu.com/XenialXerus/ReleaseSchedule Canonical will release Xenial today, so there will likely be a Xenial with Unity soon.\nAs the Ubuntu GNOME images you refer to are released today in accordance with the schedule, one must assume they are the \"final release\" ones.\n", "Q: Problem in booting my computer While installing windows i accidentally deleted all my files and could not install windows either. Now when i am trying to restart my computer it says no boot device found. I also tried reinstall Ubuntu with pen drive but still can't able to do it. Please help.  \n\nA: please boot from a 'bootable USB' device (I do not mean reinstall)/ for example run Ubuntu live and if it works, then the problem is probably your HDD. Please give me feedback because I need to dig deeper into your problem... Thanks.\n", "Q: bq M10: bluetooth keyboard and mouse at the same time? According to the user manual:\n\nRemember you can only link to one device at a time via Bluetooth, whether a keyboard or mouse. The other device must be connected via USB. You can  also connect to a single Bluetooth device which contains both a mouse and keyboard.\n\nThis seems completely ridiculous, and is contrary to all the promotional images that show it with a Bluetooth keyboard and mouse. I would consider it seriously broken if this was true.\nI currently only have a BT keyboard, and would still need to buy a mouse. Has anybody tried it with both keyboard and mouse connected through BT?\n\nA: I've connected both a keyboard an mouse via bluetooth to my BQ Aqauris M10 at the same time. Both worked fine and I was brought into convergence mode. For the record it was an apple wireless keyboard and rapoo mouse.\n\nA: In my case, only one (either mouse or keyboard) will connect automatically. Both bluetooth devices will work simultaneously, I just have to connect one manually via the Bluetooth menu.\n\nA: I connected both a Microsoft sculpt designer mouse and a logitech K480, both are working simultaneously.\nThe problem was to connect both devices, I had to try several times : first connect the mouse, then the keyboard was not detected, so i removed the mouse, then the M10 detected the K480 but not the mouse ... after several attempts both devices were finally detected and connected\n", "Q: \"E: There are problems and -y was used without --force-yes\" when installing php I'm trying to install php through the following:\nsudo apt-get install -y php7.0 libapache2-mod-php7.0 php7.0 php7.0-common php7.0-gd php7.0-mysql php7.0-mcrypt php7.0-curl php7.0-intl php7.0-xsl php7.0-mbstring php7.0-zip php7.0-iconv\n\nbut I'm getting the following message and error:\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nNote, selecting 'php7.0-common' instead of 'php7.0-iconv'\nThe following extra packages will be installed:\n  libcurl3 libgd3 libjbig0 libjpeg-turbo8 libjpeg8 libmcrypt4 libssl1.0.2 libtiff5 libvpx2\n  libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxpm4 libxslt1.1 libzip4 php-common php7.0-cli\n  php7.0-json php7.0-opcache php7.0-readline php7.0-xml\nSuggested packages:\n  php-pear libgd-tools libmcrypt-dev mcrypt\nThe following NEW packages will be installed:\n  libapache2-mod-php7.0 libcurl3 libgd3 libjbig0 libjpeg-turbo8 libjpeg8 libmcrypt4 libssl1.0.2\n  libtiff5 libvpx2 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxpm4 libxslt1.1 libzip4\n  php-common php7.0 php7.0-cli php7.0-common php7.0-curl php7.0-gd php7.0-intl php7.0-json\n  php7.0-mbstring php7.0-mcrypt php7.0-mysql php7.0-opcache php7.0-readline php7.0-xml php7.0-xsl\n  php7.0-zip\n0 upgraded, 34 newly installed, 0 to remove and 20 not upgraded.\nNeed to get 7632 kB of archives.\nAfter this operation, 28.9 MB of additional disk space will be used.\nWARNING: The following packages cannot be authenticated!\n  libssl1.0.2 php-common php7.0-common php7.0-json php7.0-opcache php7.0-readline php7.0-cli\n  libapache2-mod-php7.0 libzip4 php7.0 php7.0-curl php7.0-gd php7.0-intl php7.0-mbstring\n  php7.0-mcrypt php7.0-mysql php7.0-xml php7.0-xsl php7.0-zip\nE: There are problems and -y was used without --force-yes\n\nplease help \n\nA: Try to re-run apt-get update before you finaly run the \n\nsudo apt-get install php7.0* libapache2-mod-php7.0\n\nwithout the -y and without --force-yes.\n", "Q: uninstall python 2.7.6 and install 2.6 instead I need to uninstall python 2.7.6 and install 2.6 instead. how can I manage that. which python command gives (/usr/bin/python). my environment is ubuntu 14.04.\n\nA: You could try:\napt-get remove python2.7\nDon't remove python 2.7, instead have both at the same time\nInsert the following in /etc/apt/sources.list:\ndeb http://ppa.launchpad.net/fkrull/deadsnakes/ubuntu trusty main \ndeb-src http://ppa.launchpad.net/fkrull/deadsnakes/ubuntu trusty main\n\nOr use another PPA of your choice. Then run:\napt-get update\napt-get install python2.6\n\nDisclaimer: The PPA is just one I found on Google, no guarantees.\n", "Q: customized Xenial distro: better rebuild from scratch or upgrade from beta2? as passim I've told in some of my previous messages, I'm the maintainer of our customized LTS distro. In next few days Xenial will be released and I've already set-up a multilingual customized distro based on it (before beta1, now beta2 based), the way to get ready and don't have troubles when 16.04 will be officially released.\nNow, the question is: as soon as Xenial will be officially released, it would be better rebuild it from scratch - i.e. starting from officially released iso - or it will be sufficient updating beta2, mutatis mutandis in sources.list? Or it will be the same?\nThanks for your time and cheers,\nSilvia\n\nA: Beta ISOs were just that - beta ISOs.\nRebuild your ISOs after 16.04 officially releases.  You get kernel updates and other fixes that way.\n", "Q: How can i get a Intel HD 5500 graphics driver for linux OSes? I got a Dell Inspiron 14 3443 laptop containing Intel HD 5500 graphics but it's driver is not available for any linux OS(couldn't find on google). I am very passionate to install linux. But, without it, the brightness is maximum and can't be controlled. Please help me know how can i get the driver for linux or what should i do? Or, please make me clear if i'll be able to get that driver for linux or not?\n\nA: First it sounds as if you are new to Ubuntu / Linux , but generally the driver for your graphics card is in the kernel and thus installed already.\nSecond, if you do need to install a driver it is best to use the packages available from the repositories in your distro. \nfor Ubuntu see - https://help.ubuntu.com/community/InstallingSoftware and https://help.ubuntu.com/community/Repositories/Ubuntu\nIf there is a package you need not in the repositories, you then try a ppa or, IMHO, build from source.\nThere are various reports regarding your video card\nWorks - Intel HD 5500 support on ubuntu?\nBugs - https://bugs.launchpad.net/xserver-xorg-video-intel/+bug/1432194\nSo, have you tried Ubuntu ? Did you actually have a problem ? If you did, you would need to file / follow a bug report and/or contact Intel for a driver as is is a 3rd party proprietary (closed source) driver.\nSo to some extent your question is quite broad as you are asking about all distros, and not just ubuntu, and we do not know if you are even having a problem or not.\nTo be honest, as with any OS, it is best to either purchase a computer with Linux (Ubuntu) pre installed (same as you did with windows) or purchase a Linux compatible video card. You would have the same problem if you tried running a windows incompatible video card in windows.\n", "Q: Is possible to install/update Gnome 3.20 via Snap in Ubuntu 16.04? Probably it is not possible right now because a lot of work have to be done in order to have the packages ready. But I read that it could be possible.\nAnyone knows if there are plans to make Gnome available via Snap?\nEdit: It seems that Gnome Software Centre will support Snap. But it does not mean that Gnome is going to be installed by Snap, yet.\n\nA: No. At least not yet.\nIt's also unclear whether Snap can be used for an entire desktop or is more for running individual apps. Once someone does the work, you could run a snap for gedit 3.20 or cheese 3.20. On the other hand, it may not be feasible for a snap to include gnome-shell 3.20 or even the 3.20 version of the Settings app (gnome-control-center) because they are lower-level system software.\n", "Q: Bash script that runs a command with arguments and redirects So I'm trying to execute a command in a bash script multiple times with different but same number of arguments while redirecting the output to a text file.  For example ...\n./test arg1 arg2 arg3 >> output.txt\n\nThis works if I do it at the command line.  In a script where I have...\ncommand ./test 10 5 option1 >> output.txt\n\n\ncommand ./test 5 10 option2 >> output.txt\n\nAnd run the script, I get command not found.  If I remove the redirect to ouput.txt, the script then works / prints to the terminal window\nI tried searching online but I could not find examples where arguments were used which then redirected\nAnyone able to help?\n\nA: The issue had to do with writing the script in Windows in Sublime Text and then transferring it to a Linux server.  Switching the mode in Sublime Text made the difference\nVideonauth also pointed out that I should have just one redirect symbol \">\" since for the first line since it is a new file\n", "Q: Text installer freezes at the language selection panel on Ubuntu 16.04 LTS (UEFI) I just downloaded the newest version of Ubuntu 16.04 LTS (http://releases.ubuntu.com/16.04/)\nand created a USB UEFI boot media (with Rufus 2.8).\nThe boot is going fine, but when I press \"install ubuntu server\",\nI get stuck on the first panel (language selection).\nI read, that the possible error could be the USB keyboard,\nso I tried a different keyboard, but the problem still exists.\nThen after some trial and error, I went under \"check disk failures\"\nand this error message appears: \"Error while running 'modprobe -v usb-storage'\"\nIs there a problem with the brand new Ubuntu 16.04 LTS AMD64 image when it is installed in UEFI mode?\nedit: So I tried the same iso in a VM, and the VM installation was a success. Next, I am going to use another USB Stick for installation.\nedit2: new USB Stick -> same problem.\n\nA: I also have the same problem. I solved it by disabling SecureBoot in my BIOS settings. I have ability to disable SecureBoot and keep enabled UEFI. Some guys on other forums use legacy bios.\nI use rufus 2.8 and follow settings\n", "Q: Update PHP to use latest Curl Version We have installed Curl 7.46.0 but PHP is still referencing 7.35.0\nHow do we get PHP to use the latest installed version\ncurl--version shows correct version running but php working with previous version\nThanks\n\nA: Refer to this answer: https://serverfault.com/a/665802\nyou need to update libcurl as well, since PHP uses that instead of CURL\nEdit:\nyou can update libcurl by using the following commands: \nsudo apt-get update\nsudo apt-get install php5-curl\n\nand restart apache \nsudo service apache2 restart\n\nand PHP-FPM if needed\nsudo service php5-fpm restart\n\n", "Q: I can't open mpv player in Ubuntu 16.04 mpv: error while loading shared libraries: libgbm.so.1: cannot open shared object file: No such file or directory\neverything is from Ubuntu's repository, the 3rd party ppa doesn't work either.\nI directly upgrade it from 14.04 to 16.04\n\nA: It's a known bug and I have found the answer.\nsudo dpkg-divert --remove /usr/lib/x86_64-linux-gnu/libgbm.so.1.0.0\nsudo dpkg-divert --remove /usr/lib/x86_64-linux-gnu/libgbm.so.1\nsudo apt-get --reinstall install libgbm1\n\n\nA: The following solution posted as a comment by Noki worked for me:\nsudo apt-get install --reinstall libula5.2-0\n\nI'm on Ubuntu 17.04 and had this problem for months.\n", "Q: Upgrade Desktop form 14.04 LTS \"No new release found\" I've verified that \"Notify me of new Ubuntu version\" is set to \"For long-term support versions\" in Software & Updates. Yet when I run do-release-upgrade I get \"No new release found.\" Please help.\n\n\nA: Command do-release-upgrade -c -d at this moment will get 16.04 LTS\n\nA: Usually, LTS upgrades are not supported in the initial LTS-next. That is, 12.04LTS could not be upgraded to 14.04LTS, but only when 14.04.1LTS was released. I would expect the same to be true this time, and that you'll have to wait until 16.04.1 to be released. I don't know the planned release date, but it's usually about three months after the main release. \nYou will be notified when it's ready to be upgraded and you should not try to do it manually by entering commands unless you really know what you're doing. Upgrading LTS to LTS is more difficult than normal upgrades and for most people, it's more important, so this needs more time to be handled correctly. \nThe \".1\"-releases are Ubuntus version of \"Service packs\". So in other words, wait until the first SP is released. I would guess it'll happen sometime in July. \n\nA: As of 9th May this still does not work\nsudo do-release-upgrade \n\nBut it worked for me with -d flag.\nsudo do-release-upgrade -d\n\n\nA: the 16.04 LTS Final Release is not out yet. it will be released during sometime later today/tomorrow latest. try again then\n\nA: The 16.04 LTS Final Release is not out for upgrade yet but it will be released sometime later today/tomorrow.\nTo have a check you can simply do from terminal \ndo-release-upgrade -c\n\nthis will check if the actual release is open. If yes run the command\nsudo do-release-upgrade\n\nwithout any parameter.\n\nA: The LTS versions only upgrade to LTS by default. Which the new LTS has not hit the mirrors yet.\nStrangely I got 16.04 Ubuntu Mate for Raspberry Pi yesterday.\n", "Q: Help to upgrade ubuntu 14.04 to 16.04 Today Ubuntu 16.04 LTS is released. I saw the iso available here. But I don't want to do a clean install. Can someone explain to me how to upgrade?\n\nA: The 16.04 LTS Final Release is not out for upgrade yet but it will be released sometime later today/tomorrow.\n\nFrom man do-release-upgrade\nOPTIONS\n   -h, --help\n          show help message and exit\n\n   -d, --devel-release\n          Check if upgrading to the latest devel release is possible\n\n   -p, --proposed\n          Try upgrading to the latest  release  using  the  upgrader  from\n          Ubuntu-proposed\n\n   -m MODE, --mode=MODE\n          Run  in  a special upgrade mode. Currently \"desktop\" for regular\n          upgrades of a desktop system and \"server\" for server systems are\n          supported.\n\n   -f FRONTEND, --frontend=FRONTEND\n          Run the specified frontend\n\n   -s, --sandbox\n          Test upgrade with a sandbox aufs overlay\n\n\nThere is one function undocumented in the manpage but you can see it when you call do-release-upgrade --help:\n\n-c, --check-dist-upgrade-only\n                        Check only if a new distribution release is available\n                        and report the result via the exit code\n\n\nSo to check if the upgrade is already available you can use the following line from terminal:\ndo-release-upgrade -c\n\nwhich will give you the following output if the release is not available:\nChecking for a new Ubuntu release\nNo new release found.\n\nand the following if the release is actually available:\nChecking for a new Ubuntu release\nNew release '16.04' available.\nRun 'do-release-upgrade' to upgrade to it.\n\nIf you want to test if the upgrade will give you errors you can do the following:\nsudo do-release-upgrade -s\n\nThis will try to install the upgrade without actually installing it. The only error there coming up you can ignore is the one about grub since it is a sandbox install grub is unable to be installed. If you find other errors you should probably rather go for a fresh installation instead of an upgrade. However since it is a sandboxed installation test you can simply rebootyour machine and be back on your old system without any changes happened.\nFor the upgrade itself if you want to do it and you got the confirmation the release is available you can simply run\nsudo do-release-upgrade\n\nwithout any parameters, which will do then the upgrade.\nIn the case you don't want to wait and it is shortly before the release (i.e. release day but you got no confirmation of the release already available) you can force an upgrade to the development branch which should be at that point on par with the release itself with:\nsudo do-release-upgrade -d\n\n\nA: Now that the release is out you can do the following:\nsudo do-release-upgrade -d\nMake sure you backup your system first. You may need to intervene to tell it to overwrite any config files with changes, or to show you a diff so you can either merge it manually or make a note to fix it later.\n(The -d flag is for \"Development\" but it will give you the final 16.04 LTS release. The reason you have to force it in this way is that usually it is recommended you wait for the 16.04.1 point release to come out as it usually contains a lot of bug fixes.)\n\nA: sudo do-release-upgrade\n\nThat’s the command to upgrade to the latest version, but it won’t do anything at the moment as the latest version is not yet available on the mirrors.\nStrange point though: I downloaded Ubuntu Mate 16.04 for the RPI3 yesterday, which was quite strange, since the normal desktop image is still 15.10.\n", "Q: Okular annotations - *.xml file path and correct colour issue The review highlights made in okular are stored in ~/.kde/share/apps/okular/docdata/ , with a *.xml file for each annotated *.pdf.\n1st question:\nHow can I change the path of the xml annotations to be the same path of the *.pdf? Therefore when I would change the pdf from my computer to a pen or external disk, the *.xml file would go in the same folder - and wouldn't be lost in the standard folder.\n2nd question:\nThe underline tool hides the bottom of each line:\n\nHow can I correct it in order to do not override the bottom of each text line?\nobs.:\nIn order to underline with yellow or other colours, I have edited a file of the okular settings stored in: /usr/share/kde4/apps/okular/tools.xml . By changing that file I was able to add more review colours for underlining, by adding code analogous to this:\n<tool id=\"9\" name=\"Black Underlining\" pixmap=\"tool-underline-okular\">\n    <tooltip>Underline the text with a black line</tooltip>\n    <engine type=\"TextSelector\" color=\"#000000\">\n        <annotation type=\"Underline\" color=\"#000000\" />\n    </engine>\n    <shortcut>9</shortcut>\n</tool>\n\nand then, replacing id, shortcut and color respectively.\n\nA: 1st part:\nIn order to export the annotations to other computer we can export the document as a *.okular file (which corresponds to a zip file with the *.pdf + *.xml files). In this case, to read the annotations in the other computer, the okular program is needed in both computers.\nAlternatively I have read that the newer versions of okular compiled with poppler 0.20 do have the option to export to a pdf with annotations (though, I don't have it now).\n2nd part:\nGo to \"Settings -> Show navigation panel\"; then in \"Reviews\" view the annotations; click with the right button in each \"Highlight\"; then click in \"Properties\"; after that choose the type to \"Squiggly\" (as in fig.1, squiggly) or \"Underline\" with opacity 70% (as in fig.2, underline with opacity 70%).\nobs: it is possible to choose more colours than the default black (eg. yellow) in the \"General\" tab (alternatively of editing the code, as mentioned in the question) - in fact, by editing the code a permanent new \"highlight yellow button\" would be added, whereas if the change is made in the GUI the colour must be changed for each annotation if yellow is the desired colour.\n\n\n", "Q: New Terminal bash file error Upon opening a new terminal in Ubuntu, I get this error. I tried opening the bashrc file but It seems to be empty.\nbash: /home/rma/prac/devel/setup.bash: No such file or directory\nbash: /home/rma/trials/devel/setup.bash: No such file or directory   \nbash: /home/rma/T/devel/setup.bash: No such file or directory\nbash: /home/rma/abc/devel/setup.bash: No such file or directory\nbash: /home/rma/RMP/devel/setup.bash: No such file or directory\n$ \n\nI am running ROS Jade on Ubuntu 14.04\nI had old workspaces which I deleted following the information given here. I think there was something left which wasn't removed with the workspaces. \nWhat could be the error and how can I solve it?\nAny suggestions or comments will be appreciated. Thanks in advance!\n\nA: It worked with gedit. \ngedit ~/.bashrc brought up the bashrc file from which I was able to remove those lines. Upon saving and opening a new terminal, I could see no such lines. \n", "Q: Error in Ubuntu 16.04 installation After the installation of the Ubuntu 16.04 LTS and the login to my account is not display anything. Only the classic wallpaper of the Ubuntu and one message error which is hidden after some seconds. Ι have the same problem and with the live CD.\n\nA: Perhaps you could hit Alt+Ctrl+F3, which gives you a console. Then log in, and then do:\nsudo apt-get update\nsudo apt-get dist-upgrade\nsudo dpkg --configure -a\n\nThis could help if the installation is stuck somewhere.\n\nA: I installed another graphical evriroment and specifically the 'lubuntu-desktop' and the problem solved.\n\nA: I had the same problem, now downloading another ubuntu based distro to see if that works. My system:\nSkylake based M/B: GA-Z170X-UD5, i7 7600, GeForce GX 980 Ti\nI noticed that the installer would sometimes only recognise the onboard graphics, so I had to replug the monitor cable, when I checked the error report it was clearly related to the graphics card. I guess it's some driver issue.\n", "Q: XPS 13 9350 (2016) suspend - sound issues I own a Dell xps 13 9350 (2016) and from the beginning I had issues with suspend mode. When I would wake the machine up it would freeze and I have to reboot. I did a few system updates but then it thought some unknown audio-device was plugged in after waking it up and now, after rebooting from that, my whole soundcard is no longer detected...\nAnyone else experiencing the same, or knows how I can get my soundcard back to be recognized and work?\n\nA: I'm also using a DELL XPS 13 9360 (late 2016) and experienced the same issues on suspend. the system would suspend but would not resume. \nI have Ubuntu 16.10 installed with kernel version : 4.8.0-27-generic\nWhat solved the issue for me is the installing of user-space uswsusp package.\nsudo apt-get install uswsusp\n\nReference: PowerManagement Ubuntu\n\nA: Yes, I have the same problem. It was reported on the Dell Community Forums here: http://en.community.dell.com/techcenter/os-applications/f/4613/t/19682246\nThere seems to be no fix yet, but Dell has \"replicated the issue in house\", so I expect it won't take too long now.\n\nA: Same issue here, \nI got my xps 13 9350 last week. After I upgraded to xenial, I supended and resumed and lost all sound capabilities. It couldn't detect internal audio, the bluetooth device nor the dock station WD15. Reinstalling the whole system to Xenial fixed all my issues. \n", "Q: After Upgrade from 14.04 to 16.04 login screen runs in a loop while console login works I am on a DELL Precision 5510 Ubuntu Edition with Ubuntu 14.04 as default installation. Today I upgraded from 14.04. to 16.04 as shown here\nThe upgrade went without any error messages. However, after reboot I cannot login via Login Manager (lightdm by default?) anymore. While the password is accepted, the screen shortly prompts the desktop view for, say, a second and then immediately switches back to the login screen without further notice.\nI can properly login via text console ( CTL + ALT + F1). So it is definitely not a password wrong issue. \nI have read that this might have happened users before, see here. Difference with me is, that the screen after the login attempt is not completely black but it actually shows the desktop overview and even a system dialogue which I can't access because the loop follows to quickly.\nWhat could be wrong here? How can I use my system again? Any help is much appreciated.\n\nA: I ran into this after updating from 15.10 Wily Werewolf.\nI use Nvidia's prime-select command to enable and disable the dedicated graphics card. (After using Ctrl+Alt+F1 and logging into the console) I disabled my GT 540M graphics card with sudo prime-select intel followed by sudo reboot.  Upon reboot I was able to log into Unity.\nObviously this is more of a short-term fix and as the other answers have indicated, perhaps the long term solution will be related to  replacing or upgrading the Nvidia drivers or allowing the existing unsigned driver to run by disabling secure boot.  But hopefully this at least gets you to the desktop!\nEdit: The Nvidia driver can now be installed using the official PPA, per this answer:\nsudo apt purge nvidia-*\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt update\nsudo apt install nvidia-364\n\n\nA: I had the same problem after upgrading from 15.10\nWhat was the problem?\nFor me, the problem was that UEFI Secure Boot was enabled.\nThe NVIDIA drivers are compiled locally and are therefore not signed.\nUbuntu 16.04 does not allow unsigned kernel modules when Secure Boot is enabled.\nI disabled Secure boot, but still, I ended up in a login loop.\nWell, that was my own fault. In the meantime I switched to a terminal using Ctrl+Alt+F1 and started an Xserver using sudo. It then changed files in my home directory and set the ownership to root.\nAfter running sudo chown username:username -R /home/username (change all three username to your personal user name) I was able to log in to a normal X session.\n\nA: I got the same problem after a fresh install. \nCtrl+alt+F1 \nthen\nsudo apt-get dist-upgrade\n\nWorked for me. \nIt looks like there were some packages left behind\n\nA: I have exactly the same laptop and the same problem. After this command:\nsudo apt-get purge nvidia*\nI'm able to login again but to my surprise the system is not 16.04. I'm back at 14.04 - absolutely strange.\nUpdate:\nActually, I'm running 16.04 but system settings are telling me it's 14.04. And after activating nvidia proprietary drivers the login problem is back again.\n\nA: I got the same looping login after install NVIDIA driver, I tried to all above recommends and reinstall ubuntu-desktop, lightdm, gdm3, or unity but nothing worked. Only installing other desktop environment(mate, kubuntu) works.\nSo the problem (in my case) is because of NOMODESET\nIf you have problem that looping login that you've ever used nomodeset to boot on ubuntu or cannot boot ubuntu even from live usb, you \nshould try first\n\n\n*\n\n*set nouveau.modeset=0 \n    (press e when ubuntu first restart, when you are choosing list of OS. Then add argument nouvea.modeset=0 after quite splash) let's add argument nouveau.modeset=0 after quite splash\n\n*if the first one does not work, then try set nomodeset instead of nouveau.modeset=0\n(add nomodeset after quite splash)\n\n\nNOTE: \n\n\n*\n\n*We ONLY use nomodeset temporary, don't change it in grub default (don't add nomodeset in this file /etc/default/grub) \nafter booting ubuntu with nomodeset, install any driver you want from additional driver or from .deb package.\nthen restart the ubuntu.\n\n*Setting nomodeset after install nvidia will create the loop login or crash the ubuntu-control-center\nIf working well, then add the nouveau.modeset=0 in default of grub, run some commands in this link How do I set 'nomodeset' after I've already installed Ubuntu?\n\nA: Do not purge your drivers, if you have install them again via Additional Drivers under Software and Updates in System Settings.\nThen open up your terminal (ctrl + alt +  f1 if stuck at log in screen) and type \"sudo mokutil --disable-validation\" then enter your passwords three times.\nRestart and disable Secure Boot via Shim which should appear while booting, continue to boot and Log In.\nThen open up your terminal again after re installing the nvidia drivers via software and updates, then type \"sudo mokutil --enable-validation\" then enter your passwords three times.\nRestart and now enable Secure Boot and continue to boot.\nThis worked for me.\n\nA: I did a fresh install for a PC having a NVIDIA graphic card. In my case, there was the following simple solution: \nChange to console login via ctrl+alt+F1\nafter login, perform the following steps: \nsudo apt update\nsudo apt upgrade\nAfter that, I could login normally (possibly after a reboot). \nIt appears that even though the installation was done with internet access, not all updates were properly installed. The two above step complete the update process. \n\nA: Step 1 : Reboot The Machine\nStep 2 : Select advance option for Ubuntu\nStep 3 : Select recovery mode\nStep 4 : Select Clean      Try to make free space\nStep 5 : Select dpkg       Repair broken packages\nStep 5 : Select  Resume normal boot\n", "Q: How to install snappy packages in Ubuntu 16.04 There are lots of news going on about support for 'Snaps' in 16.04. In the original post, Olli wrote:\n\nIn Ubuntu 16.04 LTS we will make it possible to install snap packages\n  alongside traditional deb packages. These two packaging formats live\n  quite comfortably next to one another and enable us to maintain our\n  existing processes for development and updates to the OS\n\nand he goes on talking about developers and security..etc..\nBut questions remain as to how to find a snappy package and how to install a snappy package? How to even know if an application has a snappy package? Is there a 'snappy repository' that hosts these snappy applications?\n\nA: I was able to first:\nsudo apt install ubuntu-snappy-cli\n\nthen you search the repo by:\nsudo snap find\n\nbut by now the repo is small\nto install nmap for example:\nsudo snap install nmap\n\nto show all the installed snaps:\nsudo snap list\n\nthat is it.\nNow, the dpkg system will show blank entry, as a proof that nmap is not installed via DPKG:\ndpkg -l |grep nmap\n\nthe nmap snap binary is installed under:\n:~$ which nmap\n/snap/bin/nmap\n\nTo update a snap:\nsudo snap refresh nmap\n\nBut I still have to find out why the sudo command wouldn't find the binary of the snap package:\n:~$ sudo nmap\nsudo: nmap: command not found\n\n\nA: My error info:\nnote: /usr/bin/ld: cannot find -lsnappy\n          collect2: error: ld returned 1 exit status\n\nand I install:\nsudo apt install libsnappy-dev\n\nand solved the error.\n", "Q: Retrieving Files from Broken Ubuntu I run Ubuntu 14.04. I recently ran the command sudo apt-get -f install, which, for some reason, ended up removing the boot files.\nSo, I reinstalled Ubuntu on a different partition. However, I would like to get some of my personal files from the first installation back. Is there a way of doing this?\nThanks!\n\nA: If you open Nautilus, you are able to see the partition with your broken installation, you can explore that and copy the files you need on your new installation.\n", "Q: How can I get past the preparing to install screen in Ubuntu 15.10 installation in Live environment? I am using a Dell Inspiron N4110 Laptop. I have a intel Core-i5 2.5 GHz Processor and 4GB RAM. It's running Windows 10. After downloading a Ubuntu iso from the official page I have created a bootable USB drive. I chose to try Ubuntu after booting from the USB and clicked the install ubuntu shortcut. But, I got stuck in the \"Preparing to install\" screen. I have tried installing with the third-party software box and update box unchecked.\nPlease help me. Let me know if you need to know any other information.\n\nA: Old question, but I had the same issue this week. My fix was disable the secure boot in BIOS, then when the GRUB menu opens \"Try Ubuntu, Install Ubuntu, etc.\", press e and edit the install ubuntu option. Delete the \"quiet splash\" phrase and there we go. That worked for me.\n\nA: Just don't include the two option that are download updates and download third party softwares and it will work fine!It worked for me.\n", "Q: Telegram not to be found I have installed telegram many months ago and it was working fine. Today it wouldn't open from the launch or from startup and when I tried looking for it in the Ubuntu software centre it didn't seem to be among the insalled programs. I thought I needed to uninstall it first in order to try and reinstall it.\nI'm using 14.04\n\nA: What I did was: delete the old telegram folder from the download one then downloaded again from the telegram web site and now it works.\n\nA: Maybe You just need to update repositoy and libraries.\nDidyou try: sudo dpkg --configure-a // sudo apt-get install -f\nOr:\nsudo apt-get update && sudo apt-get upgrade && sudo apt-get update-manager -d -c && sudo apt-get check && sudo apt-get -f install && sudo dpkg -i --force-all %% sudo apt-get -f install && sudo apt-get dist-upgrade\nThis things above not bite. But you are in charge. If you think is no good Do not do it. I Did and still alive.\n", "Q: I'm getting this error when try to update to php5 When I try to upgrade php from 5.3 to 5.6, this wild error appears\nExtracting templates from packages: 100%\n(Reading database ... 98172 files and directories currently installed.)\nUnpacking apache2-bin (from .../apache2-bin_2.4.20-1+deb.sury.org~precise+3_amd64.deb) ...\n**dpkg: error processing /var/cache/apt/archives/apache2-bin_2.4.20-1+deb.sury.org~precise+3_amd64.deb (--unpack):\n trying to overwrite '/usr/sbin/apache2', which is also in package apache2-mpm-prefork 2.2.22-1ubuntu1.10\ndpkg-deb (subprocess): subprocess data was killed by signal (Broken pipe)**\ndpkg-deb: error: subprocess <decompress> returned error exit status 2\nErrors were encountered while processing:\n /var/cache/apt/archives/apache2-bin_2.4.20-1+deb.sury.org~precise+3_amd64.deb\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nCould somebody help me, please?\n\nA: I guess you are using PPA for PHP 5.6 for Ubuntu 12.04 (precise).\nYour issue is because that apache2-mpm-prefork is already obsoleted in 2.4.x.  You just need to remove apache2-mpm-prefork, then install apache2, and default is prefork mode.\n", "Q: Problem with PAM authorization in Dovecot I've been using postfix with sasl and dovecot for many years.  Three days ago, authorization for dovecot via PAM stopped working which means no IMAP or POP3. SASL was working as I could tunnel in with openssl s_client -connect myserver.com:993\nHowever this happens:\n* OK [CAPABILITY IMAP4rev1 LITERAL+ SASL-IR LOGIN-REFERRALS ID ENABLE IDLE AUTH=PLAIN] Dovecot ready.\na login validuser validpw\na NO [AUTHENTICATIONFAILED] Authentication failed.\na logout\n* BYE Logging out\na OK Logout completed.\n\nI changed from driver = pam to driver = shadow in the file /etc/dovecot/conf.d/auth-system.conf.ext and it works now.  This bothers me since it took 2 days to fix and I still don't know why PAM broke.\nI'm using Wily Werewolf.\nuname -a: Ubuntu 15.10 Linux host.com 4.2.0-35-generic #40-Ubuntu SMP Tue Mar 15 22:15:45 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nA: I just ran into what may be the same problem on Ubuntu 14.04.4 after applying an update.  A working dovecot configuration started getting failures on all authentication requests.\nThe fix that worked for me was in /etc/dovecot/conf.d/10-master.conf.\nUncomment this line:\n#default_vsz_limit = 256M\n\nand raise the limit.  I set it to:\ndefault_vsz_limit = 512M\n\nThe clue was these slightly mangled messages in syslog (after setting auth_verbose=yes in 10-logging.conf).\nApr 21 20:48:19 mailserver t of memory [3273]\nApr 21 20:48:21 mailserver dovecot: auth-worker(3273): pam(xxxxx,xx.xx.xx.xx): pam_authenticate() failed: Authentication failure (password mismatch?)\n\nThe update (I think) installed a new version of PAM, and something must have gotten bigger.\n", "Q: Transmission Remote (software center) does not initiate downloads in Ubuntu 14.04 I just installed Ubuntu 14.04. I installed the \"Transmission Remote\" via software center.\nBut for some reason when I click magnets, transmission does not initiate any downloads, instead it opens a \"Launch application\" window and I don't know where transmission is located to choose it as the default application to open magnets. \nIn Ubuntu 12.04 transmission was installed by default and always worked fine.\nWhat should I do?\n\nA: An automatic update of Ubuntu 14.04 inserted transmission inside the \"Launch application\" window.\nOne can also set the application by navigating through the file system to this address: /usr/bin/transmission-gtk.\n\n", "Q: What time will Ubuntu 16.04 LTS be available for upgrade in Ireland from Ubuntu 14.04 LTS? I know that it is sometime today, I have updated all my software and it says up-to-date now. If I run update-manager -d in the therminal it does say that 16.04 LTS is available but in the release notes it says that it is a development update for testing. I was looking for the final release\n\nA: It's probably just a matter of time....if you can't wait try this:\nIn Software & Updates choose Download from: \"Main server\" \n\nThen open the terminal and run\nsudo apt update    \nsudo update-manager -d \n\nEDIT: also check this tab (in Software & Update)\n\n", "Q: \"Waiting to install\" for ever - Ubuntu Software - 16.04 When I try to install .deb files with \"Ubuntu Software\", it keeps \"Waiting to install\" for ever.\n\nA: 1 - Donwload the old \"Ubuntu software center\" in the new \"Ubuntu software\".\n2 - unity --reset-icons or Restart your computer (to remove the \"waiting to install\")\n3 - Open the .deb file with the just installed \"Ubuntu software center\"\n4 - Install it\n\nA: Install .deb packages from the terminal:\n$ sudo dpkg -i <path/to/deb.deb>\n$ sudo apt-get install -f\n\nThe reasoning behind apt-get install -f from the man page:\n -f, --fix-broken\n           Fix; attempt to correct a system with broken dependencies in place. This option, when used with install/remove, can\n           omit any packages to permit APT to deduce a likely solution. If packages are specified, these have to completely\n           correct the problem. The option is sometimes necessary when running APT for the first time; APT itself does not allow\n           broken package dependencies to exist on a system. It is possible that a system's dependency structure can be so\n           corrupt as to require manual intervention (which usually means using dpkg --remove to eliminate some of the offending\n           packages). Use of this option together with -m may produce an error in some situations. Configuration Item:\n           APT::Get::Fix-Broken.\n\nCredit: Mohit Rajan's comment\n\nA: Just a suggestion, Not sure if it should help but, if you frequently install packages from .deb files it's advisable to use a reliable package handler like Gdebi\nHowever, if you like to browse for apps and install them from the same place, you should stick to Ubuntu Software Center. To trash Gnome-Software and install the classic and trusted Ubuntu Software Center follow this guide. \n\nA: It seems that we are all affected by https://bugs.launchpad.net/ubuntu/+source/gnome-software/+bug/1573206.\nUnfortunately there is no other solution than using another package manager to install these packages.\n\nA: Workaround was proposed and filed as another bug related to this issue.\n\nAll you need to do is log out, and then login again.\n\nTested and verified this workaround fixes the issue on Ubuntu 16.04.6 LTS, clean installation.\n", "Q: wifi doesn't work on asus X555LD I've just installed ubuntu 16.04 on my laptop, but my wireless card doesn't work. What can i do to fix it?\nlspci -vvnn | grep -A 9 Network \n\n03:00.0 Network controller [0280]: Broadcom Corporation BCM43142 802.11b/g/n [14e4:4365] (rev 01)\nSubsystem: Lite-On Communications Inc BCM43142 802.11b/g/n [11ad:6675]\nControl: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx-\nStatus: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx-\nLatency: 0, Cache Line Size: 64 bytes\nInterrupt: pin A routed to IRQ 255\nRegion 0: Memory at f7800000 (64-bit, non-prefetchable) [size=32K]\nCapabilities: <access denied>\nKernel modules: bcma, wl\n\n\nA: SOLVED\nI've installed this from terminal.\nsudo apt-get install bcmwl-kernel-source\n\nand after reboot i disabled the secure boot.\n", "Q: Chrome flickering on Ubuntu simple (hopefully) question; I have a Dell XPS 13 with a Skylake processor, running Ubuntu 16.04. Some webpages cause flickering (namely Twitch); I have Googled solutions and came across hardware acceleration as an option to fix it, which worked but caused a lot of screen tearing and increased page load times. Any other suggestions on a solution?\n\nA: According to this discussion, launching Chrome with following flags fixes the problem (it did solve it for me too):\n--disable-gpu-driver-bug-workarounds --enable-native-gpu-memory-buffers\n\n\nA: I think the answer is in this post. As the best answer there:\n\n\"I disabled hardware acceleration for my browser from\nSettings > Advance Settings > System > uncheck the hardware\n  acceleration\"\n\n\nA: After some research, I found a solution to this problem. It is working for me now.\nI disabled hardware acceleration for my browser from\nSettings > Advance Settings > System and unchecking hardware acceleration\nI am using google-chrome-stable Version 50.0.2661.94 (64-bit) on Ubuntu 16.04\nIf you encounter scrolling lag and screen tearing, try\nGo to: chrome://flags/#smooth-scrolling and Enable it.\n\nA: I had the same issue as you after installing chrome on Ubuntu 16.04 and enabling GPU rasterization in chrome://flags fixed it for me. Hope this helps\n\nA: Open a terminal as root and enter this command: \"sudo nano /usr/share/applications/chromium-browser.desktop\" and scroll down until you get to this line: \"Exec= chromium-browser\" Then add this two parameters  \"--disable-gpu-driver-bug-workarounds --enable-native-gpu-memory-buffers\" click Ctrl+O to save and Ctrl+X to exit.\nThen enter this command as root again: \"sudo nano /usr/share/X11/xorg.conf.d/20-intel.conf\" and add this lines\nSection \"Device\"\n   Identifier  \"Intel Graphics\"\n   Driver      \"intel\"\n   Option      \"AccelMethod\"  \"sna\"\n   Option      \"TearFree\"    \"true\"\n   Option      \"DRI\"    \"3\"\nEndSection\n\nCtrl+O and Ctrl+X.\nOpen chromium and write to address bar: \"chrome://flags/\" and enter.\nEnable-zero-copy\nEnable Override Software Rendering List\nEnable Display 2D List Canvas\n\nFinally open chrome settings and click on:\n\"Use hardware acceleration when available\"\n\n\nA: I'm on a Dell Inspiron 7559 and have had the same problem on and off for some weeks. I've tried all of the possible solutions I've found (most of which are mentioned above) in various configurations. Some stopped the tearing and flickering for a while or to some extent, but it always seemed to start again.\nSome of the solutions actually broke my os (when I changed the xorg file data).\nIn the end, I switched to using Firefox as my main browser and admitted defeat.\n(Edit): My issue seemed to stem not from Ubuntu but rather from the Nvidia drivers installed with Bumblebee.\n", "Q: Ubuntu 16.04 unity desktop environment doesn't load after fresh install After doing a fresh install of Ubuntu 16.04, I log in, but the unity desktop environment does not load. All I get is the desktop background, and occasionally an information window about an error with compiz shows up.\nI had this before also with the final Beta, and could not find a solution.\nWhen I try to restart unity from the Ctrl + Alt + F1 console, with:\nDISPLAY=:0 unity\n\nI get:\ncompiz (core) - Info: Loading plugin: core\n... many more instructions here\ncompiz (core) - Info: Unity is not supported by your hardware. Enabling software rendering instead (slow). \n... many more instructions again\ncompiz (core) - Info: Starting plugin: switcher\nIllegal instruction (core dumped)\n\nI have the Nvidia gtx980 graphics card, and according to Ubuntu, the (open-source) Nvidia driver has been installed correctly, so, imo, Unity should be fully supported, but for some reason when Ubuntu tries to start Unity, it fails with the only information being Illegal instruction.\nPlease advise on any way I can fix this or debug it\n\nA: Usually the answer to this is by resetting dconf entries for unity:\ndconf reset -f /org/compiz/\nsetsid compiz\n\nThis seems to be due to bug #1569357 on launchpad. Usually they also give a few remediations for the bug in the launchpad entry, and it only seems to happen with sddm (the simple desktop display manager) - it does not happen with lightdm.\nUsing dconf reset -f /org/compiz/ did not work with me (sudo or no sudo). setsid compiz also didn't.\nI also found that if you have logged in and have no launched and no panel, a quick way to make them start if you have a command line is:\nnohup /usr/bin/unity > /dev/null 2>&1 &\nnohup /usr/lib/x86_64-linux-gnu/unity/unity-panel-service > /dev/null 2>&1 &\n\nThis is just for the session you are in though. It won't make the launched and panel start the next time you log in.\n\nA: Use these command to fix the issue :\nsudo dpkg --configure -a  \nsudo apt-get update  \nsudo apt-get upgrade -y  \n\nAnd reboot the machine..You will get desktop back\n\nA: Unfortunately I do not have the reputation to comment, but Patola's solution worked for me with one slight change:\ndconf reset -f /org/compiz/\nsetsid compiz\n\nshould be\ndconf reset -f /org/compiz/\nsetsid compiz --replace\n\n\nA: I solved the problem following these steps:\n\n\n*\n\n*Activated the proprietary Nvidia graphics driver instead of the nouveau open-source one.\n\n*Unfortunately this made my Ubuntu fail to boot, so I had to follow these steps to get it to work: https://askubuntu.com/a/391608/281857\n\n*At this point Ubuntu was booting but there was still no launcher, top bar, etc. However I could right-click on the desktop to open a Terminal, and ran Fix 5 detailed by this answer: https://askubuntu.com/a/481620/281857\n\nA: I had the same problem, and this worked for me:\nsudo apt-get install --reinstall compiz\n\n\nA: I faced similar issue try getting hold of unity console once system boots using: Ctrl + Alt + F1.\n\n\n*\n\n*Log in with admin credentials.\n\n*List display drivers using : \nubuntu-drivers devices\n\n\n*Install nvidia driver:\nsudo apt-get install sudo apt-get install nvidia-361\n\nor\n sudo apt-get install nvidia-364\n\n\n*Reboot system:\nsudo reboot now\n\n\n*To resume graphical display:\nCtrl + Alt + F7\nWorked for me. All the best\n\nA: setsid compiz --replace\n\nwas the fix and worked in my case - unity fixed! Thanks @Jonathan Richards!\n", "Q: Which versions of ubuntu are compatible with INTEL Core i5 6th generation ASUS A556U laptop I had ubuntu 14.04 on my lap but it did not support my trackpad. I am very new to OS and compatibility issues. Please help me out\n\nA: This was a kernel bug which was fixed in Ubuntu 15.10, so 15.10 and later should be OK\n", "Q: Ubuntu 16.04.0 final (Unity desktop / Kubuntu / GNOME) can not boot from Live USB on a Z170 Skylake (6th gen) I wanted to try Ubuntu 16.04 final on a brand new system:\nA top-of-the-range AsRock Z170 ITX motherboard with i7 6700K CPU and GTX 970 connected via DVI-D. \nWhen I choose to try Linux (not to install it), both in Uefi and in non-Uefi mode, the Ubuntu 64 bit version with Unity desktop shows the background correctly, but then a blinking message box appears saying error.\nThe error message is not very readable because it is blinking, but it seems to say \"compiz crashed with SIGILL\"\nWhen I try Kubuntu 16.04.0 final 64 bit, the background appears for a fraction of as second and then the screen becomes black and nothing more happens.\nWhen I try GNOME, I read \"Nouveau failed to load\".\nThis motherboard only has USB3 ports and no USB2 ports. \nThe USB key is FAT32 formatted, and is inserted in a USB 3.0 port. The USB key was created with Rufus in Windows.\nThe motherboard is setup to allocate 1GB of RAM to the integrated graphics, and is set to start up with the NVIDIA GPU rather than with the Integrated GPU.\n[ - UPDATE - ] - \nThanks for the answers. Xubuntu 16.04.0 worked out of the box. Kubuntu 16.04.0 Live CD worked only with nomodeset, but I could not boot from the installed OS in any way (nor enter recoverymode).\nSo, in the end, the solution for me, was to set \"Primary Display\" to \"onboard\" in the UEFI \"Chipset settings\". As (K)Ubuntu 16.04.0 has got a kernel greater than 4.3, Intel integrated graphics worked with no effort. As my plan for the GTX 970 is KVM GPU-passthrough, I should not use the external GPU at boot. \n\nA: According to this :\nhttps://bugs.launchpad.net/ubuntu/+source/llvm-toolchain-3.8/+bug/1564156\nThis bug will be fixed in 16.04.1\nAll credit goes to Joakim Koed (joakimkoed) who came with a good option.\nWhat you need to do is:\nboot with nomodeset (press E after grub is booted and add nomodeset after quiet splash and press F10 (if I remember correctly)) now change to a terminal with CTRL + ALT + F2 or something.\nwget http://koti.kapsi.fi/~tjaalton/skl/build2/libllvm3.8_3.8-2ubuntu1.1_amd64.deb\nsudo dpkg -i libllvm3.8_3.8-2ubuntu1.1_amd64.deb\nsudo reboot\n\nHope this helps.\n\nA: I have exactly the same problem with Ubuntu 16.04, but with an ASUS Maximus VIII Gene motherboard. I used the same USB key with Xubuntu 16.04 and had no problem trying Xubuntu 16.04. The display functioned perfectly. This would seem to indicate that the problem lies with Unity.\nThis appears to be a recognized bug that will fixed in the 16.04.1 ISO. https://bugs.launchpad.net/ubuntu/+source/llvm-toolchain-3.8/+bug/1564156\n", "Q: Problem with videos on Ubuntu 15.10 I have noticed this particular problem on YouTube and Facebook videos in Ubuntu 15.10(with Google Chrome). The videos play fine on full screen mode but when I try to exit the full screen mode, Ubuntu just hangs(sometimes the audio keeps on playing). \nIs any driver update needed? Are there any problems with Flash plug-in?\n\nA: Flash is a very CPU intensive application and once the CPU heats, flash performance drops considerably. In your case I believe the problem goes a little further and stops the display of the content.\nAlso see: http://ubuntuforums.org/showthread.php?t=1193567\n", "Q: Will a sideloaded snap get upgraded to a newer version in the store? I grabbed youtube-dl from the snappy-desktop-examples. I then built a snap with snapcraft and installed it:\nIf/when youtube-dl is uploaded to the store, what happens, do I need to explicitly upgrade my sideloaded snap to the store version, or will it automatically upgrade?\n\nA: First, a disclaimer: I've only tested this in the current Snappy Ubuntu Core edge-- not on the desktop.\nI believe the version of the snap in this situation is actually irrelevant-- the important part here is the developer/publisher of the snap as far as the store (and snappy) is concerned. The snap coming from the store is associated with a specific publisher (e.g. your store account), whereas the one being sideloaded isn't (or maybe you could say it's associated with the \"sideloaded\" publisher, heh). This is reflected in the Developer column of snap list.\nIf you sideload snap \"foo,\" and a snap by the same name is also in the store, the one you sideloaded is considered a different package and I believe it will not update automatically-- you'll have to install the one published in the store (note that you'll first have to uninstall the sideloaded one since they have the same name). However, if you install snap \"foo\" from the store and then sideload another snap \"foo\" over the top of it, it'll treat it as a new version and you'll notice snap list says it's now sideloaded. I expect this means it'll no longer update from the store.\nNote that if you sideload the same version as the snap you installed from the store, it seems that the store version is overwritten.\n", "Q: What is the purpose of iocharset=utf8? I see iocharset=utf8 recommended nearly everywhere when mounting Windows SMB shares into Linux.\nI have mounted vhdx files to a Ubuntu VM that I want to be assured that whatever files I write to the disk from the Ubuntu VM will be readable from Windows in the future. Therefore I have two questions:\n\n\n*\n\n*Is this what iocharset=utf8 does? \n\n*Should I apply this option to the fstab for the vhdx in the Ubuntu VM too, and not just SMB shares?\n\n\nA: The default character encoding for the mounts in Linux is iso8859-1. This encoding is legacy and only supports 256 characters. All modern systems should be using utf-8 but I think default is left at ISO8859-1 for compatibility reasons. So it's always good idea to add iocharset=utf8 when mounting Windows share. Also, lot of websites enforces filemode/dirmod 777 when mounting which I think are unnecessary. The mount command that I use is,\nsudo mount -t cifs //SERVER/FOLDER /mnt/FOLDER -o username=USER,domain=DOMAIN,iocharset=utf8\n\n\nA: iocharset=utf8 sets what encoding to use when mounting drives or network shares.\nAccording to Wikipedia:\nUTF-8 is a character encoding capable of encoding all possible characters, or code points, defined by Unicode.\n\nIt's pretty much a safety feature just to make sure Ubuntu can present all text in a readable format (shows it correctly), and save everything in a format readable by other OSes.\nYou certainly can add this option to anything you mount, but unless you encounter problems with text or file paths, there's no need to add it.\n", "Q: Ubuntu Touch change scope \"today\" Does anyone knows how to change the content of scope today?\nThe news displayed there are totally unusable for me. I'm from germany and really not interested in news from El Pais or Cinco Dias. \nIs there a way to add different content? Maybe somewhere in the configs?\nWould be fine to make my M10 tablet more usable...\nCheers, Frank\n\nA: Assuming the today scope in M10 does not differ from the today scope on other devices, there is few customization possible. Clicking on the settings menu in the upper right (in between the star and the magnifying glass) you can choose some content. As for German news I have though only DIE WELT available (using the aquaris E4.5).\n\nA: You can deactivate all the scopes you don't want by unticking their boxes in the scope configuration. You have to trigger the clog icon to reach the settings menu for the content of a scope page or indeed by swiping up from the bottom to choose amongst a general scope page. Not sure I remember correctly without it in front of me, but you should get there quite easily.\nThen, if you browse for scopes in the store and install them, you'll have the possibility to activate them within the Today's scope (or by adding a new scope page). \nI removed all scopes I'm not interested in from Today's scope and added those I wanted (Belgian newspapers). Just do some digging around within the scopes and you should find the customization options.\nYou can also choose how many news you want to see per scope or how many photos per photo app, etc...\n\nA: You get access to more configuration by pulling up from the bottom middle in the scopes. Easy to miss, unsure if it'll solve your issue though.\n", "Q: Cannot participate in Skype group calls So whenever someone calls the whole group(about 9 people in it) It doesn't get me into the call.\nNeither can I join the call when its started.\nIt was working fine until about a month ago...\nDoes anyone know how to fix it?\nI tried reinstalling Skype, renaming the .Skype directory, installing from .deb and from terminal, stil doesn't work....\n\nA: Microsoft hasn't updated Skype for Linux for a long time and it no longer works. I'm not sure if a fix will be released.\n\nA: We had this problem at work recently, and we found a few workarounds :\nFix 1\nClose Skype\nIn a terminal, type :\nrm -rf ~/.Skype\n\n(this removes your whole Skype config, so be sure you know your login and password)\nrelaunch Skype\nFix 2\nIn a Skype chat window, type :\n/dumpmsnp\n\nIf the output is :\nSystem: MSNP: Connection Data:\n\n * Status: LoggedOut\n\nThen type :\n/msnp24\n\nAnd restart Skype.\nThe dumpmsnp command output should look like this :\nSNP: Connection Data (MSNP24):\n* Status: LoggedIn\n* Server Current: XXXXXXXXXXX.gateway.messenger.live.com\n* Server Saved: s.gateway.messenger.live.com\n* Login: (UIC)\n* Skypename: xxxxxxxxxxxxxxx\n* EPID:\n* ClientVersion:\n* OSVersion:\n* B:\n* Time: TZ:\n* Last Connect:\n* Push: None (Unregistered)\n\nFix 3\nClose Skype\nIn a terminal, type :\ngrep Home ~/.Skype/*/config.xml\n\nThe output should be similar to :\n    <HomeServer>s.gateway.messenger.live.com</HomeServer>\n\nIf this line is present but with another server, try replacing it with this server and relaunch Skype\nIf this line is missing, edit the config.xml file with your favorite text editor, and look for a  section.\nAdd it, or replace it if it's already here, with this :\n    <MSNPCore>\n      <HomeServer>s.gateway.messenger.live.com</HomeServer>\n      <NewThreadAllowed>1</NewThreadAllowed>\n      <P2PMigrationAllowed>0</P2PMigrationAllowed>\n      <ProtocolToUse>24</ProtocolToUse>\n      <RecentConnectionInfo></RecentConnectionInfo>\n      <RecentConversationsSyncState></RecentConversationsSyncState>\n    </MSNPCore>\n\n", "Q: errors upgrading from 14.04 to 16.04 about Unknown Multi-Arch type for compiz, libkf5akonadisearch-bin packages I'm trying to upgrade my 14.04 machine to 16.04 using do-release-upgrade. After downloading the package lists for wily, I see the following errors:\nUnknown Multi-Arch type 'no' for package 'compiz-core'\nUnknown Multi-Arch type 'no' for package 'compiz-gnome'\nIgnoring Provides line with DepCompareOp for package python-cffi-backend-api-max\nIgnoring Provides line with DepCompareOp for package python-cffi-backend-api-min\nIgnoring Provides line with DepCompareOp for package python3-cffi-backend-api-max\nIgnoring Provides line with DepCompareOp for package python3-cffi-backend-api-min\nUnknown Multi-Arch type 'no' for package 'libkf5akonadisearch-bin'\nIgnoring Provides line with DepCompareOp for package php-psr-http-message-implementation\nIgnoring Provides line with DepCompareOp for package php-psr-log-implementation\nIgnoring Provides line with DepCompareOp for package php-math-biginteger\nUnknown Multi-Arch type 'no' for package 'compiz-core'\nUnknown Multi-Arch type 'no' for package 'compiz-gnome'\nIgnoring Provides line with DepCompareOp for package python-cffi-backend-api-max\nIgnoring Provides line with DepCompareOp for package python-cffi-backend-api-min\nIgnoring Provides line with DepCompareOp for package python3-cffi-backend-api-max\nIgnoring Provides line with DepCompareOp for package python3-cffi-backend-api-min\nUnknown Multi-Arch type 'no' for package 'libkf5akonadisearch-bin'\nUnknown Multi-Arch type 'no' for package 'compiz-core'\nUnknown Multi-Arch type 'no' for package 'compiz-gnome'\nUnknown Multi-Arch type 'no' for package 'compiz-core'\nUnknown Multi-Arch type 'no' for package 'compiz-gnome'\nYou may want to run apt-get update to correct these problems\n\nIt then proceeds to abort the installation. The suggested run of apt-get update doesn't seem to do anything. Googling for the above error messages yielded others having similar problems when upgrading to other, previous releases, although I've not come across any apparent fixes. It's suggested that an apt upgrade could fix the problem, but I don't see a way to easily do that (it's up to date with the latest trusty package).\nWhat should I do in order to upgrade directly to 16.04?\n\nA: What seems to have worked for me was \napt-get -f install libc6\napt-get install --only-upgrade apt\n\n\nA: You have to do this: \nsudo apt-get install -f\n\n\nA: Here's what worked for me : \nsudo rm -r /var/lib/apt/lists/*\nsudo apt-get clean\nsudo apt-get update\n\nI had segmentation faults errors during the install, so I cleared the archives again:  \nsudo apt-get clean\n\nAnd everything went fine.\nHope it'll help !\n\nA: This is a bug in apt, and yes, the fix is to upgrade apt.\nEdit /etc/apt/sources.list and uncomment these lines:\ndeb http://au.archive.ubuntu.com/ubuntu/ wily main restricted\ndeb http://au.archive.ubuntu.com/ubuntu/ wily-updates main restricted\n\nNow run apt-get update and you'll see the same errors about 'Unknown Multi-Arch type'. \nNow upgrade apt:\napt-get install --only-upgrade apt\n\nNow run the release installer:\ndo-release-upgrade\n\n:)\n\nA: I also get the \"newest version\" message, but according to https://bugs.launchpad.net/ubuntu/+source/compiz/+bug/1404783/comments/12\nI added sources for vivid and vivid-updates to sources.list and installed the apt/vivid version.\nsudo apt-get -t vivid install apt/vivid\n\nThen I deleted vivid source from sources.list and apt-get update finished without any warning.\n\nA: Almost had an answer.\nI upgraded my Ubuntu 14.04 to 16.04. Update and upgrade commands malfunctioned. I could not find a solution anywhere. The only thing that worked for me was:\nsudo rm -r /var/lib/apt/lists/*\nsudo do-release-upgrade\n\nThat seemed to upgrade me to Ubuntu 18.04 Bionic, though with some errors.\n", "Q: What is the UH flag in routing table I'm using an Ubuntu machine as a server and it has two network interfaces. One is the 10.10.10.0/ 24 range and the other is 192.168.0.0 /24 range. I was trying to bridge these network interfaces as the second one has internet. I used the Network Connections options by selecting the Share Internet option and it did not work. I undid the changes and instead used a script that enable IP forwarding and added a masquerade option in the IP tables. But now everytime the 10.10.10.0 /24 is started the 192.168.0.0 /24 interface is flagged as UH and is unusable until I run a script to remove all default gateways and readd the 192 one. What could be the cause of this and how do I get rid of it? \n\nA: TL;DR UH flags in routing tables means:\n\n\n*\n\n*U: route is up\n\n*H: this is a route to a single host (and not a network)\n\n\nThe different flags are:\n\n 1      RTF_PROTO1       Protocol specific routing flag #1\n 2      RTF_PROTO2       Protocol specific routing flag #2\n 3      RTF_PROTO3       Protocol specific routing flag #3\n B      RTF_BLACKHOLE    Just discard pkts (during updates)\n b      RTF_BROADCAST    The route represents a broadcast address\n D      RTF_DYNAMIC      Created dynamically (by redirect)\n G      RTF_GATEWAY      Destination requires forwarding by intermediary\n H      RTF_HOST     Host entry (net otherwise)\n L      RTF_LLINFO       Valid protocol to link address translation\n M      RTF_MODIFIED     Modified dynamically (by redirect)\n R      RTF_REJECT       Host or net unreachable\n S      RTF_STATIC       Manually added\n U      RTF_UP       Route usable\n X      RTF_XRESOLVE     External daemon translates proto to link address\n\n\nYou will find a discussion on their meaning here for example.\n", "Q: Can't view Wifi networks after upgrading to Ubuntu 16.04 I can't view any wifi networks after upgrading to Ubuntu 16.04 from 14.04. This issue also occurred when trying to upgrade to Ubuntu 15.10. This is what my network window looks like:\n\nI have Broadcom enabled in the Software & Updates window:\n\nAlso there is no option for Wifi in the dropdown menu in the top right. The screenshots are from Ubuntu GNOME, but it also doesn't work for standard Ubuntu. How can I enable wifi networks?\nOutput of lspci -knn | grep Net -A2:\n07:00.0 Network controller [0280]: Broadcom Corporation BCM43142 802.11b/g/n [14e4:4365] (rev 01)\n    Subsystem: XAVi Technologies Corp. BCM43142 802.11b/g/n [1b9a:3002]\n    Kernel modules: bcma, wl\n\nOutput of sudo apt-get install bcmwl-kernel-source:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nbcmwl-kernel-source is already the newest version (6.30.223.248+bdcom-0ubuntu8).\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n\nOutput of sudo apt-get install --reinstall bcmwl-kernel-source:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\n0 upgraded, 0 newly installed, 1 reinstalled, 0 to remove and 0 not upgraded.\nNeed to get 0 B/1,515 kB of archives.\nAfter this operation, 0 B of additional disk space will be used.\n(Reading database ... 153417 files and directories currently installed.)\nPreparing to unpack .../bcmwl-kernel-source_6.30.223.248+bdcom-0ubuntu8_amd64.deb ...\nRemoving all DKMS Modules\nDone.\nUnpacking bcmwl-kernel-source (6.30.223.248+bdcom-0ubuntu8) over (6.30.223.248+bdcom-0ubuntu8) ...\nSetting up bcmwl-kernel-source (6.30.223.248+bdcom-0ubuntu8) ...\nLoading new bcmwl-6.30.223.248+bdcom DKMS files...\nBuilding only for 4.4.0-21-generic\nBuilding for architecture x86_64\nBuilding initial module for 4.4.0-21-generic\nDone.\n\nwl:\nRunning module version sanity check.\n - Original module\n   - No original module exists within this kernel\n - Installation\n   - Installing to /lib/modules/4.4.0-21-generic/updates/dkms/\n\ndepmod....\n\nDKMS: install completed.\nmodprobe: ERROR: could not insert 'wl': Required key not available\nupdate-initramfs: deferring update (trigger activated)\nProcessing triggers for initramfs-tools (0.122ubuntu8) ...\nupdate-initramfs: Generating /boot/initrd.img-4.4.0-21-generic\n\nOutput of sudo modprobe wl:\nmodprobe: ERROR: could not insert 'wl': Required key not available\n\n\nA: For me, this command worked:\nsudo /etc/init.d/network-manager restart\n\nI used to need this command for my Chromebook running 15.04 whenever it woke from suspend. It came from some thread.\nEDIT:\nSo this is only a temporary solution. To make it permanent, I put it in a script somewhere (for me ~/bin/fixwifi) then symlinked that script to the /etc/rc2.d with the name S06fixwifi.\nIn other words\nMake a script somewhere with this text in it:\n#!/usr/bin/env bash\n/etc/init.d/network-manager restart\n\nMake it executable with\nchmod a+x <scriptname>\n\nwhere scriptname is the name of the script you just made.\nThen symlink it into the startups\nsudo ln -s  </path/to/scriptname> /etc/rc2.d/S06fixwifi\n\n\nA: I think its network manager issue. I had same problem with Intel Wireless-AC 7260.\nI executed iwconfig - and the card was there but it was down (iwlist scan failed) - so I run these commands to bring it up manually:\nsudo ifconfig wlp4s0 up\nservice network-manager restart\n\nand it appeared in gnome just like a charm.\n\nA: I had the same (with an Apple PowerMac 13\" 2015) when I updated to official 16.04 Ubuntu today - with Unity. Before I used the latest 16.04 preview.\nSo there is IMHO two problems. One is that with the latest 16.04 kernel (4.4.0-21-generic) the firmware (as far as I understand it) makes the Broadcom 43602 WIFI chip not to work when booting initially. After suspend resume or\n sudo rmmod brcmfmac\n sudo modprobe brcmfmac\n\nfixed the issue.\nFor whom it will interest:\nStill then suspend and resume didn't work any more as the box resumed automatically after 2-3 seconds. This seems to be a common problem.\nDescription see https://bugzilla.kernel.org/show_bug.cgi?id=101681 .\nIn my place an\n sudo cat > /etc/rc.local <<EOF\n echo LID0 > /proc/acpi/wakeup\n echo XHC1 > /proc/acpi/wakeup\n EOF\n\ndid the trick.\n\nA: for me it was enough to re-install the driver, first restarting the service to get it working\nservice network-manager restart\nsudo apt-get purge bcmwl-kernel-source\nsudo apt-get update\nsudo apt-get install bcmwl-kernel-source\n\nI was upgrading hp dv4 from 14.04 to 16.04\n\nA: GUI-only: this worked for me, though I don't know how. \n\n\n*\n\n*I am using a Lenovo B570, an older laptop with a minimal Phoenix BIOS and, I believe, a Broadcom 4313. Proprietary wifi works out-of-the-box using my LiveUSB of 16.04. I only lack wifi after installation. So, I figured this is a failure of my hardware configuration.\n\n*In order to get the proprietary driver installed and activated (albeit broken as described above) via the Additional Drivers tab, I needed to manually deactivate my wifi hardware via my laptop switch. Only then was the Additional Drivers tool able to apply the change from the default open source kernel wifi driver. Upon reboot, I had an internet connection at the proper speed, but this displayed in Ubuntu networking as an ethernet connection, and thus could not show wifi hotspot. It merely accepted manual input of a wifi profile.\n\n*I went into my BIOS. The only thing I can change at all is the wifi switch and the boot order of devices and operating systems. I switch the wifi on and off. Saved. I switched ubuntu from the #1 slot to the #2 slot and my networking card to the #1 slot as if I were setting up a network boot. I rebooted. After a few seconds, the network boot fails, then proceeded to the Ubuntu loading screen as normal. Immediately upon boot, proprietary wifi worked perfectly with 16.04. Could it be a power issue, a networking hardware or BIOS bug? A coincidental repair of unknown origin? \n\nA: \nmodprobe: ERROR: could not insert 'wl': Required key not available\n\n\nYou need to turn off the secure boot.\nSecure Boot is a security standard developed by members of the PC industry to help make sure that your PC boots using only software that is trusted by the PC manufacturer\n\n\n*\n\n*Turn off the secure boot\n\n*Remove bcmwl-kernel-source\nsudo apt-get purge bcmwl-kernel-source\n\n\n*Re-install bcmwl-kernel-source and the kernel header:\nsudo apt-get install linux-generic bcmwl-kernel-source\n\n\n*Reboot\n\nA: Although, https://wireless.wiki.kernel.org/en/users/drivers/b43 says that [14e4:4365] is not a supported chipset but you can try\n$ sudo apt-get install firmware-b43-installer\n\nhttp://linuxwireless.sipsolutions.net/en/users/Drivers/b43/ it gives even more details. Reboot will be required after the installation.\nThere also might be some backport tweaks like intel wireless drivers but I'm not sure about.\n\nA: I had the same error with an Intel wireless card and I had to turn the secure boot off and follow the instructions given in that answer, that is:\nsudo apt purge 'oem-wifi-intel.*'\nsudo apt install linux-generic-hwe-16.04\nreboot\n\n", "Q: Unable to update to 16.04 from 15.10 I'm using Ubuntu 15.10. I want to update to 16.04. But the Software updater does not show the required update. is there a reason for this?\n\nA: According to The Ubuntu Wiki,\n\n\n*\n\n*Open the Software & Updates Setting in System Settings. \n\n*Select the Updates tab. \n\n*Set the Notify me of a new Ubuntu version dropdown menu to For any new version if you are using 15.10, or set it to long-term support versions if you are using 14.04 LTS. \n\n*Press Alt+F2 and type in update-manager into the command box. Software Updater should open up and tell you: New distribution release '16.04 LTS' is available. \n\n*Click Upgrade and follow the on-screen instructions.\n\n\nUPDATE: The release notes says that upgrade from 14.04 will only be available on the 16.04.1 release in about 3 months.\n\nA: I think its just matter of wait. If you really want then can do it by using developer release. This is not recommended as it is prone to bugs. You have to run command \nsudo do-release-upgrade -d\n\n", "Q: Mitigating CVE-2016-3115 By Disabling X11Forwarding I want to mitigate CVE-2016-3115. The report from OpenSSH states that the vulnerability exists when X11Forwarding is enabled. It shows as enabled in my  /etc/ssh/sshd_config, but I don't know why. It's a server that I only access via SSH (PuTTY) and SFTP. What are the possible issues that could come from disabling X11Forwarding?\n\nA: If you are accessing server using ssh and PuTTY and using only command-line utilities, you are good to disable X11 forwarding.\nX11 forwarding is needed only if you want to run X11 applications (graphical, window) on the remote server and have them displayed on your local desktop.\nAlso you didn't specify which Ubuntu version you are using, but currently I don't see in changelog, that this patch was backported even to 15.10.\n", "Q: How do you install Google Chrome on Ubuntu 16.04? The software installer just hangs with a ? icon and from command line it says:\ndpkg: error processing package google-chrome-stable (--install):\n dependency problems - leaving unconfigured \nProcessing triggers for man-db (2.7.5-1) ... \nProcessing triggers for gnome-menus (3.13.3-6ubuntu3) ... \nProcessing triggers for desktop-file-utils (0.22-1ubuntu5) ... \nProcessing triggers for bamfdaemon (0.5.3~bzr0+16.04.20160415-0ubuntu1) ... \nRebuilding /usr/share/applications/bamf-2.index... \nProcessing triggers for mime-support (3.59ubuntu1) ... \nErrors were encountered while processing:  google-chrome-stable\n\n\nA: This worked for me\n (all other methods suggested got me very lost):\nDownload the package (64 bit):\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n\nInstall the package, forcing install of dependencies:\nsudo dpkg -i --force-depends google-chrome-stable_current_amd64.deb\n\nIn case any dependencies didn't install (you would have a warning or failure message for this), you can force them via:\nsudo apt-get install -f\n\nNote: Refer to the link above for 32 bit systems.\n\nA: Simple steps - \n1. Search for and install 'Gdebi Package Installer' from ubuntu app store\n2. Right click the downloaded Google Chrome .deb file and select 'Open with' and then click 'Gdebi Package Installer'\n3. Done! :-)\nGdebi will automatically fetch the missing dependencies for you\n\nA: Has been answered in the past, here's a reference.\nRefer to:\nThis\n\nA: This is the answer that worked for me:\nSimple steps: \n\n\n*\n\n*Search for and install Gdebi Package Installer from the ubuntu Software Center.    \n\n*Download google chrome https://www.google.com/chrome/browser/desktop/\n\n*Right click the downloaded Google Chrome .deb file and select 'Open with' and then click 'Gdebi Package Installer' \n\n*Done! :-)\n\n\nGdebi will automatically fetch the missing dependencies for you.\nSo I just want to tell exactly what I did:\n$ sudo apt-get install gdebi\n\n$ gdebi google-chrome-stable_current_amd64.deb\n\nP.S.: I was in the Downloads folder when I did this.\n\nA: *\n\n*Download latest version from https://www.google.com/chrome/\n\n*Move to the folder that contains the file, via GUI or terminal (like cd ~/Downloads)\n\n\nInstall the package by clicking on it, or via the terminal:\nsudo dpkg -i google-chrome-stable_current_amd64.deb\n\nIf you have issues, you may have to run:\nsudo apt-get -f install\nsudo dpkg -i google-chrome-stable_current_amd64.deb\n\n\nA: After downloading the  .deb package I ran these commands first:\nsudo apt-get update  \nsudo apt-get install libgconf2-4 libnss3-1d libxss1\n\nand then change the terminal working directory to the downloaded file location\n(like cd ~/Downloads) and then install Chrome using this command on terminal:\nsudo dpkg -i google-chrome-stable_current_amd64.deb\n\nIt worked for me.\n", "Q: Can I remove a physical drive from a ZFS virtual device? Among the new things in 16.04 is the remarkable ZFS file system. The wiki presents some interesting use cases (end of page) but another wiki page mentions that \"A device can be added to a [ZFS virtual device], but cannot be removed from it.\"\nSo I can easily add drives and they will automagically enlarge the ZFS volume, but what happens when I run out of physical space/connectors in the machine? What can I do to remove/replace physical drives?\n\nA: You can replace a physical drive from a zpool. Take a look at this tutorial made by Oracle.\nReplacing a Device in a ZFS Storage Pool\nHowerver according to the zpool man page (snv_92):\n zpool remove pool device ...\n\n     Removes the specified device from the pool. This command\n     currently  only  supports  removing hot spares and cache\n     devices. Devices that are part of a mirrored  configura-\n     tion  can  be  removed using the \"zpool detach\" command.\n     Non-redundant and raidz devices cannot be removed from a\n     pool.\n\nSo if you accidentally add a device to a zpool you will need to back everything up and recreate the pool.\n\nA: Answering to your last sentence and not the title question, since this seems to be the reason for it:\nFor zfs, the drives need to have the same size in an array for a meaningful combination. The size of the zpool is limited by the smallest disk in the array for raidzX modes. \nIf you want to enlarge a pool, you need to make sure that you replace your disks by larger disks one-by-one and let the pool resilver between each step. After you added the last disk, the pool automagically enlarges itself to the new maximum capacity. Sometimes, a export and reimport of the pool with zpool export tank followed by zpool import tank is needed to trigger the process.\nI have done this several times now over the years, and it was always a sufficient solution. If you plan your pool from the start and max out your slots, the growth option available is similar to other filesystems, since you always need to replace disks. \n", "Q: Will upgrade change my desktop settings to defaults? I am going to upgrade to 16.04. I would like to know that will it change my settings to default settings of all apps or not.\n\nA: Most likely not, however it all depends on how you go about upgrading.\nYou can either use the updater (Which will most likely save every setting you have made then add all the new features).\nOr completely re-install Ubuntu from a LiveCD and therefor wiping everything.\n", "Q: UBUNTU 16.04 ERROR INSTALLING GRUB My computer has Windows 10 installed, and when I try to install Ubuntu 16.04, it does not detect Windows 10, nor does it detect Windows 10 in my partitions list.\nOn the final step of the installation, it shows me this error.\ngrub-amd64-efi\n\nLater, I run the LiveCD in \"Try Ubuntu\", and I paste this command in the terminal sudo fixparts /dev/sda, and sudo fdisk -l it does not work.\nHelp me please.\n\nA: The solution for dual boot Windows 10 and Ubuntu 16.04 is a bit tricky because it is somewhat hardware dependent. \nSee this link for detailed answer and general explanation.\nSee this link for the question in case above link is invalid. \nFor my particular case, I have a Samsung Series 9 (2011) with Windows 10 installed. No other OS,but my Windows 10 has 4 partitions (pictured below). This PC requires F2 for setup, and no F10/F11 options for boot menu. So the only configuration change in setup is \"UEFI Boot Support\" which limits the possible solutions to my problem. \nThe solution for me was to keep my Windows 10 install, and shrink partition to make room for Ubuntu 16.04 install.\nFirst press F2 for setup and change boot priority to make Primary SATA HDD and Windows Boot Manager last. Now it will allow me to boot into USB Live. Boot order in image is not correct so do what works for you, so it's okay if my ordering does not match your own.\n\nUse a 16.04 USB Live, and start the installation process.\nSelect \"Something Else\" when asked if you want to format whole disk in the \"Installation Type\" menu.\nNow you are in the manual partition page for the mounted drives. I only have one drive which is called \"sda\"\n\nAbove Image Shows that I kept my Windows 10 install and made free space for the Ubuntu 16.04 which requires Ext4 file system. \nAfter install restart, and press F2 for setup and change boot priority to have primary SATA HDD and Windows Boot Manager at the top; respectively. This was not the end, but you should try it to see if it may be for your case. I had to go a few steps further. \nWent back into USB Live installation and used a tool called Boot-Repair \nRedo Ubuntu 16.04 install, but change Device for boot loader installion from (pictured above):\n\n/dev/sda\n\nto \n\n/dev/sda1\n\nRestart and run Boot-Repair again with recommended option. \nFinal change setup boot priority to have SATA HDD and Windows Boot Manager at the top. \nA combination of installing Grub and boot loader a few times allowed the installation to work, and allow Grub to be selected first. \nNote in the image below that sda1 is windows recovery, and sda2 is Windows Boot Manager.\n\nLAST STEP: Match boot priority in setup as pictured below. \n\n\n*\n\n*SATA HDD\n\n*Windows Boot Manager\n\n*ubuntu (make it last)\n\n\n\nBelow is a picture of disk utility software output (Disk Management) to show general partition scheme with Windows 10, Ubuntu 14.04, Ubuntu 16.04, and Swap Area. All 3 OS are accessible.\n\nBelow is my current GRUB, and yes it is a bit messy. I did advanced option on Boot-Repair to get Windows Boot Manager to be selected automatically. Current GRUB setup is a messy layout due to multiple install attempts and use of Boot-Repair utility\n\n\nA: I've had this issue since the beta version of ubuntu 16. I find that after the error shows up, if you reboot to the live cd and run boot-repair, the problem is fixed and ubuntu boots. To get windows booting again, all you need to do is run sudo update-grub\n\nA: I have Windows 7, and after installing Ubuntu 16.04, I never saw the Windows option in GRUB.\nRunning this command worked for me:\nsudo update-grub\n\n", "Q: Mousewheel causes drastic volume change I may have discovered some kind of bug in the latest update for 14.04LTS. When I adjust the volume with the mouse wheel, the volume continues to rise or fall even if I only move it one click.  \nMy volume control is impossible to set.  For some reason, when I adjust the volume just one notch of the mouse wheel turn, the volume slowly increases or decreases until the level is either too loud or too soft.  When I do manage to get it reasonably close, it tends to move back and forth with no explanation as to why. \nIf I move it just one notch, it gets intolerably loud, and then when I move it back, it gets low again.  and then it fluctuates a bit.\nThis just started three days ago, ironically when my friend bought a new laptop and we talked on Skype.  I blamed it on his computer until today when this occurred with multiple online videos. \n\nA: I hate to answer my own question, and so quickly, but rather than delete it, I thought it best to leave it up for the next person who has this problem. \nI am using Vizio HDTVs for my monitors.  Somehow the audio setting for SRS True Volume got changed to \"YES\".  \nChanging it to \"NO\" fixed the problem.  \nWhile it turns out that this is NOT a Ubuntu problem, I hope it can help those others who may not realize the problem is in their TV. \nThank you for understanding.\nBuck\n", "Q: How to restore Dejadup 14.04 backup in 16.04? I backed up my 14.04 installation with dejadup on Amazon S3. \nHow can I restore it on a freshly installed Ubuntu 16.04, but not using it as backup?\n\nA: Install the s3 backend for dej-dup:\nsudo apt install deja-dup-backend-s3\n\nUse dconf-editor under org -> gnome -> dejadup to copy the settings for the base installation. Also copy the keys for the S3 bucket and the encryption password. Open the deja-dup and start restore. Hint: Disable auto backup on both installations. Create a new bucket for backups for 16.04 to preserve the 14.04 backup!\n", "Q: Laptop not detecting my home wifi I m using Ubuntu 14.04. My laptop is not detecting my home wifi network. But my mobile detects my home wifi and connects well. And my laptop detects and connects to other wifi networks except my home network.\n\nA: Have you tried reinstalling the driver? Because if it had to be manually installed try and see if you can reinstall. Ubuntu 16.04 was just released a few hours ago. so you can try and see if it will connect to wifi in the live CD/USB\n\nA: Problem solved. Just changed the name of my WiFi network. \nThanks\n", "Q: Automount pendrive like Ubuntu Desktop in Ubuntu Server (15.10) I use the Ubuntu Desktop on my PC and want my Ubuntu Server to automount USB media just like it does on my Desktop: plugin, a folder with same name as label appears in /media/ with the device mounted.\nHow can I do this?\n\nA: From the terminal issue the command sudo apt-get install usbmount\nSource: https://unix.stackexchange.com/questions/24731/automounting-usb-sticks-on-debian\n", "Q: Black screen while installing Ubuntu 14.0.04 LTS on Hp pavilion 13 laptop with pre-installed windows 8.1 (UEFI ) and GPT partition hard-drive I have browsed through many similar topics in numerous forums. I couldn’t find any satisfying solution so I have decided to post this problem here.\nI have following configuration:\nHp pavilion 13 notebook, i3-5010 processor, 4 GB RAM, Windows 8.1 pre-installed (UEFI) and 1 TB hard-drive with GPT partition. Graphics processor is Intel HD 5500\nI tried to install (dual boot) Ubuntu 14.0.4 LTS (also tried Ubuntu 15.10 with same error) on my system.\nI performed following steps:\n1.) Created a recovery point,  shrink C drive and created a new volume.\n2.) Created bootable usb (UEFI) \n3.) Turn-off fast start-up\n4.) Changed the UEFI boot order with highest priority set  to USB drive\nI am able to boot through usb into GNU-GRUB 2.02 Grub\n\nUpon pressing ‘e’ (edit), I get the following screen  edit\nNo matter what option I select, the screen turns black and gives no response  [black-scr\n][3]\n**** I have tried disabling/enabling secure-boot, makes no difference in my case (I get a black screen either ways)tried to change set gfxpayload ( to text)**tried removing ‘quiet splash’ or adding ‘nomodeset’ after ‘quiet spalsh’\nProblem still persists, any suggestions? Thanks in advance.\n\nA: HP Pavilion 13-b221no is Surkee presentation.\nAt first I suspected that the W10 engine update is firmwarenut confused, because impossible to install the windows 7.\nNor does upgrade the bios version down ?? Strange.\nUbuntu is able to be installed, legacy mode, while the Home screen, press the F6 and F6 lalitsee noapic choice.\nHowever, the battery indicator is missing from the top bar. etc ... small\nThe investigation is continuing\n", "Q: Grub Failing to install - Installation crashes I have tried multiple times to install Ubuntu 16.04 LTS on my Mac Book Pro 2011 with a TakeMS SSD and a Hitachi HDD.\nThe problem is though that it copies files fine, but as soon as it gets to GRUB, the installer fails and crashes. This has meant I had to go into GParted and clean the drive.\nI am installing the Whole system and Boot loader on the SSD and I think this is a bug.\n\nA: This is a bug and this is affecting multiple users. I figured out an work around to install any flavour of Ubuntu 16.04 as this bug is present in all of them.\nBug is related to grub so,\n\n\n*\n\n*Install Ubuntu 16.04 as usual (yes do this)\n\n*Wait for Installer to crash\n\n*As Installer crashes shut your PC down.\n\n*Create a Ubuntu 14.04 live USB or use CD.\n\n*Perform boot-repair then restart.\n\n\nFor boot-repair follow : How to install the Boot-Repair tool in an Ubuntu live disc?\nNote : Perform boot repair in live mode, don't install ubuntu 14\n\nA: Had a similar problem  upgrading from 14.04 LTS to 16 earlier today. Error message says cant install bootloader (Grub) on /sda. Several options given but no matter what selected the install program will not respond to an option and pressing ok on the menu. Only way out (for me) was to crash the install program  by a HW reboot.  I also think its a bug. \n\nA: When it asks for Force UEFI Installation?, just click Go Back. That did the trick for me. This is only if you are having problems with UEFI and BIOS mode compatibility issue.\n", "Q: Secure way of geting checksum I was just wondering, is there any way of how to securely get checksum from major branches of ubuntu? As a general rule I do not trust anything that can be easily manipulated for that I do not believe anything coming from HTTP://* addresses.\nBR\nFilip\n\nA: There is no added benefits to using https for checksums. HTTP might be insecure but that does not make the \"sums are provided over HTTP\" insecure. See the discussion on launchpad about this. Comment 8:\n\nIt doesn't matter if the ISO, checksums, and public keys are served insecurely (although it would be simple if they were), as long as the public key fingerprint is served securely, which it already is on the VerifyIsoHowto page.\n\n", "Q: How to detect screenshots in Ubuntu? Apart from monitoring keystrokes for Print Screen, is there a way for a tool or software running in Ubuntu (whatever the desktop) to detect that a screenshot or video recording of the whole or a part of the screen is being captured - regardless of the tool used (Gnome Screenshot, Shutter, etc)?\n\nA: The short answer is \"no, not on a vanilla Ubuntu distribution\" (and btw, hitting printscreen is not the only way to take a screenshot). \nThe somewhat longer answer is that the question is ill-posed.  Whether some approach might work would depend on the specific combination of X server (or whatever display server you are using), window manager, whether you are willing to write your own X extensions, what your threat model is, how tight control you have of your environment, and so on.\nI'm curious, though, what is your threat model?\n", "Q: Unable to play commercial DVD in Lenovo E555 with Ubuntu 16.04 I have installed both vlc and libdvd-pkg on my Lenovo E555 ThinkPad. I have also run the command:\nsudo dpkg-reconfigure libdvd-pkg\nIn Ubuntu 15.10 that seemed to work for playing encrypted DVD's, but on my fresh install of Ubuntu 16.04, I just see this when I try and play a commercial DVD \n\nIt works flawlessly playing a regular  DVD with an MP4 file on it, the problem only seems to occur with commercial DVD's.\n\nIn some other answers to this similar question it was suggested to use \nsudo apt-get install libdvdread4\nand to then run \nsudo /usr/share/doc/libdvdread4/install-css.sh\nHowever this dose not work in this case since the install-css.sh file dose not exist in the /usr/share/doc/libdvdread4 directory.\n\n\nIn some other cases it was pointed out that the region for playing DVD's must be set. In my case here in Eugene, OR, USA the region needs to be set to 1 in order to playback DVD's published for the US and Canada. From regionset I see my drive is set properly.\n\n\nI have now tried an external DVD player and it seems to work fine. This now makes me think that the issue is more of a driver issue. \nI have a Lenovo ThinkPad Edge E550 laptop with an AMD A10 processor in it. From sudo lshw -C disk I get the following hardware info for my cdrom:\n\nCurrently I have no clue as to where to go from here. Is this a driver issue, or something else? \nAny suggestions on how I might be able to fix this?\n\nA: I just install Ubuntu 16.04, the file /install-css.sh doesn't exist,I use a file in a usr/share/doc/libdvdread4 from linux mint partition and copy it to the same folder in Ubuntu and It's work.\nMaybe you can look for file in internte and paste the file in the folder of Ubuntu.\nusr/share/doc/libdvdread4\nAnd run the: sudo /usr/share/doc/libdvdread4/install-css.sh\n\nA: I had exactly the same problems.  The solution was 2 parts.  Part 1 is to install the Quicktime drivers: -lib and -dvd [use synaptic for this], and to ensure the VLC install is complete and up to date.  Part 2 is to ensure your dvd drive can process the blocks [my old dvd drive could not, so I bought a new one]. Now, all problems solved. \n\nA: Now with Ubuntu 20.04 LTS being available at http://cdimage.ubuntu.com/ this seams to not be the issue that it once was for me.  Besides, I've since move into the 21st century and don't use DVD's or CD's anymore and now run a dell E7470 now which has no internal player for Blueray, DVD's or CD's.\nMy resolve at the time was to just settled with the idea that my disk players drivers were not at the time easily available.\nAs it was for me in this case I threw this one on the back burner of the problem solving engine of life. Sometimes when a problem gets place on the back burner for too long the problem fails to remain relevant and thus just fades away from existence leaving nothing left to solve.\n", "Q: How to turn backlight off | Sony vaio | Ubuntu Trusty How to turn the keyboard back-light off for sony-vaio laptop.\nI have tried most of the methods described on the forum but to no avail.\nMy laptop is sony-vaio SVE15117FNB.\nAnd I am using Ubuntu 14.04.2 LTS Trusty.\n\nA: Open terminal and try this:\n\nxset led off\n\nIf that doesn't work get this.\nReferences:\nQuestion from the past.\nSony Support Answer\n", "Q: Visudo Command Not Working on Sudo User I recently bought a vps and I have am fairly new to using ubuntu on it since I have always used shared hosting. \nI have created a sudoer user and it worked perfectly fine yesterday except when I edited the ssh/ssh_config file to disable password authentication, it did not work, and I decided to work on it tomorrow. \nI stopped my server, and when I booted it up today, and tried the command sudo visudo /etc/ssh/ssh_config it would just put display \nusage: visudo [-chqsV] [-f sudoers] [-x file]\n\nrather than opening up the file. \nI know it is something wrong about my usage but I can't seem to figure it out, I did the same exact command yesterday and it worked perfectly fine.\n\nA: The command to edit a file using sudo is sudoedit:\nsudoedit /etc/ssh/sshd_config\n\nEquivalently, you can also do:\nsudo -e /etc/ssh/sshd_config\n\nvisudo, as already noted, is specifically meant for editing sudoers files. It performs syntax checking assuming the file is a sudoers file. You don't want to use it to edit other files.\n\nA: Use nano, visudo won't work for anything other than the sudoers config.\n", "Q: Problem with /home Sry for my english.\nI had /home on the other partition. I delete this partition and in graphical mode i can't log in. In console i can. I have Ubuntu 15 with link to this partition and Lubuntu 15. In this and this I can't log in. How can I solve this?\n\nA: You've trashed all your personal data, including settings for your GUI login. If you can get the /home partition back (using TestDisk, for instance, do so. If not, you may be able to recover by logging in to text mode and doing this:\nsudo mkdir -p /home/{yourusername}\n\n...where {yourusername} is your username (or the directory where your account's home directory existed).\nIf you do this and it works, you will have lost all your personal settings (desktop preferences, program settings, etc.), but you should at least be able to log in.\n", "Q: Problem with a touch screen in a HP Compaq TC4400 I have a problem with my HP Compaq Tc4400 and the touch screen with a pen.\nWhen I'm running Lubuntu 16.04 with my touchpad, the screen detects that I'm using the pen (that i'm not using) of the touch screen and moves the mouse!\nHow can I uninstall the Wacom driver (it manage the pen and the tactile mode of my screen)\nThanks in advance\n\nA: Uninstall just xserver-xorg-input-wacom\n\nsudo apt-get remove xserver-xorg-input-wacom\n\nThis will remove just the xserver-xorg-input-wacom package itself.\nUninstall xserver-xorg-input-wacom and it's dependencies\n\nsudo apt-get remove --auto-remove xserver-xorg-input-wacom\n\nThis will remove the xserver-xorg-input-wacom package and any other dependant packages which are no longer needed.\nPurging your config/data too\nIf you also want to delete your local/config files for xserver-xorg-input-wacom then this will work.\nCaution! Purged config/data can not be restored by reinstalling the package.\n\nsudo apt-get purge xserver-xorg-input-wacom\n\nOr similarly, like this xserver-xorg-input-wacom\n\nsudo apt-get purge --auto-remove xserver-xorg-input-wacom\n\nPasted from:\nThis\n", "Q: Ubuntu installation stuck on Deactivating Swap This is my first time installing Ubuntu, and it has been stuck on Deactivating Swap for the past 9 hours. \nCan anyone help me?\n\nA: it shouldn't take more than 9 seconds, let alone 9 hours!\nI don't recall ever seeing a \"deactivating swap\" message, but I assume it happens after partition selection and right before repartitioning / reformatting the disk. I also assume this happens while you are trying to install? The only reason I can think of is that there already exists a swap partition on your disk, the system is already using it, and somehow it's failing to deactivate it.\nTo fix this, boot Ubuntu again, and when you reach the screen where you get a choice between trying and installing, just select \"try\". When everything is running, start a terminal window (on plain ubuntu, use the search bar to search for \"terminal\" and click on it; on kubuntu run \"konsole\" from the start menu; on anything else you're on your own :) ). \nType sudo parted. You'll see somehting like:\nGNU Parted 3.2\nUsing /dev/sda\nWelcome to GNU Parted! Type 'help' to view a list of commands.\n(parted) \n\nthen type print. You'll see something like:\nNumber  Start   End    Size    Type      File system     Flags\n 1      1049kB  248GB  248GB   primary   ext4            boot\n 2      248GB   256GB  8520MB  extended\n 5      248GB   256GB  8520MB  logical   linux-swap(v1)\n\nNote the number of the swap partition. In this case, it's 5, but yours may be different. Type rm 5 (or whatever the swap partition is) and then quit to leave parted. Reboot. With no swap partition on the disk, there will be no reason to try to activate and then deactivate swap.\nLet us know if this worked.\n", "Q: How to install Ubuntu sdk on ubuntu touch? I bought a BQ M10 Ubuntu Edition. I want to use that device also as notebook and i want to develop ubuntu apps with the device.\nThe problem is, that there is not ubuntu sdk IDE program installed on it.\nIs there a way to install the ubuntu sdk IDE on the device and if yes, how do i do that?\nEDIT:\nHere is what i found out so far:\nThere is a script, that seems to install legacy programs on ubuntu touch.\nIt seems to be from a member of canonical: Script to install legacy programs on ubuntu touch. \nI tried it several times on the bq M10 but it ended up with errors all the time.\n\nA: Sadly I do not know the full solution to this as some packages seem to be broken (at least when using a xenial container). However, one part of the problem is that the Ubuntu SDK is not in the main/universe repos, but in a ppa, so it is necessary to add the ubuntu-sdk-team/ppa personal package archive to the apt sources ofthe container. This has to be done between the creation of the container and the installation of the package, so the line has to be inserted into the script.\nThe command to add the ppa should be \nlibertine-container-manager create -i $NAME -a ppa:ubuntu-sdk-team/ppa\n\nAfterwards in my case apparmor failed at the configuration, so multiple packages remained unconfigured. I could fix it with a mkdir call in the SDK still complained about a missing mir plug in.\n\nA: I have found a new possible solution to this. Using the Ubuntu SDK should be possible if it was compiled into a click package. In fact, there is a bazaar branch on launchpad which seems to exist just for this purpose with the name lp:ubuntu-sdk-ide-click.\nAt first, check whether you have the required development tools on a desktop Ubuntu computer. Ensure that you have installed the packages click and bzr. \nTo build the package, you must download the branch at first using\nbzr branch lp:ubuntu-sdk-ide-click\n\nGo into the newly created directory ubuntu-sdk-ide-click\ncd ./ubuntu-sdk-ide-click\n\nExport the current directory to the PATH environment variable. This is necessary, as the python script which will be run soon expects this directory to be present. \nexport PATH=$PATH:<insert current working directory here>\n\nNow you must create the necessary files and directories for building the package. Run\ncreate-ubuntu-sdk-ide-click.py\n\nThis can take quite a while. At some point of time, the script crashed in my Ubuntu installation.\nBut when the script has crashed because of an UnicodeEncodeError, you can fix the problems and do the last step to build an armhf click package for your m10 manually.\nBe careful, as the following command removes all files with non-ascii-filenames recursively in the current working directory. Assure that you are in the right directory and run\nLC_ALL=C find . -name '*[! -~]*' -delete\n\nThen you can do the last necessary step of the script manually. Run\nclick build ./click-armhf/\n\nAfterwards, there should be a click file in the current working directory. Copy this to your device for the installation process.\n\nOn the device install the package using pkcon. Most likely, you will not have signed the click package, so you have to run\npkcon --allow-untrusted install-local <insert the name of the click file on the device here>\n\n\nRunning the SDK also is a minor challenge. Based on the README available, the following set of commands should work. Eventually, you might put them into a script.\nexport TMPDIR=/tmp\nXmir :1 -mirSocket $XDG_RUNTIME_DIR/mir_socket --desktop_file_hint=dialer-app&\nexport DISPLAY=:1\nexport QT_QPA_PLATFORM=xcb\nexport LD_LIBRARY_PATH=/usr/lib/arm-linux-gnueabihf/:/opt/click.ubuntu.com/com.ubuntu.sdk/current/usr/ubuntu-sdk-ide/qtcreator/\nexport LD_LIBRARY_PATH=/opt/click.ubuntu.com/com.ubuntu.sdk/current/usr/ubuntu-sdk-dev/lib:$LD_LIBRARY_PATH\nexport QT_PLUGIN_PATH=/opt/click.ubuntu.com/com.ubuntu.sdk/current/usr/ubuntu-sdk-ide/bin/plugins/\n/opt/click.ubuntu.com/com.ubuntu.sdk/current/ubuntu-sdk-ide-click\n\nDecide whether the SDK runs sufficiently fast and running the SDK is simple enough.\n", "Q: No applications I have downloaded will open My Kodi, VLC, even transmission will not open and show the display...It's like it thinks it's open but nothing is showing on the screen. Any help?\nI have tried reinstalling unity with:\nsudo apt-get update\n\nsudo apt-get install --reinstall ubuntu-desktop\n\nsudo apt-get install unity\n\n\nA: I found it...\nLook at this page: https://wiki.ubuntu.com/XenialXerus/ReleaseNotes/\nThey have written:\nSometimes doesn't update apps to \"Installed\" after installation via search https://bugs.launchpad.net/ubuntu/+source/gnome-software/+bug/1551599\n", "Q: Xenial Xerus 'origami animal' instructions? Seemingly now almost every release has origami instructions released with it by Canonical showing you how to make the animal in the logo out of paper (clearly), so where can I find the origami instructions for Xenial Xerus (16.04)?\nAlso is there a place where the release of these instructions for each release is announced or an easy way of finding them? Are they listed somewhere?\n\nA: It gives me enormous pleasure to solve this question of the origami instructions for Xenial Xerus! The instructions have now been posted on the Canonical design site...\nNo to just get those folds just right, there are 77 steps on 4 pages and my hands are designed for a computer keyboard not folding intricate patterns into paper :)\nReferences:\n\n\n*\n\n*Wallpaper design for Xenial Xerus 16.04\n\nA: This page suggests that the folds in the wallpaper for 16.04 are the ones you need to make to create an origami xenial xeru \nhttp://design.canonical.com/2016/04/wallpaper-design-for-xenial-xerus-16-04/\n", "Q: How to see if a specific process is running or not for 1 hour in shell My process name is test. If I use\nps -ef | grep test\n\nI see that process is running. Now I want to check this every 10 mins for one hour and print success if it's running successfully for one hour. \nWhat is the best way to do so?\n\nA: You can use a while loop; here i am using pgrep to check if the process is running:\n#!/bin/bash\ncounter=0\nwhile :; do\n    [ \"$counter\" -eq 6 ] && break\n    if pgrep <process_name> &>/dev/null; then\n        echo \"Success !!\"\n        (( counter += 1 ))\n        sleep 10m\n    else\n        echo \"Process not running..exiting !!\"\n        break\n    fi\ndone\n\nReplace <process_name> with the actual name of the process you want to track.\n\nA: A simple loop in a script:\n#! /bin/bash\nstart=$SECONDS\nwhile (( SECONDS - start < 3600 ))\ndo\n    sleep 10m\n    pgrep -f test &>- || exit\ndone\necho success\n\nSECONDS is a special variable in bash that contains the number of seconds since the script has started. pgrep test checks for a process named test. If it doesn't find one, we exit the script. If not, we sleep for 10 minutes.\nIf we didn't exit, then pgrep was successful. So, echo success.\n", "Q: Why is my desktop suddenly using my home folder? Installed gdm, using GNOME Classic. Also using LDAP for authentication and home folder designation.\nI realized my home folder was set to /home/users/ldapuser which is undesired behavior, because that means my home folder will depend on which machine I'm logged into. This was after I already had a decent amount of information built up in my home folder. I edited the appropriate LDAP field to use the NFS share home directory, which is empty. I copied files from my machine into the NFS share to 'migrate' my info/settings etc.\nOriginally the Desktop was using ~/Desktop as the Desktop folder which was fine with me. But now it seems after I've switched, it is simply using ~ as the Desktop folder. So, now I have a folder on my Desktop named 'Desktop' which has all the stuff that was on my original Desktop. Also, all the files from my home folder now appear on the Desktop, the whole situation is very disconcerting.\nHow can I get the interface to treat ~/Desktop as the actual Desktop directory again, and why did it change?\n\nA: $XDG_CONFIG_HOME/user-dirs.dirs was determining that my desktop should be $HOME instead of $HOME/Desktop.\nThe rest of my folders were also set to $HOME, which is why they were gone, which I didn't even realize until now.\nNot sure how it happened, but changing these values back fixed the problem.\n", "Q: How to use snaps via the CLI and GUI? So, I have upgraded from my 15.10 to 16.04.\nI have managed to install some snaps, but now I am wondering, how do I launch them? Typing their name in CLI did not help.\nI tried:\nubuntu-core-launcher xkcd-webserver\nBut it gave me only this message:\nUsage: ubuntu-core-launcher   \nI would like to know ways to use them both in CLI and GUI.\n\nA: It depends on the type of application. Graphical apps should be launchable from the Dash. So for example, if you install the calculator app with:\nsudo snap install ubuntu-calculator-app\n\nYou should be able to:\n\n\n*\n\n*Open the Dash by pressing the Super key or the Ubuntu button in the launcher\n\n*Start typing the first letters of \"Calculator\"\n\n*Click on the Calculator icon to launch the app\n\nNote: if the icon does not appear in the Dash, you might need to log out and log back in. You should only need to do this the first time after you've installed snaps support on the desktop.\nAlternatively, you can launch the calculator app from the command line:\nubuntu-calculator-app.calculator\n\nNotice the syntax is $SNAPNAME.$COMMAND. If $SNAPNAME is the same as $COMMAND, as a shortcut you can simply run $SNAPNAME\n", "Q: Create custom keybinding to snap window There is a shortcut to snap window to either half of the screen\nCtrl + Super + Left or Ctrl + Super + Right. \nMy first question is how this shortcut is defined in the system? All default shortcuts are defined in gsettings but this is not there.\nNow coming to main question. Above shortcut snaps to half screen. I want the shortcut to snap it to 75%. How can I do this? And if I want to define a new shortcut to snap to 75%, then what will be the way?\n\nA: I was able to make it work using wmctrl and xdotool . Both are window manipulation tool.\n#!/bin/bash\nWIN=$(xdotool getactivewindow)\neval $(xdotool getwindowgeometry --shell $WIN)\nWIDTH=$(calc \"int($WIDTH*0.75)\")\nwmctrl -r :ACTIVE: -b remove,maximized_horz,sticky\nwmctrl -r :ACTIVE: -e \"0,0,24,$WIDTH,-1\"\n\nAbove script snap window to 75 % to its size to left side. Save above script in a file and assign shortcut to the file.\nSimilarly following script snap window to 25% width to the right.\n#!/bin/bash\nWIN=$(xdotool getactivewindow)\neval $(xdotool getwindowgeometry --shell $WIN)\nX=$(calc \"int($WIDTH-$WIDTH*0.25)\")\nWIDTH=$(calc \"int($WIDTH*0.25)\")\nwmctrl -i -r $WINDOW -b remove,maximized_horz\nwmctrl -i -r $WINDOW -e \"0,$X,-1,$WIDTH,-1\"\n\nCheck wmctrl and xdotool manpages and tutorials to find how they work.\nInstall dependencies using \nsudo apt-get install apcalc wmctrl xdotool\n\nNote: The resizing works relative to current window position and size. To make it relative to screen size, maximize the window then execute the script.\n", "Q: Is there any way I can fix my corrupted Hard Drive? Here is the output of badblocks -sv /dev/sda\nChecking blocks 0 to 488386583\nChecking for bad blocks (read-only test): 190698244one, 31:24 elapsed. (0/0/0 errors)\n190698245one, 31:29 elapsed. (1/0/0 errors)\n190698246one, 31:33 elapsed. (2/0/0 errors)\n190698247one, 31:37 elapsed. (3/0/0 errors)\ndone                                                 \nPass completed, 4 bad blocks found. (4/0/0 errors)\n\nWhat should I do ?\n\nA: You should also check the SMART attributes of the drive either with the Disks utility, or with smartctl on the command line.  Since badblocks has identified the bad blocks it found, you can now attempt to repair them by writing zeros to them:\nsudo dd if=/dev/sda of=/dev/null bs=1024 count=1 skip=190698244\n\nIf that returns an error, then you got the numbers right, and confirmed the sector can not be read.  Now try to write zeros to it and the drive will try to repair it:\nsudo dd if=/dev/zero of=/dev/sda bs=1024 count=1 seek=190698244\n\nNotice the difference between the two commands, especially seek instead of skip.  Make sure you type it correctly or bad things will happen.  After doing this, repeat the first command to read-test the sector again and this time it should not fail.  Also check the SMART stats on the drive.  The important numbers to look at are the counts of pending, reallocated, and offline sectors.  If there was nothing physically wrong with the disk, the count of pending sectors should go down, and there should still be zero reallocated or offline sectors.  If the count of reallocated sectors goes up, then the drive switched to using a spare sector for that block instead of the damaged area.  If there are more than a handful of these, or any offline sectors, you should replace the drive.\n", "Q: Intel Wifi Link 5100 - unstable connection i'd really love to move from windows to ubuntu, but there is a problem i have with my wireless connection. I have old Toshiba Satellite A300 with Intel Wifi Link 5100. I can see wireless networks and i can connect to them, but the connection is very unstable - it doesn't disconnect, rather connection to the web stops working. I don't know what is the problem, i tried to google it and tried some solutions posted here on askubuntu, but none of them worked.\nI'm on 16.04 now, but i had this problem on 14.04 as well.\nThis particular thing really discourages me from using Ubuntu, sice i cannot use internet properly.\nI would be really happy if someone with the same experience could tell me what to do.\nThanks in advance!\nPS: I'm absolute layperson concerning Ubuntu and other linux distributions.\n\nA: I own and use successfully two Intel wireless devices. I have honed a few techniques in several years and thousands of forum posts.\nFirst, check the settings in the router. WPA2-AES is preferred; not any WPA and WPA2 mixed mode and certainly not TKIP. Second, if your router is capable of N speeds, you may have better connectivity with a channel width of 20 MHz in the 2.4 GHz band instead of automatic 20/40 MHz, although it is likely to affect N speeds. I also have better luck with a fixed channel, either 1, 6 or 11, rather than automatic channel selection. Also, be certain the router is not set to use N speeds only; auto B, G and N is preferred. After making these changes, reboot the router. \nNext, I recommend that your regulatory domain be set explicitly. Check yours:\nsudo iw reg get\n\nIf you get 00, that is a one-size-maybe-fits-all setting. Find yours here: http://en.wikipedia.org/wiki/ISO_3166-1_alpha-2 Then set it temporarily:\nsudo iw reg set IS\n\nOf course, substitute your country code if not Iceland. Set it permanently:\ngksudo gedit /etc/default/crda\n\nUse nano or kate or leafpad if you don't have the text editor gedit.\nChange the last line to read:\nREGDOMAIN=IS\n\nProofread carefully, save and close the text editor.\nNext, I'd set IPv6 to Ignore in Network Manager: http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/images/netconfig/network-connections-ipv6-ignore.png  This example is for ethernet, but you want wireless.\nIf these changes do not help, please try:\nsudo modprobe -r iwlwifi\nsudo modprobe iwlwifi 11n_disable=8\n\nIf it helps, make it permanent:\nsudo -i\necho \"options iwlwifi 11n_disable=8\"  >>  /etc/modprobe.d/iwlwifi.conf\nexit\n\n", "Q: Python3-venv not installed ubuntu 14.04 Fresh install of ubuntu gnome 14.04, followed by dist-upgrade\none of the first things I tried to do was create virtual environment for python \npython3 -m venv flask\n\ngave me\nThe virtual environment was not created successfully because ensurepip is not\navailable.  On Debian/Ubuntu systems, you need to install the python3-venv\npackage using the following command.\n\n    apt-get install python3-venv\n\nYou may need to use sudo with that command.  After installing the python3-venv\npackage, recreate your virtual environment.\n\nwhich is odd because i thought venv was installed by default, but anyways\nsudo apt-get install python3-venv\n\ngives me\nE: Unable to locate package python3-venv\n\nam I missing something? is something wrong with my python installation? i've tried to google whether there's a repo or something i need but I can't find one.\n\nA: Do : \nsudo apt-get install python3.4-venv\n\nand then you can easily do : \npython3 -m venv flask\n\nsource\n", "Q: Evenote using Wine does not work on Ubuntu 15.10 I am trying to run Evernote using Wine, but it seems it is not working properly. Although the program launches, I am getting the same GUI where it is not possible to edit my notes:\n\nThe problem is that nothing appears where I should be able to edit the note. I hope I can solve this problem because I really need Evernote working on Ubuntu.\n\nA: According to the WineHQ database, Internet Explorer 8 may need to be installed through winetricks before the official Evernote application will work properly under Linux: https://appdb.winehq.org/objectManager.php?sClass=version&iId=33338\nThere is more information about downloading and using winetricks here: https://wiki.winehq.org/Winetricks , or you can just use PlayOnLinux (available through the official Ubuntu repositories), which bundles Wine and Winetricks with a nice GUI interface.\nOther possible options for a Linux Evernote client include the open-source third-party applications NeverNote and NixNote.\n", "Q: Compiling python3 code in terminal with interpreter When I compile my code simply with the command python3 name.py, it's being run, but then the whole story ends and I can't do anything with the compiled data.\nI want to somehow compile my program to the interpreter and have the ability to experiment with the data in that interpreter. For example, I want to use timeit(function(argument)) with the function and the argument, defined and set in my name.py program.\n\nA: What you are looking for is the -i switch. According to the manpages:\n-i    When  a  script  is passed as first argument or the -c option is\n      used, enter interactive mode after executing the script  or  the\n      command.  It does not read the $PYTHONSTARTUP file.  This can be\n      useful to inspect global variables  or  a  stack  trace  when  a\n      script raises an exception.\n\nSo if your script name is name.py what you need to do is run:\npython3 -i name.py\n\n\nA: @daltonfury42's answer is one way to do it, but note that it will run the script first before going into the interpreter. Another one is to just run the interpreter in the same directory as your script and import it.\n$ cat spam.py \ndef main(*args):\n    print(\"Called main() with args: \", args)\n\nif __name__ == \"__main__\":\n    main(\"foo\")\n$ python3 spam.py \nCalled main() with args:  ('foo',)\n$ python3\n>>> import spam\n>>> spam.main(\"bar\")\nCalled main() with args:  ('bar',)\n>>> \n\n", "Q: URL to Complete list of native- & web apps for Ubuntu tablet version on BQ M10 Where van I find the complete list of native- and web apps yhat operational on Ubuntu tablet (BQ M10 tablet)?\nI'm especially interested in professional graphical applications like Scribus, Inkscape, the Gimp, etc.\n\nA: You can browse what is in the store using uApp Explorer.\nAs far as \"legacy\" X11 desktop apps, the BQ M10 includes (as of OTA 10.1) a preview version of libertine and a container that includes LibreOffice, Gedit, Firefox, GIMP, and XChat-GNOME. There isn't a \"supported\" way to add your own X apps yet; I believe it is on the roadmap for OTA 11 at the end of May.\n", "Q: Why is enp#s# in stead of eth# ? Whats the meaning of enp#s#? I migrate from Ubuntu Server 14 to Ubuntu Server 16 I now I have problems because I'm not undertand that. \nI hope that somebody can answer me. \n\nA: These interface names are a new standard aimed at providing consistent (and persistent) names of network devices between different boots and Linux installs. There's a good amount of information and rationale here:\nhttps://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/\nThere's also the technical detail of the naming scheme here:\nhttps://github.com/systemd/systemd/blob/master/src/udev/udev-builtin-net_id.c#L20\nIn short, for your case, the enpXsY signifies that it's a pci device (from the p), on pci bus X, in slot Y.\n", "Q: How to use xrdp with Unity on Ubuntu 16.04 LTS? I'd like to remotely connect to an Ubuntu 16.04 LTS system over xrdp using the Unity desktop environment.\nI have a 14.04 LTS system that I configured to use Xfce for xrdp connections, but I prefer Unity and would like to avoid installing another desktop environment if possible.\nIs this possible? And if so, what are the steps to configure it correctly?\n\nA: -------------------Important Updates -------------------  \nsee comment above to have XRDP connecting to your Unity Desktop\nFull instruction on installing xrdp and connecting to Unity Desktop can be found at  [http://c-nergy.be/blog/?p=9962]2\n-------------------End of Updates ----------------------\nThis can be helpful to other people...\nIn Ubuntu 16.04, adding the command about the alternate desktop in the .xsession file does not seem to work anymore. To be able to use xrdp and to connect to the alternate desktop you have installed; you need to edit the following file \n\n\n*\n\n*/etc/xrdp/startwm.sh\nIf you have installed the mate desktop as alternate option, you would type the mate-session just after the fi line.  Your startwm.sh file should look like  \n#!/bin/sh \nif [ -r /etc/default/locale ]; then\n  . /etc/default/locale \n    export LANG LANGUAGE \nfi\n\n#Add this line if you plan to use mate-desktop as alternate desktop \n#insert the appropriate command based on your alternate desktop \n\nmate-session \n./etc/X11/Xsession\n\nStep by Step Instruction on how to install and Configure Xrdp in Ubuntu 16.04 can be found at this location\nHope this help\n\nA: ------------------Important Update for this topic : ------------------------\nIt seems that it's possible to use xRDP and Unity Interface even if there are still some minor issues with such setup.  (You can see a demo here) \nIn order to configure your Ubuntu 16.04 to have xrdp connecting to Unity, you would need to perform the following \n\n\n*\n\n*install TigerVNC\n\n*install XRDP\n\n*Configure preferred desktop to be used in xRDP \n\n\nFull Instructions on how to perform this can be found at http://c-nergy.be/blog/?p=9962\n------------------------ End of the Important Update------------------ \nRemarks : The information provided below is not the most recent information but it still valid.  Please be sure to read the Important Update note to get the latest informatioin.... \nTo quickly answer your question, as far as we know Unity desktop cannot be used in conjunction with xrdp.  You have no other choices other than installing an alternate desktop environment. Xfce is one option \nwe prefer to install mate-desktop as altnernate desktop.\nWith Ubuntu 16.04, you can use mutiny feature of mate desktop to have something similar to Unity (but it's not !) see this post\nYou could use the xrdp as a proxy server to connect to the Unity desktop using vnc protocol. To be able to perform such configuration, you will need to configure your vnc server to start at bootup and to configure install xrdp on the system you want to access.  \nIn the xrdp login box; you will then need to select the option console instead of Sesman-Xvnc.  (all detailed info here)  but again here you simply using the xrdp as proxy to basically initiate a vnc connection...\nHope this help \n\nA: Here are instructions to a repurposed Hyper-V solution that allows network access to xrdp Unity session.  Supports video, audio, and client workstation hard drive redirection.  Although the instructions are written assuming Ubuntu runs in a VM, I see no reason why it shouldn’t work for physical Ubuntu machine.\nFrom my own experience, this xrdp solution provides noticeably more responsive command line typing and browser rendering than one reliant on vino VNC.\nI've use this solution and automated the application of VM checkpoints to provide a secure browser experience to my LAN connected computers\n\nA: The following seems to be a good work-around...\nI found this article below, and followed it exactly. It seems to work on Ubuntu Gnome 16.04, and I'd imagine to would work on the standard Ubuntu 16.04 as well. See here: http://www.hiroom2.com/2016/05/24/ubuntu-16-04-remote-connect-to-gnome-classic-desktop-with-vnc-xrdp/\nAfter this, Remmina stopped working. To fix this, I removed Remmina and installed the latest version using a PPA. See here:\nhttps://github.com/FreeRDP/Remmina/wiki\n", "Q: Qualcomm Atheros qca61x4 network adapter not working I have looked at almost every similar question and tried the suggestions and answers people have given with no luck as of yet. I was on ubuntu 15.10 but just recently upgraded to 16.04 hoping that maybe there would be official support for my card now. From my understanding my card requires the ath10k drivers and have tried installing backports of those when I was on 15.10 and I tried using ndiswrapper with the windows drivers.\nI am still fairly new to ubuntu so I apologize in advance for not knowing a lot.\nHere are some terminal readouts:\nalex@alex-Lenovo-Edge-15:~$ lspci | grep Network\n02:00.0 Network controller: Qualcomm Atheros QCA6164 802.11ac\nWireless Network Adapter (rev 20)\n\nNow I seem have to been able to gotten the ath10k firmware to run, I think, although it refuses to start on boot, but manually starting it with 'modprobe ath10k_pci' cause it to now show up when running lsmod when prior to that command it couldn't be found on lsmod\nalex@alex-Lenovo-Edge-15:~$ lsmod | grep ath\nath10k_pci             45056  0\nath10k_core           311296  1 ath10k_pci\nath                    32768  1 ath10k_core\nmac80211              737280  1 ath10k_core\ncfg80211              565248  4 ath,mac80211,r8188eu,ath10k_core\n\nAlso worth noting is that my adapter used to show up as Unclaimed when running lshw -C network but now doesn't\nalex@alex-Lenovo-Edge-15:~$ sudo lshw -C network\n  *-network               \n       description: Network controller\n       product: QCA6164 802.11ac Wireless Network Adapter\n       vendor: Qualcomm Atheros\n       physical id: 0\n       bus info: pci@0000:02:00.0\n       version: 20\n       width: 64 bits\n       clock: 33MHz\n       capabilities: pm msi pciexpress bus_master cap_list\n       configuration: driver=ath10k_pci latency=0\n       resources: irq:49 memory:d1000000-d11fffff\n\nDespite this, iwconfig still shows nothing for my adapter and ubuntu seems to have no clue how to use it.\nThanks in advance for any help.\nEdit: Here are more requested terminal commands\nalex@alex-Lenovo-Edge-15:~$ lspci -nnk | grep 0280 -A2\n02:00.0 Network controller [0280]: Qualcomm Atheros QCA6164 802.11ac \nWireless Network Adapter [168c:0041] (rev 20)\n    Subsystem: Lenovo QCA6164 802.11ac Wireless Network Adapter [17aa:3545]\n    Kernel driver in use: ath10k_pci\n\nalex@alex-Lenovo-Edge-15:~$ uname -r\n4.4.0-21-generic\n\n\nA: My solution.\nSo I guess because I didn't do a clean install for 16.04 the windows driver I had tried to install (unsuccessfully) with ndiswrapper was still there, not sure if that is the whole problem. Running 'modprobe ath10k_pci' would start up the correct driver firmware however looking at dmesg I realized it wasn't loading correctly. The firmware I got was from here (https://github.com/kvalo/ath10k-firmware). Weirdly enough, although lspci told me my card was the 6164, the firmware it was trying to load was from the 6174 folder, the issue is it was trying to load from a hw2.1 folder which did not exist when I downloaded the firmware from the git link. I manually downloaded the files for 6174 hw2.1 from the git link and had to create that folder in lib/firmware/ath10k/6174 and paste the files in. That still didn't work so I went back in and renamed one of the files to firmware-5.bin from it's original name (firmware-5.bin_SW_RM.1.1.1-00157-QCARMSWPZ-1). After a reboot it still didn't work until I ran the 'sudo modprobe ath10k_pci' command. Lo and behold, it now works...provided I manually start up the correct firmware each boot.\nAgain, for newbies like me, to do the file operations, you must run 'sudo nautilus' to get sudo access in the file manager.\nHopefully my lengthy solution will help those like me who aren't very familiar with ubuntu.\n", "Q: How to use touchscreen to draw? I have tried different softwares for drawing using my touchscreen (e.g. Gimp or Krita).\nHowever, when I touch and drag (to draw a line) what happens is that only the mouse pointer moves from one place to the other, but as I was not \"clicking\" to draw.\nI also cannot use some gestures such as zooming a picture.\nI have installed Touchegg, but I'm not sure how to use it and if it can help me solve this problem.\n\nA: First install touchegg:\nsudo apt-get install touchegg\n\nInstall the dependencies for the GUI tool (for TouchEgg) using this command\nsudo apt-get install build-essential libqt4-dev libx11-6 libx11-dev\n\nDownload the GUI touchegg-gce from GitHub. Then:\n\n  \n*\n  \n*Change to the directory holding the .zip file.\n  \n*Issue the command unzip Touchegg-gce-master.zip to extract the file.\n  \n*Change into the Touchegg-gce-master folder.\n  \n*Issue the command qmake\n  \n*Issue the command make\n  \n*Copy the touchegg-gce file to /usr/bin\n\nSource: How to Configure a Touchscreen on Linux\nUnder \"Touchegg\" it shows you how to configure the program, maybe this'll allow you to draw on your touchscreen. I am sorry I am unable to help further as I don't know much about this program.\n\nA: A workaround is to hold down the mouse button while drawing. This gives you the advantage of not clicking accidentally when bumping the screen for example.\n", "Q: add-apt-repository producing python error Recently I updated ubuntu 14.04 to kubuntu 16.04.Whenever I try to add ppa repositories through \"add-apt-repository\",its producing python error.Please help me solve this error or suggest alternative methods.Is this a python problem?I am trying to add wine using \"sudo -E add-apt-repository ppa:ubuntu-wine/ppa\".I get the following error   \nTraceback (most recent call last):\nFile \"/usr/lib/python3.5/urllib/request.py\", line 1243, in do_open\n h.request(req.get_method(), req.selector, req.data, headers)\nFile \"/usr/lib/python3.5/http/client.py\", line 1106, in request\n self._send_request(method, url, body, headers)\nFile \"/usr/lib/python3.5/http/client.py\", line 1151, in _send_request\n self.endheaders(body)\nFile \"/usr/lib/python3.5/http/client.py\", line 1102, in endheaders\n self._send_output(message_body)\nFile \"/usr/lib/python3.5/http/client.py\", line 934, in _send_output\n self.send(msg)\nFile \"/usr/lib/python3.5/http/client.py\", line 877, in send\n self.connect()\nFile \"/usr/lib/python3.5/http/client.py\", line 1252, in connect\n super().connect()\nFile \"/usr/lib/python3.5/http/client.py\", line 849, in connect\n (self.host,self.port), self.timeout, self.source_address)\nFile \"/usr/lib/python3.5/socket.py\", line 693, in create_connection\n for res in getaddrinfo(host, port, 0, SOCK_STREAM):\nFile \"/usr/lib/python3.5/socket.py\", line 732, in getaddrinfo\n for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n socket.gaierror: [Errno -3] Temporary failure in name resolution\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\nFile \"/usr/lib/python3/dist-packages/softwareproperties/ppa.py\", line 102, in _get_https_content_py3\n lp_page = urllib.request.urlopen(request, cafile=LAUNCHPAD_PPA_CERT)\nFile \"/usr/lib/python3.5/urllib/request.py\", line 162, in urlopen\n  return opener.open(url, data, timeout)\nFile \"/usr/lib/python3.5/urllib/request.py\", line 465, in open\n  response = self._open(req, data)\nFile \"/usr/lib/python3.5/urllib/request.py\", line 483, in _open\n '_open', req)\nFile \"/usr/lib/python3.5/urllib/request.py\", line 443, in _call_chain\n result = func(*args)\nFile \"/usr/lib/python3.5/urllib/request.py\", line 1286, in https_open\n context=self._context, check_hostname=self._check_hostname)\nFile \"/usr/lib/python3.5/urllib/request.py\", line 1245, in do_open\n raise URLError(err)\nurllib.error.URLError: <urlopen error [Errno -3] Temporary failure in  name resolution>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\nFile \"/usr/lib/python3/dist-packages/softwareproperties/ppa.py\", line    327, in get_ppa_info\n ret = get_ppa_info_from_lp(user, ppa)\nFile \"/usr/lib/python3/dist-packages/softwareproperties/ppa.py\", line    92, in get_ppa_info_from_lp\n return get_info_from_lp(lp_url)\nFile \"/usr/lib/python3/dist-packages/softwareproperties/ppa.py\", line 88, in get_info_from_lp\n return _get_https_content_py3(lp_url)\nFile \"/usr/lib/python3/dist-packages/softwareproperties/ppa.py\", line 108, in _get_https_content_py3\n raise PPAException(\"Error reading %s: %s\" % (lp_url, reason), e)\n softwareproperties.ppa.PPAException: 'Error reading   https://launchpad.net/api/1.0/~ubuntu-wine/+archive/ubuntu/ppa: [Errno -3]  Temporary failure in name resolution'\n\n During handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\nFile \"/usr/lib/python3/dist-packages/softwareproperties/ppa.py\", line 393, in shortcut_handler\n return PPAShortcutHandler(shortcut)\nFile \"/usr/lib/python3/dist-packages/softwareproperties/ppa.py\", line 356, in __init__\n info = get_ppa_info(self.shortcut)\nFile \"/usr/lib/python3/dist-packages/softwareproperties/ppa.py\", line 339, in get_ppa_info\n _get_suggested_ppa_message(user, ppa))\nsoftwareproperties.shortcuts.ShortcutException: Cannot add PPA:   'ppa:~ubuntu-wine/ubuntu/ppa'.\nERROR: '~ubuntu-wine' user or team does not exist.\nError: 'ppa:ubuntu-wine/ppa' invalid\n\n\n", "Q: How to remove the Unity Amazon package in 16.04? I was able to go to the ubuntu software center before and remove it and now it doesn't show up since the switch to the gnome software store. Trying the terminal method of removing the shopping lens doesn't work in this release.\n\n\nA: In Ubuntu 18.04, just deinstall the ubuntu-web-launchers package:\nsudo apt remove ubuntu-web-launchers\n\nIt only contains the Amazon launcher, as you can see by doing\ndpkg -L ubuntu-web-launchers\n\nfirst.\n\nA: The dash still requires the old ubuntu software center to uninstall programs, even though it is not included with 16.04. Install the software-center package and log out and back in to your account and then you will be able to view screenshots of programs and uninstall them by right clicking on them in the dash like in previous versions.\n\nA: Removing the unity-webapps-common package removes Amazon from the dash. Since the Amazon webapp is part of that package, you can't just remove the Amazon portion (well, short of editing the source code). This is a problem when other programs (like Unity Tweak Tool) depend on that package.\nAs noted by fitojb in this answer to another question, however, this command will prevent the Amazon icon from showing up in the dash:\nsudo rm -rf /usr/share/applications/ubuntu-amazon-default.desktop\n\nHowever, as dobey pointed out in a comment below, when the unity-webapps-common package updates the file will be replaced and the command will have to be run again. A more permanent method is to copy the .desktop file to your local applications directory and then add a line to the file to prevent it from showing up in the dash:\necho 'Hidden=true' | cat /usr/share/applications/ubuntu-amazon-default.desktop - > ~/.local/share/applications/ubuntu-amazon-default.desktop\n\n\nA: As Aibara Iduas suggests, removing /usr/share/applications/ubuntu-amazon-default.desktop is the solution. But it will come back with the next upgrade. The solution to copy the file to ~/.local/share/applications/ubuntu-amazon-default.desktop works only for the current user. To disable this .desktop file for all users on the machine, and to prevent upgrades from putting it back, the solution is to divert the file with dpkg-divert.\nsudo dpkg-divert \\\n  --divert /usr/share/applications/ubuntu-amazon-default.desktop.diverted \\\n  --local \\\n  --rename \\\n  /usr/share/applications/ubuntu-amazon-default.desktop\n\n\nA: You just click on the app then drag it into the trash (it work for me).\n\nA: For me worked this on Ubuntu 16.04 LTS:    \ncd /usr/share/applications\nmv ubuntu-amazon-default.desktop ../~ubuntu-amazon-default.desktop\n\n\nA: To avoid installing apps to unintall the app, I did it manually (in Ubuntu 16):\nsudo rm /usr/share/applications/ubuntu-amazon-default.desktop\nsudo rm /usr/share/unity-webapps/userscripts/unity-webapps-amazon/Amazon.user.js\nsudo rm /usr/share/unity-webapps/userscripts/unity-webapps-amazon/manifest.json\n\nIf it is surreptitiously installed again, just run it again, or put it in a cleanup script you run when you update your OS.\nSource:\nhttps://www.lifewire.com/remove-amazon-application-from-ubuntu-4134329\n\nA: Attention: this solution propably only works if you have upgraded from 15.10 to 16.04 LTS\nThats pretty easy now, press windows/superkey. In bash enter amazon to find the amazon software.\nRight click it and see the detailed information, where you shalt find an incredible remove button :)\nHave fun.\n\nA: How can I remove Unity web apps?\n-> Try: \nsudo apt-get remove unity-webapps-amazon*\n\nCan't say it's the solution, because first thing I did, was search \"amazon\" files and manualy deleted  \"/usr/share/unity-webapps/userscripts/unity-webapps-amazon/\" (no this it didn't remove Amazon) and now the apt-get wont find the Amazon.\n", "Q: How to install Epson L375 printer in Ubuntu 16.04 I have installed now Ubuntu 16.04 in my computer, but the installation of my Epson Ecotank L375 printer failed. I can not find the driver of the printer and there is not a lsb file for the drivers installation. What could I do to solve this problem? \n\nA: All I had to do is run this command before adding a printer and the printer is recognized immediately\nsudo apt-get install printer-driver-escpr\n\nThe solution was provided on http://askubuntu.com/questions/763157/ubuntu-16-04-installing-epson-driver-fails-on-lsb-3-2 as pointed out by @AntoniosHadjigeorgalis.\n\nA: Add Ubuntu Trusty repository via system>software update>other software install lsb and then remove the repository. You can install the driver. This is the only way now till a solution is brought up by Canonical. The lsb files work in Xenial and even if one does an update from Trusty to Xenial with lsb installed, they are left behind and fully functional.\n", "Q: Distorted sound with bluetooth speaker in Ubuntu 16.04 I just upgrade to Ubuntu 16.04 this morning. \nWhen I got to work I connected my Blackweb Tsunami bluetooth speakers, and they connected fine, but the sound is so distorted, and almost sounds monotone. \nIt sounds horrible, these speakers worked perfectly in Ubuntu 15.10. \nEDIT:\nWhen I try to set the device sound mode from HSP/HFP to A2DP as suggested in LiveWireBTs answer the sound stops working completely.\nAny help would be appreciated.  \n\nA: Go to Sound Settings, select your Bluetooth audio device and check that the device is set to A2DP not HSP/HFP (which is mono and has very low quality).\n\nEdit: If Bluetooth audio stops working after you do that in 16.04 you need to apply the following workaround: https://askubuntu.com/a/817926/40581 \n", "Q: Booting under MAAS direction error: File not found I am PXE boot a node .... PXE IPV4 starts and then i get the error\nBooting under MAAS direction error: File not found\nI have downloaded a 14.04 image and Cluster Master is connected, Status Enabled and Images synced.......\n\nA: I had the same issue this morning.\nCheck under settings \"Default Ubuntu release used for commissioning\"\nI wasn't able to use 14.04 anymore.\nAfter adding Image 16.04 commissioning is working again.\nWith best regards,\nJockel\n\nA: In the maas GUI..go the settings>deploy options and change the Default Ubuntu release used for commissioning and save your selection.\n", "Q: MAAS 1.9.1 GUI Link interface I have two interfaces on MAAS 1.9.1\neth0 - External Network\neth1 - Private/Internal Network ie 10.x.x.x with DHCP/DNS configured\nI have MAAS GUI configured to access over eth0\nie http://192.168.1.45/MAAS\nwondering if i need to point MAAS GUI over the internal/private Network\nIf so what would be the command to make the link change with new internal IP\n\nA: By default MAAS GUI (well, Apache actually) is listening on all available interfaces (take a look at /etc/apache2/conf-enabled/maas-http.conf), so unless you have tweaked your Apache configuration otherwise in /etc/apache2/ports.conf, GUI will be accessible from your private network too.\nI guess that you do not actually mean GUI – you mean access of your MAAS server from internal network where your deployed machines are via HTTP. Access to DHCP and TFTP ports is needed, lot's of packets are transmitted to ports 3260, 5240, 5248, 8000, but port 80? No, not needed if you have everything (controllers) in one server. Even tried running tcpdump on MAAS server for curiosity. \n", "Q: Ubuntu 16.04 doesn't see second monitor daisy chained through displayport I have two Dell U2414H monitors connected in chain to AMD R7 250X. Today I installed Ubuntu 16.04 and in settings I see only one monitor while screen is duplicated on second monitor.\nIs there a way to make both monitors work in this config?\n\nA: It a bug which has been reported. \n\nA: The Daisy Chain require Intel HD Graphics. Details in Dell's KB.\n", "Q: Fresh install of Ubuntu and remove windows 10 I am currently running Ubuntu 14.04 alongside Windows 10. Since I never ever use Windows 10, I would like to completely remove Windows 10 and install Ubuntu 16.04. Now there are plenty of websites describing how to install Ubuntu, but I don't know how to remove Windows 10 and use the extra space for Ubuntu. Can anybody help me?\n\nA: Just boot from the Ubuntu installation USB/DVD, and click the Install button, and follow this guide. \nAt Installation type, make sure to select \"Erase disk and install Ubuntu\", \n\n...then proceed according to the guide.\nPS: Backup important files before installing, as the process will delete all data on the HDD.\n\nA: Well if you dont mind beginning from completely new you can go down the following route:\n\nPhase 1: Preperation\n\n\n*\n\n*Download the disk image of your ubuntu of choice.\n\n*Burn the image to a DVD or Write it bootable on an USB stick.\n\n*Make sure your image works before you continue (this is essential)!\n\n\n\nPhase 2 : Cleaning the HDD\n\n\n*\n\n*Boot into your live image and choose to try out\n\n*Press ctrl+alt+t to open a terminal\n\n*Become root by issuing sudo su (no password needed on a live CD for root i.e. password is empty)\n\n*Umount your HDD by issuing umount /dev/sda\n\n*(warning youre crossing the point of no return all data will be ireversible destroyed) !!!!\n\n*Ok to delete you HDD completely issue dd if=/dev/zero of=/dev/sda bs=4MB (let this run for as long it needs, may take a while)\n\n\n\nPhase 3:Installing\n\n\n*\n\n*Reboot now on your live CD/USB\n\n*Choose to install\n\n*?\n\n*Profit!!! (sorry couldnt resist xD)\n\n", "Q: Installing of jdk and jre 1.8 in Ubuntu 14.04 I tried with all the types possible of installing Java\nfor example:\nsudo add-apt-repository ppa:webupd8team/java -y\nsudo apt-get update\nsudo apt-get install oracle-java8-installer\n\nEven I deleted the /usr/lib/java and /lib/jvm folders. I also tried installing but it doesn't work.\nBut in all these I'm getting a same error of :\nE: The package jre1.8.0-77 needs to be reinstalled.\n\nI can't find an archive for it.\nAny help please?\n\nA: Try the following:\nInstall ppa-purge with sudo apt-get install ppa-purge\nThen bash sudo ppa-purge ppa:webupd8team/java\nTry to open your filemanager with gksu and delete the Java folders.\nNext step is to install the ppa again WITHOUT the -y option.\nYou should be able to eccept the terms of service and install java.\nIf you are done check with java -version and javac -version if you are good to go.\nCheers\n", "Q: Ubuntu 16.04 LTS, ZFS, SWRAID and mentoring inquiries It's been awhile since I have posted in this Ubuntu forums site and now I’m utilizing the mailing list. I also tried to check reddit and after reading the FAQ there, this site is the way to go. I am completely nostalgic about this. I've been a member in the Ubuntu Forums since the year 2008. It feels great to be back there and to be new here!\nMoving forward, I was just wondering if you guys can help me out utilizing the new technology that is natively supported when Ubuntu 16.04 was released. It is the ZFS file system. That term is familiar for me because I was trying to study more about FreeBSD a month ago.\nApparently, LeaseWeb (VPS) does not entirely support it and does not want to get the latest stable and release versions. I don't know if it is just them but it seems that other hosts are beginning to offer installers or templates for the 64-bit architecture alone. For me, if a server has less than 4 GB of RAM then a 32-bit version of the server should be used so that the memory won't be entirely wasted. Although, feel free to correct me if I'm wrong.\nGoing back, I asked LeaseWeb that Ubuntu 16.04 was released and hopefully they'll have an install image for it. I also told them that it would be great if they can completely utilize the ZFS feature for their installer template. The reply that I received is that they recommend me to use FreeBSD since currently, ZFS is supported there. I informed them that even though ZFS has been around for a long time, the moment that it is included in an Ubuntu LTS release, it is considered stable. I shared them the articles here. After a few minutes, they replied that my inquiry is going to be forwarded to the programming department. And I have no idea why that department in the first place.\nAs for my other server which is hosted under online.net, I haven't asked them about Ubuntu 16.04. Although, I'll be asking them about it after this post and it is the same with OVH.\nNow, as for Hetzner, I informed them about the new version of Ubuntu LTS and ZFS. They told me that they can easily create an installimage script for it. Although, it will only be available in the 64-bit architecture. It will have LVM and non-LVM versions. I asked them how about ZFS. They said ZFS isn't stable for now. I told them everything that I explained to LeaseWeb. They haven't replied up until now. It is pretty simple. They have a script that they prompt the user to modify and decide. For example, for non-LVM partition, the user can just uncomment a few lines and same thing for the LVM-partition as well as activating and deactivating SWRAID. I was sincerely asking them to make a script that would activate ZFS and additional commands that would activate ZFS' RAID feature. It seems that RAID is integrated to it so why not utilize it? If ever you guys are interested to check their so called installimage script, feel free to visit these articles.\nI sure do hope that you guys can help me out with the installation of Ubuntu 16.04 with ZFS (and ZFS RAID) configuration. By the way, I usually use CentOS 6 and CentOS 7 for my servers. Apparently, I think it is time to shift to Ubuntu 16.04 LTS. It is simply because when I was experimenting with nginx and HHVM from scratch (reading online articles about them), the PPAs are addictive. Although it is just sad that adding modsecurity to nginx means I'd have to compile it from scratch. I was also able to try out EasyEngine although it seems that their version of nginx is old since nginx wanted to use spdy instead of http2. Plus, PHP 5.6 automatically gets installed. I just find it weird since I wanted to focus on HHVM and PHP 7 (fallback) with redis cache (that doesn't actually work plus I have no idea what's the purpose of it), PHP 5.6 still gets installed. HHVM is also set to fallback to PHP 5.6 instead of PHP 7. Just weird.\nBy the way, I am looking forward to use the new feature called \"Snap\" or \"Snaps\" too and definitely interested to be part of the mentoring program.\nThanks so much, everyone.\n\nA: They need to ask their programming department because hosting is a lot of automation of virtualized machines and devices. So even though you think that ZFS is just the ticking of a checkbox, that little checkbox becomes an immense headache when you are managing thousands of hardware boxes running tens of thousands of virtual machines, and trying to make them all work reasonably stable.\nJust because Ubuntu now exists with ZFS does not mean that the whole world is going to jump onto that train right away. It takes a lot of effort and testing to figure how to integrate any \"new\" stuff into an existing infrastructure. And I wouldn't even expect a reputable hosting provider to jump onto that bandwagon before the first point release - in this case meaning 16.04.1 - because in the world of hosting, stability can make or break the entire business.\nSo you think it's time to jump to 16.04 - fine, do so with your own machines. But it's not reasonable to expect or even demand this from your hosting providers. \nIn your place, I would set up a box or three under my own desk and play around with it. In your place, I would probably have done that during the public beta phase already. That would have given me an understanding of the features and limits of the new release, as well as a sense of what it takes to get this going. \n", "Q: How can I force 16.04 to add a repository even if it isn't considered secure enough? I really need to install Nvidia Cuda but I'm getting the error\nE: Failed to fetch file:/var/cuda-repo-7-5-local/Release  No Hash entry in Release file /var/lib/apt/lists/partial/_var_cuda-repo-7-5-local_Release which is considered strong enough for security purposes\n\nCan I force it to install it anyway? I really need to use it, even if it is insecure. I doubt Nvidia will be updating the repo to work with 16.04 anytime soon. \n\nA: I had the same problem trying to install CUDA 7.5 in Ubuntu 16.04. This is due to a missing SHA256 or SHA512 entry in the CUDA package\n (as reported by Debian team here).\nIt seems that we can't force apt-get update to fetch a \"non secure repository\", but I could avoid completely the problem by using the .run file. Here's what I did step by step:\n\n\n*\n\n*Instead of downloading the .deb package, download the .run file (from \nthis page)\n\n*Install a compatible compiler (it seems that cuda 7.5 is not compatible with the default compiler of Ubuntu 16.04):\nsudo apt-get install gcc-4.9 g++-4.9\n\n\n*You may need to install some additional packages (depends on your configuration): \nsudo apt-get install nvidia-modprobe freeglut3-dev libx11-dev libxmu-dev libxi-dev libglu1-mesa-dev\n\n\n*Launch the run file and follow the instructions:\nsudo sh cuda_7.5.18_linux.run\n\nThis worked well for me (don't forget to install the NVIDIA driver)\nEDIT:\nAfter step 2 & 3, if CUDA installer tries to use gcc 5.3.1 (default for ubuntu 16.04) as compiler instead of 4.9 version, you can try to remove the 5.3.1 version, install CUDA, then reinstall the latest gcc version.\n\nA: Change your /var/cuda-repo-7-5-local/Release to the following:\nOrigin: NVIDIA\nLabel: NVIDIA CUDA\nArchitecture: repogenstagetemp\nMD5Sum:\n 51483bc34577facd49f0fbc8c396aea0            75379 Packages\n 4ef963dfa4276be01db8e7bf7d8a4f12            21448 Packages.gz\nSHA256:\n 532b1bb3b392b9083de4445dab2639b36865d7df1f610aeef8961a3c6f304d8a            75379 Packages\n 2e48cc13b6cc5856c9c6f628c6fe8088ef62ed664e9e0046fc72819269f7432c            21448 Packages.gz\n\nRun sudo apt-get update ignoring warnings about invalid signatures, and you're done.\nIf that failed, replace the SHA256 sum with the output of\nsha256sum /var/cuda-repo-7-5-local/Packages.gz\n\nand\ngunzip -c /var/cuda-repo-7-5-local/Packages.gz | sha256sum\n\n\nA: Currently you can use the following commands on Ubuntu 16.04 to install CUDA Toolkit 7.5:\nsudo apt install nvidia-cuda-toolkit\n\n\nA: I can't comment, but adding to @Horse-man's answer:\nYou don't have to uninstall/reinstall gcc if you already have gcc 4.9 installed. For me it was enough to\nsudo unlink /usr/bin/gcc\nsudo ln -s /usr/bin/gcc-4.9 /usr/bin/gcc\n\nMy gcc-4.9 was really 4.9.3 which the CUDA installer disliked, so I executed it using\nsudo sh cuda_7.5.18_linux.run --override\n\nAnd it installed properly.\n\nA: The solution is simple:\ncd /etc/apt/\nrm cuda-VERSIONHERE-local.list\napt-key net-update\napt-get update\n\n", "Q: Installing gfortran and mpich for a new Ubuntu user I am a long-term Mac user who is considering switching to Ubuntu.    I am not a system guru.    I program in fortran and mpi for cfd applications on high-performance computers.\nI am considering getting 32 cores using 2 x\nIntel Xeon E5-2683 V4 processors for software development.     Installing gfortran (gcc-5.2)  and mpich-3.2 on a Mac is reasonably straight forward for someone with my background, but I am concerned that I will have trouble installing gfortran and mpi using Ubuntu linux. \nThe system that I am considering buying is a lot more powerful and cheaper than a 12-core Mac Pro, but it only makes sense if I can get fortran and mpi working on it.   How big of a job is it for someone with very limited Ubuntu experience aside from testing it using a CD on my Mac, which went well?   \n\nA: If you install Ubuntu 16.04, it should be this simple to install mpich3.2 and gfortran 4.5 with GCC 5.3:\nOpen a terminal\nRun the following command:\nsudo apt-get install gfortran mpich gcc-5\n\n", "Q: Failed to fetch 'us.archive.ubuntu' when sudo apt-get update, cannot connect to network Ok, so I'm running Ubuntu server 14.01 LTS in virtualbox, and I'm trying to sudo apt-get update, but I get an error saying that it failed to fetch us.archive.ubuntu.com and security.ubuntu.com . I figured they might be down or something, and waited over 24 hours. Still failed. Then, I tried to ping 8.8.8.8 and it says connect: Network is unreachable . I tried changing network adapters in vbox from host-only to bridged, and vice versa. Nothing. Help?\nedit: My network connection is just fine outside of my vm on the host system.\n\nA: \"host only\" means just that; the VM can only talk to the host, nothing beyond that. So that's expected.\nWhen you say you switched to bridged mode, did you actually restart the VM? If not, it would still have the old, host-only address, and of course it wouldn't be able to talk to the outside world, as it wouldn't be getting an address from your router (an improper use of the term, but we're stuck with it). \nEither bridged mode or NAT-ed mode should work, no reason why it shouldn't, \n", "Q: Ubuntu 16.04 failed clean install on new hard drive I'm attempting a clean install on a new hd on Dell XPS 8900 i7-6700, but installation fails at \"Preparing to install Ubuntu\" with an error message \"ubipartman failed with exit code 10\".\nI can boot from the usb stick, but installation won't start from there either.\nI've tried switching to ACHI, turning the secure boot off and adding 'nodmraid' to cli boot after 'quiet splash' before double dash in various combinations.\nAny help or insight?\nPressing Esc or F6 has no effect in UEFI boot. I tried changing \n    linux   /casper/vmlinuz.efi  file=/cdrom/preseed/ubuntu.seed boot=casper only-ubiquity quiet splash ---  \n\nto\n    linux   /casper/vmlinuz.efi  file=/cdrom/preseed/ubuntu.seed boot=casper only-ubiquity quiet splash nodmraid ---\n\nin the UEFI boot options, but it didn't help. This seems to be different than the 12.10 ubi-partman case.                    \n\nA: I found an answer that fixed it for me in this thread\nhttp://www.linuxquestions.org/questions/linux-hardware-18/the-new-dell-xps-8900-a-4175559854/\nWhen entering grub during installation, I changed the line to\n    linux   /casper/vmlinuz.efi  file=/cdrom/preseed/ubuntu.seed boot=casper only-ubiquity quiet splash pcie_aspm=off ---\n\nand that did the trick. I followed info in this link\nAfter booting I made the fix permanent by editing the line in grub that starts “GRUB_CMDLINE_LINUX_DEFAULT” and adding the following:\nquiet splash pcie_aspm=off\n\nA: You need to add a trusted source in the bios. Go to security, add a very easy password and then more menu items will appear.  Then set your password to nothing when you are finished (important).  See if you can boot. They do not tell you this in the install screen.   You can also go to legacy, but you need to be in legacy mode (bios) to get a legacy install.  \nI am on legacy and if I switch to uefi, I will get a no boot disk error.  I am not sure why they are not compatible, but that is what it is.\n\nA: pcie_aspm=off FTW\nThanks Karhu! Your answer worked for me on my Asus X555UB-NH51\nFor the uninitiated, you can add the pcie_aspm=off flag by highlighting your boot choice on GRUB's boot selector screen. Then press 'e' to display the editor for adding the string to the end of the line. Once added, press F10 to boot with the modified option(s).\n\nA: I had a bunch of irq errors from clean install on usb. I was able to try to install in safe(graphics) mode but it wouldnt finish install and gave code 10 partman error at end. Figured out how to boot into recovery mode and remounted grub bootloader , it was all automatic and fixed it for me. In case someone new to linux/ubuntu reads this.\n", "Q: How can I set up Ubuntu Server 16.04 to load a GUI on demand? I would like my server to boot to command line by default but load a GUI when I need one.\nI have a virtual machine set up just for testing and I got the standard UNITY GUI installed on it no problem.  I also modified the /etc/default/grub file to boot to text mode.  It wasn't working at first and would still boot to the GUI by default but after some research I found that disabling lightdm got me back to the normal terminal login.  My issue is I can not launch back into the full GUI anymore.  I can use the command 'startx' to launch into a pretty much featureless GUI but that doesn't really help me.\n\nA: Run systemctl start lightdm to start lightdm, and by extension, the rest of the gui, when you desire.  systemctl stop lightdm will shut it down.\n\nA: Take control from the graphical login manager, use following commands:-\nsudo systemctl enable multi-user.target --force\nsudo systemctl set-default multi-user.target\n\nedit /etc/default/grub and change \nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\" \n\nto  \nGRUB_CMDLINE_LINUX_DEFAULT=\"text\"\n\nThen, update the grub, by following command :-\nsudo update-grub\n\nAfter reboot login prompt will appear instead of GNOME login terminal\nTo start GUI use following command :-\nsudo systemctl start lightdm.service && sudo gnome-session\n\n", "Q: Cannot install Nodejs 4 in Ubuntu 14.04 I've run the following commands in my Vagrant machine. As you can see, I have Node 0.10.40 and I cannot make it update it to 4.4.3 which is the current LTS version.\nvagrant@vagrant-ubuntu-trusty-64:~$ node -v\nv0.10.40\nvagrant@vagrant-ubuntu-trusty-64:~$ lsb_release -r\nRelease:        14.04\nvagrant@vagrant-ubuntu-trusty-64:~$ sudo apt-get install --yes nodejs\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nnodejs is already the newest version.\n0 upgraded, 0 newly installed, 0 to remove and 178 not upgraded.\nvagrant@vagrant-ubuntu-trusty-64:~$ node -v\nv0.10.40\n\nThese are the commands I used to install nodejs.\ncurl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\nI also tried running apt-get remove --purge nodejs to no avail.\nWhy does it not update?\n\nA: I finally managed to update it by compiling it from source:\ncd /usr/local/src\nwget http://nodejs.org/dist/v4.4.3/node-v4.4.3.tar.gz\ntar -xvzf node-v4.4.3.tar.gz\ncd node-v4.4.3\n./configure\nmake\nsudo make install\nsudo npm install npm -g\n\n", "Q: New \"Ubuntu Software\" not working (16.04) After upgrading to Ubuntu 16.04, I tried to use the new software center that came along with it, but I found it to have a few issues. One, it didn't detect all the applications I had previously installed and two, whenever I tried installing new software with it, a new icon on the launcher (saying \"Waiting to Install\") appears, but no progress is made and the icon is stuck on the launcher. \nHowever, I don't encounter any of these issues in the older Software Center. Does anybody know why this may be? \n\n\nA: I resolved this same issue using 'check for updates' thru the 'About this Computer'-->'Details' menu found thru the top right menu area of the desktop.  \n\nA: Try installing the old software-center from  the commandline:\nsudo apt install software-center\n\nOr try installing synaptic\nsudo apt install synaptic\n\n\nA: Try to download and install the old Software Center from the new Software Center. Just type in the name in the new Software Center, find it and use it.\n", "Q: The new software center in Ubuntu 16.04 shows no application data found  This is the error I get when I open the software center. I've tried rebooting and running sudo apt-get update but I see no improvement. It worked earlier but I don't know what went wrong since then. I'm using Ubuntu 16.04 final release on a Dell Inspiron 15R. Any advice will be appreciated. Thanks in advance.\nEDIT: The problem magically solved itself without me doing anything special (or maybe inadvertently doing something, I don't know). So I'd still like to get to the root of this.\n\nA: I think this has to do with the /var/cache directory, at least that is what I suspect based on my own experience.\nWorkaround that worked for me:\nsudo apt purge gnome-software ubuntu-software\nsudo apt autoremove\nsudo apt install gnome-software ubuntu-software\n\n\nA: It works for me.\nChange Language Support > Regional Formats to English(United States), then reboot your computer.\nSoftware center works properly now.\n\nA: Just had this problem after using bleachbit to cleanup the system on moving from the beta to the official release. Cleaning out all the cache data also blanked out the software center (re:user533424 above). \nIt seems to \"magically\" reappear by anything that regenerates this data. So... \nsettings>region languages> ... and changing or reinstalling your current language \n....also worked for me.  \n\nA: \nHappenes after you used BleachBit with root access and cleaned App\n  cache Data\n\n\n\n*\n\n*Open Ubuntu Software Center\n\n*Click on updates tab\n\n*Click on small refresh button located at the top-left corner\n\n*Wait for it\n\n\nRefer pic for refresh button\nEverything will be back to normal\n\n\nA: Yes, it seems to be a language configuration issue. Ridiculously impossible out-of-the-box glitch, yet there it is in an LTS release. :\\\nEven if your system is in English already, re-select it in System Settings > Language Support, re-apply system-wide, and reboot. Now the new app store actually functions.\n\nA: I had the same problem. But my problem was not rooted in language setting or anything related to that. My problem was cuased by a program called GoGui; a game of go interface program that can connect to different engines. I found solution to my problem through launchapad post: https://bugs.launchpad.net/ubuntu/+source/gnome-software/+bug/1563155 #28 and #29. So basically the problem was the gogui registers file types of *.xml to x-go+xml which I guess Ubuntu Software tries to open with but can not be found. Deleting /var/cache/app-info/xmls/fwupd.xml and unregistering the the created lines by Gogui in  /usr/local/share/mime/globs and /usr/local/share/mime/globs2 solved the problem for me!   \n\nA: I got my software center working by changing the language into English. But I can see yours is already in English, so that will probably not help you...\n\nA: I started while installing synaptic-package-manager. Multiple events started appearing, but actual installation did not start. I used bleachbit (as root) a few times, as the installation was on and using sudo apt-get update for every app installation. Unchecked the deletion of apt files from bleachbit. I managed to install synaptic package manager from command line after reboot using sudo apt-get install syanptic-package-manager. Used it to reinstall ubuntu-software. Now the all applications are listed. \n\nA: This problem is pretty annoying and tends to plague me sometimes. But what seems to work is killing the application from the terminal.\nps aux | grep -i gnome-software\nkill -9 <replace with PID number>\n\nThen restart Software and hope for the best.\n\nA: the Ubuntu Software Center on my PC is also showing \"No application data found\" but that appeared right after I was mounting /var/cache as tmpfs. I've experienced this issue with previous versions of the Ubuntu Software Center as well and therefore decided not to use a tmpfs for /var/cache any longer but I also couldn't figure out how to restore those files... Anyhow as per definition /var/cache is intended for cached data from applications. Such data is locally generated as a result of time-consuming I/O or calculation. The application must be able to regenerate or restore the data. Unlike /var/spool, the cached files can be deleted without data loss. The data must remain valid between invocations of the application and rebooting the system.\nFiles located under /var/cache may be expired in an application specific manner, by the system administrator, or both. The application must always be able to recover from manual deletion of these files (generally because of a disk space shortage). No other requirements are made on the data format of the cache directories.\nsee http://www.pathname.com/fhs/pub/fhs-2.3.html#THEVARHIERARCHY\nWhich, in this specific case is not true, since the Ubuntu Software Center won't be working correctly after deleting those files.\nHope that's a good hint for the root cause but may not solve the issue.\n", "Q: System Settings doesn't close and continuously changes focus to itself from any other window I just upgraded to Ubuntu 16.04 from 14.04.\nWhen I run System Settings, my CPU usage goes to 100%, and the Settings window always remains in focus. I tried to open System Monitor to kill System Settings, but the focus kept on changing back to Settings. When I click the close button, the current instance of Settings closes, but at the same time a new instance of the window pops up.    \nThe only solution I found was to log out of the system.\nOutput of apt-cache policy unity-control-center:\nunity-control-center:\n  Installed: 15.04.0+16.04.20160413-0ubuntu3\n  Candidate: 15.04.0+16.04.20160413-0ubuntu3\n  Version table:\n *** 15.04.0+16.04.20160413-0ubuntu3 500\n        500 http://jp.archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages\n        100 /var/lib/dpkg/status\n     15.04.0+16.04.20160413-0ubuntu1 500\n        500 http://jp.archive.ubuntu.com/ubuntu xenial/main amd64 Packages\n\n\nA: This was a bug that has since been patched. The version of unity-control-center shown in your output from apt-cache policy unity-control-center is out of date.\nI issued the following commands:\nsudo apt-get purge unity-control-center\nsudo apt-get install unity-control-center\nsudo apt-get install unity-control-center-signon\nNote the change in output.\n$ apt-cache policy unity-control-center\nunity-control-center:\n Installed: 15.04.0+16.04.20170214-0ubuntu2\n  Candidate: 15.04.0+16.04.20170214-0ubuntu2\n\n", "Q: Deleted 16GB MySQL log file, no space freed I deleted a 16GB MYSQL log file via the command line:\nsudo rm /var/log/mysql/slow.log\n\nbut the space has not been freed. Is there some sort of flush I need to run?\n\nA: Per Videonauth suggestion, this can be remedied by rotating the MySQL logs:\nlogrotate -vf /etc/logrotate.d/mysql-server\n\n", "Q: Starting the GUI terminal with specific variables I'm a relatively new user to Linux, so bear with me. I'm currently taking on the Linux From Scratch project, and I have reached a point where it calls for opening a new terminal with certain environment variables. The entire book is intended to be performed in command-line mode, which I am able to access with Ctrl+Alt+f1 (or f2 or f3 or...), but primarily for comfort I prefer to use a terminal window.\nThe book, in chapter II, section 4.4, calls for the reader to create a ~/.bash_profile with only one command: exec env -i HOME=$HOME TERM=$TERM PS1='\\u:\\w\\$ ' /bin/bash, which \"ensures that no unwanted and potentially hazardous environment variables from the host system leak into the build environment\". I've added to the command a dummy variable Q to ensure that it is functioning properly.\nWhen running Ubuntu in a virtual command line, the script is read as expected, and I have the new terminal with the variables initialized. However, I don't get this behavior if I open a terminal window through the GUI.\nIs there any way to open a GNOME Terminal with specific environment variables like what is done by the above exec for the Linux console?\n\nA: If I understand your question correctly, what you want is having gnome-terminal behave like a virtual console as far as rc scripts are concerned.\nThat should be achieved by configuring it to run the shell as a login one.\n\nEdit → Profile Preferences → Title and Command → Run command as login shell\n\n", "Q: Steam pops up with \"out of date client\" dialogue even though I used the .deb from the Steam website Title says it all. Upgraded to Ubuntu 16.04 today, (DAY ONE ^_^) and this seems odd. \nThe exact output: \n\nYour steam package is out of date. Please get an updated version from your package provider or directly from http://repo.steampowered.com/steam for supported distributions.\n\n\nA: The problem seems to be with the libpcre libraries in the version from Valve website, i fixed the problem by removing those libraries from the steam directory forcing steam to use the one installed on the system.\nrm ~/.local/share/Steam/ubuntu12_32/steam-runtime/amd64/lib/x86_64-linux-gnu/libpcre.so.3\nrm ~/.local/share/Steam/ubuntu12_32/steam-runtime/amd64/lib/x86_64-linux-gnu/libpcre.so.3.12.1\n\nYou might have to redo this step after each update steam performs (unless they fix this).\n\nA: I've found the solution for this problem, that works for me, here.\nSimply: \n\n\n*\n\n*you have to remove steam-launcher package using next command in terminal\nsudo apt-get remove steam-launcher\n\n*remove the repo \"http://repo.steampowered.com\" from Software & Updates\n\n*install steam package\nsudo apt-get install steam\n", "Q: gufw on ubuntu 16.04 don't run It doesn't run properly when I click and closes automatically.\n\nA: This post on reddit says that it's because of a broken dependency and the fix for that is:\nsudo apt-get install python-gobject\n\nAfter typing that in a terminal, I'm now able to start GUFW.\n\nA: I have installed it today (2016.05.06) and everything works fine.\nI'm using GUFW version 16.04.1, Ubuntu 16.04 with kernel 4.4.0-21-generic.\nI already had the package python-gi installed at version 3.20.0-0ubuntu1\n\nA: Had this problem in Debian Stretch RC3. Basic setup. What fixed it was  net-tools package.\nsudo apt-get install net-tools\n\n", "Q: after ubuntu 16.04 upgrade, certain key doesn't have \"keypress\" event well, I just now upgrade to 16.04 from 14.04\nI find out \"v\" is not working properly. \nafter run xev, it looks like, unlike other normal keys, it only has \"KeyRelease event\".\nKeyRelease event, serial 37, synthetic NO, window 0x4400001,\n    root 0xc4, subw 0x0, time 429479, (123,58), root:(173,547),\n    state 0x0, keycode 55 (keysym 0x76, v), same_screen YES,\n    XLookupString gives 1 bytes: (76) \"v\"\n    XFilterEvent returns: False\n\nHowever, it'll be working for long press.\nBy following https://wiki.ubuntu.com/Hotkeys/Troubleshooting, I believe it's about dot files.\nI've created another account and login, \"v\" is working. (also working in the password field of login window).\nI've deleted many dot files about gnome, but still not working.\nany help would be really appreciated!\n\n\nA: oh, I check out my startup application list and after some tests, I find out it's diodon. I uninstall it and v works again.\n", "Q: /etc/hosts configuration error , ping not working I am newbie to ubuntu plus kerberos , trying to configure kerberos in my vm ubuntu by i am not able to pass the step 2 in configuring hosts .below are the files. i am in the process of learning so please help .\nmy problem is when ping localhost i am getting response but when i ping monarch or krb1 i am getting error .\nhguna@ubuntu:~$ ping -c1 localhost\nPING localhost (127.0.0.1) 56(84) bytes of data.\n64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.034 ms\n\n--- localhost ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.034/0.034/0.034/0.000 ms\n\n\n   hguna@ubuntu:~$ ping -c1 monarch\n    PING ubuntu.spinlock.hr (192.168.7.12) 56(84) bytes of data.\n\n    --- ubuntu.spinlock.hr ping statistics ---\n    1 packets transmitted, 0 received, 100% packet loss, time 0ms\n\nmy etc/hosts looks like below\n127.0.0.1 localhost\n192.168.7.12 ubuntu.spinlock.hr ubuntu krb1.spinlock.hr krb1 monarch.spinlock.hr monarch\nmy etc/hostname look like below\nubuntu\nplease helpe me as to where i am doing wrong\nnote - Both the kerberos server and the client will be installed on the same machine. However, to differentiate between client and server roles, the client will be referred to as monarch.spinlock.hr and the server as krb1.spinlock.hr. in the etc/hosts file\n\nA: Your file /etcc/hosts is just fine. The fact that after the command\nping -c1 monarch\nYou see:\nPING ubuntu.spinlock.hr (192.168.7.12) 56(84) bytes of data.\nmeans that your system can resolve host name monarch to the IP address you told it to.\nIt seems that other network problems / misconfiguration prevents you from pinging that host.\nTo start with try ping 192.168.7.12 and if it fails try to track that error down.\n", "Q: How to do a monthly system backup I want to create an automatic monthly backup on Ubuntu 14.04 LTS - Server Ed., with the following command:\n$ tar -cvpz --exclude=/bckupftp --exclude=/ser --exclude=/proc --exclude=/lost+found --exclude=/mnt --exclude=/sys / | split -d -b 750m - /bckupftp/backup20160422-041400.tar.gz\n\nI added a date and time in the backup filename. It would be nice if this could be set to the actual-backup-date/time automatically. For a cronjob set to run on May 01, 2016 at 1am, the backup-filename would be: /bckupftp/backup20160501-010000.tar.gz.\nCan somebody help me set up a cronjob for this command ?  Thanks, Kevin\n\nA: To set up the cronjob for yr present non-root user, do in terminal:\n$ crontab -e\n\nThe above will open yr (non-root) user's crontab with his/her default editor.\nAlternatively, to do so for the root crontab, but with yr present (presumably non-root) user environment parameters (default editor, etc.):\n$ sudo -i crontab -e\n\nIn yr opened crontab, enter a new line:\n0 01 01 * * /bin/tar -cvpz --exclude=/bckupftp --exclude=/ser --exclude=/proc --exclude=/lost+found --exclude=/mnt --exclude=/sys / | /usr/bin/split -d -b 750m - /bckupftp/backup$(/bin/date +\\%Y\\%m\\%d-\\%H\\%M\\%S).tar.gz\n\n(I did not check the validity of yr tar cmd.)\nNote that:\n\n\n*\n\n*crontab uses a 24-hour clock, military style: 15 means 3pm, 03 means 3am, etc. \n\n*the above cron entry runs at 01:00 o'clock the first day of every month. In terminal , do: man crontab for more info on crontab formats.\n\n*in crontab, it's a good habit to prefix cmds with their full path. To find the full path of any non-built-in cmd, do in terminal $ which <cmd>.  Thus the tar cmd becomes /bin/tar, split becomes /usr/bin/split, etc.. \n\n*as soon as you save the newly edited crontab, the cron job becomes effective. No need to reboot, log out and back in, or restart whatever service.\n\n*when saving yr bckup file(s), the time stamp has the following format YYYYMMDD-HHMMSS.  If you need it to be more precise, try replacing %S with %s in yr crontab entry.\n\n*I am certain (meaning \"with 100% probability\") you can find all the above explained in great details in AU, SE at large as well as in other fora. Remember that StartPage is yr friend.\n\nA: Create a file: /etc/cron.monthly/backups.sh\nmake it executable by: $ chmod +x /etc/cron.monthly/backups.sh\nto tidy it up, create a variable:\nDATE=`date +%Y.%m.%d-%H.%M.%S`                   # eg. 2016.04.22-13.01.59\n\nAnd then reference your command above with:\n/bckupftp/backup${DATE}.tar.gz\nIt would produce a file similar to:\n/bckupftp/backup2016.04.22-13.01.59.tar.gz\nFeel free to remove dots to your liking and needs.\n", "Q: 16.04 can't connect via DSL I am on a DSL network which wont connect in Ubuntu 16.04. Tried all the mentioned solutions here, none of them worked. Also pon dsl-provider is not an option for me.\n\nA: I managed to make it work by adding a new dsl connection through sudo pppoeconf, and also making the same dsl connection in Network Connections, then running pon dsl-provider, then reboot.\n\nA: I had the same issue (DSL working in 14.04 and not working in 16.04). The solution was to set ppp MTU to 1492. This can be done by editing the \"DSL Connection 1\" file in /etc/NetworkManager/system-connections and adding mtu=1492 after the [ppp] line like this:\n[ppp]\nlcp-echo-failure=5\nlcp-echo-interval=30\nmtu=1492\n\nAnother way to set it is through the command: ifconfig ppp0 mtu 1492\n", "Q: Eclipse Neon/Mars is very slow/hangs on a fresh 16.04 install and Upgrade Eclipse Mars/Neon running very slow after upgrading to xenial\n\nA: I found the solution when I was on my main machine, I'm now typing this on my tablet, so please excuse the brevity. If you type export SWT_GTK3=0 before invoking eclipse from a terminal, you will load quickly. Googling for 'eclipse' and 'SWT_GTK3' will find the bug report that led me to the solution.\n\nA: open terminal and type following command  \n export SWT_GTK3=0 \n\nadd this to your ~/.profile file to make it persistent across logins (you'll need to logout and log back in to be able to start eclipse from shortcut)\nthen go to your eclipse folder and search for eclipse.ini file\nRight click anywhere in the folder and choose \"open in terminal\" and type following command in terminal  \nsudo gedit eclipse.ini  \n\nand add the following line before --launcher.appendVmargs  \n--launcher.GTK_version 2  \n\nSearch in the file for 256 and replace it with 1024  \n\nA: That works fine, you can also set:\n--launcher.GTK_version 2\n\nin the beginning of your eclipse.ini file. \nThis way if you have a .desktop shortuct it will also work automatically \n", "Q: Removing user names from welcome screen I used to have an LXDM in which there was an option not to 'select' a user to login to, but you had to type the desired username, and only then you can type in the password.\nI like it better than the \"modern\" login screen - is there any way to do that on LightDM or do I have to replace it with LXDM?\n(I have Xubuntu 15.10 in case it's relevant)\n\nA: Create a file by the name of the user in /var/lib/AccountsService/users that contains these two lines:\n[User]\nSystemAccount=true\n\nRestart lightdm either by rebooting or running this from a console:\n$ sudo service lightdm restart\n\nThe user will be treated as a SystemAccount and not be displayed.\nIf the username is myusername the file would be:\n/var/lib/AccountsService/users/myusername\n\nThe user myusername would not show on the Ubuntu login screen, nor would it show in the dropdown of the gear in the tp right of the screen control.\nThis works in Ubuntu 14.04 LTS.\nYou may want to also enable the greeter-show-manual-login function so that the user can login the system.  You can do this by adding this to the [SeatDefaults] section of the /usr/share/lightdm/lightdm.conf.d/50-greeter-wrapper.conf file.\n[SeatDefaults]\ngreeter-show-manual-login=true\n\n", "Q: How do I upgrade Gnome Files (nautilus) in Ubuntu Gnome 16.04 I was using Ubuntu Gnome 15.10 and had upgrade gnome shell via ppa to 3.18. Yesterday I updated my distro to 16.04 and was surprised to find files is now version 3.14!\nHow can I get the latest version?\n\nA: You can add the gnome3 repository to your system and upgrade.\nsudo add-apt-repository ppa:gnome3-team/gnome3\n\nsudo apt-get update && sudo apt-get upgrade\n\nWorked for me.\n\nA: To make it work, I had to first remove the old ppa:\nsudo ppa-purge ppa:gnome3-team/gnome3 \n\nthen update the dist\nsudo apt-get dist-upgrade\n\nand only then:\nsudo add-apt-repository ppa:gnome3-team/gnome3\n\nsudo apt-get update && sudo apt-get upgrade\n\n", "Q: ANACONDA - I have to type export PATH=~/anaconda3/bin:“$PATH” everytime I rerun the terminal Whenever I open a terminal, I have to write\nexport PATH=~/anaconda3/bin:$PATH\n\nto use any feature of anaconda\nI want a persistent path.\n\nA: Wouldn't it be nice if somebody else would handle that for you? ;-)\nEdit your .profile and add something like the following lines:\nif [ -d \"$HOME/anaconda3/bin\" ] ; then\n    PATH=\"$HOME/anaconda3/bin:$PATH\"\nfi\n\n\nA: the file .bashrc (hidden file), located in the home directory, runs codes every time a new terminal is opened.\nThen add a line on it:\nexport PATH=~/anaconda3/bin:$PATH\n\n\nA: Start with:\nsudo nano ~/.bashrc\n\ngo down to the last line in the file and add\nexport PATH=~/anaconda3/bin:$PATH\n\nthen Ctrl+X and then enter\nopen a new terminal and enjoy anaconda--navigator\n\nA: Reinstall anaconda, and notice that at the end of the install process there is a optional selection that allow you to add conda command to your PATH.\nYou can choose to say yes, and then you can use the command conda.\n", "Q: Screen flickering on Ubuntu 16.04 LTS I have just updated (through Software Update) to Ubuntu 16.04 LTS from 15.10. There are random instances of screen flickering throughout usage. After noticing this issue, I installed Compiz Config Settings Manager, selecting Force fulls screen redraws (buffer swap) on repaint, which did nothing. \nIs there any way this could be related to compiz settings or is this another issue?\n\nEDIT: not fixed after clean install, upgrade to kernel 4.5.2, however screen flickering is reduced, it is every now and then (10 minutes apart). I will see if upgrading to kernel 4.6.0-994-generic will fix this. \n\nEDIT: fixed as of kernel 4.6.2 generic,  currently running 4.7.2 without any issues.\n\nA: I suffered the similar problem today, when I upgraded a Lenovo V460 laptop to 16.04 from 15.10. \nMy case is due to bugs in kernel 4.4.0-21, and switching to kernel 4.5.2 solves the issue. You can try a newer kernel from here, and follow the instruction here. \n", "Q: I am unable to login Unity 8 desktop I have installed the unity8-desktop-session-mir package and logout, but no matter how I choose the Unity8, it is fail to login the desktop, it just stuck at the login screen, and I can do nothing but restart the lightdm.\n\nA: Have you installed the driver video? If yes, that is the problem. Mir doesn't work with proprietary drivers for now.\n", "Q: wiFi detection problems after installing Ubuntu 16.04 LTS I had installed Ubuntu 16.04 LTS and having trouble detecting Wifi connection . Please Help..Any suggestions ?\nI did ipconfig /release after logging in my windows 10. Doesn't seem to help. \nHow do I debug this ?\n\nA: Somehow the same issue. My wifi adapter is not detected within graphical session.\nHowever, such a command succeed :\n$ sudo iw dev wlp1s0 scan\n\nLooks like it may be possible to connect using command line... :-|\n", "Q: cannot import saved openVPN configuration file in Ubuntu 16.04 LTS I am trying to import a .ovpn file from the network manager. \nHere are the steps I follow.\n\nNetwork Manager → VPN Connections → configure VPN\n\nThis opens the Network Connections dialogue.\nThen,\n\nAdd → import saved vpn configuration → choose .ovpn file\n\nThis should load my .ovpn configuration, but instead I get a prompt saying\n\nERROR: plugin does not support import capability.\n\n\nI can still use VPN using the command \nsudo openvpn --config ~/openvpn/xxx.conf\n\nis this a bug that needs to be filed?\n\nA: I know this is an old question but since I still couldn't find an (easy) answer I want to help others (and future me).\nUse this\nsudo nmcli connection import type openvpn file FILE_NAME\n\noffcourse replace FILE_NAME with the full path to your file name\nThis will tell you exactly what's wrong with the file and which lines you should edit/delete.\nAfter you edited the file with the recommendations the command gave you. You can import the file.\n\nA: On commenting out the following line with #, I was able to successfully import the VPN config:\n#route remote_host 255.255.255.255 net_gateway default\n\nOthers have reported that commenting out, or removing, this line works for them as well per bug #606365 in launchpad in spite of this being a valid argument.\nThat said, while I'm able to successfully connect to the VPN, I'm not able to hit any host over the VPN. On trying to manually set these values using the network manager GUI, I see that only numerical IP addresses are accepted. String values like remote_host or net_gateway cannot be entered via the GUI.\nI've also had success importing the same .OVPN file without any modification in Fedora 23, Windows 10 (using Viscosity), OS X El Capitan (using Viscosity) and earlier versions of Ubuntu. Something is definitely broken in 16.04.\n\nA: Importing .ovpn profiles inside network manager has recently been improved, but there are still bugs and misleading error messages. Sometimes you can successfully import the .ovpn file by removing a single line that breaks the import procedure. In my case, I removed the line float 1 from my .ovpn file and the file has been imported successfully.\n\nA: Its working :)\nfrom https://zorrovpn.com/howto/openvpn/ubuntu?lang=en\nOpen .ovpn file with a text editor.\nAnd change lines that looks like\nremote 11.2.2.2 443 tcp-client\n\nto\nremote 11.2.2.2\nport 443\nproto tcp-client\n\nThen save .ovpn file and try again to import VPN connection.\n\nA: worked for me:\nsudo apt install network-manager-openvpn-gnome\n\n\nA: *\n\n*open your .ovpn file with any editor\n\n*add # to the beginning of this line to comment it out\nroute remote_host 255.255.255.255 net_gateway default\n\n*Go to IPv4 settings > routes > Check the option “Use this connection only for resources on its network” > press OK > Save\nDone!\nThis is just a wrap up of what worked for me on ubuntu 16.04 based on the other answers and comments here.\n\nA: I am experiencing the same issue.  It looks like a bug, according to this link:\nhttps://bugs.launchpad.net/ubuntu/+source/network-manager-openvpn/+bug/606365\n\nA: You might be suffering from the NetworkManager-openvpn bug #83.\nCurrent suggested workaround is a downgrade to 1.8.10-1, however this version is not available in Ubuntu 21.10.\nIn my case the issue was caused by a PKCS#12 certificate from which I extracted a PKCS#8 CA certificate with\nopenssl pkcs12 -in [input.p12] -cacerts -nokeys -out ca.crt\n\nand specified\nca ca.crt\n\nin the config file before being able to import the connection with\nsudo nmcli connection import type openvpn file your-file.ovpn\n\nYou might have to enter your certificate password for every connection. Consider this a workaround until the issue is fixed upstream and you can import your configuration through the UI without issues again.\n\nA: I've found out that changing \nremote REMOTE_SERVER 12345\n\nwith\nremote REMOTE_SERVER\nport 12345\n\nFixed the issue.\n\nA: For me (Ubuntu 16.04.1 LTS), removing the section\n<extra-certs> \nworked.\nHere is the ovpn file generated by a tunnel provider.\nsetenv USERNAME \"user@provider.xx\"\nclient\ndev tun\nremote host 1194 udp\nremote host 1194 udp\nremote host 443 tcp\nremote host 1194 udp\nremote host 1194 udp\nremote host 1194 udp\nremote host 1194 udp\nremote host 1194 udp\nremote-cert-tls server\ncomp-lzo no\nauth SHA1\nnobind\nverb 3\nsndbuf 0\nrcvbuf 0\nsocket-flags TCP_NODELAY\n\n<ca>\n-----BEGIN CERTIFICATE-----\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\n-----END CERTIFICATE-----\n</ca>\n\n<cert>\n-----BEGIN CERTIFICATE-----\n-----END CERTIFICATE-----\n</cert>\n\n<extra-certs>\n-----BEGIN CERTIFICATE-----\n-----END CERTIFICATE-----\n</extra-certs>\n\n<key>\n-----BEGIN RSA PRIVATE KEY-----\n-----END RSA PRIVATE KEY-----\n</key>\n\nkey-direction 1\n<tls-auth>\n-----BEGIN OpenVPN Static key V1-----\n-----END OpenVPN Static key V1-----\n</tls-auth>\n## -----BEGIN RSA SIGNATURE-----\n## DIGEST:SHA1WithRSA\n## -----END RSA SIGNATURE-----\n## -----BEGIN CERTIFICATE-----\n## -----END CERTIFICATE-----\n## -----BEGIN CERTIFICATE-----\n## -----END CERTIFICATE-----\n## -----BEGIN CERTIFICATE-----\n## -----END CERTIFICATE-----\n\n\nA: In my case the following item caused the problem:\nfloat 1\n\nAfter commenting it out, it worked:\n#float 1\n\n\nA: Nothing here worked for me so I added it to the openvpn config manually.\n$ sudo cp ~/me.ovpn /etc/openvpn/me.conf\n\nThen I start OpenVPN with:\n$ sudo systemctl start openvpn@me\n\n# Enable/disable on computer start\n$ sudo systemctl enable openvpn@me \n\n", "Q: How to upgrade from 14.04 LTS or 15.10 to 16.04 from terminal How to upgrade from 14.04 LTS or 15.10 to 16.04 from terminal. \n\nA: You can use sed for editing your sources.list file. I suggest you to backup it first.\nTo upgrade on 15.10:\nsed -i -e \"s/trusty/wily/g\" /etc/apt/sources.list\napt-get update && apt-get dist-upgrade\n\nTo upgrade on 16.04:\nsed -i -e \"s/wily/xenial/g\" /etc/apt/sources.list\napt-get update && apt-get dist-upgrade\n\n\nA: Try this\nfirst do:\nsudo nano /etc/apt/sources.list\n\nthen change everything with trusty in it to either xenial (for 16.04) or wily (for 15.10)\nthen do:\napt-get update;apt-get upgrade -y\n\nand then there you go, you have a fully upgraded 15.10/16.04 system, you do need to run \napt-get autoremove --purge -y;apt-get clean\n\nafterwards\n\nA: The easiest way is sudo do-release-upgrade.\n", "Q: Ubuntu 16.04 Unity No desktop just background wallpaper I just did a fresh install of Ubuntu 16.04 that I set to log in automatically. When it loads up all I get is the desktop wall paper but not top panel or unity side bar. Previously I was using Ubuntu 16.04 Mate edition and everything worked great. I read this question Ubuntu 16.04 unity desktop environment doesn't load after fresh install but I could not get to a tty screen like the poster in that thread. When I did Ctrl+Alt+F1 all I would get is a blank screen. I've tried switching monitor inputs and going from my nvidia card to the onboard graphics but nothing seems to work. I'm just going to switch back to Mate for now but I would really want to check out what's new in Unity. Thanks for any and all help!\n\nA: Fix compiz problem : \nsudo rm -fr ~/.cache/compizconfig-1\nsudo rm -fr ~/.compiz\n\nThen try this if your session not loading : \nsudo rm -fr ~/.Xauthority\nsudo rm -fr ~/.config/autostart\n\nReinstall compiz \nsudo apt-get install --reinstall ubuntu-desktop unity compizconfig-settings-manager upstart\n\nFinally clear the Unity Desktop :\nsudo dconf reset -f /org/compiz/\nsetsid unity\n\nThis is how I fixed my problem hope it could be helpful to you. \n", "Q: Ubuntu won't upgrade I get this message;\n\nThe upgrade has aborted. The upgrade needs a total of 97.8 M free \n  space on disk '/boot'. Please free at least an additional 17.5 M of \n  disk space on '/boot'. Empty your trash and remove temporary packages \n  of former installations using 'sudo apt-get clean'.\n\nI've tried:\nsudo apt-get clean\n\nand\nsudo apt-get autoclean\n\nBut none of them worked.\n\nA: Your /boot partition is full , you need to free some space.\nI guess you have many old kernels installed so you may want to remove them.\nOpen terminal and type uname -r this is the newest kernel don't remove it.\nThen type dpkg --list | grep linux-image this will output the list of installed kernels , you can remove any/all kernels from the list except the one you got with uname -r by typing sudo apt-get purge linux-image-x.x.x.x-generic.\n", "Q: How can i find that which file was copied from my pendrive last time? I forget my pendrive in my office. I have doubt that someone copies my important documents and files from my pendrive.\nIs there any method to find that which file is copied from my pen-drive?\nPlease tell me also if finding the mac address is possible from which my pen drive is accessed.\n\nA: Unfortunately, no; last access time is the only thing that can help you and it's not recorded by default on FAT filesystems (if you try with stat, you'll find a semi-fake number, based on last mount I think): \nθ64° [romano:/media/romano/PEN8G] % stat present.pdf\n  File: ‘present.pdf’\n  Size: 291235      Blocks: 576        IO Block: 4096   regular file\nDevice: 821h/2081d  Inode: 1599        Links: 1\nAccess: (0644/-rw-r--r--)  Uid: ( 1153/  romano)   Gid: ( 1001/  romano)\nAccess: 2016-04-22 00:00:00.000000000 +0200\nModify: 2016-03-08 10:31:56.000000000 +0100\nChange: 2016-03-10 11:05:26.000000000 +0100\n Birth: -\n\nSeems that access has a 1-day granularity. \nAnd no, there is no log of which device accessed your pen drive. \nAnyhow, anyone that has copied your files can also have faked the last access time or whatever, so no, there is no way to safely say if the files have been read, copied or whatever. \nEncryption is the only safe way to store things on pen drives. \n"]